[{"number": 13259, "title": "Implement SpatialPyramidPooling", "body": "PR Inspired from the work of @luizgh and @RikHeijdens.\r\nReferences:\r\n- He, Kaiming et al (2015): Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. http://arxiv.org/pdf/1406.4729.pdf.\r\n- [Implement SpatialPyramidPooling](https://github.com/Lasagne/Lasagne/pull/799)", "comments": ["Can one of the admins verify this patch?", "@yardstick17, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @fchollet and @jart to be potential reviewers.", "Jenkins, test this please.", "Maybe this would be a better fit for contrib. The use case for this layer is fairly niche and wouldn't warrant inclusion in core layers.\r\n\r\nA bit of feedback:\r\n\r\n- It is preferable not to have API keywords related to implementation details. API keywords should be about domain-specific parameters, i.e. about what users care about.\r\n- The API proposed is not consistent with that of other pooling layers.", "@fchollet I have updated the PR, please have a look.", "@fchollet can you take another look?", "Thank you for your patience. Sorry for the delayed review.", "@yardstick17 did you address all of @fchollet comments?", "@drpngx Yes, I incorporated the changes suggested by @fchollet.", "Thanks! @fchollet it's ready to review again.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @martinwicke: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@fchollet can you see if the changes are good? ", "Nagging Assignee @martinwicke: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @fchollet: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "@fchollet any updates on this?", "Nagging Reviewer @fchollet: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @fchollet: It has been 30 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @fchollet: It has been 45 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @fchollet: It has been 60 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @fchollet: It has been 75 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Assignee @martinwicke: It has been 96 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yardstick17 are you OK with the solution @fchollet is proposing?", "I am not sure of his proposal. He has two concerns regarding it- maintenance and coding styles.\r\n\r\nIt would be a good idea to maintain a layer which has this many citations \r\n> Spatial Pyramid Pooling in Deep Convolutional Networks for Visual ...\r\n> by K He - \u200e2014 - \u200e**Cited by 1218** - \u200eRelated articles\r\n\r\nRegarding the coding styles:\r\nIf I am violating any, why there is not system capturing this. I am happy to fix if there are considered good.\r\n\r\nLast words: The concerns were raised much later (actually when the PR was in final stage). I beleive you guys beleive it to be community driven. If it doesn't serve the purpose, I am happy to revert.", "I am sorry about the back and forth, and the long wait. We are very aware that the reviews are a bottleneck, and we are working on ways to remove that bottleneck. We also cannot maintain and support everything in TensorFlow, so for now, your own repo is probably the best option. \r\n\r\nWe are working improving how the community can contribute to TensorFlow. One such approach is a new SIG, maintaining a new repo, containing layers that are important, but which we cannot maintain in TensorFlow itself. A sketch of this proposal is in https://github.com/tensorflow/community/pull/18, expect a more detailed proposal soon as we form a special interest group.\r\n\r\nI will close this PR."]}, {"number": 13258, "title": "small mistake", "body": "https://github.com/tensorflow/tensorflow/blob/b46340f40fe5e2ec9bfcd385b07cfb914055fb51/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py#L48\r\n\r\nthis should be only y, not ||y||^2", "comments": ["@vsaase Can you fill a [template](https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md) with good explanation of the pointed mistake along with the wiki links or substantial proof?\r\nI can create PR for this one!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@vsaase is right. Thanks for pointing out this mistake. ", "We will include the fix in the next release.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 28 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 43 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 13257, "title": "Changed output directory for Pi CI build to fix permissions problem with nightlies", "body": "", "comments": ["Sorry for yet another PR! Everything's building now, this is just a fix for the artifact copying stage in Jenkins.", "No worries.\r\nFor makefile build I know what the problem is, and will fix it now."]}, {"number": 13256, "title": "segfaults in Saver.restore with missing files", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: centos 7\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-2456-g7abd587 1.4.0-dev20170922\r\n- **Python version**: 3.6\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport os\r\n\r\na = tf.get_variable('W', shape=[1,1,256,60], dtype=tf.float32)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    saver = tf.train.Saver()\r\n    saver.save(sess, './model')\r\n\r\nos.remove('model.data-00000-of-00001')\r\n\r\nwith tf.Session() as sess:\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, './model')\r\n```\r\nThe above code segfaults in today's nightly build. I expect an exception.", "comments": ["@ppwwyyxx You are right! It shut down python unexpectedly in windows as well.\r\nI guess this issue is caused due to the changes in `tensorflow\\core\\grappler\\grappler_item` file!", "I appear having the same issues with a Windows build of tensorflow (installed via pip, version 1.3.0 for Python3.5). I found the problem when porting my scripts from Linux to windows, and I tested the sample code above and got the same result. ", "This ! I happened to rename my FILENAME.data-00000-to-00001 to NEWNAME.data-0000-to-00001 (forgetting one zero), and spend hours trying to find from where the seg fault was coming...", "Fixed already in master."]}, {"number": 13255, "title": "Fix cudnn v6 function being used in cudnn v5 build", "body": "Fixes #13249", "comments": ["Jenkins, test this please.", "@benbarsdell re-running the tests as failure seemed un-related otherwise please take a look at the failures.", "Hi, can we please merge this pull request if the reviewers are fine with it?\r\n\r\nThanks!!", "Gentle ping on this.", "@andrewharp any idea what the hold up on the 'Ubuntu CC' test is? Is that the last blocker on the merge?"]}, {"number": 13254, "title": "RNNParamsSavable breaks when there is more than one RNN", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 5.2\r\n- **CUDA/cuDNN version**: 6.0\r\n- **GPU model and memory**:  Tesla K80, 12gb\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n    sess = tf.Session()\r\n    cell1 = cudnn_rnn_ops.CudnnGRU(1, 10, 10, input_mode=\"linear_input\")\r\n    sz = cell1.params_size()\r\n    params1 = tf.get_variable(\"rnn1/rnn\", sess.run(sz))\r\n    save1 = cudnn_rnn_ops.RNNParamsSaveable(\r\n        cell1, cell1.params_to_canonical, cell1.canonical_to_params,\r\n        [params1], name=\"rnn1/rnn\")\r\n    tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, save1)\r\n\r\n    params2 = tf.get_variable(\"rnn2/rnn\", sess.run(sz))\r\n    save2 = cudnn_rnn_ops.RNNParamsSaveable(\r\n        cell1, cell1.params_to_canonical, cell1.canonical_to_params,\r\n        [params2], name=\"rnn2/rnn\")\r\n    tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, save2)\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    saver = tf.train.Saver()\r\n    saver.save(sess, \"save\")\r\n```\r\n\r\n### Describe the problem\r\nAn exception is thrown: \r\n\"ValueError: At least two variables have the same name: rnn1/rnn\"\r\n\r\nThis works if there is only one RNN. If I remove the name parameters the model will save, however only one of the two RNNs will have their weights/biases saved to the checkpoint as individual tensors, so it will break if I try to restore two `CudnnCompatibleGRUCell` RNNs from this checkpoint.\r\n\r\nAs far as I can tell there is some kind of name clobbering happening within tf.Saver, maybe because `RNNParamsSaveable` set `op` to none for the super class.", "comments": ["@protoget, could you take a look at this issue?", "```RNNParamsSaveable``` is deprecated. Please look out for the new cudnn_rnn **layer APIs** which takes care of cudnn opaque variable saving."]}, {"number": 13253, "title": "Add cmake generated files/dirs in Linux to .gitignore", "body": "This fix adds cmake generated files in Linux to .gitignore\r\n\r\nBefore this fix, after:\r\n```sh\r\n$ tensorflow/tools/ci_build/ci_build.sh CMAKE tensorflow/tools/ci_build/builds/cmake.sh\r\n```\r\nThe following files/dirs are left out:\r\n```sh\r\nubuntu@ubuntu:~/tensorflow$ git status\r\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\r\nUntracked files:\r\n  (use \"git add <file>...\" to include in what will be committed)\r\n\r\n        build/\r\n        tensorflow/core/util/version_info.cc\r\n\r\nnothing added to commit but untracked files present (use \"git add\" to track)\r\nubuntu@ubuntu:~/tensorflow$\r\n```\r\n\r\nThis fix addresses the above issue.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @martinwicke and @benoitsteiner to be potential reviewers.", "Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 13252, "title": "GetConvolve*Algorithms return tensor-op algos", "body": "Attention: @jlebar and @zheng-xq\r\n\r\nThis is the follow-up on the cudnn7 patch. When enumerating convolution algorithms, it moves the tensor_ops toggle into the GetConvolve*Algorithms functions.\r\n\r\nAlso tensor_ops are no longer included in the returned algo list if they are not supported by the cuDNN version or GPU compute capability.", "comments": ["Jenkins, test this please."]}, {"number": 13251, "title": "Fix for RTLD_GLOBAL breakage of Pi builds, and removed Eigen version change that's no longer needed", "body": "", "comments": ["@petewarden, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer."]}, {"number": 13250, "title": "Update RELEASE", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "@Canpio, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @vrv and @benoitsteiner to be potential reviewers."]}, {"number": 13249, "title": "Compilation error since today morning with cudnn 5.1.10", "body": "------------------------\r\n\r\n### System information\r\nMemory : 16GB\r\nProcessor: Intel\u00ae Core\u2122 i7-7700HQ CPU @ 2.80GHz \u00d7 8 \r\nGPU: GeForce GTX 1060/PCIe/SSE2\r\nOS Type- 64 bit\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**: CUDA 8.0 CUDNN 5.1.10\r\n- **GPU model and memory**: GTX 1060 (6GB)\r\n- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n### Describe the problem\r\nSince today morning, I've been getting this error in compiling TF with cudnn 5.1.10 where it seems to be looking for a v6 file even though I've configured it to use 5.1.10. I do not see the same error when building with cudnn6.0.  I compiled it last night with the same exact configuration and it was compiling fine. I've even wiped my system clean and reinstalled the whole environment to make sure there weren't any corrupted libraries. But the error still persists.\r\n\r\n### Source code / logs\r\nERROR: /tensorflow/tensorflow/stream_executor/BUILD:52:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1).\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'cudnnStatus_t perftools::gputools::cuda::wrap::WrapperShim__cudnnSetRNNDescriptor_v6::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:140:30: error: '::cudnnSetRNNDescriptor_v6' has not been declared\r\n       cudnnStatus_t retval = ::__name(args...);                    \\\r\n                              ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:235:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'\r\n   __macro(cudnnSetRNNDescriptor_v6)                           \\\r\n   ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:240:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH_R5'\r\n CUDNN_DNN_ROUTINE_EACH_R5(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'int perftools::gputools::cuda::{anonymous}::CudnnDataTypeToByteSize(cudnnDataType_t)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:902:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'int perftools::gputools::cuda::CudnnRnnParamsDescriptor::GetRegionCountPerLayer() const':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1255:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNInputMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnInputMode(perftools::gputools::dnn::RnnInputMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:865:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDirectionMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnDirectionMode(perftools::gputools::dnn::RnnDirectionMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:877:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnRNNMode_t perftools::gputools::cuda::{anonymous}::ToCudnnRnnMode(perftools::gputools::dnn::RnnMode)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:889:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnDataType_t perftools::gputools::cuda::{anonymous}::ToCudnnDataType(perftools::gputools::dnn::DataType, perftools::gputools::dnn::DataLayout)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:853:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmDesc)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:297:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmDesc)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:320:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdFilterAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardFilterAlgo(perftools::gputools::dnn::AlgorithmDesc)':\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:342:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc: At global scope:\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:560:13: warning: 'bool perftools::gputools::cuda::TensorOpMathEnabled()' defined but not used [-Wunused-function]\r\n static bool TensorOpMathEnabled() {\r\n             ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:129:26: warning: 'tensorflow::thread::ThreadPool* perftools::gputools::cuda::wrap::GetCudaThreadpool()' defined but not used [-Wunused-function]\r\n static port::ThreadPool* GetCudaThreadpool() {\r\n                          ^\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:2001:20: warning: 'perftools::gputools::dnn::AlgorithmDesc perftools::gputools::cuda::{anonymous}::GetCudnnConvolutionForwardAlgorithm(perftools::gputools::Stream*, perftools::gputools::cuda::CUDAExecutor*, void*, int, const perftools::gputools::dnn::AlgorithmConfig&, bool, const perftools::gputools::cuda::ScopedTensorDescriptor&, const perftools::gputools::cuda::ScopedFilterDescriptor&, const perftools::gputools::cuda::ScopedConvolutionDescriptor&, const perftools::gputools::cuda::ScopedTensorDescriptor&, perftools::gputools::ScratchAllocator*, perftools::gputools::DeviceMemory<unsigned char>*)' defined but not used [-Wunused-function]\r\n dnn::AlgorithmDesc GetCudnnConvolutionForwardAlgorithm(\r\n                    ^\r\nTarget //tensorflow:libtensorflow_all.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 666.701s, Critical Path: 125.43s\r\n", "comments": ["@benbarsdell I am not sure `tf1.3` usability with `cudnn 5.1.10` even if you built it! The `tensorflow 1.3` with GPU support currently require  to have `cuDNN v6 or v6.1` as per [NVIDIARequirements](https://www.tensorflow.org/install/install_linux#NVIDIARequirements)", "@printdhruv that is true as long as you do not install grom sources. The page says so as well if you read further down. You can switch to previous versions by configuring TF to do so while building from sources. ", "Also, thanks @benbarsdell for the fix! ", "@abhishek-neurala yes,I read that! But,I am not sure how tf 1.3 will be feasible with older cuDNN in terms of features and usability if you try to build it from source!\r\n", "@printdhruv  I get your point. That'd come down to personal preferences I guess. If you're only using TF and can keep yourself up-to-date with the dependencies, your point is correct. However, if TF is just a small part of a larger codebase which is the case with me, then having backwards compatibility is important since the API changes in the newer versions might cause regression errors and updating the whole codebase to use the new API could become a challenge and might not be feasible. Hope that makes sense. ", "I had this same issue following this https://github.com/cjweeks/tensorflow-cmake with CUDA 8.0 and CUDNN 6.0. Applying https://github.com/tensorflow/tensorflow/pull/13255 fixed it."]}, {"number": 13248, "title": "Fix broken link for object detection model", "body": "In tensorflow/models repo the models have been moved under the directory `research`.\r\n\r\nThis fix fixes a couple of broken links associated with `object_direction`:\r\n`object_detection/` -> `research/object_detection/`\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @andrewharp, @petewarden and @vrv to be potential reviewers.", "@tensorflow-jenkins test this please"]}, {"number": 13247, "title": "Refactoring of canned estimators", "body": "Class specific `model_fn()` used by each canned estimator are replaced by `common_model_fn()` function and moved to `utils.py`, together with common `classifier_head()` and `regression_head()` functions. Canned estimators are then refactored to use these common functions which significantly simplified their code and increased readability.", "comments": ["Can one of the admins verify this patch?", "Some (seemingly unrelated) tests are failing, I need to check why first."]}, {"number": 13246, "title": "Documentation correction", "body": "Hi, \r\n\r\nI think there might be a possible documentation error in that of `tf.stack`. It's said that the numpy equivalent is `np.asarray`. But `np.asarray([])` will take lists of arbitrary shapes and makes it to a `ndarray` whereas `tf.stack` requires all the dimensions of objects in the list to be same. So the equivalent ideally would be `np.stack`.\r\n\r\nCheers, \r\nRamana", "comments": ["Yes, you are correct; thank you for letting us know. I'm submitting a fix for this internally which should make its away externally soon.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This has been fixed, closing."]}, {"number": 13245, "title": "Links to Object_detection model no longer work", "body": "Examples of broken links include\r\n\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/create_pascal_tf_record.py\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md\r\n\r\nThanks!\r\n", "comments": ["Current models in the repository have been moved to the subfolder called 'research', following are the new links:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/create_pascal_tf_record.py\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md\r\n\r\nDocs have been updated for the same, please point to the doc if you see any broken links there.\r\n\r\nThank you. ", "Not on that location anymore either:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py\r\n"]}, {"number": 13244, "title": "BUG:Memory leak in tf.string_split", "body": "[profile_9734.0066.txt](https://github.com/tensorflow/tensorflow/files/1325612/profile_9734.0066.txt)\r\n[profile_9734.0100.txt](https://github.com/tensorflow/tensorflow/files/1325613/profile_9734.0100.txt)\r\n[profile_9734.0150.txt](https://github.com/tensorflow/tensorflow/files/1325611/profile_9734.0150.txt)\r\n\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Centos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow\r\n- **TensorFlow version (use command below)**: tensorflow==1.3.0\r\n- **Python version**: Python 2.7.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A (CPU only)\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:  \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI am seeing noticeably large memory usage when I use `tf.string_split`  within the map function of a dataset API.  I have attached a sample code below. I tried to do a heap analysis and I see `std::basic_string::_Rep::_S_create` constantly growing in size and not freeing up its memory. \r\nIf i remove the `tf.string_split` and just return the line as is, there is no memory held over. This issue is a blocker for us to scale up the tensorflow pipeline to large datasets. \r\nI have attached three output files of pprof over time . \r\n`6447.1  96.8%  96.8%   6447.1  96.8% std::basic_string::_Rep::_S_create`\r\n`  9765.5  96.5%  96.5%   9765.5  96.5% std::basic_string::_Rep::_S_create`\r\n` 14704.7  95.5%  95.5%  14704.7  95.5% std::basic_string::_Rep::_S_create`\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n    import tensorflow as tf\r\n\r\n    def mapper(line):\r\n        line = tf.identity(line)\r\n        tokens = tf.string_split(line, delimiter='\\t')\r\n        return tokens.indices\r\n\r\n    def run():\r\n        filenames = \"sample.txt\"\r\n        # Cluster spec\r\n        cluster = tf.train.ClusterSpec({\r\n            \"worker\": [\"localhost:2223\"]\r\n        })\r\n        server = tf.train.Server(cluster, job_name=\"worker\", task_index=0)\r\n\r\n        dataset = tf.contrib.data.TextLineDataset(filenames)\r\n        dataset = dataset.batch(1000)\r\n        dataset = dataset.map(mapper, 8).repeat()\r\n        iterator = dataset.make_one_shot_iterator()\r\n        next_element = iterator.get_next()\r\n\r\n        with tf.Session(target=server.target) as session:\r\n            while True:\r\n                try:\r\n                    session.run(next_element)\r\n                except tf.errors.OutOfRangeError:\r\n                    break\r\n    run()\r\n#You can run this script by \r\n`LD_PRELOAD=/usr/lib64/libtcmalloc.so.4 HEAPPROFILE=/tmp/profile nohup python -u bug.py > output.log &`", "comments": ["@mrry, do you have any insight into this. Does the dataset pipeline hold string data in some special way?", "The dataset pipeline doesn't do anything special with strings, and relies on `tensorflow::Tensor` refcounting to release the data. \r\n\r\n@sushanthku Can you try making a `tf.constant()` string from a representative line in your file, and running `tf.string_split()` on that constant in a loop to see if the memory growth is similar?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Closing due to lack of activity. @sushanthku Feel free to reopen if you can pare this down to a self-contained reproduction."]}, {"number": 13243, "title": "Linking of rule '//tensorflow/contrib/factorization:gen_gen_clustering_ops_py_wrappers_cc' failed (missing -lcuda?)", "body": "Trying to build Tensorflow from a6f856b2f7920d4f74d7ca4e71967258423cc9f0 with CUDA and just started running into this issue:\r\n\r\n```\r\n____[7,182 / 7,674] Compiling tensorflow/core/graph/node_builder.cc\r\n____[7,183 / 7,675] Compiling tensorflow/core/graph/costmodel.cc\r\n____[7,245 / 7,715] Linking tensorflow/contrib/factorization/gen_gen_clustering_ops_py_wrappers_cc [for host]\r\n____[7,246 / 7,715] Linking tensorflow/contrib/tensor_forest/hybrid/gen_training_ops_py_wrappers_cc [for host]\r\n____[7,247 / 7,715] Linking tensorflow/cc/ops/lookup_ops_gen_cc [for host]\r\n____[7,248 / 7,715] Linking tensorflow/contrib/tensor_forest/gen_gen_model_ops_py_py_wrappers_cc [for host]\r\n____[7,249 / 7,715] Linking tensorflow/contrib/tensor_forest/gen_gen_tensor_forest_ops_py_wrappers_cc [for host]\r\n____[7,250 / 7,715] Linking tensorflow/python/gen_set_ops_py_wrappers_cc [for host]\r\n____[7,251 / 7,715] Linking tensorflow/python/gen_linalg_ops_py_wrappers_cc [for host]\r\nERROR: /build/tensorflow-git/src/tensorflow-cuda/tensorflow/contrib/factorization/BUILD:106:1: Linking of rule '//tensorflow/contrib/factorization:gen_gen_clustering_ops_py_wrappers_cc' failed (Exit 1).\r\n/usr/bin/ld: warning: libcuda.so.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemFree_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD32Async'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventCreate'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamAddCallback'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleLoadFatBinary'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxEnablePeerAccess'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemGetInfo_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuLaunchKernel'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamSynchronize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventQuery'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventElapsedTime'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceCanAccessPeer'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSynchronize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetAttribute'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuFuncGetAttribute'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoH_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamQuery'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxGetState'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSetCurrent'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamWaitEvent'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventSynchronize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleUnload'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGet'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD32_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetSharedMemConfig'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemFreeHost'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuFuncSetCacheConfig'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamCreate'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemGetAddressRange_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetDevice'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetProperties'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoHAsync_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetCount'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleGetFunction'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostRegister_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxRelease'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyHtoDAsync_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoD_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleLoadDataEx'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxRetain'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostAlloc'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuInit'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDriverGetVersion'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetPCIBusId'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventRecord'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuPointerGetAttribute'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceTotalMem_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD8_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceComputeCapability'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemAlloc_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDeviceGetName'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuDevicePrimaryCtxSetFlags'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemHostUnregister'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuModuleGetGlobal_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyDtoDAsync_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuEventDestroy_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuOccupancyMaxActiveBlocksPerMultiprocessor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxGetCurrent'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuStreamDestroy_v2'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuCtxSetSharedMemConfig'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemsetD8Async'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sfactorization_Cgen_Ugen_Uclustering_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cuMemcpyHtoD_v2'\r\ncollect2: error: ld returned 1 exit status\r\n____Building complete.\r\n____Elapsed time: 1247.002s, Critical Path: 405.23s\r\n```\r\n\r\nMy previous successful build (I haven't tried revisions in between) was from abfc9deb7. My build environment hasn't changed significantly since then (no compiler, CUDA, or relevant library changes). I suspect it must be a recent change in the Tensorflow repo that's the cause.\r\n\r\nThe only difference I see between abfc9deb7 and a6f856b2f7920d4f74d7ca4e71967258423cc9f0  in the tensorflow/contrib/factorization path is this:\r\n\r\n```diff\r\ndiff --git a/tensorflow/contrib/factorization/kernels/BUILD b/tensorflow/contrib/factorization/kernels/BUILD\r\nindex 9a6d3c6f5..44eab5601 100644\r\n--- a/tensorflow/contrib/factorization/kernels/BUILD\r\n+++ b/tensorflow/contrib/factorization/kernels/BUILD\r\n@@ -6,6 +6,8 @@ exports_files([\"LICENSE\"])\r\n\r\n package(default_visibility = [\"//tensorflow:__subpackages__\"])\r\n\r\n+load(\"//tensorflow:tensorflow.bzl\", \"tf_cc_test\")\r\n+\r\n cc_library(\r\n     name = \"all_kernels\",\r\n     deps = [\r\n@@ -50,7 +52,7 @@ cc_library(\r\n     alwayslink = 1,\r\n )\r\n\r\n-cc_test(\r\n+tf_cc_test(\r\n     name = \"clustering_ops_test\",\r\n     srcs = [\"clustering_ops_test.cc\"],\r\n     deps = [\r\n```\r\n\r\nI'm not super familiar with how Bazel works, but this looks innocuous to me. I guess something else must be implicated?\r\n\r\nAny idea what could cause it to not add `-lcuda` on the link line? Or perhaps why it didn't need to before but does now?\r\n\r\n```\r\n$ pacman -Q | grep -e gcc-mult -e ^cuda -e ^glibc -e ^cudnn -e ^gcc5 -e '^python ' -e bazel\r\nbazel 0.5.4-1\r\ncuda 8.0.61-3\r\ncudnn6 6.0.21-2\r\ngcc-multilib 7.2.1.20170910-1\r\ngcc5 5.4.0-1\r\nglibc 2.26-3\r\npython 3.6.2-1\r\n```", "comments": ["Not sure how, but could be a result of https://github.com/tensorflow/tensorflow/pull/13224/commits/5c7f9e316d8c7735308a217310350d416d7498cc\r\n\r\nI'll take a look.", "Yeah, seems related. You can work around the issue with --config=monolithic while I figure out how to fix it.", "Just checked, adding `--config=monolithic` does work. My non-chroot build didn't need that though, presumably because of previous build artifacts sitting in the bazel cache?", "Looks like it might be a Bazel linking bug. Building the pip package (bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package) works, and the resulting pip package has contrib/factorization/python/ops/gen_clustering_ops.py. But building this rule explicitly (bazel build //tensorflow/contrib/factorization:gen_gen_clustering_ops_py_wrappers_cc) messes up the dependence of libtensorflow_framework.so on CUDA libraries (the rpaths are wrong).\r\n\r\nI'm tempted to just add something like \"-Wl,-rpath,/usr/local/cuda/lib64\" until this gets fixed...", "Another workaround is to use --action_env=LD_LIBRARY_PATH=/usr/local/cuda/lib64 (or your CUDA installation directory).", "I think we're only seeing this on chroot environments because they're missing CUDA drivers (the linker complains about a missing `libcuda.so`).\r\n\r\nI think the following is a better solution than `LD_LIBRARY_PATH`:\r\n\r\n```\r\necho \"/usr/local/cuda-8.0/targets/x86_64-linux/lib/stubs\" > /etc/ld.so.conf.d/cuda-8.0-stubs.conf\r\nldconfig\r\n```", " add `--action_env=LD_LIBRARY_PATH=/path/to/cuda/lib64` still got the error.\r\nWhat does `--config=monolithic` mean ? What's the difference without this config ?", "Does symlinking in `/usr/local/cuda` and using `--action_env` help? I needed to do both.\r\n\r\nFor monolithic see https://github.com/tensorflow/tensorflow/blob/694892d4c0fba6bd4322e943f8b1483b36f1ae99/tools/bazel.rc#L19 and https://github.com/tensorflow/tensorflow/blob/694892d4c0fba6bd4322e943f8b1483b36f1ae99/tensorflow/BUILD#L423\r\n\r\n(FYI this is still blocked on the Bazel bug)", "I'm able to reproduce this error on tf 1.8, [I include --action_env](https://github.com/ahundt/robotics_setup/blob/master/tensorflow.sh#L190), and I've made sure libcuda.so and a symlink for libcuda.so.1 are on the path.", "Yeah I'm still seeing this bug. Symlinking and adding location of libcuda.so (and symlinked libcuda.so.1) to LD_LIBRARY_PATH isn't helping.", "This issue still exist in TF-1.11 ", "I'm seeing similar issue on 1.12-rc1, goes away when doing a monolithic build", "This and the similar issue with cublas (https://stackoverflow.com/questions/47080760/tensorflow-fails-to-compile) cost me a bunch of time yesterday. It would be nice to get this fixed by default.", "Recently I compiled tensorflow 1.10 from source using gcc 5.4, I have collected some errors may occurred:\r\nhttps://gist.github.com/HawkAaron/575fc12e6598a7a5f93423ee9677847f\r\n\r\nHope this can help you.", "This issue exists on tf1.10.1 with bazel 0.18. I haven't gotten an error so far with --config=monolithic.", "Hi @tycho !\r\nIt seems you are using older versions(1.x versions) of Tensorflow. We recommend that you upgrade  your code base to 2.x  versions as many features and bug fixes has been done in newer versions and let us know if the issue still persists in newer versions. Thanks!", "I'd forgotten this issue even existed. Closing."]}, {"number": 13242, "title": "Add op `tf.contrib.ffmpeg.decode_video`", "body": "This fix tries to address the request raised in #6265 where it was not possible to decode video like the existing op of `decode_audio`.\r\n\r\nThis fix adds the support of `tf.contrib.ffmpeg.decode_video` by invoking ffmpeg the same fashion as `tf.contrib.ffmpeg.decode_audo` so that video could be stored in the tensor `[frames, height, width, channel]`. At the moment, the output format is `RGB24`.\r\n\r\nThis fix fixes #6265.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ilblackdragon, @tensorflower-gardener and @caisq to be potential reviewers.", "Thanks for the review. The PR has been updated. Please take a look.", "Jenkins, test this please.", "Thanks @drpngx for the review. The PR has been rebased and `GetTempFilename` has been moved to tensorflow/core/lib/io. Please take a look.", "Jenkins, test this please.\n\nOn Thu, Oct 5, 2017, 10:52 PM Yong Tang <notifications@github.com> wrote:\n\n> *@yongtang* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/ffmpeg/default/ffmpeg_lib.cc\n> <https://github.com/tensorflow/tensorflow/pull/13242#discussion_r143113330>\n> :\n>\n> > @@ -208,22 +311,23 @@ string GetTempFilename(const string& extension) {\n>      }\n>      struct stat statbuf;\n>      if (!stat(dir, &statbuf) && S_ISDIR(statbuf.st_mode)) {\n> -      return io::JoinPath(dir, StrCat(\"tmp_file_\", getpid(), \".\", extension));\n> +      if (extension.length()) {\n> +        return io::JoinPath(dir, StrCat(\"tmp_file_\", getpid(), \".\", extension));\n>\n> Thanks. Done.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13242#discussion_r143113330>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbWGUzN4odxVQnbcDW65cnGAf84iUks5spcAFgaJpZM4PhHLN>\n> .\n>\n", "Would it be possible to also support usage of the '-vf' argument to ffmpeg to allow setting desired fps and scale for the decoded video?\r\nWhen I use ffmpeg to decode video for learning I'm using it with:\r\n-vf \"scale=w:h, fps=f\"\r\n\r\nwhere w, h, f stands for width height and fps respectively.\r\n\r\nYou guys are doing awesome work, thanks a lot! ", "@Itaydal I think it might help if you could create a separate issue for feature request. I would assume setting desired fps and scale require more discussion about the API/etc.\r\n\r\nYou can assign the issue to me and I can work on it once you create the issue for this feature request.", "@drpngx The Android and Windows Jenkins failure is caused by `mkstemps` which is not available on those two platforms.\r\n\r\nOn Windows we could use native WIN32 APIs to emulate. On Android I am not so sure. I don't have prior experience with NDK, not sure Android has the same tmpfs as normal Linux.\r\n\r\nOn the other hand, since ffmpeg is only to be used on Linux at the moment, I think we could just disable `GetTempFilename()` on Windows and Android for now to move this PR forward.\r\n\r\nIf there is a need in the future to have `GetTempFilename()` on Windows and Android I can spend time working on it.", "Updated the PR and disabled mkstemps on Windows and Android for now. Let me know if implementation is preferred/desired.", "@yongtang could you resolve the conflicts? Sorry we let this fester.", "Thanks @martinwicke. The PR has been rebased with conflict resolved. Please take a look and let me know if there are any issues.", "Jenkins, test this please.", "The error was caused by missing the header include `#include \"tensorflow/core/lib/io/path.h\"` in `ffmpeg_lib_utility_test.cc`. The PR has been updated and pushed.\r\n\r\nI think restart the Jenkins will work.", "Jenkins, test this please.", "There's still a problem in the Windows build: sys/wait.h not found.", "FAILURE\n \n", "FAILURE\n \n", "SUCCESS\n \n", "FAILURE\n \n", "I think all tests passed now.\r\n\r\nThe error related to `MacOS CPU Tests` is the timeout of \r\n```\r\n//tensorflow/python/kernel_tests:slice_op_test\r\n```\r\n, which I assume it is unrelated.\r\n\r\nFor `Ubuntu contrib` failure, it is:\r\n```\r\nERROR: command succeeded, but there were errors parsing the target pattern\r\n...\r\nAll tests passed but there were other errors during the build.\r\n```\r\nMaybe it is unrelated as well?", "Yeah, that's also unrelated, we're having issues with all the tests with the friendly G.", "hi yongtang, I use tensorflow 1.5 on ubuntu and decodevideo.\r\n\r\n`with tf.Session() as sess:`\r\n      `  summary_writer = tf.summary.FileWriter('/home/xucl/app/tensorboard_log/keras_training')`\r\n     `  movie_bin = tf.read_file('/home/xucl/app/data/bilibili/video/DongFangLieChe.mp4')`\r\n     `  movie = tf.contrib.ffmpeg.decode_video(movie_bin)`\r\n     `  movie_ev = movie.eval()`\r\n\r\nbut get an error \r\n\r\n`F tensorflow/contrib/ffmpeg/default/ffmpeg_lib.cc:401] Non-OK-status: ReadInfoFile(stderr_filename, width, height, frames) status: Unknown: Not enough video info returned by FFmpeg [0, 0, 0, 3]Could not read FFmpeg stderr file: /tmp/tmp_file_tensorflow_3_Bi0OjG.err\r\n\u5df2\u653e\u5f03 (\u6838\u5fc3\u5df2\u8f6c\u50a8)\r\n`\r\n", "more information about ffmpeg:\r\n\r\n$ ffmpeg\r\nffmpeg version 2.4.3-1ubuntu1~trusty6 Copyright (c) 2000-2014 the FFmpeg developers\r\n  built on Nov 22 2014 17:07:19 with gcc 4.8 (Ubuntu 4.8.2-19ubuntu1)\r\n  configuration: --prefix=/usr --extra-version='1ubuntu1~trusty6' --build-suffix=-ffmpeg --toolchain=hardened --extra-cflags= --extra-cxxflags= --libdir=/usr/lib/x86_64-linux-gnu --shlibdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --enable-shared --disable-stripping --enable-avresample --enable-avisynth --enable-fontconfig --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-opengl --enable-x11grab --enable-libxvid --enable-libx265 --enable-libdc1394 --enable-libiec61883 --enable-libzvbi --enable-libzmq --enable-frei0r --enable-libx264 --enable-libsoxr --enable-openal --enable-libopencv\r\n  libavutil      54.  7.100 / 54.  7.100\r\n  libavcodec     56.  1.100 / 56.  1.100\r\n  libavformat    56.  4.101 / 56.  4.101\r\n  libavdevice    56.  0.100 / 56.  0.100\r\n  libavfilter     5.  1.100 /  5.  1.100\r\n  libavresample   2.  1.  0 /  2.  1.  0\r\n  libswscale      3.  0.100 /  3.  0.100\r\n  libswresample   1.  1.100 /  1.  1.100\r\n  libpostproc    53.  0.100 / 53.  0.100\r\nHyper fast Audio and Video encoder\r\nusage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...\r\n", "@XuChunling There was a crash in some earlier versions of tensorflow, which has been fixed in #16105. Can you take a look at the latest version and see if the issue is still there? You can open a new issue tracking the bug if the issue persists.", "@yongtang tensorflow1.5 is the latest release version, and here is the API\r\nhttps://tensorflow.google.cn/api_docs/python/tf/contrib/ffmpeg\r\n\r\nI have open a new issue #17143  about it", "@XuChunling PR #16105 is after 1.5 release so it was not in. It is available for `v1.6.0-rc1` and `v1.6.0-rc0`. I assume v1.6.0 will be released fairly soon. "]}, {"number": 13241, "title": "Branch 169712715", "body": "", "comments": []}, {"number": 13240, "title": "Fix Windows build after 5c7f9e316d8c7735308a217310350d416d7498cc", "body": "Fix http://ci.tensorflow.org/job/tf-master-win-bzl/1629/console\r\nDynamic linking on Windows is not well supported yet, we can only still use the monolithic for now.\r\n@gunan ", "comments": ["Smells like a flake:\r\n```\r\n12:15:54 AssertionError: \"First\" does not match \"Too late\"\r\n```\r\nJenkins, test this please."]}, {"number": 13239, "title": "Add ReceptiveField class and coordinate conversion methods.", "body": "This PR adds a `ReceptiveField` class which supports coordinate conversion from the input to the feature space and vice versa while maintaining backwards compatibility.", "comments": ["@tillahoffmann, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.", "Can one of the admins verify this patch?", "Jenkins, test this please.", "@marksandler @andrefaraujo can you take a look?", "yes, will look into it soon. (next day or so)", "apologies on the delay for this, things got busy. Will make sure to review it next week.", "@andrefaraujo, thanks for the feedback. Comments should be addressed.", "@martinwicke , not sure if I need to do something else now. I approved but the \"TF Test Suite\" and \"Ubuntu CC\" checks have been pending for ~12hs now. Let me know if I need to do something.", "Jenkins, test this please. ", "@martinwicke, do you know why the Google cloud source builds are failing?", "No, but it's definitely unrelated to this change."]}, {"number": 13238, "title": "TensorFlow Debugger Colors Are Unreadable on Windows", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version 1.3.0**:\r\n- **TensorFlow version (use command below)**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: not applicable\r\n- **CUDA/cuDNN version**: not applicable\r\n- **GPU model and memory**: not applicable\r\n- **Exact command to reproduce**:  https://www.tensorflow.org/versions/r1.1/programmers_guide/debugger\r\n\r\n### Describe the problem\r\nWhen I run the TensorFlow Debugger (tfdbg) on a Windows command prompt the colors on the tfdbg screen are practically unreadable on my monitor.   Screen capture in the comment below. The text color is indigo and the background color is black.\r\n\r\nI have tried changing the colors on my command prompt but the curses package on tfdbg is changing both the foreground and the background colors on the blue text so that text remains unreadable.\r\n \r\nPlease change tfdbg so that default palette is readable on all monitors and so that colors can be modified.\r\n\r\n### Source code / logs\r\n\r\nScreen capture below.\r\n", "comments": ["![snip_20170922100000](https://user-images.githubusercontent.com/15482785/30756905-57a485d8-9f81-11e7-979d-9509270d97ea.png)\r\n", "cc @caisq ", "@johnsrude, tfdbg also has a readline ui_type, which can be activated with something like\r\n\r\n```python\r\nsess = tf_debug.LocalCLIDebugWrapperSession(sess, ui_type=\"readline\")\r\n```\r\n\r\nWould that suite your use case? Or do you still prefer to use the curses ui_type on Windows, which AFAIK not many users are using?", "Tried `sess = debug.LocalCLIDebugWrapperSession(sess, ui_type=\"readline\")` and got same result.", "Ah, that's because the debugger will fall back to an available ui_type if it can't find the ui_type specified by the user. My guess is that you don't have pyrealine installed on your Windows. You can install it with something like:\r\n\r\n```\r\n\"C:\\Program Files\\Anaconda3\\Scripts\\pip.exe\" install pyreadline.\r\n```", "Problem is I can't use pip (pip3) because machine is offline (long story) . I have compiled pyreadline on my machine.  Where do I need to place it so that tfdbg will find it?", "The dist_packages or site_packages folder of the python interpreter that you are using for tensorflow?", "Got it.  Ran `python3 setup.py install` in pyreadline directory and all's good."]}, {"number": 13237, "title": "Set macro instead of surpressing the warning for third_party/zlib.BUILD.", "body": "As described in issue #13188.", "comments": ["@ahyangyi, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jart and @caisq to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I just signed the CLA.", "CLAs look good, thanks!\n\n<!-- ok -->", "@aselle please review\r\n\r\nJenkins, test this please."]}, {"number": 13236, "title": "Fix documentation for `tf.case`", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13235, "title": "Branch 169689743", "body": "", "comments": ["@caisq, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yuanbyu, @jeffreyadean and @benoitsteiner to be potential reviewers."]}, {"number": 13234, "title": "the version of tensorflow on TensorFlow-experiment in iOS", "body": "i get tensorflow from cocoapods, and the func TF_Version() in \"c_api.h\" can not run.\r\ni want to get the version of tensorflow in \"tensorflow-experiment\",how can i know?", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 13233, "title": "Leaky ReLU as part of tf.nn", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \u039d/\u0391\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: bazel release 0.5.4\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce 940MX, 4Gb\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nA leaky relu function could be part of the standard tensorflow package, under tf.nn. or some other non-contrib module. It could be something like\r\n\r\n```\r\ntf.maximum(x, alpha * x)\r\n```\r\n\r\nCustom leaky relus, which is what people do now, may be largely non-efficient. See for example the discussion in https://stackoverflow.com/q/45307072/5615276 .", "comments": ["Efficiency issue could potentially be fixed by enabling XLA to fuse this pattern into a single op. That's better for maintainability than adding yet another native op (743 in the latest [count](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/core/ops/ops.pbtxt))\r\n\r\n/cc @hawkinsp in case he knows if that's close to being reality\r\n", "I think it's worth adding a leaky_relu to tf.contrib.nn for now. Using tf.maximum is fine.", "I think this was added after r1.3, it's the `max(alpha * features, features)` variant.\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/nn/leaky_relu\r\nhttps://github.com/tensorflow/tensorflow/commit/7a8c63da365106048dc96affddb39e2fdc33da89", "@rryan Indeed, it is a very recent commit. Thanks!"]}, {"number": 13232, "title": "Getting rid from unnecessary call 'inspect.stack'", "body": "Getting rid from unnecessary call 'inspect.stack' in making of decorator in 'tf.contrib.framework.add_arg_scope'\r\n\r\nP.S.\r\nOn my laptop this call gives big overhead for initialization of tensorflow", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can you take a look at #13217?\r\n\r\nThanks", "@drpngx  #13217 is Ok, but it still help to avoid unnecessary call of inspection of stack even if will used *traceback* instead *inspect* module", "Can you comment on that thread?\n\nOn Sep 26, 2017 8:54 AM, \"Alexander Verbitsky\" <notifications@github.com>\nwrote:\n\n> @drpngx <https://github.com/drpngx> #13217\n> <https://github.com/tensorflow/tensorflow/pull/13217> is Ok, but it still\n> help to avoid unnecessary call of inspection of stack even if will used\n> *traceback* instead *inspect* module\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13232#issuecomment-332242695>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbckeWBXl6Irj4n0kQ9jduDOSgF1Dks5smR4tgaJpZM4Pgkw_>\n> .\n>\n", "@rpngx what I should comment? That PR already merged and also this improvements though fixes same problem but making it in different places, so why we should work with both of this PR as one?", "Can you figure out what the problem is with the CLA?\r\n\r\n/CC: @charlesnicholson ", "This code looks reasonable. It's probably worth taking out the inspect stuff from decorators and just requiring that the author pass the name of the decorator function in as a string. (maybe not in this PR though)", "@habibutsu Can you sign the CLA?", "Closing as stalled."]}, {"number": 13231, "title": "Makefile build symbol(s) not found for architecture x86_64", "body": "I'm trying to build tensorflow on a Mac OSx Sierra to be able to use it in a C++ project but when i compile it it gives me this error:\r\n[https://pastebin.com/6K8qBNUF](https://pastebin.com/6K8qBNUF)", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13230, "title": "pb:tensorflow-gpu with cuda 7.5 and cudnn 4 is faster then tensorflow-gpu cuda8 and cudnn 6", "body": "I tested tensorflow 0.8 with cuda 7.5 and cudnn 4 (Maxwell Quadro K620), execution time=0.075s when i test the same code with cuda 8 and cudnn 5 , execution time=0.75 s\r\nI tested the some code with tensorflow 1.3 , cuda 8 ,cudnn 6 ,jetpack 3.1 (jetson tx2) , execution time =0.6s when i try to get the timeline with chromium::/tracing i added tensorflow.python.client import timeline that use libcputi , execution time become =0.3s ,the code run on gpu , because when i run it in cpu execution time become 0.9 s.\r\n\r\nthe code uses face detection with cnn.\r\ni don't understand why the code is faster when i use tensorflow with cuda 7.5 and cudnn4 then cuda 8 and cudnn 5 or 6 . any help please? ", "comments": ["There are all sorts of reasons that when code changes that some things get faster and some things get slower. Without a reproducible test case, we can only speculate. Unless you can provide a reproducible case and post it, there is no way we can look into this.\r\n"]}]