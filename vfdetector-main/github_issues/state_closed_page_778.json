[{"number": 30211, "title": "core dump occurred when run boosted tree classifier demo in official tutorial", "body": "Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz\r\nCentOS Linux release 7.2.1511 (Core)\r\ninstall from pip\r\nCPU-version\r\ntensorflow                               1.14.0rc1\r\ntensorflow-estimator             1.14.0\r\n\r\nRun boosted tree model from [official demo code ](https://www.tensorflow.org/tutorials/estimators/boosted_trees)\r\n`est.train(train_input_fn, max_steps=100)`\r\nIf 'max_steps ' set to 100 , core dump occurred.\r\nIf 'max_steps ' set to 10, demo code go successful.\r\n\r\nI tested the case with tf version 1.13 an another ubuntu docker, issue existed the same.\r\nIn tf version 1.10, there is an exception because the implementation of boosted tree does not support numeric columns.\r\n\r\nI'm a little confused with the parameter 'max_steps'.  Model trained by SGD, steps refers the times of mini_batch, or something likes 'epoch'.  Optimization algorithm for boosted tree model must compute the entire dataset for both individual tree and tree node split. So what's the param 'steps' and 'max_steps' stand for?", "comments": ["@loadwiki I tried executing the official demo code on colab and i set 'max_steps' to 10 and 100, but i did not see an issue. Can you check once and let us know is this still an issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30210, "title": "make label_image.py v2 compatible", "body": "Update `tensorflow/examples/label_image/label_image.py` to make it V2 compatible.", "comments": ["@freedomtan Could you please resolve the conflicts? Thanks!", "@freedomtan Could you please check failed build errors? Thanks!", "@gbaned it seems none of them are relevant. Maybe the master branch happened to have problems. E.g., in the [Ubuntu Python3 PIP](https://source.cloud.google.com/results/invocations/1f017dbe-c933-463f-a739-c6fd1291ae9d/log) log, the problem is in LLVM related code.", "@freedomtan Thank you. Can you please check Ubuntu Sanity failures?  ", "@gbaned I don't know how to check it. I can see logs of Ubuntu Python3 PIP, Ubuntu contrib, and Windows Bazel GPU. But not Ubuntu Sanity and Windows Bazel. See the figure below\r\n\r\n![image](https://user-images.githubusercontent.com/3395998/62347796-7b66c800-b52d-11e9-8c14-e13b96296e4c.png)\r\n", "@freedomtan Sorry for the late response. Can you please check Ubuntu Sanity failures now? Thank you.", "@gbaned Thanks. Yes, I saw them. Fixed pylint Cs.", "Can one of the admins verify this patch?", "@caisq Can you please take a look on this PR? Thanks!", "Adding @MarkDaoust to reviewers. He's looking into the examples directory recently.", "@freedomtan, thanks for taking the time to put together this PR.\r\n\r\nBut even with these updates, this is not the sort of code we want to encourage:\r\n\r\n1. Nobody should be using raw GraphDef's anymore (update them to saved models before you do anything else.).\r\n2. I'd rather not have any examples directly using Session.\r\n\r\nHow did you get pointed to this example? someone should update that link.\r\n\r\nModern examples of how to do something like this is included in: \r\n\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb\r\n\r\nI'm working on deleting this examples/ directory. Please submit future PRs to https://github.com/tensorflow/examples", "@MarkDaoust I wrote it originally :)", "> I wrote it originally :)\r\n\r\n\ud83d\ude32\r\n\r\nI do appreciate you taking the time to come back and update it.\r\nAnd I hope you understand that I mean no disrespect to you or your work.", "i use  label_image.py to predict a lot of picture .however the memory leak. anyone find it ?", "Hi @nanshihui please see the examples I linked to previously for a modern way to do this.", "i turn hub.Module params    trainable to True,\r\nit return \r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for Placeholder  with dtype float and shape [?,299,299,3]\r\n\r\n```\r\ndo you have any ways? @MarkDaoust "]}, {"number": 30209, "title": "Add amp and TRT changes to 1.14 release notes", "body": "Attn: @tfboyd\r\n ", "comments": ["Pending @gunan's merge, this will get into 1.14.1, which will be released soon. We don't yet have a timeline, but I wanted to update the PR."]}, {"number": 30208, "title": "tf keras base layer issue for input_tensors/output_tensors in 1.14.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.17763\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nIn tensorflow keras, the `input_tensors`, `output_tensors`, `output_shapes` of `class Node` was a list in tensorflow 1.13.1, even if it only contains one tensor. Now the behavior changes in 1.14.0, these variables are a single tensor (not a list any more) if there is one single element. We are developing based on tf keras, then this behavior is not backward compatible .\r\n\r\n**Describe the expected behavior**\r\nCan we change them back to list for the single tensor case?\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nfrom tensorflow.python import keras            \r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Dense(5, input_shape=(4,), activation='sigmoid'))\r\nmodel.add(keras.layers.Dense(3, input_shape=(5,), use_bias=True))\r\nmodel.compile('sgd', 'mse')\r\n\r\ndef extract_inbound_nodes(layer):\r\n     return layer.inbound_nodes if hasattr(layer, 'inbound_nodes') else layer._inbound_nodes\r\n\r\nfor l_ in model.layers:\r\n   for node_ in extract_inbound_nodes(l_):\r\n       assert isinstance(node_.output_tensors, list)\r\n       assert isinstance(node_.input_tensors, list)\r\n       assert isinstance(node_.output_shapes, list)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@jiafatom Looks like code snippet is incomplete since some entities are not defined like bias_value. Please provide the complete code to reproduce the issue. Thanks!", "Updated in the original post, The same issue for either `use_bias=True` or `use_bias=False`. Thanks.", "The code snippet you provided executed successfully in TF 1.13.1 as well as TF 1.14\r\nCan you please confirm? Thanks!", "@ymodak Thanks for your reply. I updated the original post to add the assertion there. You can see that the assertion pass for TF 1.13.1 but fail for TF 1.14\r\n\r\nWhen I post code, I have encountered indent issue while posting, so you may see bad indent there.....", "A change was made to make the node attributes mirror the structure of the inputs. So this behavior is expected. \r\nNode attributes are implementation detail - used for creating Keras graph. Probably why this change wasn't announced as a breaking change in the release.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30208\">No</a>\n"]}, {"number": 30207, "title": "Cannot Run Official TF2.0 Example in Official TF2.0 Docker Container", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Docker container tensorflow/tensorflow:2.0.0b1-gpu-py3\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: RTX 2080 Ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nRunning the the official example https://www.tensorflow.org/beta/tutorials/quickstart/advanced in the official container tensorflow/tensorflow:2.0.0b1-gpu-py3 got the following error:\r\n\r\n```\r\n> python advanced.py \r\n2019-06-27 17:09:34.195179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-06-27 17:09:34.231111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.231786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635\r\npciBusID: 0000:01:00.0\r\n2019-06-27 17:09:34.232026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-06-27 17:09:34.232777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-06-27 17:09:34.233391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-06-27 17:09:34.233576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-06-27 17:09:34.234366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-06-27 17:09:34.235052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-06-27 17:09:34.236947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-06-27 17:09:34.237053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.237643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.238201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-06-27 17:09:34.238443: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-06-27 17:09:34.323017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.324202: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x39cfd60 executing computations on platform CUDA. Devices:\r\n2019-06-27 17:09:34.324217: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2019-06-27 17:09:34.342363: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\r\n2019-06-27 17:09:34.343364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d629c0 executing computations on platform Host. Devices:\r\n2019-06-27 17:09:34.343375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-06-27 17:09:34.343534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.344103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635\r\npciBusID: 0000:01:00.0\r\n2019-06-27 17:09:34.344121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-06-27 17:09:34.344128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-06-27 17:09:34.344135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2019-06-27 17:09:34.344141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2019-06-27 17:09:34.344147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-06-27 17:09:34.344153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-06-27 17:09:34.344160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-06-27 17:09:34.344188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.344698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.345203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\r\n2019-06-27 17:09:34.345217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-06-27 17:09:34.345897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-06-27 17:09:34.345905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2019-06-27 17:09:34.345910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n2019-06-27 17:09:34.346029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.346619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-06-27 17:09:34.347293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7784 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2019-06-27 17:09:35.539500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2019-06-27 17:09:35.696347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-06-27 17:09:36.203198: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-06-27 17:09:36.209845: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-06-27 17:09:36.209897: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node my_model/conv2d/Conv2D}}]]\r\n\t [[my_model/dense_1/BiasAdd/_6]]\r\n2019-06-27 17:09:36.209959: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node my_model/conv2d/Conv2D}}]]\r\nTraceback (most recent call last):\r\n  File \"advanced.py\", line 84, in <module>\r\n    train_step(images, labels)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 428, in __call__\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1335, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 589, in _filtered_call\r\n    (t for t in nest.flatten((args, kwargs), expand_composites=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 445, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node my_model/conv2d/Conv2D (defined at advanced.py:36) ]]\r\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node my_model/conv2d/Conv2D (defined at advanced.py:36) ]]\r\n\t [[my_model/dense_1/BiasAdd/_6]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_step_848]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node my_model/conv2d/Conv2D:\r\n images (defined at advanced.py:84)\r\n\r\nInput Source operations connected to node my_model/conv2d/Conv2D:\r\n images (defined at advanced.py:84)\r\n\r\nFunction call stack:\r\ntrain_step -> train_step\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@leimao Just to verify, your CUDA version is 10.0 and cuDNN version is 7. Thanks!", "Note that I was using your official container. My local environment is CUDA 10.1 and I did not install cuDNN.", "Looks like similar issue [#29632](https://github.com/tensorflow/tensorflow/issues/29632). Thanks", "@ymodak Per #29632, this does not look like an issue directly related to the Docker images, since it's failing alongside the official installation instructions as well.", "Is this problem related? \r\nhttps://superuser.com/questions/1417842/tensorflow-gpu-was-working-but-is-not-working-anymore-error-failed-to-get-convo#new-answer\r\n", "Have you tried [Limiting GPU memory growth](https://www.tensorflow.org/beta/guide/using_gpu#limiting_gpu_memory_growth) option?\r\n[tf.config.experimental.set_memory_growth](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/config/experimental/set_memory_growth)", "I used some magic code which some other people have mentioned:\r\n```\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n```\r\nSomehow it worked and the code looks similar to yours. However I don't like the code since it does not make sense to me and there is session in the code. (TF 2.0 has no sessions!) I have a very small model (3 layers of conv) and running on 2080 TI, I don't think GPU memory is an issue here.", "Can you please justify why I should use the above code (either yours or the ones I mentioned)?", "This cuDNN open problem seems to be universal for both TF 1.x and 2.0.", "Looks like a duplicate https://github.com/tensorflow/tensorflow/issues/24496.\r\n\r\nClosing this issue for now, let's use https://github.com/tensorflow/tensorflow/issues/24496 as the canonical issue for this problem.  Please reopen if you don't think this is the same as https://github.com/tensorflow/tensorflow/issues/24496.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30207\">No</a>\n"]}, {"number": 30206, "title": "API link for r1.13 directs to r1.12 instead", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/versions/r1.12/api_docs/python/tf\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe link under API/r1.13 is pointing to r1.12.\r\n\r\nThe link should point to r1.13 https://www.tensorflow.org/versions/r1.13/api_docs/python/tf\r\n", "comments": ["Thanks. Fix is now on prod"]}, {"number": 30205, "title": "installation fails \"FAILED: Build did NOT complete successfully\"", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 1.13\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?:pip \r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: No CUDA support will be enabled for TensorFlow.\r\n- GPU model and memory: \r\n\r\n\r\n\r\n**Describe the problem**\r\nafter I install Bazel and ./configure, I try to run 'bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package', then it gives me error information:\r\n\r\nERROR: /Users/Jianhua/tensorflow/tensorflow/lite/kernels/internal/BUILD:558:1: undeclared inclusion(s) in rule '//tensorflow/lite/kernels/internal:tensor_utils':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/lite/kernels/internal/tensor_utils.cc':\r\n  'tensorflow/lite/kernels/internal/optimized/sse_tensor_utils.h'\r\n  'tensorflow/lite/kernels/internal/optimized/sse_tensor_utils_impl.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 571.490s, Critical Path: 54.09s\r\nINFO: 673 processes: 673 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\n\r\n./configure\r\n\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["@xfsm1912 Downgrade the bazel version to 0.26.0 and check the build. Let us know if you stuck. Thanks!", "OK, it looks like I directly run 'pip install tensorflow' can solve the problem with bazel 0.26.1. Now my tensorflow and keras can run well for LSTM structure ", "@xfsm1912 Good to know that you found workaround. Will close this issue now. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30204, "title": "keras.utils.vis_utils.plot_model() raises TypeError: 'InputLayer' object is not iterable", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.3\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0b1\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: /\r\n- GPU model and memory: GTX 940MX, 430.26\r\n\r\n**Describe the current behavior**\r\nRunning `keras.utils.vis_utils.plot_model()` on a `tensorflow.python.keras.engine.training.Model` object raises `TypeError: 'InputLayer' object is not iterable`. This problem seems very similar to #24622, where the same issue was reported for Sequential objects.\r\n\r\n**Describe the expected behavior**\r\nSave a png image of the model.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom keras.utils.vis_utils import plot_model\r\n\r\ninput_2D = tf.keras.Input(shape=(None, None, 3)) # unknown width and length, 3 channels (RGB)\r\nnetwork_2D = tf.keras.layers.Conv2D(\r\n    filters = 128,  # dimensionality of output space\r\n    kernel_size = 5,  # shape of 2D convolution window (5x5)\r\n)(input_2D)\r\n\r\ninput_3D = tf.keras.Input(shape=(None, None, None, 1)) # unknown width, length and depth, 1 gray channel\r\nnetwork_3D = tf.keras.layers.Conv3D(\r\n    filters = 128,  # dimensionality of output space\r\n    kernel_size = 5,  # shape of 2D convolution window (5x5)\r\n)(input_3D)\r\n\r\nnetwork_2D = tf.expand_dims(network_2D, axis=-2)\r\nnetwork_combined = network_2D + network_3D\r\n\r\nmodel_combined = tf.keras.Model(inputs = [input_2D, input_3D], outputs = network_combined)\r\nplot_model(model_combined, to_file='model_combined.png')\r\n```\r\n\r\n**Other info / logs**\r\n```Traceback (most recent call last):\r\n  File \".../repo/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-26-7a3e8204fbca>\", line 19, in <module>\r\n    plot_model(model_combined, to_file='model_combined.png')\r\n  File \".../repo/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\", line 132, in plot_model\r\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\r\n  File \".../repo/venv/lib/python3.6/site-packages/keras/utils/vis_utils.py\", line 109, in model_to_dot\r\n    for inbound_layer in node.inbound_layers:\r\nTypeError: 'InputLayer' object is not iterable```\r\n", "comments": ["@CreeperLava I tried to reproduce the issue on colab with Tensorflow 2.0.0.beta1 but i received following error message `NameError: name 'plot_model' is not defined` .Thanks!", "Right, I forgot an import. Add `from keras.utils.vis_utils import plot_model`", "Now I am able reproduce the issue with Tensorflow 2.0.0.beta1 and got the same error. ", "You may use ```tf.keras.utils.plot_model``` instead of ```from keras.utils.vis_utils import plot_model```\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/utils/plot_model\r\nThis will keep your consistent with TF framework.\r\nThus your last line of code snippet will be as below;\r\n```python\r\ntf.keras.utils.plot_model(model_combined, to_file='model_combined.png')\r\n```\r\n![image](https://user-images.githubusercontent.com/42785357/60373695-ef093880-99b5-11e9-928d-97c3760d1cb2.png)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30204\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30204\">No</a>\n"]}, {"number": 30203, "title": "Multiple output files for tf.data.experimental.TFRecordWriter", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI have a `tf.data.Dataset` that I want to write to tfrecord files. to do this, I currently use `tf.python_io.TFRecordWriter` to do this, but would like to use `tf.data.experimental.TFRecordWriter`, as it would be more efficient to also do the writing as part of the dataset graph execution. The latter has one limitation, however, which stops me from using it. I need to split my dataset between a number of different shards (files). I could achieve this effect by using the shard method to split the dataset into a number of datasets before writing, but since I want to shuffle the dataset before writing it, this is too expensive.\r\n\r\nHence, I would like `tf.data.experimental.TFRecordWriter` to write a single dataset to multiple files.\r\n\r\n**Will this change the current api? How?**\r\nOne could for instance change the signature to:\r\n```python\r\ntf.data.experimental.TFRecordWriter(\r\n    file_pattern,  # string with format brackets for index, like 'train-shard-{}.tfrecord'\r\n    num_shards=1,\r\n    compression_type=None\r\n)\r\n\r\n```\r\n\r\n**Who will benefit with this feature?**\r\nThose of us who use tfrecord files as a storage format for our datasets and need options for writing such files efficiently and with flexibility.\r\n\r\n**Any Other info.**\r\n", "comments": ["@harahu it is possible to achieve what you want using existing transformations:\r\n\r\n```\r\n  tf.enable_v2_behavior()\r\n\r\n  dataset = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\", \"d\"])\r\n\r\n  def reduce_func(key, dataset):\r\n    filename = tf.strings.join([\"/tmp/test.\", tf.strings.as_string(key)])\r\n    writer = tf.data.experimental.TFRecordWriter(filename)\r\n    writer.write(dataset.map(lambda _, x: x))\r\n    return tf.data.Dataset.from_tensors(filename)\r\n\r\n  dataset = dataset.enumerate()\r\n  dataset = dataset.apply(tf.data.experimental.group_by_window(\r\n    lambda i, _: i % NUM_SHARDS, reduce_func, tf.int64.max\r\n  ))\r\n\r\n  for elem in dataset:\r\n    print(elem.numpy())\r\n```\r\n\r\nThe above will create two files `/tmp/test.0` and `/tmp.test.1` which contain \"a\", \"c\" and \"b\", \"d\" respectively, printing the names of the files.\r\n", "@jsimsa This seems to work, thank you! Quite complex logic for a relatively simple task, though. Might be work documenting somewhere should this move out of `experimental`.", "https://github.com/tensorflow/tensorflow/commit/1d1acc507b281e69dfedafdc4706cc12e55a9933", "You are amazing.", "This example doesn't seem to work in TF 2.0?  On my machine it returns very fast (implausibly fast relative to the size of the dataset I'm trying it on), and no files are written.", "We have a test for this behavior in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/kernel_tests/tf_record_writer_test.py and the test is passing. Please create a separate issue with a minimal reproducible example for your problem.", "@jsimsa \r\ndoes it load whole dataset into memory? Because I tried to run this script on the 10GB dataset with 20 shards... and it does not create any files just eating my memory", "Yes, the `group_by_window` with \"infinite\" group size will have that effect.\r\n\r\nThe challenge with the existing API is that `tf.data.experimental.TFRecordWriter.write()` takes a dataset and in order to create a dataset for a shard, you need to iterate through the entire original dataset. An alternative to materializing all shards in memory would be to iterate through the original dataset multiple time.\r\n\r\nI can imagine extending the API of `TFRecordWriter` to support `num_shards` argument which would avoid the above problems if that's something that you are interested in, please create a feature request for it and I will mark it as contributions welcome to see if anyone in the external community has interest in implementing it. Thanks.", "I posted a solution to this Problem on [StackOverflow](https://stackoverflow.com/a/64540388/11643158). Just tested it for Tensorflow 2.x so no guarantee for TensorFlow 1.x\r\n\r\n`tf.data.experimental.group_by_window` Has to load the whole dataset into memory in order to do some sort of in memory sorting.\r\nTherefore the wired behaviour with not writing any file and just eating memory.\r\n A solution to this Problem is, using a Generator, iterating over the dataset. I assume you already batched   \r\nyour dataset `dataset = dataset.batch(items_per_file)`\r\n\r\n`def write_generator():\r\n    i = 0\r\n    iterator = iter(dataset)\r\n    while True:\r\n        optional = iterator.get_next_as_optional()\r\n        ds = optional.get_value()\r\n        batch_ds = tf.data.Dataset.from_tensor_slices(ds)\r\n        writer = tf.data.experimental.TFRecordWriter(save_to + \"\\\\\" + name + \"-\" + str(i) + \".tfrecord\", compression_type='GZIP')#compression_type='GZIP'\r\n        i += 1\r\n        yield batch_ds, writer, i\r\n        if optional.has_value().numpy() == False:\r\n            break  \r\n`\r\nAnd write the file with a for-loop using the generator:\r\n`or data, wri, i in write_generator():\r\n    start_time = time.time()\r\n    wri.write(data)\r\n    print(\"Time needed: \", time.time() - start_time, \"s\", \"\\t\", NAME_OF_FILES + \"-\" + str(i) + \".tfrecord\")` \r\n\r\n(sorry I am to dump to get the formatting right, so please visit  [StackOverflow](https://stackoverflow.com/a/64540388/11643158))\r\nAs long one single file fits raw in memory, this should just work fine."]}, {"number": 30202, "title": "Adding instructions on how to run CMSIS-NN opt kernels using mbed", "body": "Change-Id: I31812627f95de1f8dea5704d5880cc1ffcd132cc", "comments": ["@freddan80 Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks! ", "Hi @njeffrie ! \r\n\r\nThanks for the comments, and sorry for the late reply. I've been ooo for a few weeks.\r\n\r\nRegarding the line length I was trying to follow the existing style in the readme file. Some existing examples:\r\n\r\n`make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=mbed TAGS=\"CMSIS disco_f746ng\" generate_micro_speech_mbed_project`\r\n\r\nand\r\n\r\n`make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=arduino TAGS=\"\" generate_micro_speech_mock_arduino_library_zip`\r\n\r\nwhere command line instructions don't break line. Was this what you were referring to?\r\n\r\nRegards\r\nFredrik", "@njeffrie , did you have a chance to look at my comment?", "Can one of the admins verify this patch?", "When I run our markdown linter, it breaks those commands into multiple lines.  The style guide indicates to follow line limits \"when possible\" and it's possible here.  Not a huge deal either way - I understand that we break that rule in other places, but unless there's a reason to exceed the line limit I slightly prefer to follow the style guide.", "Thanks @njeffrie! I will leave it like it is for now to be consistent with the other command line commands in that readme file. Is the markdown linter you refer to publicly accessible?", "I don't know of a publicly available version, unfortunately.", "Is it possible to get the test restarted. This PR has only textual changes."]}, {"number": 30201, "title": "Why not support LeakyRelu op for C++ Api?", "body": "I try to import my pb file which use LeakyRelu as activation function in VS2015. I find I can't use \"sess->Create(&gdef)\" to import my pb. Error shows :\r\n> Not found: Op type not registered 'LeakyRelu' in binary running on 9BFHO3E5CP3B44C. Make sure the Op and Kernel are registered in the binary running in this process.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30200, "title": "sys.version_info conditional for enum34 breaks poetry (and contaminates requires in general)", "body": "To prevent enum34 issues such as #15136 a `sys.version_info` conditional was added, as can be seen in the TF source [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L101)\r\n\r\nAs per [PEP508](https://www.python.org/dev/peps/pep-0508/#environment-markers) the recommended way is using environment markers.\r\n\r\nUsing the old `sys.version_info` method breaks tools such as poetry (see eg [issue 844](https://github.com/sdispater/poetry/issues/844), and the [owner's response](https://github.com/sdispater/poetry/issues/844#issuecomment-458178991))\r\n\r\nSpecifically this breaks some of our build pipelines that get the enum34 dependency information from PyPi, which is then put into site-packages, contaminating the build and leading to crashes in various interesting ways (eg if pip/python runs from site-packages, it will use enum34 which breaks when `enum.IntFlag` is accessed)\r\n\r\nI'm hoping this can be fixed for TensorFlow too, see eg an example [here](https://github.com/confluentinc/confluent-kafka-python/pull/583/commits/4e6250d861c5be23fc45d8d11d2b8f0e8e218ab2)\r\n\r\n\r\n\r\n\r\n", "comments": ["PyPi responds with this list of dependencies for tensorflow:\r\n```\r\n$ curl -s https://pypi.org/pypi/tensorflow/1.14.0/json | jq .info.requires_dist\r\n[\r\n  \"absl-py (>=0.7.0)\",\r\n  \"astor (>=0.6.0)\",\r\n  \"gast (>=0.2.0)\",\r\n  \"google-pasta (>=0.1.6)\",\r\n  \"keras-applications (>=1.0.6)\",\r\n  \"keras-preprocessing (>=1.0.5)\",\r\n  \"numpy (<2.0,>=1.14.5)\",\r\n  \"six (>=1.10.0)\",\r\n  \"protobuf (>=3.6.1)\",\r\n  \"tensorboard (<1.15.0,>=1.14.0)\",\r\n  \"tensorflow-estimator (<1.15.0rc0,>=1.14.0rc0)\",\r\n  \"termcolor (>=1.1.0)\",\r\n  \"wrapt (>=1.11.1)\",\r\n  \"grpcio (>=1.8.6)\",\r\n  \"wheel\",\r\n  \"mock (>=2.0.0)\",\r\n  \"backports.weakref (>=1.0rc1)\",\r\n  \"enum34 (>=1.1.6)\"\r\n]\r\n```\r\n\r\ncompare this to llvmlite which explicitly includes a version marker:\r\n\r\n```\r\n$ curl -s https://pypi.org/pypi/llvmlite/json | jq .info.requires_dist\r\n[\r\n  \"enum34 ; python_version < \\\"3.4\\\"\"\r\n]\r\n```", "Added a PR #30255 for the fix."]}, {"number": 30199, "title": "Gradient returns \"Nan\" values when using triplet loss with similar batches", "body": "Hi, \r\n\r\nI am using tf 1.12.0. \r\nMy issue is related to this [one](https://github.com/tensorflow/tensorflow/issues/783). \r\nIt seems that it was closed judging it the benefit are marginal with respect to the effort.\r\nI stumbled on this problem as I was working on my use case. I am not sure how common this is, but I think it deserves a second look. \r\n\r\nI am working on sequence representation learning, and when generating [my triplet loss batches](https://arxiv.org/abs/1703.07737), I end up sometime generating positives that are similar to my anchor. \r\nThis causes the whole gradient to become \"Nan\".\r\n![Screenshot from 2019-06-27 13-03-17](https://user-images.githubusercontent.com/38140485/60261705-d547f280-98dc-11e9-9e5d-e7b84348ff0a.png)\r\n\r\nThe suggested work around of replacing nan values with zeros post-computation isn't sufficient in this case because in reality not the whole batch gradient is null.\r\nPS: I am generating the sequences randomly, however with relatively small vocabulary size and horizon, generating similar sequences does happen.\r\n\r\nFor those having the same issue, in my use case, the work around I opted for is to either condition my samples or add a small random noise. \r\n\r\nHowever I think implementing the discussed \"zero\" solution would be really helpful for future work on sequence representation learning. \r\n\r\nThanks :) \r\n\r\n\r\n", "comments": ["@Jarboui Will it be possible to provide us the ipynb file. It will indeed help us to move faster. Thanks!", "@gadagashwini I can't upload the ipynb in the comment section. \r\nI will past the code bellow for your convenience :) \r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom keras.layers import *\r\nfrom keras.models import Model\r\nimport numpy as np\r\n\r\n# I define the representation model\r\ninp_dim = 5\r\noutp_dim = 5\r\ninp = Input(shape=( inp_dim,), name=\"input\")\r\noutp = Dense(outp_dim, activation='tanh', name=\"simple_layer\")(inp)\r\nmodel = Model(inputs=inp, outputs=outp) \r\n\r\n# I define over here part of my overal loss (note that defining the full loss doesn't change the output.)\r\nanchor = tf.placeholder(tf.float32, [None, inp_dim], name=\"representation_shift\")\r\npositive = tf.placeholder(tf.float32, [None, inp_dim], name=\"representation_shift\")\r\noutp_anchor = model(anchor)\r\noutp_positive = model(positive)\r\nu = tf.math.subtract(outp_anchor, outp_positive)\r\nu_norm = tf.linalg.norm(u, axis=-1) #u_norm is the loss am trying to minimize in this example\r\n\r\n#I define here my gradient operations\r\n_OPTIMIZER = tf.train.AdamOptimizer()\r\ngrads_and_vars = _OPTIMIZER.compute_gradients(u_norm)\r\n\r\nsess = tf.Session()\r\ninit_op = tf.global_variables_initializer()\r\nsess.run(init_op)\r\n\r\n# I generate a dummy example\r\nbatch_size = 10\r\nrandom_input1 = np.random.rand(batch_size, inp_dim)\r\nrandom_input2 = np.random.rand(batch_size, inp_dim)\r\n# And I force it to the case where parts of the data is similar (juste the first line actually)\r\nrandom_input2[0] = random_input1[0] \r\n\r\ndef replace_none_with_zero(l):\r\n  return [0 if i==None else i for i in l]\r\ngrads= replace_none_with_zero(grads_and_vars)\r\n\r\nsess.run(grads, feed_dict={\r\n    anchor: random_input1,\r\n    positive: random_input2, \r\n})[0][0]\r\n# This outputs \"nan\" erroneously \r\n```\r\n\r\nI hope this could be helpful :)  ", "I could reproduce the issue on colab with Tensorflow 1.12.0. by adding following lines of code \r\n```\r\ndef replace_none_with_zero(l):\r\n  return [0 if i==None else i for i in l]\r\ngrads= replace_none_with_zero(grads_and_vars)\r\n```", "The issue here is that u_norm will be zero and the gradient of a zero norm in TF is NaN. You can use the double-where trick to replace zeros (or small values in general) with something valid, and then things should work:\r\n\r\n```\r\nu_safe = tf.where(tf.abs(u) > 0.001, u, tf.ones_like(u))\r\nu_norm = tf.linalg.norm(u_safe, axis=-1) #u_norm is the loss am trying to minimize in this example\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30199\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30199\">No</a>\n"]}, {"number": 30198, "title": "freeze_graph freeze pb error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu16.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):pip\r\nTensorFlow version (use command below):1.12.0\r\nPython version:3.6\r\nBazel version (if compiling from source):0.26\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:9\r\nGPU model and memory:16g\r\nYou can collect some of this information using our environment capture\r\nscript\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\" 2. TF 2.0: python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n\r\nDescribe the current behavior\r\ni have tried convert .pbtxt file and .ckpt file into a frozen .pb file, but this process introduce two node into the frozen .pb file and can not be convert to a tflite file.\r\nMatchingFiles/pattern======>Const\r\nMatchingFiles======>MatchingFiles\r\n\r\nDescribe the expected behavior\r\nthe above mentioned two nodes should not appear in the frozen pb file.\r\nCode to reproduce the issue\r\n[frozen_eval.txt](https://github.com/tensorflow/tensorflow/files/3333897/frozen_eval.txt)\r\n\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nOther info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "@leonzgtee Have look on official website of [Tensorflow lite](https://www.tensorflow.org/lite/convert/python_api#exporting_a_graphdef_from_file_) conversion. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30197, "title": "Resnet model Tensorflow facial landmarks (Detect in real time)", "body": "Hello,\r\nI worked on a project (CNN facial landmarks [github project](https://github.com/yinguobing/cnn-facial-landmark). \r\nI set my own dataset and I trained to detect just the eye region.\r\nMy question is:\r\nDid can this project ( Resnet Model ) support detection in real time?\r\nIf yes, How Tensorflow works to detect in real time?\r\nThanks", "comments": ["Resnet 18 can give you real time performance(or at least near real-time) on a mobile GPU and probably even on a good CPU if you adjust the channels carefully. Just go with a conventional CNN model is my suggestion. I built one a while back(using squeeze net like structures) with fairly good performance.(less than 10ms on a desktop CPU for a single image)", "I have tested a script that tested the frozen model produced after training,\r\nActually, for the video, I get false prediction and I can see landmarks drawn on the video stream.\r\nBut when I open the webcam I didn't get any landmarks drawn and the video is too slow.\r\n      \r\n\r\n            face_img = cv2.resize(face_img, (INPUT_SIZE, INPUT_SIZE))\r\n            face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\r\n            img=np.array(face_img).reshape(1,128,128,3) # update here\r\n            landmarks = detect_marks(img, sess, detection_graph)\r\n\r\nAs you can see batch=1 ,input_width=128 and channels are 3 (RGB).\r\nSo when I tried to increase the number of batchs, I get this error :\r\n> img=np.array(face_img).reshape(32,128,128,3)\r\nValueError: cannot reshape array of size 49152 into shape (32,128,128,3)\r\n\r\nDo you have any idea about how can I solve this error?", "Why are you asking this question on the tensorflow github issues page?  \r\nI do not get what you are trying to do. Why are you trying to reshape a(1,128,128,3) array into a (32,128,128,3) array? You have to do it like this if this is what you really wanted to do\r\nimg_list = []\r\nimg = np.array(face_img)    ## do not reshape into (1,128,128,3)\r\nfor i in range(32):\r\n.......       img_list.append(img)\r\n       \r\nimg_list = np.array(img_list)\r\nimg_list = np.reshape(img_list,(32,128,128,3)    \r\n\r\n\r\n\r\n\r\n", "The reshape into 32 gives an error that I have posted in the previous comment", "You cannot reshape arrays like that. They have to have the same size, before and after reshape.For example, you can reshape an array of shape (64,2) into an array of shape(128,1) etc where the sizes of the flattened arrays are the same", "Stackoverflow is a better place for question like this.", "@capilano Thanks, I will try the code that you posted and I will show what I get", "@ziyigogogo StackOverflow no longer gives any attention to such questions.", "@capilano and @ziyigogogo are correct: Stackoverflow is the appropriate forum for this sort of question.", "Can we train the facial landmark on different models like fasterrcnn, ssd and mobilenet using this https://github.com/yinguobing/cnn-facial-landmark?", "@joel5638 I think that the answer is no, you should change the architecture", "@abdou31\r\nOkay. \r\nWhat if i want to follow traditional Deep Learning methodology in labeling the data, creating tf records and then training using rcnn or mobilenet? Is it possible? Using tensorflow or pytorch.   ", "@joel5638 Yes, give it a try "]}, {"number": 30196, "title": "Signature Issue in Docker image", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker - Arch Linux 5.1.15-arch1\r\n- TensorFlow installed from (source or binary): Through docker\r\n- TensorFlow version (use command below): latest\r\n- Python version: 3\r\n- GPU model and memory: GTX 2080, 8 i think?\r\n\r\n**Describe the current behavior**\r\nWhen pulling the docker image `tensorflow/tensorflow:latest-gpu-py3` and running `apt-get update` some signatures fail to fetch and thus the build fails immediately\r\n\r\n**Describe the expected behavior**\r\nShould update apt issues\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nThis was tested 27/06/2019:  \r\n\r\n    cd `mktemp -d`\r\n    echo \"FROM tensorflow/tensorflow:latest-gpu-py3\" > Dockerfile\r\n    echo \"RUN apt-get update\" >> Dockerfile\r\n    docker build .\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nTerminal log: https://pastebin.com/EYzFE5wP\r\n", "comments": ["I just tried this and did not get an error. Could it be an environment issue?\r\n\r\nPing @angersson for this thoughts\r\n\r\n```\r\n$ docker build .\r\nSending build context to Docker daemon 2.048 kB\r\nStep 1/2 : FROM tensorflow/tensorflow:latest-gpu-py3\r\nTrying to pull repository registry.access.redhat.com/tensorflow/tensorflow ...\r\nPulling repository registry.access.redhat.com/tensorflow/tensorflow\r\nTrying to pull repository docker.io/tensorflow/tensorflow ...\r\nlatest-gpu-py3: Pulling from docker.io/tensorflow/tensorflow\r\n6abc03819f3e: Already exists\r\n05731e63f211: Already exists\r\n0bd67c50d6be: Already exists\r\nd5c73556cc1e: Already exists\r\ne059dd98ac7c: Already exists\r\ne4732fdd9b39: Already exists\r\ncbeb255d6ab1: Pull complete\r\n0809e577f6d6: Pull complete\r\n421e23cecfe8: Pull complete\r\na5abf0996067: Pull complete\r\nd718e4299c08: Pull complete\r\nf401bdaa92ad: Pull complete\r\n6669e38ab1ba: Pull complete\r\n5b6ac7f35d3d: Pull complete\r\nDigest: sha256:e72e66b3dcb9c9e8f4e5703965ae1466b23fe8cad59e1c92c6e9fa58f8d81dc8\r\nStatus: Downloaded newer image for docker.io/tensorflow/tensorflow:latest-gpu-py3\r\n ---> a7a1861d2150\r\nStep 2/2 : RUN apt-get update\r\n ---> Running in 26b8c9aa858a\r\n\r\nGet:1 file:/var/nvinfer-runtime-trt-repo-5.0.2-ga-cuda10.0  InRelease\r\nIgn:1 file:/var/nvinfer-runtime-trt-repo-5.0.2-ga-cuda10.0  InRelease\r\nGet:2 file:/var/nvinfer-runtime-trt-repo-5.0.2-ga-cuda10.0  Release [574 B]\r\nGet:2 file:/var/nvinfer-runtime-trt-repo-5.0.2-ga-cuda10.0  Release [574 B]\r\nIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\r\nHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\r\nGet:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\r\nIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\r\nHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\r\nGet:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\r\nGet:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\r\nGet:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [801 B]\r\nGet:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\r\nGet:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [720 kB]\r\nGet:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [865 kB]\r\nGet:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [10.8 kB]\r\nGet:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1229 kB]\r\nGet:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [561 kB]\r\nGet:19 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3927 B]\r\nFetched 3644 kB in 2s (1715 kB/s)\r\nReading package lists...\r\n ---> e22d3844eff4\r\nRemoving intermediate container 26b8c9aa858a\r\nSuccessfully built e22d3844eff4\r\n``` ", "@wdirons Haven gotten home from work i tried it on a local desktop. No issues there. I guess i'll have to look into the environment tomorrow.\r\n\r\nAny idea what can cause these kinds of glitches?", "Could be an issue upstream, on `apt` side.", "@mrcpj1998 It's also possible that an old local version of `latest-gpu-py3` could be causing this. Does anything change if you run `docker pull tensorflow/tensorflow:latest-gpu-py3` first?\r\n\r\nI also couldn't replicate the issue on my machine.", "@mrcpj1998 Did you get a chance look @angersson's solution. Thanks! ", "After yesterday, did a pacman -Syu and docker pull, then built without cache. I haven't been able to reproduce this image. So definitely something weird, but this issue can be closed", "@mrcpj1998 Will close issue now, Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30195, "title": "make tf.image ops support tf.float16 in tensorflow 2.0", "body": "make tf.image ops like tf.image.extract_patches/tf.image.resize to support tf.float16, or at least make them to do implicit cast.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "This is a feature request. I also need this feature (tf.image.resize for float16)", "Reassigning to @hyeygit since she has been working on image APIs recently.", "@mttbx,\r\nSorry for the delayed response. Can you please go through the documentation of [Mixed Precision](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/Policy) and [the Guide](https://www.tensorflow.org/guide/mixed_precision) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 30194, "title": "Word2vec only one GPU work (multiple gpu-based)", "body": "**I have done a multiple-gpu version word2vec, and I apply `log_device_placement` in the code  which displays some ops has been applied to multiple-gpu:**\r\n```\r\n2019-06-27 00:32:34.536178: I tensorflow/core/common_runtime/placer.cc:874] optimizer_7/gradients/loss_7/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:7\r\noptimizer_6/gradients/loss_6/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:6\r\n2019-06-27 00:32:34.536188: I tensorflow/core/common_runtime/placer.cc:874] optimizer_6/gradients/loss_6/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:6\r\noptimizer_5/gradients/loss_5/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:5\r\n2019-06-27 00:32:34.536202: I tensorflow/core/common_runtime/placer.cc:874] optimizer_5/gradients/loss_5/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:5\r\noptimizer_4/gradients/loss_4/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:4\r\n2019-06-27 00:32:34.536216: I tensorflow/core/common_runtime/placer.cc:874] optimizer_4/gradients/loss_4/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:4\r\noptimizer_3/gradients/loss_3/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:3\r\n2019-06-27 00:32:34.536231: I tensorflow/core/common_runtime/placer.cc:874] optimizer_3/gradients/loss_3/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:3\r\noptimizer_2/gradients/loss_2/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:2\r\n2019-06-27 00:32:34.536246: I tensorflow/core/common_runtime/placer.cc:874] optimizer_2/gradients/loss_2/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:2\r\noptimizer_1/gradients/loss_1/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:1\r\n2019-06-27 00:32:34.536273: I tensorflow/core/common_runtime/placer.cc:874] optimizer_1/gradients/loss_1/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:1\r\noptimizer/gradients/loss/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\r\n2019-06-27 00:32:34.536288: I tensorflow/core/common_runtime/placer.cc:874] optimizer/gradients/loss/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/device:GPU:0\r\n......\r\n````\r\n____________________________________________________________________\r\n**But the `nvidia-smi` just shows only one gpu work at that time:**\r\n```\r\n`\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n| 36%   49C    P2    80W / 250W |  10882MiB / 11178MiB |     26%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\r\n| 29%   39C    P2    56W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\r\n| 29%   36C    P2    54W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\r\n| 29%   38C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\r\n| 29%   38C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\r\n| 29%   33C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\r\n| 29%   37C    P2    55W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\r\n| 29%   36C    P2    54W / 250W |  10663MiB / 11178MiB |      6%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     38130      C   python                                      8987MiB |\r\n|    1     38130      C   python                                     10621MiB |\r\n|    2     38130      C   python                                     10621MiB |\r\n|    3     38130      C   python                                     10621MiB |\r\n|    4     38130      C   python                                     10621MiB |\r\n|    5     38130      C   python                                     10621MiB |\r\n|    6     38130      C   python                                     10621MiB |\r\n|    7     38130      C   python                                     10653MiB |\r\n```\r\n**I attach my source code here:**\r\n```\r\n\r\n...\r\nwith tf.name_scope('inputs'):\r\n\t\t\ttrain_inputs = tf.placeholder(tf.int32, shape=[batch_size])\r\n\t\t\ttrain_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\r\n\t\t\t\r\n\t\t\r\n\t\tupper = 4\r\n\t\tfor i in range(0,upper):\r\n\t\t\twith tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\r\n\t\t\t\tdata_size = batch_size / upper\r\n\t\t\t\tdata_size = int(data_size)\r\n\t\t\t\tprint(data_size)\r\n\t\t\t\t_train_inputs = train_inputs[i * data_size : (i + 1) * data_size]\r\n\t\t\t\t_train_labels = train_labels[i * data_size : (i + 1) * data_size]\r\n\r\n\t\t\t\t\r\n\t\t\t\twith tf.name_scope('embeddings'):\r\n\t\t\t\t\tif prev_emb_model == '0': \r\n\t\t\t\t\t\tembeddings = tf.Variable(\r\n\t\t\t\t\t\t\ttf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\r\n\t\t\t\t\telse:\r\n\t\t\t\t\t\tadd_on_emb = tf.random_uniform([vocabulary_size - len(emb), embedding_size], -1.0, 1.0)\r\n\t\t\t\t\t\tembeddings = tf.concat([emb, add_on_emb], 0)\r\n\t\t\t\t\tembed = tf.nn.embedding_lookup(embeddings, _train_inputs)\r\n\r\n\t\t\t\t# Construct the variables for the NCE loss\r\n\t\t\t\twith tf.name_scope('weights'):\r\n\t\t\t\t\tnce_weights = tf.Variable(\r\n\t\t\t\t\t\ttf.truncated_normal([vocabulary_size, embedding_size],\r\n\t\t\t\t\t\t\t\t\t\t\tstddev=1.0 / math.sqrt(embedding_size)))\r\n\t\t\t\twith tf.name_scope('biases'):\r\n\t\t\t\t\tnce_biases = tf.Variable(tf.zeros([vocabulary_size]))\r\n\r\n\t\t\t\t\t# Compute the average NCE loss for the batch.\r\n\t\t\t\t# tf.nce_loss automatically draws a new sample of the negative labels each\r\n\t\t\t\t# time we evaluate the loss.\r\n\t\t\t\t# Explanation of the meaning of NCE loss:\r\n\t\t\t\t#   http://mccormickml.com/2016/04/19/waord2vec-tutorial-the-skip-gram-model/\r\n\t\t\t\t\r\n\t\t\t\t# with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\r\n\t\t\t\twith tf.name_scope('loss'):\r\n\t\t\t\t\tloss = tf.reduce_mean(\r\n\t\t\t\t\t\ttf.nn.nce_loss(\r\n\t\t\t\t\t\t\tweights=nce_weights,\r\n\t\t\t\t\t\t\tbiases=nce_biases,\r\n\t\t\t\t\t\t\tlabels=_train_labels,\r\n\t\t\t\t\t\t\tinputs=embed,\r\n\t\t\t\t\t\t\tnum_sampled=num_sampled,\r\n\t\t\t\t\t\t\tnum_classes=vocabulary_size))\r\n\r\n\r\n\t\t\t\t# Construct the SGD optimizer using a learning rate of 1.0.\r\n\t\t\t\twith tf.name_scope('optimizer'):\r\n\t\t\t\t\toptimizer = tf.train.GradientDescentOptimizer(\r\n\t\t\t\t\t\t1.0).minimize(loss, colocate_gradients_with_ops=True)\r\n\r\n\r\n\t\t# Compute the cosine similarity between minibatch examples and all\r\n\t\t# embeddings.\r\n\t\tnorm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\r\n\t\tnormalized_embeddings = embeddings / norm\r\n\r\n\t\t# Add variable initializer.\r\n\t\tinit = tf.global_variables_initializer()\r\n\r\n\r\n\tconfig = tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)\r\n\t# config.gpu_options.allow_growth = True\r\n\twith tf.Session(graph=graph, config=config) as session:\r\n\r\n\t\t#  We must initialize all variables before we use them.\r\n\t\tinit.run()\r\n\t\tprint('Initialized')\r\n\t\taverage_loss = 0\r\n\r\n\t\twalks_data = []\r\n\t\tfor w in walks:\r\n\t\t\tfor n in w: \r\n\t\t\t\twalks_data.append(n)\r\n\r\n\t\tfor step in range(args.iter):\r\n\t\t\tprint(step)\r\n\t\t\t\r\n\t\t\tbatch_inputs, batch_labels = generate_batch(batch_size, 1,\r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\twindow_size, walks_data)\r\n\r\n\t\t\tfeed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\r\n\r\n\r\n\t\t\t_, loss_val = session.run([optimizer, loss],\r\n\t\t\t\t\t\t\t\t\t\t\t\tfeed_dict=feed_dict,\r\n\t\t\t\t\t\t\t\t\t\t\t\trun_metadata=run_metadata)\r\n\t\t\taverage_loss += loss_val\r\n\r\n\t\t\tif step % 2000 == 0:\r\n\t\t\t...\r\n\r\n\t\tfinal_embeddings = normalized_embeddings.eval()\r\n```\r\n", "comments": ["Please, have a look at [GPU memory growth](https://www.tensorflow.org/guide/using_gpu#allowing_gpu_memory_growth) and please, let us know it it helps.Thanks!", "> Please, have a look at [GPU memory growth](https://www.tensorflow.org/guide/using_gpu#allowing_gpu_memory_growth) and please, let us know it it helps.Thanks!\r\n\r\nIn my code, I have tried to use  `config.gpu_options.allow_growth = True`, but it seems like does not affect any process.", "Perhaps you can use ```tf.distribute.Strategy``` for training on multiple gpus.\r\nSee https://www.tensorflow.org/guide/distribute_strategy"]}, {"number": 30193, "title": "Fix URL in docstring", "body": "The URL was out-of-date.", "comments": ["@duncanriach Can you please resolve conflicts? Thanks!", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30193) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30193) for more info**.\n\n<!-- ok -->", "What happened:\r\n\r\nThe original pull request was to fix the URL in a doc string. Then there was a conflict because someone else removed the URL. I rebased to master to resolve the conflict and I accidentally pushed a commit that had a ton of other people's changes in it. This is why so many reviewers were flagged. I rolled back that last commit and force-pushed.\r\n\r\nThis is a tiny change. Sorry for the confusion."]}, {"number": 30192, "title": "Revert \"Merge pull request #29021 from Intel-tensorflow:graphrewriteP\u2026", "body": "\u2026R\" due to some tests failure.\r\n\r\nwill resubmit after fixing the failures.\r\n\r\nThis reverts commit a01d8306bf52ac0777f1c6609fa6059d1ea1ee30, reversing\r\nchanges made to d4f340bb562dd4c3a1ce9ccecaa6041beb6c26e9.", "comments": ["@ penpornk could please you hold this PR for merging temporally? some testing hasn't finished yet on our side.\r\nthanks!"]}, {"number": 30191, "title": "ERROR: Cannot uninstall 'wrapt'. during upgrade", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 19.04 on Sony notebook):\r\n- TensorFlow version:\r\n```\r\npython\r\nPython 3.6.3 |Anaconda, Inc.| (default, Oct 13 2017, 12:02:49) \r\n[GCC 7.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n/home/ronald/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n>>> print(tf.__version__)\r\n2.0.0-alpha0\r\n```\r\n\r\n**Describe the problem**\r\nI try to upgrade to beta1 with:\r\n` install tensorflow==2.0.0-beta1\r\n`\r\nat the end I get:\r\n```\r\nInstalling collected packages: wrapt, tensorflow\r\n  Found existing installation: wrapt 1.10.11\r\nERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\r\n\r\n```\r\nHow to fix it?\r\n", "comments": ["I fixed it by:\r\n```\r\nconda update --all\r\npip install --upgrade tensorflow==2.0.0-beta1\r\n```", "It didn't work for me. Still getting that error.\r\n\r\nEdit: Fixed it by installing tensorflow 1.14 first then updating it to version 2.0", "it work for me. Thank you\r\n\r\n> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nIt work for me. Thank you", "Works for me, thanks!", "It didn't work for me. Still getting that error.", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nIt worked for me also.", "conda update --all\r\npip install tensorflow", "> It didn't work for me. Still getting that error.\r\n\r\ntry\r\n`conda update wrapt`", "> conda update --all\r\n> pip install tensorflow\r\n\r\nthis worked for me!!!!\r\n\r\nPS: I got a reboot after the first line was done.\r\n      I have windows 10.", "Above solutions are not worked for me. So I remove the `wrapt' by conda operation.\r\n\r\n`conda remove wrapt`\r\n\r\nAnd, it worked.\r\n\r\n`pip install tensorflow`\r\n\r\nEnv: Windows 10", "> it work for me. Thank you\r\n> \r\n> > I fixed it by:\r\n> > ```\r\n> > conda update --all\r\n> > pip install --upgrade tensorflow==2.0.0-beta1\r\n> > ```\r\n> \r\n> It work for me. Thank you\r\n\r\nagreed!", "None of the solutions worked for me. \r\nI am always getting `ERROR: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.`\r\nand with `conda remove wrapt` I get `RemoveError: 'setuptools' is a dependency of conda and cannot be removed from conda's operating environment.`\r\n\r\nenv: Mac OS 10.14.5", "> Above solutions are not worked for me. So I remove the `wrapt' by conda operation.\r\n> \r\n> `conda remove wrapt`\r\n> \r\n> And, it worked.\r\n> \r\n> `pip install tensorflow`\r\n> \r\n> Env: Windows 10\r\n\r\nThis worked for me.", "Tensorflow seems to have trouble being friendly with other packages.  The following worked for me, starting from a clean conda environment:\r\n\r\npip install --upgrade pip\r\npip install six>=1.12.0\r\npip install  httplib2==0.12.0\r\npip uninstall -y setuptools\r\npip install setuptools>=41.0.0\r\n\r\npip install tensorflow==1.14.0\r\npip install tfx\r\n\r\npip install pylint\r\n\r\nThis sequence gets rid of wrapt as well as tensorboard warnings and google-apitools failures.", "This worked for me. I am using Jupyter notebook (OD: Ubuntu 16.0) all the commands running from the notebook:\r\n\r\nAt the time of installing tensor flow I got following two errors. The errors and solutions are:\r\nERROR 1: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\r\n\r\nSolution: run following command\r\n!conda remove wrapt --yes \r\n\r\nERROR 2: tensorboard 1.14.0 has requirement setuptools>=41.0.0\r\nSolution: run following command to solve this error\r\n!pip uninstall -y setuptools      \r\n!pip install setuptools>=41.0.0\r\n\r\nNow install tensorflow:\r\n!pip install tensorflow", "This worked for me:\r\n\r\n`pip install wrapt --upgrade --ignore-installed`\r\n`pip install tensorflow`\r\n", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\n", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nIt works for me. Thanks.", "> conda update --all\r\n> pip install tensorflow\r\n\r\nIt works for me. thank you.\r\n\r\n> > It didn't work for me. Still getting that error.\r\n> \r\n> try\r\n> `conda update wrapt`\r\n\r\n\r\n\r\n> > It didn't work for me. Still getting that error.\r\n> \r\n> try\r\n> `conda update wrapt`\r\n\r\nIt works for me. Thank you.", "> > It didn't work for me. Still getting that error.\r\n> \r\n> try\r\n> `conda update wrapt`\r\n\r\nIt worked for me. Thanks a lot.", "> Above solutions are not worked for me. So I remove the `wrapt' by conda operation.\r\n> \r\n> `conda remove wrapt`\r\n> \r\n> And, it worked.\r\n> \r\n> `pip install tensorflow`\r\n> \r\n> Env: Windows 10\r\n\r\nThanks @NoSyu  this work me", "This worked for me\r\npip install wrapt --upgrade --ignore-installed\r\npip install tensorflow", "> This worked for me\r\n> pip install wrapt --upgrade --ignore-installed\r\n> pip install tensorflow\r\n\r\nThis worked for me too.", "pip install wrapt --upgrade --ignore-installed\r\npip install tensorflow\r\nThis worked for me too\uff0cThanks.", "Worked like charm ", "> Above solutions are not worked for me. So I remove the `wrapt' by conda operation.\r\n> \r\n> `conda remove wrapt`\r\n> \r\n> And, it worked.\r\n> \r\n> `pip install tensorflow`\r\n> \r\n> Env: Windows 10\r\n\r\nit works for me, thanks very much!", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\n\r\n\r\n> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\nThanks..It worked for me.\r\n", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nworks for me too!!!! ", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nWorked for me too", "> It didn't work for me. Still getting that error.\r\n> \r\n> Edit: Fixed it by installing tensorflow 1.14 first then updating it to version 2.0\r\n\r\nThis is is the only thing that worked for me. Thanks.\r\n\r\nTried removing 'wrapt' and installing tensorflow v2.0 and then numpy threw a similar error.", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nit worked for me as well , thanks.", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\n@rickykim93 you are awesome... I love you...", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nHi, I had this problem in Raspberry Pi and your procedure worked for me.\r\nThank you.", "> > Above solutions are not worked for me. So I remove the `wrapt' by conda operation.\r\n> > `conda remove wrapt`\r\n> > And, it worked.\r\n> > `pip install tensorflow`\r\n> > Env: Windows 10\r\n> \r\n> This worked for me.\r\n\r\nThis also worked for me. Env: Mac OS 10.14.6", "above problem solution \r\n> How to fix it?\r\nif \"pip install tensorflow\" command won't work...\r\ntry to \"update conda --upgrade all\"\r\nthen \"conda install tensorflow\" this will definitely work.", ">This worked for me:\r\n```\r\npip install wrapt --upgrade --ignore-installed\r\npip install tensorflow\r\n```\r\nGreat fix.", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThanks alot,\r\nit works for me and able to installed TensorFlow and keras ", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nWorks for me, thanks :)", "> \u5b83\u5bf9\u6211\u6709\u7528\u3002\u8c22\u8c22\r\n> \r\n> > \u6211\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4fee\u590d\u5b83\uff1a\r\n> > ```\r\n> > conda update --all\r\n> > pip install --upgrade tensorflow==2.0.0-beta1\r\n> > ```\r\n> \r\n> \u5b83\u5bf9\u6211\u6709\u7528\u3002\u8c22\u8c22\r\nme too", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nThis works for me, thanks!", "> \r\n> \r\n> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nworked...great..thanks", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThis works for my Windows 8.1\r\n\r\nHowever, I was asked to consider upgrade the pip.\r\nAnd I did it first of all, using:\r\n`python -m pip install --upgrade pip`\r\n\r\nThanks!", "pip install wrapt --upgrade --ignore-installed\r\npip install tensorflow\r\n\r\n> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThis worked for me too in my mac\uff0cThanks.", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThanks so much! This saved me.", "> I fixed it by:\r\n> \r\n> ```\r\n> conda update --all\r\n> pip install --upgrade tensorflow==2.0.0-beta1\r\n> ```\r\n\r\nThis worked for me", "> conda update --all\r\n> pip install tensorflow\r\n\r\nThis worked for me\r\nEnv: Mac OS 10.14.6", "try conda from anaconda prompt or else it doesnt work", "This worked for me on a mac OS 10.14. Running in the terminal.\r\n\r\n`````\r\npip install wrapt --upgrade --ignore-installed\r\npip install tensorflow --upgrade\r\n`````", "I also fixed it by simply running\r\n```\r\nconda update wrapt\r\n```\r\nI think this avoids other unwanted upgrades by conda", "> > This worked for me:\r\n> > `pip install wrapt --upgrade --ignore-installed`\r\n> > `pip install tensorflow`\r\n> \r\n> @rickykim93 you are awesome... I love you...\r\n\r\nThat worked for me too. Fantastic !!!", "> \r\n> \r\n> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nthis worked for me. \r\nthanks a lot to the genius developers", "\r\n> ```\r\n> pip install wrapt --upgrade --ignore-installed\r\n> pip install tensorflow --upgrade\r\n> ```\r\n\r\nSo Nice! this worked for me too on Ubunto :)", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThis worked for me too ! Thank you very much!\r\nMy environment is windows 10 ", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nthis works for me, Linux64, python3.7, with pip20.0.2 under conda self-defined enviromnet", "From all the solutions named here. This one is the only one that worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nThis worked in Mac", "> This worked for me:\r\n> \r\n> `pip install wrapt --upgrade --ignore-installed`\r\n> `pip install tensorflow`\r\n\r\nI tried this and the tensorflow was successfully installed, but I had error when tired to use it. Than I tried \r\npip install --upgrade tensorflow==2.0.0-beta1\r\nand after this, it works well!", "conda uninstall wrapt\r\npip install tensorflow", "Thank you man, this worked for me!", "**Worked for Ubuntu 16.04 x86_64**\r\n\r\nWhen I perform the command \"pip install tensorflow-gpu==1.15\", I encounter the error \"Found existing installation: wrapt 1.10.11 ERROR: Cannot uninstall 'wrapt'\".\r\n\r\nmy solution:\r\n1. perform \"pip install wrapt --upgrade --ignore-installed\", upgrade wrapt 1.10.11 to wrapt-1.12.0\r\n2. perform \"pip install tensorflow-gpu==1.15\"\r\n\r\nif you cannot perform \"pip install tensorflow-gpu==1.15\" successfully. Maybe you firstly need to upgrade pip-18.1 to pip-20.0 using \"python -m pip install --upgrade pip setuptools\".\r\n\r\n\r\n", "> This worked for me. I am using Jupyter notebook (OD: Ubuntu 16.0) all the commands running from the notebook:\r\n> \r\n> At the time of installing tensor flow I got following two errors. The errors and solutions are:\r\n> ERROR 1: Cannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\r\n> \r\n> Solution: run following command\r\n> !conda remove wrapt --yes\r\n> \r\n> ERROR 2: tensorboard 1.14.0 has requirement setuptools>=41.0.0\r\n> Solution: run following command to solve this error\r\n> !pip uninstall -y setuptools\r\n> !pip install setuptools>=41.0.0\r\n> \r\n> Now install tensorflow:\r\n> !pip install tensorflow\r\n\r\nIt worked for me , thank you", "It's worked for me as well. Really appreciated for providing such details. However, could you please provide more details regarding the problem? Why we are not able to uninstall \"wrapt\" without upgrading all the packages and libraries? @Elmit2015 ", "Locking conversation to prevent a stream of \"it works\""]}, {"number": 30190, "title": "TF 2.0:  tf.GradientTape().gradient() returns None", "body": "I designed my own loss function for my graduate research, it calculates the distance between the histogram of each loss in a batch and normal distribution. I am implementing this loss function in the setting of Tensorflow 2.0 [tutorial](https://www.tensorflow.org/beta/tutorials/eager/custom_training_walkthrough) about Iris flower classification.\r\n\r\nI checked my loss value and type, they are same as the one in tutorial, but the `grads` from my `tape.gradient()` is `None`.\r\n\r\nThis is done in Google Colab with:\r\n\r\n`TensorFlow version: 2.0.0-beta1`\r\n\r\n`Eager execution: True`\r\n\r\nMy code block for loss and gradient:\r\n```\r\ndef loss(model, x, y):\r\n  y_ = model(x) # y_.shape is (batch_size, 3)\r\n  losses = []\r\n  for i in range(y.shape[0]):\r\n    loss = loss_object(y_true=y[i], y_pred=y_[i])\r\n    losses.append(float(loss))\r\n  dis = get_distance_between_samples_and_distribution(losses, if_plot = 0)\r\n  return tf.convert_to_tensor(dis, dtype=np.float32)\r\n\r\ndef grad(model, inputs, targets):\r\n  with tf.GradientTape() as tape:\r\n    loss_value = loss(model, inputs, targets)\r\n    tape.watch(model.trainable_variables)\r\n  return loss_value, tape.gradient(loss_value, model.trainable_variables)\r\n\r\nloss_value, grads = grad(model, features, labels)\r\nprint(\"loss_value:\",loss_value)\r\nprint(\"type(loss_value):\", type(loss_value))\r\nprint(\"grads:\", grads)\r\n################################################# Output:\r\nloss_value: tf.Tensor(0.21066944, shape=(), dtype=float32)\r\ntype(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>\r\ngrads: [None, None, None, None, None, None]\r\n\r\n```\r\nThe code in tutorial is:\r\n```\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\ndef loss(model, x, y):\r\n  y_ = model(x)\r\n  return loss_object(y_true=y, y_pred=y_)\r\n\r\ndef grad(model, inputs, targets):\r\n  with tf.GradientTape() as tape:\r\n    loss_value = loss(model, inputs, targets)\r\n    tape.watch(model.trainable_variables)\r\n  return loss_value, tape.gradient(loss_value, model.trainable_variables)\r\n\r\nloss_value, grads = grad(model, features, labels)\r\nprint(\"loss_value:\",loss_value)\r\nprint(\"type(loss_value):\", type(loss_value))\r\nprint(\"grads:\", grads)\r\n################################################# Output:\r\nloss_value: tf.Tensor(0.56536925, shape=(), dtype=float32)\r\ntype(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>\r\ngrads: [<tf.Tensor: id=9962, shape=(4, 10), dtype=float32, numpy=\r\narray([[ 0.0000000e+00,  6.5984917e-01,  3.0700830e-01, -7.5234145e-01,\r\n      ......\r\n```\r\nI feel the calculation of my self defined loss should not matter since the data type and shape are same, but in case it does, here is my loss function:\r\n```\r\ndef get_distance_between_samples_and_distribution(errors, if_plot = 1, n_bins = 5):\r\n  def get_middle(x):\r\n    xMid = np.zeros(x.shape[0]//2)\r\n    for i in range(xMid.shape[0]):\r\n      xMid[i] = 0.5*(x[2*i]+x[2*i+1])\r\n    return xMid\r\n\r\n  bins, edges = np.histogram(errors, n_bins, normed=1)\r\n  left,right = edges[:-1],edges[1:]\r\n  X = np.array([left,right]).T.flatten()\r\n  Y = np.array([bins,bins]).T.flatten()\r\n  X_middle = get_middle(X)\r\n  Y_middle = get_middle(Y)\r\n  distance = []\r\n  for i in range(X_middle.shape[0]):\r\n    dis = np.abs(scipy.stats.norm.pdf(X_middle[i])- Y_middle[i])\r\n    distance.append(dis)\r\n  distance2 = np.power(distance, 2)\r\n  \r\n  return sum(distance2)/len(distance2)\r\n```\r\n**I searched and tried adding `tape.watch()`, checking the indentation of my return as suggested in [issue #29942](https://github.com/tensorflow/tensorflow/issues/29942) but they did not fix this `None` problem. I will very appreciate any suggestion for fixing this. Thanks!**\r\n\r\nThe definition of class `tf.GradientTape` is [here](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/eager/backprop.py) \r\n ", "comments": ["it's solved", "@sailormoon2016 If possible post how you resolved so that it will help the community. Thanks!", "I figured my self defined loss function may not be differentiable, so I modified my loss function to make sure the calculation is differentiable, then the results come out as expected. My customized loss function did give a better accuracy compared to the default cross-entropy. you can find my working code [here](https://github.com/sailormoon2016/Transportation/blob/master/ErrorShaping/tf2_flower.ipynb) if you are interested in.", "@sailormoon2016 Thanks for the information and code. It will help others in the community. Greatly appreciated. Thanks!", "Below link is helpful for solving problems related to tf.GradientTape :\r\n\r\n[Tensorflow 2.0 Pitfalls](http://blog.ai.ovgu.de/posts/jens/2019/001_tf20_pitfalls/index.html)", "I have a stranger loss function where I am converting the output to embeddings and calculating distance of embeddings. This is not at all differentiable even if embeddings are built with TF math ops. Is there an example for writing my own differentiation code as this is not realisable through TF automatic differentiation?", "Hi I had the same issue but after indenting loss calculation within tf.GradientTape it started to work"]}, {"number": 30189, "title": " Xla integer nearestneighbor resize bug fix", "body": "WIP: For XLA/GPU, since integer convolution is not supported, use float to do the nearest neighbor resize convolution for now.  At the end, the outputs are converted back to the original input type.", "comments": ["This PR is created by mistake."]}, {"number": 30188, "title": "Different results with the same initial guess", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow version: v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: Python 3.6.8\r\n\r\nI got different results with a same initial guess. I do not know if this is a bug or how it should be, but let me explain what I saw here since I did not get any answers from [my stack overflow post](https://stackoverflow.com/questions/56729256/tensorflow-completely-different-results-from-a-same-initial-guess). \r\n\r\nThe following simple code is adapted from [here](https://databricks.com/tensorflow/training-and-convergence). \r\n```\r\nimport os\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = tf.placeholder(\"float\")\r\ny = tf.placeholder(\"float\")\r\nw = tf.Variable([1.0, 2.0], name=\"w\")\r\n\r\ny_model = tf.multiply(x, w[0]) + w[1]\r\nerror = tf.square(y - y_model)\r\ntrain_op = tf.train.GradientDescentOptimizer(0.01).minimize(error)\r\n\r\nmodel = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as session:\r\n    session.run(model)\r\n    print(\"Initial guess: \", session.run(w))\r\n    np.random.seed(seed=100)\r\n    for i in range(1000):\r\n        x_value = np.random.rand()\r\n        y_value = x_value * 2 + 6\r\n        session.run(train_op, feed_dict={x: x_value, y: y_value})\r\n\r\n    w_value = session.run(w)\r\n    print(\"Predicted model: {a:.3f}x + {b:.3f}\".format(a=w_value[0], b=w_value[1]))\r\n```\r\n\r\nFrom the code, I got `Predicted model: 2.221x + 5.882`. However, when I replaced `w` with\r\n\r\n```\r\nw_norm = tf.Variable([0.5, 1.0], name = 'w_norm')\r\nw = w_norm*2.0\r\n```\r\nthe result was `Predicted model: 2.004x + 5.998` even though it has same initial guess (`[1. 2.]`) and same number of epochs. I wonder that makes this difference. ", "comments": ["I have tried on colab with TF version  1.14 and was able to reproduce the issue.Thanks!", "Just realized that was my misunderstanding of how tensorflow works. I close this since it is answered in my stack overflow post. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30188\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30188\">No</a>\n"]}, {"number": 30187, "title": "Internal error has occurred when executing Firebase ML tasks fails on tensor allocation", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Same error across OnePlus 6 (28) and Sony Xperia (21)\r\n- TensorFlow installed from (source or binary): MLKit for Firebase \r\n- TensorFlow version (use command below): 'com.google.firebase:firebase-ml-model-interpreter:20.0.0'\r\n\r\nHi there folks, I've been setting up a Firebase MLKit project on Android to perform just simple image classification using a mobilenet model. I have been following the official guide given [here](https://firebase.google.com/docs/ml-kit/android/use-custom-models) for using a custom TF lite model which I have both locally in the android assets folder of my project and also hosted on a test firebase app as 'mobilenet'. The code gets a bitmap from the camera intent and then passes that to the run inference method where I have setup everything as per the guide. However, when it finally begins to run inference it throws an internal firebase ml error as well as some other bits in the stack trace.\r\n\r\nThe expected behaviour would be that it does indeed run the inference method and successfully prints a joyous \"IT WORKED!!!\". \r\n\r\nHere is my main activity kotilin file:\r\n`package com.example.tflite\r\n\r\nimport android.content.Intent\r\nimport android.graphics.Bitmap\r\nimport android.graphics.Color\r\nimport androidx.appcompat.app.AppCompatActivity\r\nimport android.os.Bundle\r\nimport android.provider.MediaStore\r\nimport android.util.Log\r\nimport android.view.View\r\nimport android.widget.ImageView\r\nimport android.widget.TextView\r\nimport android.widget.Toast\r\nimport com.google.firebase.ml.common.FirebaseMLException\r\nimport com.google.firebase.ml.common.modeldownload.FirebaseLocalModel\r\nimport com.google.firebase.ml.common.modeldownload.FirebaseModelDownloadConditions\r\nimport com.google.firebase.ml.common.modeldownload.FirebaseModelManager\r\nimport com.google.firebase.ml.common.modeldownload.FirebaseRemoteModel\r\nimport com.google.firebase.ml.custom.*\r\n\r\nclass MainActivity : AppCompatActivity() {\r\n\r\n    override fun onCreate(savedInstanceState: Bundle?) {\r\n        super.onCreate(savedInstanceState)\r\n        setContentView(R.layout.activity_main)\r\n    }\r\n\r\n    fun onPressAddImage(view: View) {\r\n        // Dispatch an intent to the media store of the device to capture\r\n        // an image with the requestCode id '1'\r\n        Intent(MediaStore.ACTION_IMAGE_CAPTURE).also { takePictureIntent ->\r\n            takePictureIntent.resolveActivity(packageManager)?.also {\r\n                startActivityForResult(takePictureIntent, 1)\r\n            }\r\n        }\r\n    }\r\n\r\n    override fun onActivityResult(requestCode: Int, resultCode: Int, data: Intent?) {\r\n        // Override the MainActivity function to check when a result is returned\r\n        // from any intent - if the requestCode matches then draw the resulting\r\n        // bitmap to the image view\r\n        if (requestCode == 1 && resultCode == RESULT_OK) {\r\n            val imageBitmap = data?.extras?.get(\"data\") as Bitmap\r\n            val imageView = findViewById<ImageView>(R.id.imageResult)\r\n            imageView.setImageBitmap(imageBitmap)\r\n            // Pass the bitmap result to the inference method\r\n            runInference(imageBitmap)\r\n        }\r\n    }\r\n\r\n    private fun runInference(bitmap: Bitmap) {\r\n        // Scale the bitmap to the input size of the interpreter\r\n        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, 224, 224, true)\r\n        // Create the input tensor of the image for the network\r\n        val batchNum = 0\r\n        val input = Array(1) { Array(224) { Array(224) { FloatArray(3) } } }\r\n        for (x in 0..223) {\r\n            for (y in 0..223) {\r\n                val pixel = scaledBitmap.getPixel(x, y)\r\n                // Normalize channel values to [-1.0, 1.0]. This requirement varies by\r\n                // model. For example, some models might require values to be normalized\r\n                // to the range [0.0, 1.0] instead.\r\n                input[batchNum][x][y][0] = ((Color.red(pixel) - 127) / 255.0f)\r\n                input[batchNum][x][y][1] = ((Color.green(pixel) - 127) / 255.0f)\r\n                input[batchNum][x][y][2] = ((Color.blue(pixel) - 127) / 255.0f)\r\n            }\r\n        }\r\n        // Define the Model download options before we attempt to e.g. that the device is charging and idle\r\n        val conditionsBuilder = FirebaseModelDownloadConditions.Builder().requireWifi()\r\n        val conditions = conditionsBuilder.build()\r\n        // Build a remote model object by specifying the name you assigned the model\r\n        // when you uploaded it in the Firebase console.\r\n        val cloudSource = FirebaseRemoteModel.Builder(\"mobilenet\")\r\n            .enableModelUpdates(true)\r\n            .setInitialDownloadConditions(conditions)\r\n            .setUpdatesDownloadConditions(conditions)\r\n            .build()\r\n\r\n        // Register the local model too as a fall back in case the latest cannot be registered from Firebase\r\n        val localSource = FirebaseLocalModel.Builder(\"mobilenet\") \r\n            .setAssetFilePath(\"mobilenet_float_v2_1.0_299.tflite\")\r\n            .build()\r\n\r\n        val manager = FirebaseModelManager.getInstance()\r\n        manager.registerLocalModel(localSource)\r\n        manager.registerRemoteModel(cloudSource)\r\n\r\n        // Create the interpreter\r\n        val options = FirebaseModelOptions.Builder()\r\n            .setRemoteModelName(\"mobilenet\")\r\n            .setLocalModelName(\"mobilenet\")\r\n            .build()\r\n\r\n        val interpreter = FirebaseModelInterpreter.getInstance(options)\r\n\r\n        val textView = findViewById<TextView>(R.id.textView).apply {\r\n            text = \"loaded\"\r\n        }\r\n\r\n        manager.downloadRemoteModelIfNeeded(cloudSource)\r\n            .addOnCompleteListener { task ->\r\n                if (task.isSuccessful) {\r\n                    Toast.makeText(\r\n                        this,\r\n                        \"Download remote AutoML model success.\",\r\n                        Toast.LENGTH_SHORT\r\n                    )\r\n                        .show()\r\n                } else {\r\n                    val downloadingError =\r\n                        \"Error downloading remote model.\"\r\n                    Toast.makeText(this, downloadingError, Toast.LENGTH_SHORT).show()\r\n                }\r\n            }\r\n        // Set the inputs and outputs of the interpreter\r\n        // Set the input and output options of the model\r\n        val interpreterOpts = FirebaseModelInputOutputOptions.Builder()\r\n            .setInputFormat(0, FirebaseModelDataType.FLOAT32, intArrayOf(1, 224, 224, 3))\r\n            .setOutputFormat(0, FirebaseModelDataType.FLOAT32, intArrayOf(1, 1001))\r\n            .build()\r\n        // Add the input to the interpreter and run inference\r\n        val inputs = FirebaseModelInputs.Builder()\r\n            .add(input) // add() as many input arrays as your model requires\r\n            .build()\r\n        interpreter!!.run(inputs, interpreterOpts)\r\n            .addOnSuccessListener { result ->\r\n                val output = result.getOutput<Array<IntArray>>(0)\r\n                val probabilities = output[0]\r\n                val textView = findViewById<TextView>(R.id.textView).apply {\r\n                    text = \"IT WORKED!!!\"\r\n                }\r\n\r\n            }\r\n            .addOnFailureListener { e ->\r\n                Log.e(\"TFLite\", \"Failed: ${e.message}\")\r\n                e.printStackTrace()\r\n            }\r\n    }\r\n}\r\n`\r\n\r\nAnd here is the logcat output from android studio:\r\n\r\n`E/TFLite: Failed: Internal error has occurred when executing Firebase ML tasks\r\nW/System.err: com.google.firebase.ml.common.FirebaseMLException: Internal error has occurred when executing Firebase ML tasks\r\n        at com.google.android.gms.internal.firebase_ml.zznn.zza(Unknown Source:36)\r\n        at com.google.android.gms.internal.firebase_ml.zznq.run(Unknown Source:2)\r\nW/System.err:     at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at com.google.android.gms.internal.firebase_ml.zzf.dispatchMessage(Unknown Source:6)\r\n        at android.os.Looper.loop(Looper.java:193)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n    Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Invalid begin and size.Node number 0 (SLICE) failed to prepare.\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:136)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:250)\r\n        at com.google.android.gms.internal.firebase_ml.zzpz.runForMultipleInputsOutputs(Unknown Source:4)\r\n        at com.google.android.gms.internal.firebase_ml.zzpr.zza(Unknown Source:85)\r\n        at com.google.android.gms.internal.firebase_ml.zzpr.zza(Unknown Source:125)\r\n        at com.google.android.gms.internal.firebase_ml.zznt.call(Unknown Source:4)\r\n        at com.google.android.gms.internal.firebase_ml.zznn.zza(Unknown Source:30)\r\n    \t... 6 more\r\n`\r\n\r\nIn particular it seems to be failing when allocating the tensors and so could possibly be a memory allocation issue, but not entirely sure:\r\n\r\n`Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Invalid begin and size.Node number 0 (SLICE) failed to prepare.`\r\n\r\nAny help on how to get around this issue would be great and I can't simply use the prebuilt APIs as this is a test for building a custom semantic segmentation model on.\r\n\r\n", "comments": ["Issue fixed now - I had set the wrong input size of the model (should have been 299 *299) but was receiving 224 * 224 - could a better exception thrown to check that they are indeed the same corresponding size rather than just it being an internal error at the allocation stage?"]}, {"number": 30186, "title": "[INTEL MKL] Adding a build flag to enable MKL-DNN v1.0", "body": "When TF-MKL is built with `--define build_with_mkl_dnn_v1_only=true` option, MKL-DNN v1.0 binary will be installed. Otherwise, the default v0.x binary will be used.", "comments": ["@bhavani-subramanian Could you please check reviewer comments and keep us posted. Thanks!", "@penpornk @gbaned Sorry for the delay! I have addressed the review comments. Please let me know if it looks okay. Thanks!", "@penpornk No worries. Thanks for the quick review! I have moved `:mkldnn_config_h` above `src/cpu/jit_utils/jit_utils.cpp`."]}, {"number": 30185, "title": "Issue facing while converting frozen.pb to xyz.tflite", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, RESHAPE, RESIZE_BILINEAR, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, NonMaxSuppressionV2, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\n\r\n\r\nAfter the above issue, I have added \r\n    --enable_select_tf_ops \\\r\n    --allow_custom_ops\r\nto the script, which I'm using for the conversion of the inference model to TensorFlow lite model. Now my script looks something like this:\r\n\r\ntflite_convert \\\r\n    --output_file=\"frozen_inference_graph.tflite\" \\\r\n    --graph_def_file=\"frozen_inference_graph.pb\" \\\r\n    --input_arrays=\"add/y\" \\\r\n    --output_arrays=\"Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Gather\" \\\r\n    --enable_select_tf_ops \\\r\n    --allow_custom_ops\r\nbut after compilif for some time, I again face the error :\r\n\r\n2019-06-26 23:09:54.496040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6004 nodes (0), 10038 edges (0), time = 567.948ms.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 503, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 499, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\", line 898, in convert\r\n    **converter_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-06-26 23:13:47.335610: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.357310: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358381: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.358423: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358456: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.358487: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.358547: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358580: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358608: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358667: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358695: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358722: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358757: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358785: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.358812: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-06-26 23:13:47.358843: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-06-26 23:13:47.358881: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.358931: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-06-26 23:13:47.358966: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-06-26 23:13:47.359031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-06-26 23:13:47.359064: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n2019-06-26 23:13:47.359114: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3\r\n2019-06-26 23:13:47.359149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:47.359214: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n2019-06-26 23:13:47.359251: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3\r\n2019-06-26 23:13:47.359303: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:47.362112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362167: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362200: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362232: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362262: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362293: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362322: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362353: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362381: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362412: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362440: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362469: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362501: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362531: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362559: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362588: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayV3\r\n2019-06-26 23:13:47.362616: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362655: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362683: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362710: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362742: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362769: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362795: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362855: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362880: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362912: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.362941: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.362967: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363000: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363026: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.363052: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363090: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.363117: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-06-26 23:13:47.363150: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363177: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.363204: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-06-26 23:13:47.363236: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363263: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-06-26 23:13:47.363289: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-06-26 23:13:47.363324: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-06-26 23:13:47.363368: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363400: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.363432: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.371058: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-06-26 23:13:47.371160: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-06-26 23:13:47.371197: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-06-26 23:13:47.371837: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayScatterV3\r\n2019-06-26 23:13:47.371872: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-06-26 23:13:47.371907: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayReadV3\r\n2019-06-26 23:13:47.384637: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384730: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384797: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384829: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384861: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384893: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384924: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384955: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.384986: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385017: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385048: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385080: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385142: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385205: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385237: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385268: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385299: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385361: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385392: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385424: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385455: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385487: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385549: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385581: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385613: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385644: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385675: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385705: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385737: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385768: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385800: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385863: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385894: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385925: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385956: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.385987: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386017: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386049: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386080: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386142: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386173: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386204: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386235: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386266: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386298: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386328: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386360: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386389: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386420: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386451: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386483: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386514: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386545: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386577: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386608: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386639: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386671: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386703: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386734: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386766: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386827: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386858: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386889: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386920: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386952: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.386983: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387014: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387045: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387091: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387124: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387156: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387188: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387220: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387251: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387283: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387315: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387347: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387378: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387409: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387441: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387472: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.387505: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV2\r\n2019-06-26 23:13:47.388923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n2019-06-26 23:13:47.389200: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:47.389914: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:47.389951: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:47.389984: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayWriteV3\r\n2019-06-26 23:13:48.210704: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4228 operators, 6935 arrays (0 quantized)\r\n2019-06-26 23:13:49.585661: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 3930 operators, 6444 arrays (0 quantized)\r\n2019-06-26 23:13:51.136723: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 3930 operators, 6444 arrays (0 quantized)\r\n2019-06-26 23:13:52.257715: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 3619 operators, 6018 arrays (0 quantized)\r\n2019-06-26 23:13:53.340484: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 3619 operators, 6018 arrays (0 quantized)\r\n2019-06-26 23:13:54.216385: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 3619 operators, 6018 arrays (0 quantized)\r\n2019-06-26 23:13:54.884514: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 256 bytes, theoretical optimal value: 256 bytes.\r\n2019-06-26 23:13:55.190611: E tensorflow/lite/toco/toco_tooling.cc:456] TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: TensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch.\r\n\r\nPlease help in solving this issue. ", "comments": ["Adding ```control flow ops: Enter, Exit, Merge, Switch.``` is a work in progress.\r\nhttps://github.com/tensorflow/community/pull/83\r\nhttps://github.com/tensorflow/community/pull/83/files#diff-bce60557324879642d73cc9862647ea3R50\r\nClosing this issue since we have other thread discussing the same feature. Feel free to reopen if have any questions. Thanks!", "@ymodak \r\ntf 1.14.\r\nI still get this error: TensorFlow Lite currently doesn't support control flow ops: Merge, Switch.\r\n\"control flow ops:  Enter, Exit, Merge, Switch\" is not avaliable yet?", "@an1018 Can you please share a standalone code to reproduce the issue. Thanks!"]}, {"number": 30184, "title": "tensorflow.__dict__ and __doc__ had changed after update to 1.14", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):conda-forge\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n`tensorflow.__dict__` prints out \r\n```python\r\n{\r\n'_dw_wrapped_module': <module 'tensorflow' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow/lib/python3.6/site-packages/tensorflow/__init__.py'>,\r\n'_dw_module_name': '',\r\n'_dw_deprecated_printed': set(),\r\n'_dw_warning_count': 0,\r\n'__name__': 'tensorflow',\r\n'__doc__': None,\r\n'__package__': None,\r\n'__loader__': None,\r\n'__spec__': None\r\n}\r\n```\r\nand `tensorflow.__doc__` does not print anything.\r\n\r\n**Describe the expected behavior**\r\n\r\nIn 1.13, `__dict__` had a mapping of every tensorflow functions and `__doc__` had printed out `'Bring in all of the public TensorFlow interface into this module.'`\r\n\r\nThe full log for printing `__dict__` can be seen as below\r\n```\r\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\n{'__name__': 'tensorflow', '__doc__': 'Bring in all of the public TensorFlow interface into this module.', '__package__': 'tensorflow', '__loader__': <_frozen_importlib_external.SourceFileLoader object at 0x7fa13cbef2b0>, '__spec__': ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7fa13cbef2b0>, origin='/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__init__.py', submodule_search_locations=['/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow']), '__path__': ['/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api', '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow', '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1'], '__file__': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__init__.py', '__cached__': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/__pycache__/__init__.cpython-36.pyc', '__builtins__': {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <built-in function input>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'BufferError': <class 'BufferError'>, 'MemoryError': <class 'MemoryError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'quit': Use quit() or Ctrl-D (i.e. EOF) to exit, 'exit': Use exit() or Ctrl-D (i.e. EOF) to exit, 'copyright': Copyright (c) 2001-2018 Python Software Foundation.\r\nAll Rights Reserved.\r\n\r\nCopyright (c) 2000 BeOpen.com.\r\nAll Rights Reserved.\r\n\r\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\r\nAll Rights Reserved.\r\n\r\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\r\nAll Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\r\n    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., '_': None}, '_absolute_import': _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0), 16384), '_division': _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192), '_print_function': _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536), '_os': <module 'os' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/os.py'>, 'tools': <module 'tensorflow.tools' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/tools/__init__.py'>, 'pywrap_tensorflow': <module 'tensorflow.python.pywrap_tensorflow' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py'>, '_api': <module 'tensorflow._api' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/__init__.py'>, 'app': <module 'tensorflow._api.v1.app' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/app/__init__.py'>, 'autograph': <module 'tensorflow._api.v1.autograph' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/autograph/__init__.py'>, 'bitwise': <module 'tensorflow._api.v1.bitwise' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/bitwise/__init__.py'>, 'lite': <module 'tensorflow._api.v1.lite' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/lite/__init__.py'>, 'compat': <module 'tensorflow._api.v1.compat' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/compat/__init__.py'>, 'data': <module 'tensorflow._api.v1.data' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/data/__init__.py'>, 'debugging': <module 'tensorflow._api.v1.debugging' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/debugging/__init__.py'>, 'distribute': <module 'tensorflow._api.v1.distribute' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/distribute/__init__.py'>, 'distributions': <module 'tensorflow._api.v1.distributions' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/distributions/__init__.py'>, 'dtypes': <module 'tensorflow._api.v1.dtypes' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/dtypes/__init__.py'>, 'errors': <module 'tensorflow._api.v1.errors' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/errors/__init__.py'>, 'experimental': <module 'tensorflow._api.v1.experimental' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/experimental/__init__.py'>, 'feature_column': <module 'tensorflow._api.v1.feature_column' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/feature_column/__init__.py'>, 'gfile': <module 'tensorflow._api.v1.gfile' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/gfile/__init__.py'>, 'graph_util': <module 'tensorflow._api.v1.graph_util' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/graph_util/__init__.py'>, 'image': <module 'tensorflow._api.v1.image' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/image/__init__.py'>, 'initializers': <module 'tensorflow._api.v1.initializers' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/initializers/__init__.py'>, 'io': <module 'tensorflow._api.v1.io' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/io/__init__.py'>, 'keras': <module 'tensorflow._api.v1.keras' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/keras/__init__.py'>, 'layers': <module 'tensorflow._api.v1.layers' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/layers/__init__.py'>, 'linalg': <module 'tensorflow._api.v1.linalg' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/linalg/__init__.py'>, 'logging': <module 'tensorflow._api.v1.logging' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/logging/__init__.py'>, 'losses': <module 'tensorflow._api.v1.losses' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/losses/__init__.py'>, 'manip': <module 'tensorflow._api.v1.manip' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/manip/__init__.py'>, 'math': <module 'tensorflow._api.v1.math' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/math/__init__.py'>, 'metrics': <module 'tensorflow._api.v1.metrics' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/metrics/__init__.py'>, 'nn': <module 'tensorflow._api.v1.nn' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/nn/__init__.py'>, 'profiler': <module 'tensorflow._api.v1.profiler' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/profiler/__init__.py'>, 'python_io': <module 'tensorflow._api.v1.python_io' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/python_io/__init__.py'>, 'quantization': <module 'tensorflow._api.v1.quantization' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/quantization/__init__.py'>, 'queue': <module 'tensorflow._api.v1.queue' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/queue/__init__.py'>, 'ragged': <module 'tensorflow._api.v1.ragged' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/ragged/__init__.py'>, 'random': <module 'tensorflow._api.v1.random' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/random/__init__.py'>, 'resource_loader': <module 'tensorflow._api.v1.resource_loader' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/resource_loader/__init__.py'>, 'saved_model': <module 'tensorflow._api.v1.saved_model' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/saved_model/__init__.py'>, 'sets': <module 'tensorflow._api.v1.sets' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sets/__init__.py'>, 'signal': <module 'tensorflow._api.v1.signal' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/signal/__init__.py'>, 'sparse': <module 'tensorflow._api.v1.sparse' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sparse/__init__.py'>, 'spectral': <module 'tensorflow._api.v1.spectral' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/spectral/__init__.py'>, 'strings': <module 'tensorflow._api.v1.strings' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/strings/__init__.py'>, 'summary': <module 'tensorflow._api.v1.summary' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/summary/__init__.py'>, 'sysconfig': <module 'tensorflow._api.v1.sysconfig' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/sysconfig/__init__.py'>, 'test': <module 'tensorflow._api.v1.test' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/test/__init__.py'>, 'train': <module 'tensorflow._api.v1.train' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/train/__init__.py'>, 'user_ops': <module 'tensorflow._api.v1.user_ops' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/user_ops/__init__.py'>, 'version': <module 'tensorflow._api.v1.version' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1/version/__init__.py'>, 'import_graph_def': <function import_graph_def at 0x7fa125a6a6a8>, 'AggregationMethod': <class 'tensorflow.python.ops.gradients_impl.AggregationMethod'>, 'Assert': <function should_use_result.<locals>.wrapped at 0x7fa125b9ca60>, 'AttrValue': <class 'tensorflow.core.framework.attr_value_pb2.AttrValue'>, 'ConditionalAccumulator': <class 'tensorflow.python.ops.data_flow_ops.ConditionalAccumulator'>, 'ConditionalAccumulatorBase': <class 'tensorflow.python.ops.data_flow_ops.ConditionalAccumulatorBase'>, 'ConfigProto': <class 'tensorflow.core.protobuf.config_pb2.ConfigProto'>, 'constant_initializer': <class 'tensorflow.python.ops.init_ops.Constant'>, 'DType': <class 'tensorflow.python.framework.dtypes.DType'>, 'DeviceSpec': <class 'tensorflow.python.framework.device.DeviceSpec'>, 'Dimension': <class 'tensorflow.python.framework.tensor_shape.Dimension'>, 'Event': <class 'tensorflow.core.util.event_pb2.Event'>, 'FIFOQueue': <class 'tensorflow.python.ops.data_flow_ops.FIFOQueue'>, 'FixedLenFeature': <class 'tensorflow.python.ops.parsing_ops.FixedLenFeature'>, 'FixedLenSequenceFeature': <class 'tensorflow.python.ops.parsing_ops.FixedLenSequenceFeature'>, 'FixedLengthRecordReader': <class 'tensorflow.python.ops.io_ops.FixedLengthRecordReader'>, 'GPUOptions': <class 'tensorflow.core.protobuf.config_pb2.GPUOptions'>, 'glorot_normal_initializer': <class 'tensorflow.python.ops.init_ops.GlorotNormal'>, 'glorot_uniform_initializer': <class 'tensorflow.python.ops.init_ops.GlorotUniform'>, 'GradientTape': <class 'tensorflow.python.eager.backprop.GradientTape'>, 'Graph': <class 'tensorflow.python.framework.ops.Graph'>, 'GraphDef': <class 'tensorflow.core.framework.graph_pb2.GraphDef'>, 'GraphKeys': <class 'tensorflow.python.framework.ops.GraphKeys'>, 'GraphOptions': <class 'tensorflow.core.protobuf.config_pb2.GraphOptions'>, 'HistogramProto': <class 'tensorflow.core.framework.summary_pb2.HistogramProto'>, 'IdentityReader': <class 'tensorflow.python.ops.io_ops.IdentityReader'>, 'IndexedSlices': <class 'tensorflow.python.framework.ops.IndexedSlices'>, 'InteractiveSession': <class 'tensorflow.python.client.session.InteractiveSession'>, 'LMDBReader': <class 'tensorflow.python.ops.io_ops.LMDBReader'>, 'LogMessage': <class 'tensorflow.core.util.event_pb2.LogMessage'>, 'MetaGraphDef': <class 'tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef'>, 'NameAttrList': <class 'tensorflow.core.framework.attr_value_pb2.NameAttrList'>, 'NoGradient': <function no_gradient at 0x7fa1260ce598>, 'NotDifferentiable': <function no_gradient at 0x7fa1260ce598>, 'no_gradient': <function no_gradient at 0x7fa1260ce598>, 'NodeDef': <class 'tensorflow.core.framework.node_def_pb2.NodeDef'>, 'ones_initializer': <class 'tensorflow.python.ops.init_ops.Ones'>, 'OpError': <class 'tensorflow.python.framework.errors_impl.OpError'>, 'Operation': <class 'tensorflow.python.framework.ops.Operation'>, 'OptimizerOptions': <class 'tensorflow.core.protobuf.config_pb2.OptimizerOptions'>, 'orthogonal_initializer': <class 'tensorflow.python.ops.init_ops.Orthogonal'>, 'PaddingFIFOQueue': <class 'tensorflow.python.ops.data_flow_ops.PaddingFIFOQueue'>, 'Print': <function Print at 0x7fa1253662f0>, 'PriorityQueue': <class 'tensorflow.python.ops.data_flow_ops.PriorityQueue'>, 'QueueBase': <class 'tensorflow.python.ops.data_flow_ops.QueueBase'>, 'random_normal_initializer': <class 'tensorflow.python.ops.init_ops.RandomNormal'>, 'RandomShuffleQueue': <class 'tensorflow.python.ops.data_flow_ops.RandomShuffleQueue'>, 'random_uniform_initializer': <class 'tensorflow.python.ops.init_ops.RandomUniform'>, 'ReaderBase': <class 'tensorflow.python.ops.io_ops.ReaderBase'>, 'RegisterGradient': <class 'tensorflow.python.framework.ops.RegisterGradient'>, 'RunMetadata': <class 'tensorflow.core.protobuf.config_pb2.RunMetadata'>, 'RunOptions': <class 'tensorflow.core.protobuf.config_pb2.RunOptions'>, 'Session': <class 'tensorflow.python.client.session.Session'>, 'SessionLog': <class 'tensorflow.core.util.event_pb2.SessionLog'>, 'SparseConditionalAccumulator': <class 'tensorflow.python.ops.data_flow_ops.SparseConditionalAccumulator'>, 'SparseFeature': <class 'tensorflow.python.ops.parsing_ops.SparseFeature'>, 'SparseTensor': <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>, 'SparseTensorValue': <class 'tensorflow.python.framework.sparse_tensor.SparseTensorValue'>, 'Summary': <class 'tensorflow.core.framework.summary_pb2.Summary'>, 'SummaryMetadata': <class 'tensorflow.core.framework.summary_pb2.SummaryMetadata'>, 'TFRecordReader': <class 'tensorflow.python.ops.io_ops.TFRecordReader'>, 'Tensor': <class 'tensorflow.python.framework.ops.Tensor'>, 'TensorArray': <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>, 'TensorInfo': <class 'tensorflow.core.protobuf.meta_graph_pb2.TensorInfo'>, 'TensorShape': <class 'tensorflow.python.framework.tensor_shape.TensorShapeV1'>, 'TextLineReader': <class 'tensorflow.python.ops.io_ops.TextLineReader'>, 'truncated_normal_initializer': <class 'tensorflow.python.ops.init_ops.TruncatedNormal'>, 'UnconnectedGradients': <enum 'UnconnectedGradients'>, 'uniform_unit_scaling_initializer': <class 'tensorflow.python.ops.init_ops.UniformUnitScaling'>, 'VarLenFeature': <class 'tensorflow.python.ops.parsing_ops.VarLenFeature'>, 'VariableAggregation': <enum 'VariableAggregation'>, 'VariableScope': <class 'tensorflow.python.ops.variable_scope.VariableScope'>, 'VariableSynchronization': <enum 'VariableSynchronization'>, 'Variable': <class 'tensorflow.python.ops.variables.VariableV1'>, 'variance_scaling_initializer': <class 'tensorflow.python.ops.init_ops.VarianceScaling'>, 'WholeFileReader': <class 'tensorflow.python.ops.io_ops.WholeFileReader'>, 'zeros_initializer': <class 'tensorflow.python.ops.init_ops.Zeros'>, 'abs': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4ba60>, 'accumulate_n': <function accumulate_n at 0x7fa125c63bf8>, 'acos': <function acos at 0x7fa125e7e048>, 'acosh': <function acosh at 0x7fa125e7e158>, 'add': <function add at 0x7fa125e7e268>, 'add_check_numerics_ops': <function add_check_numerics_ops at 0x7fa1254ffc80>, 'add_n': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c63a60>, 'add_to_collection': <function add_to_collection at 0x7fa1260e0c80>, 'add_to_collections': <function add_to_collections at 0x7fa1260e0e18>, 'all_variables': <function all_variables at 0x7fa125af2d08>, 'angle': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45ae8>, 'arg_max': <function arg_max at 0x7fa125c4b488>, 'arg_min': <function arg_min at 0x7fa125c4b620>, 'argmax': <function argmax at 0x7fa125c4b7b8>, 'argmin': <function argmin at 0x7fa125c4b9d8>, 'argsort': <function argsort at 0x7fa1250fc0d0>, 'as_dtype': <function as_dtype at 0x7fa1261dfc80>, 'as_string': <function as_string at 0x7fa12579b268>, 'asin': <function asin at 0x7fa125e7ebf8>, 'asinh': <function asinh at 0x7fa125e7ed08>, 'assert_equal': <function assert_equal at 0x7fa1257e1158>, 'assert_greater': <function assert_greater at 0x7fa1257e16a8>, 'assert_greater_equal': <function assert_greater_equal at 0x7fa1257e1840>, 'assert_integer': <function assert_integer at 0x7fa1257e1ea0>, 'assert_less': <function assert_less at 0x7fa1257e1488>, 'assert_less_equal': <function assert_less_equal at 0x7fa1257e1620>, 'assert_near': <function assert_near at 0x7fa1257e1400>, 'assert_negative': <function assert_negative at 0x7fa125847d08>, 'assert_non_negative': <function assert_non_negative at 0x7fa125847f28>, 'assert_non_positive': <function assert_non_positive at 0x7fa1257e10d0>, 'assert_none_equal': <function assert_none_equal at 0x7fa1257e12f0>, 'assert_positive': <function assert_positive at 0x7fa125847e18>, 'assert_proper_iterable': <function assert_proper_iterable at 0x7fa125847bf8>, 'assert_rank': <function assert_rank at 0x7fa1257e1950>, 'assert_rank_at_least': <function assert_rank_at_least at 0x7fa1257e1ae8>, 'assert_rank_in': <function assert_rank_in at 0x7fa1257e1d90>, 'assert_same_float_dtype': <function assert_same_float_dtype at 0x7fa1257e5378>, 'assert_scalar': <function assert_scalar at 0x7fa1257e5488>, 'assert_type': <function assert_type at 0x7fa1257e5048>, 'assert_variables_initialized': <function should_use_result.<locals>.wrapped at 0x7fa125af5840>, 'assign': <function assign at 0x7fa125bac378>, 'assign_add': <function assign_add at 0x7fa125bac2f0>, 'assign_sub': <function assign_sub at 0x7fa125bac268>, 'atan': <function atan at 0x7fa125e7ee18>, 'atan2': <function atan2 at 0x7fa125e7ef28>, 'atanh': <function atanh at 0x7fa125e7f0d0>, 'batch_gather': <function add_dispatch_support.<locals>.wrapper at 0x7fa125dc3048>, 'batch_to_space': <function batch_to_space at 0x7fa125e3e400>, 'batch_to_space_nd': <function batch_to_space_nd at 0x7fa125ef6598>, 'betainc': <function betainc at 0x7fa125e7f598>, 'bincount': <function bincount_v1 at 0x7fa125c63f28>, 'bitcast': <function bitcast at 0x7fa125ef6620>, 'boolean_mask': <function boolean_mask at 0x7fa125e33bf8>, 'broadcast_dynamic_shape': <function broadcast_dynamic_shape at 0x7fa125e2cb70>, 'broadcast_static_shape': <function broadcast_static_shape at 0x7fa125e2ce18>, 'broadcast_to': <function broadcast_to at 0x7fa125ef6d90>, 'case': <function case at 0x7fa125ba69d8>, 'cast': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45c80>, 'ceil': <function ceil at 0x7fa125e7f9d8>, 'check_numerics': <function check_numerics at 0x7fa125ef6f28>, 'cholesky': <function cholesky at 0x7fa125ac8048>, 'cholesky_solve': <function cholesky_solve at 0x7fa1255446a8>, 'clip_by_average_norm': <function clip_by_average_norm at 0x7fa12550b158>, 'clip_by_global_norm': <function clip_by_global_norm at 0x7fa1254ffea0>, 'clip_by_norm': <function clip_by_norm at 0x7fa1254ffe18>, 'clip_by_value': <function add_dispatch_support.<locals>.wrapper at 0x7fa1254ffd08>, 'colocate_with': <function colocate_with at 0x7fa1260dd9d8>, 'complex': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45730>, 'concat': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e33b70>, 'cond': <function cond at 0x7fa125ba50d0>, 'conj': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b048>, 'container': <function container at 0x7fa1260dd7b8>, 'control_dependencies': <function control_dependencies at 0x7fa1260dd8c8>, 'convert_to_tensor': <function convert_to_tensor at 0x7fa1260c8488>, 'convert_to_tensor_or_indexed_slices': <function convert_to_tensor_or_indexed_slices at 0x7fa1260c87b8>, 'convert_to_tensor_or_sparse_tensor': <function convert_to_tensor_or_sparse_tensor at 0x7fa1260521e0>, 'cos': <function cos at 0x7fa125e00048>, 'cosh': <function cosh at 0x7fa125e00158>, 'count_nonzero': <function count_nonzero at 0x7fa125c562f0>, 'count_up_to': <function count_up_to at 0x7fa125bac510>, 'create_partitioned_variables': <function create_partitioned_variables at 0x7fa125122d08>, 'cross': <function cross at 0x7fa125e002f0>, 'cumprod': <function cumprod at 0x7fa125c6b0d0>, 'cumsum': <function cumsum at 0x7fa125c63ea0>, 'custom_gradient': <function custom_gradient at 0x7fa125409488>, 'decode_base64': <function decode_base64 at 0x7fa12579b400>, 'decode_compressed': <function decode_compressed at 0x7fa1257f3620>, 'decode_csv': <function decode_csv at 0x7fa1253032f0>, 'decode_json_example': <function decode_json_example at 0x7fa1257f3730>, 'decode_raw': <function decode_raw at 0x7fa1257f3840>, 'delete_session_tensor': <function delete_session_tensor at 0x7fa125824a60>, 'depth_to_space': <function depth_to_space at 0x7fa125e3e378>, 'dequantize': <function dequantize at 0x7fa125efca60>, 'deserialize_many_sparse': <function deserialize_many_sparse at 0x7fa1256fa730>, 'device': <function device at 0x7fa1260ced90>, 'diag': <function diag at 0x7fa125efcb70>, 'diag_part': <function diag_part at 0x7fa125efcc80>, 'digamma': <function digamma at 0x7fa125e00620>, 'div': <function div at 0x7fa125c4aa60>, 'div_no_nan': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4ab70>, 'divide': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4be18>, 'dynamic_partition': <function dynamic_partition at 0x7fa125d72a60>, 'dynamic_stitch': <function dynamic_stitch at 0x7fa125d72b70>, 'edit_distance': <function edit_distance at 0x7fa125e35d90>, 'einsum': <function einsum at 0x7fa125369510>, 'enable_eager_execution': <function enable_eager_execution at 0x7fa1260e06a8>, 'encode_base64': <function encode_base64 at 0x7fa12579b510>, 'equal': <function equal at 0x7fa125e008c8>, 'erf': <function erf at 0x7fa125e00a60>, 'erfc': <function erfc at 0x7fa125e00b70>, 'executing_eagerly': <function executing_eagerly at 0x7fa1261c6598>, 'exp': <function exp at 0x7fa125e00bf8>, 'expand_dims': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e2c950>, 'expm1': <function expm1 at 0x7fa125e00d90>, 'extract_image_patches': <function extract_image_patches at 0x7fa125efd1e0>, 'extract_volume_patches': <function extract_volume_patches at 0x7fa125efd2f0>, 'eye': <function eye at 0x7fa125544620>, 'fake_quant_with_min_max_args': <function fake_quant_with_min_max_args at 0x7fa125efd488>, 'fake_quant_with_min_max_args_gradient': <function fake_quant_with_min_max_args_gradient at 0x7fa125efd598>, 'fake_quant_with_min_max_vars': <function fake_quant_with_min_max_vars at 0x7fa125efd6a8>, 'fake_quant_with_min_max_vars_gradient': <function fake_quant_with_min_max_vars_gradient at 0x7fa125efdae8>, 'fake_quant_with_min_max_vars_per_channel': <function fake_quant_with_min_max_vars_per_channel at 0x7fa125efdbf8>, 'fake_quant_with_min_max_vars_per_channel_gradient': <function fake_quant_with_min_max_vars_per_channel_gradient at 0x7fa125eff158>, 'fill': <function fill at 0x7fa125eff1e0>, 'fixed_size_partitioner': <function fixed_size_partitioner at 0x7fa125122b70>, 'floor': <function floor at 0x7fa125e00e18>, 'floor_div': <function floor_div at 0x7fa125e00f28>, 'floormod': <function floor_mod at 0x7fa125e010d0>, 'mod': <function floor_mod at 0x7fa125e010d0>, 'floordiv': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4aae8>, 'foldl': <function foldl at 0x7fa12558d598>, 'foldr': <function foldr at 0x7fa125537840>, 'gather': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e3ed90>, 'gather_nd': <function gather_nd at 0x7fa125eff488>, 'get_collection': <function get_collection at 0x7fa1260e0f28>, 'get_collection_ref': <function get_collection_ref at 0x7fa1260e0ea0>, 'get_default_graph': <function get_default_graph at 0x7fa1260e0950>, 'get_default_session': <function get_default_session at 0x7fa1260ddf28>, 'get_local_variable': <function get_local_variable at 0x7fa125a64a60>, 'get_seed': <function get_seed at 0x7fa126052730>, 'get_session_handle': <function get_session_handle at 0x7fa1258242f0>, 'get_session_tensor': <function get_session_tensor at 0x7fa1258249d8>, 'get_variable': <function get_variable at 0x7fa125a646a8>, 'get_variable_scope': <function get_variable_scope at 0x7fa125a64488>, 'global_norm': <function global_norm at 0x7fa1254fff28>, 'global_variables': <function global_variables at 0x7fa125aeb950>, 'global_variables_initializer': <function global_variables_initializer at 0x7fa125af5268>, 'gradients': <function gradients at 0x7fa12531eea0>, 'greater': <function greater at 0x7fa125e011e0>, 'greater_equal': <function greater_equal at 0x7fa125e012f0>, 'group': <function group at 0x7fa125ba6620>, 'guarantee_const': <function guarantee_const at 0x7fa125eff620>, 'hessians': <function hessians at 0x7fa125323730>, 'histogram_fixed_width': <function histogram_fixed_width at 0x7fa1251b86a8>, 'histogram_fixed_width_bins': <function histogram_fixed_width_bins at 0x7fa1251b8620>, 'identity': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e2c598>, 'identity_n': <function identity_n at 0x7fa125eff840>, 'igamma': <function igamma at 0x7fa125e01598>, 'igammac': <function igammac at 0x7fa125e017b8>, 'imag': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c459d8>, 'initialize_all_tables': <function initialize_all_tables at 0x7fa12518dd08>, 'initialize_all_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af52f0>, 'initialize_local_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af5510>, 'initialize_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af50d0>, 'invert_permutation': <function invert_permutation at 0x7fa125effe18>, 'is_finite': <function is_finite at 0x7fa125e01bf8>, 'is_inf': <function is_inf at 0x7fa125e01d08>, 'is_nan': <function is_nan at 0x7fa125e01e18>, 'is_non_decreasing': <function is_non_decreasing at 0x7fa1257e51e0>, 'is_numeric_tensor': <function is_numeric_tensor at 0x7fa1257e5158>, 'is_strictly_increasing': <function is_strictly_increasing at 0x7fa1257e5268>, 'is_variable_initialized': <function should_use_result.<locals>.wrapped at 0x7fa125af5730>, 'lbeta': <function lbeta at 0x7fa125369400>, 'less': <function less at 0x7fa125e01ea0>, 'less_equal': <function less_equal at 0x7fa125e03048>, 'lgamma': <function lgamma at 0x7fa125e031e0>, 'lin_space': <function lin_space at 0x7fa125e032f0>, 'linspace': <function lin_space at 0x7fa125e032f0>, 'load_file_system_library': <function load_file_system_library at 0x7fa125a931e0>, 'load_library': <function load_library at 0x7fa125a93268>, 'load_op_library': <function load_op_library at 0x7fa125a6a510>, 'local_variables': <function local_variables at 0x7fa125af2d90>, 'local_variables_initializer': <function local_variables_initializer at 0x7fa125af5488>, 'log': <function log at 0x7fa125e03400>, 'log1p': <function log1p at 0x7fa125e03510>, 'log_sigmoid': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c63d08>, 'logical_and': <function logical_and at 0x7fa125e03598>, 'logical_not': <function logical_not at 0x7fa125e036a8>, 'logical_or': <function logical_or at 0x7fa125e037b8>, 'logical_xor': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c40730>, 'make_ndarray': <function MakeNdarray at 0x7fa1260506a8>, 'make_template': <function make_template at 0x7fa1250fc840>, 'make_tensor_proto': <function make_tensor_proto at 0x7fa126050620>, 'map_fn': <function map_fn at 0x7fa1255378c8>, 'matching_files': <function matching_files at 0x7fa125b5b400>, 'matmul': <function matmul at 0x7fa125c63400>, 'matrix_band_part': <function matrix_band_part at 0x7fa125e90510>, 'matrix_determinant': <function matrix_determinant at 0x7fa125ac8b70>, 'matrix_diag': <function matrix_diag at 0x7fa125e90620>, 'matrix_diag_part': <function matrix_diag_part at 0x7fa125e90730>, 'matrix_inverse': <function matrix_inverse at 0x7fa125ac8d90>, 'matrix_set_diag': <function matrix_set_diag at 0x7fa125e90840>, 'matrix_solve': <function matrix_solve at 0x7fa125ac0048>, 'matrix_solve_ls': <function matrix_solve_ls at 0x7fa1255447b8>, 'matrix_square_root': <function matrix_square_root at 0x7fa125ac01e0>, 'matrix_transpose': <function matrix_transpose at 0x7fa125e351e0>, 'matrix_triangular_solve': <function matrix_triangular_solve at 0x7fa125ac0378>, 'maximum': <function maximum at 0x7fa125e03ae8>, 'meshgrid': <function meshgrid at 0x7fa125e35bf8>, 'min_max_variable_partitioner': <function min_max_variable_partitioner at 0x7fa125122ae8>, 'minimum': <function minimum at 0x7fa125e03e18>, 'model_variables': <function model_variables at 0x7fa125af2e18>, 'moving_average_variables': <function moving_average_variables at 0x7fa125af2f28>, 'multinomial': <function multinomial at 0x7fa125ac9400>, 'multiply': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4bf28>, 'name_scope': <class 'tensorflow.python.framework.ops.name_scope'>, 'negative': <function neg at 0x7fa125e051e0>, 'no_op': <function no_op at 0x7fa125bca8c8>, 'no_regularizer': <function no_regularizer at 0x7fa125adeea0>, 'norm': <function norm at 0x7fa125544bf8>, 'not_equal': <function not_equal at 0x7fa125e052f0>, 'one_hot': <function one_hot at 0x7fa125e3e510>, 'ones': <function ones at 0x7fa125e35840>, 'ones_like': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e35620>, 'op_scope': <function op_scope at 0x7fa1260e5488>, 'pad': <function pad at 0x7fa125e35b70>, 'parallel_stack': <function parallel_stack at 0x7fa125e336a8>, 'parse_example': <function parse_example at 0x7fa125302bf8>, 'parse_single_example': <function parse_single_example at 0x7fa125302e18>, 'parse_single_sequence_example': <function parse_single_sequence_example at 0x7fa125303158>, 'parse_tensor': <function parse_tensor at 0x7fa12580bd90>, 'placeholder': <function placeholder at 0x7fa125e358c8>, 'placeholder_with_default': <function placeholder_with_default at 0x7fa125e35950>, 'polygamma': <function polygamma at 0x7fa125e05488>, 'pow': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45620>, 'py_func': <function py_func at 0x7fa1257ed400>, 'qr': <function qr at 0x7fa125ac07b8>, 'quantize': <function quantize at 0x7fa125dc3268>, 'quantize_v2': <function quantize_v2 at 0x7fa125dc31e0>, 'quantized_concat': <function quantized_concat at 0x7fa125e9b1e0>, 'random_crop': <function random_crop at 0x7fa125ac92f0>, 'random_gamma': <function random_gamma at 0x7fa125ac9598>, 'random_normal': <function random_normal at 0x7fa125ac9048>, 'random_poisson': <function random_poisson at 0x7fa125ac9620>, 'random_shuffle': <function random_shuffle at 0x7fa125ac9268>, 'random_uniform': <function random_uniform at 0x7fa125ac91e0>, 'range': <function range at 0x7fa125c40b70>, 'rank': <function rank at 0x7fa125e332f0>, 'read_file': <function read_file at 0x7fa125b5b620>, 'real': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c458c8>, 'realdiv': <function real_div at 0x7fa125e1dbf8>, 'reciprocal': <function reciprocal at 0x7fa125e1dd90>, 'reduce_all': <function reduce_all_v1 at 0x7fa125c63048>, 'reduce_any': <function reduce_any_v1 at 0x7fa125c632f0>, 'reduce_join': <function reduce_join at 0x7fa125682ae8>, 'reduce_logsumexp': <function reduce_logsumexp_v1 at 0x7fa125c63598>, 'reduce_max': <function reduce_max_v1 at 0x7fa125c56d08>, 'reduce_mean': <function reduce_mean_v1 at 0x7fa125c560d0>, 'reduce_min': <function reduce_min_v1 at 0x7fa125c56a60>, 'reduce_prod': <function reduce_prod_v1 at 0x7fa125c568c8>, 'reduce_sum': <function reduce_sum_v1 at 0x7fa125c56048>, 'regex_replace': <function add_dispatch_support.<locals>.wrapper at 0x7fa125682840>, 'register_tensor_conversion_function': <function register_tensor_conversion_function at 0x7fa1260c89d8>, 'report_uninitialized_variables': <function should_use_result.<locals>.wrapped at 0x7fa125af5950>, 'required_space_to_batch_paddings': <function required_space_to_batch_paddings at 0x7fa125e3e048>, 'reset_default_graph': <function reset_default_graph at 0x7fa1260e08c8>, 'reshape': <function reshape at 0x7fa125e9be18>, 'reverse': <function reverse_v2 at 0x7fa125e992f0>, 'reverse_v2': <function reverse_v2 at 0x7fa125e992f0>, 'reverse_sequence': <function reverse_sequence at 0x7fa125e3eb70>, 'rint': <function rint at 0x7fa125e11950>, 'roll': <function roll at 0x7fa1253800d0>, 'round': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45b70>, 'rsqrt': <function rsqrt at 0x7fa125e11b70>, 'saturate_cast': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c45d90>, 'scalar_mul': <function scalar_mul at 0x7fa125c45268>, 'scan': <function scan at 0x7fa125537950>, 'scatter_add': <function scatter_add at 0x7fa125bac620>, 'scatter_div': <function scatter_div at 0x7fa125df6048>, 'scatter_max': <function scatter_max at 0x7fa125df6158>, 'scatter_min': <function scatter_min at 0x7fa125df6268>, 'scatter_mul': <function scatter_mul at 0x7fa125df6378>, 'scatter_nd': <function scatter_nd at 0x7fa125e99400>, 'scatter_nd_add': <function scatter_nd_add at 0x7fa125bac6a8>, 'scatter_nd_sub': <function scatter_nd_sub at 0x7fa125bac7b8>, 'scatter_nd_update': <function scatter_nd_update at 0x7fa125bac598>, 'scatter_sub': <function scatter_sub at 0x7fa125bac730>, 'scatter_update': <function scatter_update at 0x7fa125bac400>, 'searchsorted': <function searchsorted at 0x7fa125dc30d0>, 'segment_max': <function segment_max at 0x7fa125e11d90>, 'segment_mean': <function segment_mean at 0x7fa125e11ea0>, 'segment_min': <function segment_min at 0x7fa125e26048>, 'segment_prod': <function segment_prod at 0x7fa125e26158>, 'segment_sum': <function segment_sum at 0x7fa125e26268>, 'self_adjoint_eig': <function self_adjoint_eig at 0x7fa125544840>, 'self_adjoint_eigvals': <function self_adjoint_eigvals at 0x7fa1255448c8>, 'sequence_mask': <function sequence_mask at 0x7fa125e3e620>, 'serialize_many_sparse': <function serialize_many_sparse at 0x7fa1256fa598>, 'serialize_sparse': <function serialize_sparse at 0x7fa1256fa488>, 'serialize_tensor': <function serialize_tensor at 0x7fa12580bea0>, 'set_random_seed': <function set_random_seed at 0x7fa1260526a8>, 'setdiff1d': <function setdiff1d at 0x7fa125e2cd90>, 'shape': <function shape at 0x7fa125e2cf28>, 'shape_n': <function shape_n at 0x7fa125e330d0>, 'sigmoid': <function sigmoid at 0x7fa125c63c80>, 'sign': <function sign at 0x7fa125e26620>, 'sin': <function sin at 0x7fa125e26730>, 'sinh': <function sinh at 0x7fa125e26840>, 'size': <function size at 0x7fa125e331e0>, 'slice': <function slice at 0x7fa125e33510>, 'sort': <function sort at 0x7fa125122bf8>, 'space_to_batch': <function space_to_batch at 0x7fa125e3e158>, 'space_to_batch_nd': <function space_to_batch_nd at 0x7fa125e99c80>, 'space_to_depth': <function space_to_depth at 0x7fa125e3e268>, 'sparse_add': <function sparse_add at 0x7fa1256e2ea0>, 'sparse_concat': <function sparse_concat at 0x7fa1256e2c80>, 'sparse_fill_empty_rows': <function sparse_fill_empty_rows at 0x7fa1256fa400>, 'sparse_mask': <function sparse_mask at 0x7fa125e33e18>, 'sparse_matmul': <function sparse_mat_mul at 0x7fa125e26950>, 'sparse_maximum': <function sparse_maximum at 0x7fa1256fa8c8>, 'sparse_merge': <function sparse_merge at 0x7fa1256fa268>, 'sparse_minimum': <function sparse_minimum at 0x7fa1256fa950>, 'sparse_placeholder': <function sparse_placeholder at 0x7fa125e35ae8>, 'sparse_reduce_max': <function sparse_reduce_max at 0x7fa1256f68c8>, 'sparse_reduce_max_sparse': <function sparse_reduce_max_sparse at 0x7fa1256f6bf8>, 'sparse_reduce_sum': <function sparse_reduce_sum at 0x7fa1256f6d90>, 'sparse_reduce_sum_sparse': <function sparse_reduce_sum_sparse at 0x7fa1256fa158>, 'sparse_reorder': <function sparse_reorder at 0x7fa1256f6158>, 'sparse_reset_shape': <function sparse_reset_shape at 0x7fa1256fa378>, 'sparse_reshape': <function sparse_reshape at 0x7fa1256f61e0>, 'sparse_retain': <function sparse_retain at 0x7fa1256fa2f0>, 'sparse_segment_mean': <function sparse_segment_mean at 0x7fa125c6b730>, 'sparse_segment_sqrt_n': <function sparse_segment_sqrt_n at 0x7fa125c6b840>, 'sparse_segment_sum': <function sparse_segment_sum at 0x7fa125c6b620>, 'sparse_slice': <function sparse_slice at 0x7fa1256f6378>, 'sparse_softmax': <function sparse_softmax at 0x7fa1256fa840>, 'sparse_split': <function sparse_split at 0x7fa1256f6510>, 'sparse_tensor_dense_matmul': <function sparse_tensor_dense_matmul at 0x7fa1256fa7b8>, 'sparse_tensor_to_dense': <function sparse_tensor_to_dense at 0x7fa1256f6c80>, 'sparse_to_dense': <function sparse_to_dense at 0x7fa1256f6598>, 'sparse_to_indicator': <function sparse_to_indicator at 0x7fa1256fa048>, 'sparse_transpose': <function sparse_transpose at 0x7fa1256fa9d8>, 'split': <function split at 0x7fa125e33f28>, 'sqrt': <function sqrt at 0x7fa125e25378>, 'square': <function square at 0x7fa125e25598>, 'squared_difference': <function squared_difference at 0x7fa125e25730>, 'squeeze': <function squeeze at 0x7fa125e3e8c8>, 'stack': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e337b8>, 'stop_gradient': <function stop_gradient at 0x7fa125e851e0>, 'strided_slice': <function strided_slice at 0x7fa125e33598>, 'string_join': <function string_join at 0x7fa12579bc80>, 'string_split': <function string_split at 0x7fa1256828c8>, 'string_strip': <function string_strip at 0x7fa1257b6840>, 'string_to_hash_bucket_fast': <function string_to_hash_bucket_fast at 0x7fa1257b6a60>, 'string_to_hash_bucket_strong': <function string_to_hash_bucket_strong at 0x7fa1257b6b70>, 'substr': <function substr_deprecated at 0x7fa125682ea0>, 'subtract': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c451e0>, 'svd': <function svd at 0x7fa125544950>, 'tables_initializer': <function tables_initializer at 0x7fa1251b8a60>, 'tan': <function tan at 0x7fa125e259d8>, 'tanh': <function tanh at 0x7fa125e25ae8>, 'tensor_scatter_add': <function tensor_scatter_add at 0x7fa125e85620>, 'tensor_scatter_sub': <function tensor_scatter_sub at 0x7fa125e85730>, 'tensor_scatter_update': <function tensor_scatter_update at 0x7fa125e85840>, 'tensordot': <function tensordot at 0x7fa125c6b8c8>, 'tile': <function tile at 0x7fa125e859d8>, 'timestamp': <function timestamp at 0x7fa125bd9268>, 'to_bfloat16': <function to_bfloat16 at 0x7fa125c4a400>, 'to_complex128': <function to_complex128 at 0x7fa125c4a620>, 'to_complex64': <function to_complex64 at 0x7fa125c4a510>, 'to_double': <function to_double at 0x7fa125c4a0d0>, 'to_float': <function to_float at 0x7fa125c45f28>, 'to_int32': <function to_int32 at 0x7fa125c4a1e0>, 'to_int64': <function to_int64 at 0x7fa125c4a2f0>, 'trace': <function trace at 0x7fa125c636a8>, 'trainable_variables': <function trainable_variables at 0x7fa125af2ea0>, 'transpose': <function transpose at 0x7fa125e350d0>, 'truediv': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c4a8c8>, 'truncatediv': <function truncate_div at 0x7fa125e25d08>, 'truncatemod': <function truncate_mod at 0x7fa125e25e18>, 'truncated_normal': <function truncated_normal at 0x7fa125ac9158>, 'tuple': <function tuple at 0x7fa125ba6730>, 'unique': <function unique at 0x7fa125e33d90>, 'unique_with_counts': <function unique_with_counts at 0x7fa125e33ea0>, 'unravel_index': <function unravel_index at 0x7fa125ea4048>, 'unsorted_segment_max': <function unsorted_segment_max at 0x7fa125e17048>, 'unsorted_segment_mean': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b488>, 'unsorted_segment_min': <function unsorted_segment_min at 0x7fa125e17158>, 'unsorted_segment_prod': <function unsorted_segment_prod at 0x7fa125e17268>, 'unsorted_segment_sqrt_n': <function add_dispatch_support.<locals>.wrapper at 0x7fa125c6b598>, 'unsorted_segment_sum': <function unsorted_segment_sum at 0x7fa125e17378>, 'unstack': <function unstack at 0x7fa125e33a60>, 'variable_axis_size_partitioner': <function variable_axis_size_partitioner at 0x7fa1251b8730>, 'variable_op_scope': <function variable_op_scope at 0x7fa125a65158>, 'variable_scope': <class 'tensorflow.python.ops.variable_scope.variable_scope'>, 'variables_initializer': <function variables_initializer at 0x7fa125af5048>, 'verify_tensor_all_finite': <function verify_tensor_all_finite at 0x7fa1254ffbf8>, 'where': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e3e950>, 'while_loop': <function while_loop at 0x7fa125ba6378>, 'write_file': <function write_file at 0x7fa125b6b400>, 'zeros': <function zeros at 0x7fa125e35268>, 'zeros_like': <function add_dispatch_support.<locals>.wrapper at 0x7fa125e35378>, 'zeta': <function zeta at 0x7fa125e176a8>, 'disable_v2_behavior': <function disable_v2_behavior at 0x7fa12577c620>, 'enable_v2_behavior': <function enable_v2_behavior at 0x7fa12577c598>, 'wrap_function': <function wrap_function at 0x7fa1251b81e0>, 'constant': <function constant_v1 at 0x7fa132b8d9d8>, 'QUANTIZED_DTYPES': frozenset({tf.qint8, tf.quint8, tf.qint32, tf.qint8_ref, tf.quint8_ref, tf.qint32_ref, tf.qint16, tf.qint16_ref, tf.quint16_ref, tf.quint16}), 'bfloat16': tf.bfloat16, 'bool': tf.bool, 'complex128': tf.complex128, 'complex64': tf.complex64, 'double': tf.float64, 'float16': tf.float16, 'float32': tf.float32, 'float64': tf.float64, 'half': tf.float16, 'int16': tf.int16, 'int32': tf.int32, 'int64': tf.int64, 'int8': tf.int8, 'qint16': tf.qint16, 'qint32': tf.qint32, 'qint8': tf.qint8, 'quint16': tf.quint16, 'quint8': tf.quint8, 'resource': tf.resource, 'string': tf.string, 'uint16': tf.uint16, 'uint32': tf.uint32, 'uint64': tf.uint64, 'uint8': tf.uint8, 'variant': tf.variant, 'disable_eager_execution': <function disable_eager_execution at 0x7fa1260e0730>, 'init_scope': <function init_scope at 0x7fa1260e0510>, 'dimension_at_index': <function dimension_at_index at 0x7fa1261702f0>, 'dimension_value': <function dimension_value at 0x7fa126170268>, 'disable_v2_tensorshape': <function disable_v2_tensorshape at 0x7fa1261701e0>, 'enable_v2_tensorshape': <function enable_v2_tensorshape at 0x7fa126170158>, 'TensorSpec': <class 'tensorflow.python.framework.tensor_spec.TensorSpec'>, 'COMPILER_VERSION': '4.8.5', '__compiler_version__': '4.8.5', 'CXX11_ABI_FLAG': 0, '__cxx11_abi_flag__': 0, 'GIT_VERSION': \"b'v1.13.1-0-g6612da8951'\", '__git_version__': \"b'v1.13.1-0-g6612da8951'\", 'GRAPH_DEF_VERSION': 27, 'GRAPH_DEF_VERSION_MIN_CONSUMER': 0, 'GRAPH_DEF_VERSION_MIN_PRODUCER': 0, 'MONOLITHIC_BUILD': 0, '__monolithic_build__': 0, 'VERSION': '1.13.1', '__version__': '1.13.1', 'newaxis': None, 'ensure_shape': <function ensure_shape at 0x7fa1257e5400>, 'confusion_matrix': <function confusion_matrix_v1 at 0x7fa12558d268>, 'string_to_number': <function string_to_number at 0x7fa12580bf28>, 'fft': <function fft at 0x7fa126038488>, 'fft2d': <function fft2d at 0x7fa126038598>, 'fft3d': <function fft3d at 0x7fa1260386a8>, 'ifft': <function ifft at 0x7fa1260387b8>, 'ifft2d': <function ifft2d at 0x7fa1260388c8>, 'ifft3d': <function ifft3d at 0x7fa1260389d8>, 'string_to_hash_bucket': <function string_to_hash_bucket at 0x7fa1257b68c8>, 'print': <function print_v2 at 0x7fa125366400>, 'RaggedTensor': <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>, 'py_function': <function eager_py_func at 0x7fa1257ed268>, 'batch_scatter_update': <function batch_scatter_update at 0x7fa125bac950>, 'AUTO_REUSE': <_ReuseMode.AUTO_REUSE: 1>, 'disable_resource_variables': <function disable_resource_variables at 0x7fa125add048>, 'enable_resource_variables': <function enable_resource_variables at 0x7fa125b04f28>, 'variable_creator_scope': <function variable_creator_scope_v1 at 0x7fa125a65510>, 'get_logger': <function get_logger at 0x7fa126978598>, '_names_with_underscore': ['__version__', '__git_version__', '__compiler_version__', '__cxx11_abi_flag__', '__monolithic_build__'], '__all__': ['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', 'COMPILER_VERSION', 'CXX11_ABI_FLAG', 'ConditionalAccumulator', 'ConditionalAccumulatorBase', 'ConfigProto', 'DType', 'DeviceSpec', 'Dimension', 'Event', 'FIFOQueue', 'FixedLenFeature', 'FixedLenSequenceFeature', 'FixedLengthRecordReader', 'GIT_VERSION', 'GPUOptions', 'GRAPH_DEF_VERSION', 'GRAPH_DEF_VERSION_MIN_CONSUMER', 'GRAPH_DEF_VERSION_MIN_PRODUCER', 'GradientTape', 'Graph', 'GraphDef', 'GraphKeys', 'GraphOptions', 'HistogramProto', 'IdentityReader', 'IndexedSlices', 'InteractiveSession', 'LMDBReader', 'LogMessage', 'MONOLITHIC_BUILD', 'MetaGraphDef', 'NameAttrList', 'NoGradient', 'NodeDef', 'NotDifferentiable', 'OpError', 'Operation', 'OptimizerOptions', 'PaddingFIFOQueue', 'Print', 'PriorityQueue', 'QUANTIZED_DTYPES', 'QueueBase', 'RaggedTensor', 'RandomShuffleQueue', 'ReaderBase', 'RegisterGradient', 'RunMetadata', 'RunOptions', 'Session', 'SessionLog', 'SparseConditionalAccumulator', 'SparseFeature', 'SparseTensor', 'SparseTensorValue', 'Summary', 'SummaryMetadata', 'TFRecordReader', 'Tensor', 'TensorArray', 'TensorInfo', 'TensorShape', 'TensorSpec', 'TextLineReader', 'UnconnectedGradients', 'VERSION', 'VarLenFeature', 'Variable', 'VariableAggregation', 'VariableScope', 'VariableSynchronization', 'WholeFileReader', 'abs', 'accumulate_n', 'acos', 'acosh', 'add', 'add_check_numerics_ops', 'add_n', 'add_to_collection', 'add_to_collections', 'all_variables', 'angle', 'app', 'arg_max', 'arg_min', 'argmax', 'argmin', 'argsort', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_greater_equal', 'assert_integer', 'assert_less', 'assert_less_equal', 'assert_near', 'assert_negative', 'assert_non_negative', 'assert_non_positive', 'assert_none_equal', 'assert_positive', 'assert_proper_iterable', 'assert_rank', 'assert_rank_at_least', 'assert_rank_in', 'assert_same_float_dtype', 'assert_scalar', 'assert_type', 'assert_variables_initialized', 'assign', 'assign_add', 'assign_sub', 'atan', 'atan2', 'atanh', 'autograph', 'batch_gather', 'batch_scatter_update', 'batch_to_space', 'batch_to_space_nd', 'betainc', 'bfloat16', 'bincount', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'broadcast_to', 'case', 'cast', 'ceil', 'check_numerics', 'cholesky', 'cholesky_solve', 'clip_by_average_norm', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'colocate_with', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'confusion_matrix', 'conj', 'constant', 'constant_initializer', 'container', 'control_dependencies', 'convert_to_tensor', 'convert_to_tensor_or_indexed_slices', 'convert_to_tensor_or_sparse_tensor', 'core', 'cos', 'cosh', 'count_nonzero', 'count_up_to', 'create_partitioned_variables', 'cross', 'cumprod', 'cumsum', 'custom_gradient', 'data', 'debugging', 'decode_base64', 'decode_compressed', 'decode_csv', 'decode_json_example', 'decode_raw', 'delete_session_tensor', 'depth_to_space', 'dequantize', 'deserialize_many_sparse', 'device', 'diag', 'diag_part', 'digamma', 'dimension_at_index', 'dimension_value', 'disable_eager_execution', 'disable_resource_variables', 'disable_v2_behavior', 'disable_v2_tensorshape', 'distribute', 'distributions', 'div', 'div_no_nan', 'divide', 'double', 'dtypes', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'einsum', 'enable_eager_execution', 'enable_resource_variables', 'enable_v2_behavior', 'enable_v2_tensorshape', 'encode_base64', 'ensure_shape', 'equal', 'erf', 'erfc', 'errors', 'executing_eagerly', 'exp', 'expand_dims', 'experimental', 'expm1', 'extract_image_patches', 'extract_volume_patches', 'eye', 'fake_quant_with_min_max_args', 'fake_quant_with_min_max_args_gradient', 'fake_quant_with_min_max_vars', 'fake_quant_with_min_max_vars_gradient', 'fake_quant_with_min_max_vars_per_channel', 'fake_quant_with_min_max_vars_per_channel_gradient', 'feature_column', 'fft', 'fft2d', 'fft3d', 'fill', 'fixed_size_partitioner', 'float16', 'float32', 'float64', 'floor', 'floor_div', 'floordiv', 'floormod', 'foldl', 'foldr', 'gather', 'gather_nd', 'get_collection', 'get_collection_ref', 'get_default_graph', 'get_default_session', 'get_local_variable', 'get_logger', 'get_seed', 'get_session_handle', 'get_session_tensor', 'get_variable', 'get_variable_scope', 'gfile', 'global_norm', 'global_variables', 'global_variables_initializer', 'glorot_normal_initializer', 'glorot_uniform_initializer', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'guarantee_const', 'half', 'hessians', 'histogram_fixed_width', 'histogram_fixed_width_bins', 'identity', 'identity_n', 'ifft', 'ifft2d', 'ifft3d', 'igamma', 'igammac', 'imag', 'image', 'import_graph_def', 'init_scope', 'initialize_all_tables', 'initialize_all_variables', 'initialize_local_variables', 'initialize_variables', 'initializers', 'int16', 'int32', 'int64', 'int8', 'invert_permutation', 'io', 'is_finite', 'is_inf', 'is_nan', 'is_non_decreasing', 'is_numeric_tensor', 'is_strictly_increasing', 'is_variable_initialized', 'keras', 'layers', 'lbeta', 'less', 'less_equal', 'lgamma', 'lin_space', 'linalg', 'linspace', 'lite', 'load_file_system_library', 'load_library', 'load_op_library', 'local_variables', 'local_variables_initializer', 'log', 'log1p', 'log_sigmoid', 'logging', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'losses', 'make_ndarray', 'make_template', 'make_tensor_proto', 'manip', 'map_fn', 'matching_files', 'math', 'matmul', 'matrix_band_part', 'matrix_determinant', 'matrix_diag', 'matrix_diag_part', 'matrix_inverse', 'matrix_set_diag', 'matrix_solve', 'matrix_solve_ls', 'matrix_square_root', 'matrix_transpose', 'matrix_triangular_solve', 'maximum', 'meshgrid', 'metrics', 'min_max_variable_partitioner', 'minimum', 'mod', 'model_variables', 'moving_average_variables', 'multinomial', 'multiply', 'name_scope', 'negative', 'newaxis', 'nn', 'no_gradient', 'no_op', 'no_regularizer', 'norm', 'not_equal', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'op_scope', 'orthogonal_initializer', 'pad', 'parallel_stack', 'parse_example', 'parse_single_example', 'parse_single_sequence_example', 'parse_tensor', 'placeholder', 'placeholder_with_default', 'polygamma', 'pow', 'print', 'profiler', 'py_func', 'py_function', 'python', 'python_io', 'pywrap_tensorflow', 'qint16', 'qint32', 'qint8', 'qr', 'quantization', 'quantize', 'quantize_v2', 'quantized_concat', 'queue', 'quint16', 'quint8', 'ragged', 'random', 'random_crop', 'random_gamma', 'random_normal', 'random_normal_initializer', 'random_poisson', 'random_shuffle', 'random_uniform', 'random_uniform_initializer', 'range', 'rank', 'read_file', 'real', 'realdiv', 'reciprocal', 'reduce_all', 'reduce_any', 'reduce_join', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'regex_replace', 'register_tensor_conversion_function', 'report_uninitialized_variables', 'required_space_to_batch_paddings', 'reset_default_graph', 'reshape', 'resource', 'resource_loader', 'reverse', 'reverse_sequence', 'reverse_v2', 'rint', 'roll', 'round', 'rsqrt', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_add', 'scatter_div', 'scatter_max', 'scatter_min', 'scatter_mul', 'scatter_nd', 'scatter_nd_add', 'scatter_nd_sub', 'scatter_nd_update', 'scatter_sub', 'scatter_update', 'searchsorted', 'segment_max', 'segment_mean', 'segment_min', 'segment_prod', 'segment_sum', 'self_adjoint_eig', 'self_adjoint_eigvals', 'sequence_mask', 'serialize_many_sparse', 'serialize_sparse', 'serialize_tensor', 'set_random_seed', 'setdiff1d', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'signal', 'sin', 'sinh', 'size', 'slice', 'sort', 'space_to_batch', 'space_to_batch_nd', 'space_to_depth', 'sparse', 'sparse_add', 'sparse_concat', 'sparse_fill_empty_rows', 'sparse_mask', 'sparse_matmul', 'sparse_maximum', 'sparse_merge', 'sparse_minimum', 'sparse_placeholder', 'sparse_reduce_max', 'sparse_reduce_max_sparse', 'sparse_reduce_sum', 'sparse_reduce_sum_sparse', 'sparse_reorder', 'sparse_reset_shape', 'sparse_reshape', 'sparse_retain', 'sparse_segment_mean', 'sparse_segment_sqrt_n', 'sparse_segment_sum', 'sparse_slice', 'sparse_softmax', 'sparse_split', 'sparse_tensor_dense_matmul', 'sparse_tensor_to_dense', 'sparse_to_dense', 'sparse_to_indicator', 'sparse_transpose', 'spectral', 'split', 'sqrt', 'square', 'squared_difference', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'string_join', 'string_split', 'string_strip', 'string_to_hash_bucket', 'string_to_hash_bucket_fast', 'string_to_hash_bucket_strong', 'string_to_number', 'strings', 'substr', 'subtract', 'summary', 'svd', 'sysconfig', 'tables_initializer', 'tan', 'tanh', 'tensor_scatter_add', 'tensor_scatter_sub', 'tensor_scatter_update', 'tensordot', 'test', 'tile', 'timestamp', 'to_bfloat16', 'to_complex128', 'to_complex64', 'to_double', 'to_float', 'to_int32', 'to_int64', 'tools', 'trace', 'train', 'trainable_variables', 'transpose', 'truediv', 'truncated_normal', 'truncated_normal_initializer', 'truncatediv', 'truncatemod', 'tuple', 'uint16', 'uint32', 'uint64', 'uint8', 'uniform_unit_scaling_initializer', 'unique', 'unique_with_counts', 'unravel_index', 'unsorted_segment_max', 'unsorted_segment_mean', 'unsorted_segment_min', 'unsorted_segment_prod', 'unsorted_segment_sqrt_n', 'unsorted_segment_sum', 'unstack', 'user_ops', 'variable_axis_size_partitioner', 'variable_creator_scope', 'variable_op_scope', 'variable_scope', 'variables_initializer', 'variance_scaling_initializer', 'variant', 'verify_tensor_all_finite', 'version', 'where', 'while_loop', 'wrap_function', 'write_file', 'zeros', 'zeros_initializer', 'zeros_like', 'zeta', '__version__', '__git_version__', '__compiler_version__', '__cxx11_abi_flag__', '__monolithic_build__', 'contrib'], '_component_api_helper': <module 'tensorflow.python.tools.component_api_helper' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/tools/component_api_helper.py'>, 'estimator': <module 'tensorflow_estimator.python.estimator.api.estimator' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/estimator/__init__.py'>, '_CONTRIB_WARNING': '\\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\\nFor more information, please see:\\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\\n  * https://github.com/tensorflow/addons\\nIf you depend on functionality not listed there, please file an issue.\\n', 'contrib': <module 'tensorflow.contrib' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/contrib/__init__.py'>, 'flags': <module 'tensorflow.python.platform.flags' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/python/platform/flags.py'>, '_tf_api_dir': '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/_api/v1', 'compiler': <module 'tensorflow.compiler' from '/home/sylee957/miniconda3/envs/sympy_dev_36_tensorflow_113/lib/python3.6/site-packages/tensorflow/compiler/__init__.py'>}\r\n```\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow\r\nprint(tensorflow.__dict__)\r\nprint(tensorflow.__doc__)\r\n```\r\n\r\n**Other info / logs**\r\nWe have been using `tensorflow.__dict__` to look up for the tensorflow functions in rigorous manner, for code generation purposes.", "comments": ["Related to #30028 but this has a larger scope", "@sylee957, Associated PR has been merged. Can you confirm if the issue is resolved. Thanks!", "I can confirm that this had been fixed"]}, {"number": 30183, "title": "build using cmake failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version:1.14.0\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): VS 2105\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: GTX Titan X\r\n\r\n\r\n\r\n**Describe the problem**\r\nMissing directory/files: tensorflow/contrib/tpu/ops\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nrunning Cmake \r\ntensorflow/contrib/cmake/python_modules.txt contains the line but no  tensorflow/contrib/tpu/ops does not exist\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sragini24 We don't provide support for the CMake build anymore. Please use bazel instead to build.Thanks!", "Could you provide me a link to the procedures to use bazel  to generate c++ code for use with Visual Studio 2015?\r\nThanks", "@sragini24  Have a look at this issue [#24885](https://github.com/tensorflow/tensorflow/issues/24885). Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30182, "title": "autograph should handle \"for\" loops over \"range\" in a manner that is compatible with XLA compilation", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nConsider the following Python code:\r\n```python\r\nimport tensorflow as tf\r\nautograph = tf.contrib.autograph\r\nxla = tf.contrib.compiler.xla\r\n\r\ntf.enable_eager_execution()\r\n\r\n@tf.function\r\ndef bad_loop(x, count):\r\n  for _ in range(count):\r\n    x += 1\r\n  return x\r\n\r\n@tf.function\r\ndef good_loop(x, count):\r\n  i = 0\r\n  while i < count:\r\n    x += 1\r\n    i += 1\r\n  return x\r\n```\r\n\r\n`bad_loop` is the intuitive way to write this loop. However, it fails to compile with xla:\r\n```\r\n>>> xla.compile(bad_loop, [1.0, 3])\r\nInvalidArgumentError: Input 1 to node `StatefulPartitionedCall/range` with op Range must be a compile-time constant.\r\n\r\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\r\n\t [[{{node StatefulPartitionedCall/range}}]]\r\n\tThis error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS=\"tf_xla_auto_jit=2\" which will attempt to use xla to compile as much of the graph as the compiler is able to.\r\n\t [[cluster]] [Op:__inference_xla_compile_wrapper_166]\r\n```\r\n\r\nIn contrast, `good_loop` calculates the correct result:\r\n```\r\n>>> xla.compile(good_loop, [1.0, 3])\r\n[<tf.Tensor: id=229, shape=(), dtype=float32, numpy=4.0>]\r\n```\r\n\r\nAutograph seems to always convert `range()` into `tf.range()`, even in for loops. This means that XLA can't compile the function. However, the equivalent loop written as a naive `while` loop works.\r\n\r\nIdeally, Autograph would detect such uses of `range` in for loops and convert them into the style of `good_loop` automatically, rather than requiring users to do this. This would let us write cleaner code.\r\n\r\n**Will this change the current api? How?** No\r\n\r\n**Who will benefit with this feature?** Users who want to write normal Python code with Autograph.\r\n\r\n**Any Other info.**\r\n", "comments": ["I have tried on colab with TF version 1.14 and was able to reproduce the issue.Thanks!", "Looks like a few bugs are being compound here; I'll list them along with recommendations and plans to address -\r\n\r\n1. I think you are correct, in this case there is no way but to detect the use of `tf.range`; at first, I thought this would be a mere performance optimization, but it seems to be required for XLA. It wasn't already enabled because the detection of `tf.range` op is not terribly robust, but I think this example justifies it. Will follow up with a fix soon. In the mean time, using `tf.range(3)` should work (see below).\r\n\r\n2. `range` is normally not converted to `tf.range` - this only happens when its argument is a Tensor; xla.compile will auto-cast all arguments to tensors, hence `range` will receive a Tensor even though you only specify just 3. Even so, using `range(tf.constant(3))`, is not officially supported and I recommend using `tf.range`, which is more explicit anyway.\r\n\r\n3. (filed #30235) It appears that `tf.range` only works in XLA if you specify it with an inline constant: `tf.range(tf.constant(3))`; even though `bad_function` should be equivalent to that, it looks like `xla.compile` will not recognize the constant argument and raise an error. For example, the following code will work:\r\n\r\n```\r\nimport tensorflow as tf\r\nautograph = tf.contrib.autograph\r\nxla = tf.contrib.compiler.xla\r\n\r\ntf.enable_eager_execution()\r\n\r\n@tf.function\r\ndef good_bad_loop(x):\r\n  for _ in tf.range(3):\r\n    x += 1\r\n  return x\r\n\r\nxla.compile(good_bad_loop, (1.0,))\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30182\">No</a>\n", "Thank you @mdanatg!"]}]