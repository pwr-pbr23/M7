[{"number": 34982, "title": "Can I train with keras float16 and convert it to tensorflow-lite float16 model", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["TFLite converter supports FP16 quantization. https://www.tensorflow.org/lite/performance/post_training_quantization#float16_quantization_of_weights\r\nIn this case, you don't actually need to use float16 at training stage. You can train your model with float32 and covert it to tflite with fp16 quantization.", "there is lots of quantization in the model if I use tflite float16 quantization\uff0cthese quantization may consume times\uff0cis there any way to remove them", "@akkaze some quantization techniques requires quant and dequant operations which are essential. But in our benchmark, those ops impact minimal to overall computation time."]}, {"number": 34981, "title": "[Java-tensorflow-seed] Restoring saved model with dropout applied from java program", "body": "\r\n**This is my first issue, and I read the guide to post. I am not sure whether it is a new feature request. Otherwise, please correct me.**\r\n\r\n\r\nI have a pre-trained model with dropout applied and I want to restore it from java program.\r\n\r\nWith my application, in a inference session, I need to turn on dropout and repeat feeding input to the model multiple times and get an array of predictions. Another feeding session, I get another array.\r\n\r\nIn python, I set seed as follow: \r\n`slim.dropout(input, keep_prob, is_training = phase_train, scope='dropout_mask', seed=1)`\r\n\r\nIn java, I want the same inference (same array) but it is not, even though I reinitialized the session every time. \r\nI know that the dropout mask is changed over time.\r\nI guess I need \"seed\" variable as what we have in python API. But I couldn't find any reference.\r\n\r\nWhat I tried: To get the same prediction list, I need to load the model and initialize the session multiple times. But it is not optimal as it takes time and can cause memory related issue.\r\n\r\nIs there any \"seed\" variable in java API or similar things to control the output?\r\n\r\n\r\n\r\n", "comments": ["Finally, I solved the problem.\r\nFor more information, find [here](https://stackoverflow.com/questions/59244928/restoring-saved-model-with-dropout-applied-from-java-program/59300697#59300697)."]}, {"number": 34980, "title": "Missing symbols from C++ API", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock example\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ArchLinux x86_64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.1.0-rc0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 1.2.0\r\n- GCC/Compiler version (if compiling from source): 9.2\r\n- CUDA/cuDNN version: 10.2.89/7.6.5.32\r\n- GPU model and memory: NVidia GTX 980\r\n\r\n**Describe the current behavior**\r\nTrying to compile an example results in broken linking:\r\n```c++\r\n// basic.cpp\r\n// tensorflow/cc/example/example.cc\r\n\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nint main() {\r\n  namespace tf = tensorflow;\r\n  namespace tfo = tensorflow::ops;\r\n  tf::Scope root = tf::Scope::NewRootScope();\r\n  // Matrix A = [3 2; -1 0]\r\n  auto A = tfo::Const(root, { {3.f, 2.f}, {-1.f, 0.f} });\r\n  // Vector b = [3 5]\r\n  auto b = tfo::Const(root, { {3.f, 5.f} });\r\n  // v = Ab^T\r\n  auto v = tfo::MatMul(root.WithOpName(\"v\"), A, b, tfo::MatMul::TransposeB(true));\r\n  std::vector<tf::Tensor> outputs;\r\n  tf::ClientSession session(root);\r\n  // Run and fetch v\r\n  TF_CHECK_OK(session.Run({v}, &outputs));\r\n  // Expect outputs[0] == [19; -3]\r\n  LOG(INFO) << outputs[0].matrix<float>();\r\n  return 0;\r\n}\r\n```\r\ntrying to compile with `g++ basic.cpp -I/usr/include/tensorflow  -ltensorflow_cc -ltensorflow_framework  -o basic` fails:\r\n```bash\r\nmake -C tensorflow/basic run\r\nmake[1]: Entering directory '/home/gizdov/Git/arch-package-tests/tensorflow/basic'\r\ng++ basic.cpp -I/usr/include/tensorflow  -ltensorflow_cc -ltensorflow_framework  -o basic\r\n/usr/bin/ld: /tmp/ccidGpWX.o: in function `main':\r\nbasic.cpp:(.text+0x363): undefined reference to `tensorflow::ClientSession::ClientSession(tensorflow::Scope const&)'\r\n/usr/bin/ld: basic.cpp:(.text+0x3ea): undefined reference to `tensorflow::ClientSession::Run(std::vector<tensorflow::Output, std::allocator<tensorflow::Output> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) const'\r\n/usr/bin/ld: basic.cpp:(.text+0x52b): undefined reference to `tensorflow::ClientSession::~ClientSession()'\r\n/usr/bin/ld: basic.cpp:(.text+0x70d): undefined reference to `tensorflow::ClientSession::~ClientSession()'\r\ncollect2: error: ld returned 1 exit status\r\nmake[1]: *** [Makefile:6: basic] Error 1\r\nmake[1]: Leaving directory '/home/gizdov/Git/arch-package-tests/tensorflow/basic'\r\nmake: *** [Makefile:11: tensorflow/basic] Error 2\r\n```\r\n\r\n**Describe the expected behavior**\r\nCorrect symbols should be exposed in `libtensorflow_cc.so` so that linking can work properly.\r\n\r\n**Code to reproduce the issue**\r\nsource included above, `Makefile` provided below\r\n```Makefile\r\nCXX=g++\r\nBINS=basic\r\nINCL_DIR=$(shell pkg-config tensorflow_cc --cflags)\r\nLIBS=$(shell pkg-config tensorflow_cc --libs)\r\n$(BINS): $(BINS).cpp\r\n\t$(CXX) $< $(INCL_DIR) $(LIBS) -o $@\r\n.PHONY: clean run\r\nrun: $(BINS)\r\n\t./$<\r\nclean:\r\n\trm -rf $(BINS)\r\n```\r\n\r\n**Other info / logs**\r\nProvided are `nm` dumps with all available symbols that are exposed in `libtensorflow.so`, `libtensorflow_cc` and `libtensorflow_framework`:\r\n[libtensorflow.so.2.1.0rc0-nm-symbol-dump.log](https://github.com/tensorflow/tensorflow/files/3942585/libtensorflow.so.2.1.0rc0-nm-symbol-dump.log)\r\n[libtensorflow_cc.so.2.1.0rc0-nm-symbol-dump.log](https://github.com/tensorflow/tensorflow/files/3942586/libtensorflow_cc.so.2.1.0rc0-nm-symbol-dump.log)\r\n[libtensorflow_framework.so.2.1.0rc0-nm-symbol-dump.log](https://github.com/tensorflow/tensorflow/files/3942587/libtensorflow_framework.so.2.1.0rc0-nm-symbol-dump.log)\r\n\r\n", "comments": ["@kgizdov Can you please try with 2.1.0-rc1, we believe this [commit](https://github.com/tensorflow/tensorflow/commit/971a1881934f6878edaa5af753f29a0b300f04bb) to have fixed this issue.", "indeed, that seems to have fixed it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34980\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34980\">No</a>\n"]}, {"number": 34979, "title": "[r2.1 Cherrypick] Remove name-based Variable handling in keras Lambda layers, and add detailed exceptions and warnings for unsafe corner cases.", "body": "https://github.com/tensorflow/tensorflow/commit/9422eb1139b3163cf65950c6e713f39344ec33e4", "comments": ["am holding on this PR for now @robieta "]}, {"number": 34978, "title": "Disable tests tagged 'v1only' on v2 builds", "body": "If one runs regression tests for the TensorFlow V2 APIs via:\r\n```\r\nbazel test --config=v2 //tensorflow/...\r\n```\r\nthe build will run several tests that are only supposed to work with the V1 APIs. These tests are tagged `v1only`, but the default build configuration does not disable them when the `v2` build config is activated.\r\n\r\nThis pull modifies the Bazel configuration so that test targets that have the tag `v1only` are not run by default when the `v2` build configuration is active.", "comments": ["I would defer to @gunan for this."]}, {"number": 34977, "title": "Cannot build submodel with layer of nested model as output ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: Nvidia GTX 1060 6GB\r\n\r\n**Describe the current behavior**\r\n(see also the StackOverflow on this: https://stackoverflow.com/questions/59191855/how-to-build-a-submodel-in-keras-functional-api-ending-at-a-layer-of-a-nested-m)\r\n\r\nUsually when using the functional API to define a model one can build a submodel starting and ending at any of the original models layers. However, when models become many and large, it can become very convenient to encapsulate some parts of the models into different python functions. These then build another model (potentially multi input/output, hence not Sequentials), which can be used in the functional API just like a layer. The graph will differ due to the additional Input layer, but the computations should be the same. However, when trying to build a submodel from such a nested model that has an output which originally was a layer of the nested model, a  \"Graph disconnected\" error is thrown.\r\n\r\n**Describe the expected behavior**\r\nThe Graph very clearly is connected, given that the nested model in its entirety is an executable, connected graph. It should therefore be possible to build submodels, no matter how deeply nested the model is, as it should always be possible to select subgraphs.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n\r\n# NOT NESTED\r\ninp = tf.keras.Input((4,))\r\ny = tf.keras.layers.Dense(4, name=\"od_1\")(inp)\r\ny = tf.keras.layers.Dense(2, name=\"od_2\")(y)\r\ny = tf.keras.layers.Dense(4, name=\"id_1\")(y)\r\ny = tf.keras.layers.Dense(10, name=\"od_3\")(y)\r\ny = tf.keras.layers.Dense(10, name=\"od_4\")(y)\r\nfinal_model = tf.keras.Model(inputs=[inp], outputs=[y])\r\nfinal_model.summary()\r\n\r\nsub_model = tf.keras.Model(inputs=[final_model.input], outputs=[final_model.get_layer(\"id_1\").output])\r\nsub_model.summary()\r\n\r\n# NESTED\r\ninp_1 = tf.keras.Input(shape=(2,))\r\nx = tf.keras.layers.Dense(4, name=\"id_1\")(inp_1)\r\ninner_model = tf.keras.Model(inputs=[inp_1], outputs=[x], name=\"inner_model\")\r\n\r\ninp_outer = tf.keras.Input((4,))\r\ny = tf.keras.layers.Dense(4, name=\"od_1\")(inp_outer)\r\ny = tf.keras.layers.Dense(2, name=\"od_2\")(y)\r\ny = inner_model(y)\r\ny = tf.keras.layers.Dense(10, name=\"od_3\")(y)\r\ny = tf.keras.layers.Dense(10, name=\"od_4\")(y)\r\nfinal_model = tf.keras.Model(inputs=[inp_outer], outputs=[y])\r\nfinal_model.summary()\r\n\r\nsub_model = tf.keras.Model(inputs=[final_model.input], outputs=[final_model.get_layer(\"inner_model\").get_layer(\"id_1\").output])\r\nsub_model.summary()\r\n\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n    Traceback (most recent call last):\r\n      File \"/home/***/test_submodel_acces.py\", line 35, in <module>\r\n        sub_model = tf.keras.Model(inputs=[final_model.input], outputs=[final_model.get_layer(\"inner_model\").get_layer(\"id_1\").output])\r\n      File \"/home/***/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 146, in __init__\r\n        super(Model, self).__init__(*args, **kwargs)\r\n      File \"/home/***/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 167, in __init__\r\n        self._init_graph_network(*args, **kwargs)\r\n      File \"/home/***/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n      File \"/home/***/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 320, in _init_graph_network\r\n        self.inputs, self.outputs)\r\n      File \"/home/***/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1625, in _map_graph_network\r\n        str(layers_with_complete_input))\r\n    ValueError: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(None, 2), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []\r\n```", "comments": ["I have tried on colab with TF version 2.0,2.1.0-rc0 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/75f1faa518035cd06dbdcefbfeb435b1/untitled462.ipynb). Thanks!", "Is there an ETA for a fix? This is quite essential to a project I am currently working on and I would like to know if I can expect this to be solved soon (and maybe be part of 2.1 stable) or if I need to find a workaround.", "I'm facing same issue too.", "Thanks for reporting the issue. \r\n\r\nThe issue is caused by the usage of \"inner_model.get_layer(\"id_1\").output\". In the code example above, the dense layer within the inner model is used twice, first time by the inp_1, and second time with inp_outer. In that sense, there are two pairs of input/output for that layer, and layer.output returns the output for the first pair (there is an ambiguity of the API here). When you build the model with the outer input with the output from previous input, it raised error since it was expecting the input from inp_1.\r\n\r\nTo avoid the ambiguity here, keras has the API to explicitly fetch the output tensor, by layer.get_output_at(). If you change your code to follow, then it will run fine.\r\n\r\n```\r\nsub_model = tf.keras.Model(\r\n    inputs=[final_model.input], \r\n    outputs=[final_model.get_layer(\"inner_model\").get_layer(\"id_1\").get_output_at(1)])\r\nsub_model.summary()\r\n```\r\n\r\nNote that you are expect to use the second output which is at index 1. Index 0 will give u the output for the input of inp_1.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34977\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34977\">No</a>\n", "I have a very similar issue. I've tried changing the code to be get_output_at(1) instead of output, but it results in the following error message.\r\n```\r\nValueError: Asked to get output at node 1, but the layer has only 1 inbound nodes.\r\n```\r\n\r\nHere is my code:\r\n\r\n```\r\nbase_model = sm.Unet('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid')\r\n\r\ninp = Input(shape=(448, 224, 1))\r\nl1 = Conv2D(3, (1,1))(inp)\r\nout = base_model(l1)\r\nmodel = Model(inp, out, name = base_model.name)\r\nmodel.summary()\r\n\r\nintermediate_layer_model = Model(inputs=[model.input], outputs = [model.get_layer('model_1').get_layer('center_block2_relu').get_output_at(1)])\t     \r\n```\r\n\r\nAny help would be appreciated. Thanks!\r\n\r\n\r\n", "> I have a very similar issue. I've tried changing the code to be get_output_at(1) instead of output, but it results in the following error message.\r\n> \r\n> ```\r\n> ValueError: Asked to get output at node 1, but the layer has only 1 inbound nodes.\r\n> ```\r\n> \r\n> Here is my code:\r\n> \r\n> ```\r\n> base_model = sm.Unet('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid')\r\n> \r\n> inp = Input(shape=(448, 224, 1))\r\n> l1 = Conv2D(3, (1,1))(inp)\r\n> out = base_model(l1)\r\n> model = Model(inp, out, name = base_model.name)\r\n> model.summary()\r\n> \r\n> intermediate_layer_model = Model(inputs=[model.input], outputs = [model.get_layer('model_1').get_layer('center_block2_relu').get_output_at(1)])\t     \r\n> ```\r\n> \r\n> Any help would be appreciated. Thanks!\r\n```\r\n```\r\nbecause only one tensor output :\r\nintermediate_layer_model = Model(inputs=[model.input]\r\noutputs = [model.get_layer('model_1').get_layer('center_block2_relu').get_output_at(0)])\t  \r\n```   ", "@qlzh727 Thanks for the above response. My doubt is what if I have several layers in a submodel and want to make models for several layers in the submodel. I have raised a question here\r\n\r\nhttps://stackoverflow.com/questions/64118557/how-to-create-a-keras-model-using-the-intermediate-layers-of-its-submodel\r\n\r\nThank you.", "> Thanks for reporting the issue.\r\n> \r\n> The issue is caused by the usage of \"inner_model.get_layer(\"id_1\").output\". In the code example above, the dense layer within the inner model is used twice, first time by the inp_1, and second time with inp_outer. In that sense, there are two pairs of input/output for that layer, and layer.output returns the output for the first pair (there is an ambiguity of the API here). When you build the model with the outer input with the output from previous input, it raised error since it was expecting the input from inp_1.\r\n> \r\n> To avoid the ambiguity here, keras has the API to explicitly fetch the output tensor, by layer.get_output_at(). If you change your code to follow, then it will run fine.\r\n> \r\n> ```\r\n> sub_model = tf.keras.Model(\r\n>     inputs=[final_model.input], \r\n>     outputs=[final_model.get_layer(\"inner_model\").get_layer(\"id_1\").get_output_at(1)])\r\n> sub_model.summary()\r\n> ```\r\n> \r\n> Note that you are expect to use the second output which is at index 1. Index 0 will give u the output for the input of inp_1.\r\n\r\nIf I'm not mistaken, this fix does not work (anymore). At least not in TF 2.4.1.\r\nI have also created a separate code snippet in which basically the same issue is present, and was not able to solve it by using `.get_output_at`, as the layer has only a single output/inbound node.\r\nShouldn't the code snippet below be able to work?\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# Define an inner model of an input and a single dense layer\r\ninner_input = tf.keras.layers.Input(10)\r\nx = inner_input\r\nx = tf.keras.layers.Dense(10, name=\"inner_layer\")(x)\r\ninner_output = x\r\n\r\ninner_model = tf.keras.Model(inner_input, inner_output, name='inner_model')\r\ninner_model.summary()\r\n\r\n# Define an outer model in which we prepend a single Dense layer before the inner model.\r\n# The inner model is thus a layer or sub-model within the outer model\r\nouter_input = tf.keras.layers.Input(10)\r\nx = outer_input\r\nx = tf.keras.layers.Dense(10, name=\"outer_layer\")(x)\r\nouter_output = inner_model(x)\r\n\r\nouter_model = tf.keras.Model(outer_input, outer_output, name='outer_model')\r\nouter_model.summary()\r\n\r\n# Append an extra Dense layer after `inner_layer`, and create a new model with inputs\r\n# the `inner_input` and outputs the output of the newly appended Dense layer.\r\n# This works.\r\nx = inner_model.get_layer('inner_layer').output\r\nx = tf.keras.layers.Dense(10)(x)\r\nextended_inner_model_output = x\r\nextended_inner_model = tf.keras.Model(inner_input, extended_inner_model_output)\r\nextended_inner_model.summary()\r\n\r\n# Append an extra Dense layer after `inner_layer`, and create a new model with inputs\r\n# the `outer_input`(!) and outputs the output of the newly appended Dense layer.\r\n# This does not work.\r\nx = outer_model.get_layer('inner_model').get_layer('inner_layer').output\r\nx = tf.keras.layers.Dense(10)(x)\r\nextended_inner_model_output = x\r\nextended_inner_model = tf.keras.Model(outer_input, extended_inner_model_output)\r\nextended_inner_model.summary()\r\n```"]}, {"number": 34976, "title": "C:\\Users\\david\\Anaconda3\\envs\\amajiration\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or  '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.   _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])", "body": "C:\\Users\\david\\Anaconda3\\envs\\amajiration\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or \r\n'1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n\r\nI got this when I ran the test code I don't know what it means", "comments": ["did you just skip all of the wonderful templating to file this issue?", "Wonderful templating? I don't follow", "See https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md\r\n\r\nWhenever a new issue is created, you get that text already included in the large text area and you are supposed to fill in all those details as well as post a descriptive title, not just a copy paste of the error.", "when you file an issue you have to select an issue type and then fill out a template for that issue. Here you just seemed to have dumped a stack trace ", "oh, I'm sorry. I'm new to github and haven't fully understood it. ", "@amajiration ,\r\nAs per instruction from @mihaimaruseac and @jhallard\r\nPlease provide us a brief description of the issue being faced with reproducible code and tensorflow version used so that we can help you resolving it, Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing as there hasn't been any new activity."]}, {"number": 34975, "title": "[TF 2.0 API Docs] `tf.keras.callbacks.LearningRateScheduler` (Very small update)", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nDoc Link:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\r\nCode Link:\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/callbacks.py#L1311-L1358\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Parameters\r\n\r\nThe next API for `scheduler` parameter of `LearningRateScheduler` takes in 2 parameters, `epoch` and `lr` (learning rate) instead of just `epoch`, this is evident in the `on_epoch_begin` of the `LearningRateScheduler` method.\r\n\r\nThe documentation for this method is still outdated, the docs and the example code still shows the `scheduler` function takes in only `epoch` instead of both `epoch` and `lr`. I think the doc should be updated to reflect the new API.\r\n\r\nProposed change to the doc:\r\n\r\n1) update the description of `scheduler`: \r\n\r\n`\r\nschedule: a function that takes an epoch index as input (integer, indexed from 0) and current learning rate and returns a new learning rate as output (float).\r\n`\r\n(copied from the doc from keras.io)\r\n\r\n2) update the example usage to include a `scheduler` that utilize the current learning rate as well.\r\n\r\nI hope this is helpful! Happy to contribute if needed.\r\n\r\n### Submit a pull request? Yes, if this should be updated.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["fixed :)"]}, {"number": 34974, "title": "[r2.1 Cherrypick]: Support DistributionStrategy in LossScaleGradientTape, take 2.", "body": "Without this cherrypick, LossScaleGradientTape crashes with a cryptic error when DistributionStrategy is used.\r\n\r\nPiperOrigin-RevId: 284116353\r\nChange-Id: Ia5ef17ae8ddf36af3244c157ebc0ecbd807eccb0", "comments": []}, {"number": 34973, "title": "Ensure sorted=true in top_k converter", "body": "This PR adds a check for a `TopK` argument that is not supported by TensorRT.", "comments": []}, {"number": 34972, "title": "Docs: Update Readme.md to reflect pip package changes with TF 2.1", "body": "As requested in https://github.com/tensorflow/tensorflow/pull/34967#issuecomment-563348994.\r\n\r\nDescribes that the main TF package now contains CUDA GPU support, and that a smaller CPU-only package can be used.\r\n\r\nBased on the changes announced in https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0-rc0", "comments": ["Can it be merged?", "There is an automatic merge process that seems to be stalled for now."]}, {"number": 34971, "title": "Throw an explicit error if calling TPUStrategy in eager mode", "body": "", "comments": []}, {"number": 34970, "title": "[r2.1 Cherrypick] Correct number of output shapes written by SavedModel and Update keras standardization code to error out when a namedtuple is encountered.", "body": null, "comments": []}, {"number": 34969, "title": "Fix the estimator version.", "body": "Should fix #34963", "comments": []}, {"number": 34968, "title": "Classification signature on tf serving.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `no`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 18.04`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `no`\r\n- TensorFlow installed from (source or binary): `no`\r\n- TensorFlow version (use command below): `2.0.0`\r\n- Python version: `3.7.3`\r\n- Bazel version (if compiling from source): `-`\r\n- GCC/Compiler version (if compiling from source): `-`\r\n- CUDA/cuDNN version: `-`\r\n- GPU model and memory: `-`\r\n\r\n**Describe the current behavior**\r\n\r\nIt seem currently *not* possible to export a `classify` signature to use within `Tensorflow Serving`.\r\n\r\n**Describe the expected behavior**\r\nIt should be possible to export a `classify` signature to use within `Tensorflow Serving`.\r\nI was able to experience the issue also by exporting directly a `tf.Module` and a subclassed `tf.Model`. In [this](https://github.com/tensorflow/serving/issues/1420#issuecomment-552475340) comment I was also wondering about both the `inference` and `classify` signatures being *deprecated* since it looks like in [_generate_signatures](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/save.py#L466) the `method_name` is assigned to `signature_constants.PREDICT_METHOD_NAME`.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(2, activation=\"softmax\"),\r\n])\r\nmodel.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\nX = [0.42]\r\nY = [[0, 1]]\r\nmodel.fit(X, Y, epochs=1)\r\npred_before = model.predict(X)\r\nprint(f\"*** pred : {pred_before} ***\")\r\nmodel.save(\"./mymodel/1\", save_format=\"tf\")\r\nmodel = tf.keras.models.load_model(\"./mymodel/1\")\r\nmodel.predict([X])\r\nprint(f\"*** signatures : {model.signatures} ***\")\r\npred_after = model([X])\r\nnp.testing.assert_almost_equal(pred_before, pred_after)\r\nprint(model.predict([X]))\r\n```\r\n\r\n```bash\r\ndocker run -p 8501:8501 -v /path/to/mymodel:/models/mymodel -e MODEL_NAME=mymodel --name serving_tmp tensorflow/serving\r\n```\r\n\r\n```\r\ncurl -XPOST http://localhost:8501/v1/models/mymodel:classify -d '{\"examples\": [{}]}'\r\n# { \"error\": \"Expected classification signature method_name to be tensorflow/serving/classify. Was: tensorflow/serving/predict\" }\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n{ \"error\": \"Expected classification signature method_name to be tensorflow/serving/classify. Was: tensorflow/serving/predict\" }\r\n```\r\n\r\nIf I modify `tensorflow_core/python/saved_model/save.py@469`\r\n```python\r\n# from\r\nmethod_name=signature_constants.PREDICT_METHOD_NAME)\r\n\r\n# to\r\nmethod_name=signature_constants.CLASSIFY_METHOD_NAME)\r\n``` \r\n\r\nI'm then able to get what expected:\r\n```\r\ncurl -XPOST http://localhost:8501/v1/models/mymodel:classify -d '{\"examples\": [{}]}'\r\n{ \"error\": \"No classification inputs found in SignatureDef: inputs {\\n  key: \\\"text\\\"\\n  value {\\n    name: \\\"serving_default_text:0\\\"\\n    dtype: DT_FLOAT\\n    tensor_shape {\\n      dim {\\n        size: -1\\n      }\\n      dim {\\n        size: -1\\n      }\\n    }\\n  }\\n}\\noutputs {\\n  key: \\\"probabilities\\\"\\n  value {\\n    name: \\\"StatefulPartitionedCall_2:0\\\"\\n    dtype: DT_FLOAT\\n    tensor_shape {\\n      dim {\\n        size: -1\\n      }\\n      dim {\\n        size: 99\\n      }\\n    }\\n  }\\n}\\nmethod_name: \\\"tensorflow/serving/classify\\\"\\n\" }\r\n```", "comments": ["@stefanondisponibile,\r\n\r\nThis issue seems to be related to Tensorflow serving, could you please raise an issue in [this repository](https://github.com/tensorflow/serving/issues/new). Thanks!", "Thank you @amahendrakar, I'll open one there. I was reporting on this repo since I thought the problem was in the `tf.saved_model.save` function.", "Closing this issue as it is related to TF Serving.", "@amahendrakar as @gowthamkpr said on the Tensorflow Serving repo the issue seems related to TensorFlow (not Serving). The problem is that even if it is possible to export a custom signature via `@tf.function` it is **not** possible to define the exported signature's **`method_name`** (as everything's handled by TensorFlow under the hood).", "> @stefanondisponibile,\r\n> \r\n> This issue seems to be related to Tensorflow serving, could you please raise an issue in [this repository](https://github.com/tensorflow/serving/issues/new). Thanks!\r\n\r\nThere is already an issue reported #1521 - But it is closed refering that  the issue is to be reported on tensorflow core ", "@santhoshscs the issue is reported here \ud83d\ude42", "Is there any update on this topic ? Or any possibility (hack) to update the method_name afterwards?", "This is definitely a bug because from the documentation of `tf.saved_model.save` one has:\r\n\r\n> The keys of such a dictionary may be arbitrary strings, but will typically be from the `tf.saved_model.signature_constants` module.\r\n\r\nbut:\r\n\r\n1. tf2.1 does not have such module available but rather I was able to find `tf.saved_model.CLASSIFY_METHOD_NAME`\r\n1. setting the name of the signature as indicated in the documentation does not solve the problem (clear reason why when reading the source code though), as show in the example below:\r\n\r\n```\r\n> saved_model_cli show --dir my_model/1 --tag_set serve --signature_def tensorflow/serving/classify\r\n\r\nThe given SavedModel SignatureDef contains the following input(s):\r\n  inputs['crop_window'] tensor_info:\r\n      dtype: DT_INT32\r\n      shape: (-1, 4)\r\n      name: tensorflow/serving/classify_crop_window:0\r\n  inputs['image_bytes'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1)\r\n      name: tensorflow/serving/classify_image_bytes:0\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs['output_0'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, -1)\r\n      name: StatefulPartitionedCall_5:0\r\nMethod name is: tensorflow/serving/predict\r\n```", "@ClementWalter I am trying to understand the difference between the default method, Predict versus Classify. For your particular use case what is it that not possible to do with Predict so you need Classify. Thank you so much in advance. ", "@stefanondisponibile  This function ([tf.compat.v1.saved_model.signature_def_utils.MethodNameUpdater](https://www.tensorflow.org/api_docs/python/tf/compat/v1/saved_model/signature_def_utils/MethodNameUpdater)) was specially added so that there's a way to change predict signatures to classify/regress.\r\n\r\nMarking this issue as closed, please reopen if this does not work for you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34968\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34968\">No</a>\n", "Awesome! \ud83e\udd73", "@goldiegadde I'm super glad to hear that the `MethodNameUpdater()` function is available, cause it does exactly what I need. Unfortunately, I'm not able to use it (getting an `AttributeError`). Here's my setup: \r\n\r\nOS Platform: macOS Catalina, Version 10.15.5\r\nTensorflow Version: 2.3.0\r\nPython Version: 3.7.9\r\n\r\nWould be very happy about any help with this! ", "@florence27 can you please report a new issue along with the complete  code to reproduce the error that is not working and cc me on it as well. \r\nThanks, \r\nGoldie"]}, {"number": 34967, "title": "Docs: Update Readme.md to reflect pip package changes with TF 2.1", "body": "Describes that the main TF package now contains CUDA GPU support, and that a smaller CPU-only package can be used.\r\n\r\nBased on the changes announced in https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0-rc0", "comments": ["Can you make this against master please? And then cherry-pick it here?", "@mihaimaruseac see #34972"]}, {"number": 34966, "title": "Document about masking does not have previous masks information", "body": "Greetings,\r\n\r\nWhile the document about [masking](https://www.tensorflow.org/guide/keras/masking_and_padding) is super good, I found it misses an important point: how the mask associated with the previous mask in compute_mask(input, previous_mask)\r\n\r\nSpecifically, let us assume we have two inputs A and B. I wrote a custom Add layers:\r\n\r\n```\r\nclass CustomAddingWithMasking(tf.keras.layers.Layer):\r\n    def __init__(self, masking_boolean, **kwargs):\r\n        super(CustomAddingWithMasking, self).__init__(**kwargs)\r\n\r\n    def call(self, inputs):\r\n        return inputs[0] + inputs[1]\r\n    \r\n    def compute_mask(self, inputs, mask=None):\r\n        return mask\r\n```\r\n\r\nHere, I want to compute the sum of two tensors. Let us also assume that A and B have their own masks, which could be different to each other. Because we technically have two \"previous masks\" (from A and B separately), I don't know how the mask parameter in compute_mask was received. Is it the OR (or AND?) operation between mask of A and mask of B?\r\n\r\nThose things are not clear as well as not documented well.", "comments": ["@hoangcuong2011 \r\nIs this still an issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "The Masking and padding [guide](https://www.tensorflow.org/guide/keras/masking_and_padding) has been updated over time.  Please comment if further information/clarification is required. Thanks!"]}, {"number": 34965, "title": "Keras Callback log entry wrong documented", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\r\n\r\n\r\n> on_epoch_end: logs include `acc` and `loss`, and\r\n>    optionally include `val_loss`\r\n>    (if validation is enabled in `fit`), and `val_acc`\r\n>    (if validation and accuracy monitoring are enabled).\r\n\r\nand\r\n\r\n> on_batch_end: logs include `loss`, and optionally `acc`\r\n\r\nThis is correct for the original Keras implementation. However, in tf2.keras callbacks get `accuracy` and `val_accuracy` instead of the short documented versions `acc`/`val_acc`. Either the implementation is wrong or the documentation.\r\n", "comments": ["@marcj Are you willing to raise a PR to correct the docs? Thanks!", "@jvishnuvardhan does this mean this is a doc issue only and thus a breaking change compared to official/current Keras implementation?", "@jvishnuvardhan @lamberta  i would like to contribute .\r\n\r\n> @marcj Are you willing to raise a PR to correct the docs? Thanks!\r\n\r\n", "The docs are now updated by the above commit. Thanks!"]}, {"number": 34963, "title": "R2.1 pip install failed to find a correct tensorflow-estimator", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source code build and then pip install\r\n- TensorFlow version: R2.1 (b2474d99ae962ce66d6db896606488797152dc4d)\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.29.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CPU(MKL)\r\n\r\n\r\n**ERROR: No matching distribution found for tensorflow-estimator<2.2.0,>=2.1.0 (from tensorflow==2.1.0rc1)**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\n```\r\nTarget //tensorflow/tools/pip_package:build_pip_package up-to-date:\r\n  bazel-bin/tensorflow/tools/pip_package/build_pip_package\r\n\u001b[0m\u001b[91mINFO: Elapsed time: 1088.439s, Critical Path: 237.61s\r\nINFO: 19007 processes: 19007 local.\r\n\u001b[0m\u001b[91mINFO: Build completed successfully, 19988 total actions\r\n\u001b[0m\u001b[91mINFO: Build completed successfully, 19988 total actions\r\n\u001b[0mMon Dec 9 09:18:14 UTC 2019 : === Preparing sources in dir: /tmp/tmp.fqqQwu5J91\r\n/tensorflow /tensorflow\r\n/tensorflow\r\n/tmp/tmp.fqqQwu5J91/tensorflow/include /tensorflow\r\n/tensorflow\r\nMon Dec 9 09:18:21 UTC 2019 : === Building wheel\r\n\u001b[91mwarning: no files found matching 'README'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.pyd' under directory '*'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.pd' under directory '*'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.dylib' under directory '*'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.dll' under directory '*'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.lib' under directory '*'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*.csv' under directory '*'\r\nwarning: no files found matching '*.h' under directory 'tensorflow_core/include/tensorflow'\r\n\u001b[0m\u001b[91mwarning: no files found matching '*' under directory 'tensorflow_core/include/third_party'\r\n\u001b[0mMon Dec 9 09:18:57 UTC 2019 : === Output wheel file is in: /tmp/pip\r\n\u001b[91mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\r\n\u001b[0mProcessing /tmp/pip/tensorflow-2.1.0rc1-cp27-cp27mu-linux_x86_64.whl\r\nCollecting gast==0.2.2\r\n  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\r\nCollecting grpcio>=1.8.6\r\n  Downloading https://files.pythonhosted.org/packages/0c/47/35cc9f6fd43f8e5ed74fcc6dd8a0cb2e89c118dd3ef7a8ff25e65bf0909f/grpcio-1.25.0-cp27-cp27mu-manylinux2010_x86_64.whl (2.4MB)\r\nRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.1.0rc1) (1.16.5)\r\nCollecting protobuf>=3.8.0\r\n  Downloading https://files.pythonhosted.org/packages/a3/27/9a375cc85b90c93ab847370c31fe1302a763b6cd57d54daee20171d720ff/protobuf-3.11.1-cp27-cp27mu-manylinux1_x86_64.whl (1.3MB)\r\nRequirement already satisfied, skipping upgrade: wheel; python_version < \"3\" in /usr/lib/python2.7/dist-packages (from tensorflow==2.1.0rc1) (0.30.0)\r\nCollecting wrapt>=1.11.1\r\n  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\r\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.1.0rc1) (1.1.0)\r\nCollecting backports.weakref>=1.0rc1; python_version < \"3.4\"\r\n  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\r\nCollecting six>=1.12.0\r\n  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\r\nRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.1.0rc1) (1.0.8)\r\nCollecting functools32>=3.2.3; python_version < \"3\"\r\n  Downloading https://files.pythonhosted.org/packages/c5/60/6ac26ad05857c601308d8fb9e87fa36d0ebf889423f47c3502ef034365db/functools32-3.2.3-2.tar.gz\r\nCollecting termcolor>=1.1.0\r\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\r\nCollecting absl-py>=0.7.0\r\n  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\r\nCollecting opt-einsum>=2.3.2\r\n  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\r\nCollecting tensorboard<2.2.0,>=2.1.0\r\n  Downloading https://files.pythonhosted.org/packages/e4/c5/94a66686b86adfb3ef6f34837d0a7cc2efdc995bc39cad64a9b3e103f0d5/tensorboard-2.1.0-py2-none-any.whl (3.8MB)\r\n\u001b[91mERROR: Could not find a version that satisfies the requirement tensorflow-estimator<2.2.0,>=2.1.0 (from tensorflow==2.1.0rc1) (from versions: 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12, 1.13.0rc0, 1.13.0, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0, 1.15.1, 2.0.0, 2.0.1, 2.1.0rc0)\r\n\u001b[0m\u001b[91mERROR: No matching distribution found for tensorflow-estimator<2.2.0,>=2.1.0 (from tensorflow==2.1.0rc1)\r\n```\r\n", "comments": ["It is still work-in-progress so please be patient. \r\n\r\nGently ping @mihaimaruseac.", "It should get fixed today, sorry about this. I'll ping back here when it gets fixed.", "Should be fixed now", "fixed. Thanks @mihaimaruseac and @byronyi "]}, {"number": 34962, "title": "TypeError: unhashable type: 'ListWrapper' after adding losses to tf.keras model", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14, 1.15, 2.0, 2.1rc0\r\n- Keras version: 2.2.4-tf\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.0 and 10.1 / 7.6.5\r\n- GPU model and memory: RTX 2060 6GB\r\n\r\n**Describe the current behavior**\r\nIn project based on Mask_RCNN I got `TypeError: unhashable type: 'ListWrapper'` during training in add_loss(loss) method:\r\n```\r\n\r\nFile \"C:\\Project\\project.py\", line 41, in build_Model\r\n\tmaskRcnn = MaskRCNN(mode, config, model_dir)\r\nFile \"C:\\Project\\project.py\", line 58, in __init__\r\n\tmaskRcnn.compile()\r\nFile \"C:\\Project\\MaskRCNN\\model.py\", line 2175, in compile\r\n\tself.keras_model.add_loss(loss)\r\nFile \"C:\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 1132, in add_loss\r\n\tself._graph_network_add_loss(symbolic_loss)\r\nFile \"C:\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1433, in _graph_network_add_loss\r\n\tself._insert_layers(new_layers, new_nodes)\r\nFile \"C:\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1392, in _insert_layers\r\n\tlayer_set = set(self._layers)\r\nFile \"C:\\python36\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py\", line 547, in __hash__\r\n\traise TypeError(\"unhashable type: 'ListWrapper'\")\r\nTypeError: unhashable type: 'ListWrapper'\r\n```\r\n\r\nIt's what happens when I use  tf.keras instead of keras.\r\n", "comments": ["Related topics:\r\nhttps://github.com/matterport/Mask_RCNN/issues/1889\r\nhttps://github.com/tensorflow/tensorflow/issues/33471\r\nhttps://github.com/tensorflow/tensorflow/issues/32127", "@kiflowb777 ,\r\nCan you share a standalone code to reproduce the error reported here?Thanks!", "It's a bug from Mask_RCNN:\r\nhttps://github.com/matterport/Mask_RCNN/issues/1889\r\n\r\nThe source of the error is:\r\nhttps://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py#L2175", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It's not really a TF bug. Fixed against the following code of Mask_RCNN:\r\n https://github.com/matterport/Mask_RCNN/tree/295c802f0bebbc4a34ec4855f4960a52a701271d/mrcnn", "@kiflowb777 ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Hi, I got the same error, i tried some solution to resolve them:\r\njust comment out line 2163 & 2164\r\ni.e.,\r\nself.keras_model._losses = []\r\nself.keras_model._per_input_losses = {}"]}, {"number": 34961, "title": "EfficientDet: Are you going to implement this in the object detection API?", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI read about this new Network topology: [https://arxiv.org/pdf/1911.09070.pdf](https://arxiv.org/pdf/1911.09070.pdf ) \r\n\r\nIt seems to work precisely and fast. Are you going to implement this new topology to your framework?\r\n\r\n**Will this change the current api? How?**\r\nPossible\r\n\r\n**Who will benefit with this feature?**\r\nEveryone who works with object detectors!\r\n\r\n**Any Other info.**\r\nIf the answer is yes: will there be a quantized version for TPU inference?\r\n\r\nThanks in advance,\r\nTimo", "comments": ["Linking a [community-built implementation of EfficientDet in TF 2.x](https://github.com/Guillem96/efficientdet-tf) in the interim. Thanks, @Guillem96!", "@dynamicwebpaige I am still working with it. My intention is to override `train_step` method of my EfficientDet class, [just as tf 2.2.0 style](https://twitter.com/fchollet/status/1250622989541838848?s=19) , and get the `.fit` method extra features (TPUDistribute strategy, logging, callbacks,...) for free.\n\nThanks for linking my implementation here \ud83d\ude03", "@TimoK93 \r\nIt's now available in the TensorFlow 2 Detection Model Zoo\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md", "@TimoK93,\r\nSorry for the delayed response. **`EfficientDet`** is present in the [Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) as well as in [Tensorflow.org](https://www.tensorflow.org/lite/tutorials/model_maker_object_detection#customize_the_efficientdet_model_hyperparameters).\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 34960, "title": "the model of Tensorflow2.0 lite has low accuracy, is there anything wrong?", "body": "Hello, I create new model with the program as follows:\r\nhttps://github.com/tensorflow/hub/blob/master/tensorflow_hub/tools/make_image_classifier/make_image_classifier.py\r\nand after the whole train process, the accuracy is more than 93%\r\nHowever, I  run the program as follows to test the model:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py\r\nwith the same dataset as validacation datasets. But the accuracy is very low, less than 80%.\r\nIs there anything wrong? Thanks very much for your help.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (or github SHA if from source):\r\n2.0.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\nmake_image_classifier --image_dir /home/ioz/bird/images/ --tfhub_module /home/tensorflow-2.0/resnet101v4/ --image_size 224 --saved_model_dir /home/ioz/bird/models/ --labels_output_file /home/ioz/bird/m\r\nodels/class_labels.txt --tflite_output_file /home/ioz/bird/models/resnet101_20_0.001True_model.tflite --learning_rate 0.001 --train_epochs 20 --do_fine_tuning True\r\n\r\n", "comments": ["https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier shows Top-K accuracy with the given dataset. But https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py shows softmax output with the given single image which is not the Top-K accuracy.", "Closing this issue since it's resolved. Feel free to reopen if have further questions. Thanks!"]}, {"number": 34959, "title": "Add release note about CUDA 10.1 and cuDNN 7.6", "body": "", "comments": ["Good note. Two comments:\r\n - CUDA 10.2 isn't integrated right? Do you know if there's an issue where CUDA 10.2 integration is tracked?\r\n - Which exact cuDNN version? 7.6.5?", "We build and test against cuDNN v7.6.4.38. But you should be able to install any 7.6 version and run the TF pip package with it.\r\n\r\nCUDA 10.2 is not yet supported, and I'm now aware of any tracking issue. We might actually want to wait for CUDA 11, which shouldn't be too far out."]}, {"number": 34958, "title": "NFC - minor spelling tweaks under compiler directory ", "body": "This PR addresses minor spelling tweaks under `tensorflow/compiler` directory. In addition, `RELEASE.MD` is also addressed.", "comments": ["Would it be possible to let me know if smaller PRs (e.g. 100 files per PR) are better for ease of review? I will split this into two PRs.", "I use a script to list up potential candidates. The script lists up a lot of false positives. Finally, I manually find and fix them.\r\nDoes my script help you even if it looks premature?\r\n\r\nAn example of outputs\r\n```\r\n...\r\nabstrat\r\nabsw\r\nabsx\r\nabt\r\nabuf\r\nabx\r\nabz\r\naca\r\nacad\r\nacat\r\nacb\r\nacbb\r\nacbd\r\nacc\r\naccbuffer\r\nacccbbdddd\r\naccd\r\nacce\r\naccel\r\n...\r\n```", "We might need to use the script internally to convert tooling that expects some of the same typos to exist.", "I use this script from https://qiita.com/debility/items/d3b24bc9a941241e82b8\r\n```\r\nfind . -type f -print |xargs file |grep text |awk -F' ' '{print $1}' |sed -e 's/://g' |xargs cat |sed \"s/[A-Z][a-z]/ \\0/g\" |tr '[A-Z]' '[a-z]' |aspell list |sort|uniq\r\n```", "I am working for other directories now."]}, {"number": 34957, "title": "How to use SparseTensor in capi?", "body": "HI :\r\n    How to use SparseTensor in capi?", "comments": ["@haolujun ,\r\nCan you please refer this [link](https://www.tensorflow.org/api_docs/cc#sparse_ops) and let us know if it helped? Thanks!", "@haolujun ,\r\nAny update on the issue?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34956, "title": "RunMetaData", "body": "Hello!\r\nI want to know how to use tf.RunMetaData() in tf.contrib.tpu.TPUEstimator(), because I want to analyze the time in ops.\r\nThank you!", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 34955, "title": "DepthwiseConv in lite/kernels/internal/reference/depthwiseconv_float.h can be optimized better", "body": "These two lines https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/reference/depthwiseconv_float.h#L62 can be moved up, because they only depend on out_x/out_y, there's no need to compute them per input depth/depth_multiplier.\r\n", "comments": ["Hi @yurivict, thank you for your question. You are correct. However, the reference operations are designed for clarity rather than optimized for performance so that others can implement optimized implementations.", "> reference operations are designed for clarity\r\n\r\nIt's less clarity this way because lines are misplaced, producing the impression that they need to be recomputed per input_channel/multiplier when in reality they are not.\r\n", "Sorry for the very very long wait. Short answer is that we want to keep the code in the innermost loop to make the code as simple to read as possible  -- compiler can handle simple optimizations like this in any case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34955\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34955\">No</a>\n"]}, {"number": 34954, "title": "Keras MobilenetV3 weights ", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nTensorflow MobilenetV3 code and checkpoints(.ckpt, .pb, .tflite) have been provided. What changes need to be incorporated to use the model, in Keras. As of now, Keras supports applications till MobilenetV2, and not MobilenetV3. If provided, it will be easier for model loading and usage as it is. \r\n\r\n**Will this change the current api? How?**\r\nNo. It will be an update to the current scenario.\r\n\r\n**Who will benefit with this feature?**\r\nUsers of Tensorflow and Keras\r\n\r\n**Any Other info.**\r\nNIL", "comments": ["Any updates on this request!! @fchollet ??", "MobileNetV3 was added to keras-applications: https://github.com/keras-team/keras-applications/pull/176", "Closing this issue since it's resolved. Thanks!\r\n\r\n> MobileNetV3 was added to keras-applications: [keras-team/keras-applications#176](https://github.com/keras-team/keras-applications/pull/176)\r\n\r\n", "Was added to keras-applications, but not to keras-applications inside TensorFlow, so do not close it, please.", "This feature is now available with TF 2.4.1\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small?hl=zh-cn and\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Large?hl=zh-cn", "Then this can be closed now", "Can we close this?"]}, {"number": 34953, "title": "A question about PSNR implementation in tensorflow 2.0", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n  \r\nI am working on some image processes using PSNR ( [tf.image.psnr](https://www.tensorflow.org/api_docs/python/tf/image/psnr)), but always I\r\ngot results larger than what I expected. Then I check the source code and I\r\nfind\r\n\r\n\r\n```\r\npsnr_val = math_ops.subtract(\r\n\r\n20 * math_ops.log(max_val) / math_ops.log(10.0),\r\n\r\nnp.float32(10 / np.log(10)) * math_ops.log(mse),\r\n\r\nname='psnr')\r\n```\r\n\r\nCompare to the standard PSNR algorithm, its formula as follows:\r\n\r\n![image](https://user-images.githubusercontent.com/14346086/70408961-03814f00-1a85-11ea-8df2-8c0f470e86f0.png)\r\n\r\n\r\nI wonder why there is np.log(10) in the tensorflow implementation rather\r\nthan np.log10(10)? Or is there anything I get wrong?\r\n\r\nThanks for any help.\r\n", "comments": ["its the same...\r\n\r\n![image](https://user-images.githubusercontent.com/26292862/72998480-e6ea6d80-3dcb-11ea-9ce9-184290c71b76.png)\r\n", "I'll close this, as the comment above shows the equation is equivalent.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34953\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34953\">No</a>\n"]}, {"number": 34952, "title": "tensorflow1.14.0 correspond protobuf version\uff1f", "body": "ImportError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringE\r\n\r\nI think the problem is caused by incompatible versions\uff1fSo i need protobuf version that conrrespond tensorflow1.14.0", "comments": ["@zxgm \r\n\r\nWhich protobuf version you are using?.Request you to check using `! pip show protobuf` . Request you to uninstall by using `!pip uninstall protobuf` and try installing  `!pip install protobuf==3.8 ` and see how it progresses. Thanks!", "Thanks a lot! I sovled the problem.", "@zxgm \r\n\r\nClosing the issue since its resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34952\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34952\">No</a>\n"]}]