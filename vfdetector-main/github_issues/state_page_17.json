[{"number": 52879, "title": "[MHLO]: add BatchNormTraining and BatchNormGrad support in hlo-legalize-to-lhlo", "body": "It basically resolved lowering of some op with a result as a tuple of tensors.\r\nThere seem only BatchNormTraining and BatchNormGrad requiring this.\r\nhttps://github.com/tensorflow/mlir-hlo/pull/18", "comments": ["Build is failing:\r\n```\r\ntensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/hlo_legalize_to_lhlo.cc:210:50: error: non-virtual member function marked 'final' hides virtual member functions\r\n      ConversionPatternRewriter& rewriter) const final {\r\n```\r\n", "```\r\nthird_party/llvm/llvm-project/mlir/include/mlir/IR/PatternMatch.h:1066:14: error: no matching member function for call to 'addDebugLabels'\r\n    pattern->addDebugLabels(debugLabels);\r\n    ~~~~~~~~~^~~~~~~~~~~~~~\r\nthird_party/llvm/llvm-project/mlir/include/mlir/IR/PatternMatch.h:1009:13: note: in instantiation of function template specialization 'mlir::RewritePatternSet::addImpl<mlir::mhlo::(anonymous namespace)::HloTupleOutputToLhloOpConverter<mlir::mhlo::BatchNormGradOp>, mlir::BufferizeTypeConverter &, mlir::MLIRContext *&>' requested here\r\n        0, (addImpl<Ts>(/*debugLabels=*/llvm::None, arg, args...), 0)...};\r\n            ^\r\n```", "```\r\nthird_party/llvm/llvm-project/mlir/include/mlir/IR/PatternMatch.h:280:9: error: cannot initialize object parameter of type 'const mlir::Pattern' with an expression of type 'mlir::mhlo::(anonymous namespace)::HloTupleOutputToLhloOpConverter<mlir::mhlo::BatchNormGradOp>'\r\n    if (pattern->getDebugName().empty())\r\n        ^~~~~~~~~\r\n```", "> Build is failing:\r\n> \r\n> ```\r\n> tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/hlo_legalize_to_lhlo.cc:210:50: error: non-virtual member function marked 'final' hides virtual member functions\r\n>       ConversionPatternRewriter& rewriter) const final {\r\n> ```\r\n\r\nI encountered this before when I accidentally used the master llvm.\r\nIt seemed that tensorflow might recently update the submoduled llvm version. \r\nLet me rebase it, and try to fix it. \r\n", "> > Build is failing:\r\n> > ```\r\n> > tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/hlo_legalize_to_lhlo.cc:210:50: error: non-virtual member function marked 'final' hides virtual member functions\r\n> >       ConversionPatternRewriter& rewriter) const final {\r\n> > ```\r\n> \r\n> I encountered this before when I accidentally used the master llvm. It seemed that tensorflow might recently update the submoduled llvm version. Let me rebase it, and try to fix it.\r\n\r\nChanged to the virtual function using adaptor. ", "Sorry this fell of my queue...", "@lchang20  Can you please resolve conflicts? Thanks!", "@lchang20 Any update on this PR? Please. Thanks!", "> @lchang20 Any update on this PR? Please. Thanks!\r\n\r\nMy bad, I thought it got merged. It should be fixed.\r\nAfter tuple results becoming variadic, the fix became very simple. \r\nI just rollback and did minimal change on top of master.  \r\n", "@lchang20 Can you please resolve conflicts? Thanks!", "> @lchang20 Can you please resolve conflicts? Thanks!\r\n\r\nDone."]}, {"number": 52853, "title": "Upgrade grpc to 1.41.1 and protobuf to 3.19.0", "body": "This is a retry of https://github.com/tensorflow/tensorflow/pull/51923", "comments": ["I can reproduce the [Windows failure](https://github.com/tensorflow/tensorflow/pull/51923#issuecomment-919490693) mentioned in #51923 locally, but couldn't figure out the exact reason. But managed to work it around by upgrading grpc and protobuf to newer versions, let's see if the tests pass.\r\n\r\n/cc @mihaimaruseac ", "With protobuf 3.19.1, many Linux tests are failing with Segmentation fault:\r\n https://source.cloud.google.com/results/invocations/23e260dc-55b8-446a-92c2-a57b7423a56f/targets\r\n\r\nI did a bisect on protobuf in the TensorFlow build, can identify the breakage on Linux comes from this commit:\r\nhttps://github.com/protocolbuffers/protobuf/commit/a00125024e9231d76746bd394fef8876f5cc15e2\r\n\r\nUnfortunately, this is a sync commit with internal code base, it's still very hard to figure out what's the exact breakage.\r\n\r\n/cc @learning-to-play  @yongtang \r\n/cc protobuf experts @acozzette @TeBoring", "@meteorcloudy I looked at a couple of the failures but the logs didn't seem to include a stack trace or anything. Do you know if there is any way to get access to a more detailed error message?", "@acozzette Thanks for looking into it, I managed to get a stack trace with gdb:\r\n```\r\nReading symbols from bazel-bin/tensorflow/c/experimental/ops/gen/cpp/cpp_generator_test...done.\r\n\r\nwarning: core file may not match specified executable file.\r\n[New LWP 5773]\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nCore was generated by `bazel-bin/tensorflow/c/experimental/ops/gen/cpp/cpp_generator_test'.\r\nProgram terminated with signal SIGSEGV, Segmentation fault.\r\n#0  0x00007f4fddc1657d in tensorflow::OpDef::OpDef(tensorflow::OpDef const&) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#0  0x00007f4fddc1657d in tensorflow::OpDef::OpDef(tensorflow::OpDef const&) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#1  0x00007f4fdd12f573 in std::_Function_base::_Base_manager<tensorflow::register_op::OpDefBuilderWrapper::operator()()::{lambda(tensorflow::OpRegistrationData*)#1}>::_M_manager(std::_Any_data&, std::_Function_base::_Base_manager<tensorflow::register_op::OpDefBuilderWrapper::operator()()::{lambda(tensorflow::OpRegistrationData*)#1}> const&, std::_Manager_operation) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#2  0x00007f4fdd12a785 in std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>::function(std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#3  0x00007f4fdd12a84d in void std::vector<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>, std::allocator<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> > >::_M_realloc_insert<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&>(__gnu_cxx::__normal_iterator<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>*, std::vector<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>, std::allocator<std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> > > >, std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#4  0x00007f4fdd1301ba in tensorflow::OpRegistry::Register(std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#5  0x00007f4fdd130980 in tensorflow::register_op::OpDefBuilderWrapper::operator()() ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/_U_S_Stensorflow_Sc_Sexperimental_Sops_Sgen_Scpp_Ccpp_Ugenerator_Utest___Utensorflow/libtensorflow_framework.so.2\r\n#6  0x00007f4fce8a8712 in __static_initialization_and_destruction_0(int, int) [clone .constprop.17] ()\r\n   from /home/kbuilder/.cache/bazel/_bazel_kbuilder/b35e56146bb385d966771bab3ed3e8cb/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/c/experimental/ops/gen/cpp/../../../../../../_solib_local/libtensorflow_Scompiler_Smlir_Stensorflow_Slibmlir_Upassthrough_Uop.so\r\n#7  0x00007f4fde5828d3 in call_init (env=0x7fff2e73b0b8, argv=0x7fff2e73b0a8, argc=1, l=<optimized out>) at dl-init.c:72\r\n#8  _dl_init (main_map=0x7f4fde79d170, argc=1, argv=0x7fff2e73b0a8, env=0x7fff2e73b0b8) at dl-init.c:119\r\n#9  0x00007f4fde5730ca in _dl_start_user () from /lib64/ld-linux-x86-64.so.2\r\n#10 0x0000000000000001 in ?? ()\r\n#11 0x00007fff2e73cb44 in ?? ()\r\n#12 0x0000000000000000 in ?? ()\r\n```\r\n\r\nAnother interesting observation is that this only happens with test binary built with **remote execution,** I cannot reproduce if build and test locally (test passes normally).", "This has something to do with the RBE cc toolchain, I can reproduce the issue with \r\n`bazel test --config=rbe_cpu_linux_base //tensorflow/c/experimental/ops/gen/cpp:cpp_generator_test` locally.", "I bet this is related to the global protobuf default instances being constant-initialized, since that is one of the major C++ changes in the protobuf commit from the bisect.\r\n\r\nHere is my guess for what is happening: for some reason the RBE toolchain is not constant-initializing the protobuf default instances and is instead trying to initialize them at runtime. Then Tensorflow registration is not working properly because it uses the `OpDef` proto which isn't fully functional without the default instances initialized. This could be a variation of the C++ static initialization order [fiasco](https://en.cppreference.com/w/cpp/language/siof).", "> the RBE toolchain is not constant-initializing...\r\n\r\nAre we not matching in the macro on RBE the extra case for:\r\n```\r\n #define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n```", "> > the RBE toolchain is not constant-initializing...\r\n> \r\n> Are we not matching in the macro on RBE the extra case for:\r\n> \r\n> ```\r\n>  #define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n> ```\r\n\r\nThat could be. My understanding is that the constant initialization is supposed to work regardless of how `PROTOBUF_CONSTINIT` is defined, but we define it when possible anyway because that will force the compiler to return an error if it's unable to do the constant initialization.\r\n\r\n@sbenzaquen Do you have any ideas on whether something could be going wrong with the const initialization?", "@acozzette Thanks! Sounds like this one https://stackoverflow.com/questions/11911662/c-static-member-initialization-confuses-with-compiler-linking-how-to-solve? \r\nIs there a way to prevent this problem from protobuf side?", "> > > the RBE toolchain is not constant-initializing...\r\n> > \r\n> > \r\n> > Are we not matching in the macro on RBE the extra case for:\r\n> > ```\r\n> >  #define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n> > ```\r\n> \r\n> That could be. My understanding is that the constant initialization is supposed to work regardless of how `PROTOBUF_CONSTINIT` is defined, but we define it when possible anyway because that will force the compiler to return an error if it's unable to do the constant initialization.\r\n> \r\n> @sbenzaquen Do you have any ideas on whether something could be going wrong with the const initialization?\r\n\r\nConstant initialization is mainly there to save on resources. It reduces binary size and runtime costs.\r\nIn MSVC, for example, we are not constant initializing the globals and they will just be runtime initialized during static initialization time.\r\n\r\nI see that the stack trace above is happening during static initialization time.\r\nUsing protobuf during static initialization time is not supported, since the protobuf library itself is being initialized at this time.\r\nIf this platform is not constant initializing the objects, then it might be likely using it before it is initialized. Note that even on platforms that support constant initialization you are still at risk of using parts of protobuf before they are initialized.", "@meteorcloudy Do you have a way to make an edit to force `PROTOBUF_CONSTINIT` to be `[[clang::require_constant_initialization]]` and rerun the tests on RBE that way? It would be good to confirm for sure that we know what the problem is.", "@acozzette Sure, can you send me a patch? I can help verify it. I'm currently building with protobuf at protocolbuffers/protobuf@a001250", "I was thinking you could just replace lines 577-587 [here](https://github.com/protocolbuffers/protobuf/blob/7ccf4d8f67878a6ceb2184df279478cb3314372b/src/google/protobuf/port_def.inc#L577) with this one line:\r\n```\r\n#define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n```", "@acozzette I still failed with the same error with the following patch on protocolbuffers/protobuf@a001250:\r\n```\r\n--- a/src/google/protobuf/port_def.inc\r\n+++ b/src/google/protobuf/port_def.inc\r\n@@ -562,27 +562,29 @@\r\n // by this flag is supposed to be removed after this experiment.\r\n // #define PROTOBUF_MESSAGE_OWNED_ARENA_EXPERIMENT\r\n\r\n-#if defined(__cpp_constinit)\r\n-#define PROTOBUF_CONSTINIT constinit\r\n-#elif defined(__has_cpp_attribute)\r\n-#if __has_cpp_attribute(clang::require_constant_initialization)\r\n #define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n-#endif\r\n-#endif\r\n-#ifndef PROTOBUF_CONSTINIT\r\n-#define PROTOBUF_CONSTINIT\r\n-#endif\r\n\r\n-#if defined(__cpp_constinit)\r\n-#define PROTOBUF_CONSTINIT constinit\r\n-#elif defined(__has_cpp_attribute)\r\n-#if __has_cpp_attribute(clang::require_constant_initialization)\r\n-#define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n-#endif\r\n-#endif\r\n-#ifndef PROTOBUF_CONSTINIT\r\n-#define PROTOBUF_CONSTINIT\r\n-#endif\r\n```", "I found an easy way to reproduce this inside a RBE docker container used on TF kokoro (but no need to enable RBE).\r\n```\r\n# Inside docker container gcr.io/tensorflow-testing/nosla-cuda11.2-cudnn8.1-ubuntu18.04-manylinux2010-multipython\r\n \r\ngit clone https://github.com/meteorcloudy/tensorflow.git\r\ncd tensorflow\r\ngit fetch origin upgrade_protobuf_grpc\r\ngit checkout upgrade_protobuf_grpc\r\n \r\n./configure # Set Python to /usr/local/bin/python3.9, leave everything else default\r\n \r\nbazel test --config=rbe_cpu_linux_base //tensorflow/c/experimental/ops/gen/cpp:cpp_generator_test\r\n```\r\nFeel free to try it out.\r\n\r\nIf you want to make any change to protobuf, you can clone the protobuf repo and use `--override_repository=com_google_protobuf=<path to >/protobuf` to point `com_google_protobuf` repo to it, this way you don't have to modify the workspace2.bzl file of TF.", "> bazel test --config=rbe_cpu_linux_base //tensorflow/c/experimental/ops/gen/cpp:cpp_generator_test\r\n\r\nI've runned this in the image but the test log is empty:\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/c/experimental/ops/gen/cpp:cpp_generator_test\r\n-----------------------------------------------------------------------------\r\n```", "> I've runned this in the image but the test log is empty:\r\n\r\nYes, that's because the test binary failed at startup time due to the Segmentation fault. You'll need gdb to debug it, something like https://serverfault.com/questions/61659/can-you-get-any-program-in-linux-to-print-a-stack-trace-if-it-segfaults.\r\n\r\nUnfortunately I don't have enough C++/protobuf/TF knowledge for this..", "Oh it was a segmentation fault.. so we can just use this bazel workaround in the meantime:\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/11371#issuecomment-884455884", "> I was thinking you could just replace lines 577-587 [here](https://github.com/protocolbuffers/protobuf/blob/7ccf4d8f67878a6ceb2184df279478cb3314372b/src/google/protobuf/port_def.inc#L577) with this one line:\r\n> \r\n> ```\r\n> #define PROTOBUF_CONSTINIT [[clang::require_constant_initialization]]\r\n> ```\r\n\r\nI think this will not have any effect on the RBE image as we are using `gcc (GCC) 7.3.1 20180303`\r\n\r\nAlso `__constinit` for our c++14 mode I think was introduce only in GCC 10:\r\n\r\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=91360\r\n\r\nEDIT:\r\nThe `__constinit` test is better highlighted at:\r\nhttps://github.com/gcc-mirror/gcc/commit/4742dbe71804b3db099eb0eb8620dff2c79a71cf#diff-459ef0538db5b68226ef487810243947e937fd9fece08b5ff93de690f8dde319R3\r\n", "@bhack Could you try defining `PROTOBUF_CONSTINIT` as something like `__attribute__((init_priority((102))))`? We use this in `PROTOBUF_ATTRIBUTE_INIT_PRIORITY` in a few other places to guarantee that our initialization happens earlier than other initializations. This could be one potential solution. I'm not 100% sure if we would want to do this, but it would at least be useful to know if it fixes the problem.", "@acozzette No, it is not working.\r\n", "With the RBE cc toolchain, we are using `/dt7/usr/bin/gcc` instead of `/usr/bin/gcc` to do cross compiling which targets manylinux. There are some suspect that it's caused due to mismatch of libc/libc++ versions in the docker.", "> With the RBE cc toolchain, we are using `/dt7/usr/bin/gcc` instead of `/usr/bin/gcc` to do cross compiling which targets manylinux. There are some suspect that it's caused due to mismatch of libc/libc++ versions in the docker.\r\n\r\nUsing bazel ` --subcommands` I see we are comping with \r\n\r\n`external/ubuntu18.04-gcc7_manylinux2010-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`\r\n\r\nThat with `--version` is:\r\n\r\n`gcc (GCC) 7.3.1 20180303\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.`", "I suppose it is coming from:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl", "@bhack You are right, if you looking into `external/ubuntu18.04-gcc7_manylinux2010-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`, the underlying cpp compiler would be `/dt7/usr/bin/gcc`", "> @bhack You are right, if you looking into `external/ubuntu18.04-gcc7_manylinux2010-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`, the underlying cpp compiler would be `/dt7/usr/bin/gcc`\r\n\r\nSo what is the incompatibility that you suppose we have between gcc `7.3.1 20180303`  and `libc++` (what version?) in the RBE docker?", "I don't know the exact reason, but here is the dockerfile for the RBE docker:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.rbe.cuda11.2-cudnn8.1-ubuntu18.04-manylinux2010-multipython#L32", "@d0k @jyknight might know more.", "@meteorcloudy But just to be sure that it is related to the RBE image  have you tried if your branch and this selected test run regularly in the `tensorflow/tensorflow-devel` official image?", "> But just to be sure that it is related to the RBE image have you tried if your branch and this selected test run regularly in the tensorflow/tensorflow-devel official image?\r\n\r\nYes, the tests pass correctly in my local build. It's only failing with the RBE docker contains with the RBE toolchain, which uses different compiler and toolchain. Normally it should be fine and it's how we always run TF tests on CI.", "So, tests fail with the devtoolset gcc, which uses the pre-C++11-string ABI.\r\nIt looks to me like  fixed_address_empty_string is not initialized because InitProtobufDefaultsImpl is not called.\r\nI'm still trying to reproduce this.", "> So, tests fail with the devtoolset gcc, which uses the pre-C++11-string ABI.\r\n\r\nhttps://discuss.python.org/t/how-to-set-glibcxx-use-cxx11-abi-for-manylinux2014-and-manylinux2010-wheels/10551/4\r\n\r\nThat it is also  the problem we have experimenting with https://github.com/tensorflow/build/pull/41", "Problem found:\r\nprotobuf doesn't support constructing protos from static initalizers.\r\nHere, specificially, the global empty string instance protobuf relies on is not constructed.\r\nPutting OpDef::descriptor() into OpDefBuilderWrapper::operator()() \"fixes\" the issue.\r\nWe need some way for protobuf to support being used from initializers from user code.", "@r4nt Why It was working in the non RBE env like https://github.com/tensorflow/tensorflow/pull/52853#issuecomment-961860165?", "Sign... some Windows tests still failed with `Windows fatal exception: code 0xc0000374`", "For anyone who's interested in debugging the Windows failure, to reproduce, simply:\r\n```\r\ngit clone https://github.com/meteorcloudy/tensorflow.git\r\ncd tensorflow\r\ngit fetch origin upgrade_protobuf_grpc\r\nconfigure\r\nbazel test --announce_rc --config=opt tensorflow/python/grappler:memory_optimizer_test --test_arg=MemoryOptimizerSwapTest.testNoSwapping\r\n```", "Can you post the error we have in:\r\n`grappler/memory_optimizer_test/test.log` ?", "Here is the log, but it doesn't provide much useful information:\r\n```\r\n==================== Test output for //tensorflow/python/grappler:memory_optimizer_test:\r\nRunning tests under Python 3.9.7: C:\\Python39\\python.exe\r\n[ RUN      ] MemoryOptimizerSwapTest.testNoSwapping\r\n2021-11-12 13:58:41.522874: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\r\n2021-11-12 13:58:41.525970: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\r\n2021-11-12 13:58:41.529455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nHello world\r\nWindows fatal exception: code 0xc0000374\r\n\r\nCurrent thread 0x00028698 (most recent call first):\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\grappler\\tf_optimizer.py\", line 67 in OptimizeGraph\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\grappler\\memory_optimizer_test.py\", line 57 in testNoSwapping\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\framework\\test_util.py\", line 1532 in decorated\r\n  File \"C:\\Python39\\lib\\unittest\\case.py\", line 550 in _callTestMethod\r\n  File \"C:\\Python39\\lib\\unittest\\case.py\", line 592 in run\r\n  File \"C:\\Python39\\lib\\unittest\\case.py\", line 651 in __call__\r\n  File \"C:\\Python39\\lib\\unittest\\suite.py\", line 122 in run\r\n  File \"C:\\Python39\\lib\\unittest\\suite.py\", line 84 in __call__\r\n  File \"C:\\Python39\\lib\\unittest\\suite.py\", line 122 in run\r\n  File \"C:\\Python39\\lib\\unittest\\suite.py\", line 84 in __call__\r\n  File \"C:\\Python39\\lib\\unittest\\runner.py\", line 176 in run\r\n  File \"C:\\Python39\\lib\\unittest\\main.py\", line 271 in runTests\r\n  File \"C:\\Python39\\lib\\unittest\\main.py\", line 101 in __init__\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\testing\\absltest.py\", line 2553 in _run_and_get_tests_result\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\testing\\absltest.py\", line 2584 in run_tests\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\testing\\absltest.py\", line 2172 in _run_in_app\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\testing\\absltest.py\", line 2065 in main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\platform\\googletest.py\", line 51 in g_main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\app.py\", line 258 in _run_main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\absl_py\\absl\\app.py\", line 312 in run\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\platform\\googletest.py\", line 60 in main_wrapper\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\platform\\benchmark.py\", line 514 in benchmarks_main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\platform\\googletest.py\", line 62 in main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\platform\\test.py\", line 56 in main\r\n  File \"\\\\?\\C:\\src\\temp\\Bazel.runfiles__yzpk26z\\runfiles\\org_tensorflow\\tensorflow\\python\\grappler\\memory_optimizer_test.py\", line 325 in <module>\r\n```\r\n\r\nI managed to locate the \"Windows fatal exception\" was triggered at:\r\nhttps://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/python/grappler/tf_optimizer_wrapper.cc;l=98 when calling the constructor of `tensorflow::grappler::MetaOptimizer`\r\n\r\nMaybe this problem is related to https://github.com/protocolbuffers/protobuf/issues/7691", "Mhh, currently I don't have enough resources to compile that target on Qemu.\r\n\r\nIs the `dbg`config working for the Windows build?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#debug-builds", "@bhack Yes, the `--config=dbg` build should work on Windows as well.\r\n\r\nUpdate: \r\nHmm, it doesn't quite work. If you encounterred \"python39_d.lib\" not found, you can workaround by replacing \".lib\" with \"_d.lib\" [here](https://cs.opensource.google/tensorflow/tensorflow/+/master:third_party/py/python_configure.bzl;l=177?q=%22python_import_lib%22&ss=tensorflow%2Ftensorflow).\r\n\r\nUpdate 2:\r\nOr just cherry-pick https://github.com/meteorcloudy/tensorflow/commit/771d6f34f8047a61872c6aa0fcfa34257543ce6b to make the debug build work, but there are some linking error for _pywrap_tensorflow_internal.so... ", "So can you debug a break point on the suspected section with this `dbg` config and  your fixes?", "Figured out an easy way to reproduce this issue, checkout this commit: https://github.com/meteorcloudy/tensorflow/commit/ffb1b5c85a676502146a5dacf107517036f8b84b and run \r\n```\r\nbazel run --announce_rc --config=opt tensorflow/python/grappler:_pywrap_tf_optimizer.so\r\n```\r\nThis way, the python extension thingy isn't involved, and should be easier to debug, but I still have to figure out how to use windbg..", "> still have to figure out how to use windbg..\n\nIf you find a way a reproducible way It could be very useful to add few documenting lines in the `Contributing.md` debug section other then a PR with your branch changes for the Windows debug build configuration fix.", "> other then a PR with your branch changes for the Windows debug build configuration fix.\r\n\r\nThe fix didn't actually work, because it failed at linking _pywrap_tensorflow_internal.so. If it works, I will definitely better document it.\r\n\r\n", "I don't know if @reedwm has some feedback on this as he documented that `dbg` build config at:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/48919#issuecomment-866438774", "I am very unfamiliar with Windows so unfortunately I cannot help much here. Make sure you are using `--config=dbg` and not `-c dbg`. What is the error message you got when linking _pywrap_tensorflow_internal.so?", "OK, I found an easy way to reproduce and debug this. In https://github.com/meteorcloudy/tensorflow/commit/61d7c3a4b19903d4fa0f9ff8d7f7e9a1c254eac4, I added a few targets to imitate how the how _pywrap_tf_optimizer link to _pywrap_ternsorflow_internal.pyd (but without actually depending on the actual giant shared library). \r\nLuckily, the issue can be reproduced, and we can easily build a debuggable binary:\r\n```\r\nbazel run --announce_rc --config=dbg tensorflow/python/grappler:tf_optimizer_wrapper_bin\r\n```\r\n\r\nI'm able to get a stack trace in VS:\r\n![image](https://user-images.githubusercontent.com/4171702/142431583-5575d474-3ba7-4382-a199-cb5701f94e51.png)\r\n\r\nHowever, my C++ and protobuf knowledge is limited, and this place is likely the victim of some other code that actually corrupted the heap.\r\n\r\n@acozzette Do you have any good guess on what's happening here? I suspect it's related to that protobuf is statically linked in both the cc binary and the DLL it depends on. Any suggestion where I should debug into? Context: https://github.com/tensorflow/tensorflow/pull/52853#issuecomment-967138677", "@acozzette Maybe something related to https://github.com/protocolbuffers/protobuf/tree/master/cmake#dlls-vs-static-linking? In TF, dynamic link isn't avoidable, and protobuf could be statically linked for each DLL, any suggestion on making them work correctly?", "I think you are probably right that this crash has something to do with DLLs. Protobuf has a default string object and decides whether to delete a string or not by comparing a given string pointer with the address of the default string, so if the protobuf runtime is linked in more than one place then there can be more than one default string. This would be consistent with the crash in the stack trace.\r\n\r\nIt seems to me that there are two possible ways to fix this problem:\r\n- Make sure the protobuf runtime is only linked in one place (so if it's in the DLL then don't link it in the main cc_binary).\r\n- If the runtime has to be linked in more than one place, then try to keep them completely separate (e.g. hide symbols as much as possible and don't pass protos across the DLL boundary).", "@meteorcloudy Can you please resolve conflicts? Thanks!", "I think this should now wait for #53234 \r\n\r\n@gbaned let's not ping this PR anymore until linked issue above gets resolved, to reduce noise", "@meteorcloudy Can you please resolve conflicts? Thanks!\r\n", "Still waiting for https://github.com/tensorflow/tensorflow/issues/53234"]}, {"number": 52845, "title": "TensorFlow binary crashes on Apple M1 in x86_64 Docker container", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): TensorFlow 2.6.0, tf-nightly 2.8.0.dev20211028\r\n- Python version: 3.6.9, 3.7.x, 3.8.x\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n```\r\ndwyatte-macbookpro:~ dwyatte$ docker run tensorflow/tensorflow:latest python -c \"import tensorflow as tf\"    \r\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\r\n2021-10-28 22:50:41.481158: F tensorflow/core/lib/monitoring/sampler.cc:42] Check failed: bucket_limits_[i] > bucket_limits_[i - 1] (0 vs. 10)\r\nqemu: uncaught target signal 6 (Aborted) - core dumped\r\n```\r\n\r\n**Describe the expected behavior**\r\nClean exit\r\n\r\n**Standalone code to reproduce the issue**\r\nRequires an Apple M1 (arm64) host OS:\r\n`docker run tensorflow/tensorflow:latest python -c \"import tensorflow as tf\"`\r\n\r\nThis was previously mentioned in https://github.com/tensorflow/tensorflow/issues/42387 but unfortunately closed. When importing TensorFlow in an x86_64 docker container on an Apple M1, TensorFlow crashes. As far as I can tell, this should work as I can import and use other Python packages in the same container without problems (including things like `numpy`).\r\n\r\nIt's unclear whether this is something that can be avoided at the TensorFlow level or an unavoidable bug in qemu ([[1]](https://github.com/docker/for-mac/issues/5342#issuecomment-779133157), [[2]](https://gitlab.com/qemu-project/qemu/-/issues/601)), but I wanted to reraise the issue.", "comments": ["Hi @dwyatte ! Could you check these threads ? [link1](https://stackoverflow.com/questions/66662820/m1-docker-preview-and-keycloak-images-platform-linux-amd64-does-not-match-th),[link2](https://stackoverflow.com/questions/65942641/docker-image-built-on-mac-osx-wont-run-on-aws-ec2-instance/65952339#65952339)", "Thanks @mohantym \r\n\r\nThe links just reference the warning above which I believe is innocuous since Docker can emulate the image's platform. TensorFlow doesn't publish official linux/arm64/v8 images (would require an aarch64 TensorFlow build), but I would think that would remove the warning. Note that the problem is specifically with TensorFlow's assumptions about the emulated platform and not the image or other libraries, which run fine when emulating linux/amd64:\r\n\r\n```\r\ndwyatte-macbookpro:~ dwyatte$ docker run tensorflow/tensorflow:latest python -c \"import numpy as np; print(np.random.rand(10))\"   \r\nWARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\r\n[0.86125896 0.40657583 0.76832123 0.77205272 0.99326573 0.513298\r\n 0.64218547 0.15977918 0.37553315 0.56692333]\r\n```\r\n\r\nI suspect `Check failed: bucket_limits_[i] > bucket_limits_[i - 1] (0 vs. 10)` is a sanity check that TensorFlow runs on startup that fails under emulation. IMO this issue is about whether there is anything that can be done on the TensorFlow side to relax or correct this check or whether this is a critical check that is violated e.g., by qemu (https://gitlab.com/qemu-project/qemu/-/issues/601 suggests it could be floating point inaccuracy, although that seems to just be a guess).", "Hi @sanatmpa1! Could you please look at this issue?", "I am taking a class where we use tensorflow inside docker containers and everybody with an M1 mac in that class had this exact same issue including me. Unfortunately nobody has found a fix so I am going to subsribe to this issue as well, I hope there exist some kind of workarround/solution!", "Hi,\r\n\r\nI have the exact same issue. It is hindering my development process. While my app is deployed on an x86 server, I do need to use my M1 mac with emulation to develop code locally and to push it to production.\r\n\r\nAll other major data science packages work correctly under x86 rosetta emulation: pandas, scikit-learn, torch, transformers, spacy, xgboost, lightgbm.\r\n\r\nI appreciate the great work you are doing with TensorFlow. I would be really grateful if you could take the time to help the data scientists / ML engineers out there who are using ARM-based development laptops.\r\n\r\nThanks a lot,\r\n\r\nAlex\r\n\r\nPS: I am not interested in forks like tensorflow-macos etc as I need my work to be cross-platform.", "https://github.com/apple/tensorflow_macos/issues/164#issuecomment-776785984\n\nhttps://github.com/ARM-software/Tool-Solutions/tree/master/docker/tensorflow-aarch64\n\nBut as someone still needs to use this in emulation I suppose in that It could be a qemu BUG with `DBL_MAX` in emulation\n\n\n\n\n", "Did anybody find any way to run tensorflow inside a docker container on any M1, M1 Pro or M1 Max device? Would really love to know any workaround so I can start building containers with tf. Thanks in advance for any tips!", "If the point is to have a published X86 wheel without AVX we have already an open ticket, so it is better to add a comment there instead of having a new ticket:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/19584\r\n\r\nIf instead you want to have AVX TCG support in QEMU e.g. on M1 there is already an open ticket at:\r\nhttps://gitlab.com/qemu-project/qemu/-/issues/164", "So I do think this is due to AVX instructions. If I install an unofficial wheel (e.g., from https://github.com/yaroslavvb/tensorflow-community-wheels/issues/198) and run a variant of the `docker run` command above, I do not get a crash on import.\r\n\r\n```\r\ndwyatte-macbookpro:~ dwyatte$ docker run -it tensorflow/tensorflow:latest bash -c 'pip uninstall -y tensorflow-cpu && pip install -U https://tf.novaal.de/barcelona/tensorflow-2.6.0-cp38-cp38-linux_x86_64.whl && python -c \"import tensorflow as tf; tf.print(\\\"hello world\\\")\"'\r\n...\r\n2021-11-15 23:44:35.660302: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nhello world\r\n```\r\n\r\nThanks for the lead @bhack. I agree, some solutions which you mention are:\r\n1.) Publishing non-AVX wheels (or having non-AVX code paths available within a single wheel)\r\n2.) Correctly handling in qemu via emulation/TCG/etc.", "For the first point I don't know if anyone at @intel-tensorflow is interested to publish an SSE4.x only wheel in https://pypi.org/project/intel-tensorflow/", "@dwyatte Thanks a lot for the tip. With an unofficial wheel I was able to get Tensorflow running within Docker on an Apple M1 processor \ud83d\ude80 ", "@gabac One you built or one that is available online? I'm facing the same issue...", "E.g. if you use pip as a package manager use e.g. `pip install -U https://tf.novaal.de/barcelona/tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl` for Python 3.7, Tensorflow 2.5.0", "Thanks, that did the trick! Unfortunately, Docker + M1 Mac seems to be pretty slow... :( (not talking about training...)", "For performance you need to use `tensorflow-macos`", "Untill we will have `AMX2` support in the compiler stack (starting with LLVM) It will be hard to have a docker Linux image with a TF optimized for M1 CPU.\n\nSee \n> Special note about Apple M1\n\n https://nod.ai/nod-codegen-beats-mkl-blis-accelerate/\n\n", "It seems to be Docker Desktop on the M1 that is causing performance issues. It's not even TF related, only testing model conversion and single inference... ", "Docker desktop on Apple silicon for X86 I think It uses rosetta2.\n\nhttps://developer.apple.com/documentation/apple-silicon/about-the-rosetta-translation-environment\n\n> Rosetta translates all\u00a0x86_64\u00a0instructions, but it doesn\u2019t support the execution of some newer instruction sets and processor features, such as AVX, AVX2, and AVX512 vector instructions. If you include these newer instructions in your code, execute them only after verifying that they are available. For example, to determine if AVX512 vector instructions are available, use the\u00a0sysctlbyname\u00a0function to check the\u00a0hw.optional.avx512f\u00a0attribute.\n\n\nOther then the missing CPU accell you will not have Neural engine and GPU access.\n\nSo I don't think it could be suggested to use It in emulation on linux for performance as the platform isn't documented, fully supported on linux and in the opensoruce compilers stacks.", "(Thanks for the tip about the non-AVX unofficial build, will give that a try. 1 or 2 mentioned by @dwyatte seem like better medium term solutions though.)\r\n\r\nI think Docker uses QEMU for emulation (not rosetta2), which is one of the reasons it's slow in general. \r\n\r\n[1] https://docs.docker.com/desktop/mac/apple-silicon/#known-issues\r\n[2] https://news.ycombinator.com/item?id=25449561", "Yes It Is just that Partially Docker itself still run Rosetta 2\u00a0as some binaries are still Darwin/AMD but the emulation is Qemu.\r\n\r\nBut both have no AVX support so It is hard to achieve top performances and Linux don't support AMX2 as are still going to be supported at compiler level (and fully documented/reverse engineered).\r\n\r\n", "I'm building the software on my Mac (old one for now), where I mostly build the apps, APIs, UI, inference engines, and run tests for the whole system. I need a Mac to run the model conversion tests for CoreML. \r\n\r\nI tried running linux/amd64 images on the M1  and got things to work for PyTorch and TF (using the non-AVX TF build described above). \r\n\r\nUnfortunately, the tests now take about 3x as long to run, note these are integration tests and don't involve training networks, for which I use a Linux machine. I just wanted to keep them separate in order to run the full suite of tests on linux (excluding coreML tests) while continue to develop on my Mac. ", "@janvdp have you made any more progress in the last 2 months ? I added the --platform argument to my docker file to run Linux/amd and installed an unofficial non avx tensor flow 2.7. Finally got the image built but damn it's slow. The unit tests are so much slower. Also many of the tests fail because for some reason some of the rounded precision assertions are different etc. \n\n\nIf you have made any progress let me know ! ", "@DrChrisLevy I'm a novice when it comes to Docker, how did you add the dependency of the unofficial tensor flow to your docker build? Currently I have TF configured as below\r\n\r\n```\r\ndependencies:\r\n  - sqlalchemy==1.3.20\r\n  - pymysql==1.0.2\r\n  - pip==21.3\r\n  - pip:\r\n    - tensorflow==2.3.1\r\n    - tensorflow-serving-api==2.3.0\r\n    - sentry-sdk==1.4.3\r\n    - transformers==4.11.3\r\n    - torch==1.9.1\r\n```", "@coreation\r\n\r\nSo update since I last wrote. Last time above I said I got it working using emulation (so running on x86). This is not ideal because it's slow. It's much faster if you can get it running on aarch64.  It all depends on what other libraries \r\nyou are installing and what your base docker image looks like. \r\n\r\nWhat docker image are you using?\r\nWhen you type `uname -m` within the docker container running do you get `aarch64` or `x86_64`? \r\n\r\nIf you are doing something like `pip install tensorflow==2.3.1` its going to use one of the official tensorflow wheels. \r\nAnd which one it uses depends on if the docker container is running `aarch64` or `x86_64`. But both will have issues. \r\n\r\nIf you are running `x86_64` then its gonna be slow. But to get it working you need to install unofficial community wheel without AVX. You can see a list of such options [here](https://github.com/yaroslavvb/tensorflow-community-wheels/issues). For example, when I was trying to go this `x86_64` emulation route I first tried\r\n`TensorFlow 2.7.0 No AVX, No GPU, Python 3.7, 3.8, 3.9, Ubuntu 18.04, multiple Archs` which is this [link](https://github.com/yaroslavvb/tensorflow-community-wheels/issues/206). I tried the `barcelona` one and all of its builds are [here](https://tf.novaal.de/barcelona/). You then have to choose the one for your TF version and Python version. I tried TF  2.7 and Python 3.8 so I used `tensorflow-2.7.0-cp38-cp38-linux_x86_64.whl` which is this link: `https://tf.novaal.de/barcelona/tensorflow-2.7.0-cp38-cp38-linux_x86_64.whl`. So to install this with pip you do\r\n`pip install -f https://tf.novaal.de/barcelona/tensorflow-2.7.0-cp38-cp38-linux_x86_64.whl`. \r\n\r\nI don't recommend this route ^^ though because emulation on m1 chip not ideal. Better to get your docker container running\r\non `aarch64`. For example I use the docker image `FROM python:3.8-slim`. And I am using an aarch64 community wheel\r\nfor Tensorflow. For example, in dockerfile `RUN pip install tensorflow -f https://tf.kmtea.eu/whl/stable.html`. I got the wheel from [here](https://github.com/KumaTea/tensorflow-aarch64).\r\n\r\nNow in our DEV/PROD ENV we actually manage all dependencies with [poetry](https://python-poetry.org/) and are running everything on x86 so we actually just use the official tensorflow wheels. Our apps dont run on aarch64 in production. But since I use a macbook with m1 chip for local development I needed to get my local dev env running on m1 chip. And its great/fast if I use `aarch64`. So I had to uninstall tensorflow official from my container and then use the above mentioned hack of installing Tensorflow AARCH64. But its working great. \r\n\r\nLet me know if you need more details.\r\n\r\n", "Hi @DrChrisLevy Thank you so much for your elaborate reply, I'll try as good as I can to provide answers so that I can hopefully get the docker containers running again.\r\n\r\nI believe the base image starts from \"continuumio/miniconda3\" and then adds dependencies to build the images that we're using. The result of the uname -m is ```x86_64 ```.\r\n\r\nI then built our images using the aarch64 tensorflow wheel, I added tensorflow-serving-api as I think it's more basic python implementation to talk with tensorflow-serving.\r\n\r\nMy build currently doesn't start and returns a more generic error message: ```Error response from daemon: configured logging driver does not support reading``` So I'll have to debug that first.\r\n\r\nDo you happen to know where I could find / start looking for a tensorflow-serving M1 compatible image?", "The slowdown with non-AVX TensorFlow wheels is likely mainly due to emulation (compared to anything inherent to TensorFlow itself). IMO an ideal outcome would be to have official aarch64 wheels on PyPI that can use platform detection to `pip install tensorflow` without having to specify a community webpage. This would also seamlessly support the workflows being discussed here (running an aarch64 image locally and building/deploying an amd64 image in production)\r\n\r\nWhile I suspect this issue might have more visibility, https://github.com/tensorflow/tensorflow/issues/52973 is probably better for discussing aarch64 wheels.\r\n\r\nHere are some benchmarks for a subset of my unit tests (roughly an order of magnitude slower under emulation):\r\n\r\n```\r\ndwyatte-macbookpro:tensorflow-test dwyatte$ ./build_and_test.sh \r\n[+] Building 0.9s (8/8) FINISHED                                                                                                                                                                                        \r\n => [internal] load build definition from Dockerfile_amd64                                                                                                                                                         0.0s\r\n => => transferring dockerfile: 209B                                                                                                                                                                               0.0s\r\n => [internal] load .dockerignore                                                                                                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/library/python:3.7-slim                                                                                                                                                 0.8s\r\n => [1/4] FROM docker.io/library/python:3.7-slim@sha256:71287598b4d9fcc01fa3949035aeace14c6bde733462bb4f64fb4ee13c6b3fec                                                                                           0.0s\r\n => CACHED [2/4] RUN pip install https://tf.novaal.de/westmere/tensorflow-2.7.0-cp37-cp37m-linux_x86_64.whl                                                                                                        0.0s\r\n => CACHED [3/4] RUN pip install pandas                                                                                                                                                                            0.0s\r\n => CACHED [4/4] RUN pip install pytest                                                                                                                                                                            0.0s\r\n => exporting to image                                                                                                                                                                                             0.0s\r\n => => exporting layers                                                                                                                                                                                            0.0s\r\n => => writing image sha256:af60a6f5973c2a8568619c233580d5046670c3dfa5633e287e20869a99a9365e                                                                                                                       0.0s\r\n => => naming to docker.io/library/tensorflow-test                                                                                                                                                                 0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\n================================================================================================= test session starts ==================================================================================================\r\nplatform linux -- Python 3.7.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\r\nrootdir: /host\r\ncollected 19 items                                                                                                                                                                                                     \r\n\r\ntests/test_callbacks.py ...........                                                                                                                                                                              [ 57%]\r\ntests/test_datasets.py ...                                                                                                                                                                                       [ 73%]\r\ntests/test_layers.py .....                                                                                                                                                                                       [100%]\r\n\r\n=================================================================================================== warnings summary ===================================================================================================\r\n../usr/local/lib/python3.7/site-packages/flatbuffers/compat.py:19\r\n  /usr/local/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n    import imp\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\r\n============================================================================================ 19 passed, 1 warning in 3.17s =============================================================================================\r\n[+] Building 0.5s (8/8) FINISHED                                                                                                                                                                                        \r\n => [internal] load build definition from Dockerfile_aarch64                                                                                                                                                       0.0s\r\n => => transferring dockerfile: 474B                                                                                                                                                                               0.0s\r\n => [internal] load .dockerignore                                                                                                                                                                                  0.0s\r\n => => transferring context: 2B                                                                                                                                                                                    0.0s\r\n => [internal] load metadata for docker.io/library/python:3.7-slim                                                                                                                                                 0.4s\r\n => [1/4] FROM docker.io/library/python:3.7-slim@sha256:71287598b4d9fcc01fa3949035aeace14c6bde733462bb4f64fb4ee13c6b3fec                                                                                           0.0s\r\n => CACHED [2/4] RUN pip install https://snapshots.linaro.org/ldcg/python/tensorflow-io-manylinux/7/tensorflow-io-gcs-filesystem/tensorflow_io_gcs_filesystem-0.21.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2  0.0s\r\n => CACHED [3/4] RUN pip install pandas                                                                                                                                                                            0.0s\r\n => CACHED [4/4] RUN pip install pytest                                                                                                                                                                            0.0s\r\n => exporting to image                                                                                                                                                                                             0.0s\r\n => => exporting layers                                                                                                                                                                                            0.0s\r\n => => writing image sha256:f1a848557f756bf7c99fdbe7bf666d3cb4272eec73a63bdd8abe20283e492aef                                                                                                                       0.0s\r\n => => naming to docker.io/library/tensorflow-test                                                                                                                                                                 0.0s\r\n\r\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\n================================================================================================= test session starts ==================================================================================================\r\nplatform linux -- Python 3.7.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\r\nrootdir: /host\r\ncollected 19 items                                                                                                                                                                                                     \r\n\r\ntests/test_callbacks.py ...........                                                                                                                                                                              [ 57%]\r\ntests/test_datasets.py ...                                                                                                                                                                                       [ 73%]\r\ntests/test_layers.py .....                                                                                                                                                                                       [100%]\r\n\r\n=================================================================================================== warnings summary ===================================================================================================\r\n../usr/local/lib/python3.7/site-packages/flatbuffers/compat.py:19\r\n  /usr/local/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n    import imp\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\r\n============================================================================================ 19 passed, 1 warning in 0.32s =============================================================================================\r\n```\r\n\r\n\r\n", "Thanks @DrChrisLevy!\r\n\r\nIt also turns out tensorflow has [Dockerfiles for arm64v8](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles/arm64v8), but they don't push the images, so you need to build them yourself. Useful for trying to keep development docker images as close as possible to the official ones.\r\n\r\n\r\n---\r\nEdit: Two gotchas:\r\n1. Remove the `enum34` python package from the Dockerfile\r\n2. Remove the fixed version of `numpy` in the Dockerfile (can let the version be the latest) \r\n---\r\n\r\nFor posterity:\r\n\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git --depth 1\r\ncd tensorflow/tensorflow/tools/dockerfiles\r\n\r\n# edit arm64v8/devel-cpu-arm64v8-jupyter.Dockerfile and remove enum34 / remove the version from numpy\r\n\r\ndocker build -f ./arm64v8/devel-cpu-arm64v8-jupyter.Dockerfile -t tf-devel-cpu-arm64v8-jupyter .\r\n```\r\n\r\nThen make a new Dockerfile, and use this:\r\n```\r\nFROM tf-devel-cpu-arm64v8-jupyter\r\n\r\n# Or use this version: RUN pip install tensorflow-aarch64 -f https://tf.kmtea.eu/whl/stable.html\r\n\r\nRUN pip install tensorflow -f https://tf.kmtea.eu/whl/stable.html\r\n```", "@ibash thank you for the heads up, when I ran the docker build using the arm64v8 (not jupyter) I ran into the issue of pandas not being able to install because of the numpy version that was locked in the build file. Setting the version of pandas to something arbitrary like 1.0.5 did the trick.\r\n\r\nDo you happen to know if a similar approach exists for tensorflow-serving? That's also a package that currently doesn't run on Apple Silicon.", "@coreation not sure about tensorflow-serving, I'm not using it.\r\n\r\nRe: numpy I hit that too, updated the comment above.", "@ibash thanks for the comment anyway, from what I read there's no Apple Silicon compatible wheel from the community, but I wanted to check anyway. Thanks for the edit!", "Are there any update here? Not being able to run tensorflow in docker on our new powerful M1-based machines is both a big downer and quite the annoyance to \"solve\". ATM our best workaround is having an intel-based VM for development, which feels quite unnecessary. ", "This works.\r\n> FROM tf-devel-cpu-arm64v8-jupyter\r\n> \r\n> Or use this version: RUN pip install tensorflow-aarch64 -f https://tf.kmtea.eu/whl/stable.html\r\n> \r\n> RUN pip install tensorflow -f https://tf.kmtea.eu/whl/stable.html\r\n> ```\r\nHowever, tensorflow does not find gpus.\r\n", "@hoangmt So what do I put in my Pipfile, if I want a version that I can install both in docker on my M1 machine, and build on linux/x64 to send to for example Vertex AI as a training job?\r\n\r\nLocally, I don't care about GCP access, it just needs to work so I can develop models with a tiny version of my dataset. The M1-ish GPUs are not good for _training_ models anyway. The \"Neural Engine\" only accelerates inference AFAIK.\r\n\r\nBasically this\r\n> IMO an ideal outcome would be to have official aarch64 wheels on PyPI that can use platform detection to pip install tensorflow without having to specify a community webpage. This would also seamlessly support the workflows being discussed here (running an aarch64 image locally and building/deploying an amd64 image in production)", "If you are using an old 1.x version of Tensorflow, downgrading to max 1.5, Python 3.6, and running docker targeting x86 is a quick, crappy solution since AVX was introduced in 1.6. \r\n\r\nWe don't really use Tensorflow for anything critical (was kinda a devs pet project a few years back) so it works for us. Sounds like either qemu needs to support avx to move this foward OR Tensorflow starts publishing multi arch wheels without avx?"]}, {"number": 52831, "title": "Retrieving exactly the same recommendations for all users", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/recommenders/examples/basic_retrieval#making_predictions\r\n\r\n## Description of issue (what needs changing):\r\nWhen making predictions, the model is retrieving the exact same predictions for all users when using other datasets.\r\n\r\n### Clear description\r\nWhen model is trained and we're making predictions, everything works fine when using the movielens dataset which is provided in the tutorial.\r\nBut if swapping to any other dataset (have tried several datasets), the recommendation becomes the exact same for all users.\r\n\r\n### Correct links\r\nI cannot publish my data since it is GDPR sensitive. However, this user has used an open source data and has published his work on Github:\r\nhttps://github.com/fickaz/TFRS-on-Retail-Data/blob/main/src%20a.%20Retrieval.ipynb\r\n\r\nUnfortunately, he has not checked predictions for any other user than \"user 42\". But if you replicate his work, you will see that the predictions are same for all users.\r\n\r\n### Parameters defined\r\nIn my dataset (recipes), I have tried to mimic the Movielens dataset as close as possible, ending up with around 1k users, 1k recipes and 100k rows. each user has interacted with about 60-300 recipes during 1 year.\r\nMovielens dataset have 25-700 movies per user. Other than that, very similair.\r\n", "comments": ["@hamcapem \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "There is no template for \"other issues\" though.\r\nIs there anything other than mentioned you need?", "@hamcapem Could you please let us know which TF version you are using ? Thanks!", "@sushreebarsa I am using the following versions:\r\ntf   version:    2.6.0\r\ntfrs version:   v0.6.0\r\ntfds version:    4.4.0\r\n\r\n", "@Saduf2019 Was able to replicate the issue on colab using TF v2.6.0 ,please find the [gist](https://colab.research.google.com/gist/sushreebarsa/cb2ac34b3cdabd2ad1ccdace0dd19f07/basic_retrieval.ipynb) for reference.Thanks!", "@Saduf2019 any luck with this?", "@jvishnuvardhan did you have a chance to look at this?", "@hamcapem Sorry for the late response. I checked with `TF2.7` and I see different recommendations for different users. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/436a436b1cc63c1d712b9196f55fe15e/basic_retrieval.ipynb).\r\n\r\n```\r\n# Get recommendations.\r\n_, titles = index(tf.constant([\"42\"]))\r\nprint(f\"Recommendations for user 42: {titles[0, :3]}\")\r\n\r\nRecommendations for user 42: [b'Bridges of Madison County, The (1995)'\r\n b'Father of the Bride Part II (1995)' b'Rudy (1993)']\r\n\r\n# Get recommendations.\r\n_, titles = index(tf.constant([\"44\"]))\r\nprint(f\"Recommendations for user 44: {titles[0, :3]}\")\r\n\r\nRecommendations for user 44: [b'Lion King, The (1994)' b'Aristocats, The (1970)'\r\n b'Sword in the Stone, The (1963)']\r\n\r\n# Get recommendations.\r\n_, titles = index(tf.constant([\"2\"]))\r\nprint(f\"Recommendations for user 2: {titles[0, :3]}\")\r\n\r\nRecommendations for user 2: [b'A Chef in Love (1996)' b'Secrets & Lies (1996)' b'Kolya (1996)']\r\n\r\n```\r\n\r\nPlease let us know if I am interpreting the results correctly or not. Thanks!", "> @hamcapem Sorry for the late response. I checked with `TF2.7` and I see different recommendations for different users. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/436a436b1cc63c1d712b9196f55fe15e/basic_retrieval.ipynb).\r\n> \r\n> ```\r\n> # Get recommendations.\r\n> _, titles = index(tf.constant([\"42\"]))\r\n> print(f\"Recommendations for user 42: {titles[0, :3]}\")\r\n> \r\n> Recommendations for user 42: [b'Bridges of Madison County, The (1995)'\r\n>  b'Father of the Bride Part II (1995)' b'Rudy (1993)']\r\n> \r\n> # Get recommendations.\r\n> _, titles = index(tf.constant([\"44\"]))\r\n> print(f\"Recommendations for user 44: {titles[0, :3]}\")\r\n> \r\n> Recommendations for user 44: [b'Lion King, The (1994)' b'Aristocats, The (1970)'\r\n>  b'Sword in the Stone, The (1963)']\r\n> \r\n> # Get recommendations.\r\n> _, titles = index(tf.constant([\"2\"]))\r\n> print(f\"Recommendations for user 2: {titles[0, :3]}\")\r\n> \r\n> Recommendations for user 2: [b'A Chef in Love (1996)' b'Secrets & Lies (1996)' b'Kolya (1996)']\r\n> ```\r\n> \r\n> Please let us know if I am interpreting the results correctly or not. Thanks!\r\n\r\nHi @jvishnuvardhan,\r\n\r\nI think you missed the description of the issue:\r\n\r\n`When model is trained and we're making predictions, everything works fine when using the movielens dataset which is provided in the tutorial.\r\nBut if swapping to any other dataset (have tried several datasets), the recommendation becomes the exact same for all users.\r\n`\r\n\r\nIn your test, you seem to have used the movielens dataset again.", "Is anyone still working on this? It's soon half a year now.."]}, {"number": 52814, "title": "Linear regression learnt parameters are wrong when using sklearn with my specific docker instance. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary? Installed via docker pull tensorflow/tensorflow:2.4.0-jupyter\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 11.0\r\n- GPU model and memory: NVIDIA GeForce GTX 1650 Ti/PCIe/SSE2\r\n\r\n**Describe the current behavior**\r\n\r\nThe docker tf container is causing an issue with sklearn's linear regression function (and I'm not sure what else it is causing an issue with). \r\n\r\nAfter running a tf docker container which was pulled from one of the tf images, I seek to fit a polynomial model using sklearn. \r\n\r\nI find that the coefficients which are given are not the coefficients which are found if the regression problem is explicitly solved for using maximum likelihood.\r\n\r\nI have checked and I see that when everything is run with a non-tf docker (e.g. jupyter one) or just using a conda env, the issue is no longer there.\r\n\r\nFurther checks included running the same tf docker container on a mac (instead of my ubuntu 20.04). On doing so there was no issue. \r\n\r\nI have also tried running the same tf docker in a virtual machine ubuntu 20.04 to see if my machine was causing the bug. But the issue persists in the virtual machine ubuntu 20.04.\r\n\r\nMoreover, I find that when the number of data points is fewer, there is no issue. Only when the number of data points is increased is this issue there.\r\n\r\nHence I don't know if it is particular to this combination of ubuntu + the tf docker + use of sklearn. Or just something else.\r\n\r\nI've included alternative ways to get at the coefficients (by training a tf model with mse loss --- this gives the correct answer), and using the statsmodels library (which gives the wrong answer), for reference.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behaviour - sklearn's linear regression coefficients should match with those derived by solving the maximum likelihood estimation set-up. \r\n\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing): N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nTo reproduce:\r\n\r\n1. Need to create an ubuntu 20.04 environment (e.g. through virtual box). Although you can proceed without doing this, but i don't know if the issue will then be reproduced.\r\n2. Download the following data (https://drive.google.com/file/d/1NkQJbgn2cG-4y30AcEn1olthpROFWrLo/view?usp=sharing) and notebook  (https://drive.google.com/file/d/1XKEGgwoQ-3OyQYie9-HNI4w0mqNMPWo1/view?usp=sharing) into your working directory. \r\n3. You need to have docker installed and configured \r\n4. From the working directory run the following:\r\n5. `docker run --name abc --user \"$(id -u):$(id -g)\" -v \"$(pwd)\":/tf -it -p 8888:8888 tensorflow/tensorflow:2.4.0-jupyter`\r\n6. Kill this with \"ctrl+c\"\r\n7. `docker start abc`\r\n8.  `docker exec -it abc pip install --no-cache-dir --upgrade pip`\r\n9. `docker start -i abc`\r\n10. Now you should be able to run the notebook and see the issue.\r\n\r\n", "comments": ["Hi @raghul-parthipan ! Could you try again the same in TF 2.6 version?", "Hi @mohantym! I did as you said and the issue still persists. No change.\r\n\r\n(To reproduce my steps, I followed my instructions above but changed step 5 to `docker run --name abc --user \"$(id -u):$(id -g)\" -v \"$(pwd)\":/tf -it -p 8888:8888 tensorflow/tensorflow:2.6.0-jupyter`)", "Hi @Saduf2019! Could you please look at this issue?", "Hi, Have you tried the same code outside docker? Just to understand the root cause of your problem.", "Hi @sachinprasadhs yes I have - I wrote in the initial comments under \"Describe the current behavior\" that in a non-tf docker it works and in a separate conda env (no docker) with tf it works too.", "Then in that case it doesn't looks like TF issue, did you check the same issue in the docker repo.", "But, as written above, when I run it in a non-TF docker then there is no issue. So it looks like it is a result of ubuntu 20.04 + docker + tf. Hence I made the issue here as with the non-TF docker there isn't an issue."]}, {"number": 52794, "title": "TFLite GPU Delegate Precision loss enabled produces different/wrong result.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Galaxy Note20 Ultra(Snapdragon), Galaxy S10(Exynos)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.5.0, 2.6.0, 2.7.0 (All same result)\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): Android NDK 19.2.5345600\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: Snapdragon 865, Exynos 9820\r\n\r\n**Describe the current behavior**\r\nI have been trying to run inference of my custom model using TFLite 2.5.0 or 2.6.0 with OpenCL GPU delegate enabled.\r\nWhen I set gpu_precision_loss_allowed=true, avg_error is 0.334995. But for gpu_precision_loss_allowed=false, it is 6.36335e-06. The error diff between precision_loss enabled(fp16) and precision_loss disabled(fp32) is so large. It can be understandable that if fp16 result is less than 0.003. But 0.33 is so large.\r\n\r\nHere are outputs of the inference_diff/run_eval tool obtained using [my model](https://github.com/tensorflow/tensorflow/files/7434381/model.zip) on Galaxy Note20 Ultra:\r\n\r\n```\r\n\u279c   adb shell /data/local/tmp/run_eval \\\r\n    --model_file=/data/local/tmp/model.tflite \\\r\n    --delegate=gpu \\\r\n    --num_runs=5 \\\r\n    --gpu_precision_loss_allowed=true \r\nGPU delegate created.\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Replacing 623 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : lite/tools/evaluation/stages/tflite_inference_stage.cc:144 \r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 389 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 336 partitions.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 5\r\nReference run latency: avg=645950(us), std_dev=40910(us)\r\nTest run latency: avg=62793.9(us), std_dev=3209(us)\r\nOutputDiff[0]: avg_error=0.394511, std_dev=0.139682\r\n```\r\n\r\n```\r\n\u279c   adb shell /data/local/tmp/run_eval \\\r\n    --model_file=/data/local/tmp/model.tflite \\\r\n    --delegate=gpu \\\r\n    --num_runs=5 \\\r\n    --gpu_precision_loss_allowed=false\r\nGPU delegate created.\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Replacing 623 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions.\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:77 Test interpreter has been initialized.\r\nnative : lite/tools/evaluation/stages/tflite_inference_stage.cc:144 \r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 389 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 336 partitions.\r\nnative : lite/tools/evaluation/stages/inference_profiler_stage.cc:91 Reference interpreter (1 thread on CPU) has been initialized.\r\nNum evaluation runs: 5\r\nReference run latency: avg=650665(us), std_dev=44175(us)\r\nTest run latency: avg=162572(us), std_dev=2556(us)\r\nOutputDiff[0]: avg_error=5.53458e-06, std_dev=1.72756e-06\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe result difference between CPU and GPU result should be similar. It is expected that avg_error should less than 0.003.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n1. The custom model I attached \r\n2. GPU Delegate - OpenCL backend\r\n3. Precision loss enabled\r\n\r\nPlease let me know, if you need more details/logs/code etc. Thanks in advance.", "comments": ["Hi @sachinprasadhs! Could you please look at this issue?"]}, {"number": 52774, "title": "How to convert a tensorlfow SpaceToBatchND-Conv2D-BatchToSpaceND to a single Conv2D in tflite", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): docker image\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0-gpu-jupyter\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import (\r\n        Concatenate,\r\n        DepthwiseConv2D,\r\n        ZeroPadding2D,\r\n        Activation,\r\n        GlobalAveragePooling2D,\r\n        BatchNormalization,\r\n        Conv2D,\r\n        Input,\r\n)\r\nfrom tensorflow.keras.models import Model\r\n\r\ndef SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\r\n    if stride == 1:\r\n        depth_padding = \"same\"\r\n    else:\r\n        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\r\n        pad_total = kernel_size_effective - 1\r\n        pad_beg = pad_total // 2\r\n        pad_end = pad_total - pad_beg\r\n        x = ZeroPadding2D((pad_beg, pad_end))(x)\r\n        depth_padding = \"valid\"\r\n\r\n    if not depth_activation:\r\n        x = Activation(tf.nn.relu)(x)\r\n    x = DepthwiseConv2D(\r\n        (kernel_size, kernel_size),\r\n        strides=(stride, stride),\r\n        dilation_rate=(rate, rate),\r\n        padding=depth_padding,\r\n        use_bias=False,\r\n        name=prefix + \"_depthwise\",\r\n    )(x)\r\n    x = BatchNormalization(name=prefix + \"_depthwise_BN\", epsilon=epsilon)(x)\r\n    if depth_activation:\r\n        x = Activation(tf.nn.relu)(x)\r\n    x = Conv2D(filters, (1, 1), padding=\"same\", use_bias=False, name=prefix + \"_pointwise\")(x)\r\n    x = BatchNormalization(name=prefix + \"_pointwise_BN\", epsilon=epsilon)(x)\r\n    if depth_activation:\r\n        x = Activation(tf.nn.relu)(x)\r\n\r\n    return x\r\n\r\nx = Input(shape=(22, 40, 160))\r\nb0 = Conv2D(256, (1, 1), padding=\"same\", use_bias=False, name=\"aspp0\")(x)\r\nb0 = BatchNormalization(name=\"aspp0_BN\", epsilon=1e-5)(b0)\r\nb0 = Activation(tf.nn.relu, name=\"aspp0_activation\")(b0)\r\nb1 = SepConv_BN(x, 256, \"aspp1\", rate=4, depth_activation=True, epsilon=1e-5)\r\nb2 = SepConv_BN(x, 256, \"aspp2\", rate=8, depth_activation=True, epsilon=1e-5)\r\nb3 = SepConv_BN(x, 256, \"aspp3\", rate=12, depth_activation=True, epsilon=1e-5)\r\nb4 = GlobalAveragePooling2D()(x)\r\nb4 = tf.reshape(b4, (-1, 1, 1, b4.shape[-1]))\r\nb4 = Conv2D(256, (1, 1), padding=\"same\", use_bias=False, name=\"image_pooling\")(b4)\r\nb4 = BatchNormalization(name=\"image_pooling_BN\", epsilon=1e-5)(b4)\r\nb4 = Activation(tf.nn.relu)(b4)\r\nsize_before = tf.shape(x)\r\nb4 = tf.image.resize(b4, size_before[1:3], method=tf.image.ResizeMethod.BILINEAR)\r\ny = Concatenate(name=\"concat_head\")([b4, b0, b1, b2, b3])\r\nmodel = Model(x, y, name=\"aspp\")\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\nmodel.save(\"example.h5\")\r\nopen(\"example.tflite\", \"wb\").write(tflite_model)\r\n```\r\nThe models and graphs are also provided.\r\n[models.zip](https://github.com/tensorflow/tensorflow/files/7432732/example.zip)\r\n\r\n![keras model using Netron](https://user-images.githubusercontent.com/86588364/139223891-45dadbd6-4960-46c1-a222-3da0db42a5d0.png)\r\n![tflite model using Netron](https://user-images.githubusercontent.com/86588364/139223763-66e0167f-4046-42e6-84a8-3eda2a1bc238.png)\r\n\r\n\r\n\r\n### 3. Failure after conversion\r\nThe codes is an implementation of ASPP structure as used in segmentation. In the Keras model, there is no `space_to_batch` or `batch_to_space` operations. However, in the converted tflite model, they appear, which are not supported by tflite gpu-delegate. This means the inference speed will be slowed down due to those operations. \r\n\r\nIs there a way to convert the keras model without  those gpu-unsupported operations?\r\n\r\nI found a related [issue](https://github.com/tensorflow/tensorflow/issues/29509), but the issue still exists.\r\n", "comments": []}, {"number": 52752, "title": "tf.nn.ctc_loss calculated sequentially when using tf.distribute.MirroredStrategy()", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- TensorFlow installed from (source or binary): docker pull tensorflow/tensorflow:2.5.0-gpu, running in a TFJob\r\n- GPU model and memory: Tesla P100\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am working on a ctc based model and wanted to accelerate the training by applying the MirroredStrategy to my custom training loop. I modified my code according to the tutorials, but did not observe any speed up. After digging into it with the profiler I noticed in the trace viewer that each gpu seemed to compute the loss one after another instead of concurrently (see image further below). Also, there seemed a lot of communication to be going on between the devices and the host. Moreover, the overview page stated that more than ~95% of the device time is spent on eager execution. Maybe that's related somehow?\r\n\r\n**Describe the expected behavior**\r\nMaybe there is some misunderstanding on my side how exactly ctc_loss and MirroredStrategy work, but I would expect that it is possible to calculate the loss concurrently on all gpus.\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is some example code which reproduces the issue I am facing. I removed the model forward/backward pass as it is not important and did not seem to cause any problems:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# some dummy parameters, not really important\r\nprofile_steps = 3\r\nper_replica_batch_size = 2\r\nmax_label_seq_length = frames = 20\r\nnum_labels = 10\r\nstrategy = tf.distribute.MirroredStrategy()\r\nGLOBAL_BATCH_SIZE = per_replica_batch_size * strategy.num_replicas_in_sync\r\n\r\nwith strategy.scope():\r\n    def compute_loss(labels, logits, label_length, logit_length):\r\n        per_replica_loss = tf.nn.ctc_loss(labels, logits, label_length, logit_length)\r\n        return tf.nn.compute_average_loss(\r\n            per_replica_loss, global_batch_size=GLOBAL_BATCH_SIZE\r\n        )\r\n\r\n@tf.function\r\ndef train_step():\r\n    labels = tf.ones((GLOBAL_BATCH_SIZE, max_label_seq_length), dtype=tf.int32)\r\n    logits = tf.random.normal(shape=(frames, GLOBAL_BATCH_SIZE, num_labels))\r\n    label_length = tf.ones(GLOBAL_BATCH_SIZE, dtype=tf.int32) * max_label_seq_length\r\n    logit_length = tf.ones(GLOBAL_BATCH_SIZE, dtype=tf.int32) * frames\r\n    loss = compute_loss(labels, logits, label_length, logit_length)\r\n\r\ntf.profiler.experimental.start(\"logs/profiler\")\r\nfor step in range(profile_steps):\r\n    with tf.profiler.experimental.Trace(\"train\", step_num=step, _r=1):\r\n        loss = strategy.run(\r\n            train_step,\r\n        )\r\ntf.profiler.experimental.stop()\r\n```\r\n\r\n**Other info / logs** \r\n\r\nHere is a screenshot of the trace viewer of the above code when executed on 3 gpus.\r\n\r\n<img width=\"694\" alt=\"tf_distributed\" src=\"https://user-images.githubusercontent.com/36960190/139153715-0ca32c6a-30b4-43a9-93f8-18f475deb5a5.PNG\">\r\n\r\n\r\n", "comments": ["Hi @Saduf2019 ! Could you please have a look at this issue ?"]}, {"number": 52706, "title": "[TFLite] Add int16x8 support for comparison operators", "body": "Hello,\r\n\r\nThis PR adds int16x8 support for comparison operators.\r\nComparison operators: LESS, GREATER, GREATER_EQUAL, LESS_EQUAL, EQUAL, NOT_EQUAL.\r\n\r\nFurthermore, this PR transforms the absolute scaling of each input by a relative scaling (based on the highest scaling of the two inputs). This allows for greater precision when dealing with very small scales.\r\n\r\nThanks,\r\nJohan.", "comments": ["@miaout17 Can you please review this PR ? Thanks!", "@miaout17 Can you please review this PR ? Thanks!", "@johan-gras Can you please sign CLA. Thank you!"]}, {"number": 52673, "title": "No SVDF ref kernel support with all 8 bit weights and state", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source): 1180d389b41314e9715336b4b7b194140292d5c8\r\n\r\nTFLM has support for this already:\r\nhttps://github.com/tensorflow/tflite-micro/pull/506\r\n\r\nIf CMSIS-NN should add support for this it would be good to first have support in Tensorflow Lite, since CMSIS-NN has TFL as reference for its tests.\r\n\r\n\r\n", "comments": ["Tagging @freddan80 @petewarden @advaitjain "]}, {"number": 52621, "title": "RuntimeError: Quantization not yet supported for op: Without OP specifier", "body": "### 1. System information\r\n\r\nWindows 10\r\nTensorflow 2.3.0rc0 (also tried 2.3.1)\r\n\r\n### 2. Code\r\n\r\nI am trying to convert my custom yolov3-tiny (with relu instead of leakyRelu) SavedModel to 8bit quantized tflite for edge tpu support with the following:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n\r\n    def representative_dataset_gen():\r\n        for _ in range(250):\r\n            yield [np.random.uniform(0.0, 1.0, size=(1, 416, 416, 3)).astype(np.float32)]\r\n\r\n    model = tf.keras.models.load_model('yolo_relu_model')\r\n\r\n    batch_size = 1\r\n    input_shape = model.inputs[0].shape.as_list()\r\n    input_shape[0] = batch_size\r\n    func = tf.function(model).get_concrete_function(tf.TensorSpec(input_shape, model.inputs[0].dtype))\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([func])\r\n\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.representative_dataset = representative_dataset_gen\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.inference_input_type = tf.uint8\r\n    converter.inference_output_type = tf.uint8\r\n    converter.experimental_new_quantizer = True\r\n\r\n    model_lite = converter.convert()\r\n    f = open(\"yolo_relu_model.tflite\", \"wb\")\r\n    f.write(model_lite)\r\n    f.close()\r\n\r\n\r\nwhich leads to:\r\n\r\n```\r\n  File \"quantize.py\", line 37, in <module>\r\n    quantize_model(\"yolo_relu\")\r\n  File \"quantize.py\", line 31, in quantize_model\r\n    model_lite = converter.convert()\r\n  File \"C:\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 1076, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"C:\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 900, in convert\r\n    self).convert(graph_def, input_tensors, output_tensors)\r\n  File \"C:\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 638, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"C:\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 452, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"C:\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\", line 98, in calibrate_and_quantize       \r\n    np.dtype(activations_type.as_numpy_dtype()).num)\r\nRuntimeError: Quantization not yet supported for op:\r\n```\r\n\r\n\r\nI have also started  a colab [here](https://colab.research.google.com/gist/lukqw/fcdafa1381300ca6b53804b6fdffbb16/tensorflow-lite-debugger-colab.ipynb) which runs on tensorflow 2.6 (I cant seem to change the version), which produces a different output.\r\n\r\n\r\nyou can download the zip of my model [here](https://drive.google.com/file/d/1Ovj0aCeG7yhF6_7-piQHb88LV7CTLn0z/view?usp=sharing) and upload the zip inside colab.\r\n\r\nIn colab I get this output:\r\n\r\n```\r\nWARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\r\nWARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\r\nWARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\r\nWARNING:absl:For model outputs containing unsupported operations which cannot be quantized, the `inference_output_type` attribute will default to the original type.\r\n```\r\n\r\nWhen converting the tflite produced by colab with edgetpu_compiler I get the following result:\r\n\r\n```\r\nEdge TPU Compiler version 16.0.384591198\r\nStarted a compilation timeout timer of 180 seconds.\r\n\r\nModel compiled successfully in 1270 ms.\r\n\r\nInput model: co_yolo_relu_model.tflite\r\nInput size: 8.57MiB\r\nOutput model: co_yolo_relu_model_edgetpu.tflite\r\nOutput size: 8.61MiB\r\nOn-chip memory used for caching model parameters: 1.95MiB\r\nOn-chip memory remaining for caching model parameters: 15.75KiB\r\nOff-chip memory used for streaming uncached model parameters: 6.54MiB\r\nNumber of Edge TPU subgraphs: 1\r\nTotal number of operations: 62\r\nOperation log: co_yolo_relu_model_edgetpu.log\r\n\r\nModel successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\r\nNumber of operations that will run on Edge TPU: 22\r\nNumber of operations that will run on CPU: 40\r\nSee the operation log file for individual operation details.\r\nCompilation child process completed within timeout period.\r\nCompilation succeeded!\r\n``` \r\nI'd like to have all operations on the Edge TPU (obviously), but I am kinda stumped here on how to proceed.\r\n\r\nCan someone point me in the right direction on how to convert the model correctly (with tf 2.3.1 or others)?\r\n\r\nWhy is there no specifier on which op is not supported in the error message\r\n`RuntimeError: Quantization not yet supported for op: `\r\n?\r\n\r\n\r\nThis is the log of edgetpu_compiler:\r\n\r\n```\r\nEdge TPU Compiler version 16.0.384591198\r\nInput: co_yolo_relu_model.tflite\r\nOutput: co_yolo_relu_model_edgetpu.tflite\r\n\r\nOperator                       Count      Status\r\n\r\nSTRIDED_SLICE                  8          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nMUL                            6          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nDEQUANTIZE                     2          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nCONCATENATION                  4          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nCONCATENATION                  1          Mapped to Edge TPU\r\nEXP                            2          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nCONV_2D                        13         Mapped to Edge TPU\r\nQUANTIZE                       1          Mapped to Edge TPU\r\nQUANTIZE                       4          More than one subgraph is not supported\r\nQUANTIZE                       4          Operation is otherwise supported, but not mapped due to some unspecified limitation\r\nRESIZE_NEAREST_NEIGHBOR        1          Mapped to Edge TPU\r\nLOGISTIC                       6          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nMAX_POOL_2D                    6          Mapped to Edge TPU\r\nRESHAPE                        2          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\nADD                            2          Tensor has unsupported rank (up to 3 innermost dimensions mapped)\r\n```", "comments": ["@lukqw,\r\n\r\n> I have also started a colab here which runs on tensorflow 2.6 (I cant seem to change the version)\r\n\r\nTo changed the version of TF running in colab, run the command !pip install tensorflow==2.3.0 in a cell and restart the kernel once the installation is done.", "@sanatmpa1 \r\n\r\nthanks for the tip! I have adjusted the colab accordingly - which now produces the same error as on my machine.\r\n\r\nany idea about what is the problem in my conversion?", "@lukqw,\r\n\r\nI have commented out these 3 flags and added a flag `converter.allow_custom_ops = True`. Now the code executes fine and please take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/a2ef7abfd37e71262f22fd32200b5ef4/52621.ipynb)\r\n\r\n```python\r\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n# converter.inference_input_type = tf.uint8\r\n# converter.inference_output_type = tf.uint8\r\n```", "@sanatmpa1 \r\nthanks for your suggestions\r\nI made your changes to the code to try it out, but as I want to achieve 8-bit quantization to allow full support of the edgetpu_compiler I do have to include the flags.\r\n\r\nWith the tflite model produced by your solution I get the following output with edgetpu_compiler:\r\n```\r\nEdge TPU Compiler version 16.0.384591198\r\nStarted a compilation timeout timer of 180 seconds.\r\nERROR: :61 op_context.input->type == kTfLiteUInt8 || op_context.input->type == kTfLiteInt8 || op_context.input->type == kTfLiteInt16 || op_context.input->type == kTfLiteFloat16 was not true.\r\nERROR: Node number 41 (DEQUANTIZE) failed to prepare.\r\n\r\nCompilation failed: Model failed in Tflite interpreter. Please ensure model can be loaded/run in Tflite interpreter.\r\nCompilation child process completed within timeout period.\r\nCompilation failed!\r\n``` ", "@sanatmpa1 \r\nI have for now decided to use tensorflow 2.6 for conversion of my model, as it seems to work with the initial configuration (including the code here once more):\r\n\r\n```\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_spec.supported_types = [tf.int8]\r\n    converter.representative_dataset = representative_dataset_gen\r\n    converter.inference_input_type = tf.int8\r\n    converter.inference_output_type = tf.int8\r\n```\r\n\r\nMy problem lies in actual inference with the newly generated 8bit quantized tflite model.\r\n\r\nWhen I perform inference with the 8bit quantized tflite model produced with the above config, the output looks like this:\r\n![image](https://user-images.githubusercontent.com/39307517/139156799-ad6a6734-ae70-45c2-a658-f721b850e644.png)\r\n\r\nI'm performing inference in the following way\r\n```\r\n            self.model = tflite.Interpreter(model_path='yolo_relu_quantized_model_edgetpu.tflite', experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\r\n            self.model.allocate_tensors()\r\n            input_details = self.model.get_input_details()[0]\r\n\r\n            scale, zero_point = input_details['quantization']\r\n            tflite_integer_input = frame / scale + zero_point\r\n            tflite_integer_input = np.int8(tflite_integer_input)\r\n\r\n            self.model.set_tensor(input_details['index'], tflite_integer_input)\r\n            self.model.invoke()\r\n\r\n            output_details = self.model.get_output_details()\r\n            outputs = []\r\n            for i in range(len(output_details)):\r\n                scale, zero_point = output_details[i]['quantization']\r\n                val = self.model.get_tensor(output_details[i]['index'])\r\n                val = val.astype(np.float32)\r\n                val = (val - zero_point) * scale\r\n                outputs.append(val)\r\n            return outputs \r\n```\r\n\r\nWhen running the tflite model with no 8 bit quantization (basically just tflite conversion) config like this:\r\n```\r\n    batch_size = 1\r\n    input_shape = model.inputs[0].shape.as_list()\r\n    input_shape[0] = batch_size\r\n    func = tf.function(model).get_concrete_function(tf.TensorSpec(input_shape, model.inputs[0].dtype))\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([func])\r\n\r\n    model_lite = converter.convert()\r\n    f = open(f\"{YOLO_V3_TINY_TFLITE_BASE}/yolo_relu_model.tflite\", \"wb\")\r\n    f.write(model_lite)\r\n    f.close() \r\n```\r\n\r\nand inference:\r\n```\r\ninput_details = self.model.get_input_details()\r\n            output_details = self.model.get_output_details()\r\n            if self.inftype == \"tail\":\r\n                frame = frame[0]\r\n            self.model.set_tensor(input_details[0]['index'], frame)\r\n            self.model.invoke()\r\n            return [self.model.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\r\n```\r\n\r\nthe model actually produces something worthwhile on the same image as before:\r\n\r\n![image](https://user-images.githubusercontent.com/39307517/139157685-be70aa69-5c7d-47c1-8078-ace001ddc46e.png)\r\n\r\n\r\nDo you have any idea on what could be causing this?\r\n\r\nIt seems to me that the confidence in the first image is 2.65, which seems erroneous, considering that it should be between 0 and 1?", "Although 8 bit quantized models will be less precise, but in your case it looks significant, could you please refer to [this](https://coral.ai/docs/edgetpu/models-intro/#compatibility-overview) and see if you can make any changes to improve the accuracy.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sachinprasadhs \r\n\r\nI have followed the guide over at [the tensorflow guide](https://www.tensorflow.org/lite/performance/post_training_integer_quant) to convert my model to a fully quantized uint8 model, which you can also find inside [this colab](https://colab.research.google.com/gist/lukqw/fcdafa1381300ca6b53804b6fdffbb16/tensorflow-lite-debugger-colab.ipynb#scrollTo=D7XL1JBR6iyP).\r\n\r\nFor inference I am using the following to load and initialize the model:\r\n\r\n```\r\nimport tflite_runtime.interpreter as tflite\r\nmodel = tflite.Interpreter(model_path=(\"yolo_relu_model.tflite\"))\r\nmodel.allocate_tensors()\r\n```\r\n\r\nFor actually performing inference I use the following:\r\n\r\n```\r\n# frame is padded and divided through 255\r\n\r\ndef predict(frame):\r\n    input_details = model.get_input_details()[0]\r\n    scale, zero_point = input_details['quantization']\r\n    tflite_integer_input = frame * 255\r\n    tflite_integer_input = tflite_integer_input.astype(input_details['dtype'])\r\n    \r\n    model.set_tensor(input_details['index'], tflite_integer_input)\r\n    model.invoke()\r\n    \r\n    output_details = model.get_output_details()\r\n    outputs = []\r\n    for i in range(len(output_details)):\r\n        scale, zero_point = output_details[i]['quantization']\r\n        val = model.get_tensor(output_details[i]['index'])\r\n        val = val.astype(np.float32)\r\n        val = (val - zero_point) * scale\r\n        outputs.append(val)\r\n    return outputs \r\n\r\n```\r\n\r\nDo you notice any errors here? From what I can tell this is the suggested method from [here](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb#scrollTo=KuTEoGFYd8aM) and [here](https://github.com/guichristmann/edge-tpu-tiny-yolo/blob/master/inference.py).\r\n\r\nAfter noticing the differences in inference, which you can see in above post I tried my luck with the [quantization debugger](https://www.tensorflow.org/lite/performance/quantization_debugger), where no real outliers exist for rmse/scale values. I have also attached the file for this debugging session (took over 5hrs to create).  \r\n[debugger_results_more_data.csv](https://github.com/tensorflow/tensorflow/files/7532663/debugger_results_more_data.csv)\r\n\r\nWhat I find especially weird is, that the probability is always 2.65 for inference with the quantized tflite model, while it is \"normal\" (from 0 - 1) for the non-quantized tflite model.\r\n\r\nAfter some more digging I found the following: \r\nI compared the outputs of both normal tflite and quantized tflite model prediction for this image:\r\n![person](https://user-images.githubusercontent.com/39307517/141659081-1d0cfd87-79f7-4591-94e6-64df60d038a7.jpg)\r\n\r\nIn postprocessing of the results i compared pred_xywh, pred_conf and pred_prob. \r\nWhile pred_xywh is pretty similar between normal tflite and quantized model, the pred_conf and pred_prob are very different.\r\nHere are two examples, which each include the np.max(pred_conf) and np.max(pred_prob), to show that output is differing.\r\n\r\nExample np.max(pred_conf ) AND np.max(pred_prob) for tflite NORMAL:\r\n(This result also includes a bounding box around the person with 0.99 confidence)\r\n```\r\n0.993759 \r\n0.9999705\r\n```\r\nExample np.max(pred_conf ) AND np.max(pred_prob) for tflite NORMAL\r\n(This result does not have a bounding box around the person)\r\n```\r\n0.0 \r\n1.6284815\r\n```\r\n\r\nFurthermore, when performing inference on the video as in the previous replies, I get a constant output of 1.6284815 for np.max(pred_prob), while I also get 1.6284815 for np.max(pred_conf) when it draws the bounding box.\r\n\r\nDo you know why this might be?\r\n\r\nDo you notice any errors on my side? Please tell me if you have any directions for me. ", "This could be the problem with the data, try normalizing your data before feeding it to model and test it again.", "I am normalizing the data.\r\n\r\nAs far as I understood, the data from representative_dataset will be fed into the existing float 32 model, just like during \"normal\" inference. Therefore I use `resize_fame` just like I do before usual inference.\r\n\r\n```\r\ndef representative_dataset_gen():\r\n    for file in os.listdir('./inf_data/repres_images'):\r\n        img = cv2.imread(f'./inf_data/repres_images/{file}')\r\n        resized = resize_frame(img, 416)\r\n        yield [resized]\r\n```\r\n\r\nAny other ideas?"]}, {"number": 52610, "title": "Golang support for tf.Variable", "body": "**System information**\r\n- TensorFlow version (you are using): unsure\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI don't see any equivalent of \"tf.Variable\" in the Go API:\r\nhttps://pkg.go.dev/github.com/tensorflow/tensorflow/tensorflow/go#section-readme\r\nand\r\nhttps://pkg.go.dev/github.com/tensorflow/tensorflow/tensorflow/go/op\r\n\r\n**Will this change the current api? How?**\r\nIt will change the Go API.\r\n\r\n**Who will benefit with this feature?**\r\nGolang users who want to train models.\r\n\r\nI have a model I am creating in Golang and then sending to Python to use the optimization API. I need tf.Variable objects to pass to the minimize function.\r\n\r\n**Any Other info.**\r\nI mistakenly filed this FR in an unofficial repo: https://github.com/galeone/tfgo/issues/62\r\n", "comments": []}, {"number": 52605, "title": "Model serving signature with SparseTensor input feature", "body": "This is a bug report.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX 11.5.2, GCP Linux hosted instance\r\n-   **TensorFlow installed from (source or binary)**: TFX 1.0.0 docker image on Linux; on OSX installed binary with pip\r\n-   **TensorFlow version (use command below)**: 2.5.0\r\n-   **Python version**: 3.8.1 and 3.8.5 (Mac), 3.7 (Linux)\r\n-   **Bazel version (if compiling from source)**: N/A\r\n-   **GCC/Compiler version (if compiling from source)**: N/A\r\n-   **CUDA/cuDNN version**: N/A CPU only\r\n-   **GPU model and memory**: N/A\r\n-   **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nWhen saving the model signature function with sparse tensor input, (generated from `get_concrete_function` or `tf.function(input_signatures=...)` decorator), the recovered model signature no longer accepts sparse tensor as inputs. Here is an example script:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# Mock a model\r\ninput_x = tf.keras.Input(1)\r\noutput_y = tf.keras.layers.Dense(1)(input_x)\r\nmodel = tf.keras.Model(input_x, output_y)\r\n\r\ndef _get_serving_signature(model):\r\n    @tf.function\r\n    def my_func(x, y):\r\n        x_out = tf.cast(tf.sparse.to_indicator(x, 5), tf.int64)\r\n        return {\"x\": x_out, \"y\": y}\r\n    \r\n    return my_func\r\n\r\n# Get the concrete func\r\nconcrete_func = _get_serving_signature(model).get_concrete_function(\r\n        x=tf.SparseTensorSpec(shape=[None, None], dtype=tf.int64),\r\n        y=tf.TensorSpec(shape=[None, 1], dtype=tf.int64),\r\n    )\r\n\r\n# Store this function inside the model\r\nmodel.my_func = concrete_func\r\n    \r\n# Build the signature dict\r\nsignatures = { \"default\": concrete_func}\r\n\r\n# save the model\r\nmodel.save(\"./serving_dir\", save_format=\"tf\", signatures=signatures)\r\n\r\n# Load the model back\r\nmodel2 = tf.keras.models.load_model(\"./serving_dir\")\r\n\r\n# Make up some data\r\nx = tf.ragged.constant([[1, 3], [2, 3, 1], [2]], dtype=tf.int64).to_sparse()\r\ny = tf.expand_dims(tf.constant([1, 2, 1], dtype=tf.int64), axis=1)\r\n\r\n# Make inference on saved my_func\r\nout_func_attr = model2.my_func(x=x, y=y)\r\n\r\n# Make inference using signature\r\nout_signature = model2.signatures[\"default\"](x, y)\r\n```\r\n\r\nDuring saving of the model, a warning message appears:\r\n\r\n```\r\nWARNING:absl:Function `my_func` contains input name(s) x with unsupported characters which will be renamed to x_2 in the SavedModel.\r\n```\r\n\r\nCalling the saved function as a model attribute returns the correct output\r\n```python\r\nout_func_attr = model2.my_func(x=x, y=y)\r\n```\r\n\r\n```python\r\n{'y': <tf.Tensor: shape=(3, 1), dtype=int64, numpy=\r\n  array([[1],\r\n        [2],\r\n        [1]])>,\r\n  'x': <tf.Tensor: shape=(3, 5), dtype=int64, numpy=\r\n  array([[0, 1, 0, 1, 0],\r\n        [0, 1, 1, 1, 0],\r\n        [0, 0, 1, 0, 0]])>}\r\n```\r\n\r\nMake inference using signature \r\n\r\n```python\r\nout_signature = model2.signatures[\"default\"](x, y)\r\n```\r\nreturns the following error:\r\n\r\n\r\n```python\r\nTraceback (most recent call last):\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1724, in _call_impl\r\nreturn self._call_with_flat_signature(args, kwargs,\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1748, in _call_with_flat_signature\r\nraise TypeError(\r\n\r\nTypeError: signature_wrapper(x, x_1, x_2, y) takes 0 positional arguments but 2 were given\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/Users/edward/Desktop/sparse_serving.py\", line 61, in <module>\r\n    out_signature = model2.signatures[\"default\"](x, y)\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1711, in __call__\r\n    return self._call_impl(args, kwargs)\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1727, in _call_impl\r\n    raise structured_err\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1720, in _call_impl\r\n    return self._call_with_structured_signature(args, kwargs,\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1798, in _call_with_structured_signature\r\n    self._structured_signature_check_missing_args(args, kwargs)\r\n\r\n  File \"/Users/edward/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1817, in _structured_signature_check_missing_args\r\n    raise TypeError(\"{} missing required arguments: {}\".format(\r\n\r\nTypeError: signature_wrapper(*, x_2, y, x_1, x) missing required arguments: x, x_1, x_2, y\r\n\r\n```\r\n\r\nThe saved function attribute `model2.my_func` is\r\n\r\n```python\r\n <ConcreteFunction my_func(x, y) at 0x7F9D824BBF10>\r\n```\r\n\r\nwhich is expected.\r\n\r\nThe signature `model2.signatures[\"default\"]`  is a\r\n```python\r\n<ConcreteFunction signature_wrapper(*, x_2, y, x_1, x) at 0x7F9D824C5A90>\r\n```\r\n\r\nwhich is incorrect.\r\n\r\nOne can also easily modify the above script and verify him/herself that, if `x` is a dense tensor, with `TensorSpec` rather than `SparseTensorSpec`, the serving signature no longer has this problem.\r\n\r\n", "comments": ["@sanatmpa1 ,\r\nI was able to reproduce the issue in tf v2.6 and nightly.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/a699c96140c7e85086d89e4bee47306b/untitled100.ipynb).\r\n\r\n[EDIT]  This is still an issue with `tf-nightly`(2.9.0-dev20220309)"]}, {"number": 52599, "title": "Asset initialization using SavedModel C++ API", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- TensorFlow installed from: source, commit 1dd2070b5f9\r\n- TensorFlow version: 2.8\r\n- Python version: 3.8.5\r\n- Bazel version: 3.7.2\r\n- GCC version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: V100-SXM2 16GB\r\n\r\n**Describe the current behavior**\r\nI would like to infer a TF-TRT converted model using the C++ API of tensorflow. I have followed the https://github.com/bmzhao/saved-model-example. Before saving the model I have converted it with TF-TRT. See https://github.com/tfeher/tf-trt-saved-model-example for details.\r\n\r\nWhile loading the SavedModel, the assets are initialized. This is confirmed by the printout from TF-TRT's op that initializes the engine from the asset file:\r\n```\r\nI tensorflow/compiler/tf2tensorrt/kernels/trt_engine_resource_ops.cc:160] Loaded 1 TRT engines for op TRTEngineOp_0_0 on device /job:localhost/replica:0/task:0/device:GPU:0 from file\r\n /data/saved-model-example/mnist_model_trt/assets/trt-serialized-engine.TRTEngineOp_0_0\r\n\r\n```\r\n\r\nAfterwards, when I try to infer the model, I receive the following error:\r\n```\r\nError executing session.Run() INVALID_ARGUMENT: 2 root error(s) found.\r\n  (0) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'asset_path_initializer' with dtype string\r\n         [[{{node asset_path_initializer}}]]\r\n         [[Func/StatefulPartitionedCall/input/_1/_67]]\r\n  (1) INVALID_ARGUMENT: You must feed a value for placeholder tensor 'asset_path_initializer' with dtype string\r\n         [[{{node asset_path_initializer}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n```\r\n\r\nI do not understand why does it want to initialize the assets again. They are already initialized. In fact, if I modify the example to add the asset_path, then TRT resource initializer throws the following error:\r\n```\r\nError executing session.Run() INTERNAL: 2 root error(s) found.                                                                                                                                                    \r\n  (0) INTERNAL: Expect engine cache to be empty, but got 1 entries.                                                                                                                                               \r\n         [[{{function_node __inference_<lambda>_42188}}{{node InitializeTRTResource}}]]                                                                         \r\n         [[StatefulPartitionedCall/_69]]                                                                                                                                                                          \r\n  (1) INTERNAL: Expect engine cache to be empty, but got 1 entries.                                                                                                                                               \r\n         [[{{function_node __inference_<lambda>_42188}}{{node InitializeTRTResource}}]]   \r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect that I can infer the model once it is loaded by `LoadSavedModel`, since `LoadSavedModel` runs initialization on the assets and variables.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://github.com/tfeher/tf-trt-saved-model-example \r\n\r\nTagging @bixia1 and @DEKHTIARJonathan  for visibility.", "comments": []}, {"number": 52591, "title": "[mlir-hlo]The following operations cannot be legalized: tf.VariableV2 ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.6.0\r\n- Are you willing to contribute it (Yes/No): No, i want to but i don't know how to\r\n\r\n**Describe the feature and the current behavior/state.**\r\nfeature: \r\nlower the op tf.VariableV2/tf.VarHandleOp/tf.ReadVariableOp/tf.AssignVariableOp of tf.dialect into mlir-hlo or other dialect. \r\n\r\nthe current behavior: \r\nwhen i trying to do the translation as follow:\r\ntf-opt --tf-to-hlo-pipeline target-func.mlir -o target-mhlo.mlir\r\ni get the following error message:\r\ntarget-func.mlir:2:3: error: The following operations cannot be legalized: tf.Assign (count: 1); tf.AssignAdd (count: 1); tf.VariableV2 (count: 1). These legalization failure(s) may be due to missing TF to HLO lowerings and/or unsupported attributes, etc.\r\n  func @main() attributes {tf.entry_function = {control_outputs = \"Variable/Assign,AssignAdd\", inputs = \"\", outputs = \"\"}} {\r\n\r\n**Will this change the current api? How?**\r\nyes.\r\nconvertion should be add to the file [legalize_hlo_patterns.td](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/transforms/legalize_hlo_patterns.td) or else\r\n\r\n**Who will benefit with this feature?**\r\nMLIR users, all tensorflow IR users\r\n\r\n**Any Other info.**\r\nis there any feature similar completed \uff1f\r\n", "comments": []}, {"number": 52589, "title": "Modifying the Categorical Cross entropy for Mirrored strategy/Distributed training causing low validation accuracy", "body": "**System information**\r\n**Have I written custom code (yes)\r\n**OS Platform and Distribution (Windows)\r\n**TensorFlow installed from (binary)\r\n**TensorFlow version (2.4.1)\r\n**Python version(3.7.9)\r\n**CUDA/cuDNN version(11.1/8/0):\r\n**GPU model and memory(Titan XP, 12 GB):\r\n\r\n**Describe the problem**\r\nFor **normal (single GPU training)** current loss is being calculated as follows:\r\n\r\n```\r\ndef compute_loss(labels, predictions):\r\n    loss = tf.reduce_mean(\r\n    tf.keras.losses.categorical_crossentropy(y_true=labels, y_pred=predictions)\r\n    )\r\n    return loss\r\n```\r\n\r\nFor **Mirrored strategy/Distributed training (8 GPU)**, I am computing loss as follows:\r\n\r\n\r\n```\r\nloss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False,\r\n              reduction=tf.keras.losses.Reduction.NONE)\r\ndef compute_loss(labels, predictions):\r\n    per_example_loss = loss_object(labels, predictions) \r\n    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n```\r\n\r\nBut in the Distributed strategy the loss is not converging as fast and getting very poor validation accuracy as compared to the original.\r\n", "comments": ["Hi @ashishsb0307 ! Could you please provide a sample stand alone code as a Colab Gist to reproduce this issue ?", "> Hi @ashishsb0307 ! Could you please provide a sample stand alone code as a Colab Gist to reproduce this issue ?\r\n\r\nGive me some time, will create a standalone code.", "@ashishsb0307! Have you tried same in latest version 2.6 yet?", "> Hi @ashishsb0307 ! Could you please provide a sample stand alone code as a Colab Gist to reproduce this issue ?\r\n\r\n[The standalone code for normal/single GPU training](https://colab.research.google.com/drive/10M5eZs2sV1uZJ09N_zz7yujMj81FyaGH?usp=sharing)", "> Hi @ashishsb0307 ! Could you please provide a sample stand-alone code as a Colab Gist to reproduce this issue?\r\n\r\n[The standalone code for distributed/multiple GPU training](https://colab.research.google.com/drive/1DAwZ0DDKRQJlM1XBFNiMaArrnBHt5ozJ?usp=sharing)\r\n\r\nPlease use a multi-GPU environment to validate this", "> @ashishsb0307! Have you tried same in latest version 2.6 yet?\r\nNo, Don't seem to have the same issue with the sample code provided in the Docs with TF 2.4.1 though.", "Hi @sanatmpa1! Could you look at this issue? User's request is to use multiple GPU environment to validate the issue."]}, {"number": 52587, "title": "tf.io.read_file loads indefinitely", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): `v2.4.0-49-g85c8b2a817f 2.4.1`\r\n- Python version: `3.8.5`\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: - \r\n- GPU model and memory: - \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nSplitting a Dataset  and then reading the first item of the Validation Dataset loads indefinitely.\r\n```python\r\ntrain_dataset = dataset.take(n_train_items)\r\nval_dataset = dataset.skip(n_train_items)\r\n```\r\nCalling `next(iter(train_dataset .take(1)))` works calling `next(iter(val_dataset .take(1)))` loads indefinitely.\r\n\r\n\r\n**Describe the expected behavior**\r\nI want my Validation Dataset to just return Data as expected. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): -\r\n- Briefly describe your candidate solution(if contributing): -\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nNotebook, that Produces the Issue: https://colab.research.google.com/drive/1w5RQDp6W3Zyu4p1kEBRlHT2Vl9zvxVOk?usp=sharing\r\n\r\nStackoverflow Post: https://stackoverflow.com/questions/69634758/reading-validation-dataset-takes-indefinitely-long\r\nThe Problem is withing `prep_image`, when i just return the Filename without opening the Data everything works as expected:\r\n\r\n```python\r\ndef prep_image(filename, img_shape=(144,144), channels=3, dtype=tf.float32):\r\n    return filename\r\n#    image_string = tf.io.read_file(filename)\r\n#    image = tf.image.decode_jpeg(image_string, channels=channels)\r\n#    image = tf.image.convert_image_dtype(image, dtype)\r\n#    image = tf.image.resize(image, img_shape)\r\n#    return image\r\n```\r\nIf i just return the Output of `tf.io.read_file` the first item of the Validation-Dataset already loads indefinitely:\r\n```python\r\ndef prep_image(filename, img_shape=(144,144), channels=3, dtype=tf.float32):\r\n    return tf.io.read_file(filename)\r\n```\r\n\r\nEdit:// Loading the First Train-Dataset Item Takes:\r\n`0:00:00.063014`  `HH:MM:SS:ms`\r\nand getting the first Validation item takes:\r\n`0:31:09.717694`\r\n\r\n", "comments": ["@Saduf2019 ,\r\nI was able to reproduce the issue in tf [v2.6](https://colab.research.google.com/gist/tilakrayal/f942af07c7c2a8c88815700941c8ebdb/2-6minimal_sample.ipynb), v2.5 and [nightly](https://colab.research.google.com/gist/tilakrayal/e1600c211b2f17c1faf7d9837e71c80a/minimal_sample.ipynb).Please find the gist.", "Any ideas on how I can work around the problem in the meantime?", "?"]}, {"number": 52576, "title": "[TFLite] Add int16x8 support for SPACE_TO_BATCH_ND and BATCH_TO_SPACE operators", "body": "Hello,\r\n\r\nThis PR adds int16x8 support for SPACE_TO_BATCH_ND and BATCH_TO_SPACE operators.\r\n\r\nThanks,\r\nJohan.", "comments": ["@miaout17 Can you please review this PR ? Thanks!", "@miaout17 Can you please review this PR ? Thanks!", "@miaout17 Can you please review this PR ? Thanks!", "@johan-gras Can you please sign CLA. Thank you!"]}, {"number": 52573, "title": "Crash with camera2api due to unsupported ImageFormat.YUV_420_888", "body": "### Reproducible example\r\nExample project from https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/android crashes after allowing camera permission due to:\r\n```bash\r\norg.tensorflow.lite.examples.poseestimation W/CameraDevice-JV-4: Stream configuration failed due to: createSurfaceFromGbp:1583: Camera 4: No supported stream configurations with format 0x23 defined, failed to create output stream\r\n```\r\n\r\n### Adbcat error log\r\n\r\nFrom start to crash:\r\nhttps://gist.githubusercontent.com/xRiot/f50680c94ec65dfdfae52fda609665b7/raw/aa95bf99362751f1af6d2e53fb20bfc9168c4bdc/gistfile1.txt\r\n\r\n### Environment\r\nThis issue is specific to Android 11 on Samsung Galaxy s20+\r\n\r\n### Source of the issue\r\n\r\nThis line causes the error, it seems like `YUV_420_888` is not supported on my particular device:\r\n```kotlin\r\nImageReader.newInstance(PREVIEW_WIDTH, PREVIEW_HEIGHT, ImageFormat.YUV_420_888, 3)\r\n```\r\n", "comments": ["Just noticed that TFLite posenet example project runs fine on Samsung Galaxy s20+ with the older Android camera api from: https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/android", "For reference, I tried all available `ImageFormat` formats from `~/Android/Sdk/sources/android-30/android/graphics/ImageFormat.java`:\r\n\r\n> UNKNOWN - detected\r\n> RGB_565 - No supported stream configurations with format 0x4 defined\r\n> YV12 - No supported stream configurations with format 0x32315659 defined\r\n> Y8 - No supported stream configurations with format 0x20203859 defined\r\n> Y16 - Unresolved reference\r\n> NV16 - detected\r\n> NV21 - detected\r\n> YUY2 - No supported stream configurations with format 0x14 defined\r\n> JPEG - No supported stream configurations with format 0x21 defined\r\n> DEPTH_JPEG - No supported stream configurations with format 0x21 defined\r\n> YUV_420_888 - No supported stream configurations with format 0x23 defined\r\n> YUV_422_888 - detected\r\n> YUV_444_888 - detected\r\n> FLEX_RGB_888 - detected\r\n> FLEX_RGBA_8888 - detected\r\n> RAW_SENSOR - No supported stream configurations with format 0x20 defined\r\n> RAW_PRIVATE - No supported stream configurations with format 0x24 defined\r\n> RAW10 - No supported stream configurations with format 0x25 defined\r\n> RAW12 - No supported stream configurations with format 0x26 defined\r\n> DEPTH16 - detected\r\n> DEPTH_POINT_CLOUD - No supported stream configurations with format 0x21 defined\r\n> RAW_DEPTH - Unresolved reference\r\n> PRIVATE - detected\r\n> HEIC - No supported stream configurations with format 0x21 defined"]}, {"number": 52520, "title": "Document whether the GPU execution of concrete functions are asynchronous", "body": "## URL(s) with the issue:\r\n- https://www.tensorflow.org/guide/eager#performance\r\n- https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed-up\r\n- https://www.tensorflow.org/api_docs/python/tf/experimental/async_scope\r\n\r\n## Description of issue (what needs changing):\r\nThe comment in the example code at https://www.tensorflow.org/guide/eager#performance states:\r\n```\r\n# tf.matmul can return before completing the matrix multiplication\r\n# (e.g., can return after enqueing the operation on a CUDA stream).\r\n# The x.numpy() call below will ensure that all enqueued operations\r\n# have completed\r\n```\r\n\r\nIn contrast, the benchmark script at https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed-up do not contain the `numpy()` call:\r\n\r\n```python\r\ndef power(x, y):\r\n  result = tf.eye(10, dtype=tf.dtypes.int32)\r\n  for _ in range(y):\r\n    result = tf.matmul(x, result)\r\n  return result\r\n\r\nprint(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))\r\n\r\npower_as_graph = tf.function(power)\r\nprint(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))\r\n```\r\n\r\nIs the second example correct, don't we need a `numpy()` call to ensure that the computation is completed?\r\n\r\n### Improve the documentation of graph function execution\r\n\r\nWhile reading through the guides https://www.tensorflow.org/guide/intro_to_graphs#graph_execution_vs_eager_execution and https://www.tensorflow.org/guide/function, I did not find any reference to the possibly asynchronous nature of function execution.\r\n\r\nCan we improve the guide by stating that \r\n```\r\nA graph function can return before completing the computation (e.g., can return after enqueing the operation on a CUDA stream).\r\n```\r\n~~If this is not the case, then can we state that explicitly?~~\r\n\r\n### async_scope\r\n\r\nThe description at https://www.tensorflow.org/api_docs/python/tf/experimental/async_scope mentions that \"function calls inside the scope can return before finishing the actual execution. \". But looking into the source code indicates that the scope controls whether remote executions are synchronous.\r\n\r\nWhat is the status with a function execution on a local GPU? Is that affected by this scope? Could you expand the docstring with this information?\r\n\r\n", "comments": ["It seems, that there is a difference in terminology what do we mean by \"synchronous\". `async_scope`, or `tf.config.experimental.set_synchronous_execution` use a different meaning, compared to what we use in CUDA terminology.\r\n\r\nFor reference: [async_wait](https://github.com/tensorflow/tensorflow/blob/2f73ac99e94c1e0c8a8b6ce0efdb3d11b834fe3d/tensorflow/python/eager/context.py#L2571) (used by `set_synchronous_execution` ) is calling [SyncExecutors](https://github.com/tensorflow/tensorflow/blob/2f73ac99e94c1e0c8a8b6ce0efdb3d11b834fe3d/tensorflow/core/common_runtime/eager/context.cc#L929) which uses WaitForAllPendingNodes. The C wrapper has the [following docstring](https://github.com/tensorflow/tensorflow/blob/799eb5181378cbdbcf77002366f89d99e805c803/tensorflow/c/eager/c_api_experimental.h#L346-L353):\r\n```\r\n// Causes the calling thread to block till all ops dispatched in this executor\r\n// have been executed. Note that \"execution\" here refers to kernel execution /\r\n// scheduling of copies, etc. Similar to sync execution, it doesn't guarantee\r\n// that lower level device queues (like GPU streams) have been flushed.\r\n```\r\n\r\nIn contrast, in the context of GPU programming, when we mention synchronous or asynchronous kernel execution, we refer to synchronization between [host and device](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#concurrent-execution-host-device).\r\n\r\nFor those who are benchmarking performance of TF models, it would be very useful if the doc clarifies this difference.", "> In contrast, the benchmark script at https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed-up do not contain the `numpy()` call\r\n> [...]\r\n> Is the second example correct, don't we need a `numpy()` call to ensure that the computation is completed?\r\n\r\nI have run some benchmarks with Nsight profiling tools to investigate this, and we do need a `numpy()` call. Otherwise the measured time only corresponds to the launch time. I have also confirmed that `set_synchronous_execution` and `async_scope` do not affect GPU synchronicity.\r\n\r\n(measured time without `numpy()` call highlighted in green)\r\n\r\n![2021-10-18_tftrt_bench_tl_nosync](https://user-images.githubusercontent.com/17441062/138310961-0b208f54-519f-457d-8298-baaa52386ad5.PNG)\r\n\r\n\r\n", "Since in the document https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed-up, it is the comparison between eager and `tf.function`, if you use numpy() it will throw error, since `numpy()` is not supposed to be used in the graph mode or inside tf.function.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thank you @sachinprasadhs for the answer. If we want to compare performance of any calculation, we need to ensure that the calculation is finished. The question of this issue: how to ensure that the calculation is finished when we are working with GPU kernels. For the https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed-up link, this is how to insert the numpy calls to ensure synchronization:\r\n\r\n```python\r\ndef power(x, y):\r\n  result = tf.eye(10, dtype=tf.dtypes.int32)\r\n  for _ in range(y):\r\n    result = tf.matmul(x, result)\r\n  return result\r\n\r\nprint(\"Eager execution:\", timeit.timeit(lambda: power(x, 100)[0].numpy(), number=1000))\r\n\r\npower_as_graph = tf.function(power)\r\nprint(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100)[0].numpy(), number=1000))\r\n```"]}, {"number": 52465, "title": "[tensorflow/compiler/jit/test_util.cc] Add calls to `reserve()` before populating vector", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": ["@gbaned @jpienaar Any issue with this PR?", "@jpienaar Can you please review this PR ? Thanks!", "@jpienaar Can you please review this PR ? Thanks!", "@jpienaar Can you please review this PR ? Thanks!", "@jpienaar Can you please review this PR ? Thanks!"]}, {"number": 52464, "title": "[tensorflow/compiler/jit/increase_dynamism_for_auto_jit_pass.cc] Use correct size type for `NumElements` iterator", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": ["@gbaned @jpienaar Any issue with this PR?", "@jpienaar Can you please review this PR ? Thanks!"]}, {"number": 52392, "title": " Compiling test case failure [TensorFlow Lite]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.4.3\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):  gcc 7.5.0\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n1. configure\r\n\r\n```bash\r\n./configure\r\n```\r\noutput\r\n\r\n```bash\r\nYou have bazel 3.1.0 installed.\r\nPlease specify the location of python. [Default is /media/envs/miniconda/envs/tf2.x/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /media/xx/code/AnimaX\r\n  /media/envs/miniconda/envs/tf2.x/lib/python3.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/media/xx/code/AnimaX]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y\r\nSearching for NDK and SDK installations.\r\n\r\nPlease specify the home path of the Android NDK to use. [Default is /home/xx/Android/Sdk/ndk-bundle]: /home/xx/Android/Sdk/ndk/18.1.5063045\r\n\r\n\r\nPlease specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28']] [Default is 21]: \r\n\r\n\r\nPlease specify the home path of the Android SDK to use. [Default is /home/xx/Android/Sdk]: \r\n\r\n\r\nPlease specify the Android SDK API level to use. [Available levels: ['19', '30']] [Default is 30]: \r\n\r\n\r\nPlease specify an Android build tools version to use. [Available versions: ['19.1.0', '30.0.2']] [Default is 30.0.2]: \r\n\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=mkl_aarch64 \t# Build with oneDNN support for Aarch64.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n```\r\n\r\n2. build\r\n\r\n```bash\r\nbash tensorflow/lite/tools/build_aar.sh\r\n```\r\n\r\nwithout any exception.\r\n\r\n3. test\r\n\r\n```bash\r\nbazel build -c opt  //tensorflow/lite/kernels:reverse_test\r\n```\r\n\r\noutput\r\n\r\n```bash\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=146\r\nINFO: Reading rc options for 'build' from /media/xx/libraries/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /media/xx/libraries/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /media/xx/libraries/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/media/envs/miniconda/envs/tf2.x/bin/python3 --action_env PYTHON_LIB_PATH=/media/xx/code/AnimaX --python_path=/media/envs/miniconda/envs/tf2.x/bin/python3 --action_env PYTHONPATH=/media/envs/install/pangolin/lib/python3.7/dist-packages:/media/envs/install/g2o/lib/python3.7/dist-packages:/media/envs/install/nvtop/lib/python3.7/dist-packages:/media/envs/install/ceres-solver/lib/python3.7/dist-packages:/media/envs/install/vtk/lib/python3.7/dist-packages:/media/envs/install/protobuf/lib/python3.7/dist-packages:/media/envs/install/opencv/lib/python3.7/dist-packages:/media/envs/install/cmake/lib/python3.7/dist-packages:/media/envs/install/openmpi/lib/python3.7/dist-packages:/media/envs/install/pangolin/lib/python3.7/dist-packages:/media/envs/install/g2o/lib/python3.7/dist-packages:/media/envs/install/nvtop/lib/python3.7/dist-packages:/media/envs/install/ceres-solver/lib/python3.7/dist-packages:/media/envs/install/vtk/lib/python3.7/dist-packages:/media/envs/install/protobuf/lib/python3.7/dist-packages:/media/envs/install/opencv/lib/python3.7/dist-packages:/media/envs/install/cmake/lib/python3.7/dist-packages:/media/envs/install/openmpi/lib/python3.7/dist-packages::/media/xx/code/AnimaX:/media/xx/code/AnimaX --config=xla --action_env ANDROID_NDK_HOME=/home/xx/Android/Sdk/ndk/18.1.5063045 --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=30.0.2 --action_env ANDROID_SDK_API_LEVEL=30 --action_env ANDROID_SDK_HOME=/home/xx/Android/Sdk --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /media/xx/libraries/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /media/xx/libraries/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /media/xx/libraries/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:linux in file /media/xx/libraries/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /media/xx/libraries/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Build options --cxxopt, --fat_apk_cpu, and --host_crosstool_top have changed, discarding analysis cache.\r\nINFO: Analyzed target //tensorflow/lite/kernels:reverse_test (26 packages loaded, 3873 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /media/xx/libraries/tensorflow/tensorflow/lite/kernels/internal/BUILD:720:1: C++ compilation of rule '//tensorflow/lite/kernels/internal:kernel_utils' failed (Exit 1)\r\nIn file included from tensorflow/lite/kernels/internal/kernel_utils.cc:19:0:\r\n./tensorflow/lite/kernels/internal/tensor_utils.h: In function 'void tflite::tensor_utils::ApplyTanhToVector(const float*, int, float*)':\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:550:39: error: 'Vector' is not a member of 'Eigen'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:550:39: note: suggested alternative: 'VectorXd'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n                                       VectorXd\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:550:39: error: 'Vector' is not a member of 'Eigen'\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:550:39: note: suggested alternative: 'VectorXd'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n                                       VectorXd\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:550:67: error: template argument 1 is invalid\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                                                   ^~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:551:3: error: 'VectorMap' was not declared in this scope\r\n   VectorMap input_map(const_cast<float* __restrict__>(vector), v_size);\r\n   ^~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:551:3: note: suggested alternative: 'vector'\r\n   VectorMap input_map(const_cast<float* __restrict__>(vector), v_size);\r\n   ^~~~~~~~~\r\n   vector\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:552:13: error: expected ';' before 'output_map'\r\n   VectorMap output_map(result, v_size);\r\n             ^~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:553:3: error: 'output_map' was not declared in this scope\r\n   output_map.array() = input_map.array().tanh();\r\n   ^~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:553:24: error: 'input_map' was not declared in this scope\r\n   output_map.array() = input_map.array().tanh();\r\n                        ^~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h: In function 'void tflite::tensor_utils::ApplySigmoidToVector(const float*, int, float*)':\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:567:39: error: 'Vector' is not a member of 'Eigen'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:567:39: note: suggested alternative: 'VectorXd'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n                                       VectorXd\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:567:39: error: 'Vector' is not a member of 'Eigen'\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:567:39: note: suggested alternative: 'VectorXd'\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                       ^~~~~~\r\n                                       VectorXd\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:567:67: error: template argument 1 is invalid\r\n   using VectorMap = Eigen::Map<Eigen::Vector<float, Eigen::Dynamic>>;\r\n                                                                   ^~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:568:3: error: 'VectorMap' was not declared in this scope\r\n   VectorMap input_map(const_cast<float* __restrict__>(vector), v_size);\r\n   ^~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:568:3: note: suggested alternative: 'vector'\r\n   VectorMap input_map(const_cast<float* __restrict__>(vector), v_size);\r\n   ^~~~~~~~~\r\n   vector\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:569:13: error: expected ';' before 'output_map'\r\n   VectorMap output_map(result, v_size);\r\n             ^~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:570:3: error: 'output_map' was not declared in this scope\r\n   output_map.array() = input_map.array().logistic();\r\n   ^~~~~~~~~~\r\n./tensorflow/lite/kernels/internal/tensor_utils.h:570:24: error: 'input_map' was not declared in this scope\r\n   output_map.array() = input_map.array().logistic();\r\n                        ^~~~~~~~~\r\nTarget //tensorflow/lite/kernels:reverse_test failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 4.225s, Critical Path: 1.62s\r\nINFO: 27 processes: 27 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@KangGrandesty \r\nCould you please try on 2.5/2.6 and let us know if you still face the issue.", "- [x] v2.5.0\r\n- [x] v2.6.0\r\n- [x] v2.7.0-rc0\r\n- [x] nightly\r\n\r\nAll checked tags&branches occur the same excpetion.\r\n\r\n@Saduf2019 "]}, {"number": 52388, "title": "tf.image.non_max_suppression_padded returns dynamic-sized tensors: fails on TFlite GPU Delegate", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Mobile device: Snapdragon 845 (Pixel 3, Galaxy S9)\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nExporting `tf.image.non_max_suppression_padded` to tflite yields a model that fails to run on the TFlite GPU delegate:\r\n```\r\n$ ./android_aarch64_benchmark_model --use_gpu=true --graph=nms (3).tflite                                                                       \r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [nms (3).tflite]\r\nUse gpu: [1]\r\nLoaded model nms (3).tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\nFailed to apply GPU delegate.\r\nBenchmarking failed.\r\n```\r\n\r\n**Describe the expected behavior**\r\nCompared to `tf.image.non_max_suppression`, `tf.image.non_max_suppression_padded` should not return dynamic-sized tensors, and should therefore be able to run on the GPU delegate.\r\n\r\n**Standalone code to reproduce the issue**\r\nCollab to reproduce model:\r\nhttps://colab.research.google.com/drive/14KIEfiNIHB9q2erUgHs3uwEY4mxvgGeU?usp=sharing\r\n\r\nModel:\r\n[nms (3).tflite.zip](https://github.com/tensorflow/tensorflow/files/7355110/nms.3.tflite.zip)\r\n\r\n\r\nBenchmarking tool:\r\n[android_aarch64_benchmark_model.zip](https://github.com/tensorflow/tensorflow/files/7349358/android_aarch64_benchmark_model.zip)\r\n(source: https://www.tensorflow.org/lite/performance/measurement#download_or_build_the_binary )\r\n\r\n![image](https://user-images.githubusercontent.com/20094729/137530204-f1bd75d0-44b2-40e5-bfa2-d4d944f91f31.png)\r\n\r\n\r\n\r\n", "comments": ["A few things:\r\n\r\n1. Your script does not use `tf.image.non_max_suppression_padded`, am I missing something?\r\n2. Once you use nms padded as suggested above, please set `pad_to_max_output_size=True` in the arguments to `non_max_suppression_padded`. Also set `batch_size=1` in `keras.Input`.", "@srjoglekar246 My apologies, I was linking an older version of the collab. I've updated the code w/ `batch_size=1` and I've also simplified the model so that it now contains solely the `non_max_suppression_padded` operation. \r\n\r\nThe code, model, logs, and diagram are now up-to-date, but the error message remains the same. Please let me know if I'm still missing anything.", "Hi @alexdwu13!\r\nCould you please share the above notebook as Colab gist as it will help expedite the issue..Attaching similar issues  for reference [link1](https://github.com/tensorflow/tensorflow/issues/46388#issuecomment-871074251),[link2](https://github.com/tensorflow/tensorflow/issues/49224),[link3](https://stackoverflow.com/questions/60826779/valueerror-none-is-only-supported-in-the-1st-dimension-tensor-flatbuffer-data/60869999#60869999). Thanks!", "@mohantym https://gist.github.com/alexdwu13/cb08ceea33c546c1fcabac3b1b6b0c25 "]}, {"number": 52357, "title": "different output value in pytorch->onnx->tflite(int8 quantization)", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): tensorflow:2.5.0-gpu docker\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2/ 8.1.0\r\n- GPU model and memory: RTX 3090\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI convert resnet50 pytorch -> onnx -> tflite with int8 quantization.\r\noutput value validation between pytorch <-> onnx, pytorch <-> pb, pytorch <-> tflite, pb <-> tflite\r\ninput is same image with size 256, check output value \"np.testing.assert_allclose(output1, output2, rtol=1e-3, atol=1e-05)\"\r\n(using tflite interpreter only when i inference tflite \"https://www.tensorflow.org/lite/guide/python?hl=ko\")\r\n\r\nMax absolute difference: 0.00076199 in pytorch <-> onnx\r\nMax absolute difference: 0.00112534 in pytorch <-> pb\r\nMax absolute difference: 13.387602 in pytorch <-> tflite(quantized)\r\nMax absolute difference: 13.387438 in pb <-> tflite(quantized)\r\nit's same max absolute difference between tflite(no quantized) and something(pytorch, onnx, pb)\r\nex) 0.0076~ in pytorch <-> tflite(no quant), 0.0011~ in pytorch <-> tflite(no quant)\r\ni don't know why occur this difference\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n**pb to tflite log**\r\n2021-10-13 09:18:56.162936: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-13 09:18:57.485452: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-10-13 09:18:57.511230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.511916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.68GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-10-13 09:18:57.511955: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-13 09:18:57.513717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2021-10-13 09:18:57.513767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2021-10-13 09:18:57.514354: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2021-10-13 09:18:57.514537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2021-10-13 09:18:57.515198: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\r\n2021-10-13 09:18:57.515720: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2021-10-13 09:18:57.515866: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2021-10-13 09:18:57.515918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.516398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.516976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-10-13 09:18:57.517199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-10-13 09:18:57.517766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.518224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.68GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-10-13 09:18:57.518272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.518814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.519243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-10-13 09:18:57.519268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-13 09:18:57.810376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-10-13 09:18:57.810410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-10-13 09:18:57.810420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2021-10-13 09:18:57.810591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.811162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.811684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:57.812186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21512 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2021-10-13 09:18:58.498192: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\r\n2021-10-13 09:18:58.498225: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\r\n2021-10-13 09:18:58.498234: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\r\n2021-10-13 09:18:58.498881: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: backbone_saved_model/\r\n2021-10-13 09:18:58.515289: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n2021-10-13 09:18:58.515331: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: backbone_saved_model/\r\n2021-10-13 09:18:58.515383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-10-13 09:18:58.515393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \r\n2021-10-13 09:18:58.527926: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2021-10-13 09:18:58.546224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\r\n2021-10-13 09:18:58.563849: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: backbone_saved_model/\r\n2021-10-13 09:18:58.577967: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 79088 microseconds.\r\n2021-10-13 09:18:58.657933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2021-10-13 09:18:58.675431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:58.675985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.68GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-10-13 09:18:58.676068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:58.676635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:58.677107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-10-13 09:18:58.677148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-10-13 09:18:58.677157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-10-13 09:18:58.677165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2021-10-13 09:18:58.677253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:58.677779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-13 09:18:58.678280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21512 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\nfully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\r\n", "comments": ["@JunhoohnuJ \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "#**1. \"\"\"make input\"\"\"**\r\n\r\nimport numpy as np\r\nnp.save('input.npy', np.random.rand(1, 3, 256, 256))\r\n\"\"\"end make\"\"\"\r\n\r\n\r\n#**2. \"\"\"pytorch to onnx\"\"\"**\r\n\r\nimport torch\r\nfrom torch import nn\r\nfrom torchvision.models import resnet50\r\n\r\nmodel = resnet50(pretrained=True)\r\ntorch_model = nn.Sequential(*[model.layer1, model.layer2, model.layer3, model.layer4])\r\ntorch_model = torch_model.cuda()\r\n\r\nx = np.load('input.npy')\r\nx = torch.tensor(x, dtype=torch.float32).cuda()\r\nwith torch.no_grad():\r\n    coord = torch_model(x)\r\n    out = coord.detach().cpu().numpy()\r\n    np.save('output_pytorch.npy', out)\r\n\r\ntorch.onnx.export(torch_model,\r\n                  x,\r\n                  \"backbone.onnx\",\r\n                  export_params=True, \r\n                  opset_version=12, \r\n                  input_names=['input'],\r\n                  output_names=['output'], \r\n                  keep_initializers_as_inputs=True,\r\n                  # dynamic_axes={'input': {0: 'batch_size'}\r\n                  )\r\n\r\n#**3. \"\"\"onnx runtime\"\"\"**\r\nimport onnxruntime\r\nimport onnxruntime.tools\r\nimport onnxruntime as ort\r\n\r\nx = np.load('input.npy')\r\noutput_torch = np.load('output_pytorch.npy')\r\nort.set_default_logger_severity(0)\r\noptions = ort.SessionOptions()\r\nort_session = onnxruntime.InferenceSession(\"backbone.onnx\", options)\r\nort_inputs = {ort_session.get_inputs()[0].name: x}\r\nonnxOut = ort_session.run(None, ort_inputs)\r\nnp.save('output_onnx.npy', onnxOut[0])\r\nnp.testing.assert_allclose(output_pytorch, onnxOut[0], rtol=1e-3, atol=1e-05)\r\n\r\n\r\n\r\n#**4. \"\"\"onnx to pb\"\"\"**\r\nimport numpy as np\r\nimport onnx\r\nimport tensorflow as tf\r\nfrom onnx_tf.backend import prepare\r\nimport os\r\n\r\nonnx_model = onnx.load(\"backbone.onnx\")\r\ntf_model_path = \"backbone_saved_model\"\r\n\r\ntf_rep = prepare(onnx_model)\r\ntf_rep.export_graph(tf_model_path)\r\nprint('saved model')\r\n\r\nmodel = tf.saved_model.load(tf_model_path)\r\nmodel.trainable = False\r\nprint('load model')\r\n\r\nx = np.load('input.npy')\r\nout = model(**{'input': x})\r\n\r\noutput_pytorch = np.load('output_pytorch.npy')\r\nnp.save('output_pb.npy', out)\r\nnp.testing.assert_allclose(out, output_pytorch, rtol=1e-3, atol=1e-05)\r\nprint(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\r\n\r\n\r\n#**5. \"\"\"pb to tflite\"\"\"**\r\nimport onnx\r\nfrom onnx_tf.backend import prepare\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\nimport os\r\nimport torchvision.transforms as transforms\r\nimport time\r\n\r\ninput_shape = (3, 256, 256)\r\n\r\ndef representative_data_gen():\r\n    a = []\r\n    pixel_mean = (0.485, 0.456, 0.406)\r\n    pixel_std = (0.229, 0.224, 0.225)\r\n    # COCO dataset\r\n    datapath = \"/nvme1/datasets/COCO/val2017/\"     ########### need to change\r\n    file_list = os.listdir(datapath)\r\n    for i in range(160):\r\n        img = cv2.imread(os.path.join(datapath, file_list[i]))\r\n        img = cv2.resize(img, (256, 256))\r\n        transform = transforms.Compose(\r\n            [transforms.ToTensor(), transforms.Normalize(mean=pixel_mean, std=pixel_std)])\r\n        img = transform(img).numpy()\r\n        img = img.astype(np.float32)\r\n        a.append(img)\r\n    a = np.array(a)\r\n    img = tf.data.Dataset.from_tensor_slices(a).batch(1).take(100)\r\n    for i in img.take(1):\r\n        print(i)\r\n        yield [i]\r\n\r\n\r\ntf_model_path = \"backbone_saved_model/\"\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset=representative_data_gen\r\ntflite_model = converter.convert()\r\ntflite_model_path = \"backbone.tflite\"\r\n\r\nwith open(tflite_model_path, 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n\r\n#**6. \"\"\"inference tflite\"\"\"**\r\nimport tflite_runtime.interpreter as tflite\r\nimport numpy as np\r\n\r\npose_post_model_file = 'backbone.tflite'\r\n\r\ninterpreter = tflite.Interpreter(model_path=pose_post_model_file)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninput_shape = input_details[0]['shape']\r\n\r\nx = np.load('input.npy')\r\ninterpreter.set_tensor(input_details[0]['index'], x)\r\n\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n\r\noutput_pytorch = np.load('output_pytorch.npy')\r\nnp.save('output_tflite.npy', output_data)\r\nnp.testing.assert_allclose(output_data, output_pytorch, rtol=1e-3, atol=1e-05)\r\nprint(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\r\n\r\n\r\neach output is output_*.npy(* is pytorch, onnx, pb, tflite)\r\n\r\n", "Same issue with custom CenterNet model based on PyTorch. My pipeline for conversion is follows: PyTorch-> ONNX -> Keras -> TFLite. Interestingly, that error(Absolute and squared errors) between output tensors of PyTorch and Keras(after conversion) models is near zero.  But, when conversion from Keras to TFLite is done the error is big. ", "> Same issue with custom CenterNet model based on PyTorch. My pipeline for conversion is follows: PyTorch-> ONNX -> Keras -> TFLite. Interestingly, that error(Absolute and squared errors) between output tensors of PyTorch and Keras(after conversion) models is near zero. But, when conversion from Keras to TFLite is done the error is big.\r\n\r\nthank you for comment. Can you tell me how many errors occurred specificantly?", "@Xhark @liufengdb @ebrevdo @jianlijianli\r\n\r\nI am seeing mobilenet_v2 tflite(quatized) that I generated from pytorch is not working as expected.\r\nand float(32) model seems to be working fine.\r\nMay be I am doing something wrong with Post training quatization,could anyone of you look below Colab/github link and letme know.\r\n\r\n//colab link\r\nhttps://colab.research.google.com/github/nyadla-sys/pytorch_2_tflite/blob/main/pytorch_to_onnx_to_tflite(quantized)_with_imagedata.ipynb\r\n\r\n//github link\r\nhttps://github.com/nyadla-sys/pytorch_2_tflite/blob/main/pytorch_to_onnx_to_tflite(quantized)_with_imagedata.ipynb\r\n", "@Xhark @liufengdb @ebrevdo @jianlijianli : Gentle reminder.!"]}, {"number": 52351, "title": "[TFLite] Add int16x8 support for the MIRROR_PAD operator", "body": "Hello,\r\n\r\nThis PR adds int16x8 support for the MIRROR_PAD operator.\r\n\r\nThanks,\r\nJohan.", "comments": ["@jianlijianli  Can you please review this PR ? Thanks!", "@jianlijianli Can you please review this PR ? Thanks!", "@jianlijianli Can you please review this PR ? Thanks!", "@johan-gras  Can you please sign CLA. Thank you!"]}, {"number": 52344, "title": "Migration script inserts loss_reduction argument", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): using code from OSS repo mentioned below\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): PyPI binary\r\n- TensorFlow version (use command below): 1.15.3\r\n- Python version: 3.7.11\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0.130 / 7.6.5\r\n- GPU model and memory: Tesla T4 16GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nAfter applying the [migration script](https://www.tensorflow.org/guide/migrate/upgrade) `tf_upgrade_v2 ` to [the recommenders repo](https://github.com/microsoft/recommenders/tree/main/recommenders), tests on [this code](https://github.com/microsoft/recommenders/blob/main/recommenders/models/wide_deep/wide_deep_utils.py) \r\nfail with the error\r\n```\r\nE       AttributeError: module 'tensorflow.python.keras.api._v1.keras.losses' has no attribute 'Reduction'\r\n```\r\nThe cause of the error is that the script has inserted an additional argument \r\n`loss_reduction=tf.keras.losses.Reduction.SUM`\r\nin lines https://github.com/microsoft/recommenders/blob/27709229cdc4aa7d39ab715789f093a2d21d2661/recommenders/models/wide_deep/wide_deep_utils.py#L176\r\nhttps://github.com/microsoft/recommenders/blob/27709229cdc4aa7d39ab715789f093a2d21d2661/recommenders/models/wide_deep/wide_deep_utils.py#L186\r\nhttps://github.com/microsoft/recommenders/blob/27709229cdc4aa7d39ab715789f093a2d21d2661/recommenders/models/wide_deep/wide_deep_utils.py#L200\r\n\r\n**Describe the expected behavior**\r\n\r\nIt seems that the migration script should not insert the `loss_reduction` argument in the code. Because after removing this argument the tests pass successfully. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):N/A\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nFrom a conda environment with `python=3.7 cudatoolkit=10.0 \"cudnn>=7\" tensorflow==1.15` do\r\n```\r\ngit clone https://github.com/microsoft/recommenders.git\r\ncd recommenders\r\ntf_upgrade_v2 --intree recommenders --outtree recommenders_v2/recommenders --reportfile recommenders_report.txt\r\ntf_upgrade_v2 --intree tests --outtree recommenders_v2/tests --reportfile tests_report.txt\r\nmv recommenders_v2/recommenders recommenders\r\nmv recommenders_v2/tests tests\r\n```\r\nDeactivate this env and then do\r\n```\r\nconda create -n tf1_15 python=3.7 cudatoolkit=10.0 \"cudnn>=7\"\r\nconda activate tf1_15\r\npip install --upgrade pip setuptools\r\npip install .[gpu,dev]\r\npytest tests/unit/recommenders/models/test_wide_deep_utils.py::test_wide_model\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/7329622/log.txt)\r\n", "comments": ["@anargyri \r\nWe see that you are using a very old version of tensorflow, there is no support for tf 1.x, please upgrade to 2.x and let us know.\r\nyou may also refer to,[link](https://github.com/tensorflow/tensorflow/issues/33356), [link1](https://stackoverflow.com/questions/58384884/tensorflow-python-keras-api-v1-keras-losses-has-no-attribute-reduction).", "Yes, I know. This is what we are trying to do, upgrade to 2.6. \r\nThe issue I report is about the upgrade script, not about TF 1.15. ", "Hi @anargyri, thank you for creating this issue. \r\n\r\nThe main issue here does not seem to be with the loss reduction argument that is being added as that seems to be correct. The issue could be either one of:\r\n\r\n1. Incorrect conversion of imports\r\nOR\r\n2. You might need to run the TF2.x binary on the converted code (if it's a symbol that wasn't in TF 1.15 compat.v2)\r\n\r\nIt most likely is a binaries issue as after conversion, TF is expecting you to be using TF2.x binaries. \r\n\r\nPlease let us know if this helps.", "Hi @anirudh161 \r\nThe issue is about TF1 based on the instructions you have [here](https://www.tensorflow.org/guide/migrate/upgrade#recommended_upgrade_process).\r\nI am talking about step 5: \"Run the converted tests with TensorFlow 1.15: Your code should still run fine in TensorFlow 1.15. Run your unit tests again. Any error in your tests here means there\u2019s a bug in the upgrade script. Please let us know.\"\r\n\r\nI am not blocked by this (since I removed the inserted argument) but I just report the issue following the suggestion \"Please let us know\".\r\n\r\nYou are thinking of step 8, which is not relevant to this issue."]}, {"number": 52343, "title": "Pixel OpenGL only not working", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.6 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel3a\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below):2.4\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source): bazel 3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI have an [application](https://github.com/terryky/android_tflite/tree/master/tflite_dbface) running face detection with c++ on android, and when using default Tensorflow GPU backend (which seems to be OpenCL) everything works fine, but when adding `.experimental_flags = TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY,`  because I have an android device which support only OpenGL drivers (db845c) I get no errors but nothing is displayed on screen and the detection results are 0.\r\n**Describe the expected behavior**\r\nI would expect at least having same error logs when it cannot use OpenGL only as if OpenCL is not supported, GPU Delegate will automatically fall back to OpenGL and run in this problem.\r\n\r\n**Standalone code to reproduce the issue**\r\nCode using to run with OpenGL only: \r\n![Screenshot from 2021-10-12 11-21-18](https://user-images.githubusercontent.com/80002509/136929039-3d5eef9b-2547-410e-af00-0dde7d4a6a7b.png)\r\nThe only difference between apps below is removing `.experimental_flags = TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY,` \r\nI have prebuild the same app in both modes so you can test it easier. Details are in the name of the application. \r\n[face_detection_gpu.zip](https://github.com/tensorflow/tensorflow/files/7328587/face_detection_gpu.zip)\r\n\r\n\r\n**Other info / logs** \r\nThis are logs that I get from Pixel3a when running model with OpenGL only.\r\n[pixel3a.txt](https://github.com/tensorflow/tensorflow/files/7328564/pixel3a.txt)\r\nModel used in this app: \r\n[dbface_keras_480x640_float32_nhwc.zip](https://github.com/tensorflow/tensorflow/files/7328651/dbface_keras_480x640_float32_nhwc.zip)\r\n", "comments": ["@impjdi any idea on this ?", "For OpenGL, it's important that you're using the same thread.  You can't initialize the OpenGL backend with thread 123, and then run inference with thread 456; it has to be thread 123.  Can you check?", "<img width=\"427\" alt=\"Screen Shot 2021-10-18 at 11 12 46\" src=\"https://user-images.githubusercontent.com/80002509/137702857-0e0c27f0-4e2c-4064-84f4-87d164d05ff8.png\">\r\nNo, I don't think so. All those steps are running in the same thread, I have even tried with an executable build with Bazel and got same results.", "@impjdi since this is affecting a lot of devices ( Devices which doesn't have OpenCL support) did you reproduce this issue? ", "My apologies, this issue dropped off my radar.\r\n\r\n@srjoglekar246 QQ: Is `TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY` properly supported?  Do we have a Pixel 3a we can test it on?"]}, {"number": 52332, "title": "Compiling TF 2.6 in debug mode on Windows env. (unresolved externals)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): r2.6.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.3/8\r\n- GPU model and memory: GTX 1060\r\n\r\n**Describe the current behavior**\r\nI try to compile my example program that utilises TF:\r\n// tensorflow/cc/example/example.cc\r\n\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nint main() {\r\n  using namespace tensorflow;\r\n  using namespace tensorflow::ops;\r\n  Scope root = Scope::NewRootScope();\r\n  // Matrix A = [3 2; -1 0]\r\n  auto A = Const(root, { {3.f, 2.f}, {-1.f, 0.f} });\r\n  // Vector b = [3 5]\r\n  auto b = Const(root, { {3.f, 5.f} });\r\n  // v = Ab^T\r\n  auto v = MatMul(root.WithOpName(\"v\"), A, b, MatMul::TransposeB(true));\r\n  std::vector<Tensor> outputs;\r\n  ClientSession session(root);\r\n  // Run and fetch v\r\n  TF_CHECK_OK(session.Run({v}, &outputs));\r\n  // Expect outputs[0] == [19; -3]\r\n  LOG(INFO) << outputs[0].matrix<float>();\r\n  return 0;\r\n}\r\n\r\nAfter patching few files to allow debug compilation (https://github.com/tensorflow/tensorflow/issues/51799#issuecomment-912567685) all tensorflow libs compile, but the example linkage still fails.\r\n\r\nbazel build --jobs 1 --local_ram_resources=HOST_RAM*.7 -c dbg --config=opt --config=windows --config=cuda --copt=/FS --copt=-nvcc_options=disable-warnings --linkopt=/DEBUG:NONE --strip=never --define=no_tensorflow_py_deps=true -s  --verbose_explanations --subcommands=pretty_print //tensorflow/cc/example:example\r\n\r\nERROR: E:/tensorflow_r2.6_cpp_debug_gpu/tensorflow/cc/example/BUILD:3:13: Linking of rule '//tensorflow/cc/example:example' failed (Exit 1120): link.exe failed: error executing command\r\n  cd E:/tensorflow_r2.6_cpp_debug_gpu/output/fqonm2l5/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/cudnn-11.3-windows-x64-v8.2.0.53\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\\\MSBuild\\Current\\Bin;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.0,7.5,8.0,8.6\r\n    SET TF_CUDA_VERSION=11.3\r\n    SET TF_CUDNN_VERSION=8\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/link.exe @bazel-out/x64_windows-dbg/bin/tensorflow/cc/example/example.exe-2.params\r\nExecution platform: @local_execution_config_platform//:platform\r\n   Creating library bazel-out\\x64_windows-dbg\\bin\\tensorflow\\cc\\example\\example.lib and object bazel-out\\x64_windows-dbg\\bin\\tensorflow\\cc\\example\\example.exp\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'utils.lib(utils.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'captured_function.lib(captured_function.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'arithmetic_optimizer.lib(arithmetic_optimizer.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'memory_optimizer.lib(memory_optimizer.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'pin_to_host_optimizer.lib(pin_to_host_optimizer.obj)'\r\nLINK : warning LNK4217: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'batch_kernels.lo.lib(batch_kernels.obj)' in function '\"void __cdecl tensorflow::`dynamic initializer for 'register_kernel_0''(void)\" (??__Eregister_kernel_0@tensorflow@@YAXXZ)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'window_dataset.lib(window_dataset.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'ragged_tensor_variant.lib(ragged_tensor_variant.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'snapshot_utils.lib(snapshot_utils.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'utils.lib(utils.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'gpu_id_impl.lib(gpu_id_manager.obj)'\r\nLINK : warning LNK4217: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'batch_kernels.lo.lib(batch_kernels.obj)' in function '\"void __cdecl tensorflow::`dynamic initializer for 'register_kernel_1''(void)\" (??__Eregister_kernel_1@tensorflow@@YAXXZ)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'arithmetic_optimizer.lib(arithmetic_optimizer.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'memory_optimizer.lib(memory_optimizer.obj)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'tensor.lo.lib(types.obj)' is imported by 'pin_to_host_optimizer.lib(pin_to_host_optimizer.obj)'\r\nLINK : warning LNK4286: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'traceme_recorder_impl.lo.lib(traceme_recorder.obj)' is imported by 'bfc_allocator.lib(bfc_allocator.obj)'\r\nLINK : warning LNK4217: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'traceme_recorder_impl.lo.lib(traceme_recorder.obj)' is imported by 'batch_kernels.lo.lib(batch_kernels.obj)' in function '\"public: static bool __cdecl tensorflow::profiler::TraceMeRecorder::Active(int)\" (?Active@TraceMeRecorder@profiler@tensorflow@@SA_NH@Z)'\r\nLINK : warning LNK4286: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'traceme_recorder_impl.lo.lib(traceme_recorder.obj)' is imported by 'batch_resource_base.lib(batch_resource_base.obj)'\r\nLINK : warning LNK4286: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'traceme_recorder_impl.lo.lib(traceme_recorder.obj)' is imported by 'snapshot_utils.lib(snapshot_utils.obj)'\r\nLINK : warning LNK4286: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'traceme_recorder_impl.lo.lib(traceme_recorder.obj)' is imported by 'captured_function.lib(captured_function.obj)'\r\nLINK : warning LNK4217: symbol 'TF_DataTypeSize' defined in 'tf_datatype.lo.lib(tf_datatype.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4286: symbol 'TF_DataTypeSize' defined in 'tf_datatype.lo.lib(tf_datatype.obj)' is imported by 'tf_tensor.lib(tf_tensor.obj)'\r\nLINK : warning LNK4217: symbol 'TF_NewStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_NewStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_NewStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_NewStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_DeleteStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_SetStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'tf_tensor.lib(tf_tensor.obj)'\r\nLINK : warning LNK4217: symbol 'TF_SetStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4286: symbol 'TF_SetStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_SetStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_SetStatus' defined in 'tf_status.lib(tf_status.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_GetCode' defined in 'tf_status.lib(tf_status.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4286: symbol 'TF_GetCode' defined in 'tf_status.lib(tf_status.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_GetCode' defined in 'tf_status.lib(tf_status.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_GetCode' defined in 'tf_status.lib(tf_status.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_Message' defined in 'tf_status.lib(tf_status.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_Message' defined in 'tf_status.lib(tf_status.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_Message' defined in 'tf_status.lib(tf_status.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_Message' defined in 'tf_status.lib(tf_status.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_NewOpDefinitionBuilder' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_NewOpDefinitionBuilder' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_NewOpDefinitionBuilder' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_NewOpDefinitionBuilder' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_RegisterOpDefinition' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_RegisterOpDefinition' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_RegisterOpDefinition' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_RegisterOpDefinition' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_OpDefinitionBuilderAddAttr' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddAttr' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddAttr' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddAttr' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_OpDefinitionBuilderAddInput' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddInput' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddInput' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddInput' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_OpDefinitionBuilderAddOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderAddOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_OpDefinitionBuilderSetShapeInferenceFunction' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl RegisterBitcastOp(void)\" (?RegisterBitcastOp@@YAXXZ)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderSetShapeInferenceFunction' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderSetShapeInferenceFunction' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_OpDefinitionBuilderSetShapeInferenceFunction' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_NewShapeHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextGetInput' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextSetOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4286: symbol 'TF_ShapeInferenceContextSetOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_ShapeInferenceContextSetOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_ShapeInferenceContextSetOutput' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextVectorFromSize' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_NewDimensionHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContext_GetAttrType' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextRankKnown' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextWithRankAtLeast' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextDim' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextSubshape' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextSetUnknownShape' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl bitcast_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?bitcast_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_DimensionHandleValueKnown' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_DimensionHandleValue' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextConcatenateShapes' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_DeleteShapeHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteShapeHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteShapeHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)'\r\nLINK : warning LNK4286: symbol 'TF_DeleteShapeHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)'\r\nLINK : warning LNK4217: symbol 'TF_DeleteDimensionHandle' defined in 'ops.lo.lib(ops.obj)' is imported by 'bitcast_op_lib.lo.lib(bitcast.obj)' in function '\"void __cdecl ComputeNewShape(struct TF_ShapeInferenceContext *,struct TF_ShapeHandle *,enum TF_DataType,enum TF_DataType,struct TF_Status *)\" (?ComputeNewShape@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_ShapeHandle@@W4TF_DataType@@2PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextScalar' defined in 'ops.lo.lib(ops.obj)' is imported by 'histogram_summary_op_lib.lo.lib(histogram_summary.obj)' in function '\"void __cdecl histogram_summary_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?histogram_summary_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextScalar' defined in 'ops.lo.lib(ops.obj)' is imported by 'merge_summary_op_lib.lo.lib(merge_summary.obj)' in function '\"void __cdecl merge_summary_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?merge_summary_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_ShapeInferenceContextScalar' defined in 'ops.lo.lib(ops.obj)' is imported by 'summary_op_lib.lo.lib(summary.obj)' in function '\"void __cdecl scalar_summary_shape_inference_fn(struct TF_ShapeInferenceContext *,struct TF_Status *)\" (?scalar_summary_shape_inference_fn@@YAXPEAUTF_ShapeInferenceContext@@PEAUTF_Status@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_NumDims' defined in 'tf_tensor.lib(tf_tensor.obj)' is imported by 'tensor_shape_utils.lib(tensor_shape_utils.obj)' in function '\"class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::ShapeDebugString(struct TF_Tensor *)\" (?ShapeDebugString@tensorflow@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAUTF_Tensor@@@Z)'\r\nLINK : warning LNK4217: symbol 'TF_Dim' defined in 'tf_tensor.lib(tf_tensor.obj)' is imported by 'tensor_shape_utils.lib(tensor_shape_utils.obj)' in function '\"class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::ShapeDebugString(struct TF_Tensor *)\" (?ShapeDebugString@tensorflow@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAUTF_Tensor@@@Z)'\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt32,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt32@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\ntensor_array_ops.lo.lib(tensor_array_ops.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt16,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt16@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QUInt16,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQUInt16@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt8,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt8@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\ntensor_array_ops.lo.lib(tensor_array_ops.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QUInt8,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQUInt8@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\ntensor_array_ops.lo.lib(tensor_array_ops.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nconcat_op.lo.lib(concat_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring,1>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\ntensor_array_ops.lo.lib(tensor_array_ops.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,int,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<int const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<int,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@H$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBH$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@H$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,unsigned char,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned char,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@E$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBE$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@E$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@E@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)depth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::Variant,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::tstring,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,bool,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<bool const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<bool,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@_N$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,bool>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,class std::complex<double>,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double>,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@V?$complex@N@std@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<double> >::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@N@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,class std::complex<float>,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float>,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@V?$complex@M@std@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<float> >::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@M@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,double,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<double,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@N$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBN$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,double>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,float,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<float,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@M$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBM$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@M$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,float>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@M@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,struct Eigen::bfloat16,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::bfloat16 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::bfloat16,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@Ubfloat16@2@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUbfloat16@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Ubfloat16@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,struct Eigen::bfloat16>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Ubfloat16@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,struct Eigen::half,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::half const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::half,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@Uhalf@2@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Uhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,struct Eigen::half>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Uhalf@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,signed char,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<signed char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<signed char,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@C$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBC$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@C$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,short,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<short,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@F$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBF$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@F$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,short>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@F@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,unsigned short,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@G$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBG$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@G$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned short>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@G@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,unsigned int,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned int,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@I$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBI$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@I$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned int>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@I@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,__int64,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<__int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<__int64,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@_J$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,__int64>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_J@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(spacetodepth_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::ThreadPoolDevice,unsigned __int64,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$SpaceToDepthOpFunctor@UThreadPoolDevice@Eigen@@_K$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_K$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_K$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned __int64>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_K@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,5,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,5,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,5,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,5,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,int,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<int const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<int,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@H$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBH$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@H$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::Variant,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,class tensorflow::tstring,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,bool,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<bool const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<bool,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@_N$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,bool>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@_N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,class std::complex<double>,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double>,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@V?$complex@N@std@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class std::complex<double> >::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@V?$complex@N@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,class std::complex<float>,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float>,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@V?$complex@M@std@@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class std::complex<float> >::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@V?$complex@M@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,double,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<double,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@N$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBN$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,double>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,float,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<float,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@M$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBM$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@M$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,float>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@M@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,struct Eigen::bfloat16,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::bfloat16 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::bfloat16,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@Ubfloat16@2@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUbfloat16@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Ubfloat16@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,struct Eigen::bfloat16>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@Ubfloat16@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,struct Eigen::half,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::half const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::half,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@Uhalf@2@$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Uhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,struct Eigen::half>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@Uhalf@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,signed char,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<signed char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<signed char,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@C$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBC$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@C$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,unsigned char,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned char,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@E$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBE$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@E$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned char>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@E@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)depth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,short,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<short,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@F$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBF$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@F$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,short>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@F@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,unsigned short,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@G$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBG$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@G$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned short>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@G@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,unsigned int,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned int,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@I$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBI$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@I$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned int>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@I@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,__int64,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<__int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<__int64,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@_J$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,__int64>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@_J@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ndepth_space_ops.lo.lib(depthtospace_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::ThreadPoolDevice,unsigned __int64,1>::operator()(struct Eigen::ThreadPoolDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DepthToSpaceOpFunctor@UThreadPoolDevice@Eigen@@_K$00@functor@tensorflow@@QEAAXAEBUThreadPoolDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_K$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_K$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned __int64>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@_K@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::PackOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$PackOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\ntensor_array_ops.lo.lib(tensor_array_ops.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\nlist_kernels.lo.lib(list_kernels.obj) : error LNK2001: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)\r\npack_op.lo.lib(pack_op.obj) : error LNK2019: unresolved external symbol \"void __cdecl tensorflow::ConcatGPU<class tensorflow::ResourceHandle>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,2,1,__int64>,16,struct Eigen::MakePointer> *)\" (??$ConcatGPU@VResourceHandle@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function \"public: virtual void __cdecl tensorflow::PackOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$PackOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nresource_variable_ops.lo.lib(resource_variable_ops.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::DenseUpdate<struct Eigen::GpuDevice,class tensorflow::Variant,2>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,1,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$DenseUpdate@UGpuDevice@Eigen@@VVariant@tensorflow@@$01@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@VVariant@tensorflow@@$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EnsureSparseVariableAccess<struct Eigen::GpuDevice,class tensorflow::Variant>(class tensorflow::OpKernelContext *,class tensorflow::Var *)\" (??$EnsureSparseVariableAccess@UGpuDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@YA?AVStatus@0@PEAVOpKernelContext@0@PEAVVar@0@@Z)\r\nself_adjoint_eig_v2_op.lo.lib(self_adjoint_eig_v2_op_gpu.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::UnaryFunctor<struct Eigen::GpuDevice,struct tensorflow::functor::conj<double> >::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<double const ,1,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$UnaryFunctor@UGpuDevice@Eigen@@U?$conj@N@functor@tensorflow@@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@N$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBN$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SelfAdjointEigV2OpGpu<double>::ComputeAsync(class tensorflow::OpKernelContext *,class std::function<void __cdecl(void)>)\" (?ComputeAsync@?$SelfAdjointEigV2OpGpu@N@tensorflow@@UEAAXPEAVOpKernelContext@2@V?$function@$$A6AXXZ@std@@@Z)\r\nself_adjoint_eig_v2_op.lo.lib(self_adjoint_eig_v2_op_gpu.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::UnaryFunctor<struct Eigen::GpuDevice,struct tensorflow::functor::conj<float> >::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<float const ,1,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$UnaryFunctor@UGpuDevice@Eigen@@U?$conj@M@functor@tensorflow@@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@M$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBM$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::SelfAdjointEigV2OpGpu<float>::ComputeAsync(class tensorflow::OpKernelContext *,class std::function<void __cdecl(void)>)\" (?ComputeAsync@?$SelfAdjointEigV2OpGpu@M@tensorflow@@UEAAXPEAVOpKernelContext@2@V?$function@$$A6AXXZ@std@@@Z)\r\nresize_bilinear_op.lo.lib(resize_bilinear_op.obj) : error LNK2019: unresolved external symbol \"public: void __cdecl tensorflow::functor::ResizeBilinearGrad<struct Eigen::GpuDevice,struct Eigen::half>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float const ,4,1,__int64>,16,struct Eigen::MakePointer>,float,float,bool,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::half,4,1,__int64>,16,struct Eigen::MakePointer>)\" (??R?$ResizeBilinearGrad@UGpuDevice@Eigen@@Uhalf@2@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBM$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@MM_NV?$TensorMap@V?$Tensor@Uhalf@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function \"public: virtual void __cdecl tensorflow::ResizeBilinearOpGrad<struct Eigen::GpuDevice,struct Eigen::half>::Compute(class tensorflow::OpKernelContext *)\" (?Compute@?$ResizeBilinearOpGrad@UGpuDevice@Eigen@@Uhalf@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nbazel-out\\x64_windows-dbg\\bin\\tensorflow\\cc\\example\\example.exe : fatal error LNK1120: 51 unresolved externals\r\nTarget //tensorflow/cc/example:example failed to build\r\nINFO: Elapsed time: 67285.637s, Critical Path: 2170.18s\r\nINFO: 12571 processes: 3669 internal, 8902 local.\r\nFAILED: Build did NOT complete successfully", "comments": ["https://github.com/tensorflow/tensorflow/issues/52203#issuecomment-939039663", "Also, https://github.com/tensorflow/tensorflow/issues/52250"]}, {"number": 52330, "title": "Problems to convert a TF model with mutable variables even if I use converter.experimental_enable_resource_variables = True", "body": "### System information\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 20.10\r\n- TensorFlow installation: pip package\r\n- Tensorflow version: 2.6.0\r\n-  Python version: 3.8\r\n\r\nI'm trying to convert a TF model which uses a custom layer where there are some tf.Variable (instead of numpy arrays for partial computations) and for loops statements (not tf.while_loop statements). The model works fine without the custom layer. \r\nIn order to convert the model I use these lines of code:\r\n\r\n    tmpdir = tempfile.mkdtemp()\r\n    model_save_path = os.path.join(tmpdir, \"model/1/\")\r\n    tf.saved_model.save(model, model_save_path) \r\n    \r\n    converter = tf.lite.TFLiteConverter.from_saved_model(model_save_path)\r\n    converter.target_spec.supported_ops = [\r\n       tf.lite.OpsSet.TFLITE_BUILTINS, \r\n       tf.lite.OpsSet.SELECT_TF_OPS \r\n    ]\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    tflite_model = converter.convert()\r\n    with open('model.tflite', 'wb') as f:\r\n       f.write(tflite_model)\r\n\r\nHowever I get this error:\r\n    \r\n    WARNING:absl:Found untraced functions such as mylayer_layer_call_and_return_conditional_losses, mylayer_layer_call_fn,     \r\n    mylayer_layer_call_fn, mylayer_layer_call_and_return_conditional_losses, mylayer_layer_call_and_return_conditional_losses    \r\n    while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\n    2021-10-11 19:37:04.586845: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\r\n    2021-10-11 19:37:04.586883: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored     \r\n    drop_control_dependency.\r\n    2021-10-11 19:37:04.586892: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored   \r\n    change_concat_input_ranges.\r\n    2021-10-11 19:37:04.587804: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /tmp/tmp332hc4f9  \r\n    /model/1/\r\n    2021-10-11 19:37:04.647880: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n    2021-10-11 19:37:04.647960: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from:     \r\n    /tmp/tmp332hc4f9/model/1/\r\n    2021-10-11 19:37:04.990385: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\r\n    2021-10-11 19:37:05.508553: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at   \r\n    path: /tmp/tmp332hc4f9/model/1/\r\n    2021-10-11 19:37:05.985453: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: \r\n    OK. Took 1397650 microseconds.\r\n    2021-10-11 19:37:07.818608: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash \r\n    reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n    loc(\"module_wrapper/mylayer/Variable\"): error: is not immutable, try removing mutable variables in your model since mutable \r\n    variables are currently not supported through this converter\r\n    Traceback (most recent call last):\r\n    File \"model.py\", line 231, in <module>\r\n    tflite_model = converter.convert()\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 729, in wrapper\r\n    return self._convert_and_export_metrics(convert_func, *args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 715, in _convert_and_export_metrics\r\n    result = convert_func(self, *args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 994, in convert\r\n    result = _convert_saved_model(**converter_kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 215, in wrapper\r\n    raise converter_error from None  # Re-throws the exception.\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 208, in wrapper\r\n    return func(*args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 821, in convert_saved_model\r\n    data = toco_convert_protos(\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert.py\", line 313, in toco_convert_protos\r\n    raise converter_error\r\n    tensorflow.lite.python.convert_phase.ConverterError: <unknown>:0: error: loc(\"module_wrapper/mylayer/Variable\"): is not   \r\n    immutable, try removing mutable variables in your model since mutable variables are currently not supported through this    \r\n    converter\r\n\r\nInstead, if I add this line:\r\n  \r\n    converter.experimental_enable_resource_variables =True\r\n\r\nI get this:\r\n\r\n    WARNING:absl:Found untraced functions such as mylayer_layer_call_and_return_conditional_losses, mylayer_layer_call_fn,     \r\n    mylayer_layer_call_fn, mylayer_layer_call_and_return_conditional_losses, mylayer_layer_call_and_return_conditional_losses    \r\n    while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\n    2021-10-11 19:37:04.586845: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\r\n    2021-10-11 19:37:04.586883: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored     \r\n    drop_control_dependency.\r\n    2021-10-11 19:37:04.586892: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored   \r\n    change_concat_input_ranges.\r\n    2021-10-11 19:37:04.587804: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: /tmp/tmp332hc4f9  \r\n    /model/1/\r\n    2021-10-11 19:37:04.647880: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n    2021-10-11 19:37:04.647960: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from:     \r\n    /tmp/tmp332hc4f9/model/1/\r\n    2021-10-11 19:37:04.990385: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\r\n    2021-10-11 19:37:05.508553: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at   \r\n    path: /tmp/tmp332hc4f9/model/1/\r\n    2021-10-11 19:37:05.985453: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: \r\n    OK. Took 1397650 microseconds.\r\n    2021-10-11 19:37:07.818608: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash \r\n    reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n\r\n    segmentation fault (core dumped)\r\n\r\nWith these lines:\r\n\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.target_spec.supported_ops = [\r\n       tf.lite.OpsSet.TFLITE_BUILTINS, \r\n       tf.lite.OpsSet.SELECT_TF_OPS \r\n    ]\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    tflite_model = converter.convert()\r\n    with open('model.tflite', 'wb') as f:\r\n       f.write(tflite_model)\r\n\r\nI have this error:\r\n   \r\n    WARNING:absl:Found untraced functions such as mylayer_layer_call_fn, mylayer_layer_call_and_return_conditional_losses, \r\n    mylayer_layer_call_fn, mylayer_layer_call_and_return_conditional_losses, mylayer_layer_call_and_return_conditional_losses \r\n    while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\n    2021-10-11 19:57:58.096866: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute    \r\n    capability >= 0.0): 0\r\n    2021-10-11 19:57:58.097108: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\r\n    2021-10-11 19:58:00.117971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler   \r\n    item: graph_to_optimize\r\n    function_optimizer: Graph size after: 41 nodes (24), 46 edges (27), time = 273.451ms.\r\n    function_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 471.521ms.\r\n    Optimization results for grappler item: while_body_119\r\n    function_optimizer: function_optimizer did nothing. time = 0.019ms.\r\n    function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n    Optimization results for grappler item: while_cond_118\r\n    function_optimizer: function_optimizer did nothing. time = 0.015ms.\r\n    function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n\r\n    Traceback (most recent call last):\r\n    File \"model.py\", line 231, in <module>\r\n    tflite_model = converter.convert()\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 729, in wrapper\r\n    return self._convert_and_export_metrics(convert_func, *args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 715, in _convert_and_export_metrics\r\n    result = convert_func(self, *args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1123, in convert\r\n    self._freeze_keras_model())\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 218, in wrapper\r\n    raise error from None  # Re-throws the exception.\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/convert_phase.py\", line 208, in wrapper\r\n    return func(*args, **kwargs)\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\", line 1079, in _freeze_keras_model\r\n    _convert_to_constants.convert_variables_to_constants_v2_as_graph(\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 1234, in    \r\n    convert_variables_to_constants_v2_as_graph\r\n    frozen_func = _construct_concrete_function(func, output_graph_def,\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 1078, in    \r\n    _construct_concrete_function\r\n    new_func = wrap_function.function_from_graph_def(output_graph_def,\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py\", line 650, in    \r\n    function_from_graph_def\r\n    wrapped_import = wrap_function(_imports_graph_def, [])\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py\", line 621, in wrap_function\r\n    func_graph.func_graph_from_py_func(\r\n    File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in   \r\n    func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py\", line 87, in __call__\r\n     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py\", line 93, in wrapped\r\n     return fn(*args, **kwargs)\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py\", line 648, in _imports_graph_def\r\n     importer.import_graph_def(graph_def, name=\"\")\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\", line 549, in new_func\r\n     return func(*args, **kwargs)\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/importer.py\", line 400, in import_graph_def\r\n     return _import_graph_def_internal(\r\n     File \"/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/importer.py\", line 501, in     \r\n      _import_graph_def_internal\r\n      raise ValueError(str(e))\r\n\r\n     ValueError: Input 0 of node sequential/module_wrapper/mylayer/StatefulPartitionedCall/AssignVariableOp was passed int32     \r\n     from Func/sequential/module_wrapper/mylayer/StatefulPartitionedCall/input/_1:0 incompatible with expected resource.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["I managed to convert the model with tf-nightly version 2.8.0.dev20211012. The TFLite model uses FlexVarHandleOp and FlexAssignVariableOp: these ops are supported in TFLite micro by AddVarHandle() and AddAssignVariable(), which are in micro_mutable_op_resolver? Regarding While op, given that it shouldn't be supported in TFLite micro, does exist a workaround to replace it?", "Unassigning myself since I work on TFLM, not the converter.", "Advait,\r\nLooks like the conversion issue is resolved based on the earlier comment. The question now is about using loops in micro.\r\n\r\nCan you please advice how they can get it to work or not possible now.\r\n\r\nThanks"]}]