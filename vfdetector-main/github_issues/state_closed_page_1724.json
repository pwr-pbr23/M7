[{"number": 1180, "title": "Installation Issue 0.7", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:\n**Ubuntu 14.04**\n\n**Python 2.7.11**\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\n```\nName: pip\nVersion: 8.0.2\n```\n1. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n```\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/noname/tensorflow/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/home/noname/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 41, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"/home/noname/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 35, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/home/noname/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/home/noname/tensorflow/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 46, in <module>\n    from google.protobuf.pyext import _message\nImportError: /home/noname/tensorflow/lib/python2.7/site-packages/google/protobuf/pyext/_message.so: undefined symbol: PyUnicodeUCS4_FromEncodedObject\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n```\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. `pip install --upgrade virtualenv`\n2. `virtualenv --system-site-packages ~/tensorflow`\n3. Download Cuda Toolkit v 7.5 from: http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb\n4. Install cuda toolkit 7.5:\n   `sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb`\n   `sudo apt-get update`\n   `sudo apt-get install cuda`\n5. Download cuDNN v4: https://developer.nvidia.com/rdp/assets/cudnn-70-linux-x64-v40\n6.  Followed by: \n   `tar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz`\n   `sudo cp cuda/include/cudnn.h /usr/local/cuda/include`\n   `sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64`\n   `sudo chmod a+r /usr/local/cuda/lib64/libcudnn*`\n7. Add the following to the end of ~/.bashrc file:\n   `export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"`\n   `export CUDA_HOME=/usr/local/cuda`\n8. Activate the Virtualenv environment created in step 2: `source ~/tensorflow/bin/activate`\n9. Finally install tensorflow with GPU support enabled: `pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.0-py2-none-linux_x86_64.whl`\n### What have you tried?\n1. I have tried to test the tensorflow installation as described here: https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#test-the-tensorflow-installation\n   and it gives me the same import error as above.\n2. I deleted all of the virtual folder (incl contents) and removed cuda toolkit and cudNN and installed them, repeating 3 times, but it doesn't seem to go pass the import error. \n\nPlease if anyone could help out, a whole lot of time has gone by with this ...\n", "comments": ["can you try pip install protobuf==3.0.0b2 ?\n", "Hey @vrv  Vijay, thanks for looking into my issue and responding. I did like you mentioned `pip install protobuf==3.0.0b2` but its still the same error...\n", "A similar error at https://github.com/psi4/psi4/issues/94 seems to suggest an issue due to mixed versions of python.  You might want to install from sources rather than using our wheels, at least until we can figure this out more generally.\n", "Hi @vrv Vijay, Thanks for searching the issue and responding so quickly. So I will go ahead and install it from the source. On a side note, I just installed the cpu version with Virtualenv environment on my mac laptop and there are no errors on testing the installation.\n", "@vrv Vijay, Just to add on to the page, since the link mentions about different python versions, and it suggests to check `which python` and `which python-config`. \nAnd this is what I got when I do in the active environment: \n\n```\n(tensorflow) noname@noname-desktop:~/Downloads/software$ which python\n/home/noname/tensorflow/bin/python\n(tensorflow) noname@noname-desktop:~/Downloads/software$ which python-config\n/home/noname/tensorflow/bin/python-config\n(tensorflow) noname@noname-desktop:~/Downloads/software$ python --version\nPython 2.7.11\n```\n\nAnd then this is the output outside the environment:\n\n```\nnoname@noname-desktop:~$ which python\n/home/noname/.linuxbrew/bin/python\nnoname@noname-desktop:~$ which python-config\n/home/noname/.linuxbrew/bin/python-config\nnoname@noname-desktop:~$ python --version\nPython 2.7.11\n```\n", "I wanted to add that I was able to successfully install and test Tensorflow version 0.6 using the same steps as described above, with Cuda toolkit version 7.0 and cudNN v2.\nHowever, when I upgraded to version 0.7 with Cuda toolkit version 7.0 and cudNN v2, I get the same import error as stated in the beginning of this issue thread.\nAttached is the image for confirmation of Tensorflow version 0.6 working.\n\n![selection_001](https://cloud.githubusercontent.com/assets/5087437/13186653/33c7f662-d715-11e5-8f6b-23ab4e45f3a8.png)\n", "Ok try our new 0.7.1 wheel (cleanly uninstall tensorflow 0.7.0 and protobuf, then install 0.7.1).  The pip installation requires cudnn v4 though.  Otherwise you'll need to install from sources.\n", "Hi @vrv Vijay, I did exactly as you recommended, and hey hey hey its working...What an excellent start to the week. Thanks so much for clearing up the issue. Great work!\n", "Thanks @vrv this also worked for me.\n"]}, {"number": 1179, "title": "libcuda suffix issue", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System: Centos 7\nCuda 7.5, cuDNN v4\n\nIf installed from sources, provide the commit hash: 99813c26f9fae11b2d6a6f8d12e68493cb06f73c\n### Steps to reproduce\n1. Followed \"Installing from sources\" instructions\n2. `./configure` - run and cuda version explicitly set to 7.5 \n3. `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer` - runs without issue\n4. `bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu` - fails (relevant log below) due to an attempt to load libcuda.so.7.5 via `tensorflow/stream_executor/dso_loader.cc`. \n### What have you tried?\n1. Attempting to create a symbolic link of `libcuda.so.7.5` pointing at `libcuda.so` did not work.\n2. Editing `tensorflow/stream_executor/dso_loader.cc` line 99 from:\n\n``` c\n/* static */ port::Status DsoLoader::GetLibcudaDsoHandle(void** dso_handle) {\n  return GetDsoHandle(FindDsoPath(\"libcuda.so\" + GetCudaVersion(),\n                                  \"third_party/gpus/cuda/driver/lib64\"),\n                      dso_handle);\n}\n```\n\nto\n\n``` c\n/* static */ port::Status DsoLoader::GetLibcudaDsoHandle(void** dso_handle) {\n  return GetDsoHandle(FindDsoPath(\"libcuda.so\", // + GetCudaVersion(),\n                                  \"third_party/gpus/cuda/driver/lib64\"),\n                      dso_handle);\n}\n```\n\nfixed the issue.\n3. This naming convention issue also appears to be the case on Ubuntu 14.04 - but I have not attempted to rebuilt everything there.\n### Logs or other output that would be helpful\n\n```\n[tensorflow]$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcuda.so.7.5. LD_LIBRARY_PATH:\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: ---\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n...\n```\n", "comments": ["Thanks -- I pushed a bad commit there.\n\nSync past d0a822fbcb04d95a643d8efe65699a8d1cdce98b and it should work\n"]}, {"number": 1177, "title": "Cherry-pick into master: pip.sh: die on pip install failure", "body": "", "comments": ["Merged\n"]}, {"number": 1176, "title": "Fix Python3 tensorboard server_test failure.  Fixes #1147.", "body": "Change: 114916060\n\nCherry-picked from master\n", "comments": ["LGTM\n"]}, {"number": 1175, "title": "fix broken links in docs", "body": "fix issue #1169 \n", "comments": ["Duplicate?\n", "this one is for r0.7 branch.\n", "thanks -- we'll cherry-pick it for the r0.7 branch once we mint the binaries (the binaries and the docs are somewhat independent, and we want to keep the number of changes minimal)\n"]}, {"number": 1174, "title": "fix broken links in docs", "body": "fix issue #1169 \n", "comments": ["Ahh, new lines.\n\nLGTM\n", "Merged\n"]}, {"number": 1173, "title": "Problems with viewing a graph using the mnist tutorial code", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:Ubuntu 14.0\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. \n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   0.06\n   If installed from sources, provide the commit hash:\n### Steps to reproduce\n1. This doesn't make generate a graph\n   summary_writer = tf.train.SummaryWriter(train_dir,graph_def=sess.graph_def)\n2. This generates a graph\n   summary_writer= tf.python.training.summary_io.SummaryWriter(train_dir,graph_def=sess.graph_def)\n### What have you tried?\n\n1.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["(Try upgrading to 0.7.1 -- there have been many bug fixes since that release).\n", "Thanks.\n\nDonald McMenemy\nOn Feb 22, 2016 2:32 PM, \"Vijay Vasudevan\" notifications@github.com wrote:\n\n> (Try upgrading to 0.7.1 -- there have been many bug fixes since that\n> release).\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1173#issuecomment-187334620\n> .\n", "Closing this issue, since the upgrade seems to have worked. Let us know if it didn't!\n"]}, {"number": 1172, "title": "pip.sh: die on pip install failure", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@jendap's comment addressed. Squashed.\n", "Merged\n"]}, {"number": 1171, "title": "Undefined reference to symbol 'ceil@@GLIBC_2.2.5' at build time", "body": "I'm working on compiling Tensorflow from source, using non-standard GCC/etc. installations.  Environment info: RHEL 6.7, GCC 5.2.1, Bazel 0.1.5.  I'm installing Tensorflow from HEAD (commit f82ad36).  I'm using a non-CUDA configuration.  I've followed the steps @sethbruder suggests in his comment on [bazel#649](https://github.com/bazelbuild/bazel/issues/649), including copying the contents of `tools` from bazel into `tensorflow/tools/` and into `tensorflow/google/protobuf/tools/`.  This is possibly related to #332, as I'm getting the same error, but at build time as opposed to API usage.\n\nI've tried to set up the relevant paths for my non-standard system resource install using the following settings before invoking bazel:\n\n``` sh\nexport LDFLAGS=\"-Wl,-rpath,/opt/rh/devtoolset-4/root/usr/lib64 -lrt -lm\"\nexport CC=\"/opt/rh/devtoolset-4/root/usr/bin/gcc\"\nexport CXX=\"/opt/rh/devtoolset-4/root/usr/bin/g++\"\nexport JAVA_HOME=\"/u/drspeech/opt/jdks/jdk1.8.0_25\"\nexport LD_LIBRARY_PATH=\"/opt/rh/devtoolset-4/root/usr/lib:${LD_LIBRARY_PATH}\"\nexport BAZEL_ARGS=\"--verbose_failures\"\nexport EXTRA_BAZEL_ARGS=\"${EXTRA_BAZEL_ARGS} --linkopt=-Wl,-rpath,/opt/rh/devtoolset-4/root/usr/lib64\"\nexport EXTRA_BAZEL_ARGS=\"${EXTRA_BAZEL_ARGS} --linkopt=-Wl,-rpath,/u/drspeech/opt/jdks/jdk1.8.0_25/lib\"\nexport EXTRA_BAZEL_ARGS=\"${EXTRA_BAZEL_ARGS} --linkopt=-lz\"\n#export EXTRA_BAZEL_ARGS=\"${BAZEL_ARGS} --linkopt=-Wl,-rpath,/usr/local/cuda-7.0/lib64\"\nexport PYTHON_MAJOR_VERSION=3\nexport PYTHON_BINARY=/u/drspeech/opt/python-3.5.1/bin/python3\nexport MYBAZEL=/u/drspeech/opt/bazel-0.1.5/0.1.5/bazel-0.1.5/output/bazel\n```\n\n(there may be some leftover settings; this is adapted from what I used for building bazel in [bazel#925](https://github.com/bazelbuild/bazel/issues/925))\n\nWhen I invoke bazel with\n\n``` sh\n${MYBAZEL} build -c opt //tensorflow/tools/pip_package:build_pip_package\n```\n\nI get the following error output:\n\n```\nWARNING: Output base '/homes/2/griffisd/.cache/bazel/_bazel_griffisd/294e12ab714f8384c060bacb49311f55' is on NFS. This may lead to surprising failures and undetermined behavior.\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\n____Loading...\n____Found 1 target...\n____Building...\n____[1 / 12] Compiling google/protobuf/python/google/protobuf/pyext/descriptor.cc\n____[1 / 147] Compiling external/re2/re2/compile.cc\nERROR: /homes/0/drspeech/opt/tensorflow-0.6.0/0.7.0/tensorflow/google/protobuf/BUILD:272:1: Linking of rule '//google/protobuf:protoc' failed: gcc failed: error executing command \n  (cd /homes/2/griffisd/.cache/bazel/_bazel_griffisd/294e12ab714f8384c060bacb49311f55/tensorflow && \\\n  exec env - \\\n  /opt/rh/devtoolset-4/root/usr/bin/gcc -o bazel-out/host/bin/google/protobuf/protoc -B/opt/rh/devtoolset-4/root/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections -Wl,@bazel-out/host/bin/google/protobuf/protoc-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command \n  (cd /homes/2/griffisd/.cache/bazel/_bazel_griffisd/294e12ab714f8384c060bacb49311f55/tensorflow && \\\n  exec env - \\\n  /opt/rh/devtoolset-4/root/usr/bin/gcc -o bazel-out/host/bin/google/protobuf/protoc -B/opt/rh/devtoolset-4/root/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections -Wl,@bazel-out/host/bin/google/protobuf/protoc-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/opt/rh/devtoolset-4/root/usr/bin/ld: /opt/rh/devtoolset-4/root/usr/lib/gcc/x86_64-redhat-linux/5.2.1/libstdc++_nonshared.a(hashtable_c++0x.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n//lib64/libm.so.6: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n____Elapsed time: 0.707s, Critical Path: 0.34s\n```\n\nIt seems like I may be missing an \"-lm\" flag in the invocation to gcc to the protobuf target; I've tried including it in LDFLAGS as shown above, but it doesn't seem to be appearing in the gcc invocation.\n", "comments": ["(You may get more help again from the bazel team on this one ...)\n", "undefined reference to symbol 'ceil@@GLIBC_2.2.5'\nI get the same and a great many Info/Warnings.\nthis issue was patched and merged, but I simply follow the syntaxnet instructions:\n\n  git clone --recursive https://github.com/tensorflow/models.git\n  cd models/syntaxnet/tensorflow\n  ./configure\n  cd ..\n  bazel test syntaxnet/... util/utf8/...\n\nit still gives:\n /home/tf/.cache/bazel/_bazel_sam/5cd71b2b91989f3dd022ee2c43ab916c/external/org_tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '@org_tensorflow//tensorflow/tools/proto_text:gen_proto_text_functions' failed: gcc failed: error executing command /usr/bin/gcc -o bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/proto_text/gen_proto_text_functions -pthread -no-canonical-prefixes -B/usr/bin -B/usr/bin -pass-exit-codes '-Wl,--build-id=md5' ... (remaining 12 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/usr/bin/ld: bazel-out/host/bin/external/org_tensorflow/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line\n\nis this a Bazel issue? that's a fairly obscure build system, what should I do?\n", "@sammoes did you figure this out?\n\nEDIT:\nThis did the trick for me. Modify `LINK_OPTS` in `bazel-tensorflow/external/protobuf/BUILD` by adding the `-lm` flag to `//conditions:default`:\n\n```\nLINK_OPTS = select({\n    \":android\": [],\n    \"//conditions:default\": [\"-lpthread\", \"-lm\"],\n})\n```\n", "Thanks @rasmi . Just to add that the file  that I needed to edit to fix my problem was here:\n/home/my_user_name/.cache/bazel/_bazel_my_user_name/e2c708629a3b2c9645109cfe38374186/external/protobuf/BUILD\n", "Code from @rasmi and help from @czakon worked! :D\n", "Code from @rasmi and help from @czakon worked for me too.  Thanks, Will\n"]}, {"number": 1170, "title": "Fix dataset encoding in MNIST example for Python 3", "body": "The beginner example didn't work for me in Python 3. I believe this is because files are opened in UTF-8 mode by default. This patch tells `gfile` to open them in binary mode instead.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "Merged\n", "@vrv Thanks. Do you know why the pull request is labeled as closed rather than merged?\n", "Because we rebase your commits before merging and GitHub apparently is not smart enough to detect that.\n", "Okay cool.\n"]}, {"number": 1169, "title": "Broken link in \"A Tool Developer's Guide...\" for graph_metrics.py", "body": "Here is the link for `graph_metrics.py` in [this tutorial](https://www.tensorflow.org/versions/r0.7/how_tos/tool_developers/index.html#graphdef) but it's broken:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorfl%0Aow/python/tools/graph_metrics.py\n\nUpdate:\nJust found other links to the files, such as `freeze_graph()` and `tensorflow/core/framework/tensor.proto` also not working.\n", "comments": ["Thanks for the report! I'd accidentally added new-lines to some URLs when I was formatting the markdown to an 80-column width, but I've just pushed a fix internally. This bug should be updated automatically once the change goes in, and then the website should get a push soon after that.\n", "Actually I rolled back my internal change since it looks like #1174 / #1175 fix this and we don't want merging conflicts. Closing this bug.\n"]}, {"number": 1168, "title": "Program using GPU and CPU mix got slower in  Tensorflow 0.7", "body": "I have a Titan X, \nOn 0.6, code running well and fast 5 sec for 10 epoch.\nI upgrade to 0.7, code running so slow 85 sec for 10 epoch and no matter python2.7 or python3.4.\nGPU always on and detected so no CPU is used (unless it has to : \"allow_soft_placement=True\").\nWith nvidia-smi, i checked that the GPU was 40 % used in 0.6 version. And it is 97% used in 0.7 version.\nSo, the GPU is more used for a worst training time ?\n", "comments": ["My guess is that more ops than before are now supported on GPU, so there may be more copying of data between CPU and GPU if you are not careful (e.g., you set allow_soft_placement=True, which means surprising placement decisions could be made :).  Try turning on log_device_placement in the ConfigProto to see what might have changed.\n", "Closing since we'd need more information to debug.  Please comment or open a new issue if more information arises.\n"]}, {"number": 1167, "title": "Unsupported Wheel", "body": "### Environment info\n\nOperating System: Ubuntu 15.10\n\nIf installed from binary pip package, provide:\n1. pip package: pip3\n   ### Steps to reproduce\n2. I installed pip3 and Python3 along with the build-essentials setup\n3. I installed Scipy Pack comprising numpy, and the rest.\n4. I tried the pip3 install for CPU using the instructions provided [here](https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#pip-installation) for 64 bits CPU\n### What have you tried?\n1. I read the error file but I did not understand it\n### Logs or other output that would be helpful\n\n---\n\n/usr/bin/pip3 run on Thu Feb 18 04:37:08 2016\ntensorflow-0.7.0-py3-none-linux_x86_64.whl is not a supported wheel on this platform.\nException information:\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/pip/basecommand.py\", line 122, in main\n    status = self.run(options, args)\n  File \"/usr/lib/python3/dist-packages/pip/commands/install.py\", line 283, in run\n    InstallRequirement.from_line(name, None))\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 168, in from_line\n    raise UnsupportedWheel(\"%s is not a supported wheel on this platform.\" % wheel.filename)\npip.exceptions.UnsupportedWheel: tensorflow-0.7.0-py3-none-linux_x86_64.whl is not a supported wheel on this platform.\n", "comments": ["I found a workaround for this problem. See [here](https://github.com/tensorflow/tensorflow/issues/1142).\n", "Thank you so much for your prompt reply. It worked\n", "Thanks @HellMood, we'll take further discussion to that bug and we'll try to fix it in the next patch release.\n"]}, {"number": 1166, "title": "upgrade to cuda 7.5 and cudnn 4", "body": "", "comments": ["LGTM, what do you think @martinwicke  ?\n", "LGTM.\n", "Merged\n"]}, {"number": 1165, "title": "Can tensor take advantage of  multiple machines with multiple gpus?", "body": "As title\n", "comments": ["Duplicate of #23 \n", "@vrv thanks :)\n"]}, {"number": 1164, "title": "Fix tensorboard import path", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@danmane: is this correct? \n\nhttps://github.com/tensorflow/tensorflow/commit/880011919c7b113802eb23c54ed5b8e2218e4416 specifically changed this a few days ago.\n", "Hm, with the reorganization of tensorboard, I think this is right.  Currently  tensorboard install is broken at HEAD, and I think this fixes it.\n", "(Merged a few days ago)\n"]}, {"number": 1163, "title": "Fix a wrong parenthesis", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Merged\n"]}, {"number": 1162, "title": "Inconsistent Naming with different input shapes", "body": "Install from binary pip package\n1. Which pip package you installed. CPU only for Linux\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\": 0.7.0\n### Steps to reproduce\n\nRun the following code:\n\n```\nimport tensorflow as tf\n\na = tf.placeholder(tf.float32, name='haha', shape=[128, 20, 20, 20])\nc = tf.nn.moments(a, axes=[0])[0]\nprint c.name\n\nwith tf.Graph().as_default():\n    a = tf.placeholder(tf.float32, name='haha', shape=[None, 20, 20, 20])\n    c = tf.nn.moments(a, axes=[0])[0]\n    print c.name\n```\n\nIt prints:\n\n```\nmoments/Squeeze:0\nmoments/Squeeze_1:0\n```\n\nIn short, with different input shapes, the op returns a variable with different names.\nI'm not sure whether this is expected to happen, or something to be fixed. IMHO, this could cause some problems because one may use a fixed batch size for training, and a `None` batch size for inference. Getting a different name make it harder to manage variable load & restore.\n", "comments": ["The reason is that moments produces a slightly different graph when the input shape is known (it can be pre-computed).  When it's unknown, the code introduces a \"squeeze\" operator that isn't normally there, in the same op scope as the final mean, so there's a name collision and we increment by 1.\n\n@vincentvanhoucke: can we/ should we make moments() return a consistent name for the returned tuples?\n", "These are the names of the ops, not the variables, so it won't be an issue for save and restore.\nWe should try to provide stable names for endpoints of composite ops though, that seems sane, even if users should definitely not rely on that naming to be stable over time. I'm working on updates to `moments()` for v0.8, I'll put that on my list of requirements. \n", "I agree that usually ops won't be an issue for save and restore. But what happen to me is that I'm using ExponentialMovingAverage on `c`, then there will be a variable that inherit the inconsistent name from `c`, and then cause problems for save/restore.\nBTW, this is how the non-official batch normalization mentioned in #1122 works (take moving average on mean/var). \n", "A fix for this has been checked in and should make its way to github shortly.\n", "is it fixed now? I have a same problem about tf.saver.restore() with different batch size train time and inference time. and i want to know this is the reason or not.\n"]}, {"number": 1161, "title": "Trouble importing tensorflow after installing with virtualenv", "body": "### Environment info\n\nFedora 19\nPython2.7.8\npip 8.0.2\n### Steps to reproduce\n1. I installed tensorflow from the Download and Setup page using virtualenv. \n2. When I typed \"import tensorflow as tf\" I got the following error:\n\n\">>> import tensorflow\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/emerson/tensorflow/lib/python2.7/site-packages/tensorflow/**init**.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/home/emerson/tensorflow/lib/python2.7/site-packages/tensorflow/python/**init**.py\", line 69, in <module>\n    from tensorflow.python.training import training as train\n  File \"/home/emerson/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/training.py\", line 149, in <module>\n    from tensorflow.python.training.saver import generate_checkpoint_state_proto\n  File \"/home/emerson/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 29, in <module>\n    from google.protobuf.any_pb2 import Any\nImportError: No module named any_pb2\"\n\nI have searched for this error and have not seen a clear solution. I am new with linux and tensorflow. I think I might need to set the PYTHONPATH or get out of the working directory that contains tensorflow. However I am not sure how to do either of those things. \n\nThanks\n", "comments": ["What was the solution to the problem? I didn't get it with 0.5 but now get it with 0.7 using both the official version or the anaconda repository verisons\n", "I never found a solution to virtualenv. I assume it had something to do with the issue I had when I installed normally without Virtualenv. \n\nAfter the Virtualenv problems I went back to trying to install normally and my python wouldn't recognize TensorFlow to import.  I had to uninstall protobuf before I installed TesnorFlow because it needed a specific protobuf version for TensorFlow to work. \n", "I had the same problem and tried all sorts of solutions which didn't work.  After upgrading my \nvirtualenv: sudo pip install --upgrade virtualenv\nIt now works.\n", "For anyone else who is running into the same issue, I was also having similar problems when trying to import tensorflow on notebook via jupyter. The modules were installed using conda. After spending two days on it without any success (kept getting the same, no module any_pb2/contrib), it was obvious it was a notebook problem and not tensorflow related since I could import tensorflow from python shell. So I decided to switch back to vanilla python and installed everything manually (tensorflow via pip & got rid of jupyter & installed ipython instead) and now I am able to import tensorflow from my ipython notebook.\n", "@ankitgyawali  \nHi there,\nJust for your information.\nI have the same problem as your description. But I solved it by following this post and did not reinstall anything.http://stackoverflow.com/a/37081342/4837894\n"]}, {"number": 1160, "title": "Adding tests and options to pip.sh", "body": "1) Adding test-on-intall for\ntensorflow/python/{contrib,examples,models,tensorboard}\n\n2) Adding option for TF_BUILD_IS_PIP=BOTH, which performs both the\n\"bazel test\" step and the \"pip.sh\" test-on-install step in one single\nbuild\n\n3) Adding \"bazel clean\" switch to pip.sh\n\nThis is the mirror of #1154 \n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1159, "title": "Remove extra colons", "body": "The documentation has double colons in a couple places.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed the CLA.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Merged, thanks for the surgery!\n", "Wow, that was quick!\n"]}, {"number": 1158, "title": "Kernel version vs DSO version mismatch when running example after bazel build", "body": "After successful bazel build, running into error when executing example with gpu. Please suggest on how to resolve. The GPU has been used with MathConvNet (another deep learning package) without this error.\n## Log:\n\n`bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: en4113750l\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: en4113750l\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.55  Thu Oct  8 15:18:00 PDT 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.55\nE tensorflow/stream_executor/cuda/cuda_diagnostics.cc:229] kernel version 352.55 does not match DSO version 352.63 -- cannot find working devices in this configuration\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: \nF tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{\"x\", x}}, {\"y:0\", \"y_normalized:0\"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0'\n     [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=\"/gpu:0\"]()]])\nF tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{\"x\", x}}, {\"y:0\", \"y_normalized:0\"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0'\n     [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=\"/gpu:0\"]()]])\nF tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{\"x\", x}}, {\"y:0\", \"y_normalized:0\"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0'\n     [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=\"/gpu:0\"]()]])\nAborted (core dumped)`\n## Specifications:\n\nUbuntu LTS 14.04\nTitan X GPU\nCUDA 7.5\n", "comments": ["```\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 352.63\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module 352.55 Thu Oct 8 15:18:00 PDT 2015\nGCC version: gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.55\nE tensorflow/stream_executor/cuda/cuda_diagnostics.cc:229] kernel version 352.55 does not match DSO version 352.63 -- cannot find working devices in this configuration\n```\n\nMy guess is that you have to update your cuda driver to 352.63, is that right @zheng-xq  ?\n", "Thats right @vrv, but Titan X has had trouble with CUDA 7.5 with the login-loop issue. That's the reason I had installed 352.55. I got it resolved using the tips on http://olivernina.blogspot.com/2015/11/installing-titan-x-drivers-and-cuda-75.html\n\nGet rid of nvidia residuals\n`sudo apt-get remove --purge nvidia*`\nReboot and switch to terminal login with Ctrl+Alt+F1. Then download the required version of the nvidia driver (in my case 352.63)\n`cd ~/Downloads \nwget us.download.nvidia.com/XFree86/Linux-x86\u00ad_64/352.63/NVIDIA-Linux-x86_64-352.63.ru\u00adn`\nThen run\n`sudo service lightdm stop`\nGo to Downloads directory and change permissions to execute and run\n`chmod +x NVIDIA*.run`\n`sudo ./NVIDIA*.run`\n", "Incidentally, one fix for this is to install the right nvidia driver. \n\nhttp://www.nvidia.com/download/driverresults.aspx/95159/en-us\n", "But what's the right version mean? and can we make them be syncronized automatically? \r\nI found this issue keep happening after my ubuntu upgrade its components, everytime I need debug this issue mannually. Now my current error logs are:\r\n\r\n@> 2018-01-22 10:12:52.860623: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n> 2018-01-22 10:12:52.860688: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: clockAsusDesktop\r\n> 2018-01-22 10:12:52.860714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: clockAsusDesktop\r\n> 2018-01-22 10:12:52.860790: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 384.111.0\r\n> 2018-01-22 10:12:52.860851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.90  Tue Sep 19 19:17:35 PDT 2017\r\n> GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.5) \r\n> \"\"\"\r\n> 2018-01-22 10:12:52.860907: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 384.90.0\r\n> 2018-01-22 10:12:52.860934: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version 384.90.0 does not match DSO version 384.111.0 -- cannot find working devices in this ", "Ok, It's my mistake. My problem is fixed after I upgrade my system with the following commands:\r\n\r\n> sudo add-apt-repository ppa:graphics-drivers/ppa\r\n> sudo apt-get update \r\n> sudo apt-get upgrade\r\n\r\nand then:\r\n\r\n reboo\r\n", "@clockzhong  I suspect you also executed `sudo apt-get upgrade` after `sudo apt-get update` - which will install the latest driver.", "@xiaoyongzhu  yes, right! It's my typo. And it's corrected now. Thanks."]}, {"number": 1157, "title": "Still seeing 'missing dependency declarations' when building with Bazel 0.1.4/0.1.5", "body": "I'm still getting the error from #469, even with the fix in #788.\n\nDebian, gcc 4.9.2, bazel 0.1.5 (tried 0.1.4 as well with the same results).\n\nCommand line:\n\n```\nbazel build -c opt --config=cuda --verbose_failures --spawn_strategy=standalone  //tensorflow/cc:tutorials_example_trainer\n```\n\nError output:\n\n```\nERROR: /usr/local/src/tensorflow/tensorflow/core/BUILD:334:1: undeclared inclusion(s) in rule '//tensorflow/core:gpu_kernels':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/cwise_op_gpu_cos.cu.cc':\n  '/usr/local/cuda/include/vector_types.h'\n  '/usr/local/cuda/include/math_constants.h'\n  '/usr/local/cuda/include/cuda_runtime.h'\n  '/usr/local/cuda/include/curand_kernel.h'\n  '/usr/local/cuda/include/curand.h'\n  '/usr/local/cuda/include/curand_discrete.h'\n  '/usr/local/cuda/include/curand_precalc.h'\n  '/usr/local/cuda/include/curand_mrg32k3a.h'\n  '/usr/local/cuda/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda/include/cuda.h'\n  '/usr/local/cuda/include/curand_mtgp32.h'\n  '/usr/local/cuda/include/curand_philox4x32_x.h'\n  '/usr/local/cuda/include/curand_globals.h'\n  '/usr/local/cuda/include/curand_uniform.h'\n  '/usr/local/cuda/include/curand_normal.h'\n  '/usr/local/cuda/include/curand_normal_static.h'\n  '/usr/local/cuda/include/curand_lognormal.h'\n  '/usr/local/cuda/include/curand_poisson.h'\n  '/usr/local/cuda/include/curand_discrete2.h'.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n```\n", "comments": ["@damienmg, any more ideas? :)\n", "I am seeing the exact same problem.\n\nOS:\n\n```\nmgix@alphanor:~/tensorflow$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 15.10\nRelease:    15.10\nCodename:   wily\n```\n\nBazel is built from github head:\n\n```\nmgix@alphanor:~/tensorflow$ bazel version\nBuild label: head (@12ecc0b)\nBuild target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Sat Mar 5 01:35:18 2016 (1457141718)\nBuild timestamp: 1457141718\nBuild timestamp as int: 1457141718\n```\n\ngcc is gcc 4.9.3\n\n```\nmgix@alphanor:~/tensorflow$ gcc -v\nUsing built-in specs.\nCOLLECT_GCC=gcc-4.9\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.9/lto-wrapper\nTarget: x86_64-linux-gnu\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 4.9.3-5ubuntu1' --with-bugurl=file:///usr/share/doc/gcc-4.9/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.9 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.9 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.9-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\nThread model: posix\ngcc version 4.9.3 (Ubuntu 4.9.3-5ubuntu1) \n```\n\nBuilding tensorflow from head with GPU on:\n\n```\nmgix@alphanor:~/tensorflow$ pwd; git log | head -1\n/home/mgix/tensorflow\ncommit 6eb0f2ee3db263791f292f6147a2cda600dd6a1f\n```\n\nTrying to build with --spawn_strategy=standalone\n\n```\nmgix@alphanor:~/tensorflow$ bazel build --spawn_strategy=standalone  --verbose_failures -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nINFO: Found 1 target...\nINFO: From Compiling tensorflow/core/kernels/cwise_op_minimum.cc:\nIn file included from ./tensorflow/core/platform/default/logging.h:23:0,\n                 from ./tensorflow/core/platform/logging.h:24,\n                 from ./tensorflow/core/lib/core/status.h:24,\n                 from ./tensorflow/core/framework/op_def_builder.h:25,\n                 from ./tensorflow/core/framework/op.h:23,\n                 from ./tensorflow/core/kernels/cwise_ops_common.h:25,\n                 from tensorflow/core/kernels/cwise_op_minimum.cc:16:\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::__cxx11::string = std::__cxx11::basic_string<char>]':\n./tensorflow/core/kernels/cwise_ops_common.h:64:5:   required from 'static Eigen::array<long int, NDIMS> tensorflow::BinaryOpShared::ToIndexArray(const Vec&) [with int NDIMS = 2; tensorflow::BCast::Vec = tensorflow::gtl::InlinedVector<long long int, 4>]'\n./tensorflow/core/kernels/cwise_ops_common.h:122:26:   required from 'void tensorflow::BinaryOp<Device, Functor>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::GpuDevice; Functor = tensorflow::functor::minimum<long long int>]'\ntensorflow/core/kernels/cwise_op_minimum.cc:36:1:   required from here\n./tensorflow/core/platform/default/logging.h:194:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n                         == )  // Compilation error with CHECK_EQ(NULL, x)?\n                         ^\n./tensorflow/core/platform/macros.h:54:28: note: in definition of macro 'TF_PREDICT_TRUE'\n #define TF_PREDICT_TRUE(x) x\n                            ^\n./tensorflow/core/platform/default/logging.h:193:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\n ^\nERROR: /data/home/mgix/tensorflow/tensorflow/core/kernels/BUILD:205:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:gather_op_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/gather_op_gpu.cu.cc':\n  '/usr/local/cuda/targets/x86_64-linux/include/vector_types.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/cuda_fp16.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/math_constants.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/cuda_runtime.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_kernel.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_discrete.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_precalc.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_mrg32k3a.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/cuda.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_mtgp32.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_philox4x32_x.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_globals.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_uniform.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_normal.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_normal_static.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_lognormal.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_poisson.h'\n  '/usr/local/cuda/targets/x86_64-linux/include/curand_discrete2.h'.\nnvcc-real warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc-real warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 18.195s, Critical Path: 18.09s\n```\n", "Adding\n\n`cxx_builtin_include_directory: \"/usr/local/cuda/targets/x86_64-linux/include\"`\n\nto file `tensorflow/third_party/gpus/crosstool/CROSSTOOL`\n\nseem to be a workaround.\n", "Oh gosh, sorry @vrv, I totally missed that message.\n\nYes missing cxx_builtin_include_directory is the usual suspect when you have such message.\n\nNote that I am rolling out a mechanism in Bazel to auto-configure those include dir (see https://groups.google.com/forum/#!msg/bazel-discuss/MSunz2ZUOq0/U5tE7uQLJQAJ), using it in TF would significantly reduce those bug reports\n", "@damienmg I'm having the same issue with TensorFlow Serving compiled with cuda. Adding `cxx_builtin_include_directory: \"/usr/local/cuda-7.0/include\"` to the CROSSTOOL file works, but changing it to `\"/usr/local/cuda/include` (symlink) fails with the same error above (this rule is missing dependency declarations...)\nThe path that works is user specific, so we can't add it as is.\n\nI tried to auto-configure using the link you provided, and got stuck in other places. The relevant part of the error message including the command it generated is:\n`/usr/bin/gcc -shared -o bazel-out/local-opt/bin/tensorflow_serving/resources/libresource_values.so -no-canonical-prefixes -B/usr/bin -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,rpath,/usr/local/cuda-7.0/lib -L/usr/local/cuda-7.0/lib -Wl,rpath,/usr/local/cuda-7.0/lib64 -L/usr/local/cuda-7.0/lib64 -Wl,--gc-sections -Wl,@bazel-out/local-opt/bin/tensorflow_serving/resources/libresource_values.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/usr/bin/ld: cannot find rpath: No such file or directory\n/usr/bin/ld: cannot find /usr/local/cuda-7.0/lib: File format not recognized\n/usr/bin/ld: cannot find rpath: No such file or directory\n/usr/bin/ld: cannot find /usr/local/cuda-7.0/lib64: File format not recognized\ncollect2: error: ld returned 1 exit status`\n\nnote that it's using /usr/bin/gcc but TensorFlow's crosstool config uses clang/bin/crosstool_wrapper_driver_is_not_gcc. I only added\n`load(\"@bazel_tools//tools/cpp:cc_configure.bzl\", \"cc_configure\")\ncc_configure()`\nand not sure if there's a way to configure the tool_path for gcc since cc_configure() is the only public function and it takes no parameters. \n", "cc_configure is for general gcc (it is rolled-out by default now on Bazel @HEAD by the way).\n\nThere was an error in cc_configure in 0.2.1 that prevents rpath from working correctly and you are hitting it (it should be `-Wl,-rpath,...` not `-Wl,rpath,...`)\n\ncc_configure.bzl probably needs to be adapted for the cuda crosstool for TensorFlow, will be happy to provide guidance on doing it.\n", "@martinwicke You could do further triage on this?  Taking advantage of @damienmg's new feature seems worth doing if it reduces further bug reports.\n", "Do I understand correcly that this issue will be resolved once current bazel head lands in a release?\n", "Sorry I was not clear. Bazel @HEAD (since 0.2.2) has made C++ auto-configuration the default. I am proposing to adapt the script we use for CUDA configuration. Which is what @davidzchen has started to do IIUC. I also sent a PR for doing the same for python.\n\nDoing that would:\n1. Remove issues with CUDA configuration.\n2. Remove needs for ./configure (which can be kept for user interface), helping people depends on TensorFlow without needing for calling the ./configure script.\n\nInternal reference: b/29006900\n", "I have started working on the CUDA autoconf. With this and Python detection, I think the only thing left that the configure script manages is whether to build with GCP support.\n", "@davidzchen @damienmg that is exciting.\n", "Here is the tracking bug for cuda autoconf: #2873\n", "Will close this bug in favor of #2873.\n", "@kirilg You save my day. In my case, adding `cxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"`  to `third_party/gpus/crosstool/CROSSTOOL` works, but `cxx_builtin_include_directory: \"/usr/local/cuda/include\"` doesn't.\n\nSeems that the building system is not as smart as cmake.\n", "@ZiangYan  cxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\" works for me too! \n", "@ZiangYan We are actively working on improving Bazel's autoconfiguration support. We appreciate your patience.\n\n@lberki, @ulfjack - it seems that the C++ toolchain configuration does not follow symlinks for builtin include directories. I ran into this issue as well while working on #2873. Even though `/usr/local/cuda` is a symlink to `/usr/local/cuda-7.5`, as other users have pointed out, `cxx_builtin_include_directory: \"/usr/local/cuda/include\"` still produces this error while `cxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"` does not. Is this a bug?\n", "@dbikard - You may have added your `cxx_builtin_include_directory:` entry to the wrong part of the config. Can you paste a snippet illustrating where in your CROSSTOOL config you added that entry to?\n\nFYI, the CROSSTOOL config file is in text Protocol Buffer format and is parsed into a `CToolchain` Protocol Buffer message. Here is the message definition, which serves as the schema for the CROSSTOOL config file, and here is where the `cxx_builtin_include_directory` field is in the proto: https://github.com/bazelbuild/bazel/blob/master/src/main/protobuf/crosstool_config.proto#L370\n", "@davidzchen Thanks, that was indeed my mistake. I realized that shortly after posting here, so I deleted my message. I have now managed to build tensorflow. Thanks for your help!\n", "I have same problem when building r0.9 without cudn, always such errors:\nERROR: /home/hadoop/.cache/bazel/_bazel_hadoop/688bf433e3d98b943fba735d08e17b8c/external/jpeg_archive/BUILD:77:1: undeclared inclusion(s) in rule '@jpeg_archive//:jpeg':\nthis rule is missing dependency declarations for the following files included by 'external/jpeg_archive/jpeg-9a/jdatasrc.c':\n  'bazel-out/host/genfiles/external/jpeg_archive/jconfig.h'.\n\nThe error file is changed if I run bazel build again.\n\nThere is no problem when I build TF master version 0.11.\n\nbazel version is 0.3.2-jdk7\n", "Hey guys I had the same problem and fixed it by:\r\n1. Uninstalling and re-installing gcc and g++\r\n2. Removing ~/.cache/bazel\r\n\r\nI also restarted the machine but I think (2) was the one that really fixed it for me.", "> Hey guys I had the same problem and fixed it by:\r\n> \r\n> 1. Uninstalling and re-installing gcc and g++\r\n> 2. Removing ~/.cache/bazel\r\n> \r\n> I also restarted the machine but I think (2) was the one that really fixed it for me.\r\n\r\nstep (2) Removing ~/.cache/bazel did work for me!.\r\nMany thanks"]}, {"number": 1156, "title": "Cherry-pick fixes to tensorboard/gfile/saver to r0.7 branch", "body": "", "comments": []}, {"number": 1155, "title": "Fix doc to test GPU kernels using docker", "body": "the documentation says to use gpu_pip.sh but there is not such a command in the `tensorflow/tools/ci_build/` directory only `pip.sh`\n", "comments": ["Can one of the admins verify this patch?\n", "@Mistobaan can you also squash the commits please?\n", "@jendap updated and squashed. \n", "Thank you!\n\nLGTM, @vrv can you merge this please?\n", "Merged\n"]}, {"number": 1154, "title": "Adding tests and options to pip.sh", "body": "1) Adding test-on-intall for\ntensorflow/python/{contrib,examples,models,tensorboard}\n\n2) Adding option for TF_BUILD_IS_PIP=BOTH, which performs both the\n\"bazel test\" step and the \"pip.sh\" test-on-install step in one single\nbuild\n\n3) Adding \"bazel clean\" switch to pip.sh\n\n(This is a squashed version of https://github.com/tensorflow/tensorflow/pull/1151, with the same changes)\n", "comments": ["Can one of the admins verify this patch?\n", "@jendap has LGTM'ed this in #1151. Ready to merge.\n", "Merged\n"]}, {"number": 1153, "title": "Cherry-pick some fixes into r0.7 branch", "body": "gfile changes are necessary for input_data.py\n\ntensorboard requires polymer 1.2.4, so updating the workspace entry\n", "comments": ["The polymer should fix tensorboard! Nice!\n\nWhy is the gfile still failing? Should this fix the mac python3 build?\n", "it's failing in python3 test only -- do you want me to cherry pick that fix too? :)\n", "Eh, why not.  @tensorflow-jenkins: test this please.\n", "Does this look good? I can merge if so.\n", "Closing, going to do all of this on a separate branch until we get it working.\n"]}, {"number": 1152, "title": "fix master cpu build url", "body": "because we have renamed the master to master-cpu\n", "comments": ["@caisq I wanted to rename it some time ago. But then ... one would have to to bother updating this.\n"]}, {"number": 1151, "title": "Adding tests and options to pip.sh", "body": "1) Adding test-on-intall for tensorflow/python/{contrib,examples,models,tensorboard}\n\n2) Adding option for TF_BUILD_IS_PIP=BOTH, which performs both the \"bazel test\" step and the \"pip.sh\" test-on-install step in one single build\n\n3) Adding \"bazel clean\" switch to pip.sh\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@jendap: I know some tests will faiure (Mac+Python3). Those are unrelated to this change set. Also, the commits are messed up and difficult to rebase. I'll create another PR with only one single commit (with the same changes, of course).\n", "@tensorflow-jenkins test this please\n", "I think the linux build was killed by mac py3 failing. I have fixed that.\n\nCan you squash and rebase it please?\n\nOtherwise it looks good. (although I'm getting a bit lost in those scripts, but I may have idea about that)\n"]}, {"number": 1150, "title": "tensorflow 0.7.0 gpu-enabled version crashes bad on import", "body": "DISTRIB_CODENAME=trusty\nDISTRIB_DESCRIPTION=\"Ubuntu 14.04 LTS (upgraded from: Ubuntu 12.04.4 LTS)\"\n\nLinux .... 3.13.0-76-generic #120-Ubuntu SMP Mon Jan 18 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nI used the trick of renaming the wheel to:\n  tensorflow-0.7.0-cp34-none-linux_x86_64.whl\nto get it installed\n\nlaunched ipython via:\n\n``` python\nCUDA_HOME=/usr/local/cuda-7.0 LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib64/ ipython3\n\nIn [1]: import tensorflow\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-a649b509054f> in <module>()\n----> 1 import tensorflow\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/__init__.py in <module>()\n     21 from __future__ import print_function\n     22 \n---> 23 from tensorflow.python import *\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/__init__.py in <module>()\n     47 \n     48 # Import things out of contrib\n---> 49 from tensorflow import contrib\n     50 \n     51 # Framework\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/__init__.py in <module>()\n     21 \n     22 # Add projects here, they will show up under tf.contrib.\n---> 23 from tensorflow.contrib import layers\n     24 from tensorflow.contrib import util\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/layers/__init__.py in <module>()\n     66 # pylint: disable=unused-import,wildcard-import\n     67 from tensorflow.contrib.layers.python.framework.tensor_util import *\n---> 68 from tensorflow.contrib.layers.python.layers import *\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/layers/python/layers/__init__.py in <module>()\n     20 \n     21 # pylint: disable=wildcard-import\n---> 22 from tensorflow.contrib.layers.python.layers.initializers import *\n     23 from tensorflow.contrib.layers.python.layers.layers import *\n     24 from tensorflow.contrib.layers.python.layers.regularizers import *\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/layers/python/layers/initializers.py in <module>()\n     22 \n     23 from tensorflow.python.framework import dtypes\n---> 24 from tensorflow.python.ops import random_ops\n     25 \n     26 \n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/random_ops.py in <module>()\n     21 \n     22 from tensorflow.python.framework import dtypes\n---> 23 from tensorflow.python.framework import ops\n     24 from tensorflow.python.framework import tensor_shape\n     25 from tensorflow.python.framework import tensor_util\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py in <module>()\n     37 from tensorflow.python.framework import registry\n     38 from tensorflow.python.framework import tensor_shape\n---> 39 from tensorflow.python.framework import versions\n     40 from tensorflow.python.util import compat\n     41 from tensorflow.python.platform import logging\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/versions.py in <module>()\n     20 from __future__ import print_function\n     21 \n---> 22 from tensorflow.python import pywrap_tensorflow\n     23 \n     24 __version__ = pywrap_tensorflow.__version__\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\n     26                 fp.close()\n     27             return _mod\n---> 28     _pywrap_tensorflow = swig_import_helper()\n     29     del swig_import_helper\n     30 else:\n\n/usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py in swig_import_helper()\n     22         if fp is not None:\n     23             try:\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n     25             finally:\n     26                 fp.close()\n\n/usr/lib/python3.4/imp.py in load_module(name, file, filename, details)\n    241                 return load_dynamic(name, filename, opened_file)\n    242         else:\n--> 243             return load_dynamic(name, filename, file)\n    244     elif type_ == PKG_DIRECTORY:\n    245         return load_package(name, filename)\n\nImportError: /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: PyClass_Type\n\nIn [2]: \nDo you really want to exit ([y]/n)? y\nlibgcc_s.so.1 must be installed for pthread_cancel to work\nAborted (core dumped)\n```\n\n---\n\nNote the core dump at the bottom!\n", "comments": ["For posterity, this was user error: I installed a python 2 wheel into python3.\n"]}]