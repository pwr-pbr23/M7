[{"number": 25218, "title": "Complex step derivatives", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIs it possible to implement the complex-step derivative method as a way to compute gradients? This would presumably require a \"fairly simple\" change of traversing the Ops of the graph, copying each one, and modifying its args from Real to Complex numbers and doing a 1e-16 delta in imaginary space. It may allow for easier computation of full Jacobians and Hessians. \r\n\r\n**Will this change the current api? How?**\r\nI'm not sure.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who need full rank Jacobian/Hessians.\r\n\r\n**Any Other info.**\r\nReference paper:\r\n\r\nhttp://mdolab.engin.umich.edu/sites/default/files/Martins2003CSD.pdf\r\n\r\nThe trick is basically to convert real numbers into complex numbers, and doing a small delta in imaginary space. Since many of tensorflow's ops already naturally support complex numbers, this seems like something that's doable.\r\n", "comments": ["I think this would be a considerable amount of work, since our gradient functions currently don't expect to work over complex numbers. Someone could possibly prototype this by writing a version that works with a small number of ops though and see how it looks.", "I'm marking this \"contributions welcome\" in case someone experienced with TF wants to investigate this. Please don't attempt to fully implement this without further discussion though :)", "@skye, this looks like an interesting topic to me, can I give a try? ", "Sure. Do you have a rough plan of attack? If possible, I would recommend prototyping this first to get an idea of how much work it would be and what the benefits are. If the prototype is promising, I think ideally this would go in https://github.com/tensorflow/addons. Just to set expectations, I'm skeptical that a project of this complexity will make sense to include in TF core, so keep that in mind if you decide to take it on.", "**Implement analytic complex derivative instead of numeric complex derivative**\r\n\r\n@skype, after reading the paper recommended by @proteneer, I am not sure complex step derivatives is necessary for tensorflow framework. Basically, it is a complex number version of numerical derivative approximation.\r\n\r\n>   f'= (f(x + h) - f(h)) / h \r\n\r\nIn backprop instead of using the above approximation,  we normally compute the exact analytic derivative of a real function.  Therefore, in consistence with the real number case, I suppose we should add the analytic derivate for complex valued function. I realize that tf already support  some complex valued ops,  I can start by extending some other math ops to complex case and modify the optimizer accordingly. For example, I can follow the implementation here:\r\n\r\n> https://github.com/ChihebTrabelsi/deep_complex_networks    \r\n\r\nWhat do you think?", "I'm not familiar with complex nets or derivatives, so I don't have a sense for how useful this will be. @proteneer can you explain more what the end goal is? You mentioned full rank Jacobians and Hessians, does @musikisomorphie 's suggestion also achieve this?", "This is far less complicated than what you guys think it is. It basically allows for an easy way to do forward-mode AD in an embarassingly parallel way:\r\n\r\n``` python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nsess = tf.Session()\r\n\r\ndef cosine_squared(x):\r\n    return tf.reduce_sum(tf.pow(tf.cos(x), 2))\r\n\r\ninp = tf.convert_to_tensor([1.0, 2.0], dtype=np.float64)\r\nresult = cosine_squared(inp)\r\nbackprop = sess.run(tf.gradients(result, inp)[0])\r\nprint(backprop)\r\n\r\nstep = 1e-7\r\ninp = np.array([1.0, 2.0], dtype=np.float64) + 1j * np.array([step, 0], dtype=np.float64)\r\nresult = sess.run(cosine_squared(inp))\r\ndfdx = result.imag/step\r\nprint(dfdx)\r\n\r\nstep = 1e-7\r\ninp = np.array([1.0, 2.0], dtype=np.float64) + 1j * np.array([0, step], dtype=np.float64)\r\nresult = sess.run(cosine_squared(inp))\r\ndfdx = result.imag/step\r\nprint(dfdx)\r\n```\r\n\r\nprints:\r\n\r\n```\r\n[-0.90929743  0.7568025 ]\r\n-0.9092974264015236\r\n0.7568024946574002\r\n```\r\n\r\nLiterally the only engineering that's needed is to wrap the dfdx's in a parallel_for. \r\n\r\nAs such it becomes trivial to do full-rank jacobians (as opposed to the reduced variants) that we currently have. And doesn't require _any_ backpropagation via jacobian-vector-products. The complex step takes care of this for you, automagically, in a single forward pass. A similar analogy can be made for Hessians.\r\n", "@proteneer @skye, thank you for your response. \r\nYou suggest computing complex-step derivative when traversing the Ops of the graph.\r\nBut what about the possibility that the numerical errors of this kind of derivative will propagate and accumulate through the graph, especially when the nn is very deep?  I guess that is the reason why we always compute the analytic derivative for each op. \r\nFor sure for certain ops like Jacobian/Hessians I can implement a temporary backbp by computing their complex-step derivative.  Personally, I am not sure implementing complex-step derivative through an entire graph is a good idea. \r\nI have a deadline this week, I can start coding next week once we come up with a solution that all of us agree with. ", "The whole point of this method is that it's *insensitive* to the choice of the step size and the typical numerical problems that plague finite-difference type of approaches. It should have the same error as prop and forward prop. "]}, {"number": 25215, "title": "lite: non-standard variable-length arrays", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit [01dec19](https://github.com/tensorflow/tensorflow/tree/01dec19e827ab46ff7ff5dbd6142ba5a26efc4da)\r\n- GCC/Compiler version (if compiling from source): gcc 8.2.1 20181127\r\n\r\n**Describe the problem**\r\n\r\nStructures `TfLiteIntArray` and `TfLiteFloatArray` have flexible array member `data`, which is not supported by the C++ standard. The header file name \"c_api_internal.h\" suggests that it's \"C API\" and \"internal API\", but it gets indirectly included by user C++ code via \"interpreter.h\". Although in practice it may not cause problems other than compiler warnings, it may still worth rewriting in standard C++ if the fix is easy and doesn't interfere with other code.\r\n\r\nI propose using arrays of length 1:\r\n\r\n    typedef struct {\r\n      int size;\r\n      int data[1];\r\n    } TfLiteIntArray;\r\n\r\n    typedef struct {\r\n      int size;\r\n      float data[1];\r\n    } TfLiteFloatArray;\r\n\r\nThe dynamic size then can be calculated as follows:\r\n\r\n    offsetof(TfLiteIntArray, data) + sizeof(int) * size\r\n\r\nand\r\n\r\n    offsetof(TfLiteFloatArray, data) + sizeof(float) * size\r\n\r\nI checked that the dynamic size is always obtained via the functions `TfLiteIntArrayGetSizeInBytes` and `TfLiteFloatArrayGetSizeInBytes`. So only these functions would need to be changed, and no other code is affected.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nCompile tensorflow/tensorflow/lite/examples/minimal/minimal.cc with -Wpedantic.", "comments": ["Changing this could be problematic for historical reasons, but might be worth considering.\r\n\r\n@karimnosseir any thoughts?"]}, {"number": 25104, "title": "Xcode: How to use an static library (a.framework) which force_load  libtensorflow-core.a?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iphone 7\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.6\r\n- Python version: \r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI'm trying to provide an IOS static library as an SDK (named demo.framework) using tensorflow. By tensorflow's instruction, I must link libTensorflow.a with force_load flag in my project. So I link libTensorflow.a with force_load flag in demo.framework's project, and build a library(demo.framework).\r\n\r\nIn a test, I create a sample app project (appXXX), and link my demo.framework to use the SDK. Compiling was success, but when running it gives the error:\r\n\r\nNot found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.\r\n\r\nI try to solve this by link libTensorflow.a with force_load flag for \"other link flags\" in my appXXX's project, it works fine but that is not what I want (In my option, appXXX needn't be care of tensorflow, it just care of demo.framework). How can I provide a \"clean\" demo.framework library without force_load any library in appXXX? \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 25087, "title": "Two roundings in MultiplyByQuantizedMultiplier(TFLite) leads to inconsistent result with tensorflow", "body": "https://github.com/tensorflow/tensorflow/blob/ff91cd691027076e6128afbd902d3d38e3672787/tensorflow/lite/kernels/internal/common.h#L105\r\nPer my understanding, `MultiplyByQuantizedMultiplier` is used to simulate floating point multiplication.\r\nBut in some cases, the two roundings in it will cause different result from floating point arithmetic, which will further lead to unpredictable tflite accuracy compared with tensorflow training pipeline.\r\n\r\n`inline int32 MultiplyByQuantizedMultiplier(int32 x, int32 quantized_multiplier, int shift)`\r\nAssume x = 7984, quantized_multiplier = 1583594044, shift = -9 (the simulated floating point arithmetic is `std::round(7984 * 0.0014402703931141053)`). The multiplication of x and quantized_multiplier will be 12643414847296(0xB7FC6402F40), it will undergo two rounding shift(one in `SaturatingRoundingDoublingHighMul` and the other one in `RoundingDivideByPOT`), and results in number 12. But the floating point result is 11. We can find that if we combine these two rounding shifts into one, i.e. do only one rounding shift, the results will be 12, which matches with floating point result.", "comments": ["Hi, could you describe more what you mean by \"do only one rounding shift\"?\r\n\r\nSince we are doing integer math to approximate a float scale, it is inevitable that for some values we will have an error. We can plan with the logic to move that error around, but we cannot represent all values exactly without using an actual float value.", "Well, in the case I described above, `SaturatingRoundingDoublingHighMul` will perform **31** bits right shift, and `RoundingDivideByPOT` will perform **9** bits right shift, I mean if we only do one **(31+9)** bits right shift instead, then this issue can be avoided.\r\n\r\nI understand that being bit-match might be very difficult, but this issue will result in quite large relative error(sometimes >20%), and more than 5% elements of a feature map will hit this issue in one convolution layer from my observation. So I think it has significant impact to the final accuray.", "Hey, thanks for raising the question and explaining your logic in the example.\r\n\r\nI think the problem is not with splitting the 31 bit shift and 9 bit shift: (a >> 31) >> 9 is the same as a >> 40, assuming there is no overflow. The subtle difference in from the \"nudge\" in gemmlowp (https://github.com/google/gemmlowp/blob/master/fixedpoint/fixedpoint.h#L320), that instead of (a >> 31) >> 9, it becomes ((a + delta) >> 31) >> 9. The nudge logic is added to simulate \"VQRDMULH\".\r\n- if one merges the >> 9 to .../(1ll<<31) to make it .../(1ll<<40), the result is still 12.\r\n- If one forces \"nudge\" to be zero, the result is 11.\r\n\r\nBTW, the value just happen to be close to one of the 0.5. Without nudge, SaturatingRoundingDoublingHighMul gives 5887 and 5887/2^9 = 11.49, which rounds to 11; with nudge, SaturatingRoundingDoublingHighMul gives 5888 and 5888/2^9 = 11.5, which rounds to 12.\r\n\r\nDo you have a measurement of the overall accuracy impact because of this rounding? Thanks.", "> Hey, thanks for raising the question and explaining your logic in the example.\r\n> \r\n> I think the problem is not with splitting the 31 bit shift and 9 bit shift: (a >> 31) >> 9 is the same as a >> 40, assuming there is no overflow. The subtle difference in from the \"nudge\" in gemmlowp (https://github.com/google/gemmlowp/blob/master/fixedpoint/fixedpoint.h#L320), that instead of (a >> 31) >> 9, it becomes ((a + delta) >> 31) >> 9. The nudge logic is added to simulate \"VQRDMULH\".\r\n> \r\n> * if one merges the >> 9 to .../(1ll<<31) to make it .../(1ll<<40), the result is still 12.\r\n> * If one forces \"nudge\" to be zero, the result is 11.\r\n> \r\n> BTW, the value just happen to be close to one of the 0.5. Without nudge, SaturatingRoundingDoublingHighMul gives 5887 and 5887/2^9 = 11.49, which rounds to 11; with nudge, SaturatingRoundingDoublingHighMul gives 5888 and 5888/2^9 = 11.5, which rounds to 12.\r\n> \r\n> Do you have a measurement of the overall accuracy impact because of this rounding? Thanks.\r\n\r\n--> The nudge logic is added to simulate \"VQRDMULH\".\r\nI think using VQRDMULH is wrong here,  because the result is not final number and you need to perform rounding-shift again.  Rounding after 31-bit shifting will cause the error on numbers such as x.499. \r\nI think VQDMULH without rounding is the correct instruction to use.\r\n", "> instead of (a >> 31) >> 9, it becomes ((a + delta) >> 31) >> 9.\r\n>     * if one merges the >> 9 to .../(1ll<<31) to make it .../(1ll<<40), the result is still 12.\r\n\r\nI'm also a bit puzzled by the gemmlowp mechanism.\r\nIf I understand correctly, in `RoundingDivideByPOT`, effectively another nudge is added, making it `(((a+delta_1) >> 31) + delta_2) >> 9`. (This is not implemented by adding a constant `delta_2` because of overflow reasons, but by checking if the 'shifted-away-bits' are larger than a threshold, and then adding 1 to the result.). My understanding is that these delta's are something along the lines of `round(x) = truncate(x+0.5)` (with corrections for negative `x`).\r\nI think that's the reason why the two separate shifts are not the same as a single shift of 40, and that might be the cause of these rounding mismatches ? I think both gemmlowp functions are correct, and are simulating the correct instruction, but due to using two of these in a row, one can get the effect of first rounding `0.4995` to `0.5000` and then to `1.0`.\r\n\r\nI found that the effect can be amplified to numbers further away from `0.5`, effectively rounding `1.25` to `2` instead of to `1`:\r\n```cpp\r\n  double multiplier = 0.25;\r\n  std::int32_t significand;\r\n  int shift;\r\n  ::tflite::QuantizeMultiplier(multiplier, &significand, &shift);\r\n\r\n  int x = 5;\r\n  int result = ::tflite::MultiplyByQuantizedMultiplier(x, significand, shift);\r\n```\r\nThis computes `round(5 * 0.25) = round(1.25)` and produces `result = 2`.\r\n\r\nThe two roundings can be merged into one by modifying the gemmlowp function as follows:\r\n```cpp\r\nstd::int32_t SaturatingRoundingDoublingHighMulWithShift(std::int32_t a,\r\n                                                   std::int32_t b, int shift) {\r\n  // TODO: how to handle overflow when shift <= 0 ?\r\n  bool overflow = a == b && a == std::numeric_limits<std::int32_t>::min();\r\n  std::int64_t a_64(a);\r\n  std::int64_t b_64(b);\r\n  std::int64_t ab_64 = a_64 * b_64;\r\n  // nudge updated with shift and turned into int64\r\n  std::int64_t nudge =\r\n      ab_64 >= 0 ? ((1ll << (30 + shift))) : (1 - (1ll << (30 + shift)));\r\n  std::int32_t ab_x2_high32 =\r\n      static_cast<std::int32_t>((ab_64 + nudge) / (1ll << (31 + shift)));\r\n  return overflow ? std::numeric_limits<std::int32_t>::max() : ab_x2_high32;\r\n}\r\n```\r\n(This is for `multiplier < 1.0`, I haven't looked at the other case yet.)\r\nI ran this fix on all multipliers of the form `i / 1000` where `i` ranges from 1 to 999. For each multiplier, I iterated over several values that would cause rounding near ties, for example when the multiplier is `0.625` then I would attempt `-13 * 0.625`, `-12 * 0.625` and `-11 * 0.625` , all close to `-7.5`.\r\nThe results were that the tflite double rounding had `19772` 'wrong roundings' and the fix above only had `300` wrong roundings. There were `156` cases where the tflite version was correct and the fix was not, and there were `19628` cases where the fix was correct and the tflite version was not.\r\nThe average bias introduced by the two methods was almost equal.\r\nImportantly, the 'fix' was only wrong on perfect ties, i.e. incorrectly rounding `4.5` to `4`. The tflite version, for every multiplier, was always wrong exactly once *below every tie*.\r\n\r\nThis would suggest that this 'fix' is better (and it'd even be faster than the separate rounds). However I think it might not be efficiently implementable with NEON instructions, so it would only be useful on microcontrollers and such.", "@petewarden  Would it be a good idea to use this rounding on tflite-micro ?", "Bit-exactness is not part of the contract here. Do whatever is friendly to your target hardware as long as it's a reasonable round-to-nearest scheme without significant bias.\r\n\r\nIt is expected that different hardware targets will run different, non-bit-exact flavors of MultiplyByQuantizedMultiplier and RoundingRightShift.\r\n\r\nRegarding MultiplyByQuantizedMultiplier:\r\nFor example, we have seen people use 16-bit fixedpoint instead of 32-bit fixedpoint multipliers on Qualcomm HVX, and we have seen people use float32 instead of 32-bit fixedpoint multipliers on Google EdgeTPU.\r\n\r\nRegarding RoundingRightShift:\r\nEven on ARM NEON, our thinking has evolved a bit. We used to think that it would be important for the rounding right shift to break ties away from zero, out of a concern that breaking ties upward would be \"biased\". However, in practice, away-from-zero is only unbiased if the data is centered around zero, which it not always is, so there was no practical unbiasing benefit from that, so we now happily use ARM NEON's own \"rounding right shift\", breaking ties upward.\r\n\r\nIn the newer matrix multiplication library used by TFLite in the quantized case on ARM, we are using SQRDMULH followed by RSHL i.e. native NEON rounding shift per the previous paragraph, by default. We've retained the ability to compile to the old break-ties-away-from-zero way but might drop it soon.\r\nSearch for NATIVE_ROUNDING in this file,\r\nhttps://github.com/google/ruy/blob/a0ca5e6d3d1b1771197368c5cf38de1f9fe7f1e0/ruy/kernel_arm64.cc\r\n\r\nWe hadn't bothered to update these TFLite functions because not much time was being spent there.\r\n\r\nDo you care about the efficiency of these functions because they're significant on your CPU profiles or do you care about the clarification that bit-exactness is not required for your own ports?  In the former case, we'll happily take a patch optimizing these functions by relaxing them as in the above-linked ruy code. In the latter case, this might be more of a documentation issue? Do you still see a need for SaturatingRoundingDoublingHighMulWithShift given the non-requirement of bit-exactness ?", "Thanks for the clarification, that helps a lot!\r\nI will investigate the latency impact of this on the systems I'm interested in, and if its significant I'll submit a patch.\r\n\r\n> Do whatever is friendly to your target hardware as long as it's a reasonable round-to-nearest scheme without significant bias.\r\n\r\nI have one more question about this: from what I understood, the scheme should always round-to-nearest, and the freedom is in how perfect ties are rounded. But in the example above, the numbers `0.25`, `1.25`, `2.25` etc all get rounded upwards to `1`, `2`, `3` respectively, which is not round-to-nearest anymore. So is there more freedom than just the ties?", "Ah, I understand what you were saying now, sorry that I didn't read closely enough the first time.\r\n\r\nIt's not very well defined what exactly are the boundaries of what's allowed. As I alluded to above, some hardware targets have needed to perform these computations at lower bit depths, such as 16-bit fixedpoint multipliers on Qualcomm HVX or 23-bit-mantissa float32 on Google EdgeTPU. That in itself is more freedom than merely freedom in breaking ties. So when I said \"Do whatever is friendly to your target hardware as long as it's a reasonable round-to-nearest scheme without significant bias.\" it had by necessity to include allowing for such deeper arithmetic differences, such as using lower precision data types, and then it seems unavoidable that we can't require off-by-one errors to be limited to ties only.  So yes, there is more freedom than just the ties.\r\n\r\nHow much freedom exactly, is not formalized at the moment.\r\n\r\nSeparate from \"how much freedom do hardware ports have\" is the other question \"what code should TFLite carry as 'reference code'\". TFlite's reference code needs to be accurate, portable, and give a reasonable starting point for porting to hardware. The current code is shown by the present issue to have a quite serious accuracy flaw, but on the other hand it's easy to port to hardware thanks to being a sequence of two distinct steps, MultiplyByQuantizedMultiplier and RoundingRightShift, each of which tends to be fairly well understood how to map to hardware. by contrast, SaturatingRoundingDoublingHighMulWithShift is better accuracy-wise but it is apparently difficult to port to most hardware, because it seems to require going through twice-wider integer (e.g. 32bit -> 64bit) to apply the nudge there, unless the architecture natively has an instruction for doing exactly that computation (it's not inherently harder to implement in hardware, it just does not fit common fixed-point-multiplication instructions). So at this point I don't know what we can usefully do about this.  Maybe at least add a summary of this discussion / a link to this issue in a comment ?", "> TFlite's reference code needs to be accurate, portable, and give a reasonable starting point for porting to hardware. \r\n\r\nThanks for the clarification, that makes a lot of sense, and the 'fix' I suggested does indeed not satisfy those criteria.\r\n\r\n> it seems to require going through twice-wider integer (e.g. 32bit -> 64bit) to apply the nudge there\r\n\r\nI'm not sure if that is a big problem, since the nudge was already being added to the 64-bit multiplication result, before it was right-shifted back into a 32-bit value. I do agree that the function as a whole would no longer translate to a common hardware instruction.\r\n\r\n> Maybe at least add a summary of this discussion / a link to this issue in a comment ?\r\n\r\nThat sounds good to me.\r\n\r\n\r\nI have been running TF Micro on Cortex-M cores using CMSIS-NN, and it seems that in their effort to become [TF Micro compliant](https://github.com/ARM-software/CMSIS_5/blob/develop/CMSIS/NN/README.md), they have copied this reference rounding code, see [here](https://github.com/ARM-software/CMSIS_5/blob/5b694867a8c8dce47b860cf4a17403cc4754bafb/CMSIS/NN/Include/arm_nnsupportfunctions.h#L739-L743) .\r\nAs far as I know, on the Cortex-M series these two functions do not directly translate to instructions, in which case `SaturatingRoundingDoublingHighMulWithShift` would actually make things faster (and more accurate).\r\nSo based on what you're saying (and if its indeed faster), it makes sense to ping the devs of CMSIS-NN and tell them that the bit-exact match is not needed, and they can use `SaturatingRoundingDoublingHighMulWithShift`, potentially guarded by a preprocessor flag like `RUY_OPT_NATIVE_ROUNDING` from the example you linked to.\r\n\r\n(The tflite implementation of `MultiplyByQuantizedMultiplier` could also do this based on such a preprocessor flag, but that would only affect reference code so it should not matter so much.)", "> I do agree that the function as a whole would no longer translate to a common hardware instruction.\r\n\r\nRight, that's the concern that I was highlighting here.\r\n\r\nI agree with everything you say. I hadn't been following these developments around TFLite for microcontrollers. It does sound like some documentation or at least comments to make the conclusions of the present discussion more discoverable, would be useful.\r\n\r\nPoint taken that, SaturatingRoundingDoublingHighMulWithShift, while less friendly to NEON hardware, is more friendly to Cortex-M, so it arguably makes a better reference function to have here in TFLite code. I'd like to let others take it from here, as I haven't been very closely involved in this code for the past 2 years and I shouldn't end up owning this again. @suharshs ?", "Thanks @bjacob for the detailed responses.\r\n\r\nWe cannot change the default rounding mode in TFLite due to backwards compat issues, that being said since you are targetting a microcontroller, TFLite Micro may be able to accomodate this need in their infra. Will assign to them to get their thoughts.\r\n\r\nThanks!"]}, {"number": 25077, "title": "No code examples for rewriting existing graph using tf.quantization.fake_quant_with_min_max_vars for quantization-aware training", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12.0\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\nIt would be great if code examples or a tutorial can be written up to help with manually inserting fake quant nodes into an existing TensorFlow graph. The current rewriter provided in contrib/quantize doesn't seem to be able to handle complex graphs well.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": []}, {"number": 24795, "title": "Recurrent batch normalization : While_loop and control_depenecies bug", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): compiled from source \r\n- GCC/Compiler version (if compiling from source): c++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- CUDA/cuDNN version: 9.1\r\n- GPU model and memory:  Tesla K80 \r\n\r\n\r\n**Describe the current behavior**\r\nAdding batch normalization to a bidirectional RNN prevent me from updating the moving_mean and moving_variances during training and inference correctly.\r\nThe problem is that both the ```tf.control_dependencies``` and the ``while_loop```  of the dynamic_rnn are executed at the same time. The gradient will find nodes that have input from different frames and will throw errors. \r\n\r\nMy error message is  : \r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: node train/update (defined at ...)  has inputs from different frames. \r\nThe input node bidirectional_rnn/fw/fw/while/fw/bnlstm_cell/bnlstm_cell/state/batch_normalization/AssignMovingAvg (defined at ... )  is in frame 'train/Listener/features/layer1/BLSTM/bidirectional_rnn/fw/fw/while/while_context'. The input node train/apply_gradients/Assign (defined at ... )  is in frame ''.\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe expected behaviour is being able to add the control_dependencies when we have the while_loop context. \r\nAdding clearer documentation about how to handle the moving_mean and moving_variance in case you have a distributed training.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\ndef _update(self, loss, learning_rate, cluster):\r\n    '''\r\n    create the op to update the model\r\n\r\n    args:\r\n        loss: the loss to minimize\r\n        learning_rate: the learning rate\r\n        cluster: the tf cluster\r\n\r\n    returns: the update op\r\n    '''\r\n\r\n    #create the optimizer\r\n    optimizer = tf.train.AdamOptimizer(learning_rate)\r\n\r\n    #create an optimizer that aggregates gradients\r\n    if int(self.conf['numbatches_to_aggregate']) > 0:\r\n        if 'local' in cluster.as_dict():\r\n            num_workers = 1\r\n        else:\r\n            num_workers = len(cluster.as_dict()['worker'])\r\n\r\n        optimizer = tf.train.SyncReplicasOptimizer(\r\n            opt=optimizer,\r\n            replicas_to_aggregate=int(\r\n                self.conf['numbatches_to_aggregate']),\r\n            total_num_replicas=num_workers)\r\n\r\n\r\n    tf.summary.scalar('training_loss', loss,\r\n                      collections=['training_summaries'])\r\n\r\n    #get the list of trainable variables\r\n    trainable = tf.trainable_variables()\r\n\r\n    #get the list of variables to be removed from the trainable\r\n    #variables\r\n    untrainable = tf.get_collection('untrainable')\r\n\r\n    #remove the variables\r\n    trainable = [var for var in trainable\r\n                 if var not in untrainable]\r\n\r\n    #compute the gradients\r\n    grads_and_vars = optimizer.compute_gradients(\r\n        loss=loss,\r\n        var_list=trainable)\r\n\r\n    with tf.variable_scope('clip'):\r\n        #clip the gradients\r\n        grads_and_vars = [(tf.clip_by_value(grad, -1., 1.), var)\r\n                          for grad, var in grads_and_vars]\r\n\r\n\r\n    #opperation to apply the gradients\r\n    apply_gradients_op = optimizer.apply_gradients(\r\n        grads_and_vars=grads_and_vars,\r\n        name='apply_gradients')\r\n\r\n    #all remaining operations with the UPDATE_OPS GraphKeys\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    print(\"update_ops {}\".format(update_ops))\r\n    print(\"################\")\r\n    #create an operation to update the gradients, the batch_loss\r\n    #and do all other update ops\r\n    update_op = tf.group(\r\n        *([apply_gradients_op] + update_ops),\r\n        name='update')\r\n\r\n    return update_op\r\n\r\n```\r\n**Other info / logs**\r\n\r\nrelated issues : \r\n1) https://github.com/tflearn/tflearn/issues/540#issue-197855026\r\n2) https://github.com/tensorflow/tensorflow/issues/6087#issue-193534788\r\n\r\n", "comments": ["Looking down for the implementation of the batch norm I read this comment on the code of the ```tf.contrib.layers.batch_norm```:\r\n\r\n` # Create moving_mean and moving_variance variables and add them to the\r\n    # appropriate collections. We disable variable partitioning while creating\r\n    # them, because assign_moving_average is not yet supported for partitioned\r\n    # variables (this needs to be handled carefully, as it may break\r\n    # the checkpoint backward compatibility).`\r\n\r\n\r\n [link to the comment](https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/contrib/layers/python/layers/layers.py#L335)", "Hello @AzizCode92 , confirm that you want this to be treated as documentation issue. Thanks.\r\nHi @ebrevdo , can we document this moving_mean/moving_variance behavior or is there some workaround? Thanks.", "Hello @msymp, thank you for your answer. Yes part of my question should be treated as lack of the documentation for handling the moving_mean/moving_variance in case of \r\n1. bidirectional rnn (how to keep track of the update_op inside the while_loop ).\r\n2. distributed training (maybe extend the batch_norm to include number of gpus (int variable: optional) and it will handle averaging the mean/variance for you during training/inference)\r\n\r\n\r\nHowever, the error when we got when handling the control_dependencies inside a while_loop was described by a lot of users before so maybe it should be treated as a bug.\r\n\r\n\r\n\r\n"]}, {"number": 24732, "title": "ARM6/RPI: Executor failed to create kernel _FusedConv2D", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nARM 6 (Raspberry PI Zero W)\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n\r\n- TensorFlow installed from (source or binary):\r\nSource at 92b598a32d5f8c636b9eb1cdc7afcb958395500f\r\n\r\n- TensorFlow version (use command below):\r\nn/a\r\n\r\n- Python version:\r\nn/a\r\n\r\n- Bazel version (if compiling from source):\r\nn/a\r\n\r\n- GCC/Compiler version (if compiling from source):\r\nn/a\r\n\r\n- CUDA/cuDNN version:\r\nn/a\r\n\r\n- GPU model and memory:\r\nn/a\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nn/a\r\n\r\n**Describe the current behavior**\r\nMy use case is running TensorFlow as a C-library using Go interface. I am performing an image inferencing task using a model (`.pb file`). I see that my `libtensorflow.so` build works fine on ARM7 but fails on ARM6 with the following error:\r\n```\r\n2019-01-07 04:07:27.533445: E tensorflow/core/common_runtime/executor.cc:634] Executor failed to create kernel. Not found: No registered '_FusedConv2D' OpKernel for CPU devices compatible with node {{node module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu}}\r\n\t.  Registered:  <no registered kernels>\r\n\r\n\t [[module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu]]\r\n2019/01/07 04:07:27 session run:No registered '_FusedConv2D' OpKernel for CPU devices compatible with node {{node module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu}}\r\n\t.  Registered:  <no registered kernels>\r\n\r\n\t [[module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/Relu]]\r\n```\r\n\r\n**Describe the expected behavior**\r\nexpecting ARM6 build of `libtensorflow.so` and `libtensorflow_framework.so` to work the same as ARM7 build.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hello @sdeoras , Although your question is interesting, it is more of a systems query regarding ARM6 vs ARM7 builds, hence is best addressed on Stack Overflow at:\r\n[Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow)\r\nWe shall close this issue now. Thanks.", "@msymp, np. i'll try to explore this issue on stack overflow. I could not tell from the error mesg if was code issue or ARM6 issue :)", "@petewarden may know\r\n", "Hello @sdeoras I have exactly the same problem on a armv7l board (cortex A9) with tensorflow 1.12.0. Do you solve this problem on StackOverflow (i didn't find any relevant questions on SO) ?\r\n\r\nRegards. ", "@nemo-point: i saw the issue on arm 6 but things worked fine on arm 7. I tried master though. no, i have not found a solution so far.", "I'm not sure what's happening here unfortunately! I don't think I'll have a chance soon to debug, so adding contributions welcome.", "hello\r\nsame error here\r\nhave you solve it ?", "Yep, same problem here on Raspberry 3+", "I solved my problem (Nitrogen Quad board - iMX6 - cortex A9, armv7l) by changing some compilation features following the [notifications from ARM](https://community.arm.com/developer/tools-software/tools/b/tools-software-ides-blog/posts/arm-cortex-a-processors-and-gcc-command-lines): \r\n\r\nUsing the build script provided by tensorflow for RASPBERRY boards, I used the following compilation line in tensorflow/tools/ci_build/pi/build_raspberry_pi.sh : \r\n\r\n```\r\nPI_COPTS=\"--copt=-march=armv7-a --copt=-mfpu=vfpv3\r\n  --copt=-std=gnu11 --copt=-DS_IREAD=S_IRUSR --copt=-DS_IWRITE=S_IWUSR\r\n  --copt=-O3\r\n  --copt=-U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_1\r\n  --copt=-U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_2\r\n  --copt=-U__GCC_HAVE_SYNC_COMPARE_AND_SWAP_8\"\r\n  WHEEL_ARCH=linux_armv7l\r\n```\r\nAfter cross-compiling and installing the wheel on the target board, everything was OK : training, testing, load & save models with a simple CNN on MNIST ([classical example of Keras](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)). \r\n\r\nRegards", "Any TF staff guidance on an ARM6l fix/workaround? It seems Tensorflow is keen to fuse the Conv2D & ReLU operations even if I make them separate ops - in contrast to using the activation parameter in tf.keras.layers.Conv2D.", "@petewarden may have a comment on this.", "It seems fused Conv2D and ReLU operations can work on ARMv6 if I disable biasing in Conv2D operations (use_bias=False).\r\n"]}, {"number": 24717, "title": "Deadlock probably with RandomShuffleQueue and FIFOQueue", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5 LTS (GNU/Linux 4.17.0-041700-generic x86_64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tensorflow-gpu (1.12.0)\r\n- Python version: Python 3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 1080Ti 12G\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nI used seq2seq to train an RNN model, and during training the process randomly hangs. It seems to be associated with RandomShuffleQueue or FIFOQueue because they seem to create threads.\r\n\r\n```\r\n    for dataset in datasets:\r\n      _, line = parallel_reader.parallel_read( # This creates tf.FIFOQueue\r\n        dataset.data_sources,\r\n        reader_class=dataset.reader,\r\n        num_epochs=num_epochs, # This should be None\r\n        num_readers=1,\r\n        shuffle=False,\r\n        capacity=common_queue_capacity,\r\n        min_after_dequeue=common_queue_min,\r\n        seed=seed\r\n      )\r\n      lines.append(line)\r\n\r\n    if shuffle:\r\n      shuffle_queue = tf.RandomShuffleQueue(\r\n        dtypes=[tf.string for _ in datasets],\r\n        capacity=common_queue_capacity,\r\n        min_after_dequeue=common_queue_min,\r\n        seed=seed\r\n      )\r\n      enqueue_ops = []\r\n      enqueue_ops.append(shuffle_queue.enqueue(lines))\r\n      tf.train.add_queue_runner(\r\n          tf.train.QueueRunner(shuffle_queue, enqueue_ops))\r\n```\r\nTo debug, I start another thread to print the current stacks. When it does not hang, it prints:\r\n```\r\n--------------------------------------------------------------------\r\nthreads: 2019-01-06 02:09:15.317473\r\nThread 0x00007f39da7fc700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39daffd700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1267 in _single_tensor_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39db7fe700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39dbfff700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f0ff9700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f17fa700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f1ffb700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f27fc700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f2ffd700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f37fe700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f3fff700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39f8e17700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fc7f8700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fcff9700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fd7fa700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fdffb700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fe7fc700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39feffd700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3a03ab1700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3cb8ff9700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3cb97fa700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3cb9ffb700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3a032b0700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3a02aaf700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39fffff700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/threading.py\", line 549 in wait\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 311 in wait_for_stop\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 293 in _close_on_stop\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f39ff7fe700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1257 in _single_operation_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257 in _run\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f3d9ffff700 (most recent call first):\r\n  File \"/usr/lib/python3.5/threading.py\", line 293 in wait\r\n  File \"/usr/lib/python3.5/queue.py\", line 164 in get\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/summary/writer/event_file_writer.py\", line 159 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nCurrent thread 0x00007f3f50b37700 (most recent call first):\r\n  File \"/home/yjf/s2s_download/seq2seq/bin/thread_monitor.py\", line 25 in log_threads\r\n  File \"/usr/lib/python3.5/threading.py\", line 862 in run\r\n  File \"/usr/lib/python3.5/threading.py\", line 914 in _bootstrap_inner\r\n  File \"/usr/lib/python3.5/threading.py\", line 882 in _bootstrap\r\n\r\nThread 0x00007f4075bb4700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407 in _call_tf_sessionrun\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1319 in _run_fn\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1334 in _do_call\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1328 in _do_run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152 in _run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 929 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1076 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1312 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1240 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1156 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 671 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1095 in _train_model\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 525 in fit\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488 in new_func\r\n  File \"/home/yjf/s2s_download/seq2seq/seq2seq/contrib/experiment.py\", line 104 in continuous_train_and_eval\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 52 in _execute_schedule\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 225 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 306 in new_func\r\n  File \"/home/yjf/s2s_download/seq2seq/bin/train.py\", line 273 in main\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125 in run\r\n  File \"/home/yjf/s2s_download/seq2seq/bin/train.py\", line 280 in <module>\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85 in _run_code\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184 in _run_module_as_main\r\n--------------------------------------------------------------------\r\n```\r\n\r\nWhen the process is hang, seemingly in deadlock, the only change is the main thread's stack,\r\nwith the top of the stack being `join`.\r\n\r\n```\r\nThread 0x00007f4075bb4700 (most recent call first):\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py\", line 373 in join  # <--------------------- HERE\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1229 in close\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 1069 in close\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 821 in _close_internal\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 783 in __exit__\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1095 in _train_model\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 525 in fit\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488 in new_func\r\n  File \"/home/yjf/s2s_download/seq2seq/seq2seq/contrib/experiment.py\", line 104 in continuous_train_and_eval\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 52 in _execute_schedule\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 225 in run\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 306 in new_func\r\n  File \"/home/yjf/s2s_download/seq2seq/bin/train.py\", line 273 in main\r\n  File \"/home/yjf/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125 in run\r\n  File \"/home/yjf/s2s_download/seq2seq/bin/train.py\", line 280 in <module>\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85 in _run_code\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184 in _run_module_as_main\r\n```\r\nI am not quite familiar with python multi-thread. Perhaps due to the GIL, this info was not printed when the process hanged, but when I interrupted the process with ctrl+c. If you have any ideas on these kind of debugging, I will be very grateful to hear.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should not hang.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nI am not quite sure which parts lead to the hanging.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nNone.", "comments": ["More information: Two of the Queues share one file. Does that matter?\r\n\r\nWell, copying the file and let them read separately seems to have empirically solved my problem (not true). But it does not make sense to me that read-only stuff can lead to deadlock. Maybe the document should warn people not to share any file among queues.\r\n\r\nAfter copying the file, it hangs again.", "Hello @ebrevdo , This user has queue APIs that seem to have their threads deadlock on a file read. Can you confirm that the user is correct in the statement: \"Maybe the document should warn people not to share any file among queues.\" Thanks.", "the queues should not deadlock when reading from the same file.  what filesystem are you reading from?", "@hanayashiki , can you provide the filesystem details on your Ubuntu 16.04.5 LTS. Thanks.", "> @hanayashiki , can you provide the filesystem details on your Ubuntu 16.04.5 LTS. Thanks.\r\n```\r\n\u6587\u4ef6\u7cfb\u7edf       \u7c7b\u578b          1K-\u5757       \u5df2\u7528       \u53ef\u7528 \u5df2\u7528% \u6302\u8f7d\u70b9\r\nudev           devtmpfs  115468104          0  115468104    0% /dev\r\ntmpfs          tmpfs      23100400      19188   23081212    1% /run\r\n/dev/sdb2      ext4      215960612  190471176   14496236   93% /\r\ntmpfs          tmpfs     115501980        208  115501772    1% /dev/shm\r\ntmpfs          tmpfs          5120          4       5116    1% /run/lock\r\ntmpfs          tmpfs     115501980          0  115501980    0% /sys/fs/cgroup\r\n/dev/sdb1      vfat         523248       3496     519752    1% /boot/efi\r\n/dev/sda       ext4     9687795200 2845535192 6354000424   31% /data\r\ntmpfs          tmpfs      23100400         44   23100356    1% /run/user/108\r\ntmpfs          tmpfs      23100400          0   23100400    0% /run/user/1004\r\ntmpfs          tmpfs      23100400          0   23100400    0% /run/user/1010\r\ntmpfs          tmpfs      23100400          4   23100396    1% /run/user/1002\r\ntmpfs          tmpfs      23100400          0   23100400    0% /run/user/1007\r\ntmpfs          tmpfs      23100400          0   23100400    0% /run/user/1015\r\n```\r\nMine is using /dev/sdb2      ext4      215960612  190471176   14496236   93% /\r\nThank you for your attention.", "Hi @ebrevdo , the user indicates they are using an ext4 filesystem in the listing. does that narrow the problem? Thanks."]}, {"number": 24575, "title": "[Performance] Unnecessary 'memcpy' in Gather Op", "body": "**Describe the current behavior**\r\nIn distributed mode, user define a Graph, 'distribute_runtime' partition graph, register graph, and then run graph, For example as below.\r\n![image](https://user-images.githubusercontent.com/7778833/50445822-3140b700-094c-11e9-8d5e-78418403836f.png)\r\nps: Gather Op generates a new Tensor (allocation and **memcpy**), Send Op put the Tensor to local Rendezvous's table.\r\nworker: Recv Op triggers GRPC RecvTensorResponse method via remote Rendezvous, calls EncodeTensorToByteBuffer(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/distributed_runtime/rpc/grpc_tensor_coding.cc), if DataTypeCanUseMemcpy==true, encodes tensor with wire format instead of TensorProto serialization. in this case, TensorEncoding doesn't depend on a continuous memory(Gather Op output Tensor)\r\n\r\n**Describe the expected behavior**\r\nWhen Gather Op -> Send Op and Tensor's dtype is simple type, Gather Op's output is a 'IndexedTensor' without memcpy. The 'IndexedTensor' contains some offsets of IDs and a RefCounted TensorBuffer. In GRPC ZeroCopyStream, send the list<pair<pointer, length>> by grpc::Slice.\r\nPerformance: reduce a memcpy\r\nSame optimization can apply to other Op, such as: Concat Op, Slice Op ...\r\n\r\n**Other info**\r\n\r\n", "comments": ["@saeta thanks"]}, {"number": 24539, "title": "[feature request] make MutableHashTableOfScalars and MutableHashTableOfTensors trainable", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThis issue is related to issue #19324, in which we need some technique to do embedding on a large sparse hash table, so that we can reduce memory usage and the probability of hash collision.\r\n\r\nAs far as I can see, ops like MutableHashTableOfScalars and MutableHashTableOfTensors in [lookup table ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/lookup_ops.cc) can be used to meet this demand. The main problem is that they are not trainable. \r\n\r\nIn other words, what we need may be a feature like this:\r\n```\r\n# define a Hash Table\r\ntable = tf.contrib.lookup.MutableHashTable(\r\n    key_dtype=tf.string,\r\n    value_dtype=tf.float64,\r\n    default_value=-1)\r\nparams = table.lookup([\"w1\", \"w2\", \"b\"])\r\n# define other ops with params\r\n...\r\n# optimize the table\r\ntrain_op = optimizer.minimize(loss, var_list=[table], global_step=global_step)\r\n```\r\n\r\n**Will this change the current api? How?**\r\n\r\nYes, the current API would be changed. \r\n\r\nIn order to implement a feature like this, we may need to:\r\n* do modification on the lookup table ops to make it trainable. This involves several parts of fix like:\r\n   1. some fix in python layer as only variables are trainable now.\r\n   2. several new ops may be add in lookup table so that we can update the gradients. \r\n* modify the api of MutableHashTable, so that we can pass more args, like: \r\n   1. shard it to different parameter servers.\r\n   2. when value for a key doesn't exist, we can initialize it with different initial value.\r\n   3. we can make the KV pairs have TTL.\r\n* add a new API like embedding_lookup_sparse, or do modification on it.\r\n* make sure the checkpoint for hash tables can work properly\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAs a matter of fact, sparse models in recommend system may benefit with this feature a lot.\r\n", "comments": ["Looking forward to the feature.", "\u671f\u5f85\u65b0\u7279\u6027\uff01", "@gunan We have tried a roughly implementation at https://github.com/tensorflow/tensorflow/pull/24915 based on class `MutableHashTableOfTensors`. Can you have a look?", "I would not be the right reviewer of this.\r\nI will reassign to see if we can find a better reviewer.", "@gunan Many thanks.\r\nAnd @jvishnuvardhan could you take some time to revew the codes? Thanks!", "FYI @ebrevdo ", "Looking forward to the feature.", "this is very useful and important . In China, tensorflow is dramatically used in recommender system. However, when we want to learn something from user's behavior, large embedding layers are always required. \r\n\r\n", "Looking forward to the feature.", "Looking forward to the feature.\r\n\r\n", "This was discussed in https://github.com/tensorflow/tensorflow/issues/19324 and the RFCs from Tencent/Alibaba are under discussion https://github.com/tensorflow/community/pull/237 ."]}, {"number": 24445, "title": "Bad accuracy on ML Kit with InceptionV3 tflite model", "body": "Hi, I have a problem with InceptionV3 tflite model executed on MLKit SDK. I'm not using the ILSVRC Dataset for reasons of storage space and execution time. I'm using the Caltech Dataset , find it [here](http://www.vision.caltech.edu/Image_Datasets/Caltech101/). I have also remove categories that Inception V3 is not able to recognize. I'm doing a comparison of the new Mobile Machine Learning SDKs, and i try to use the new Snapdragon Neural Processing Engine (SNPE) and MLKit. I ran inceptionV3 on both SDKs, and with SNPE I have reached the 82% of correct classifications, and with MLKit the 47%. For MlKit, I have download the tflite float model from [here](https://www.tensorflow.org/lite/models).\r\nI build the network with the following code:\r\n\r\n            long startBuild = SystemClock.elapsedRealtime();\r\n            FirebaseLocalModelSource localSource =\r\n                    new FirebaseLocalModelSource.Builder(\"inception_v3\")  // Assign a name for this model\r\n                            .setAssetFilePath(\"inception_v3.tflite\")\r\n                            .build();\r\n            FirebaseModelManager.getInstance().registerLocalModelSource(localSource);\r\n            FirebaseModelOptions options = new FirebaseModelOptions.Builder()\r\n                    .setLocalModelName(\"inception_v3\")\r\n                    .build();\r\n            FirebaseModelInterpreter firebaseInterpreter =\r\n                    FirebaseModelInterpreter.getInstance(options);\r\n            FirebaseModelInputOutputOptions inputOutputOptions =\r\n                    new FirebaseModelInputOutputOptions.Builder()\r\n                            .setInputFormat(0, FirebaseModelDataType.FLOAT32, new int[]{1, 299, 299, 3})\r\n                            .setOutputFormat(0, FirebaseModelDataType.FLOAT32, new int[]{1, 1001})\r\n                            .build();\r\n            long endBuild = SystemClock.elapsedRealtime();\r\n\r\nAnd then I preprocess image:\r\n\r\n            resized_image =  Bitmap.createScaledBitmap(image, 299,299, false);\r\n            input = new float[1][299][299][3];\r\n            for (int x = 0; x < 299; x++) {\r\n                for (int y = 0; y < 299; y++) {\r\n                    int pixel = resized_image.getPixel(x, y);\r\n                    // Normalize channel values to [0.0, 1.0]. This requirement varies by\r\n                    // model. For example, some models might require values to be normalized\r\n                    // to the range [-1.0, 1.0] instead.\r\n\r\n                    float b = ((pixel)       & 0xFF);\r\n                    float g = ((pixel >>  8) & 0xFF);\r\n                    float r = ((pixel >> 16) & 0xFF);\r\n                    input[batchNum][x][y][0] = (r - 127) / 128.0f;\r\n                    input[batchNum][x][y][1] = (g - 127) / 128.0f;\r\n                    input[batchNum][x][y][2] = (b - 127) / 128.0f;\r\n                    //input[batchNum][x][y][0] = (Color.red(pixel) - 128) / 128.0f;\r\n                    //input[batchNum][x][y][1] = (Color.green(pixel) - 128) / 128.0f;\r\n                    //input[batchNum][x][y][2] = (Color.blue(pixel) - 128) / 128.0f;\r\n                }\r\n            }\r\n\r\n            inputs = new FirebaseModelInputs.Builder()\r\n                    .add(input)  // add() as many input arrays as your model requires\r\n                    .build();\r\n\r\n\r\n\r\n            Task<FirebaseModelOutputs> task = firebaseInterpreter.run(inputs, inputOutputOptions);\r\n", "comments": ["I'm using Ubuntu 18.04, Android Studio 3.1 and I ran the test on this [device](https://www.intrinsyc.com/snapdragon-embedded-development-kits/open-q-660-development-kit/).", "Does anyone have a solution or a motivation fot this behavior?", "@srjoglekar246 would you mind validating the accuracy of the linked Inceptionv3 model (against our standard classification test)? Thanks."]}, {"number": 24439, "title": "TypeError: Can't convert Operation 'MutableHashTable' to Tensor", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version: 3.6.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nmeta graph exported by export_meta_graph cannot be imported by import_meta_graph\r\n\r\n**Describe the expected behavior**\r\n\r\nexport_meta_graph and import_meta_graph works.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.lookup.lookup_ops import MutableHashTable\r\nfrom tensorflow.contrib.lookup.lookup_ops import MutableDenseHashTable\r\n\r\nexport_dir = 'minimal_saved_model'\r\n#builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\r\n\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n\r\n    #table = MutableDenseHashTable(key_dtype=tf.int64, \\\r\n    # value_dtype=tf.int64, default_value=-1, empty_key=0)\r\n    table = MutableHashTable(key_dtype=tf.int64, value_dtype=tf.int64, default_value=-1)\r\n    aa = tf.get_variable('xxx', shape=(3,))\r\n\r\n    meta = tf.train.export_meta_graph()\r\n    saver = tf.train.Saver()\r\n\r\n\r\nwith tf.Session(graph=tf.Graph()) as sess1:\r\n    tf.train.import_meta_graph(meta)\r\n```\r\n**Other info / logs**\r\nrelated to #11888 . It seems that SaveableObject is not recreated correctly.\r\n\r\nstack traces:\r\n\r\n```python\r\n  File \"minimal_case.py\", line 22, in <module>\r\n    tf.train.import_meta_graph(meta)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1970, in import_meta_graph\r\n    return Saver()\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 813, in _build_internal\r\n    saveables = self._ValidateAndSliceInputs(names_to_saveables)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 661, in _ValidateAndSliceInputs\r\n    names_to_saveables = BaseSaverBuilder.OpListToDict(names_to_saveables)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 629, in OpListToDict\r\n    var = ops.internal_convert_to_tensor(var, as_ref=True)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1104, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 6130, in _operation_conversion_error\r\n    name, as_ref))\r\nTypeError: Can't convert Operation 'MutableHashTable' to Tensor (target dtype=None, name=None, as_ref=True)\r\n```\r\n", "comments": ["I think we could close this. Also we don't support TF 1.x anymore.", "Hello, i got the same problem. Did you have a solution?", "> Hello, i got the same problem. Did you have a solution?\r\n\r\n@kkzheng Not yet. But I think what you can do it to replace `import_meta_graph` call by yourself. I encounter the problem when I try to import and export again in order to manipulate the graph. Finally, I gave it up.", "I replicated this problem using compatibility mode in [2.8](https://colab.sandbox.google.com/gist/mohantym/26ff856cd8771e5a1370306c25542ccc/github_24439.ipynb#scrollTo=x-Fthhl55aHo). ", "The problem is that we don't have an import test for `MutableHashTable` but only for `StaticHashTable`:\r\nhttps://github.com/tensorflow/tensorflow/blob/480dd2f0f7dbd6da754b714925f7f4623472ad89/tensorflow/python/kernel_tests/data_structures/lookup_ops_test.py#L413-L431\r\n", "Now it is covered by an expected failing test https://github.com/tensorflow/tensorflow/pull/55200 that we could merge.\r\n\r\nWe could investigate later how to fix it and collect some hints from the internal team on what kind of PR they want.", "This is now covered by an expected failing test. \r\nTo contribute this feature with a PR a contributor will need to write the code and pass this test removing the `@unittest.expectedFailure` decorator.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3cb23b56712d2e85e0a97c58cac771dcf40ca7cb/tensorflow/python/kernel_tests/data_structures/lookup_ops_test.py#L3358-L3381\r\n\r\n@mihaimaruseac @theadactyl @yarri-oss  Do you think that we could use a special label other the eventually `stat:contributions welcome` when we have a ticket covered by an expected failing test like e.g `stat:test_covered`?\r\nCause I think It could be really useful for two main goals:\r\n- to set a potential preference on contributing a PR cause we have already a specific test that need to pass.\r\n- for the @tensorflow/dev-support to not periodically go  to manually check an often not \"minimized\" gist on Colab against nightly and new  TF releases to verify that the bug/FR wasn't \"silently\" solved."]}, {"number": 24364, "title": "Block Matrix / Block Diagonal Matrix", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): python 1.12.0\r\n- Are you willing to contribute it (Yes/No): I would but I have very little knowledge of the TF internals\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am requesting the development of a block diagonal function for tensors. In `scipy` this is included in the `scipy.linalg.block_diag` function. Converted to tensors, it makes sense that given a `[M, K, X, ...]` tensor, when calling the proposed `tf.block_diag` it would return a `[M*K, M*K, X, ...]` matrix with the diagonal elements containing the elements from the `[K, X, ...]` submatrix. This seems to be implemented as a LinearOperator but it is not conducive to the tensor-level functions that exist for the rest of the linear algebra domain.\r\n\r\n**Will this change the current api? How?**\r\nNo, this should not change current api, only add an extra function\r\n\r\n**Who will benefit with this feature?**\r\nI will benefit from this feature, as well as anyone else trying to convert code from numpy/scipy to TF. It is a seemingly standard operator in linear algebra and so it makes sense for it to exist in Tensorflow.\r\n\r\n**Any Other info.**\r\nI have a cludgy working version that uses padding and concatenation\r\nGiven Tensor `input` of shape `(B, K, K, ...)` will return a Tensor of shape `(K*B, K*B)` zero filled except for the `KxK` diagonal elements\r\n```python\r\nimport tensorflow as tf\r\nB, K, = input.shape[:2]\r\npaddings = tf.constant([[0, (B-1)*K)],[0, 0]])\r\ndiag = tf.pad(input[0], paddings)\r\nfor i in range(1, B):\r\n    paddings = tf.constant([[i*K, (B-i-1)*K],[0, 0]])\r\n    zeros = tf.pad(input[i], paddings)\r\n    diag = tf.concat([diag, zeros], 1)\r\n```\r\n", "comments": ["@mileslucas  Please fill [this](https://github.com/tensorflow/tensorflow/issues/new?template=30-feature-request.md) template for a new feature request. ", "@harshini-gadige I have edited my comment to fit new template, thank you.", "@rmlarsen want to triage this?", "+1", "Hey. Any updates on this? I was looking for a way to efficiently inverse a block matrix. Seems like a way to go is having LinearOperator support anti diagonals, and having LinearOperatorBlockAntiDiag  with LinearOperatorBlock additional to LinearOperatorBlockDiag classes.", "bump", "@mileslucas,\r\nCan you please refer the documentation of [tf.linalg.LinearOperatorBlockDiag](https://www.tensorflow.org/api_docs/python/tf/linalg/LinearOperatorBlockDiag) and check if this is what you are looking for? Thanks!\r\n ", "If I am not mistaken, unlike `scipy.linalg.block_diag`, `tf.linalg.LinearOperatorBlockDiag` does not support non-square sub-matrices.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Okay, if you want to close the issue that's fine but it's clearly not resolved. It's been 3 years since I opened this and I am no longer using TF or working on the same project (we settled on numpy/scipy for all the math) so I don't want to be the lynch pin for this feature. "]}, {"number": 24337, "title": "TOCO cannot identify dilated convolution correctly", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): N/A\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): 0.19.1\r\n- GCC/Compiler version (if compiling from source): gcc 7.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nIn this line of [comment](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc#L116), it said the `Bias op is required before or after BatchToSpace`. However, in the DeepLab model ([mobilenetv2_coco_voc_trainval](http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz)), there isn't any BiasAdd around the `BatchToSpace`. So the TOCO will fail to combine a sequence of `SpaceToBatchND` - `(Depthwise)Conv2D` - `BatchToSpaceND` into dilated convolution. Instead, the `SpaceToBatchND` and `BatchToSpaceND` will still remain in the graph.\r\n", "comments": ["Is this still an issue with the most recent tf release?", "Hi, just want to second this issue:\r\n```\r\ninpt = tf.keras.layers.Input(shape=(257, 257, 3))\r\nout = tf.keras.layers.DepthwiseConv2D(\r\n    kernel_size=64, dilation_rate=2, add_bias=False\r\n)\r\nmodel = tf.keras.Model(inpt, [out])\r\n```\r\ndoes not properly convert to a depthwise conv in the output:\r\n![image](https://user-images.githubusercontent.com/1422280/70248416-dcefab00-1748-11ea-976e-7befa2f6ac4d.png)\r\n\r\n\r\nHowever this is a temporary workaround to get it to properly identify the pattern:\r\n```\r\ninpt = tf.keras.layers.Input(shape=(257, 257, 3))\r\nout = tf.keras.layers.DepthwiseConv2D(\r\n    kernel_size=64, dilation_rate=2, add_bias=False\r\n)\r\nout = tf.keras.layers.Lambda(lambda x: x + 0.0)\r\nmodel = tf.keras.Model(inpt, [out])\r\n```\r\nAlso, the workaround doesn't work when using the experimental converter.", "Hi @liyunlu0618,\r\nSeems that this problem still remains"]}, {"number": 24268, "title": "Check failed: is_weights() on creating tensorrt inference graph", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): r1.12\r\n- Python version: 3.6.7\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: 10.0, 7.4.1.5\r\n- GPU model and memory: GTX 1050ti, 4000mb\r\n\r\nI am trying to create optimized inference graph with tensorflow.contrib.tensorrt.create_inference_graph. But when I call the function, it runs for a while, and than fails. The last line at logs is:\r\n\r\n```2018-12-10 22:23:42.564811: F tensorflow/contrib/tensorrt/convert/convert_nodes.cc:421] Check failed: is_weights()```", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "[Download freezed graph](https://drive.google.com/file/d/1C7u3bWGubmb616rpV_CZNFVKOMW9JeAC/view?usp=sharing)\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.tensorrt as trt\r\nimport numpy as np\r\nfrom tensorflow.python.framework import tensor_util\r\nfrom tensorflow.core.framework import attr_value_pb2\r\nfrom tensorflow.core.framework import graph_pb2\r\nfrom tensorflow.core.framework import node_def_pb2\r\n\r\n# loading freezed graph def\r\nwith tf.gfile.GFile(\"freezed\", \"rb\") as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\n# outputs\r\nout_names = ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3',\r\n 'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3',\r\n 'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3']\r\n\r\n# here I freeze input image dimensions. Without this trt doesn't do any valuable optimizations\r\nshape_proto = tensor_util.tensor_shape.as_shape([None, 800, 800, 3]).as_proto()\r\ngraph_def.node[0].attr['shape'].CopyFrom(attr_value_pb2.AttrValue(shape=shape_proto))\r\n\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n    tf.import_graph_def(graph_def, name=\"\")\r\n\r\ninput_tensor = graph.get_tensor_by_name(\"input_1:0\")\r\noutput_tensors = [graph.get_tensor_by_name(out + \":0\") for out in out_names]\r\n\r\nsess = tf.Session(graph=graph)\r\n\r\n# check graph is working\r\nzeros = np.zeros((2, 800, 800,3))\r\n%timeit sess.run(output_tensors, feed_dict={input_tensor: zeros})\r\n\r\n# we fail here\r\nfused = trt.create_inference_graph(graph_def, out_names,\r\n                                   max_batch_size=2, \r\n                                   max_workspace_size_bytes=2 << 30,\r\n                                   minimum_segment_size=10,\r\n                                   precision_mode=\"FP32\")\r\n```\r\n\r\n", "May be there is any workaround?", "I figured out, that if not to freeze graph `from tensorflow.python.tools import freeze_graph`, but with `tf.graph_util.convert_variables_to_constants` the exception is not raised, and graph is fused normaly. Therefore,  `tensorflow.python.tools.freeze_graph` spawns some layers, that can not be normally processed by `trt.create_inference_graph`.", "@alexander-shustanov you can also try to use dynamic op if you have a fixed input size that is known only at run-time. It needs to be constant between executions,i.e. same shape for all run() calls though. Also, import_graph_def has an option to replace some tensors with existing tensors where you can replace generic shape with an placeholder with a defined shape.", "@trevor-m @pooyadavoodi  Can you PTAL", "@trevor-m @pooyadavoodi, any updates. Should I close this?"]}, {"number": 24253, "title": "Not able to read objets from private s3 bucket", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10, 7.3\r\n- GPU model and memory: 4x 1080ti 11Gb\r\n\r\n\r\n**Describe the current behavior**\r\ni am not able to access any data from my private s3  bucket, i just keep getting this error\r\nNotFoundError: Object s3://bla/bla does not exist\r\ni have checked that my local machine has aws credentials in ~/.aws/credentials \r\nnot only that i have also tried setting environment variables\r\n```\r\nos.environ['AWS_REGION'] = <my region>\r\nos.environ['AWS_ACCESS_KEY_ID'] = < my creds > \r\nos.environ['AWS_SECRET_ACCESS_KEY'] = < my creds > \r\n```\r\nIt still doesnt let me access my data from s3\r\n**Code to reproduce the issue**\r\n```\r\nfrom tensorflow.python.lib.io import file_io\r\nfile_io.stat(s3_image_url)\r\n```\r\ns3_image_url is a valid url for s3 object which i confirmed by downloading it with awscli\r\n\r\n\r\n**logs**\r\n```\r\n2018-12-09 20:42:26.203155: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key\r\n2018-12-09 20:42:26.203221: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-09 20:42:27.158491: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 403\r\n2018-12-09 20:42:27.158586: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-09 20:42:27.158702: I tensorflow/core/platform/s3/aws_logging.cc:54] Found secret key\r\n2018-12-09 20:42:27.158882: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-09 20:42:27.388300: W tensorflow/core/platform/s3/aws_logging.cc:57] Encountered AWSError\r\nSignatureDoesNotMatch\r\nThe request signature we calculated does not match the signature you provided. Check your key and signing method.:\r\n2018-12-09 20:42:27.388399: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n```", "comments": ["@harshini-gadige\r\n\r\n", "@srihari-humbarwadi  Can you please try with CUDA 9 and check", "@harshini-gadige its the same on pre-built binaries, i tried the cpu version too", "@jhseu are you familiar with the s3 connector? I wonder if we're not escaping the credentials properly or something.", "I haven't personally used it, but @yongtang might have some thoughts. What @srihari-humbarwadi described should work.", "I face the same issue. Appreciate if any progress on this", "need help ~~~", "@srihari-humbarwadi @nagads @xxllp @skye  I am working on this issue. Could you elaborate what is a private s3 bucket ? Is it a bucket like this ?\r\n<img width=\"616\" alt=\"image\" src=\"https://user-images.githubusercontent.com/17511625/102716343-e628c700-430d-11eb-9ed0-b30b04a1d6bb.png\">\r\n\r\n", "@vnvo2409 thats correct. thanks", "@nagads \r\nCould you check your `~/.aws/config` and `~/.aws/credentials` because it said `SignatureDoesNotMatch\r\nThe request signature we calculated does not match the signature you provided. Check your key and signing method.:`\r\n\r\nand I don't have any problem reading this bucket from Tensorflow ( 2.4 )", "@vnvo2409 tested with tf  2.4 , works fine now thanks.\r\nare there any plans for changing env variables to make them more generic. as s3 is no longer confined to AWS cloud and adopted by all public clouds. Thanks.\r\n\r\nos.environ['AWS_REGION'] = <my region>\r\nos.environ['AWS_ACCESS_KEY_ID'] = < my creds > \r\nos.environ['AWS_SECRET_ACCESS_KEY'] = < my creds > ", "> are there any plans for changing env variables to make them more generic.\r\n\r\nI think no. In fact, we use `aws-sdk-cpp` as the backend for `s3` filesystem so the envs like `AWS_ACCESS_KEY_ID` are actually passed into `aws-sdk-cpp`."]}, {"number": 24226, "title": "DistributionStrategy and Keras models: support for sample_weight_mode", "body": "**System information**\r\n- TensorFlow version (you are using): master (Nov. 30, 2018)\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen using a DistributionStrategy with a Keras model that includes sample_weights, a 'NotImplemented' exception is thrown.  For example,\r\n\r\n ```\r\n    strategy = mirrored_strategy.MirroredStrategy()\r\n     model.compile(loss='categorical_crossentropy',\r\n                     optimizer=opt,\r\n                     metrics=['accuracy'],\r\n                     weighted_metrics=['accuracy'],\r\n                     sample_weight_mode='temporal',\r\n                     distribute=strategy)\r\n```\r\n\r\nThe exception originates in tensorflow/python/keras/engine/training.py\r\n      \r\n```\r\n if sample_weight_mode:\r\n\t        raise NotImplementedError('sample_weight_mode is not supported with '\r\n\t                                  'DistributionStrategy.')\r\n```\r\n\r\nCan this be supported or can you give an estimated timeline?\r\n\r\nMany thanks\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo.  It looks like the API should support this.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone using keras models with sample_weights in a DistributedStrategy mode.\r\n\r\n**Any Other info.**\r\n\r\n", "comments": ["@pawarrick  Currently adding this feature is not in the immediate radar(as there are many other prioritized features in the pipeline). Hence marking this as Contributions Welcome.\r\nAs you mentioned above, if you would like to contribute for the same please open a PR and link the PR # here.  ", "@fchollet Hi Fran\u00e7ois, this is the issue I mentioned to you today.\r\nThanks again for chatting", "If the issue hasn't been solved yet, I'd like to contribute. Please update on status.", "@shivam13juna, I have not seen any note of work being done on this, so I think your contribution would be most welcome\r\n", "Thanks @shivam13juna , please go ahead and contribute. We don't have anyone working on this in the near future. ", "@hgadig @guptapriya Is there anyone still working on here? If not, maybe I could have a try for this, but I hope could get some reference first. Thanks!\r\n", "We don't have anyone working on this currently, so please feel free. \r\nWe also recently discovered a bug in the regular sample weights with keras when using distribution strategy. Specifically, sample_weights are being set to `None` here, but this should happen only in the case they are not present:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/distribute/distributed_training_utils.py#L579\r\n\r\nYou will have to fix this bug first before you can get sample_weight_mode working. Would you be interested in first fixing that bug and then adding new support for sample weight mode?\r\n\r\ncc @anj-s \r\n", "@guptapriya, Thanks. I'd like to fix the bug first. Is there any issue linked to the bug you describe abov?Or could you please help describe bug with much more  details.", "We currently retrieve the sample_weights from the dataset but don't feed it to the model as part of \r\n```\r\nins = inputs + targets + sample_weights\r\n```\r\nThis is because if you look at https://github.com/tensorflow/tensorflow/issues/24226#issuecomment-478427894 we pass Nones instead. We originally did this because placeholders are created for sample weights (irrespective of if the feature is used) and the learning phase tensor is appended to it in the end. In order to pass the right learning phase at the right index in a sense we had to append a sample weight array and then the learning phase after that. \r\n\r\nWe still want to pass the None array if there are no sample_weights to consider. If the user does pass sample_weights we should standardize it and feed it to the model via `ins.`\r\n\r\nHope this helps. ", "Seems we should make it supported. @pawarrick Do you need sample weight to be inside the canonical dataset when you do model.fit(dataset), or you want it to be a separate dataset such as model.fit(data_dataset, sample_weight_dataset)?", "@tanzhenyu with no DistributionStrategy, it works fine \"inside the canonical dataset\" doing model.fit(dataset), so supporting it the same way would be excellent.", "I'm interested to know if progress has been made with enabling `sample_weight_mode` for distribution strategies. If no progress has been made, what is the method is advised to deal with variable length outputs?", "sample_weights have been fixed, but afaik, there is no progress on sample_weight_mode=temporal support. ", "Thanks for the comment @guptapriya, temporal weighting is what I need, so this saddens me a bit.", "My hope is that we would add support for it sometime in the next few\nmonths. We welcome contributions as well.\n\nOn Wed, Jun 19, 2019 at 11:42 PM Freddy Snijder <notifications@github.com>\nwrote:\n\n> Thanks for the comment @guptapriya <https://github.com/guptapriya>,\n> temporal weighting is what I need, so this saddens me a bit.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24226?email_source=notifications&email_token=ADLTSF2OBG4Z2CZMMM5O3J3P3MRG5A5CNFSM4GJEOET2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODYENWAI#issuecomment-503896833>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADLTSFYLMI7ZEEK6VPZHX33P3MRG5ANCNFSM4GJEOETQ>\n> .\n>\n", "@guptapriya I noticed that in commit 3782019ca739f2b00f1f1990d737e7be65e09df9 support was added for \"temporal sample weight mode in non-graph networks\". Does that affect this issue? Just wondering.", "@guptapriya Ah, I see that `sample_weight_mode` is still not supported with `tf.distribute.Strategy` in the r2.0 branch.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/c75bb66a99ad45e5a3c9fc4625c8abeb705520b5/tensorflow/python/keras/engine/training.py#L1467\r\n\r\nWhat is the current status of this issue? Do you have any insights in how to proceed (how to fix it)?\r\n\r\n\r\n", "Current status is that this is still not supported. \r\nHowever, we have made some progress recently on unifying keras execution with and without distribution strategy. This means that we should be able to provide this functionality sooner than later.\r\n@tomerk @qlzh727 - do you have any insight into when the new execution path may support sample weight mode? ", "I believe @pavithrasv has integrated sample_weight_mode into the unified path (although I'm not sure if she tested it with distribution strategies or not). You can go ahead and try the nightlies to see if it fixes it for you.\r\n\r\nIf it does we may still be able to cherrypick it into 2.0, or it may have to wait until a followup release.", "@guptapriya @tomerk Thanks for your replies. Apparently @pavithrasv added \"support for sample weight mode in v2 single execution path\" through commit 9f30dc6211ac2531f98e1516f23bcb995d7a15c2. However, looking in to the latest version of `training.py` in the `master` branch, using `sample_weight_mode` is still not supported in combination with a training distribution strategy:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2123cb71b81c92e08a9210d80b5974df5292878b/tensorflow/python/keras/engine/training.py#L1500\r\n\r\nFurther [`temporal_sample_weights_correctness_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/temporal_sample_weights_correctness_test.py) does not contain any tests related to distributed training strategies (as far as I could tell).\r\n\r\n@tomerk Do you suggest, based on the above, that if I would remove the code that raises a `NotImplementedError`, when I use `sample_weight_mode` with a distribution strategy, it might work now?\r\n\r\n ", "That method only runs in the older execution path that we will be removing soon once the new path supports everything the old path used to (it currently supports everything except for target_tensors & hdf5 matrix inputs & scipy sparsematrices)\r\n\r\nIf you run the nightly now sample_weight_mode shouldn't trigger the old path anymore so `_validate_compile_param_for_distribution_strategy` will no longer be run.\r\n\r\nThat said, it may or may not work with distribution strategies yet, but trying it is worth a shot. Please let us know how it goes if you do!", "Hi @tomerk, @pavithrasv, to my surprise, after some fiddling to adapt my code to Tensorflow 2.0, temporal sample weighting works with the `MirroredStrategy`!\r\n\r\nPlease see my [Tensorflow Keras issues tests repo](https://github.com/visionscaper/tf-issues) that I use to investigate what features from the original Keras work in `tf.keras` and which don't.\r\n\r\nYou can run this test and see it in action yourself:\r\n\r\n```\r\npython3 tests/tf20_keras/tests.py TestIssuesTFKeras.test_multi_gpu_float32_no_masking_no_dropout_noise_shape_sample_weight_mode\r\n```\r\n\r\nTo run the test above you need to have the dependencies in [`requirements_tensorflow20_keras_env.txt`](https://github.com/visionscaper/tf-issues/blob/master/requirements_tensorflow20_keras_env.txt) installed, also see the [`README.md`](https://github.com/visionscaper/tf-issues/blob/master/README.md).\r\n\r\n", "@visionscaper Thank you for the update, is this with the latest nightly or did you have to make any changes for it to work with MirroredStrategy?", "@pavithrasv No, I didn't need to change anything related to the MirroredStrategy. And, yes, I used the very latest nightly (2 days ago):\r\n\r\n```\r\n$ pip list | grep tf-nightly\r\ntf-nightly-gpu-2.0-preview       2.0.0.dev20190824   \r\n```\r\n\r\nThanks for your efforts!\r\n\r\n[This](https://github.com/visionscaper/tf-issues/blob/f5d82f308809c194ed84baf7c221ab58599d0117/tests/tf20_keras/tests.py#L206) is the test I ran.", "Great, thanks for confirming!", "Hi @visionscaper  @tomerk and everyone.\r\n\r\nDo you know by any chance does some distributed strategy supports target_tensors now?\r\nI am unable to use multi gpu training as my model can only compile with use of target_tensors.", "Hi djo-koconi@, due to their degree of required technical complexity and relatively niche use cases, target_tensors have actually been removed entirely in recent versions of tensorflow  unless you're running legacy code with eager disabled + compat.v1 apis\r\n\r\nThe recommended way to achieve the same effect as target_tensors is to override your model's training step to pass the target into the model at training time.\r\n\r\nThis thread from fchollet@ demonstrates what overriding train_step looks like (in this case for training GANs, but the idea remains the same):\r\nhttps://mobile.twitter.com/fchollet/status/1250622989541838848\r\n\r\nWe are also working on guides that will go more into detail on how to go about overriding different components of the training/evaluation loops to handle unique training workflows.", "Thank you very much @tomerk .\r\nI finally managed to overcome using target_tensors the issue by using tf-nightly.\r\n\r\nJust now my model now trains slower on 2 gpus compared to using single gpu which makes another unexpected issue. \r\nhttps://stackoverflow.com/questions/61594176/tensorflow-multi-gpu-training-slower-than-on-single-gpu", "sample_weight_mode still seems incompatible with any distributed strategy"]}, {"number": 24215, "title": "bazel error for saved_model_cli", "body": "Hi,\r\n\r\ni get the follwing error when i try to build saved_model_cli (following this tutorial: https://www.tensorflow.org/guide/saved_model). Any idea whats the issue?\r\n\r\n```\r\n$ bazel build tensorflow/python/tools:saved_model_cli\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/Users/geri/Documents/tensorflow/tools/bazel.rc\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: 466cba21-c0aa-4740-970a-fd0d67250a82\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:2985:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/gan/BUILD:136:1: in py_library rule //tensorflow/contrib/gan:losses_impl: target '//tensorflow/contrib/gan:losses_impl' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/metrics/BUILD:16:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:76:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:233:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:356:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:76:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/python/tools:saved_model_cli (309 packages loaded, 16772 targets configured).\r\nINFO: Found 1 target...\r\nINFO: From Linking external/protobuf_archive/libprotobuf_lite.a [for host]:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf_archive/_objs/protobuf_lite/arenastring.o has no symbols\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf_archive/_objs/protobuf_lite/io_win32.o has no symbols\r\nINFO: From Linking tensorflow/core/libplatform_base.a [for host]:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: warning same member name (env_time.o) in output file used for input files: bazel-out/host/bin/tensorflow/core/_objs/platform_base/0/env_time.o and: bazel-out/host/bin/tensorflow/core/_objs/platform_base/1/env_time.o (due to use of basename, truncation, blank padding or duplicate input files)\r\nINFO: From Linking external/protobuf_archive/libprotobuf.a [for host]:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf_archive/_objs/protobuf/gzip_stream.o has no symbols\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf_archive/_objs/protobuf/error_listener.o has no symbols\r\nINFO: From ProtoCompile tensorflow/core/lib/core/error_codes.pb.cc [for host]:\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.cc:\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/lib/core/error_codes.pb.cc:\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.cc [for host]:\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example.pb.cc:\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/darwin-fastbuild/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example.pb.cc [for host]:\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/host/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nERROR: /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/external/flatbuffers/BUILD.bazel:57:1: C++ compilation of rule '@flatbuffers//:flatc_library' failed (Exit 1) cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 44 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nexternal/flatbuffers/src/util.cpp:50:3: error: use of undeclared identifier 'FLATBUFFERS_ASSERT'\r\n  FLATBUFFERS_ASSERT(g_load_file_function);\r\n  ^\r\nexternal/flatbuffers/src/util.cpp:55:3: error: use of undeclared identifier 'FLATBUFFERS_ASSERT'\r\n  FLATBUFFERS_ASSERT(g_file_exists_function);\r\n  ^\r\n2 errors generated.\r\nTarget //tensorflow/python/tools:saved_model_cli failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 302.643s, Critical Path: 46.91s\r\nINFO: 396 processes: 396 darwin-sandbox.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nmore infos:\r\n```\r\n$ bazel build tensorflow/python/tools:saved_model_cli --sandbox_debug\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/Users/geri/Documents/tensorflow/tools/bazel.rc\r\nINFO: Invocation ID: b46f49c0-8fce-46a2-8bfc-4d3ad5ba2ef7\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:2985:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:76:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/metrics/BUILD:16:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/gan/BUILD:136:1: in py_library rule //tensorflow/contrib/gan:losses_impl: target '//tensorflow/contrib/gan:losses_impl' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:233:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:76:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:356:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/python/tools:saved_model_cli (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nINFO: From Linking external/grpc/libtsi.a:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/darwin-fastbuild/bin/external/grpc/_objs/tsi/ssl_session_openssl.pic.o has no symbols\r\nINFO: From Linking external/grpc/libgrpc++_base.a:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/darwin-fastbuild/bin/external/grpc/_objs/grpc++_base/rpc_method.pic.o has no symbols\r\nERROR: /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/external/grpc/BUILD:1515:1: C++ compilation of rule '@grpc//:grpc_resolver_dns_ares' failed (Exit 1) sandbox-exec failed: error executing command \r\n  (cd /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/geri/.pyenv/shims:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/go/bin:/Users/geri/intelligence/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    TMPDIR=/var/folders/7t/9l0n105n4_jbrq076r887pthz96c2m/T/ \\\r\n  /usr/bin/sandbox-exec -f /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/sandbox/darwin-sandbox/61/sandbox.sb /var/tmp/_bazel_geri/install/c71a8bada5761bf76ced20ca6672b491/_embedded_binaries/process-wrapper '--timeout=0' '--kill_delay=15' external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer '-std=c++0x' -MD -MF bazel-out/darwin-fastbuild/bin/external/grpc/_objs/grpc_resolver_dns_ares/grpc_ares_wrapper.pic.d '-frandom-seed=bazel-out/darwin-fastbuild/bin/external/grpc/_objs/grpc_resolver_dns_ares/grpc_ares_wrapper.pic.o' -fPIC '-DPB_FIELD_32BIT=1' -iquote external/grpc -iquote bazel-out/darwin-fastbuild/genfiles/external/grpc -iquote bazel-out/darwin-fastbuild/bin/external/grpc -iquote external/bazel_tools -iquote bazel-out/darwin-fastbuild/genfiles/external/bazel_tools -iquote bazel-out/darwin-fastbuild/bin/external/bazel_tools -iquote external/zlib_archive -iquote bazel-out/darwin-fastbuild/genfiles/external/zlib_archive -iquote bazel-out/darwin-fastbuild/bin/external/zlib_archive -iquote external/com_github_nanopb_nanopb -iquote bazel-out/darwin-fastbuild/genfiles/external/com_github_nanopb_nanopb -iquote bazel-out/darwin-fastbuild/bin/external/com_github_nanopb_nanopb -isystem external/grpc/include -isystem bazel-out/darwin-fastbuild/genfiles/external/grpc/include -isystem bazel-out/darwin-fastbuild/bin/external/grpc/include -isystem external/zlib_archive -isystem bazel-out/darwin-fastbuild/genfiles/external/zlib_archive -isystem bazel-out/darwin-fastbuild/bin/external/zlib_archive -isystem external/grpc/third_party/address_sorting/include -isystem bazel-out/darwin-fastbuild/genfiles/external/grpc/third_party/address_sorting/include -isystem bazel-out/darwin-fastbuild/bin/external/grpc/third_party/address_sorting/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc -o bazel-out/darwin-fastbuild/bin/external/grpc/_objs/grpc_resolver_dns_ares/grpc_ares_wrapper.pic.o)\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:29:10: fatal error: 'ares.h' file not found\r\n#include <ares.h>\r\n         ^~~~~~~~\r\n1 error generated.\r\nTarget //tensorflow/python/tools:saved_model_cli failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 13.689s, Critical Path: 4.82s\r\nINFO: 57 processes: 57 darwin-sandbox.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nthan i installed ares:\r\n```\r\n$ ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" < /dev/null 2> /dev/null\r\n$ brew install c-ares\r\n```\r\n\r\nand tried it again, and got this error:\r\n```\r\n$ bazel build tensorflow/python/tools:saved_model_cli --sandbox_debug\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/Users/geri/Documents/tensorflow/tools/bazel.rc\r\nINFO: Invocation ID: 2e76455c-b877-4561-85f0-7a34a9337adc\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:2985:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/python/BUILD:76:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/metrics/BUILD:16:1: in py_library rule //tensorflow/contrib/metrics:metrics_py: target '//tensorflow/contrib/metrics:metrics_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/gan/BUILD:136:1: in py_library rule //tensorflow/contrib/gan:losses_impl: target '//tensorflow/contrib/gan:losses_impl' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:233:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:76:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:356:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /Users/geri/Documents/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/python/tools:saved_model_cli (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nINFO: From ProtoCompile external/protobuf_archive/python/google/protobuf/any_pb2.py [for host]:\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example_pb2.py [for host]:\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nINFO: From Compiling tensorflow/core/framework/function.cc [for host]:\r\ntensorflow/core/framework/function.cc:1107:18: warning: reading variable 'function_defs_' requires holding mutex 'clone.mu_' [-Wthread-safety-precise]\r\n  for (auto iter : clone.function_defs_) {\r\n                 ^\r\ntensorflow/core/framework/function.cc:1107:18: note: found near match 'mu_'\r\ntensorflow/core/framework/function.cc:1107:18: warning: reading variable 'function_defs_' requires holding mutex 'clone.mu_' [-Wthread-safety-precise]\r\n  for (auto iter : clone.function_defs_) {\r\n                 ^\r\ntensorflow/core/framework/function.cc:1107:18: note: found near match 'mu_'\r\ntensorflow/core/framework/function.cc:1117:18: warning: reading variable 'func_grad_' requires holding mutex 'clone.mu_' [-Wthread-safety-precise]\r\n  for (auto iter : clone.func_grad_) {\r\n                 ^\r\ntensorflow/core/framework/function.cc:1117:18: note: found near match 'mu_'\r\ntensorflow/core/framework/function.cc:1117:18: warning: reading variable 'func_grad_' requires holding mutex 'clone.mu_' [-Wthread-safety-precise]\r\n  for (auto iter : clone.func_grad_) {\r\n                 ^\r\ntensorflow/core/framework/function.cc:1117:18: note: found near match 'mu_'\r\n4 warnings generated.\r\nINFO: From Compiling tensorflow/core/util/example_proto_fast_parsing.cc [for host]:\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:77:15: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n    *result = SparseTensor(ix, vals, shape, order);\r\n              ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:77:15: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n    *result = SparseTensor(ix, vals, shape, order);\r\n              ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:132:9: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n      : SparseTensor(other.ix_, other.vals_, other.shape_, other.order_) {}\r\n        ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:135:9: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n      : SparseTensor(std::move(other.ix_), std::move(other.vals_),\r\n        ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:568:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_ix, output_vals, final_shape, final_order);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:568:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_ix, output_vals, final_shape, final_order);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:726:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_indices, output_values, output_shape);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:99:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_fast_parsing.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_fast_parsing.h:32:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:726:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_indices, output_values, output_shape);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:99:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\n8 warnings generated.\r\nINFO: From Compiling tensorflow/core/util/strided_slice_op.cc [for host]:\r\ntensorflow/core/util/strided_slice_op.cc:275:33: warning: lambda capture 'i' is not used [-Wunused-lambda-capture]\r\n    auto canonical = [stride_i, i, dim_i, masks, valid_range](int64 x, int c) {\r\n                                ^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/framework/dataset.cc [for host]:\r\nIn file included from tensorflow/core/framework/dataset.cc:15:\r\nIn file included from ./tensorflow/core/framework/dataset.h:27:\r\n./tensorflow/core/framework/model.h:235:13: warning: writing variable 'buffered_bytes_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->buffered_bytes_ = buffered_bytes_;\r\n            ^\r\n./tensorflow/core/framework/model.h:235:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:236:13: warning: writing variable 'processing_time_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->processing_time_ = processing_time_;\r\n            ^\r\n./tensorflow/core/framework/model.h:236:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:237:13: warning: writing variable 'num_elements_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->num_elements_ = num_elements_;\r\n            ^\r\n./tensorflow/core/framework/model.h:237:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:238:13: warning: writing variable 'parameters_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->parameters_ = parameters_;\r\n            ^\r\n./tensorflow/core/framework/model.h:238:13: note: found near match 'mu_'\r\n4 warnings generated.\r\nINFO: From Compiling tensorflow/core/util/example_proto_helper.cc [for host]:\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:77:15: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n    *result = SparseTensor(ix, vals, shape, order);\r\n              ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:77:15: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n    *result = SparseTensor(ix, vals, shape, order);\r\n              ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:132:9: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n      : SparseTensor(other.ix_, other.vals_, other.shape_, other.order_) {}\r\n        ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:135:9: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n      : SparseTensor(std::move(other.ix_), std::move(other.vals_),\r\n        ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:568:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_ix, output_vals, final_shape, final_order);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:568:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_ix, output_vals, final_shape, final_order);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:113:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:726:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_indices, output_values, output_shape);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:99:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\nIn file included from tensorflow/core/util/example_proto_helper.cc:15:\r\nIn file included from ./tensorflow/core/util/example_proto_helper.h:31:\r\n./tensorflow/core/util/sparse/sparse_tensor.h:726:10: warning: 'SparseTensor' is deprecated: Use Create() functions instead of constructors directly. [-Wdeprecated-declarations]\r\n  return SparseTensor(output_indices, output_values, output_shape);\r\n         ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:99:3: note: 'SparseTensor' has been explicitly marked deprecated here\r\n  ABSL_DEPRECATED(\"Use Create() functions instead of constructors directly.\")\r\n  ^\r\nexternal/com_google_absl/absl/base/macros.h:149:49: note: expanded from macro 'ABSL_DEPRECATED'\r\n#define ABSL_DEPRECATED(message) __attribute__((deprecated(message)))\r\n                                                ^\r\n8 warnings generated.\r\nINFO: From Compiling tensorflow/core/framework/model.cc [for host]:\r\nIn file included from tensorflow/core/framework/model.cc:16:\r\n./tensorflow/core/framework/model.h:235:13: warning: writing variable 'buffered_bytes_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->buffered_bytes_ = buffered_bytes_;\r\n            ^\r\n./tensorflow/core/framework/model.h:235:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:236:13: warning: writing variable 'processing_time_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->processing_time_ = processing_time_;\r\n            ^\r\n./tensorflow/core/framework/model.h:236:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:237:13: warning: writing variable 'num_elements_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->num_elements_ = num_elements_;\r\n            ^\r\n./tensorflow/core/framework/model.h:237:13: note: found near match 'mu_'\r\n./tensorflow/core/framework/model.h:238:13: warning: writing variable 'parameters_' requires holding mutex 'result->mu_' exclusively [-Wthread-safety-precise]\r\n    result->parameters_ = parameters_;\r\n            ^\r\n./tensorflow/core/framework/model.h:238:13: note: found near match 'mu_'\r\n4 warnings generated.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data_pb2.py [for host]:\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nexternal/protobuf_archive/python: warning: directory does not exist.\r\nINFO: From Linking tensorflow/core/liblib_internal_impl.a [for host]:\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: warning same member name (env.o) in output file used for input files: bazel-out/host/bin/tensorflow/core/_objs/lib_internal_impl/0/env.o and: bazel-out/host/bin/tensorflow/core/_objs/lib_internal_impl/1/env.o (due to use of basename, truncation, blank padding or duplicate input files)\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: warning same member name (tracing.o) in output file used for input files: bazel-out/host/bin/tensorflow/core/_objs/lib_internal_impl/0/tracing.o and: bazel-out/host/bin/tensorflow/core/_objs/lib_internal_impl/1/tracing.o (due to use of basename, truncation, blank padding or duplicate input files)\r\n/Library/Developer/CommandLineTools/usr/bin/libtool: file: bazel-out/host/bin/tensorflow/core/_objs/lib_internal_impl/android_armv7a_cpu_utils_helper.o has no symbols\r\nERROR: /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/external/flatbuffers/BUILD.bazel:99:1: C++ compilation of rule '@flatbuffers//:flatc' failed (Exit 1) sandbox-exec failed: error executing command \r\n  (cd /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/geri/.pyenv/shims:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/go/bin:/Users/geri/intelligence/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    TMPDIR=/var/folders/7t/9l0n105n4_jbrq076r887pthz96c2m/T/ \\\r\n  /usr/bin/sandbox-exec -f /private/var/tmp/_bazel_geri/af336600bf091f11bdb6522728b81044/sandbox/darwin-sandbox/381/sandbox.sb /var/tmp/_bazel_geri/install/c71a8bada5761bf76ced20ca6672b491/_embedded_binaries/process-wrapper '--timeout=0' '--kill_delay=15' external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/host/bin/external/flatbuffers/_objs/flatc/idl_gen_grpc.d '-frandom-seed=bazel-out/host/bin/external/flatbuffers/_objs/flatc/idl_gen_grpc.o' -iquote external/flatbuffers -iquote bazel-out/host/genfiles/external/flatbuffers -iquote bazel-out/host/bin/external/flatbuffers -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote bazel-out/host/bin/external/bazel_tools -isystem external/flatbuffers/grpc -isystem bazel-out/host/genfiles/external/flatbuffers/grpc -isystem bazel-out/host/bin/external/flatbuffers/grpc -isystem external/flatbuffers/include -isystem bazel-out/host/genfiles/external/flatbuffers/include -isystem bazel-out/host/bin/external/flatbuffers/include -g0 -g0 -Wno-implicit-fallthrough -fexceptions -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/flatbuffers/src/idl_gen_grpc.cpp -o bazel-out/host/bin/external/flatbuffers/_objs/flatc/idl_gen_grpc.o)\r\nexternal/flatbuffers/src/idl_gen_grpc.cpp:57:21: error: no member named 'doc_comment' in 'flatbuffers::RPCCall'; did you mean 'rpc_comment'?\r\n    return method_->doc_comment;\r\n                    ^~~~~~~~~~~\r\n                    rpc_comment\r\n/usr/local/include/flatbuffers/idl.h:349:28: note: 'rpc_comment' declared here\r\n  std::vector<std::string> rpc_comment;\r\n                           ^\r\nexternal/flatbuffers/src/idl_gen_grpc.cpp:174:9: error: use of undeclared identifier 'FLATBUFFERS_ASSERT'\r\n        FLATBUFFERS_ASSERT(indent_ >= 0);\r\n        ^\r\n2 errors generated.\r\nTarget //tensorflow/python/tools:saved_model_cli failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 166.831s, Critical Path: 93.66s\r\nINFO: 379 processes: 378 darwin-sandbox, 1 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nbazel version:\r\n```\r\nbazel version\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/Users/geri/Documents/tensorflow/tools/bazel.rc\r\nINFO: Invocation ID: 143fe03e-0926-4e69-9516-0e132c8ed3b5\r\nBuild label: 0.20.0\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Nov 30 14:38:25 2018 (1543588705)\r\nBuild timestamp: 1543588705\r\nBuild timestamp as int: 1543588705\r\n```\r\n\r\nosx version:\r\n```\r\n10.14.2 (18C54)\r\n```\r\n\r\nPython version:\r\n```\r\n$ python3 --version\r\nPython 3.6.0\r\n```\r\n\r\ntensorflow version:\r\n```\r\n$ pip3 install --upgrade tensorflow\r\nRequirement already up-to-date: tensorflow in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (1.12.0)\r\nRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.2.0)\r\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.11.0)\r\nRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.7.1)\r\nRequirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.6.1)\r\nRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.17.0)\r\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (0.32.3)\r\nRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.0.6)\r\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.0.5)\r\nRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (3.6.1)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.14.5)\r\nRequirement already satisfied, skipping upgrade: tensorboard<1.13.0,>=1.12.0 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.12.0)\r\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied, skipping upgrade: h5py in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\r\nRequirement already satisfied, skipping upgrade: setuptools in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (28.8.0)\r\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\r\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /Users/geri/.pyenv/versions/3.6.0/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\r\n```\r\n\r\ngcc version:\r\n```\r\n$ gcc --version\r\nConfigured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.0 (clang-1000.10.44.4)\r\nTarget: x86_64-apple-darwin18.2.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\n\r\ng++ version:\r\n```\r\nMM-MAC-3270:tensorflow gstanje$ g++ --version\r\nConfigured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.0 (clang-1000.10.44.4)\r\nTarget: x86_64-apple-darwin18.2.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```", "comments": ["I have no experience with saved_model_cli\r\n@yifeif have you worked with this binary before?", "If you pip installed TensorFlow, you shouldn't need to re-build saved_model_cli, you can just run it by calling \"saved_model_cli\"/\r\nIf you are trying to build saved_model from scratch, have you ran ./configure?\r\n", "@yifeif could you try to run the same commands, to see the error?"]}, {"number": 24205, "title": "Hard arbitrary limit on Saved model size", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Both\r\n- TensorFlow version (use command below): 1.10+\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): 17.2\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to load a 1.4GiB binary saved model and am getting an error saying that the protobuf message is too big i.e. over 1GiB\r\n\r\n**Describe the expected behavior**\r\nCurrent default limits for protobuf messages loaded by a CodedInputStream are 2GiB so my model should load without error.\r\n\r\n**Code to reproduce the issue**\r\n\r\nComment out line 503 in env.cc:\r\n//coded_stream.SetTotalBytesLimit(1024LL << 20, 512LL << 20);\r\nrebuild and everything works as expected. \r\n\r\n**Other info / logs**\r\n\r\nAlso the second parameter to SetTotalBytesLimit has been deprecated and is no longer enforced. \r\n", "comments": []}, {"number": 24204, "title": "Spurious syntax highlighting of code blocks in site documentation", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: N/A\r\n- Doc Link: Various, but see for example [/community/documentation](https://www.tensorflow.org/community/documentation), [/guide/debugger](https://www.tensorflow.org/guide/debugger), or [/guide/datasets_for_estimators](https://www.tensorflow.org/guide/datasets_for_estimators)\r\n\r\n\r\n**Describe the documentation issue**\r\nMany of the code blocks in [this guide on Writing Tensorflow Documentation](https://www.tensorflow.org/community/documentation#description_of_the_docstring_sections) are meant to represent markdown, but they're syntax highlighted as... something else. e.g. the word \"from\" is highlighted as if it were a keyword in:\r\n```\r\nFlips an image horizontally from left to right.\r\n```\r\n\r\nThese blocks should either have no syntax highlighting, or markdown syntax highlighting (if the library you're using for syntax highlighting allows it).\r\n\r\nIn some cases, authors have explicitly used a language identifier of 'none' in fenced code blocks, presumably to try to suppress syntax highlighting, but it doesn't look like that's respected when rendering. For example, the first two code blocks in [/guide/debugger](https://www.tensorflow.org/guide/debugger) are tagged 'none' in [the corresponding md file](https://github.com/tensorflow/docs/blob/master/site/en/guide/debugger.md), but the \"Accuracy at step...\" block is still lit up like a Christmas tree.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI wish I could, but as far as I can tell, the markdown -> html part of the docs pipeline isn't part of any public repo. ", "comments": ["Any thoughts @lamberta @MarkDaoust ? Here is a screenshot for reference.\r\n\r\n![image](https://user-images.githubusercontent.com/1689183/50228406-dcaea200-0375-11e9-990f-921ec896ef33.png)\r\n", "Thanks for reporting this.\r\n\r\nIt uses [prettify](https://github.com/google/code-prettify#how-do-i-specify-the-language-of-my-code) to do the syntax highlighting. There doesn't seem to be a markdown option. \r\n\r\nYou can use a `<pre>` tag without the \"prettyprint\" class to render as plain text. \r\n\r\n```\r\n<pre>\r\nFlips an image horizontally from left to right.\r\n</pre>\r\n```\r\n\r\nproduces on the site.\r\n\r\n```\r\nFlips an image horizontally from left to right.\r\n```\r\n\r\n@colinmorris, @epicfaace : Any chance you could send a PR fixing some of those problems?\r\n(And maybe mention this, and that link to prettify link to community/documentation?)", "@MarkDaoust , sure. How do I generate documentation for specific pages locally?", "> @MarkDaoust , sure. How do I generate documentation for specific pages locally?\r\n\r\nThere's no way to preview the final product :(. A lot of the pipeline is built into the site infrastructure, so there's no way to opensource it. \r\n"]}, {"number": 24198, "title": "TextLineDataset supporting start/end file positions", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.11.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen constructing a text dataset pipeline, we often want to extract text lines from part of a large text file, instead of from the whole file. For example, \r\n\r\n- using 99% lines at the head of a large file as train set and the remaining 1% as valid set.\r\n\r\n- when training a model in parallel on multiple GPUs or nodes, we want to split large text files into equal-lengthed parts for each GPU to train one part of them.\r\n\r\nTraditionally, to achieve this goal we have to do file operations such as splitting, copying and renaming. These operations are tedious, error-pruning and cost more disk space and time. It also messes up directory/file structures. More over, it is hard to share between different environments with different count of GPUs/nodes, or with different text file set.\r\nHere I have created a `TextLineBlockDataset` op kernel as well as a python `dataset_ops.Dataset` by mimicking `TextLineDataset`. `TextLineBlockDataset` uses a [begin_offset, end_offset) range to mark a block of a text file, freeing one from tedious file splitting preparations.\r\n\r\nThis is the registration of the dataset op:\r\n```\r\nREGISTER_OP(\"TextLineBlockDataset\")\r\n    .Input(\"filenames: string\")\r\n    .Input(\"begin_offsets: int64\")\r\n    .Input(\"end_offsets: int64\")\r\n    .Input(\"buffer_size: int64\")\r\n    .Output(\"handle: variant\")\r\n    .SetIsStateful()  // TODO(b/65524810): Source dataset ops must be marked\r\n        // stateful to inhibit constant folding.\r\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\r\n      shape_inference::ShapeHandle unused;\r\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(0), 1, &unused));\r\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(1), 1, &unused));\r\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(c->input(2), 1, &unused));\r\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\r\n      return shape_inference::ScalarShape(c);\r\n    });\r\n```\r\nand the python API interface to it:\r\n```\r\n@tf_export(\"data.TextLineBlockDataset\")\r\nclass TextLineBlockDataset(dataset_ops.Dataset):\r\n    \"\"\"A `Dataset` comprising lines from one or more text file blocks.\"\"\"\r\n\r\n    def __init__(self, filenames, begin_offsets, end_offsets, buffer_size=None):\r\n        \"\"\"Creates a `TextLineBlockDataset`.\r\n        An element in zip(filenames, begin_offsets, end_offsets) denotes a text\r\n        file block in file filename, beginning at begin_offset and ends at\r\n        end_offset, in byte.\r\n        `begin_offsets` and `end_offsets` will be smoothed to match text line\r\n        boundaries under the hood.\r\n\r\n        Args:\r\n          filenames: A `tf.string` tensor containing one or more filenames.\r\n          begin_offsets: A `tf.int64` 1-d tensor denoting begin offsets.\r\n          end_offsets: A `tf.int64` 1-d tensor denoting end offsets.\r\n          buffer_size: (Optional.) A `tf.int64` scalar denoting the number of bytes\r\n            to buffer for each block, for each block. A value of 0 results in the \r\n            default values chosen on the compression type.\r\n        \"\"\"\r\n```\r\n\r\nThis is how I use it:\r\nSuppose I have 3 large text files, I want to extract text lines ranging from ratio 2/4 to 3/4 of each text file. Each text file block will be split into 8 smaller blocks for better shuffle effect.\r\n```\r\nif __name__ == '__main__':\r\n    filenames = [\"data/train.txt\", \"data/dev.txt\", \"data/test.txt\"]\r\n    n_files = len(filenames)\r\n    # this is the 2nd of the 4 towers which consumes range 2/4 ~ 3/4 text lines of each file\r\n    n_towers, tower_id = 4, 2\r\n    n_splits = 8    # each range will be further split into 8 parts for better shuffle\r\n    buffer_size = 256 * 1024\r\n\r\n    block_params = []\r\n    for file_id in range(n_files):\r\n        file_size = os.path.getsize(filenames[file_id])\r\n        split_size = file_size / (n_towers * n_splits)\r\n        for split_id in range(n_splits):\r\n            begin_offset = int(split_size * (tower_id * n_splits + split_id))\r\n            end_offset = int(split_size * (tower_id * n_splits + split_id + 1))\r\n            block_params.append((filenames[file_id], begin_offset, end_offset))\r\n    dataset = TextLineBlockDataset(*zip(*block_params), buffer_size)\r\n    dataset = dataset.shuffle(32000)  # shuffle in the same manner as `TextLineDataset`\r\n    get_next = dataset.make_one_shot_iterator().get_next()\r\n\r\n    sess = tf.Session()\r\n    while True:\r\n        try:\r\n            print(sess.run(get_next).decode(\"utf-8\"))\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\n```\r\n\r\n**Will this change the current api? How?**\r\nYes.\r\nA new dataset op kernal will be registered in the C++ side, and a corresponding python \r\nclass tf.data.TextLineBlockDataset will be added.\r\n\r\n**Who will benefit with this feature?**\r\nTensorflow users who deal with large text files.\r\n\r\n**Any Other info.**\r\n@mrry @eaplatanios @rachellim\r\n", "comments": ["@mrry Could you please take a look?", "@aselle ", "@mrry @aselle\r\nIf you think this is worthy I will fire a PR and do performance tests on really large files, and also some visualization test to show line number generated at each step when batching or shuffling is using.\r\nI can add a param so the user can decide whether to do interleaving or concatenating on the input file blocks. And I strongly suggest that `TextLineDataset` also supporting interleaving.", "@martinwicke, Do you know who might have insight into this. I don't handle the data pipeline that much. Certainly @mrry would possibly know as well.\r\n", "I hope @jsimsa can take a look.", "@chenjiasheng Can you clarify whether a) you are asking us to implement this API or b) you have an implementation of this API and you are looking for feedback on it.\r\n\r\nIf it is a), the request should clarify what should happen when the underlying file is compressed (`TextLineDataset` supports GZIP and ZLIB compression). Or are compressed files not supported by `TextLineBlockDataset`?\r\n\r\nOn a related note, how large are the text files in question? Instead of splitting the input file manually, you could make use of `tf.data.Dataset.shard()` or `tf.data.Dataset.filter()` in your input pipeline to \"partition\" the input across different GPUs. I say \"partition\" because a solution based on `shard()` and `filter()` read all the bytes and then discard the bytes that do not belong into this partition. If the time needed to read the all bytes is negligible compared to the time needed spend on training, then I recommend using existing transformations, instead of proposing a custom one.\r\n\r\nIf it is b), then I would be open to accepting this as a contribution to `tf.data.experimental` and reviewing the PR, provided the solution supports compressed files.", "@jsimsa \r\n\r\n> Can you clarify whether a) you are asking us to implement this API or b) you have an implementation of this API and you are looking for feedback on it.\r\n\r\nYes, I do have an implementation and I'd like to contribute it to `tf.data.experimental`. I wrote it by mimicking `TextLineDataset`. Compression supports were removed just for personal simplicity, and of cause it can be added back.\r\n\r\n> On a related note, how large are the text files in question?\r\n\r\n700M ~ 40G, each file has a different source, including wikipedia, weibo/douban (something similar to twitter), news, film subtitle, etc.\r\n\r\n\r\n> ... If the time needed to read the all bytes is negligible compared to the time needed spend on training, then I recommend using existing transformations, instead of proposing a custom one.\r\n\r\nYes, it is negligible compared to training. But it is not negligible when you are anxiously waiting for the training process start up normally . \r\nThe large memory consumed is not acceptable as well. \r\nMore over,  as I know `tf.data.Dataset.shard` generate lines in a concatenate order instead of interleaving, as a result almost all Wikipedia corpus lines come out before all the subtitle lines. \r\n", "@chenjiasheng happy to review the PR ... please add support for compression before sending it out"]}, {"number": 24181, "title": "tf.image (CLAHE) contrast limited adaptive histogram equalization.", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tf.image.clahe` would perform contrast limited adapative histogram equalization to enhance images natively on the tensorflow graph.\r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\nThose that want to run image processing natively on tensorflow ops.\r\n", "comments": ["@aselle @drpngx what do you think? ", "Yes please! If it can be GPU optimised and support 16 and 32bit float tensors it would also be a huge improvement over OpenCV etc... Especially for high bit depth users, such as in medical imaging. ", "We really need this since it is much better to do CLAHE after data augmentation since there are some kinds of grids would be on the image after CLAHE. If we combine it with the random rotation  it would turn the grids to the noise of data augmentation.", "Please check also (TF1) MCLAHE https://github.com/VincentStimper/mclahe/issues/3", "**M**CLAHE would be particularly wonderful - yes please!", "We had a PR proposal for CLAHE. If you want to try to contribute to MCLAHE please coordinate at https://github.com/tensorflow/addons/issues/2359", "Yeah, there is an [existing PR](https://github.com/tensorflow/addons/pull/2362) to fix this."]}, {"number": 24155, "title": "InfeedEnqueueTuple placed on TPU device blocks indefinitely", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): N/A\r\n- TensorFlow version (use command below): Cloud nightly\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Cloud TPUv3\r\n\r\n**Describe the current behavior**\r\n\r\nThere are two documented ways to use the TPU infeed ops:\r\n1. Place them on the CPU device and set device_ordinal to the requisite device\r\n2. Place them on the TPU device and leave device_ordinal empty\r\n\r\nThe first way works fine, the second way does transfer the data to the device, but then blocks, never returning control to the client. Of note, this deadlock only happens if there is currently an op running on the TPU device (via XRTExecute, but potentially others).\r\n\r\n**Describe the expected behavior**\r\n\r\nBoth methods should work.", "comments": []}, {"number": 24105, "title": "Add an ability to terminate tf.data.choose_from_datasets/sample_from_datasets early", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Don't know\r\n\r\n**Describe the feature and the current behavior/state.**\r\nPresently, choose_from_datasets terminates as soon all datasets finish. \r\nIt would be nice ho have an option to terminate as soon as *any* of datasets finish as well.\r\n\r\nSuppose you have a main dataset which you use for training and a secondary dataset you mix into your first one. They can be of completely different sizes, but you want training to terminate as soon as main dataset terminates without any regard to the secondary dataset.\r\n\r\n**Will this change the current api? How?**\r\nAdd a flag to choose_from_datasets/sample_from_datasets\r\n\r\n**Who will benefit with this feature?**\r\nUsers who write complex tf.data pipelines\r\n\r\n**Any Other info.**\r\n", "comments": ["This sounds like a reasonable option. It might be possible to implement it with a sliding `Dataset.window(2)` for detecting when an input is exhausted (e.g. look for the first time you get a single-element window, and that means that one of the inputs has reached the end), though we might need some kind of `take_while()` to terminate the overall iteration.\r\n\r\nI'm going to mark it as contributions welcome, for a change in `tf.data.experimental`.\r\n\r\n/cc @jsimsa since we were chatting about `take_while()`.", "Hey, I'd like to take a crack at this! Is that alright? \r\n", "If by taking a crack at this, you mean implementing `take_while` that sounds good to me.\r\n\r\nMy suggestion is to start by taking a look at how another op that takes a user defined function (e.g. `tf.data.experimental.scan`) is implemented and tested. Here are relevant code pointers for `scan`:\r\n\r\n- [python API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/scan_ops.py)\r\n- [op registration](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/experimental_dataset_ops.cc)\r\n- [C++ kernel implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/experimental/scan_dataset_op.cc)\r\n- [tests](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/kernel_tests/scan_test.py)", "I'll start working on `take_while`, but before I started I had a couple of questions. \r\n\r\n1. `take_while` will be part of `tf.data.experimental`, but should I make a separate `take_while_ops.py`, or should I include in a pre-existing python file? Are there any pre-existing ops of this type?\r\n2. What should the API of `take_while` look like? Do I make a general `take_while(cond_func)`, where `cond_func` returns a `tf.bool`. Or should it be more specific to this particular case of ending the overall iteration when one or all of the datasets finish?", "1. creating `take_while_ops.py` is fine\r\n2. general purpose `take_while(predicate)` as the API sounds good"]}, {"number": 24044, "title": "Secondary algorithm not provided error when not using cuDNN autotune", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.0 / 7.1.4\r\n- GPU model and memory: Nvidia Tesla K80, Quadro M1200\r\n\r\n**Describe the current behavior**\r\nI get the following error message when I set TF_CUDNN_USE_AUTOTUNE=0:\r\n 2018-11-22 10:10:01.227780: E tensorflow/stream_executor/cuda/cuda_dnn.cc:82] The primary convolution algorithm failed memory allocation, while a secondary algorithm is not provided.\r\n\r\n**Describe the expected behavior**\r\nI would expect a secondary algorithm that does not require any workspace to kick in should the scratch allocation for the primary algorithm fail even when I am not using autotune.\r\n\r\n**Other info / logs**\r\nI traced back the error message to when it was [first introduced](https://github.com/tensorflow/tensorflow/blob/466eb299f0ce20cf929b9e06d3d3c16959360c59/tensorflow/stream_executor/cuda/cuda_dnn.cc#L706) in the code base to revise the logic.\r\n\r\nIt seems to me that years of refactoring have disabled the [fallback mechanism](https://github.com/tensorflow/tensorflow/blob/466eb299f0ce20cf929b9e06d3d3c16959360c59/tensorflow/stream_executor/cuda/cuda_dnn.cc#L792) when both the primary and secondary algorithms are the default ones.\r\n", "comments": ["@zheng-xq  Can you please take a look? Thanks!", "@zheng-xq Gentle ping. Can you please take a look/point me at another resource? Thanks!"]}, {"number": 24003, "title": "Unable to train a LinearClassifier with categorical columns and CollectiveAllReduce", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nI'm trying to train a simple model LinearClassifier (tf.estimator.LinearClassifier) with different distribution strategies. \r\nI've successfully managed to train a model with parameter servers with numeric columns (tf.feature_column.numeric_column) and categorical columns (tf.feature_column.categorical_column_with_*). \r\nI've also successfully managed to train a model with CollectiveAllReduce and only numeric columns. \r\nBut unfortunately, I'm getting the following error whith the same model (with CollectiveAllReduce) but with one categorical column in place of a numeric column:\r\n\r\n> ValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\n\r\nSee below for the all traceback and logs.\r\n\r\nHere is a part of the code I am running:\r\n\r\n```\r\nestimator = tf.estimator.LinearClassifier(\r\n        feature_columns=[\r\n            tf.feature_column.categorical_column_with_hash_bucket(\"partnerid\", 13, dtype=tf.int64),\r\n            tf.feature_column.numeric_column(\"campaignid\", dtype=tf.int64)\r\n        ],\r\n        model_dir=\"my_path\",\r\n        n_classes=2,\r\n        optimizer=\"Adam\",\r\n        config=tf.estimator.RunConfig(\r\n            experimental_distribute=tf.contrib.distribute.DistributeConfig(\r\n                train_distribute=tf.contrib.distribute.CollectiveAllReduceStrategy(),\r\n                remote_cluster=cluster_spec\r\n            )\r\n        )\r\n    )\r\n\r\n    tf.estimator.train_and_evaluate(\r\n        estimator,\r\n        tf.estimator.TrainSpec(\r\n            input_fn_train,\r\n            max_steps=training_steps\r\n        ),\r\n        tf.estimator.EvalSpec(\r\n            input_fn_test,\r\n            steps=evaluation_steps,\r\n            start_delay_secs=0,\r\n            throttle_secs=evaluation_throttle_secs\r\n        )\r\n    )\r\n```\r\nIs it a known issue ? Are there current limitations with CollectiveAllReduce ?\r\n\r\n```\r\nINFO:tensorflow:Waiting for worker:0/init\r\ntensorflow - Waiting for worker:0/init\r\nINFO:tensorflow:Waiting for worker:1/init\r\ntensorflow - Waiting for worker:1/init\r\ncluster_spec: ClusterSpec({'worker': ['10.188.17.14:42897', '10.188.50.21:48063']})\r\nINFO:tensorflow:CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\r\ntensorflow - CollectiveAllReduceStrategy with local_devices = ['/device:CPU:0']\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\ntensorflow - Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\r\ntensorflow - RunConfig initialized for Distribute Coordinator with STANDALONE_CLIENT mode\r\nINFO:tensorflow:Using config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7bef60>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7bef60>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7d3208>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7d3208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'standalone_client'}\r\ntensorflow - Using config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7bef60>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7bef60>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7d3208>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7d3208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'standalone_client'}\r\nINFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\r\ntensorflow - Running `train_and_evaluate` with Distribute Coordinator.\r\nINFO:tensorflow:Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\r\ntensorflow - Running Distribute Coordinator with mode = 'standalone_client', cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = None, task_id = None, environment = None, rpc_layer = 'grpc'\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\ntensorflow - `eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ['/job:worker/task:0']\r\ntensorflow - Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ['/job:worker/task:0']\r\nINFO:tensorflow:Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ['/job:worker/task:1']\r\ntensorflow - Multi-worker CollectiveAllReduceStrategy with cluster_spec = {'worker': ['10.188.17.14:42897', '10.188.50.21:48063']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ['/job:worker/task:1']\r\nINFO:tensorflow:Updated config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7d3710>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7601d0>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760438>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7603c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.188.17.14:42897', '_evaluation_master': 'grpc://10.188.17.14:42897', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'standalone_client'}\r\ntensorflow - Updated config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7d3710>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7601d0>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760438>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a7603c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.188.17.14:42897', '_evaluation_master': 'grpc://10.188.17.14:42897', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'standalone_client'}INFO:tensorflow:Updated config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7d3cc0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a760630>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760898>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760828>, '_task_type': 'worker', '_task_id': 1, '_global_id_in_cluster': 1, '_master': 'grpc://10.188.50.21:48063', '_evaluation_master': 'grpc://10.188.50.21:48063', '_is_chief': False, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'standalone_client'}\r\n\r\ntensorflow - Updated config: {'_model_dir': 'hdfs://root/user/username/model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a7d3cc0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': DistributeConfig(train_distribute=<tensorflow.contrib.distribute.python.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f1c4a760630>, eval_distribute=None, remote_cluster=<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760898>), '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c4a760828>, '_task_type': 'worker', '_task_id': 1, '_global_id_in_cluster': 1, '_master': 'grpc://10.188.50.21:48063', '_evaluation_master': 'grpc://10.188.50.21:48063', '_is_chief': False, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'standalone_client'}\r\n2018-11-27 13:25:56.606318: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\nINFO:tensorflow:Calling model_fn.\r\ntensorflow - Calling model_fn.\r\nWARNING:tensorflow:Partitioned variables are disabled when using DistributionStrategy.\r\ntensorflow - Partitioned variables are disabled when using DistributionStrategy.\r\nINFO:tensorflow:Calling model_fn.\r\ntensorflow - Calling model_fn.\r\nDEBUG:tensorflow:Transforming feature_column _NumericColumn(key='campaignid', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None).\r\ntensorflow - Transforming feature_column _NumericColumn(key='campaignid', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None).\r\nDEBUG:tensorflow:Transforming feature_column _NumericColumn(key='campaignid', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None).\r\ntensorflow - Transforming feature_column _NumericColumn(key='campaignid', shape=(1,), default_value=None, dtype=tf.int64, normalizer_fn=None).\r\nDEBUG:tensorflow:Transforming feature_column _HashedCategoricalColumn(key='partnerid', hash_bucket_size=13, dtype=tf.int64).\r\ntensorflow - Transforming feature_column _HashedCategoricalColumn(key='partnerid', hash_bucket_size=13, dtype=tf.int64).\r\nDEBUG:tensorflow:Transforming feature_column _HashedCategoricalColumn(key='partnerid', hash_bucket_size=13, dtype=tf.int64).\r\ntensorflow - Transforming feature_column _HashedCategoricalColumn(key='partnerid', hash_bucket_size=13, dtype=tf.int64).\r\nINFO:tensorflow:Error reported to Coordinator: `IndexSlices` is not supported for Collective All-Reduce.\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\ntensorflow - Error reported to Coordinator: `IndexSlices` is not supported for Collective All-Reduce.\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\r\n    worker_fn(strategy)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/distribute/estimator_training.py\", line 246, in _worker_fn\r\n    hooks=hooks)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1205, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1316, in _train_model_distributed\r\n    self.config)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 721, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 556, in _call_for_each_tower\r\n    return _call_for_each_tower(self, fn, *args, **kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 183, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\n\r\nINFO:tensorflow:Error reported to Coordinator: `IndexSlices` is not supported for Collective All-Reduce.\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\ntensorflow - Error reported to Coordinator: `IndexSlices` is not supported for Collective All-Reduce.\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_coordinator.py\", line 344, in _run_single_worker\r\n    worker_fn(strategy)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/distribute/estimator_training.py\", line 246, in _worker_fn\r\n    hooks=hooks)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1205, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1316, in _train_model_distributed\r\n    self.config)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 721, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 556, in _call_for_each_tower\r\n    return _call_for_each_tower(self, fn, *args, **kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 183, in _call_for_each_tower\r\n    coord.join(threads)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 177, in _call_for_each_tower\r\n    **merge_kwargs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 661, in _distributed_apply\r\n    variable_scope.VariableAggregation.SUM, grads_and_vars)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/python/training/distribute.py\", line 776, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 628, in _batch_reduce\r\n    value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 243, in batch_reduce\r\n    return self._batch_reduce(aggregation, value_destination_pairs)\r\n  File \"/home/username/miniconda3/envs/explorer2/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py\", line 829, in _batch_reduce\r\n    \"`IndexSlices` is not supported for Collective All-Reduce.\")\r\nValueError: `IndexSlices` is not supported for Collective All-Reduce.\r\n```", "comments": ["I have encounter the same issuse. Can anyone provide a runable demo for Collective All-Reduce?", "Gentle ping @yuefengz", "Hi also encounter this problem in training Bert use multi-machine. \r\nI set the use_one_hot_embeddings to be true than it will have no error.\r\nDo not know why.", "SparseTensor and IndexSlices are currently not supported since it requires all-gather. @poxvoculi @dubey ", "The issue is still there in tf 1.13.1. \r\nDo you have any news ? \r\n@poxvoculi @dubey @yuefengz\r\n", "@fhoering could you try nightly TF? 1.13 release branch was cut last year and we can\u2019t really introduce any new feature. ", "@byronyi I tried with tf-nighly 1.14.1\r\nIndeed I doesn't give the not implemented error anymore but now fails with grpc error:\r\n```\r\n2019-05-17 14:23:01.822779: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingGather with Internal: RecvBufResponse returned 48 bytes where to_tensor expected 56\r\n2019-05-17 14:23:01.822834: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: RecvBufResponse returned 48 bytes where to_tensor expected 56\r\n```\r\n\r\nSide notes:\r\n- I tried with slightly different model, all logs + source code attached\r\n- When trying with NumericColumns only (that one that works) there are a lot of logs that disapeared. It doesn't seem to say that it is even using CollectiveAllReduceStrategy/Standalone mode anymore, but finishes with success and model is created, not sure it is actually distributed but metrics like loss/accuracy seem fine compared to ps strategy\r\n\r\n[Code.zip](https://github.com/tensorflow/tensorflow/files/3191918/Code.zip)\r\n[client.log](https://github.com/tensorflow/tensorflow/files/3191913/client.log)\r\n[worker1.log](https://github.com/tensorflow/tensorflow/files/3191914/worker1.log)\r\n[worker2.log](https://github.com/tensorflow/tensorflow/files/3191915/worker2.log)\r\n\r\n\r\n\r\n", "@byronyi \r\nI tried with another model and also post the error message:\r\n```\r\ntensorflow - Error reported to Coordinator: From /job:worker/replica:0/task:0:\r\nRecvBufResponse returned 206400 bytes where to_tensor expected 194400\r\n\t [[node allreduce_1/CollectiveGather_1 (defined at /threading.py:864) ]]\r\n```\r\n\r\nMaybe it is clearer than the attached logs of the previous model.\r\n\r\nIt fails in the reduce of gradients in tf.gather operation which seems to return a sparse tensor. \r\nhttps://github.com/tensorflow/tensorflow/blob/a5c387b5ed78c9126424618d5c70f51cd3799857/tensorflow/python/ops/array_ops.py#L3261\r\n\r\nSo the problem is still there but with a different form.\r\nCan you please have a look ?\r\n\r\n[full_stack_trace.txt](https://github.com/tensorflow/tensorflow/files/3201503/full_stack_trace.txt)", "any progress on this issue?", "`IndexedSlices` has already been supported a while ago, could you try it out again?", "Looks like there is some issue with the support for `IndexedSlices`. Right now there is some restriction that allgather requires all inputs have the same input sizes. If your `IndexedSlices` have different slices on different replicas, it will crash. @dubey ", "@fhoering can you confirm that it is indeed the case that your input tensors have different sizes on different replicas?", "We tried with only categorical features and only continuous features. For categorical features, there is indeed no guarantee that replicas have the same number of slices for allgather of sparse gradients. All worker process the same number of examples per iteration but the number of slices depend on the features included in batches", "Yes, I confirm. As mentioned by @nateagr. As each worker (with shuffling activated) sees different examples, they see different categories, therefore different gradients are activated and the indexes of the sparse tensors are different. \r\nI don't see any case with categorical features where this can actually work, maybe when having only one category per feature across all examples or deactivating shuffling, but in this case no need to train in a distributed way.", "Hi\uff0ccan eager mode supported now when updating indices slices?"]}, {"number": 23947, "title": "Network Bandwidth Un-expected Behavior ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Linux Ubuntu\r\n- TensorFlow installed from (source or binary): Yes\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 3.5\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: No GPU only CPU.\r\n\r\n\r\nI have a simple model 2.8 MB. I wrote a distributed Tensorflow code with one parameter server and one worker. I measured the network bandwidth for in and out from worker.\r\nI found that worker utilized bandwidth-in is 53 MB and worker utilized bandwidth-out is 26 MB. \r\nMy dataset is MNIST dataset which is 46 MB. \r\nThe total worker and server bandwidth are 92.5 MB.\r\n\r\nMy question is that I thought I will see only the size of my model in and out from to worker but where these 53, 26 data come from.\r\n\r\nThis is my code:\r\n\r\nhttps://github.com/salemmohammed/TensorflowDistributedExample/blob/master/PS_Dist1.py\r\n\r\n", "comments": ["@mrry "]}, {"number": 23928, "title": "C++ compilation of rule '//tensorflow/python:cost_analyzer_lib' failed (Exit 2): msvc_wrapper_for_nvcc.bat failed: error executing command", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 Professional\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nTrying to compile to CUDA 10\r\n- **TensorFlow version (use command below)**:\r\n1.12\r\n- **Python version**:\r\n3.6 64-bits\r\n- **Bazel version (if compiling from source)**:\r\n0.19.2\r\n- **GCC/Compiler version (if compiling from source)**:\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.16.27024.1 for x86\r\n- **CUDA/cuDNN version**:\r\nCUDA 10\r\n- **GPU model and memory**:\r\nGeForce GTX 1080 Ti \r\n11 GB GDDR5X\r\n- **Exact command to reproduce**:\r\nWhen buiilding from source:\r\nbazel --output_base=C:\\Temp\\finalbuild build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nAfter many atempts to compile this for use with CUDA 10 I get this error in the end of a really long compile. Tried everything but I still get this annoying error.\r\nI use VS 2017 Enterprise and CUDA 10\r\n\r\n### Source code / logs\r\nERROR: C:/temp/tensorflow/tensorflow/python/BUILD:247:1: C++ compilation of rule '//tensorflow/python:cost_analyzer_lib' failed (Exit 2): msvc_wrapper_for_nvcc.bat failed: error executing command\r\n  cd C:/temp/finalbuild/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\MSBuild\\15.0\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.17763.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Program Files (x86)/Microsoft Visual Studio/Shared/Python36_64/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/<USERNAME>/AppData/Roaming/Python/Python36/site-packages\r\n    SET TEMP=C:\\Users\\<USERNAME>~1\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\<USERNAME>~1\\AppData\\Local\\Temp\r\n\r\n\r\nDriver Version | 416.94\r\n-- | --\r\nDriver Model | WDDM\r\nCUDA Device Index | 0\r\nGPU Family | GP102-A\r\nCompute Capability | 6.1\r\nNumber of SMs | 28\r\nFrame Buffer Physical Size (MB) | 11264\r\nFrame Buffer Bandwidth (GB/s) | 484,44\r\nFrame Buffer Bus Width (bits) | 352\r\nFrame Buffer Location | Dedicated\r\nGraphics Clock (Mhz) | 803\r\nMemory Clock (Mhz) | 5505\r\nProcessor Clock (Mhz) | 1607\r\nRAM Type | GDDR5X\r\nAttached Monitors | 2\r\n\r\n\r\nName | AMD Ryzen Threadripper 1950X 16-Core Processor\r\n-- | --\r\nArchitecture | x64\r\nFrequency | 3\u00a0750 MHz\r\nNumber of Cores | 32\r\nPage Size | 4\u00a0096\r\nTotal Physical Memory | 16\u00a0258,00 MB\r\nAvailable Physical Memory | 11\u00a0372,00 MB\r\nHybrid Graphics Enabled | False\r\nVersion Name | Windows 10 Pro\r\nVersion Number | 10.0.17134\r\nNsight Version | 6.0.0.18227\r\nNsight Edition | Standard\r\nVisual Studio Version | 15.0\r\n\r\n\r\n", "comments": ["When rebuilding directly after the build failed it can build some more modules before failing again.\r\nCan this be due to my computer firing up 32 builds at the same time and that this mess upp with deps?\r\n\r\nI will try on Saturday to force Bazel to only execute 1 job and not 32 at once and see if that makes any difference.", "Did not work but still if I run build command again it fails on another module.\r\nThis is annoying since I need CUDA 10 support", "I have the same error, did you solve this problem? Thanks!", "@gunan @meteorcloudy any ideas?", "@port513 What is the actual error message from the compiler? Can you provide more detailed log?"]}, {"number": 23900, "title": "No clear_devices in BestExporter", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, please see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n/a\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): n/a\r\n- TensorFlow version (use command below): 1.10+\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: whatever is on Colab\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nOne can not train a distributed-`Estimator` and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter\r\n\r\n```\r\n__init__(\r\n    name='best_exporter',\r\n    serving_input_receiver_fn=None,\r\n    event_file_pattern='eval/*.tfevents.*',\r\n    compare_fn=_loss_smaller,\r\n    assets_extra=None,\r\n    as_text=False,\r\n    exports_to_keep=5\r\n)\r\n```\r\nit is apparent that `clear_devices` is not an option.\r\n\r\n**Describe the expected behavior**\r\n\r\nLet me easily export and import `Estimators`\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n see this [Colab](https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub)\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hello @SumNeuron , There some good posts on Stack Overflow about Estimator export/import:\r\nhttps://stackoverflow.com/questions/50612923/tensorflow-export-estimators-for-prediction\r\nhttps://stackoverflow.com/questions/51537682/how-do-i-export-an-estimator-tf-estimator-dnnclassifier\r\nWe shall close this issue now. Thanks.\r\n", "@msymp I believe you misunderstood.\r\n\r\nas stated in the question title, this is about a missing `clear_devices` flag in the export function.\r\n\r\nFurther, I would say that your two linked SO posts are not really related.\r\n\r\nThe first just uses the `model_dir` flag in the estimator constructor. \r\nThe second either uses the `serving_input_reciever_fn` or also the `model_dir`.\r\n\r\nBoth of which lead me to believe you are missing the point, which in the issue, under \"Describe current behavior\" is stated as : \r\n\r\n> One can not train a distributed-Estimator and export the model, then load it on a non-distributive device because if we look at the TensorFlow docs for BestExporter\r\n\r\nIn short, or to recap, without the `clear_devices` flag, the current way estimators are exported, if the `model_fn` uses any `with_device` specification (as is done in the official TF documentation for distributed models), the estimator can only be loaded to a system with at least that many devices with the same names.\r\n\r\nSo please open and re-read the issue.\r\n\r\n", "@msymp seems to be relevant again but in [Keras](https://github.com/tensorflow/tensorflow/issues/33474) as sessions takes the saved the model which doesn't have clear device options", "@SumNeuron We see that you are using old version of tensorflow , We recommend that you upgrade to 2.6.0  and let us know if the issue still persists in newer versions .Thanks!", "My apologies if this seems a bit jaded, but this issue opened almost three years ago (at the time when estimators were not more or less tossed aside in favor of Keras).  It only required a `clear_devices` flag be lifted from lower layers to higher layers.\r\n\r\nGoogling:\r\n\r\nhttps://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/exporter.py#L165-L365\r\n\r\nno, hasn't been added\r\n\r\nand I'm not the first to report this either: (2017)\r\n\r\nHERE IS THE LINE\r\nhttps://github.com/tensorflow/estimator/blob/a0186faff92d1502f0314e3c86a995b540fa6eb6/tensorflow_estimator/python/estimator/estimator.py#L837\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/14143\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.6.0/tensorflow/python/saved_model/builder_impl.py#L438-L627\r\n"]}, {"number": 23898, "title": "Error occurs when importing metagraph that contains cudnnRNN cells", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install .whl\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 2.7.14\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\n- CUDA/cuDNN version: cuda: 9.0 cuDNN: 7.1.3\r\n- GPU model and memory: GTX1050Ti/4GB\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/2603030/tf_env.txt)\r\n\r\n\r\n**Describe the current behavior**\r\nI try to import graph from a MetaGraphDef proto that contains a CudnnRNN cell, the error below raises:\r\n\r\n```\r\n Traceback (most recent call last):\r\n  File \"test.py\", line 21, in <module>\r\n    saver = tf.train.import_meta_graph(mgd)\r\n  File \"/root/anaconda2/envs/tf12/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1674, in import_meta_graph\r\n    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\r\n  File \"/root/anaconda2/envs/tf12/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1696, in _import_meta_graph_with_return_elements\r\n    **kwargs))\r\n  File \"/root/anaconda2/envs/tf12/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 852, in import_scoped_meta_graph_with_return_elements\r\n    ops.prepend_name_scope(value, scope_to_prepend_to_names))\r\n  File \"/root/anaconda2/envs/tf12/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3490, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/root/anaconda2/envs/tf12/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3550, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'cudnn_lstm/opaque_kernel_saveable' refers to an Operation not in the graph.\"\r\n```\r\n\r\nWhat I've done:\r\nI've debuged the souce code and found out that a CudnnLSTMSaveable instance is created when cudnnRNN cell gets called and corresponding op was saved in tf.GraphKeys.SAVEABLE_OBJECTS collections with the name \"cudnn_lstm/opaque_kernel_saveable\".\r\nwhen executing saver.import_meta_graph, in saver.save_op(line 189 of saver.py) function the saveable object mentioned above is somehow transfered into \"cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\" and \"cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\" and gets saved. But the op named \"cudnn_lstm/opaque_kernel_saveable\" didn't gets saved. I'm wandering if this is a bug.\r\n\r\n**Describe the expected behavior**\r\ngraph gets imported\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nnum_layers = 1\r\nnum_units = 128\r\ndirection = \"unidirectional\"\r\ninputs    = tf.placeholder(tf.float32, [None, None, 32], name=\"inputs\")\r\nconvolved = tf.transpose(inputs, [1, 0, 2])\r\n\r\nlstm      =  tf.contrib.cudnn_rnn.CudnnLSTM(num_layers, num_units, direction=direction)\r\noutputs, output_states = lstm(convolved, training=True)\r\nenc_output = tf.transpose(outputs, [1, 0, 2])\r\noptimizer  = tf.train.AdamOptimizer(0.001)\r\noptim = optimizer.minimize(enc_output)\r\nsaver     = tf.train.Saver()\r\ninit      = tf.global_variables_initializer()\r\nwith tf.Session() as session:\r\n    session.run(init)\r\n    # export MetaGraphDef proto to mgd\r\n    mgd=saver.export_meta_graph()\r\nwith tf.Session(graph=tf.Graph()) as session:\r\n    # import graph from mgd on another graph\r\n    saver = tf.train.import_meta_graph(mgd)\r\n```\r\n\r\n", "comments": ["Getting the same issue while loading SavedModel with cudnn_lstm layer inside. I thought maybe I need to prune these nodes, but when I inspected graph with tensorboard it couldn't find any! Moreover, due to the same issue it's impossible to launch Graph Transform Tool on it. \r\nI think I'm close as never before to another one-layer perceptron for university exam project...", "I'm struggling with the same problem. I'have saved my network with using CudnnLstm ;\r\n```python\r\nwith graph.as_default():\r\n    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name='inputs')\r\n    labels_ = tf.placeholder(tf.float32, [None, n_classes], name='labels')\r\n    keep_prob_ = tf.placeholder(tf.float32, name='keep')\r\n    learning_rate_ = tf.placeholder(tf.float32, name='learning_rate')\r\n\r\n    lstm_in = tf.transpose(inputs_, (1, 0, 2))\r\n    cudnn_lstm =tf.contrib.cudnn_rnn.CudnnLSTM(num_layers=2, num_units=36, dtype=tf.float32)  \r\n    outputs_, _ = cudnn_lstm(lstm_in)\r\n\r\nwith graph.as_default():\r\n    saver = tf.train.Saver()\r\n\r\nwith tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    iteration = 1\r\n\r\n    for e in range(epochs):\r\n        for x, y in get_batches(X_tr, y_tr, batch_size):\r\n\r\n            feed = {inputs_: x, labels_: y, keep_prob_: 0.5, learning_rate_: learning_rate}\r\n\r\n            loss, _,  acc = sess.run([cost, optimizer, accuracy], feed_dict=feed)\r\n  saver.save(sess, \"checkpoints/lstm.ckpt\")\r\n```\r\nI saved it in a checkpoint file. After that, using the code seen below, I'm trying to restore variables like input placeholder or accuracy.\r\n```python\r\ngraph = tf.Graph()\r\nwith tf.Session(graph=graph) as sess:\r\n    saver = tf.train.import_meta_graph('checkpoints-cnn/har.ckpt.meta')\r\n    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn/.'))\r\n\r\n    input = graph.get_tensor_by_name('inputs:0')\r\n```\r\nBut I get this error \" The name 'cudnn_lstm/opaque_kernel_saveable' refers to an Operation not in the graph'", "@protoget Any update on this issue? Really stuck at this point. Any feeble suggestions will greatly help! ", "@protoget Anything new? I'm getting this exact same error but with cudnn_gru,\r\n\" The name 'cudnn_gru/opaque_kernel_saveable' refers to an Operation not in the graph'", "@protoget Anything new? I have the same problem ", "When does **KeyError:The name 'something' refers to an Operation not in the graph** occur. facing similar issue. What operation is being performed(possibly in ops.py) that leads to this error?\r\nAlso, kindly look [this](https://github.com/tensorflow/tensorflow/pull/12759#issuecomment-467860111)", "As a temporary work around I used tf.keras.layers.CuDNNLSTM to build my RNN layers. ", "@shahinkl  I solved it, you should rebuild model and restore ckpt instead of using  import_meta_graph   ", "@brennenhuang\r\nWe know it will work with restore ckpt. That is why we are able to do validation and testing while training the graph. We face the issue while exporting and deploying the saved_model", " Anything new? I have the same problem", "Same issue here. Any pointers?", "Same issue here", "Same issue", "same issue\r\n", "same issue, any update?", "bump, same issue @drpngx @protoget ", "same issue, any update?", "same issue,solved?", "Using tensorflow serving to deploy metagraphdef proto does not have this issue", "same issue, any possible solution?", "I solve it like that:\r\n\r\nmodel = Autoencoder(self.hp, is_training=True)\r\nsaver = tf.train.Saver(max_to_keep=5)\r\nself.sess = tf.Session()\r\nckpt = tf.train.latest_checkpoint(self.checkpoints)\r\nsaver.restore(self.sess, ckpt)", "same issue when importing graph from .meta file by using tf.train.import_meta_graph\uff1f tensorflow version==1.14.0, looking forward to solve.", "same issue, any possible solution?", "I find this problem is because one node named 'cudnn_lstm/opaque_kernel_saveable' was added to graph.collection['saveable_objects'] but this node not added to saved model.\r\nwhen i build saved model, i run print(sess.graph.get_collection('saveable_objects')), then i got:\r\n[<tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTMSaveable object at 0x7fd0881535d0>]\r\nso, i try this before building saved model: sess.graph.clear_collection('saveable_objects'), then i can restore saved model.\r\nHowever, i am not sure whether this is right, and i can only delete all nodes in graph.collection['saveable_objects'], how can i only delete the node 'cudnn_lstm/opaque_kernel_saveable'?\r\n", "> I find this problem is because one node named 'cudnn_lstm/opaque_kernel_saveable' was added to graph.collection['saveable_objects'] but this node not added to saved model.\r\n> when i build saved model, i run print(sess.graph.get_collection('saveable_objects')), then i got:\r\n> [<tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTMSaveable object at 0x7fd0881535d0>]\r\n> so, i try this before building saved model: sess.graph.clear_collection('saveable_objects'), then i can restore saved model.\r\n> However, i am not sure whether this is right, and i can only delete all nodes in graph.collection['saveable_objects'], how can i only delete the node 'cudnn_lstm/opaque_kernel_saveable'?\r\n\r\n\r\n\r\n> same issue, any possible solution?\r\n\r\ni used keras.layers.CuDNNLSTM (tensorflow version:1.14) to avoid this issue", "Update, i find the codes add node named 'cudnn_lstm/opaque_kernel_saveable' to graph.collection['saveable_objects'] in /usr/lib64/python2.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/cudnn_rnn.py L372-L373(Tensorflow 1.15):\r\n```\r\n# Create saveable in the outer scope of the cudnn subgraph, such that\r\n# alternative subgraph with platform-independent rnn cells can load the\r\n# checkpoints directly.\r\nif not (self.built or vs.get_variable_scope().reuse is True):\r\n    self._create_saveable()\r\n```\r\n\r\nSo i delete them to slove this problem.\r\n", "same issue, any update?", "> Update, i find the codes add node named 'cudnn_lstm/opaque_kernel_saveable' to graph.collection['saveable_objects'] in /usr/lib64/python2.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/cudnn_rnn.py L372-L373(Tensorflow 1.15):\r\n> \r\n> ```\r\n> # Create saveable in the outer scope of the cudnn subgraph, such that\r\n> # alternative subgraph with platform-independent rnn cells can load the\r\n> # checkpoints directly.\r\n> if not (self.built or vs.get_variable_scope().reuse is True):\r\n>     self._create_saveable()\r\n> ```\r\n> \r\n> So i delete them to slove this problem.\r\n\r\nI tried but it doesn't work", "same issue, any possible solution?"]}]