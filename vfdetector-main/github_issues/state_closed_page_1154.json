[{"number": 18586, "title": "tf.train.batch does not work with tf.uint32 and tf.uint64 data types", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nvalues = tf.constant([0, 1, 2, 3, 4], dtype=tf.uint64)\r\nbatch = tf.train.batch(\r\n    [values],\r\n    batch_size=2,\r\n    num_threads=1,\r\n    enqueue_many=True,\r\n)\r\n\r\nwith tf.Session() as sess:\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n    print(sess.run(batch))\r\n\r\n    coord.request_stop()\r\n    coord.join(threads)\r\n```\r\n\r\n### Describe the problem\r\n`tf.train.batch` does not work on tensors with types `uint32` or `uint64`. It works with all other primitive types. The source of this issue can be traced back to `CopyElementToSlice` which calls `TF_CALL_ALL_TYPES`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/kernels/batch_util.cc#L94\r\n\r\nThis `TF_CALL_ALL_TYPES` macro eventually calls into `TF_CALL_INTEGRAL_TYPES` \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3128b43eb0bf37ac3c49cb22a6e1789d8ea346e8/tensorflow/core/framework/register_types.h#L154\r\n\r\nThis macro includes `int8`, `uint8`, `int16`, `uint16`, `int32`, and `int64` but **does not** include `uint32` or `uint64`\r\n\r\nThe change to support these types appears to be simple, but since `TF_CALL_ALL_TYPES` is a high-level macro, I did not know if these data types were purposefully excluded.\r\n", "comments": ["@alextp Do you know why these types are excluded?", "I wonder if the issue in this SO question is related to this one? https://stackoverflow.com/questions/49437216/tf-data-dataset-from-generator-not-supporting-uint16-uint32", "Can you try changing the definition of tf_call_all_types and send a pull request? A lot of our dtype handling decisions aren't very principled..", "Added a PR #18805 to support uint32 and uint64."]}, {"number": 18585, "title": "(do not merge) Testing changes for a future r1.7 patch release", "body": "", "comments": []}, {"number": 18584, "title": "Fix Warning in reduce_* related deprecation argument keep_dims", "body": "This PR is to fix WARNING in reduce_* related deprecation argument keep_dims.\r\n> calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\r\n> Instructions for updating: keep_dims is deprecated, use keepdims instead\r\n\r\nThe `keep_dims` for reduce_mean has been deprecated and replaced with `keepdims` in below ops:\r\n- [reduce_mean](https://www.tensorflow.org/api_docs/python/tf/reduce_mean)\r\n- [reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum)\r\n- [reduce_logsumexp](https://www.tensorflow.org/api_docs/python/tf/reduce_logsumexp)\r\n- [reduce_max](https://www.tensorflow.org/api_docs/python/tf/reduce_max)\r\n", "comments": ["The failure is timeout of `//tensorflow/core:common_runtime_ring_reducer_test`, which seems to be unrelated. "]}, {"number": 18583, "title": "Fail to save the checkpoint with dataset Iterator saveable when using shuffle", "body": "\r\n### System information\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.14.2)\r\nprotobuf (3.5.2.post1)\r\nsimple-tensorflow-serving (0.2.6, /usr/local/lib/python2.7/site-packages/simple_tensorflow_serving-0.2.6-py2.7.egg)\r\ntensorflow (1.7.0)\r\ntensorflow-hub (0.1.0)\r\ntensorflow-model-analysis (0.6.0)\r\ntensorflow-serving-api (1.0.0)\r\ntensorflow-tensorboard (1.5.0)\r\ntensorflow-transform (0.6.0)\r\ntensorflowjs (0.1.0)\r\ntensorflowonspark (1.0.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.7.0\r\ntf.GIT_VERSION = v1.7.0-3-g024aecf414\r\ntf.COMPILER_VERSION = v1.7.0-3-g024aecf414\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np\r\n.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\na.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Describe the problem\r\n\r\nWe follow the [official document](https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state) to save the checkpoint with dataset Iterator saveable but it fails. Maybe the implementation of serializing `iterator_ops` is not released in public repo.\r\n\r\n### Source code / logs\r\n\r\n```\r\ndataset = tf.data.Dataset.from_tensor_slices((image_list_placeholder, label_list_placeholder))\r\niterator = dataset.make_initializable_iterator()\r\nsaveable = tf.contrib.data.make_saveable_from_iterator(iterator)\r\ntf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)\r\nsaver = tf.train.Saver()\r\n\r\nwith tf.Session() as sess:\r\n  saver.save(sess, checkpoint_file, global_step=step_value)\r\n```\r\n\r\nHere is the error log.\r\n\r\n```\r\n2018-04-17 11:02:40.756347: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:1049 : Unimplemented: AsGraphDefInternal\r\nTraceback (most recent call last):\r\n  File \"./mnist_train.py\", line 181, in <module>\r\n    main(parse_args())\r\n  File \"./mnist_train.py\", line 156, in main\r\n    saver.save(sess, checkpoint_file, global_step=step_value)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1676, in save\r\n    {self.saver_def.filename_tensor_name: checkpoint_file})\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1140, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnimplementedError: AsGraphDefInternal\r\n         [[Node: SerializeIterator = SerializeIterator[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Assigning to @saxenasaurabh who was the author of these lines:\r\n\r\n```cpp\r\n  virtual Status AsGraphDefInternal(DatasetGraphDefBuilder* b,\r\n                                    Node** node) const {\r\n    return errors::Unimplemented(\"AsGraphDefInternal\");\r\n  }\r\n```", "Hi @tobegit3hub \r\n\r\nThanks for trying this out! The error you are seeing should happen if any of the Datasets in your input pipeline does not support  serialization. However, from you code sample, your input pipeline just contains the TensorSliceDataset which [does support](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/tensor_slice_dataset_op.cc#L87) checkpointing. Could you please verify that you have indeed posted your complete input pipeline?\r\n\r\nThanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Sorry for the late response. I still get the same error with `TensorFlow 1.8.0`. I will post the test script so that everyone can re-produce this issue easily.", "I get this error when adding `shuffle()` for the `dataset` object. It is easy to re-produce. We need one image file which could be named `1.jpg` and one csv file named `train.csv`. The content of `train.csv` is like this.\r\n\r\n```\r\n1.jpg,1\r\n```\r\n\r\nThen we can run the following script which throw `UnimplementedError` when saving the checkpoint. Notice that it is normal if we don't use `shuffle()` for the dataset.\r\n\r\n```\r\n#!/usr/bin/env python\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\n\r\ndef _decode_image_file(filename, label):\r\n  image_string = tf.read_file(filename)\r\n  features = tf.image.decode_jpeg(image_string, channels=1)\r\n  features = tf.image.resize_images(features, [28, 28])\r\n  return features, label\r\n\r\n\r\ndef main():\r\n  train_csv_file = \"./train.csv\"\r\n  feature_size = 28 * 28 * 1\r\n  label_size = 10\r\n  epoch_number = 10\r\n  batch_size = 1\r\n\r\n  train_image_list_placeholder = tf.placeholder(tf.string, [None])\r\n  train_label_list_placeholder = tf.placeholder(tf.int64, [None])\r\n  train_dataset = tf.data.Dataset.from_tensor_slices(\r\n          (train_image_list_placeholder, train_label_list_placeholder))\r\n  train_dataset = train_dataset.repeat(epoch_number).shuffle(1000).map(_decode_image_file).batch(batch_size)\r\n  train_iterator = train_dataset.make_initializable_iterator()\r\n  train_features_op, train_label_op = train_iterator.get_next()\r\n  train_features_op = tf.cast(train_features_op, tf.float32)\r\n\r\n  train_dataframe = pd.read_csv(\r\n      train_csv_file,\r\n      delimiter=\",\",\r\n      header=None,\r\n      dtype={\"label\": \"int64\"}).sample(frac=1.0)\r\n  train_image_list = train_dataframe[0].tolist()\r\n  train_label_list = train_dataframe[1].tolist()\r\n\r\n  global_step = tf.Variable(\r\n      0, name=\"global_step\", dtype=tf.int64, trainable=False)\r\n  input = tf.reshape(train_features_op, (-1, feature_size))\r\n  weights = tf.get_variable(\r\n          \"weight\", [feature_size, label_size],\r\n          dtype=tf.float32,\r\n          initializer=tf.zeros_initializer)\r\n  bias = tf.get_variable(\"bias\", [label_size], dtype=tf.float32, initializer=tf.zeros_initializer)\r\n  logits = tf.matmul(input, weights) + bias\r\n  loss = tf.reduce_mean(\r\n      tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n          logits=logits, labels=train_label_op))\r\n  train_op = tf.train.GradientDescentOptimizer(0.01).minimize(\r\n          loss, global_step=global_step)\r\n\r\n  saveable = tf.contrib.data.make_saveable_from_iterator(train_iterator)\r\n  tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)\r\n  saver = tf.train.Saver()\r\n\r\n  with tf.Session() as sess:\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(\r\n        train_iterator.initializer,\r\n        feed_dict={\r\n            train_image_list_placeholder: train_image_list,\r\n            train_label_list_placeholder: train_label_list\r\n        })\r\n\r\n    try:\r\n      _, loss_value, global_step_value = sess.run([train_op, loss, global_step])\r\n      saver.save(sess, \"checkpoint/checkpoint.ckpt\", global_step=global_step_value)\r\n    except tf.errors.OutOfRangeError:\r\n      print(\"End of data\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  main()\r\n```", "I'm not sure if it is by design. If so, it would be better to add the introduction about the conflict of `shuffle` and `checkpoint`.\r\n\r\nSaving the status of \"shuffled\" data is different from the offset and not needed in checkpoint files. But we use `dataset` to read training data and \"resuming\" training with checkpoints. We can do that by shuffling data in advance and do not use `shuffle` in dataset. Or dataset supports saving the \"offset\" of data but not strictly guarantee the sequence of shuffled data.", "Nagging Assignee @tobegit3hub: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This should be fixed as of [8666eff](https://github.com/tensorflow/tensorflow/commit/8666eff2359ccacd528dfda404a1f8ae35762542). @tobegit3hub  please re-open if you are still running into any issues.", "Great. Thanks @saxenasaurabh \ud83d\udc4d "]}, {"number": 18582, "title": "Remove conditional scope logic now that \"current_arg_scope\" exists in contrib", "body": "", "comments": []}, {"number": 18581, "title": "Fix typo", "body": "", "comments": []}, {"number": 18580, "title": "Branch 193119953", "body": "Manually resolved\r\ntensorflow/contrib/data/python/kernel_tests/sequence_dataset_op_test.py\r\ntensorflow/contrib/data/python/ops/batching.py\r\ntensorflow/contrib/metrics/python/ops/metric_ops.py\r\ntensorflow/contrib/tensorrt/convert/convert_nodes.cc\r\ntensorflow/core/common_runtime/process_util.cc\r\ntensorflow/core/kernels/cwise_op_clip.cc\r\ntensorflow/core/kernels/cwise_op_clip.h\r\ntensorflow/core/kernels/cwise_op_clip_gpu.cu.cc\r\ntensorflow/core/kernels/maxpooling_op.cc\r\ntensorflow/python/framework/dtypes.py\r\ntensorflow/python/framework/tensor_shape_test.py\r\ntensorflow/python/kernel_tests/clip_ops_test.py\r\ntensorflow/python/ops/clip_ops.py\r\ntensorflow/python/util/tf_inspect.py\r\ntensorflow/tools/api/generator/create_python_api.py\r\ntensorflow/tools/docs/parser.py\r\ntensorflow/tools/docs/parser_test.py\r\n", "comments": ["cc: @jsimsa ", "We decided against it because it's hard to make a reversible\ntransformation, and they are not harmful either. In a perfect world,\neverybody would make a GitHub issue to link, but it's pretty far down the\nlist of important things to do.\n", "Seems that both py presubmit failed on same test case, need some check and probably rollback.", "Internal continuous builds were all green, and so are github builds. I wonder if I mess something up during merge.", "Tried reproducing the failure locally and I get a segfault. constant_op_test itself didn't change. Maybe one of the underlying ops it use is causing issues? Any suggestion?", "Turns out to be issue with merge indeed! The change in dtypes.py from https://github.com/tensorflow/tensorflow/pull/18481/files got override. Will fix. ", "Nice debugging!\u200b\n"]}, {"number": 18579, "title": "Enable consumption of GIT_TAG_OVERRIDE env var in release build script.", "body": "", "comments": []}, {"number": 18578, "title": "GCS Filesystem should not cache checkpoint file as we need to read th\u2026", "body": "\u2026e updated checkpoints from the contents.\r\n\r\nPiperOrigin-RevId: 192517819\r\n(cherry picked from commit 079d63d59b75bdfd25f7371efda25ec5f6739b78)", "comments": []}, {"number": 18577, "title": "Added support for saved_model_cli input files stored on GCS/AWS.", "body": "", "comments": []}, {"number": 18576, "title": "Added support for saved_model_cli input files stored on GCS/AWS", "body": "", "comments": []}, {"number": 18575, "title": "Fix TFLite Makefile FFT2D dependency.", "body": "FFT2D dependency was introduced a while ago so Makefile no longer works\r\nuntil this fix.", "comments": []}, {"number": 18574, "title": "Added support for saved_model_cli input files stored on GCS/AWS", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->"]}, {"number": 18573, "title": "1.8.0-rc1 cherry-pick request: Disable square rewrite for complex types, re-enable arithmetic optimizations for tests", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@annarev it looks like there is another cherrypick that I did not request mixed into this PR. How come?", "PR was originally set to commit to \"master\". I think that caused additional diff to show. I changed it to \"r1.8\".", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@annarev @yifeif Thanks!"]}, {"number": 18572, "title": "Feeding variable length list data (from csv) to an 'indicator_column' feature", "body": "I have a feature as follows:\r\n`tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_file(...))`\r\n\r\nCorresponding 'vocabulary_file' contains integer values as follows:\r\n\r\n10\r\n20\r\n32\r\n44\r\n5\r\n1212\r\n...\r\n\r\nConsider such training examples:\r\nJack, M, 22, **\"[10, 20]\"**, 2.33, 1\r\nSara, F, 24, **\"[32, 44, 5, 1212]\"**, 5.6, -1\r\n\r\nEach training example has a variable length list data like [10, 20] or [32, 44, 5, 1212]\r\nNow, I want to capture this data from csv file into the 'indicator_column' feature and then feed the multi-hot representation (result) to a deep model. \r\nThe `decode_csv` function only support `float32`, `float64`, `int32`, `int64`, `string` and I have issue for **'list'** type data in csv. \r\n\r\n------------------------\r\n\r\n### System information\r\n- **OS Platform**: Win8\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: 1.5\r\n- **Python version**: 3.6\r\n- **Bazel version**: None\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: GPU> None | CPU> AMD(Phenom II x4)\r\nExact command to reproduce is clear.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler : I've updated the issue template.", "@skye ", "@mrry do you know if there are any plans to implement something like this?", "This is already possible: simply apply `tf.string_split(list_column, ',')` to the field with list data to get a `tf.SparseTensor` representing the variable-length list. (You may also need to use `tf.regex_replace()` to remove the `'['` and `']'` characters from the list, if you can't remove them when the data is being produced; and `tf.cast()` to convert the string elements to integers.)", "@mrry @skye @tensorflowbutler \r\n\r\nConverting tensor of string of ints to tensor of list of ints done successfully. But I get an error when passing this resulted tensor to the `indicator_column` or `embedding_column` as follows:\r\n\r\n`tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot batch tensors with different shapes in component 4. First element had shape [5] and element 1 had shape [4].`\r\n\r\n`\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?], [?], [?], [?], [?,?], ..., [?], [?], [?], [?], [?]], output_types=[DT_INT32, DT_FLOAT, DT_STRING, DT_STRING, DT_INT32, ..., DT_STRING, DT_STRING, DT_STRING, DT_FLOAT, DT_BOOL], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n`\r\n", "Judging from the error, you are attempting to use `Dataset.batch()` on a dataset of elements with different shapes. If the elements have different shapes, you must either (i) transform them to all have the same shape (e.g. using `Dataset.map()`) or (ii) use `Dataset.padded_batch()` to add padding to some of the components.", "@mrry \r\nSome of my features have different length values, But I already defined `embedding_column`s for them in my model. As you know, an `embedding_column` has a constant `dimension` so why shapes various when I parse and map my dataset and then pass them to the model?", "@mrry \r\nConsider you have an `embedding_column` named `ec`. `ec` is defined in estimator model for accepting a sparse column. Further consider the column's values are different length integer list. How you parse and pass the column to `ec`?", "@imanirajian \r\n\r\nHave you figured out how to input variable length feature data to get embedding columns?\r\n", "# coding: utf-8\r\nimport collections\r\nimport os\r\nimport sys\r\nimport time\r\nimport re\r\nimport math\r\nimport random\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.feature_column.feature_column import _CategoricalColumn\r\nfrom tensorflow.python.framework import dtypes, tensor_shape\r\nfrom tensorflow.python.ops import parsing_ops, array_ops, string_ops\r\nfrom tensorflow.python.framework import sparse_tensor as sparse_tensor_lib\r\nfrom tensorflow.python.util import deprecation\r\n\r\nplt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # plt\u4e2d\u6587\u663e\u793a\r\npd.set_option('display.max_columns', None)  # pandas\u663e\u793a\u6240\u6709\u5217\r\npd.set_option('display.max_rows', None)  # pandas\u663e\u793a\u6240\u6709\u884c\r\npd.set_option('max_colwidth', 1000)\r\npd.set_option('display.width', 1000 * 10)\r\nnp.set_printoptions(threshold=sys.maxsize)\r\n\r\n\r\nclass SparseVarLenCategoricalColumnWithHashBucket(_CategoricalColumn,\r\n                                                  collections.namedtuple('SparseVarLenCategoricalColumnWithHashBucket',\r\n                                                                         ['key', 'hash_bucket_size', 'delimiter'])):\r\n    \"\"\"\r\n    \u8f93\u5165\u4e3a X1&X2&X3 \u5f62\u5f0f, &\u4e3adelimiter\r\n    \"\"\"\r\n\r\n    @property\r\n    def name(self):\r\n        return self.key\r\n\r\n    @property\r\n    def parse_example_spec(self):\r\n        return {self.key: parsing_ops.VarLenFeature(dtypes.string)}\r\n\r\n    _FEATURE_COLUMN_DEPRECATION_DATE = None\r\n    _FEATURE_COLUMN_DEPRECATION = ('The old _FeatureColumn APIs are being '\r\n                                   'deprecated. Please use the new FeatureColumn '\r\n                                   'APIs instead.')\r\n\r\n    @property\r\n    @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,\r\n                            _FEATURE_COLUMN_DEPRECATION)\r\n    def _parse_example_spec(self):\r\n        return self.parse_example_spec\r\n\r\n    def _transform_feature(self, inputs):\r\n\r\n        input_tensor = inputs.get(self.key)\r\n        print(\"DEBUG\", input_tensor)\r\n        flat_input = array_ops.reshape(input_tensor, (-1,))\r\n        input_tensor = tf.string_split(flat_input, self.delimiter)\r\n\r\n        if not isinstance(input_tensor, sparse_tensor_lib.SparseTensor):\r\n            raise ValueError('key={key} must be sparse tensor'.format(key=self.key))\r\n\r\n        sparse_values = input_tensor.values\r\n        sparse_id_values = string_ops.string_to_hash_bucket_fast(sparse_values, self.hash_bucket_size, name='lookup')\r\n        return sparse_tensor_lib.SparseTensor(input_tensor.indices, sparse_id_values, input_tensor.dense_shape)\r\n\r\n    @property\r\n    def _variable_shape(self):\r\n        if not hasattr(self, '_shape'):\r\n            self._shape = tensor_shape.vector(self.hash_bucket_size)\r\n        return self._shape\r\n\r\n    @property\r\n    def _num_buckets(self):\r\n        return self.hash_bucket_size\r\n\r\n    def _get_sparse_tensors(self, inputs, weight_collections=None, trainable=None):\r\n        return _CategoricalColumn.IdWeightPair(inputs.get(self), None)\r\n\r\n\r\ndef categorical_column_with_var_len_hash_bucket(key, hash_bucket_size, delimiter=\",\"):\r\n    return ValueError('invalid hash_bucket_size {} !'.format(hash_bucket_size)) if (hash_bucket_size is None) or (hash_bucket_size < 1) \\\r\n        else SparseVarLenCategoricalColumnWithHashBucket(key, hash_bucket_size, delimiter)\r\n\r\n\r\ncustom_cat_col = categorical_column_with_var_len_hash_bucket(\"seq\", hash_bucket_size=10, delimiter=\"&\")\r\ncustom_cat_emd_col = tf.feature_column.embedding_column(categorical_column=custom_cat_col, dimension=5, combiner='sum')\r\nprint(custom_cat_emd_col)\r\n\r\nfeatures = {\r\n    'seq': [[\"\"], ['A'], ['B'], ['C'], ['A&B'], ['A&B&B'], [\"A&B&C\"]],\r\n}\r\n\r\ntensor = tf.feature_column.input_layer(features, [custom_cat_emd_col])\r\n\r\nwith tf.Session() as session:\r\n    session.run(tf.global_variables_initializer())\r\n    session.run(tf.tables_initializer())\r\n    print(session.run([tensor]))\r\n=========\r\n\u8fd9\u662f\u6211\u7684\u5b9e\u73b0\uff0c\u53ef\u4ee5\u652f\u6301pb\u5bfc\u51fa\uff0c\u76f4\u63a5\u4f20 \u201c1&2\u201d\uff0c\u4e0d\u7528padding\u3002"]}, {"number": 18571, "title": "Merge pull request #18568 from case540/enable_git_tag_override", "body": "Add ability to override git tag in __git_version__ string.", "comments": ["@av8ramit assigning you since this is required for release process update, right?", "@yifeif just a heads up for rc1."]}, {"number": 18570, "title": "Fix the issue with Bahdanau attention when normalized=True and dtype = float16/32", "body": "While revisiting #18106 I noticed that Bahdanau attention has a similar dtype mismatch issue when normalized=True. The issue comes from:\r\n```\r\n     g = variable_scope.get_variable(\r\n         \"attention_g\", dtype=dtype,\r\n         initializer=math.sqrt((1. / num_units)))\r\n```\r\nwhere the initializer value does not work well with differnt dtype.\r\n\r\nThis fix converts changes the initializer to `init_ops.constant_initializer`\r\nto address the issue, and adds additional test cases for it.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": []}, {"number": 18569, "title": "Merge branch", "body": "Merging r1.8 changes into master.", "comments": []}, {"number": 18568, "title": "Add ability to override git tag in __git_version__ string.", "body": "Adding this functionality to make release process smoother. It will\r\nallow us to create the release builds before creating the git\r\nrelease tag.\r\n\r\nTo override the git version string, build using flag such as...\r\n--action_env=GIT_TAG_OVERRIDE=\"v1.8.0\"", "comments": []}, {"number": 18567, "title": "Fix expand_dims of dim argument has been deprecated with axis", "body": "This PR is to fix tf.expand_dims of dim argument has been deprecated with axis.\r\n\r\nAs we can see from [array_ops.expand_dims#L147](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L147), the dim argument of array_ops.expand_dims has been deprecated and in favor of axis.\r\n\r\nBesides, we can see from [tf.expand_dims](https://www.tensorflow.org/api_docs/python/tf/expand_dims) as below: axis/ dim should be scalar type instead of list/ tuple.\r\n![image](https://user-images.githubusercontent.com/1680977/38824384-9f6d3214-41db-11e8-8d76-1ca2e9195be5.png)\r\n", "comments": ["Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 141 days with no activity and the `awaiting review` label has been applied.", "thank you!", "A conflict has crept in (sorry this took so long!), could you rebase/fix? "]}, {"number": 18566, "title": "Help with C++API configuration", "body": "What do I need to choose at `./configure` ?If I just want to start learn tensorflow by C++API , when I choose nothing and run bazel( `bazel build :libtensorflow_cc.so` ) I get \r\n`ERROR: Skipping ':libtensorflow_cc.so': no such target '//:libtensorflow_cc.so': target 'libtensorflow_cc.so' not declared in package '' defined by /home/vjusak/Tensorflow/BUILD\r\nWARNING: Target pattern parsing failed.\r\nERROR: no such target '//:libtensorflow_cc.so': target 'libtensorflow_cc.so' not declared in package '' defined by /home/vjusak/Tensorflow/BUILD\r\nINFO: Elapsed time: 0.393s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n`\r\nUbuntu 16.10 \r\n\r\n> bazel version\r\n`Build label: 0.12.0\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Aug 4 01:22:27 +50246 (1523462001747)\r\nBuild timestamp: 1523462001747\r\nBuild timestamp as int: 1523462001747\r\n`", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hi,\r\n    try `bazel build //tensorflow:libtensorflow_cc.so`"]}, {"number": 18565, "title": "add checking for input values in GANHead constructor", "body": "", "comments": ["@martinwicke Hello, what status of this PR?", "Waiting for a review from @joel-shor. ", "Nagging Reviewer @joel-shor: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Hi @joel-shor . Thank you very much for your review. Yes, I'm agree with you comment. Now it's fixed.", "Nagging Assignee @martinwicke: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@joel-shor can you take a look and see whether you have any more comments?", "The build failure is unrelated (and also on master, probably infra)"]}, {"number": 18564, "title": "Failed to compile summarize_graph on macOS with TF 1.7", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.3\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**: 0.12.0-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Xcode 9.3: Apple LLVM version 9.1.0 (clang-902.0.39.1)\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: `bazel build tensorflow/tools/graph_transforms:summarize_graph`\r\n\r\n### Describe the problem\r\nBuild fails with the output in the section below. Removing `armeabi-v7a` from `third_party/jpeg/jpeg.BUILD` seems to resolve the issue. See output of `git diff` below.\r\n\r\nBuilding `summarize_graph` above fails fast, but I originally found the issue by trying to build `print_selective_registration_header` using the following command, which fails in ~90 seconds on my machine:\r\n```bash\r\nbazel build tensorflow/tools/graph_transforms:summarize_graph\r\n```\r\n\r\n### Source code / logs\r\nOutput of build command:\r\n```\r\nWARNING: /private/var/tmp/_bazel_json/e38619818ff94aae50ac5b3bdbbe0f32/external/protobuf_archive/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_json/e38619818ff94aae50ac5b3bdbbe0f32/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nINFO: Analysed target //tensorflow/tools/graph_transforms:summarize_graph (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /private/var/tmp/_bazel_json/e38619818ff94aae50ac5b3bdbbe0f32/external/jpeg/BUILD:44:1: C++ compilation of rule '@jpeg//:jpeg' failed (Exit 1)\r\nerror: unknown target CPU 'armv7-a'\r\nTarget //tensorflow/tools/graph_transforms:summarize_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 0.877s, Critical Path: 0.18s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nDiff of workaround via `git diff`:\r\n```diff\r\ndiff --git a/third_party/jpeg/jpeg.BUILD b/third_party/jpeg/jpeg.BUILD\r\nindex 87a23925c4..fa6dd27a70 100644\r\n--- a/third_party/jpeg/jpeg.BUILD\r\n+++ b/third_party/jpeg/jpeg.BUILD\r\n@@ -28,12 +28,6 @@ libjpegturbo_copts = select({\r\n         \"-w\",\r\n     ],\r\n }) + select({\r\n-    \":armeabi-v7a\": [\r\n-        \"-D__ARM_NEON__\",\r\n-        \"-march=armv7-a\",\r\n-        \"-mfloat-abi=softfp\",\r\n-        \"-fprefetch-loop-arrays\",\r\n-    ],\r\n     \":linux_ppc64le\": [\r\n         \"-mcpu=power8\",\r\n         \"-mtune=power8\",\r\n@@ -125,7 +119,6 @@ cc_library(\r\n     visibility = [\"//visibility:public\"],\r\n     deps = select({\r\n         \":k8\": [\":simd_x86_64\"],\r\n-        \":armeabi-v7a\": [\":simd_armv7a\"],\r\n         \":arm64-v8a\": [\":simd_armv8a\"],\r\n         \":linux_ppc64le\": [\":simd_altivec\"],\r\n         \"//conditions:default\": [\":simd_none\"],\r\n@@ -423,7 +416,6 @@ genrule(\r\n         \":windows\": \"cp $(location jconfig_win.h) $@\",\r\n         \":windows_msvc\": \"cp $(location jconfig_win.h) $@\",\r\n         \":k8\": \"cp $(location jconfig_nowin_simd.h) $@\",\r\n-        \":armeabi-v7a\": \"cp $(location jconfig_nowin_simd.h) $@\",\r\n         \":arm64-v8a\": \"cp $(location jconfig_nowin_simd.h) $@\",\r\n         \":linux_ppc64le\": \"cp $(location jconfig_nowin_simd.h) $@\",\r\n         \"//conditions:default\": \"cp $(location jconfig_nowin_nosimd.h) $@\",\r\n@@ -524,11 +516,6 @@ config_setting(\r\n     values = {\"crosstool_top\": \"//external:android/crosstool\"},\r\n )\r\n \r\n-config_setting(\r\n-    name = \"armeabi-v7a\",\r\n-    values = {\"android_cpu\": \"armeabi-v7a\"},\r\n-)\r\n-\r\n config_setting(\r\n     name = \"arm64-v8a\",\r\n     values = {\"android_cpu\": \"arm64-v8a\"},\r\n```", "comments": ["People over at the Bazel Github page have encountered this issue but were apparently able to fix it by using the install version of bazel as compared to the Homebrew version of bazel (which is weird since Homebrew should be compiling it from source). You can see some of the discussion at the bottom of bazelbuild/bazel/issues/4794. \r\n\r\nI have encountered this issue, but I have not tried their solution. It sounds to me like its a problem with bazel not detecting the correct architecture. I will, however, note that if I compile with version 0.11.1 from Homebrew that I get an unrelated error.\r\n\r\nI will be trying various solutions and seeing if I can get anything to work.", "Same problem on macOS, using bazel 0.12 to build tensorflow r1.7. It's very strange that the build target became armv7-a during building.", "@FrederickGeek8 That sounds reasonable. I just (re-)installed bazel today and I'm fairly certain it did *not* compile from source (it was way too fast and didn't output a whole lot to stdout). I'll try doing a manual installation of bazel at some point and see what happens.", "@sadlerjw Homebrew by nature tends to compile source code (if you don't believe me check out the [Homebrew formula repo](https://github.com/Homebrew/homebrew-core/blob/master/Formula/) or the Bazel [formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/bazel.rb). \r\n\r\nThat being said, **I was successfully able to build Tensorflow** by using Bazel 0.11.1 installed using their [installer](https://github.com/bazelbuild/bazel/releases/download/0.11.1/bazel-0.11.1-installer-darwin-x86_64.sh) (NOT Homebrew). Although its unrelated to this specific issue, I also was forced to downgrade from Xcode 9.2 to 8.2.1.\r\n\r\nI do want to clear up some confusion from before. I misunderstood how the installer worked for Bazel. Although Homebrew compiles Bazel from sources and Bazel offers source code for their program, the installer for Bazel just installs (from what I can tell) precompiled binaries, which at least for me, work for compiling Tensorflow.", "@gunan, can you take a look?", "I am OOO, you may want to redirect this for faster triage.", "/CC @av8ramit", "With macOS Sierra and bazel 0.12 installed WITH the bazel installer (NOT Homebrew), I get the exact same armv7-a error on a x86_64 architecture.  I am attempting to build the r17 branch.", "I think I saw another issue similar to this today.\r\nThis is a known bug with latest version of bazel.\r\nPlease either use bazel 0.11 with tf 1.7 branch, or switch to 1.8 branch.", "Confirmed fixed (for me) in v1.8.0 tag.", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18563, "title": "Update gemmlowp version for cmake build", "body": "The gemmlowp has been updated in bazel, though cmake version was not updated. This fix updates\r\ngemmlowp in cmake so that cmake and bazel versions are synced.\r\n\r\nNOTE: Due to a Windows compilation issue, upstream changes is needed. I have created a upstream PR in gemmlowp repo which has been merged:\r\n\r\ngoogle/gemmlowp#135\r\n\r\nBecause of the above changes, this PR updates both cmake and bazel version at the same time, to sync up and make sure the behaviors are the same.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@martinwicke As the upstream PR (google/gemmlowp#135) has been merged, this PR is ready for review. Please take a look.", "Updating tests, otherwise looks good.", "The Mac build error is as follows:\r\n```\r\nINFO: Analysed 983 targets (394 packages loaded).^M\r\nINFO: Found 983 test targets...^M\r\n[0 / 192] [-----] BazelWorkspaceStatusAction stable-status.txt^M\r\n[280 / 5,144] Executing genrule @protobuf_archive//:protos_python_genrule [for host]; 3s remote ... (25 actions, 24 running)^M\r\nERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/core/BUILD:460:1: Couldn't build file tensorflow/core/_objs/core_stringpiece/tensorflow/core/lib/core/stringpiece.o: C++ compilation of rule '//tensorflow/core:core_stringpiece' failed: Unexpected IO error.: xcode-locator failed with code 1.\r\nThis most likely indicates that xcode version 8.3.3 is not available on the host machine.\r\nProcess exited with status 1\r\nstderr: ^M\r\nERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/core/BUILD:1945:1: Couldn't build file tensorflow/core/_objs/version_lib/tensorflow/core/util/version_info.o: C++ compilation of rule '//tensorflow/core:version_lib' failed: Unexpected IO error.: xcode-locator failed with code 1.\r\nThis most likely indicates that xcode version 8.3.3 is not available on the host machine.\r\nProcess exited with status 1\r\nstderr: ^M\r\nERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/core/BUILD:1772:1: Couldn't build file tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: Unexpected IO error.: xcode-locator failed with code 1.\r\nThis most likely indicates that xcode version 8.3.3 is not available on the host machine.\r\n```\r\n\r\nI think this might be an infrastructure issue.", "Yes, that's infra. I think the MacOS contrib build gives us enough coverage to feel good about this."]}, {"number": 18562, "title": "Update libpng to v1.6.34 for cmake build", "body": "The libpng has been updated from v1.2.53 to v1.6.34 in PR 18299.\r\nHowever, the cmake version of libpng has not been updated yet. This fix updates the libpng for cmake to v1.6.34.\r\n\r\nThe fix is tested with cmake on linux:\r\n```\r\ntensorflow/tools/ci_build/ci_build.sh CMAKE tensorflow/tools/ci_build/builds/cmake.sh\r\n```\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["I'm a bit skeptical since the CMake build fails with this, but it is not a known failure. Can you check on this?", "Thanks @martinwicke. The error log is:\r\n```\r\nImportError: No module named 'google'\r\n```\r\nwhich looks like to be unrelated. I rebased and pushed the PR. All tests passes now. I think this is a transient error. Please take a look.", "Thanks. Yeah, some flake. Thanks for checking!"]}, {"number": 18561, "title": "Update docs for tf.cast with supported types", "body": "This fix tries to address the issue raised in #18529 where there are some confusion over supported types for `tf.cast`. This fix updates the docs with explicitly supported numeric type for `tf.cast`:\r\n```\r\n`uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`,\r\n`float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\r\n```\r\n\r\nThis fix fixes #18529.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": ["What happens when complex and real types are mixed? I don't think that's supported, right? If we're doing this we should be explicit about which pairs actually work.", "Thanks @martinwicke. I took a look at the implementation and verified that all pairs works.\r\n\r\nIn case of complex data types, for complex type -> real type, only the real part is returned. For real type to complex type, the imag part is set to 0 for returned value. For example,\r\n```\r\n# python\r\n>>> import tensorflow as tf\r\n>>> v = tf.cast(tf.constant(1j), tf.float32)\r\n>>> tf.Session().run(v)\r\n0.0\r\n>>> \r\n```\r\n\r\nThis seems to match numpy behavior with reasoning mentioned in the comment of the source code:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/982549ea3423df4270ff154e5c764beb43d472da/tensorflow/core/kernels/cast_op.h#L75-L94\r\n\r\nI have updated the PR with added docs to mentioned the processing of complex data types. Please take a look.", "The failure test is the target:\r\n```\r\n//tensorflow/core:common_runtime_ring_reducer_test\r\n```\r\n\r\nI think this might be unrelated as I have seen the same failures on several other tests.", "Yes, that's known and unrelated. "]}, {"number": 18560, "title": "ate", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 18559, "title": "Failed to use tf.ones with brackets", "body": "version: 1.4\r\n\r\nfor example:\r\n```\r\na = tf.constant(2, dtype=tf.int32)\r\ntf.ones(shape=(a))\r\n# ValueError: Shape must be rank 1 but is rank 0 for 'ones_18' (op: 'Fill') with input shapes: [], [].\r\n```\r\nbut \r\n```\r\na = tf.constant(2, dtype=tf.int32)\r\ntf.ones(shape=[a])\r\n# works well\r\n```\r\n", "comments": ["@jiemojiemo With 1.7.0 the issue is resolved:\r\n```\r\n$ python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'1.7.0'\r\n>>> a = tf.constant(2, dtype=tf.int32)\r\n>>> tf.ones(shape=(a))\r\n<tf.Tensor 'ones:0' shape=(?,) dtype=float32>\r\n>>> \r\n```\r\n\r\nI think you can try update your tensorflow version."]}, {"number": 18558, "title": "Fix tf.argmax warnings on dimension argument by using axis instead", "body": "This PR is to fix tf.argmax warnings on dimension parameter by using axis instead.\r\n\r\nAccording to [tf.argmax](https://www.tensorflow.org/api_docs/python/tf/argmax), dimension argument was deprecated, it will be removed in a future version and it generates a warning.\r\nInstructions for updating: Use the axis argument instead", "comments": ["The test failures appear unrelated."]}, {"number": 18557, "title": "'Missing required flag: input_file' when using TOCO with SavedModel", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: toco --savedmodel_directory=/Models/Final/1523530083 --output_file=move.tflite\r\n\r\n### Describe the problem\r\nI have a SavedModel trained and I am trying to use TOCO to convert it to tflite format. When I use the above command, given as an example in the docs [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#savedmodel) I get prompted for the input_format. Specifying this as TENSORFLOW_GRAPHDEF gives a new error for output_format. Specifying this as TFLITE now prompts for required parameter input_file. As this is a SavedModel and not a GraphDef, I can't provide the input_file and in fact, shouldn't have to as savedmodel_directory has already been provided. \r\n\r\nThe model directory 1523530083 contains saved_model.pb and a variables folder. There are no assets. ", "comments": ["The issue is likely that the version of TensorFlow you are using does not have SavedModel support. Try and build with the latest version of TensorFlow.\r\n\r\nInstructions are available here: https://www.tensorflow.org/install/install_sources.", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @gargn: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I've updated to 1.8 and now rather than throwing an exception you get:\r\n\r\n_TOCO from pip install is currently not working on command line.\r\nPlease use the python TOCO API or use_\r\n\r\nClosing out issue. ", "There was some issue in version 1.8 and it did not install TOCO. After updating to version 1.10 it installed TOCO and also following error got resolved.\r\nMissing required flag: input_file", "after updating to tensorflow from 17 to 1.10 (!pip install --upgrade \"tensorflow==1.10.*\") its resolved my issue \r\n"]}]