[{"number": 22207, "title": "Example in Keras guide does not work when training with tf.data datasets", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:na\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.11.0-dev20180907\r\n- **Python version**:v3.6.3:2c5fed8\r\n- **Bazel version (if compiling from source)**:na\r\n- **GCC/Compiler version (if compiling from source)**:na\r\n- **CUDA/cuDNN version**:na\r\n- **GPU model and memory**:na\r\n- **Exact command to reproduce**:na\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nWhen going through the tutorial in https://www.tensorflow.org/guide/keras, training with numpy arrays works, but training with tf.data datasets only works if you first perform training with numpy arrays. I expected that you could train with tf.data datasets without first going through numpy arrays. This issue was first identified in #20827 but it was closed as solved at the moment, for some nightly build over tensorflow v1.9.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe code below works if one uncomments the line `#model.fit(data, labels, epochs=10, batch_size=32)`. If it runs as it is, it will give an error, showed below.\r\n\r\nCode:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nmodel = keras.Sequential()\r\n# Adds a densely-connected layer with 64 units to the model:\r\nmodel.add(keras.layers.Dense(64, activation='relu'))\r\n# Add another:\r\nmodel.add(keras.layers.Dense(64, activation='relu'))\r\n# Add a softmax layer with 10 output units:\r\nmodel.add(keras.layers.Dense(10, activation='softmax'))\r\n\r\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.001),\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\n# Configure a model for categorical classification.\r\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\r\n              loss=keras.losses.categorical_crossentropy,\r\n              metrics=[keras.metrics.categorical_accuracy])\r\n\r\nimport numpy as np\r\n\r\ndata = np.random.random((1000, 32))\r\nlabels = np.random.random((1000, 10))\r\n\r\n#model.fit(data, labels, epochs=10, batch_size=32)\r\n\r\n# Instantiates a toy dataset instance:\r\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\r\ndataset = dataset.batch(32)\r\ndataset = dataset.repeat()\r\n\r\n# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\r\nmodel.fit(dataset, epochs=10, steps_per_epoch=30)\r\n```\r\n\r\nError:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"...\\tensorflow\\python\\framework\\op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"...\\tensorflow\\python\\framework\\ops.py\", line 1145, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"...\\tensorflow\\python\\ops\\variables.py\", line 799, in _TensorConversionFunction\r\n    \"of type '%s'\" % (dtype.name, v.dtype.name))\r\nValueError: Incompatible type conversion requested to type 'float64' for variable of type 'float32'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"...\\temp.py\", line 34, in <module>\r\n    model.fit(dataset, epochs=10, steps_per_epoch=30)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\training.py\", line 1440, in fit\r\n    validation_split=validation_split)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\training.py\", line 944, in _standardize_user_data\r\n    class_weight, batch_size)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\training.py\", line 984, in _standardize_weights\r\n    self._set_inputs(x)\r\n  File \"...\\tensorflow\\python\\training\\checkpointable\\base.py\", line 426, in _method_wrapper\r\n    method(self, *args, **kwargs)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\training.py\", line 1198, in _set_inputs\r\n    self._symbolic_set_inputs(inputs, training=training)\r\n  File \"...\\tensorflow\\python\\training\\checkpointable\\base.py\", line 426, in _method_wrapper\r\n    method(self, *args, **kwargs)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\training.py\", line 1282, in _symbolic_set_inputs\r\n    outputs = self.call(dummy_input_values, training=training)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\sequential.py\", line 232, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"...\\tensorflow\\python\\keras\\engine\\sequential.py\", line 250, in _call_and_compute_mask\r\n    x = layer.call(x, **kwargs)\r\n  File \"...\\tensorflow\\python\\keras\\layers\\core.py\", line 947, in call\r\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\r\n  File \"...\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4856, in mat_mul\r\n    name=name)\r\n  File \"...\\tensorflow\\python\\framework\\op_def_library.py\", line 546, in _apply_op_helper\r\n    inferred_from[input_arg.type_attr]))\r\nTypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.\r\n\r\nProcess finished with exit code 1\r\n```\r\n", "comments": ["I can confirm, with yesterday's nightly\r\n\r\nTensorFlow v1.11.0-dev20180910 \r\n\r\nI also now get \r\n\r\n`Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.`\r\n\r\nagain.", "```\r\ndata = np.random.random((1000, 32)).astype(np.float32)\r\nlabels = np.random.random((1000, 10)).astype(np.float32)\r\n```", "@zakizhou thank you for the code lines. This is indeed a workaround, but the issue is that either you shouldn't need to do that (IMO the conversion could be automatic), or, if you do need, this should be stated in the Keras guide (preferably with some explanation...).\r\n\r\nExactly the same issue has been closed as solved once (https://github.com/tensorflow/tensorflow/issues/20827), so I suppose this has been fixed somehow at that time.", "@pavithrasv is this still an issue?", "I am still seeing this issue. \r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 7\r\nTensorFlow installed from (source or binary):binary\r\nTensorFlow version (use command below):1.12.0-rc2-3-ga6d8ffae09\r\nPython version:v3.6.7\r\nBazel version (if compiling from source):na\r\nGCC/Compiler version (if compiling from source):na\r\nCUDA/cuDNN version:na\r\nGPU model and memory:na\r\nExact command to reproduce:na", "pinging, I am seeing this issue on 1.12.0", "the solution is in #20827, you have to specify the input_shape for the first dense layer\r\n`model.add(keras.layers.Dense(64, activation='relu', input_shape=(32,)))`\r\n\r\nhttps://www.tensorflow.org/guide/keras needs to be updated", "@Efaq This was resolved already. I cannot reproduce the issue when I use `tf-nightly`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/137af30f9d6c70f254280023346cb0a7/tf_22207_keras_datasets.ipynb). Thanks!\r\n\r\nI am closing this issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!"]}, {"number": 22206, "title": "[tflite] make build_rpi_lib.sh work again", "body": "fix undefined referneces introduced by 1a25a8e6. Functions\r\ndefined and implemented in `neon_tensor_utils.h`, but not\r\nincluded anywhere so that there are undefined references.\r\n\r\nerror messages:\r\n```\r\n....\r\nlayer_norm_lstm.cc:(.text+0x20f6): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2104): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2110): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2138): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2146): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2152): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x216c): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x217c): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2188): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x21ea): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x21fa): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2206): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x229e): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x22ac): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x22b8): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x22d2): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x22e0): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x22ec): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2306): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2316): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2322): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x23f4): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2402): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x240e): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2428): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2438): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2444): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\n/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a(layer_norm_lstm.o): In function `tflite::ops::custom::layer_norm_lstm::LayerNormLstmStep(float const*, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, signed char const*, float, float const*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, signed char const*, float, float const*, float, float, TfLiteFusedActivation const&, int, int, int, int, float*, float*, float*, float*, float*, float*, float*, signed char*, signed char*, signed char*, float*, float*, float*)':\r\nlayer_norm_lstm.cc:(.text+0x2f06): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2f14): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2f20): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2f40): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2f4e): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2f5a): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2f76): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2f84): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2f90): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x2ff0): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x2ffe): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x300a): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x326a): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x3278): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x3284): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x32c0): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x32ce): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x32da): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x32f6): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x3304): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x3310): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x337c): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x338a): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x3396): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x33b6): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x33c4): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x33d0): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x35d6): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x35e4): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x35f0): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x3610): undefined reference to `tflite::tensor_utils::MeanStddevNormalization(float const*, float*, int, int, float)'\r\nlayer_norm_lstm.cc:(.text+0x361e): undefined reference to `tflite::tensor_utils::VectorBatchVectorCwiseProduct(float const*, int, float const*, int, float*)'\r\nlayer_norm_lstm.cc:(.text+0x362a): undefined reference to `tflite::tensor_utils::VectorBatchVectorAdd(float const*, int, int, float*)'\r\ncollect2: error: ld returned 1 exit status\r\ntensorflow/contrib/lite/tools/make/Makefile:191: recipe for target '/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/bin/minimal' failed\r\nmake: *** [/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/bin/minimal] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n\r\n```", "comments": ["Well, actually, there was no problem. It's my own fault. I didn't clean up old dependency."]}, {"number": 22205, "title": "Python Tensorflow1.10.0 Pooling Invalid", "body": "  W1 = parameters[\"W1\"]\r\n    W2 = parameters[\"W2\"]\r\n\r\n    # \u6784\u5efa\u5377\u79ef\r\n    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\r\n    A1 = tf.nn.relu(Z1)\r\n    # \u6c60\u5316\r\n    P1 = tf.nn.max_pool(A1, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding='VALID')  # \u60ca\u4eba\u53d1\u73b0,padding\u5bf9\u6c60\u5316\u6ca1\u6709\u8d77\u5230\u4efb\u4f55\u7684\u4f5c\u7528\r\n\r\n    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\r\n    A2 = tf.nn.relu(Z2)\r\n    P2 = tf.nn.max_pool(A2, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding='SAME')\r\n\r\n\r\n##################\r\ntf.nn.max_pool() padding specify SAME is valid,I think this is a very important  problem", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Could you provide a concrete example (i.e. creating explicit tensors) where you think the shape is not correct?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 22204, "title": "Java API support from Gradle", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nOnly specific dependency  in vanila Gradle**W** project from maven central:\r\n```\r\nplugins {\r\n    id 'java'\r\n}\r\n\r\ngroup 'tf-test'\r\nversion '1.0-SNAPSHOT'\r\n\r\nsourceCompatibility = 1.8\r\n\r\nrepositories {\r\n    mavenCentral()\r\n}\r\n\r\ndependencies {\r\n    compile group: 'org.tensorflow', name: 'tensorflow', version: '1.10.1'\r\n    testCompile group: 'junit', name: 'junit', version: '4.12'\r\n}\r\n```\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nDarwin Kernel Version 17.7.0\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.10.1\r\n\r\n- **Python version**:\r\nPython 3.6.5 :: Anaconda, Inc.\r\n\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n- **Exact command to reproduce**:\r\n```\r\n./gradlew clean build\r\n```\r\n\r\nYou can collect some of this information using our environment capture script:\r\nN/A\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nArtifact described in the documentation not available and/or not retrievable using Gradle wrapper v4.8.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nCould not resolve all files for configuration ':compileClasspath'.\r\n> Could not find org.tensorflow:tensorflow:1.10.1.\r\n  Searched in the following locations:\r\n    - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow/1.10.1/tensorflow-1.10.1.pom\r\n    - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow/1.10.1/tensorflow-1.10.1.jar\r\n  Required by:\r\n      project :\r\n\r\n* Try:\r\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.\r\n```\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Can you clarify what you are trying to do?", "Simple:\nSimple *gradle script unable to retrieve tensorflow Java API* from maven\ncentral and/or jcenter.\nPlease see the gradle script in the previous post to reproduce the issue.\n\nThanks!\n\nOn Sat, Sep 15, 2018 at 7:43 AM, Karmel Allison <notifications@github.com>\nwrote:\n\n> I apologize, but I am having a hard time understanding what the problem\n> is, where the problem is, and what version it affects. Can you clarify what\n> you are trying to do?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22204#issuecomment-421491005>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADiccjqBFowLSt6PqO-zFKHX6SIAi03eks5ubCMAgaJpZM4Wib0K>\n> .\n>\n", "@asimshankar @andrehentz -- this involves the Java API + Gradle; can you take a look or reassign to the appropriate contact?", "Sorry for the delayed response.\r\nOops, seems like a documentation error since we didn't publish 1.10.1 for Java, but did publish 1.10.0.\r\nThat said, we've since release 1.11.0 and that should be working.\r\n\r\nSee: https://search.maven.org/artifact/org.tensorflow/tensorflow/1.11.0/jar\r\n\r\nHope that helps.\r\nThanks!\r\n(Apologies for the incorrect documentation)"]}, {"number": 22203, "title": "Replace global starter flags with call-specific flags", "body": "The earlier version of convenient default flags mistakenly applied --build_tests_only to normal \"bazel build\" calls, which broke pip.sh (and probably invalidated some other things). This resolves that problem by setting flags specific to \"test\" and \"build\" commands.\r\n\r\nPiperOrigin-RevId: 212355193", "comments": []}, {"number": 22202, "title": "Java version for GPU at Maven Central is built for CUDA 0.9 (==a bit too old)", "body": "I have **libcublas.so.9.2** installed.\r\n\r\nPlease, update. And make it somewhat usable if possible.\r\nMany thanks.\r\n\r\npom.xml:\r\n```\r\n    <dependency>\r\n        <groupId>org.tensorflow</groupId>\r\n        <artifactId>libtensorflow</artifactId>\r\n        <version>1.10.0</version>\r\n    </dependency>\r\n    <dependency>\r\n         <groupId>org.tensorflow</groupId>\r\n         <artifactId>libtensorflow_jni_gpu</artifactId>\r\n         <version>1.10.0</version>\r\n    </dependency>\r\n```\r\n```\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1536621740227-0/libtensorflow_jni.so: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)\r\n\tat java.lang.Runtime.load0(Runtime.java:809)\r\n\tat java.lang.System.load(System.java:1086)\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:101)\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:66)\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:70)\r\n\tat org.tensorflow.Graph.<clinit>(Graph.java:337)\r\n\tat TensorflowExamplePlugin.main(TensorflowExamplePlugin.java:25)\r\n\tat TensorflowExamplePlugin.run(TensorflowExamplePlugin.java:17)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "You're welcome.\r\n> Have I written custom code\r\n\r\nNo, testing HelloTF.java from [here](https://www.tensorflow.org/install/install_java). Would like to try Java version of TF for GPU.\r\n> OS Platform and Distribution\r\n\r\nKubuntu 16.04 64x\r\n> TensorFlow installed from\r\n\r\nhttps://mvnrepository.com/artifact/org.tensorflow/libtensorflow_jni_gpu ?\r\n> TensorFlow version\r\n\r\n1.10.0\r\n> Bazel version\r\n\r\nN/A\r\n> CUDA/cuDNN version\r\n\r\n0.9.2\r\n> GPU model and memory\r\n\r\nGeForce GTX 750 Ti\r\n\r\n> Exact command to reproduce\r\n\r\nN/A\r\n> Mobile device\r\n\r\nN/A\r\n\r\nThanks", "Alright, I installed CUDA 9.0 and set LD_LIBRARY_PATH in the Eclipse configuration for that particular project. This is a simpler workaround than building from source.\r\nThanks"]}, {"number": 22201, "title": "Fall 2018 Symposium Performance Talk Notes", "body": "There were additional topics discussed that could not be turned into coherent notes after the fact.\r\n\r\n## Action items\r\n   * TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions. [#22356](https://github.com/tensorflow/tensorflow/issues/22356)\r\n   * Make the NVIDIA Library to TF Version matrix more visible and consider better error messages. [#22357](https://github.com/tensorflow/tensorflow/issues/22357)\r\n   * Document tips and methods to use for large batch scaling with TensorFlow.  Possibly mention where this is proven and unproven to work.  This would include adding optimizers or wrapper to simplify usage.  Researchers are large labs want to scale but do not have the knowledge to do it quickly. [#22358](https://github.com/tensorflow/tensorflow/issues/22358)\r\n\r\n## General Questions and discussion results\r\n\r\n   * Should TensorFlow default builds move forward more aggressively with newer versions of CUDA/cuDNN?\r\n      * Internally Google moves slowly to new versions of CUDA as the verification process is long and often includes multiple patches with NVIDIA until all edge cases are covered.  The bar is extremely high for obvious reasons.\r\n      * Group thought was it doesn\u2019t matter. Situation would be improved with better error messages indicating what version is needed and making the matrix showing what NVIDIA libs are needed for each TensorFlow version.\r\n   * Provide more models with good performance and accuracy in github.com/tensorflow/models.  Too many different versions and unsure which one to use.  Example:  There are 3+ ResNet models.\r\n      * Contact tfboyd@ or comment in this thread if there is a specific model of interest and why.  MLPerf may improve this situation.\r\n   * Auto regressive models with long dependency chains are hard to optimize by doing fusion by hand.\r\n      * Consider trying XLA and providing feedback. An objective of XLA is to reduce the need for custom fusion.\r\n   * [Ask] Distributing the input pipeline across servers.  Some work has been done and rumored to have occured in production but not trivial to setup.  Consider an RFP and/or reach out to the tf.data team.\r\n   * TensorCores are only used if you are using tf.16.  You can do Pseudo FP16 with an envar that should be in TF 1.11 from NVIDIA as an experimental feature.  You still need to do loss scaling.\r\n\r\n## Debugging and performance investigations\r\n   * Hard to get timelines and profiler results.\r\n      * New guide is on the way, not positive this will make it as easy as desired.\r\n   * [Ask] Provide an interface to autotuning parameters such as intra and inter thread pools.\r\n      * In hindsight, more information is needed to make this actionable.  Please add info to the comments.  \r\n\r\n## Distributed compute (multi-gpu and multi-node)\r\n   * All reduce API for multi-node and support MPI.\r\n      * MPI would be useful for supercomputers where you need to use their MPI library to get good communication.\r\n      * NCCL currently used by MirroredStrategy but only for multi-GPU.  TensorFlow\u2019s own `ops` are used for multi-node all-reduce.\r\n\r\n   * Document on how the distribution strategies is setup with the goal of showing how others can add their own solution and collective ops.  The API is the best place right now to figure this out.\r\n   * [AI] TensorFlow team to create a block diagram and then go deeper.  Goal is to help people who want to contribute plugins or extensions.\r\n   * Having a hard time with MPI.  People are using a newer versions of MPI\r\n   * How do we plan to support fault tolerance? Will it allow dynamic addition and removal of machines to the collective. E.g. preemption but keep training with a smaller pool. Also increasing machines & batch size as training progresses. Need to adjust the learning rate, so maybe get a callback, especially when you are going to lose or have just lost a machine. Response to call back is starting with revised set of machines an new learning rate.\r\n   *[AI] Document strategies for large batch training.  LARS looking to automatic learning rate, warmup rate and stuff.  \r\n\r\n## Model parallelism and Data parallelism\r\n   * Model parallelism is currently manual.  Work to automate it is on going and it can be phrased as an RL problem.  \r\n   * Data parallelism supported via MirroredStrategy discussed today\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. ", "I would be interested if @tfboyd could share more information on this particular event; I cannot find any information online apart from this issue."]}, {"number": 22200, "title": "Image retraining tutorial (label_image.py issue)", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:pip\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**:-\r\n- **GCC/Compiler version (if compiling from source)**:-\r\n- **CUDA/cuDNN version**:-\r\n- **GPU model and memory**:no dedicated GPU\r\n- **Exact command to reproduce**: python label_images.py --graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt --input_layer=Placeholder --output_layer=final_result --input_height=128 --input_width=128 --image=flower.png\r\n\r\n### Describe the problem\r\n\r\n\r\nRunning the tutorial script label_image.py results in crashing (Container localhost does not exist)\r\nI used mobilenet_v2 instead of inception_v3 during retraining\r\n\r\n\r\n### Source code / log\r\nCaused by op \r\n\r\n'import/module_apply_default/MobilenetV2/expanded_conv_13/depthwise/depthwise/ReadVariableOp', defined at:\r\n  File \"label_images.py\", line 118, in <module>\r\n    graph = load_graph(model_file)\r\n  File \"label_images.py\", line 33, in load_graph\r\n    tf.import_graph_def(graph_def)\r\n  File \"/home/john/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 316, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/john/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 554, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/home/john/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/home/john/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\r\nNotFoundError (see above for traceback): Error while reading resource variable module/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/module/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights)\r\n\t [[Node: import/module_apply_default/MobilenetV2/expanded_conv_13/depthwise/depthwise/ReadVariableOp = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](import/module/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights)]]\r\n\r\n", "comments": ["@jazztf this doesn't look like a label_image bug. With master branch, I can retrain MobileNet V2 and validate results with `label_image` without problem. You may want to check your Python, TensorFlow, and other setting first.\r\n\r\n@harshini-gadige This is not tflite related.", "@freedomtan\r\nThank you for your answer..\r\nI did some research and it may be my tensorflow version(1.5.0) causing the problem. My CPU isn't compatible with AVX instructions set so I'll have to install the newest tensorflow release on another machine and see if the error shows up again", "I'm gonna close this for now, please reopen if it turns out to be a TF bug. Thanks.", "@freedomtan Can you tell me how to retrain mobilenetv2 with tensorflow ? very thanks!", "@imxboards what do you mean by \"retain mobilenetv2\"? If you follow the [retrain tutorial](https://www.tensorflow.org/hub/tutorials/image_retraining), should be quite easy. If you want to retrain with SLIM, read the [doc](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet) for MobileNet V2."]}, {"number": 22199, "title": "Use random_seed for the contrib/tensor_forest.  process input ops", "body": "Right now the process_input ops is not using the random seed passed in.\r\n\r\n", "comments": []}, {"number": 22198, "title": "third_party: update libjpeg-turbo to 2.0.0", "body": "libjpeg-turbo-2.0.0 fixes CVE-2018-1152 and CVE-2018-11813\r\n\r\nThe build and source tree has been rearranged, the simd files are now in\r\nsubdirs.\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 22197, "title": "KeyError u'ImageProjectiveTransform' when loading Tensorflow model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: using pip\r\n- **TensorFlow version (use command below)**:1.10.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: Tesla K80 on Google Colab\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\n\r\nI trained a ConvNet on MNIST, and saved the model using simple_save.\r\n\r\nWhen loading the saved model, using \r\n`tf.saved_model.loader.load(sess,[tag_constants.SERVING],'/save_folder')`\r\n\r\nI get this error `KeyError: u'ImageProjectiveTransform'`\r\n\r\nCode for saving my ConvNet model\r\n\r\n```\r\ngraph = tf.get_default_graph()\r\n\r\nfrom tensorflow.python.saved_model import tag_constants\r\nwith graph.as_default():\r\n  input_dict = {\"x\":x,\"y\":y,\"keep_prob\":keep_prob,\"aug_img\":aug_img}\r\n  output_dict = {\"logits\":fc3}\r\n  tf.saved_model.simple_save(sess,'/saved_model/',input_dict,output_dict)\r\n```\r\n\r\nI used tf.contrib.image.rotate as a augmentation technique, but didn't add that to any of the dicts while saving the model.\r\n\r\n### Source code / logs\r\n\r\nThis is the code for the model and the training part\r\n```\r\nx = tf.placeholder(tf.float32,shape=[None,28,28])\r\ny = tf.placeholder(tf.int64,shape=[None])\r\nkeep_prob = tf.placeholder(tf.float32,shape=())\r\nlr = tf.placeholder(tf.float32,shape=())\r\n\r\naug_img = tf.placeholder(tf.float32,shape=[28,28])\r\n\r\nimg_rotate = tf.contrib.image.rotate(aug_img,-0.5+np.random.random(),interpolation='BILINEAR')\r\nimg_affine = tf.contrib.image.transform(aug_img,[np.random.random() for i in xrange(8)])\r\n\r\nwith tf.device('/gpu:0'):\r\n  conv1 = tf.layers.conv2d(tf.reshape(x,shape=[-1,28,28,1]),filters=64,kernel_size=3,strides=1,padding='same',activation=tf.nn.leaky_relu)\r\n  conv2 = tf.layers.conv2d(conv1,filters=64,kernel_size=3,strides=2,padding='same',activation=tf.nn.leaky_relu) #NX14X14\r\n  conv3 = tf.layers.conv2d(conv2,filters=128,kernel_size=3,strides=1,padding='same',activation=tf.nn.leaky_relu)\r\n  conv4 = tf.layers.conv2d(conv3,filters=64,kernel_size=1,strides=1,padding='same',activation=tf.nn.leaky_relu)\r\n  conv5 = tf.layers.conv2d(conv4,filters=128,kernel_size=3,strides=2,padding='same',activation=tf.nn.leaky_relu) #NX7X7\r\n  conv6 = tf.layers.conv2d(conv5,filters=64,kernel_size=1,strides=1,padding='same',activation=tf.nn.leaky_relu)\r\n  conv7 = tf.layers.conv2d(conv6,filters=128,kernel_size=3,strides=2,padding='same',activation=tf.nn.leaky_relu) #NX3X3\r\n  conv8 = tf.layers.conv2d(conv7,filters=128,kernel_size=3,strides=1,padding='same',activation=tf.nn.leaky_relu) #NX1X1\r\n  flat = tf.contrib.layers.flatten(conv7)\r\n  fc1 = tf.layers.dense(flat,units=256,activation=tf.nn.leaky_relu)\r\n  do1 = tf.nn.dropout(fc1,keep_prob)\r\n  fc2 = tf.layers.dense(do1,units=256,activation=tf.nn.leaky_relu)\r\n  do2 = tf.nn.dropout(fc2,keep_prob)\r\n  fc3 = tf.layers.dense(do2,units=10)\r\n  \r\n  cost = loss(fc3,y)\r\n  opt = tf.train.AdamOptimizer(learning_rate=0.0001)\r\n  opt_op = opt.minimize(cost)\r\n  \r\n  top1_acc = accuracy(fc3,y)\r\n\r\nepochs = 25\r\nne=0\r\nbatchsize = 50\r\nnumiter = 400\r\nwhile(ne<epochs):\r\n    print 'Epoch:: ',ne+1,'-->'\r\n    stime = time.time()\r\n    if ne != 0:\r\n       np.random.shuffle(index)\r\n       images = images[index]\r\n       labels = labels[index]\r\n    for niter in xrange(numiter):\r\n      offset = niter*batch_size\r\n      x_iter, y_iter = np.array(images[offset:offset+batch_size,:,:]), np.array(labels[offset:offset+batch_size])\r\n      for n in xrange(batch_size):\r\n        augs = np.random.choice([True,False])\r\n        if augs==True:\r\n          x_iter[n] = sess.run(img_rotate,feed_dict={aug_img:x_iter[n]})\r\n      feed_trdict={x:x_iter,y:y_iter,keep_prob:0.6}\r\n      sess.run(opt_op,feed_dict=feed_trdict)\r\n    ne+=1\r\n\r\n```", "comments": ["@asimshankar  Any update on this?", "@sadimanna : Can you provide a [minimal, complete, verifiable example](https://stackoverflow.com/help/mcve)?\r\n\r\nWithout a full reproduction, some questions that come to mind:\r\n- Are you loading in the same Python process you saved the model in, or a separate on?\r\n- If the latter, can you share the fill program for loading the model?\r\n- Could you try adding an `import tensorflow.contrib.image` before calling `saved_model.loader.load`?\r\n\r\nWhat I suspect is happening here is that since you're using `tf.contrib.image`, it defines some extension operations in a shared library ([`image_ops.so`](https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/contrib/image/python/ops/image_ops.py#L34)). So you need to load that library explicitly before loading the model. Importing `tensorflow.contrib.image` does that, alternatively you can explicitly load the library using `tf.load_op_library`.\r\n\r\nHope that helps.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@asimshankar, what about tensorflow serving? I am using tf.contrib.image.transform and when I serve model I get next message: \r\n\r\n\r\n`\u201cFailed to start server. Error: Unknown: 1 servable(s) did not become available: {{{name: slider_universal version: 1} due to error: Not found: Op type not registered \u2018ImageProjectiveTransformV2\u2019 in binary running on 254345a5d9f1. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) tf.contrib.resampler should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.}, }\u201d `\r\n\r\nI tried it with docker. After I built with bazel I have also got this message", "I'm facing a similar issue.\r\n\r\nI found a possible solution here:\r\nhttps://stackoverflow.com/questions/53284674/tensorflow-serving-with-contrib-operations", "I too am getting the same error using Tensorflow version 1.12.0  In fact, I can't export and read in the same meta file at all..", "I also had a similar issue where I trained a model and saved it using Model Saver module of TF.\r\nBut when I tried to load the module, I got the following error.\r\n\r\n`KeyError: u'StatelessRandomUniform' `\r\n\r\nI was using a particular Module (`tf.contrib.stateless.stateless_random_uniform`) when training the model.\r\n \r\nSo after importing tensorflow in my inference script where I loaded the trained model, I also imported the module like below\r\n\r\n`from tensorflow.contrib import stateless`\r\n\r\nIt Worked!\r\n\r\nSimilarly, for this problem, you could try the following import as stated below.\r\n\r\n`from tensorflow.contrib import image`"]}, {"number": 22196, "title": "Revert changes that removed absl headers from some files", "body": "We applied the original rollback before realizing that many more files reference Absl headers. Those headers have been added to TensorFlow's pip package. See https://github.com/tensorflow/tensorflow/pull/22159.", "comments": []}, {"number": 22195, "title": "Replace blanket-exclusion of TF Lite tests with --build_tests_only", "body": "PiperOrigin-RevId: 212065169", "comments": []}, {"number": 22194, "title": "Apache Ignite File System", "body": "This is a proposal to support [Apache Ignite File System](https://ignite.apache.org/features/igfs.html) in TensorFlow.\r\n\r\n[Apache Ignite](https://ignite.apache.org/) is a memory-centric distributed database, caching, and processing platform for transactional, analytical, and streaming workloads, delivering in-memory speeds at petabyte scale. This proposal is a part of a more global initiative to implement so called \"TensorFlow on Apache Ignite\" ([IGNITE-8335](https://issues.apache.org/jira/browse/IGNITE-8335), [Design Document](https://docs.google.com/document/d/1jROIahK1rc7bSgOvhJhfpMqIGvht_IE8zn5NAt6x8ks)).\r\n\r\nThe integration is based on [custom filesystem plugin](https://www.tensorflow.org/extend/add_filesys) from TensorFlow side and IGFS Native API from Apache Ignite side. More information about this module you can find in [README.md](https://github.com/dmitrievanthony/tensorflow/blob/apache-ignite-igfs/tensorflow/contrib/igfs/README.md).\r\n\r\nTests have also been added. They use docker to hide configuration complexity, so that the implemented functionality can be tested quite simply by manual run.\r\n\r\n**Be aware that this pull request is based on previous #22210 that is not merged yet (significant part of the code you see here will be merged in #22210).** ", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Thanks @dmitrievanthony. Could you check the cla for all contributors who have commits in this PR?", "Hi, @yifeif. Thank you for attention. Did I understand correctly from the message above that all authors have signed CLA and the problem is only that the committer and the author of one commit are not the same? If so, I asked @artemmalykh to write here that he's ok with this PR.", "I'm totally OK with PR!", "Thanks @dmitrievanthony and @artemmalykh. Looks good now.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@yifeif, I just rebased this branch, so commits haven't been changed. I think CLA check should be fine. I still waiting #22210 to be merged so I'll make one more rebase when it will be merged and ping you again.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Hi, @mrry, @martinwicke, @yifeif.\r\n\r\nAfter merge of #22210 I rebased and updated this pull request, so now it's ready for review. It's quite big, but less that Ignite Dataset. \r\n\r\nDerek, I'll be grateful if you have a look and start reviewing. Please let me know if changes required.\r\n\r\nWould be great if someone starts tests and clicks `cla:yes` (cla checker is too suspicious in case of rebases). ", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Hi, @mrry. Any updates?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Hi, @mrry. Thanks for review. I updated code in accordance with all your comments, please have a look.\r\n\r\nPS: Behavior of CLA checker is a bit weird, I understand the initial problem (commit with @artemmalykh mentioned as author), but why it fails on new commits is unclear to me. ", "Hi @mrry. Any updates?", "Hi, @mrry, @yifeif. I don't clearly understand current state. Do you have some concerns about this PR or it's ready to be merged?", "Hi @mrry. I merged `ignite` and `igfs` modules together and fixed other remarks. Please have a look.", "Hi @mrry. I've updated the code, please have a look.", "It looks like Sanity failed because of `//tensorflow/core:lib` dependency in `igfs_kernels`. I've removed it, so please rerun tests.", "Thanks @mrry, looks like everything is fixed. Currently only one test fails and it fails in non related to my code part.\r\n\r\nHope the PR will be merged soon :)", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 22193, "title": "AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RaspberryPi stretch\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: https://www.tensorflow.org/install/install_linux\r\n- **TensorFlow version (use command below)**: 0.11.0\r\n- **Python version**: Python 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI was trying to run facenet module on raspberrypi. and in facenet.py I am getting this error.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n[facenet.zip](https://github.com/tensorflow/tensorflow/files/2367106/facenet.zip)\r\n\r\n", "comments": ["You're running a pretty old version of tensorflow; it seems likely that the model in question was simply written for a newer version of tf. Please check the package versions, and if the problem still persists feel free to reopen this issue."]}, {"number": 22192, "title": "Unknown shape on placeholder caused by tf.graph_util.convert_variables_to_constants", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nv1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- **Python version**:\r\nPython 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nPlaceholders with shape `()` gets shape `<unknown>` after `tf.graph_util.convert_variables_to_constants` has been run on a graph def.\r\n\r\nThe expected result is that the shape is kept, as it is for tensors with higher rank.\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    placeholder = tf.placeholder(tf.float32, shape=(), name='placeholder')\r\n    output = tf.identity(placeholder)\r\n\r\n    graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [output.op.name])\r\n    print('Before:', placeholder.shape)\r\n\r\n\r\nwith tf.Graph().as_default() as g, tf.Session() as sess:\r\n    tf.import_graph_def(graph_def, name='')\r\n    placeholder = g.get_tensor_by_name('placeholder:0')\r\n    print('After:', placeholder.shape)\r\n```\r\nOutput\r\n\r\n    Before: ()\r\n    After: <unknown>\r\n", "comments": ["@reedwm related to #21856?", "As per I know Importing an old graphdef will trigger this behavior.", "Yep, this is a duplicate of #21856."]}, {"number": 22191, "title": "toco: error: one of the arguments --graph_def_file --saved_model_dir --keras_model_file is required", "body": "I'm trying to convert my tensorflow model to .tflite following the devguide on the official tensorflowlite site. I got the following error: toco: error: one of the arguments --graph_def_file --saved_model_dir --keras_model_file is required\r\nThanks in advance for your help.\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary (pip install through anaconda)\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Can you provide the command you are running?\r\n\r\nThe documentation for converting a TFLite model is available [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_reference.md). Examples are available here [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md).", "@Elites2017 Can you please provide the command ", "> \r\n> \r\n> @Elites2017 Can you please provide the command\r\n\r\nI used the toco command and the arguments; it gives me the following error now.\r\n\r\nValueError: None is only supported in the 1st dimension. Tensor 'image_tensor:0' has invalid shape '[None, None, None, 3]'.\r\n\r\nAny help is welcome", "The exact command:\r\n\r\ntoco \\\r\n  --input_file=mobilenet_v1_1.0_224/teste/sfrozen_inference_graph.pb \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_file=/tmp/mobilenet_v1_1.0_224.tflite \\\r\n  --input_shape=-1,-1,-1,3 \\\r\n  --input_array=image_tensor \\\r\n  --output_array=detection_boxes,detection_scores,detection_classes,detection_nums \\", "\r\n\r\nNow I got this problem when trying to build the demo app on Android Studio. (Windows 10)\r\n\r\n**\\contrib\\lite\\examples\\android\\BUILD\\android-profile**", "> Now I got this problem when trying to build the demo app on Android Studio. (Windows 10)\r\n> \r\n> **\\contrib\\lite\\examples\\android\\BUILD\\android-profile**\r\n\r\ni am getting the same issue while converting to tflite model\r\ntoco: error: one of the arguments --graph_def_file --saved_model_dir --keras_model_file is required\r\n\r\ncould you please tell me how did you solved it?", "@natansh25 use the graph_summarize tool to know the details about your model and you can use them as parameters to convert it:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md\r\n\r\n[](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md)\r\n\r\n**bazel build tensorflow/tools/graph_transforms:summarize_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=tensorflow_inception_graph.pb**\r\n", "@Elites2017 `None` is only supported in the first dimension. You can set the input shape using the `input_shapes` argument in the command line or in whichever classmethod you are using.\r\n\r\nThe windows 10 issues are being tracked in issue https://github.com/tensorflow/tensorflow/issues/22897.", "Nagging Assignee @gargn: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22190, "title": "metrics=['accuracy'] seems to be calculated differently if one uses tf.data inputs instead of numpy arrays for keras model", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: **YES**\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: **Windows 10**\r\n- **Mobile device**:na\r\n- **TensorFlow installed from (source or binary)**: **binary**\r\n- **TensorFlow version (use command below)**:**1.11.0-dev20180907**\r\n- **Python version**:**3.6.3**\r\n- **Bazel version (if compiling from source)**:na\r\n- **GCC/Compiler version (if compiling from source)**:na\r\n- **CUDA/cuDNN version**:na\r\n- **GPU model and memory**:na\r\n- **Exact command to reproduce**:na\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nGiven the same piece of code for loading mnist data and training a keras model in tensorflow, the metric \"accuracy\" given as argument to keras_model.compile(metrics=[...]) generates very different values (order of 0.10 versus order of 0.90) depending on if you use numpy arrays or tf.data datasets as training inputs. Note that the values of the loss in each case are very close. I suspect that \"accuracy\" is being calculated differently depending on the type of input (numpy or tf.data), or that it is being calculated wrong in one of the cases.\r\nIn particular, as an example, using numpy arrays as input, one can get the pair loss: 0.2086 - acc: 0.9389 in one of the steps, while the same loss in with tf.data gives the pair loss: 0.2086 - acc: 0.1024.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe code below as it is can be run and training with tf.data datasets will be performed. If you comment the block between `#Train with tf.data datasets` and `########################` and uncomment the block between `#Train with numpy arrays` and `########################`, training with numpy arrays as inputs will be performed.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnp.random.seed(1)\r\ntf.set_random_seed(1)\r\nBATCH_SIZE = 32\r\n\r\n#Import mnist dataset as numpy arrays\r\n(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()#Import\r\nx_train = x_train / 255.0 #normalizing\r\ny_train = y_train.astype(dtype='float32')\r\nx_train = x_train.astype(dtype='float32')\r\n\r\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))#Reshaping the 2D picture\r\n\r\n##############################################################################################\r\n#THIS BLOCK CREATES A DATASET FROM THE NUMPY ARRAYS. IT WILL BE USED FOR THE CASE OF TF.DATA DATASET INPUTS\r\ntfdata_dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\ntfdata_dataset_train = tfdata_dataset_train.batch(BATCH_SIZE).repeat()\r\n##############################################################################################\r\n\r\n#Create model\r\nkeras_model = tf.keras.models.Sequential([\r\n    tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n    tf.keras.layers.Dropout(0.2, seed=1),\r\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\n#Compile the model\r\nkeras_model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n                    loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n                    metrics=['accuracy'])\r\n\r\n#Train with numpy arrays\r\n#keras_training_history = keras_model.fit(x_train,\r\n#                y_train,\r\n#                epochs=1\r\n#                )\r\n########################\r\n\r\n#Train with tf.data datasets\r\nkeras_training_history = keras_model.fit(tfdata_dataset_train,\r\n                epochs=1,\r\n                steps_per_epoch=60000//BATCH_SIZE\r\n                )\r\n########################\r\n```\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "@tensorflowbutler Sure, I have just updated it.", "@Efaq \r\nThis is caused by a bug in ```tf.keras.metrics.sparse_categorical_accuracy```.\r\n* Train with Numpy array, the shape of ```y_true``` is ```(num_samples, 1)```. Because ```y_true``` is feed with a placeholder which is generated according the shape of ```y_pred```, see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L580).\r\n* Train with ```tf.data```, the shape of ```y_true``` is ```(num_samples,)```.\r\n\r\n```tf.keras.metrics.sparse_categorical_accuracy``` doesn't handle the latter case correctly, which leads the error output. I have sent #22392 to fix this, wish it can help you. Thanks.", "Sounds great, thank you!", "@Efaq I think it's better to keep this open until #22392 get merged, otherwise, it maybe harder to track the bugs and issues whether fixed or not. Thanks.", "Sure!"]}, {"number": 22189, "title": "Speech recognition ios example not found", "body": "Hi TFTeam,\r\nI want to make an application in iOS which will convert the speech to text. But unfortunately there are no examples for iOS are included in the github where there exist example for android. How could i implement the same feature in iOS platform", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hi Team,\r\n\r\nFor android you guys provided the example for Speech to Text translation. But for iOS there is no such sample code. Could you confirm me whether this framework  has speech to text recognition or not for iOS. If it has please provide me the sample code to achieve Speech to Text in Objective C or Swift\r\n\r\nThanks", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22188, "title": "Fix dynamic rnn comment", "body": "", "comments": ["@yifeif have fixed as you suggested. please help check. "]}, {"number": 22187, "title": "keras.layers.Conv3DTranspose error when reused", "body": "Version 1.10\r\n\r\nfile: tensorflow/python/keras/layers/ convolution.py\r\n\r\nline: 1000\r\n\r\nproblem: \r\n\r\ninput_spec is modified every time the module is called; \r\ninput_spec uses dynamic shape causes error in shape checker when the layer is reused\r\n", "comments": ["solution: delete line 1000, input_spec should only be modified in constructor or build function", "@kor01 Thank you for your suggestion. Would you be interested in submitting a PR?\r\n/cc @fchollet ", "> @kor01 Thank you for your suggestion. Would you be interested in submitting a PR?\r\n> /cc @fchollet\r\n\r\nOK, I'll submit a PR.", "Great. Thank you! Please post here once you do.", "@kor01 Hi, any update on the PR ?", "@harshini-gadige This issue seems to be fixed. Can you update the status?\r\nVersion: r1.10 :\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/python/keras/layers/convolutional.py#L997\r\n\r\nVersion master:\r\nhttps://github.com/tensorflow/tensorflow/blob/7bcbcc1392516a2b2d7a7abae2ccce7091c8dae3/tensorflow/python/keras/layers/convolutional.py#L1070\r\n", "> @harshini-gadige This issue seems to be fixed. Can you update the status?\r\n> Version: r1.10 :\r\n> [tensorflow/tensorflow/python/keras/layers/convolutional.py](https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/python/keras/layers/convolutional.py#L997)\r\n> \r\n> Line 997 in [4dcfddc](/tensorflow/tensorflow/commit/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23)\r\n> \r\n>  self.input_spec = InputSpec(ndim=5, axes={c_axis: inputs_shape[c_axis]}) \r\n> Version master:\r\n> [tensorflow/tensorflow/python/keras/layers/convolutional.py](https://github.com/tensorflow/tensorflow/blob/7bcbcc1392516a2b2d7a7abae2ccce7091c8dae3/tensorflow/python/keras/layers/convolutional.py#L1070)\r\n> \r\n> Line 1070 in [7bcbcc1](/tensorflow/tensorflow/commit/7bcbcc1392516a2b2d7a7abae2ccce7091c8dae3)\r\n> \r\n>  def call(self, inputs):\r\n\r\nSure. Closing the issue."]}, {"number": 22186, "title": "Incorrect .runfiles folder name \u2014 building from source on Windows", "body": "### System information\r\n\r\nHave I written custom code: No\r\nOS Platform and Distribution: Windows 7\r\nTensorFlow installed from: Building from source\r\nTensorFlow version: 1.10.1\r\nBazel version: 0.16.1\r\nCUDA/cuDNN version: 9.0 / 7.2.1\r\nGPU model and memory: nVidia GeForce GTX 660 Ti, 2 GB\r\nExact command to reproduce: `bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package D:\\temp\\tensorflow_pkg`\r\nMobile device: N/A\r\n\r\nPython: 3.6\r\n\r\n### Describe the problem\r\nI'm building from source following these instructions: https://www.tensorflow.org/install/install_sources_windows\r\n\r\nI've completed the step Build pip package with GPU support:\r\n`bazel --output_user_root=D:\\temp\\bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\nI was running out of disk space on system drive, so I specified a different base folder via `--output_user_root=D:\\temp\\bazel`.\r\n\r\nI'm stuck on the next step:\r\n`bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package D:\\temp\\tensorflow_pkg`\r\nThe error reads:\r\n`cp: cannot stat 'bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/tensorflow': No such file or directory`\r\n\r\nUpon inspection, the folder `build_pip_package.runfiles` is called `build_pip_package.exe.runfiles` and contains single file:\r\n![Screenshot of incorrect folder](https://i.imgur.com/x84Nifs.png \"Incorrect folder\")\r\n![Screenshot folder with single file](https://i.imgur.com/sjMe6ZK.png \"Folder contains single file\")\r\n\r\nMy guess is that Bazel created folder based on Windows .exe file name and then could not copy the content.\r\n\r\n### Source code / logs\r\nOutput from `bazel --output_user_root=D:\\temp\\bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`:\r\n```\r\nTarget //tensorflow/tools/pip_package:build_pip_package up-to-date:\r\n  D:/temp/bazel/ir5rkgt6/execroot/org_tensorflow/bazel-out/x64_windows-opt/bin/tensorflow/tools/pip_package/build_pip_package\r\n  D:/temp/bazel/ir5rkgt6/execroot/org_tensorflow/bazel-out/x64_windows-opt/bin/tensorflow/tools/pip_package/build_pip_package.exe\r\nINFO: Elapsed time: 35809,593s, Critical Path: 9300,80s\r\nINFO: 4105 processes: 4105 local.\r\nINFO: Build completed successfully, 4106 total actions\r\nINFO: Build completed successfully, 4106 total actions\r\n```\r\n\r\nOutput from `bazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package D:\\temp\\tensorflow_pkg`:\r\n```\r\nMon Sep 10 12:44:13 KST 2018 : === Preparing sources in dir: /tmp/tmp.cdKFXp2q0W\r\n\r\ncp: cannot stat 'bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/tensorflow': No such file or directory\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated", "@meteorcloudy could you take a look?", "@jaros3 \r\nI believe this is because the `build_pip_package.sh` script failed to recognize your platform as Windows. It shouldn't reach the cp command at all.\r\nSee\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/tools/pip_package/build_pip_package.sh#L67-L72\r\n\r\nWhich bash are you using? I guess the `PLATFORM` env wasn't `msys_nt`? We should fix this `is_windows` function.", "Can you try to modify `is_windows` function to \r\n```\r\nfunction is_windows() {\r\n  # On windows, the shell script is actually running in msys\r\n  if [[ \"${PLATFORM}\" =~ cygwin_nt*|mingw64_nt*|msys_nt* ]]; then\r\n    true\r\n  else\r\n    false\r\n  fi\r\n}\r\n```\r\nAnd then rerun?", "Yes, this should do the trick \u2014 my `${PLATFORM}` was `mingw64_nt-6.1`\r\n\r\nI'll report back after build completes", "Cool, I sent a fix for this", "Ah, it's actually fixed in https://github.com/tensorflow/tensorflow/pull/18953, just not included in 1.10", "It now calls Python incorrectly:\r\n```\r\nINFO: Found 1 target...\r\nBuilding: no action\r\n[1 / 2] [-----] BazelWorkspaceStatusAction stable-status.txt\r\nERROR: D:/lib/tensorflow-build/tensorflow/tensorflow/core/BUILD:2344:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 127): bash.exe failed: error executing command\r\n  cd D:/temp/bazel/ir5rkgt6/execroot/org_tensorflow\r\n  SET PATH=D:\\lib\\msys64\\usr\\bin;D:\\lib\\msys64\\bin;D:\\lib\\cuda9.0.176\\libnvvp;D:\\Program Files\\Python36\\Scripts\\;D:\\Program Files\\Python350;C:\\ProgramData\\Oracle\\Java\\javapath;E:\\Program Files\\CMake\\bin;E:\\Program Files\\Git LFS;E:\\Program Files\\Git\\bin;E:\\Program Files\\Skype\\Phone\\;E:\\Program Files\\TortoiseGit\\bin;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Windows\\System32;C:\\Program Files\\dotnet\\;D:\\lib\\torch\\bin;D:\\lib\\cuda9.0.176\\bin;D:\\lib\\cudnn9.0v7.2.1\\bin;D:\\lib\\msys64\\usr\\bin;D:\\lib\\cuda9.0.176\\extras\\CUPTI\\libx64;E:\\Program Files\\CMake\\bin;E:\\Program Files\\Git LFS;E:\\Program Files\\Git\\bin\r\n  D:/lib/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; tensorflow/tools/git/gen_git_source.py --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref \"bazel-out/host/genfiles/tensorflow/core/util/version_info.cc\" --git_tag_override=${GIT_TAG_OVERRIDE:-}\r\n/usr/bin/env: 'python': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 4,544s, Critical Path: 0,44s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "Do you have `python` in your `PATH`?", "Is `D:\\Program Files\\Python350` the correct python directory? Maybe it should be `D:\\Program Files\\Python36`?", "I've corrected the path, but Bazel insists on using old one. Guess I'll make a full rebuild", "You can do a `bazel shutdown` to make Bazel pickup the new `PATH`"]}, {"number": 22185, "title": "\u5f55\u89c6\u9891\u540e\u65e0\u6cd5\u64ad\u653e\uff0c\u663e\u793a\u5927\u5c0f\u4e3a0kb", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 22184, "title": "Keras equivalent of \"class_weight\" in fit method in Tensorflow Estimator", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI want to weight down the imbalanced class documents by implementing Keras \"class_weight\" provided in fit method. Is there any equivalent of it in Tf.estimator?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n", "comments": ["How about preprocessing your label with [tf.feature_column.weighted_categorical_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column) ?", "@midnitekoder Did you try the @facaiy 's  suggestion? Does it solve your issue?\r\n\r\n> How about preprocessing your label with [tf.feature_column.weighted_categorical_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/weighted_categorical_column) ?\r\n\r\n\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22183, "title": "\" error: no member named 'stoi' in namespace 'std' \" when bazel build //tensorflow/contrib/lite/tools/accuracy/ilsvrc:imagenet_accuracy_eval", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\nLinux Ubuntu 14.04.4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nsnapdragon SDM845\r\n- **TensorFlow installed from (source or binary)**:\r\nInstall from binary\r\n- **TensorFlow version (use command below)**: \r\n1.9.0 , CPU only\r\n- **Python version**: \r\nPython 2.7.6\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.4 \r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n**### Describe the problem**\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/accuracy  \r\nbazel build -c opt \\\r\n  --config=android_arm \\\r\n  --config=monolithic \\\r\n  --cxxopt='--std=c++11' \\\r\n  --copt=-D__ANDROID_TYPES_FULL__ \\\r\n  --copt=-DSUPPORT_SELECTIVE_REGISTRATION \\\r\n  //tensorflow/contrib/lite/tools/accuracy/ilsvrc:imagenet_accuracy_eval \r\n\r\nNFO: Analysed target //tensorflow/contrib/lite/tools/accuracy/ilsvrc:imagenet_accuracy_eval (71 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /local/mnt/workspace/ruipan/tf_source/tensorflow/tensorflow/contrib/lite/tools/accuracy/ilsvrc/BUILD:122:1: C++ compilation of rule '//tensorflow/contrib/lite/tools/accuracy/ilsvrc:imagenet_model_evaluator' failed (Exit 1): clang failed: error executing command\r\n  (cd /local/mnt/workspace/ruipan/tmp/cache_bazel/_bazel_ruipan/9f5b27aadc11adc5a986b0783cdd6b20/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=28.0.0 \\\r\n    ANDROID_NDK_API_LEVEL=16 \\\r\n    ANDROID_NDK_HOME=/local/mnt/workspace/ruipan/android/android-ndk-r16b \\\r\n    ANDROID_SDK_API_LEVEL=28 \\\r\n    ANDROID_SDK_HOME=/local/mnt/workspace/ruipan/android/sdk \\\r\n    PATH=/local/mnt/workspace/ruipan/android/android-ndk-r16b:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin:/local/mnt/workspace/ruipan/android/sdk/tools:/local/mnt/workspace/ruipan/android/sdk/platform-tools \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang '-D__ANDROID_API__=16' -isystemexternal/androidndk/ndk/sysroot/usr/include/arm-linux-androideabi -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -fpic -ffunction-sections -funwind-tables -fstack-protector-strong -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -no-canonical-prefixes -fno-integrated-as -target armv7-none-linux-androideabi '-march=armv7-a' '-mfloat-abi=softfp' '-mfpu=vfpv3-d16' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/armeabi-v7a-opt/bin/tensorflow/contrib/lite/tools/accuracy/ilsvrc/_objs/imagenet_model_evaluator/imagenet_model_evaluator.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/tensorflow/contrib/lite/tools/accuracy/ilsvrc/_objs/imagenet_model_evaluator/imagenet_model_evaluator.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' '-DS_IEXEC=S_IXUSR' -iquote . -iquote bazel-out/armeabi-v7a-opt/genfiles -iquote bazel-out/armeabi-v7a-opt/bin -iquote external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/genfiles/external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/bin/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/bin/external/bazel_tools -iquote external/nsync -iquote bazel-out/armeabi-v7a-opt/genfiles/external/nsync -iquote bazel-out/armeabi-v7a-opt/bin/external/nsync -iquote external/protobuf_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive -iquote external/eigen_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/eigen_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/armeabi-v7a-opt/genfiles/external/local_config_sycl -iquote bazel-out/armeabi-v7a-opt/bin/external/local_config_sycl -iquote external/double_conversion -iquote bazel-out/armeabi-v7a-opt/genfiles/external/double_conversion -iquote bazel-out/armeabi-v7a-opt/bin/external/double_conversion -iquote external/fft2d -iquote bazel-out/armeabi-v7a-opt/genfiles/external/fft2d -iquote bazel-out/armeabi-v7a-opt/bin/external/fft2d -iquote external/gemmlowp -iquote bazel-out/armeabi-v7a-opt/genfiles/external/gemmlowp -iquote bazel-out/armeabi-v7a-opt/bin/external/gemmlowp -iquote external/gif_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/gif_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/armeabi-v7a-opt/genfiles/external/jpeg -iquote bazel-out/armeabi-v7a-opt/bin/external/jpeg -iquote external/png_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/png_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/png_archive -iquote external/zlib_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/zlib_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/zlib_archive -iquote external/flatbuffers -iquote bazel-out/armeabi-v7a-opt/genfiles/external/flatbuffers -iquote bazel-out/armeabi-v7a-opt/bin/external/flatbuffers -iquote external/arm_neon_2_x86_sse -iquote bazel-out/armeabi-v7a-opt/genfiles/external/arm_neon_2_x86_sse -iquote bazel-out/armeabi-v7a-opt/bin/external/arm_neon_2_x86_sse -iquote external/androidndk -iquote bazel-out/armeabi-v7a-opt/genfiles/external/androidndk -iquote bazel-out/armeabi-v7a-opt/bin/external/androidndk -iquote external/farmhash_archive -iquote bazel-out/armeabi-v7a-opt/genfiles/external/farmhash_archive -iquote bazel-out/armeabi-v7a-opt/bin/external/farmhash_archive -isystem external/nsync/public -isystem bazel-out/armeabi-v7a-opt/genfiles/external/nsync/public -isystem bazel-out/armeabi-v7a-opt/bin/external/nsync/public -isystem external/protobuf_archive/src -isystem bazel-out/armeabi-v7a-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/armeabi-v7a-opt/bin/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/armeabi-v7a-opt/genfiles/external/eigen_archive -isystem bazel-out/armeabi-v7a-opt/bin/external/eigen_archive -isystem external/double_conversion -isystem bazel-out/armeabi-v7a-opt/genfiles/external/double_conversion -isystem bazel-out/armeabi-v7a-opt/bin/external/double_conversion -isystem external/gif_archive/lib -isystem bazel-out/armeabi-v7a-opt/genfiles/external/gif_archive/lib -isystem bazel-out/armeabi-v7a-opt/bin/external/gif_archive/lib -isystem external/png_archive -isystem bazel-out/armeabi-v7a-opt/genfiles/external/png_archive -isystem bazel-out/armeabi-v7a-opt/bin/external/png_archive -isystem external/zlib_archive -isystem bazel-out/armeabi-v7a-opt/genfiles/external/zlib_archive -isystem bazel-out/armeabi-v7a-opt/bin/external/zlib_archive -isystem tensorflow/contrib/lite/schema -isystem bazel-out/armeabi-v7a-opt/genfiles/tensorflow/contrib/lite/schema -isystem bazel-out/armeabi-v7a-opt/bin/tensorflow/contrib/lite/schema -isystem external/flatbuffers/include -isystem bazel-out/armeabi-v7a-opt/genfiles/external/flatbuffers/include -isystem bazel-out/armeabi-v7a-opt/bin/external/flatbuffers/include -isystem external/farmhash_archive/src -isystem bazel-out/armeabi-v7a-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/armeabi-v7a-opt/bin/external/farmhash_archive/src -D__ANDROID_TYPES_FULL__ -DSUPPORT_SELECTIVE_REGISTRATION '--std=c++11' -DFARMHASH_NO_CXX_STRING '-mfpu=neon' '-mfloat-abi=softfp' '-std=c++11' -O3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '--sysroot=external/androidndk/ndk/platforms/android-16/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/contrib/lite/tools/accuracy/ilsvrc/imagenet_model_evaluator.cc -o bazel-out/armeabi-v7a-opt/bin/tensorflow/contrib/lite/tools/accuracy/ilsvrc/_objs/imagenet_model_evaluator/imagenet_model_evaluator.o)\r\ntensorflow/contrib/lite/tools/accuracy/ilsvrc/imagenet_model_evaluator.cc:240:56: error: no member named 'stoi' in namespace 'std'\r\n                   [](const string& val) { return std::stoi(val) - 1; });\r\n                                                  ~~~~~^\r\n1 error generated.\r\nTarget //tensorflow/contrib/lite/tools/accuracy/ilsvrc:imagenet_accuracy_eval failed to build\r\nINFO: Elapsed time: 18.066s, Critical Path: 2.62s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["@PennySHE : Can you use a newer version of NDK, this should not be an issue with the newer versions of NDK.", "@shashishekhar  _SUPPORTED_ANDROID_NDK_VERSIONS = [10, 11, 12, 13, 14, 15, 16]\r\n\r\nI'm using NDK 16 which is the most stable version right now.", "@PennySHE : Ah! correct the parsing code for NDK support seems incorrect. Please see my comment [here](https://github.com/tensorflow/tensorflow/issues/20192#issuecomment-404971539) for using a higher version of NDK. Sorry for the trouble, we are going to fix this soon.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "You may try this in `.tf_configure.bazelrc`\r\n```bazel\r\nbuild --action_env ANDROID_NDK_HOME=\"/path/to/android-ndk-r17b\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"21\"\r\n```"]}, {"number": 22181, "title": "Add support for SquaredDifference in TFLite", "body": "Issue #21526\r\n\r\nAdds support for SquaredDifference in TFLite", "comments": ["Hi, any reviews for this PR?", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 59 days with no activity and the `awaiting review` label has been applied."]}, {"number": 22180, "title": "Tensorflow java built failure on amazon linux - C++ compilation of rule '@protobuf_archive//:protobuf_lite' failed (Exit 1)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Amazon Linux AMI 2018.03\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:  17a34ab\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**:  0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nFailed building Tensorflow Java library from source in Amazon Linux 2018.03\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n[root@ip-xxx-xx-xx-xx tensorflow-master]# ./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.16.1- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/site-packages\r\n  /usr/lib64/python2.7/dist-packages\r\n  /usr/lib64/python2.7/site-packages\r\n  /usr/local/lib64/python2.7/site-packages\r\n  /usr/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]:\r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]:\r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]:\r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon AWS Platform support? [Y/n]:\r\nAmazon AWS Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]:\r\nApache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]:\r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]:\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with nGraph support? [y/N]:\r\nNo nGraph support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]:\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]:\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\n[root@ip-xxx-xx-xx-xx tensorflow-master]# bazel build --config opt \\\r\n>   //tensorflow/java:tensorflow \\\r\n>   //tensorflow/java:libtensorflow_jni\r\nStarting local Bazel server and connecting to it...\r\nWARNING: /root/tensorflow-master/tensorflow/core/BUILD:2480:1: in includes attribute of cc_library rule //tensorflow/core:framework_internal_headers_lib: '../../external/com_google_absl' resolves to 'external/com_google_absl' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /root/tensorflow-master/tensorflow/tensorflow.bzl:1373:20\r\nWARNING: /root/tensorflow-master/tensorflow/core/BUILD:2565:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/com_google_absl' resolves to 'external/com_google_absl' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /root/tensorflow-master/tensorflow/tensorflow.bzl:1373:20\r\nINFO: Analysed 2 targets (97 packages loaded).\r\nINFO: Found 2 targets...\r\nERROR: /root/.cache/bazel/_bazel_root/510cb3499e6983b92a09020af9102ff3/external/protobuf_archive/BUILD:70:1: C++ compilation of rule '@protobuf_archive//:protobuf_lite' failed (Exit 1)\r\ncc1plus: error: unrecognized command line option '-mno-sha'\r\ncc1plus: error: unrecognized command line option '-mno-sgx'\r\ncc1plus: error: unrecognized command line option '-mno-avx512f'\r\ncc1plus: error: unrecognized command line option '-mno-avx512er'\r\ncc1plus: error: unrecognized command line option '-mno-avx512cd'\r\ncc1plus: error: unrecognized command line option '-mno-avx512pf'\r\ncc1plus: error: unrecognized command line option '-mno-prefetchwt1'\r\ncc1plus: error: unrecognized command line option '-mno-clflushopt'\r\ncc1plus: error: unrecognized command line option '-mno-xsavec'\r\ncc1plus: error: unrecognized command line option '-mno-xsaves'\r\ncc1plus: error: unrecognized command line option '-mno-avx512dq'\r\ncc1plus: error: unrecognized command line option '-mno-avx512bw'\r\ncc1plus: error: unrecognized command line option '-mno-avx512vl'\r\ncc1plus: error: unrecognized command line option '-mno-avx512ifma'\r\ncc1plus: error: unrecognized command line option '-mno-avx512vbmi'\r\ncc1plus: error: unrecognized command line option '-mno-avx5124fmaps'\r\ncc1plus: error: unrecognized command line option '-mno-avx5124vnniw'\r\ncc1plus: error: unrecognized command line option '-mno-clwb'\r\ncc1plus: error: unrecognized command line option '-mno-mwaitx'\r\ncc1plus: error: unrecognized command line option '-mno-clzero'\r\ncc1plus: error: unrecognized command line option '-mno-rdpid'\r\nexternal/protobuf_archive/src/google/protobuf/stubs/structurally_valid.cc:1:0: error: bad value (haswell) for -march= switch\r\n // Protocol Buffers - Google's data interchange format\r\n ^\r\nexternal/protobuf_archive/src/google/protobuf/stubs/structurally_valid.cc:1:0: error: bad value (haswell) for -mtune= switch\r\ncc1plus: warning: unrecognized command line option \"-Wno-writable-strings\" [enabled by default]\r\nINFO: Elapsed time: 22.577s, Critical Path: 0.07s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["I tried with Amazon Linux and was able to build the commit 7d3884bb87dc02c4548f55749f3d6db1b8364ddc,\r\n\r\nThe AMI I use is ami-0ff8a91507f77f867. The bazel was installed from Federa COPR (epel 7): https://docs.bazel.build/versions/master/install-redhat.html\r\n\r\nMaybe you could try again with a fresh EC2 instance and see if the issue still exist?", "@yongtang \r\n\r\nThanks for your response. Is it possible to post your configurations and the exact bazel build command ?", "My `./configure` options are all default (return only). And my bazel command is:\r\n```\r\n bazel build --config opt //tensorflow/java:tensorflow \r\n```", "It must be the `EC2 instance type` then. Can you please inform the instance type you used ?", "The AMI I was using was ami-0ff8a91507f77f867.", "@yongtang \r\n\r\nSorry, did you build it in a docker container or did you started an EC2 instance ? If you were using an EC2 instance, which `EC2 instance type` did you choose (e.g. m5.large, t2.2xlarge)?\r\n\r\nhttps://aws.amazon.com/ec2/instance-types/", "That was t2.xlarge on us-east-1 with AMI ami-0ff8a91507f77f867", "Nagging Assignee @rohan100jain: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi @yongtang \r\n\r\nThanks for your help. This issue is now resolved."]}, {"number": 22179, "title": "TypeError: argmax() got an unexpected keyword argument 'output_type' in tensorflow1.2", "body": "Hello, I encountered TypeError error when I was running the program.\r\n\r\nFile \"/home/kjm/Desktop/inpainting/GatedConvolution/inpaint_ops.py\", line 512, in contextual_attention\r\noffset = tf.argmax(yi, axis=3, output_type=tf.int32)\r\nTypeError: argmax() got an unexpected keyword argument 'output_type'\r\n\r\nI used python3.6+tensorflow1.2.And what should I do to correct this error?\r\n\r\nThank you very much for your help.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I am very sorry that I did not express the basic configuration of the computer clearly.\r\nI downloaded others repository from github, but I made a mistake on my computer. And this statement just called argmax() function.\r\n\r\n-----------------This is the error statement -----------------------\r\noffset = tf.argmax(yi, axis=3, output_type=tf.int32)\r\nTypeError: argmax() got an unexpected keyword argument 'output_type'\r\n-----------------This is the error statement -----------------------\r\n\r\nAnd my platform: Ubuntu16.04LST, CUDA8.0, cudnn5.1, python3.6, tensorflow1.2(I installed Tensor Flow on the official website and downloaded the .whl file)\r\nGPU: TITAN X(Pascal)\r\nMem: 64GB\r\nThank you for your patient answer.", "Nagging Assignee @bignamehyp: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm having the same issue, please someone solve it ;(", "solved it, replace\r\ntf.argmax(yi, axis=3, output_type=tf.int32)\r\nwith\r\ntf.cast(tf.argmax(yi, axis=3) ,tf.int32)", "Closing as this is resolved"]}, {"number": 22178, "title": "feature request:  A transform that maps the input to the output in tf.contrib.image", "body": "**feature request: \r\nA transform that map the input to the output in tf.contrib.image**\r\n\r\nIn current tf.contrib.image.transform, it says \"The transforms are *inverted* compared to the transform mapping input points to output points\".\r\nThis is counter-intuitive to me. Why would you define a function that applies a transform converting the output to the input? Isn't input -> transform matrix -> output more straight forward?\r\n\r\nUpdate: \r\n\r\nI believe this should be easy to implement.\r\n\r\nYou can check the the source code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/image/python/ops/image_ops.py).\r\n\r\nUnder `def transform`, it says:\r\n\r\n>\" it maps the *output* point `(x, y)` to a transformed *input* point\"\r\n\r\nTo make the inverted transform work, people have to use it with `tf.linalg.inv`.\r\n\r\n**My request is to change it to a normal transform, which maps the input point to the output point, so that we don't have to bother with `tf.linalg.inv`.**\r\n\r\n### System information\r\n- Have I written custom code: NO\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: N/A\r\n- TensorFlow installed from:\r\n- TensorFlow version: 1.10.0\r\n- Python version: 2.7.12\r\n- Bazel version:N/A\r\n- GCC/Compiler version : 5.4.0\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: GTX 1070 8G\r\n- Exact command to reproduce: N/A\r\n", "comments": ["@cy89 Hi, could you please clarify if this can be implemented or open for contributions ?", "We don't want to invert the transformation in the normal code path, since it adds extra complexity (the matrix could not be invertible). Internally, we need to loop over each output pixel and determine the transformed input pixel, so we do need the reverse transformation.\r\n\r\nNormally, I think rotate() is used more often, which is negated compared to the usual transformation matrix to avoid needing to use the linalg ops. We also expose the rotation matrix through another function for the user to compose other transformations, and that matrix should be consistent with the one used internally (it should be a reverse transform).\r\n\r\nWe could add an option to transform(), maybe \"forward\" that defaults to False, but will invert the matrix if True.", "Image transformations are moving to tensorflow_addons with TF 2.0: https://github.com/tensorflow/addons\r\n\r\nPlease open an issue there, and feel free to link to my comment as a possible way to handle this. Thanks!"]}, {"number": 22177, "title": "Wavelet transform ", "body": "Is there any plan in making tensorflow support wavelet transform?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Have I written custom code: N/a\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: N/A\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\nMobile device: N/A", "Not that I'm aware of. You could probably support it in your own repo.", "Thank you for the response @drpngx "]}]