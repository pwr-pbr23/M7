[{"number": 20721, "title": "Update README.md", "body": "Add 64 bit support when available", "comments": []}, {"number": 20720, "title": "Update README.md", "body": "Add 64 bit support flag for the mobile app", "comments": []}, {"number": 20719, "title": "Update README.md", "body": "Add 64 bit support flag in instructions for building the TFLite mobile app", "comments": []}, {"number": 20718, "title": "Optimized model is slow on Android ", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android 7.0 \r\n- **TensorFlow installed from (source or binary)**: Binary \r\n- **TensorFlow version (use command below)**: Tensorflow Android 1.6 with Java TFInferenceInterface\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**: Please see below. \r\n\r\n### Describe the problem\r\nI am using graph transformation tool to optimize SSD model. Here is the command I used to strip the nodes, quantize the weights and for other optimization methods. \r\n```markdown\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/workspace/frozen_inference_graph.pb --out_graph=/workspace/frozen_inference_graph_opti.pb \\\r\n      --inputs='image_tensor:0' --outputs='detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0' \\\r\n          --transforms='strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics)\\\r\n              fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights'\r\n```\r\nThe model size changed from 53 MB to 13 MB, new optmization model is working perfectly fine on Ubundu 16.04 and Windows 10 with the following numbers (without the GPU) : \r\n# On Ubuntu 16.04 & Windows 10 : \r\nBefore the Optimization :  \r\nInference time = 616 mSec/image \r\nAfter the optmization : \r\nInference time =200 mSec /image\r\nAs you can observe that, there is clear three fold speed boost with the optimized model without compromising the accuracy. However, on android inference time remains same after the optmization. \r\n# On Android \r\nBefore the optmization : \r\nInference time = 900 mSec/image\r\nAfter the optimization : \r\nInference time = 890 mSec/image \r\n\r\nThe mobile device I am using is Galaxy Tab S2 8.0 with Octa-core processor. \r\nI have digged most of the issues here but those are either issues with slower model on one OS or some sort of error with optimized model. This is the first time I am seeing this strange behavior when moving to mobile plateform.  \r\n\r\n Let me know if you need more information. \r\nThanks in advance. \r\n", "comments": ["Hi, any help would be appreciated, thanks in advance. ", "It's not clear what the exact problem is here, but you probably need to run timelines profiler to find out what the op distributions are in each of your test cases. The memory allocator in android is also not as fast as the desktop (as is the cpu). \r\n\r\nYou might consider using the ssd work of @achowdhery which is quantized and should run faster on a phone.", "Thanks for getting back on this. \r\nSure, let me run the profiling, I will post the cases. \r\nDo you think Tensorflow Lite would be faster in using optimized models? \r\nI can give a shot to quantized training too but I was trying to take the complete advantage of graph-transformation tool on inference model, just to avoid the re-training again with quantized weights. ", "When using tensorflow/tools/graph_transforms/transform_graph it is expected that there will be more work to do during inference, but the file would be smaller. I'd expect start up times to improve, but repeated latency times to increase slightly (due to the extra dequantization step)", "@skulhare If you are able to migrate your workflow to use Tensorflow Lite for SSD model, we have been able to get much lower latencies by following the steps in `[blog post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)` we published recently. Then you dont need to use transform_graph.py", "@skulhare Did this get resolved?", "Apologies for the delay in response. I am training a new 8 bits model and going to use TF Lite for inference.  Will post the results soon. Thanks ", "Great timing @tensorflowbutler :) \r\n@achowdhery, I followed your medium article and trained a quantized SSDMobilenet. After the training, I export the graph with export_tflite_ssd_graph.py script. Now I am using toco/tflite_convert to convert .pb to .tflite but I am getting this error : \r\n\r\n   File \"/usr/local/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 91, in _convert_model\r\n    converter = _get_toco_converter(flags)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 81, in _get_toco_converter\r\n    return converter_fn(**converter_kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 204, in from_frozen_graph\r\n    import_graph_def(graph_def, name=\"\")\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py\", line 418, in import_graph_def\r\n    graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'TFLite_Detection_PostProcess' in binary running on be8098d5af8f. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n\r\n\r\nIt seems like I will have explicitly remove some operations from the graph those are not supported in this conversion? \r\n\r\nThanks in advance. ", "TFLite_Detection_PostProcess wasn't available until after tensorflow 1.11. Could you try with a recent version and report back? Thanks!", "Closing due to inactivity.", "same problem"]}, {"number": 20717, "title": "go api speed up array of frames", "body": "I have raw decoded video frame format *image.YCbCr\r\n\r\nbut for work I need to encode it to jpeg or png\r\n\r\nop.DecodeJpeg\r\nop.DecodePng\r\n\r\nthis operation takes about 20 ms\r\n\r\ncan I somehow convey a raw image so as not to waste this time?\r\n\r\nor maybe I can convert to rgb and send pix() to  tensorflow op\r\n\r\nIt's really not convenient to code to decode and slow down the work with an array of frames; (\r\n\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 20716, "title": "Update ci unit test to use Bazel 0.14.1", "body": "ci_parameterized_build.sh is currently failing because it installs\r\nbazel 0.11.0 which is missing the function setup_vc_env_vars\r\nin windows_cc_configure.bzl. This function was added in a later\r\nbazel version. I see other parts of Tensorflow moving to 0.14.1,\r\ndoing the same here.", "comments": ["As reference, that bazel function was added with this commit:\r\nhttps://github.com/tensorflow/tensorflow/commit/ab39198aceb641d7be631ba85091a4139edf203f", "The same change was done in https://github.com/tensorflow/tensorflow/commit/c067242a12b8a0cc0cc9996e2a3e1eed7de4f53b\r\n\r\nClosing this PR."]}, {"number": 20715, "title": "[ROCm] rocBLAS BLAS algorithms integration logic in ROCm StreamExecutor", "body": "Please focus on the content in commit https://github.com/tensorflow/tensorflow/pull/20715/commits/c12b7df5a9321582e785d13edf81c32fc9df379b\r\n\r\nThe pull request contains rocBLAS integration logic for ROCm platform.\r\n\r\nThere are additional changes included in this pull request which are covered\r\nin other pull requests for ROCm. In order to ensure each pull request is\r\nself-contained and builds / runs on both CUDA & ROCm platform they are still\r\nincluded here.\r\n\r\n- #20277 : bazel changes and continuous integration logic\r\n- #20675 : StreamExecutor interface change\r\n- #20709 : barebone ROCm StreamExecutor implementation\r\n\r\nAuthors:\r\n\r\n- Jack Chung: jack.chung@amd.com\r\n- Deven Desai: deven.desai@amd.com\r\n- Johannes M Dieterich: Johannes.Dieterich@amd.com", "comments": ["@jlebar This is the subsequent PR after #20709 to cover integration logic for rocBLAS BLAS algorithms on ROCm StreamExecutor implementation", "cc @chsigg ", "@whchung, is this PR still alive? Please resolve the merge conflict if this is the case.", "@qlzh727 all of my PRs are still alive. it's just literally they all hinge on #20277 where I have to fix issues met on Mac / Windows and certain Ubuntu build targets. I'll rebase and revise the PR once #20277 lands", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20714, "title": "Seq2seq tutorial dissapeared", "body": "Hi, \r\n\r\n[https://www.tensorflow.org/tutorials/seq2seq](https://www.tensorflow.org/tutorials/seq2seq) tutorial returns 404 not found. This is where an extensive tutorial by Luong et al was located until several days ago, I assume it was deleted or moved by mistake. \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: NA\r\nOS Platform and Distribution: NA\r\nTensorFlow installed from: NA\r\nTensorFlow version: NA\r\nBazel version: NA\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce: NA\r\n\r\n", "It might have been removed from the main tutorials page because of its dependency on Tensorflow Nightly. Perhaps this page has all the content you need- https://github.com/tensorflow/nmt", "Actually the tutorials page (https://www.tensorflow.org/tutorials/) does have a link to the NMT page (https://github.com/tensorflow/nmt) under the \"Sequences\" tab. You will notice that the tutorials page has also changed quite a bit - tutorials are now clubbed under collapsed sections on the left.", "Aayush is correct, we've updated the tutorials page and are cleaning up some old examples.\r\nThat NMT tutorial is linked under 'Sequences' (there's another [NMT w/ attention](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb) using eager listed under 'Research and experimentation').\r\n\r\nI added a redirect for '/tutorials/seq2seq' to fix the 404. It redirects back to the main tutorials page."]}, {"number": 20713, "title": "[ROCm] MIOpen DNN algorithms integration logic in ROCm StreamExecutor", "body": "Please focus on the content in commit https://github.com/tensorflow/tensorflow/pull/20713/commits/7c87476fe25e48039d59ab5058480bdfa91c9e3b\r\n\r\nThe pull request contains MIOpen integration logic for ROCm platform.\r\n\r\nThere are additional changes included in this pull request which are covered\r\nin other pull requests for ROCm. In order to ensure each pull request is\r\nself-contained and builds / runs on both CUDA & ROCm platform they are still\r\nincluded here.\r\n\r\n- #20277 : bazel changes and continuous integration logic\r\n- #20675 : StreamExecutor interface change\r\n- #20706 : StreamExecutor interface change\r\n- #20708 : StreamExecutor interface change\r\n- #20709 : barebone ROCm StreamExecutor implementation\r\n\r\nAuthors:\r\n\r\n- Jack Chung: jack.chung@amd.com\r\n- Peng Sun: Peng.Sun@amd.com", "comments": ["@jlebar This is the subsequent PR after #20709 to cover integration logic for MIOpen DNN algorithms on ROCm StreamExecutor implementation", "@chsigg volunteered to help with this.  Christian, you can see the full set of patches at https://github.com/tensorflow/tensorflow/pulls/whchung.", "Thanks Wen-Heng, this looks very good at first glance. There have been some changes to cuda_dnn.cc that I think would be worth integrating to mroc_dnn.cc. Do you think that would be feasible?\r\n\r\nI think it might make sense to integrate the mroc_dnn files from the cuda_dnn files (at least the header, and potentiall the cc file as well to make it simpler to port changes going forward).", "@chsigg Thanks for the feedback. The philosophy behind the current implementation was to keep existing interface and CUDA implementation as is so we can come up with a working implementation on ROCm platform with least intrusive changes.\r\n\r\nMoving forward indeed DNN interface and implementation deserve to be refactored between both paths to share common logic as much as possible.\r\n\r\nI'm working on addressing requests by @jlebar in #20708 and will follow-up with you on this PR after that's done.", "Seems that the #20708 has been merge. Please resolve the merge conflict here and we can proceed again.", "will revise the PR after #20277 is fixed and lands. this PR depends on it.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20712, "title": "[ROCm] rocFFT integration logic in ROCm StreamExecutor", "body": "Please focus on the content in commit https://github.com/tensorflow/tensorflow/pull/20712/commits/1a34db1da952351788da04a8a8161888647d8687\r\n\r\nThe pull request contains rocFFT integration logic for ROCm platform.\r\n\r\nThere are additional changes included in this pull request which are covered\r\nin other pull requests for ROCm. In order to ensure each pull request is\r\nself-contained and builds / runs on both CUDA & ROCm platform they are still\r\nincluded here.\r\n\r\n- #20277 : bazel changes and continuous integration logic\r\n- #20675 : StreamExecutor interface change\r\n- #20709 : barebone ROCm StreamExecutor implementation\r\n\r\nAuthors:\r\n\r\n- Jack Chung: jack.chung@amd.com\r\n- Johannes M Dieterich: Johannes.Dieterich@amd.com", "comments": ["@jlebar This is the subsequent PR after #20709 to cover integration logic for FFT on ROCm StreamExecutor implementation", "@chsigg volunteered to help with this.  Christian, you can see the full set of patches at https://github.com/tensorflow/tensorflow/pulls/whchung.", "It has been 20 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@whchung, please rebase and resolve the merge conflict here if this PR is still alive.", "@qlzh727\r\n\r\nThis PR is still active. As with the other ROCm related PRs, we are waiting for PR #20277 to get merged, since that is a per-requisite to getting this PR merged. Once that PR is merged, we expect to rebase and resolve the merge conflicts.\r\n\r\nThanks", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20711, "title": "Fix copied buffer", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/20656", "comments": []}, {"number": 20710, "title": "Merge r1.9.0 branch back into master", "body": "Doing this to basically pick up version string changes, make tf.__git_version__ show 1.9.0 tag\r\nwhen building on master branch, and to make sure to pick up any fixes committed directly\r\nto the release branch.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "No idea why this is complaining about CLA stuff?", "That's happened quite a few times recently", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Done", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "pinging this. I think it needs to be re-approved", "Done."]}, {"number": 20709, "title": "[ROCm] StreamExecutor logic for ROCm platform", "body": "Please focus on the content in commit https://github.com/tensorflow/tensorflow/pull/20709/commits/33505b8cfa1298653e4954974abcbbadbcb746ca\r\n\r\nThe pull request contains StreamExecutor logic for ROCm platform. It includes\r\nintegration logic with major components on ROCm platform:\r\n\r\n- HIP runtime APIs\r\n- rocRAND for RNG\r\n\r\nAlso included are relevant changes to:\r\n\r\n- bazel script to build ROCm StreamExecutor on ROCm platform\r\n\r\nFollowing components in ROCm StreamExecutor are not included and will be filed\r\nas separate pull requests:\r\n\r\n- #20712 : rocFFT for FFT algorithms\r\n- #20713 : MIOpen for DNN algorithms\r\n- #20715 : rocBLAS for BLAS algorithms\r\n\r\nThere are additional changes included in this pull request which are covered\r\nin other pull requests for ROCm. In order to ensure each pull request is\r\nself-contained and builds / runs on both CUDA & ROCm platform they are still\r\nincluded here.\r\n\r\n- #20277 : bazel changes and continuous integration logic\r\n- #20675 : StreamExecutor interface change\r\n\r\nAuthors:\r\n\r\n- Jack Chung: jack.chung@amd.com\r\n- Deven Desai: deven.desai@amd.com\r\n- Johannes M Dieterich: Johannes.Dieterich@amd.com\r\n- Peng Sun: Peng.Sun@amd.com\r\n- Jeffrey Poznanovic: Jeffrey.Poznanovic@amd.com\r\n", "comments": ["@jlebar Per your comment in #20675 , this is the barebone ROCm StreamExecutor implementation, after clang-format\r\n", "@jlebar Based on your comments, I've revised the PR again and only cherry-pick commits in previous PRs which are truly necessary for this particular PR to build.\r\n\r\nAll relevant changes in this particular PR has been placed in 1 commit:\r\nhttps://github.com/tensorflow/tensorflow/pull/20709/commits/33505b8cfa1298653e4954974abcbbadbcb746ca", "cc @chsigg ", "@qlzh727 I addressed styling found in \"Ubuntu Sanity\" check. Could you help restart the test? Thanks.", "It has been 20 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@whchung, please rebase and resolve the merge conflict here if this PR is still alive.\r\n", "@qlzh727 \r\n\r\nThis PR is still active. Waiting for PR #20277 to get merged, since that is a per-requisite to getting this PR merged.  Once that PR is merged, we expect to rebase and resolve the merge conflicts.\r\n\r\nThanks", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20708, "title": "[ROCm] add scratch memory size in AlgorithmDesc", "body": "Certain algorithms in MIOpen, the DNN library on ROCm platform, requires\r\nscratch memory be allocated in TensorFlow and passed to MIOpen at runtime.\r\n\r\nIn MIOpen algorithm finding phase, such information would be returned via\r\nMIOpen API and kept in AlgorithmConfig.\r\n\r\nIn this pull request, changes to AlgorithmConfig and convolutional operators are\r\nadded first. Subsequent PR would cover changes for ROCm StreamExecutor.\r\n", "comments": ["@jlebar based on our discussion in #20675, this is the another part of proposed interface changes to enable StreamExecutor on ROCm platform\r\n", "> In MIOpen algorithm finding phase, such information would be returned via MIOpen API and kept in AlgorithmConfig and ProfileResult.\r\n\r\nWe need to have a consistent API between CUDA and MIOpen.\r\n\r\nI'm fine with putting the scratch memory requirement in the Algorithm struct, but then we need to do that for CUDA, too.  So we can't take this patch as-is, because CUDA is going to return 0 for the scratch memory requirement, which is wrong.", "The alternative is to continue doing things as we do now.  Although I think this API change would be a net positive, it's not clear to me why MIOpen needs the scratch memory requirement in the Algorithm while CUDA does not.", "@daniellowell @dagamayank for MIOpen algorithm finding strategy. Please help weigh in.\r\n\r\n@jlebar Auto-tuning logic works a bit different between CuDNN and MIOpen.\r\n\r\nIn CuDNN algorithm finding phase, a vector of available algorithms (via `GetConvolveXXXAlgorithms` in `cuda_dnn.cc`  in CUDA StreamExecutor) is iterated, and passed into CuDNN to find the best algorithm with scratch memory, and the one without scratch memory.\r\n\r\nIn MIOpen algorithm finding phase, MIOpen `FindConvolveXXXAlgorithm` API is invoked in ROCm StreamExecutor, *without* the vector of available algorithms. MIOpen would find the best algorithm based on its pre-computed performance database, and return the ID of the algorithm, plus the size of scratch memory needed for the algorithm back to the client application (TensorFlow).\r\n\r\nIt's therefore such an member variable is added in this pull request. And this member variable won't be used in CuDNN path.", "> this member variable won't be used in CuDNN path.\r\n\r\nHow is a user supposed to avoid reading Algorithm::scratch_bytes_used() in the CUDA case, observing that it is zero, and then having a bug?\r\n\r\n> In MIOpen algorithm finding phase, MIOpen FindConvolveXXXAlgorithm API is invoked in ROCm StreamExecutor, without the vector of available algorithms. MIOpen would find the best algorithm based on its pre-computed performance database, and return the ID of the algorithm, plus the size of scratch memory needed for the algorithm back to the client application (TensorFlow).\r\n\r\nIf at all possible we should use MIOpen the same way we use cudnn, where we ask MIOpen for a list of algorithms, and then TensorFlow / XLA runs all of the algorithms, choosing the fastest one.\r\n\r\nWe need the ability to run \"non-optimal\" algorithms for a variety of reasons, including checking for correctness or having limited scratch memory available.\r\n\r\nSo MIOpen should support an API that works like the cudnn API works today.", "> How is a user supposed to avoid reading Algorithm::scratch_bytes_used() in the CUDA case, observing that it is zero, and then having a bug?\r\n\r\n@jlebar How do you think if we refactor the logic, and put this scratch memory size field into `AlgorithmDesc`, and ensure the following semantic:\r\n\r\nFor both CUDA and ROCm paths:\r\n- `AlgorithmConfig::algorithm_()` would contain the algorithm ID which uses scratch memory, plus the size of scratch memory.\r\n- `AlgorithmConfig::algorithm_no_scratch()_` would contain the algorithm ID which doesn't use scratch memory, with the size of scratch memory be 0.\r\n\r\nThis could be implemented without changing MIOpen API. I'll address your other comment in another reply.", "> If at all possible we should use MIOpen the same way we use cudnn, where we ask MIOpen for a list of algorithms, and then TensorFlow / XLA runs all of the algorithms, choosing the fastest one.\r\n> We need the ability to run \"non-optimal\" algorithms for a variety of reasons, including checking for correctness or having limited scratch memory available.\r\n> So MIOpen should support an API that works like the cudnn API works today.\r\n\r\nTo my understanding a new MIOpen API termed as \"direct mode\" is under development where it's possible for client applications to specify exact algorithm be used. This should help realize your request to allow XLA and TensorFlow to pick the best/not-so-best algorithm. However this feature is not released yet.\r\n\r\nI'd like to ask @daniellowell to weigh in on the availability of this \"direct mode\". He is in charge of MIOpen API design. ", "> How do you think if we refactor the logic, and put this scratch memory size field into AlgorithmDesc, and ensure the following semantic: [...]\r\n\r\nsgtm!\r\n\r\n> To my understanding a new MIOpen API termed as \"direct mode\" is under development where it's possible for client applications to specify exact algorithm be used. This should help realize your request to allow XLA and TensorFlow to pick the best/not-so-best algorithm. However this feature is not released yet.\r\n\r\nOK.\r\n\r\nUntil direct mode is available, I think we can still implement the same API as we have for cudnn, though?  Just have ROCm return the one (autotuned) algorithm in the list of algorithms.\r\n\r\nIf the presence of algorithm_no_scratch is a problem for ROCm (because you only get one algorithm with however much scratch required -- take it or leave it), we can try a bigger refactoring that gets rid of that...  Once you're returning the scratch memory requirement in the AlgorithmDescription, then we can simplify this whole thing quite a bit just by making the client preallocate the scratch buffer.  No need to have a ScratchAllocator in these calls at all -- it can just accept the preallocated scratch buffer instead.", "@jlebar \r\n\r\n> If at all possible we should use MIOpen the same way we use cudnn, where we ask MIOpen for a list of algorithms, and then TensorFlow / XLA runs all of the algorithms, choosing the fastest one.\r\n\r\nMIOpen attempts to auto-tune all the available algorithms for any particular inputs. This is similar to `cudnnFindConvolutionForwardAlgorithmEx`. But perhaps XLA, TensorFlow is not using that cuDNN API. Different algorithms require different scratch-space sizes ranging between zero to several MBs and hence, MIOpen provides another API to let the user know how much scratch is needed.\r\n\r\n> We need the ability to run \"non-optimal\" algorithms for a variety of reasons, including checking for correctness or having limited scratch memory available.\r\n> Until direct mode is available, I think we can still implement the same API as we have for cudnn, though? Just have ROCm return the one (autotuned) algorithm in the list of algorithms.\r\n\r\nI think this is still possible today. One can just pass zero as scratch-space size. However, in this case it is not guaranteed a valid algorithm is available for any and all inputs. In some scenarios scratch is _a_ requirement. This [link](https://github.com/ROCmSoftwarePlatform/MIOpen/wiki/MIOpen-Convolutions) adds some more color to my description.\r\n\r\nWith `direct` mode, MIOpen will more closely track cuDNN's usage of -\r\n`cudnnGetConvolutionForwardAlgorithm`  -- returns the algo for a particular config\r\n` cudnnGetConvolutionForwardWorkspaceSize` -- returns the scratch size for that config\r\n`cudnnConvolutionForward` -- executes convolution\r\n\r\nI think both cuDNN and MIOpen are doing the same thing albeit the implementations are slightly different. If you look at the [description](https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnFindConvolutionForwardAlgorithm) of `cudnnFindConvolutionForwardAlgorithm` -\r\n_This function attempts all cuDNN algorithms (including CUDNN_TENSOR_OP_MATH and CUDNN_DEFAULT_MATH versions of algorithms where CUDNN_TENSOR_OP_MATH may be available) for cudnnConvolutionForward(), using memory allocated via **cudaMalloc()**,_\r\n\r\nIn this case, cuDNN internally manages all the memory including scratch as needed, whereas, MIOpen explicitly requires users to manage the memory.", "> Until direct mode is available, I think we can still implement the same API as we have for cudnn, though? Just have ROCm return the one (autotuned) algorithm in the list of algorithms.\r\n\r\n...or if that is hard because you'd need a to pass scratch allocator to the generate-a-list-of-algorithms function (that seems like a bad API), then in the generate-the-list-of-algorithms function, can we run autotuning with zero scratch memory and return that algorithm as our one result?  That will potentially return a slow conv, but it will be functionally correct, which will unblock us.", "@jlebar I've updated this PR. Now I put the scratch memory size field into AlgorithmDesc, and ensure the following semantic:\r\n\r\nFor both CUDA and ROCm paths:\r\n\r\nAlgorithmConfig::algorithm_() would contain the algorithm ID which uses scratch memory, plus the size of scratch memory.\r\nAlgorithmConfig::algorithm_no_scratch()_ would contain the algorithm ID which doesn't use scratch memory, with the size of scratch memory be 0.\r\n\r\nCould you kindly review it once again? Thanks.", "a gentle ping?", "I appreciate the ping, especially because I haven't learned how to juggle my reviews in github, so there's a real possibility I'll miss pending reviews.  But to set expectations, sometimes it's going to take more than a day to get back to you.  I really want it XLA:AMDGPU to happen, and I'm doing my best trying to keep up, but...I have other things I also have to do.  :-/\r\n\r\nIf not getting a review really quickly blocks you, we should try to come up with a workflow that lets you make progress without relying on super-fast reviews from my side.  I'm not sure what changes we'd make, but happy to take ideas.", "@jlebar Thanks for prompt reply. I'm not blocked yet as I still have quite a few PRs under preparation for GPU common runtime, operator implementations, and XLA.", "@timshen91 you've been looking at this code lately, would you mind doing a review of this (including double-checking my design suggestion)?", "@jlebar , I can take this PR.\r\n\r\nIIUC cuDNN also supports \"given scratch space limit, find the algorithm\" [1]. Today, cuda_dnn.cc gets the scratch size limit [2] by calling `scratch_allocator->GetMemoryLimitInBytes(stream)`.\r\n\r\nFor supporting MIOpen, Instead of propagating the scratch limit through AlgorithmDesc, maybe try to set it in the scratch allocator?\r\n\r\nFrom design's perspective, I think we should have two distinct types:\r\na) a type that describes the constraint users provide, for the DNN library to suggest an algorithm.\r\nb) a type that describes an exact algorithm either picked by the user, or suggested by the DNN library.\r\n\r\nUnfortunately AlgorithmDesc is (b) and a little bit of (a) [3]. But I'm leaning towards separating (a) from (b). Adding scratch space limit to AlgorithmDesc makes them more mixed.\r\n\r\n[1] https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnConvolutionBwdDataPreference_t\r\n[2] https://github.com/tensorflow/tensorflow/blob/f55028af4861bc78516164975a43f259507adf60/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2127\r\n[3] https://github.com/tensorflow/tensorflow/blob/f55028af4861bc78516164975a43f259507adf60/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2123", "@timshen91 Thanks for the review. The idea using `ScratchAllocator` is an interesting one and let me explore this. If it works we won't need any change in `AlgorithmDesc`.", "@timshen91 Please find the revised PR. Instead of changing `AlgorithmDesc` I now add one member variable `algorithm_scratch_size` in `AlgorithmConfig`. It would be used to keep the size of scratch memory for the best algorithm with scratch memory. Convolution operators in TF have also been changed to see show how the new interface is used.\r\n\r\nPlease notice `algorithm_scratch_size` is set in this PR but not read actually as it's not required for CuDNN. For MIOpen integration logic the field would be used, and would be submitted in a separate PR after prerequisites such as #20277 is accepted and merged.\r\n\r\n", "Can you clarify that which of the following algorithm_scratch_size_ is?\r\n* The scratch size required by algorithm_. It's passed from the DNN library to the user.\r\n* The memory limit of scratch allocation required by the user. It's passed from the user to the DNN library.\r\n\r\nHonestly I'm not sure which one is it in the context...", "@timshen91 it would be:\r\n\r\nThe scratch size required by algorithm_. It's passed from the DNN library to the user.\r\n", "Ah I see, sorry for the confusion. I was thinking about the other one all the time.\r\n\r\nFrom my understanding, AlgorithmConfig is the one users send to the DNN library (e.g. ThenConvolveWithAlgorithm), and AlgorithmDesc is the one DNN sends to the user (e.g. GetConvolveAlgorithms), so AlgorithmDesc is a better place for describing \"The scratch size required by an algorithm\".\r\n\r\nIt's also implementable in cuDNN (cudnnGetConvolutionForwardWorkspaceSize), and I think we should implement that too, maybe in a separate commit.", "@timshen91 Thanks for the comments. It seems you are leaning toward getting the field added in `AlgorithmDesc`. In fact that was what the previous version of the PR looked like. :)  Let me try revive it.", "Yes, and sorry about that. :)\r\n\r\nAfter that, do you plan to use cuDNN's cudnnGetConvolutionForwardWorkspaceSize() to populate the scratch size in AlgorithmDesc? So that the scratch size is always valid, not like 0 sometimes depending on the DNN library.", "We use AlgorithmDesc when launching convolutions as well.\n\nDo I have to pass an AlgorithmDesc with the correct scratch requirement on\npain of fatal error?  Or is it ignored?  How do we propose this works?\n\nOn Wed, Jul 25, 2018 at 2:02 PM Tim Shen <notifications@github.com> wrote:\n\n> Yes, and sorry about that. :)\n>\n> After that, do you plan to use cuDNN's\n> cudnnGetConvolutionForwardWorkspaceSize() to populate the scratch size in\n> AlgorithmDesc? So that the scratch size is always valid, not like 0\n> sometimes depending on the DNN library.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/20708#issuecomment-407893362>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAJMhzpmTN5MTUTGPrdCbE0IGEFXaFeeks5uKNzwgaJpZM4VLqoU>\n> .\n>\n", "@jlebar In my previous version of this PR. The proposed semantic is:\r\n\r\nThe scratch memory size field into `AlgorithmDesc`, and ensure the following semantic:\r\n\r\nFor both CUDA and ROCm paths:\r\n\r\n`AlgorithmConfig::algorithm_()` would contain the algorithm ID which uses scratch memory, plus the size of scratch memory.\r\n`AlgorithmConfig::algorithm_no_scratch()_` would contain the algorithm ID which doesn't use scratch memory, with the size of scratch memory be 0.\r\n\r\nHere's what be implemented in CUDA path:\r\n\r\nIn algorithm finding stage (conv_ops.cc, conv_grad_*.cc), use `scratch_allocator.TotalByteSize()` to populate the field inside `AlgorithmDesc`, which is embedded in `ProfileResult` to determine the best algorithm.\r\n\r\nSame logic would probably need to be applied in XLA (service/gpu/cudnn_convolution_algorithm_picker.cc).\r\n\r\nIn CUDA StreamExecutor (cuda_dnn.cc), prior to launching convolutions, `GetCudnnConvolutionXXXAlgorithm` would be invoked. Inside it, `GetCudnnConvolutionXXXAlgo` and `AllocateCudnnConvolutionXXXWorkspace` would be invoked to allocate scratch memory, and when supplied with `AlgorithmDesc` created in the previous stage, really allocate scratch memory and populate `AlgorithmDesc` which reflects the actual scratch memory allocated. And then launch the algorithm.", "> In algorithm finding stage (conv_ops.cc, conv_grad_*.cc), use scratch_allocator.TotalByteSize() to populate the field inside AlgorithmDesc, which is embedded in ProfileResult to determine the best algorithm.\r\n\r\nDoes that mean the scratch size field carries two meanings?\r\n* `AlgorithmConfig(...).algorithm_.algorithm_scratch_size_` is set to `scratch_allocator.TotalByteSize()`, meaning users intend to put a limit on the total scratch for use, this is passed from the user to the DNN library.\r\n* `ProfileResult(...).algorithm_.algorithm_scratch_size_` means the actual scratch memory needed by the very algorithm it keeps. This is passed from the DNN library to the users.\r\n\r\nIf that's the case, I don't like the dual meaning of `algorithm_scratch_size_`. If we need both kinds of variables, we can create two of them, and handle them consistently.\r\n\r\nI almost feels like we want `AlgorithmConfig` to have a new field `scratch_size_limit_`, and `ProfileResult`/`AlgorithmDesc` to have a new field `scratch_size_used_`, but I'm not quite sure, as I don't know enough about MIOpen.", "My intention is to keep the new field only be set by the DNN library and never by users. To my understanding scratch_allocator.TotalByteSize() is actually set by the DNN library?", "I see, yes `scratch_allocator.TotalByteSize()` records the memory size allocated by cuDNN. I think that's the way to go. For a while I mistakenly thought `TotalByteSize()` as `GetMemoryLimitInBytes()`.\r\n\r\nCan you also add a TODO that the ProfileResult scratch memory usage should be populated by DNN library itself, not user code like `conv_ops.cc`, `conv_grad_*.cc`?", "@timshen91 sorry it took me a while to update this PR. was out of town for a couple of days and I was also more focused on #20277.\r\n\r\nNow the PR has been updated so the new field to track the size of scratch memory is inside `AlgorithmDesc`. Also in CUDA StreamExecutor implementation the field is populated inside `AllocateCudnnXXXWorkspace()`. Notice instead of calling `scratch_allocator.TotalByteSize()` I use the result from `cudnnGetXXXWorkspaceSize()` which should attain the same result.\r\n\r\n", "@timshen91 I addressed the build errors on CI, made sure they build / run tests correctly on my end. Could you review once again and re-initate the tests? sorry it takes that long."]}, {"number": 20707, "title": "Highwash fix for rebuild", "body": "highwash works the same way now as the others.", "comments": ["@gunan, not sure who is the owner of CMAKE, please assign to proper owner. Thanks.", "Closing based on discussion in #21035."]}, {"number": 20706, "title": "[ROCm] Interface changes for pooling APIs in StreamExecutor", "body": "Due to the design of MIOpen, the DNN library on ROCm platform, an instance of\r\nScratchAllocator has to be passed into pooling routines. This commit address\r\nsuch interface changes and the implementation in CUDA StreamExecutor.", "comments": ["@jlebar based on our discussion in #20675, this is the 2nd part of proposed interface changes to enable StreamExecutor on ROCm platform", "@gunan I think this API change is going to require corresponding changes to google3 code.\r\n\r\nWhat's our procedure for doing this in a non-breaking way?  Should I make an internal CL based on this one and check it in, subsuming this PR?", "That is a good idea. In the new system, you will see the internal change before it gets merged. You can choose to work on the resulting cl, too.", "> That is a good idea. In the new system, you will see the internal change before it gets merged. You can choose to work on the resulting cl, too.\r\n\r\nCan I do that now (i.e. import this patch, prepare an internal change), or do I need to wait for something?", "I think you can do that anytime you want. You can do the conversion once now, and if you see issues you can wait, and do another conversion with a more updated version of this PR again later.\r\n@yifeif for instructions.", "I will attempt to submit this upstream."]}, {"number": 20705, "title": "Match for path instead of name", "body": "", "comments": ["Cherry-picking to master"]}, {"number": 20704, "title": "R1.9 cherrypick docs", "body": "Latest updates and fixes into 1.9 so we can generate the site", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I'm not sure why the CLA bot is failing, nitisht@ appears to have signed it here: https://github.com/tensorflow/tensorflow/pull/20637\r\n", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "Assigning to @av8ramit since this is merging to release branch.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Seeing if I can eliminate the problematic cherry-pick commit in https://github.com/tensorflow/tensorflow/pull/20854"]}, {"number": 20703, "title": "Character access is not supported in tf.contrib.autograph", "body": "For example this is not working and it returns an error\r\n```\r\n@autograph.convert()\r\ndef is_hashtag(x):\r\n  if x[0] == \"#\":\r\n    return True\r\n  return False\r\n\r\nwith tf.Graph().as_default():  \r\n  with tf.Session() as sess:\r\n    print(sess.run(is_hashtag(tf.constant(\"#asdf\"))))\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "OS Platform and Distribution: linux\r\nTensorFlow installed from: mvnrepository\r\nTensorFlow version: 1.7\r\nBazel version: no idea\r\nCUDA/cuDNN version: not using\r\nGPU model and memory: not using\r\nExact command to reproduce\r\n```\r\n@autograph.convert()\r\ndef is_hashtag(x):\r\n  if x[0] == \"#\":\r\n    return True\r\n  return False\r\n\r\nwith tf.Graph().as_default():  \r\n  with tf.Session() as sess:\r\n    print(sess.run(is_hashtag(tf.constant(\"#asdf\"))))```", "Hi, sorry for the delay! This looks like a feature we should add. Here's a workaround in the mean time:\r\n\r\n    @autograph.convert()\r\n    def is_hashtag(x):\r\n      if tf.substr(x, 0, 1) == \"#\":\r\n        return True\r\n      return False\r\n\r\nRight now, what happens is that x is a scalar tensor of type string. The `[0]` operator is trying to index into a scalar tensor, and fails. It makes more sense when you thing of a vector tensor or type string, like `x = tf.constant([\"foo\", \"bar\", \"baz\"]`, for which `x[0]` will be the scalar `\"foo\"`). But we could detect that the tensor is a scalar of type string and index into it.\r\n\r\nThat should be fairly straightforward to do by extending the tensor index operator `_tf_tensor_get_item` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/autograph/operators/slices.py", "Nagging Assignee @mdanatg: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20702, "title": "[Improvement] Make tf.contrib.model_pruning.masked_conv2d API compatible with tf.layers.conv2d", "body": "TensorFlow version: v1.8.0-0-g93bc2e2072 1.8.0\r\n\r\n### Describe the problem\r\nI know contrib isn't officially supported, but I don't know who I should request this to:\r\nmasked_conv2d is intended to be a plug-in replacement of conv2d, but argument names are different. Some simples changes such as: num_outputs->filters, scope->name etc should be enough to make it compatible", "comments": ["@yifeif ", "I remember tf.contrib is always subject to change. Though would like to be confirmed by API review before working on updating the API.", "Correct, we do not promise API stability for symbols in `tf.contrib` so they can be changed.\r\nRemoving the \"API Review\" label.\r\n\r\nI'll defer to the maintainers of the `model_pruning` module on whether they want to make the change though.\r\n\r\n@suyoggupta "]}, {"number": 20701, "title": "Eager execution does not work for R interface under Python 3", "body": "Hi there, I am the maintainer of the R interface to TensorFlow. We are currently in the process of porting various Eager examples to R. We haven't had trouble with Python 2 versions of TensorFlow, but with Python 3 versions we get some strange errors. \r\n\r\nI realize that this is within the R interface so technically falls outside of the scope of TF for Python. However, in order for us to address this we need some insight as to what might be different for Eager under Python 3. I'll provide a detailed repro and explanation of it's under the hood behavior below.\r\n\r\ncc @martinwicke @random-forests \r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: TensorFlow v1.10.0-dev20180710 \r\n- **Python version**:  3.6.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\n\r\nUsing the R interface to TensorFlow:\r\n\r\n```r\r\nlibrary(tensorflow)\r\ntf$enable_eager_execution()\r\nx <- tf$constant(1)\r\ntf$add(x, x)\r\n```\r\n\r\nResults in this error:\r\n\r\n```\r\nSystemError: <built-in function TFE_Py_FastPathExecute> returned a result with an error set \r\n```\r\n\r\nThis error occurs within the definition of `add()` within `gen_math_ops.py`:\r\n\r\n```python\r\n  _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\r\n        _ctx._context_handle, _ctx._eager_context.device_name, \"Add\", name,\r\n        _ctx._post_execution_callbacks, x, y)\r\n```\r\n\r\nThis code works as expected under TF w/ Python 2.\r\n\r\nAgain, I realize that this is the R interface so you might not have an intuition about what could be wrong. You can think of the R interface conceptually as just using the C Python API to invoke functions. So in the above code we are essentially using:\r\n\r\n- `PyImport_Import` to import the tensorflow module\r\n- `PyObject_CallFunctionObjArgs` to call Python functions (e.g. `tf.enable_eager_execution`, `tf.constant`, etc.)\r\n\r\nMy theory is that under Python 3 there is something being done at the Python language level that we aren't emulating or capture when calling through the Python C interface.  Hopefully this provides you with some clues as to what that might be and we will be able to make whatever changes are required to make this work within R.\r\n\r\n", "comments": ["I have seen this error before (not in TF) when I made some mistake I believe related to reference counting in connection with exceptions. But I can't say what's wrong here. I also think that Py3 is stricter about what it lets you get away with, which is probably why you only see this with Py3. \r\n\r\nAdded Alex, who has more context on Eager specifically.", "Interesting. @akshaym can you take a look at this? Maybe FastPathExecute is doing something funny.\r\n\r\n@jjallaire , can you also show us some more information about what error is being set? If you print the TF_Status error code it'll be really helpful.\r\n", "Interesting. To test whether the R interface might be leaving an error set before calling I added a pre-emptive call to `PyErr_Clear()` right before we call `PyObject_CallFunctionObjArgs()`. Unfortunately the error is still occurring so it may be that there is a Python error occurring somewhere within the call to `TFE_Py_FastPathExecute`.\r\n\r\nSo this particular error condition could be somewhat of a red herring: i.e. there is an error occurring during execution b/c some precondition is not met when calling via the C API but we don't see it. \r\n\r\nLooking at the code for `TFE_Py_FastPathExecute()` (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/pywrap_tfe_src.cc#L2232) there are lots of reasons an error might occur but I don't have any intuition about which of these might only be tickled when calling a Python op via the C API as opposed to the Python interpreter.\r\n\r\n\r\n", "Is there a way to get the `TF_Status` error code from the Python interface?", "(sorry)", "We usually raise an exception from the TF_Status error code. It might be\neasier to print it in TFE_FastPathExecute though since I don't know how\nexceptions work across the python/R boundary.\n\nOn Wed, Jul 11, 2018 at 12:32 PM J.J. Allaire <notifications@github.com>\nwrote:\n\n> Is there a way to get the TF_Status error code from the Python interface?\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20701#issuecomment-404283707>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxY5EXDgGgbQmlfonTpVNT2ywBcObks5uFlKxgaJpZM4VLaa0>\n> .\n>\n\n\n-- \n - Alex\n", "Hi @jjallaire, Do you have steps to replicate your environment?\r\n\r\nI'm pretty unfamiliar with how to set up R (I tried the r-base docker, but wasn't able to install TF using https://tensorflow.rstudio.com/tensorflow/).\r\n\r\nSome questions I have:\r\nSince the TF py3 docker has 3.5.2 (and your version is 3.6.5), can you check that this error doesn't occur from the python interpreter directly? If so, it might be easier for me to debug that.\r\nDoes it happen with all ops (perhaps try a matmul)?\r\nDoes tf.constant(1) return a reasonable looking Tensor?\r\n\r\n(I'm trying to answer the first one myself, but responded in case its easy enough for you to run)", "The error doesn't occur when I execute from the Python interpreter directly.\r\n\r\nIt does appear to happen with other ops (I tried `tf.subtract` and `tf.matmul` and it occurred for both of those). For `tf.matmul` the error is slightly different, it occurs on this line of code:\r\n\r\n```python\r\nwith ops.name_scope(name, \"MatMul\", [a, b]) as name:\r\n```\r\n\r\nThe specific error is:\r\n\r\n```\r\nSystemError: <class 'tensorflow.python.framework.ops.name_scope'> returned a result with an error set \r\n```\r\n\r\n`tf$constant(1)` does in fact return a reasonable looking tensor.\r\n\r\nHere's how I would suggest replicating:\r\n\r\n1. Start from a system that already has TF for Python installed and working.\r\n\r\n2. Install R\r\n\r\n3. Install the R tensorflow package from the R console:\r\n    \r\n    ```r\r\n    install.packages(\"tensorflow\", repos = \"https://cran.rstudio.com\")\r\n    ```\r\n\r\n4. Execute this R script:\r\n\r\n    ```r\r\n    library(tensorflow)\r\n    tf$enable_eager_execution()\r\n    x <- tf$constant(1)\r\n    tf$add(x,x)\r\n    ````\r\n\r\nR should be able to find your installation of TensorFlow. If it's in a virtualenv you may need to add this to give it a hint:\r\n\r\n```r\r\nlibrary(tensorflow)\r\nuse_virtualenv(\"/path/to/virtualenv\")\r\n```\r\n\r\n", "To install R on Debian just do this:\r\n\r\n```bash\r\nsudo apt-get install r-base\r\n```", "Then to run R:\r\n\r\n```bash\r\nR\r\n```", "So to summarize:\r\n\r\n```bash\r\n$ sudo apt-get install r-base\r\n$ R\r\n```\r\n\r\nThen from within R:\r\n\r\n```r\r\n> install.packages(\"tensorflow\", repos = \"https://cran.rstudio.com\")\r\n> library(tensorflow)\r\n> use_virtualenv(\"/path/to/virtualenv\") # if necessary\r\n> tf$enable_eager_execution()\r\n> x <- tf$constant(1)\r\n> tf$add(x,x)\r\n```\r\n\r\nOr, after installing the R tensorflow packages w/ `install.packages()`, just put the following in a text file e.g. \"eager.R\":\r\n\r\n```r\r\nlibrary(tensorflow)\r\nuse_virtualenv(\"/path/to/virtualenv\") # if necessary\r\ntf$enable_eager_execution()\r\nx <- tf$constant(1)\r\ntf$add(x,x)\r\n```\r\n\r\nAnd then execute:\r\n\r\n```bash\r\n$ Rscript eager.R\r\n```\r\n\r\nIf you need to keep the process alive for debugging then you can go into R and do this:\r\n\r\n```r\r\nsource(\"eager.R\")\r\n```\r\n", "Thanks @jjallaire! \r\n\r\nI'm able to reproduce with your steps. \r\n\r\nThe following fails for me though: \r\n```R\r\nlibrary(tensorflow)\r\ntf$enable_eager_execution()\r\nx <- tf$constant(1.0)\r\nprint(x) # fails with \"returned a result with an error set\" in EagerTensor_datatype_enum\r\nprint(x) # the second call succeeds on the same tensor.\r\n```\r\n\r\nSo it *seems* as if the constant call is actually returning with an error set (regardless, the tf$add calls also fail after this). So something isn't working right there. \r\n\r\nI'll try to spend some more time on this soon. ", "Okay, great!\r\n\r\nIn terms of a conceptual model, think of the R interface as just using the C API to do everything. So perhaps there is some side-effect or state associated with using Eager via the Python interpreter that is not being replicated? Just a hunch about one angle to consider. Hopefully once you can see the actual failure on the C side everything will become clear!\r\n", "@jjallaire,\r\n\r\nThis seems to happen since the EagerTensor python type doesn't have a `__module__`, which is accessed here: https://github.com/rstudio/reticulate/blob/c9e222fc709a6dcbdda586bbb49d93757fc86086/src/python.cpp#L287\r\n\r\nI'm looking into how to include a `__module__` attribute for the EagerTensor class (looks like we might just need a fully qualified name for the EagerTensor).\r\n\r\nI also sent a pull request to fix reticulate to not generate the python error in any case: https://github.com/rstudio/reticulate/pull/312 (I'm not entirely sure how to actually test this).\r\n\r\nI'll leave this open till I get the `__module__` to work for EagerTensor. ", "Brilliant!!!  So happy we figured this out.\r\n\r\nHere is the fix I made in reticulate: https://github.com/rstudio/reticulate/commit/b1728da7765b042dde04e07886595f5630286048#diff-849f590f08cba3094f269e0a4d69398d \r\n\r\nI only know of one other case in the wild where a Python object didn't have a module so clients are likely conditioned to expect it (whether or not it is formally required, I'm guessing it isn't).\r\n\r\nI'll watch for this issue to be closed and sync to the new __module__ name for EagerTensor (right now we default it to something generic but we'll want to use whatever you end up with once it's checked in.\r\n"]}, {"number": 20700, "title": "Add OpKernel of QuantizedReluX", "body": "This fix tries to address the issue raised in #20514 where no OpKernel was registered to support Op `QuantizedReluX`.\r\n\r\nThis fix add the OpKernel for `QuantizedReluX`.\r\n\r\nThis fix fixes #20514.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Ping Peter again for review.", "Also adding Josh for review.", "Please find someone familiar with quantized operations to review.", "Ping @petewarden for review.", "Nagging Reviewer @petewarden: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 44 days with no activity and the `awaiting review` label has been applied.", "Sorry for the delayed response. We're no longer actively working on the Quantized* ops within mainline TensorFlow, so closing this one."]}, {"number": 20699, "title": "Increasing memory use of Estimator with Dataset", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: Binary (pip install)\r\n- **TensorFlow version (use command below)**: Tested on 1.8.0 and 1.10.0-dev20180620\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX1050\r\n- **Exact command to reproduce**: See below for minimal test case\r\n\r\n### Describe the problem\r\nI'm experiencing a memory leak that leaves some allocated memory behind after each Estimator training/evaluation run. I noticed this when my ML Engine jobs started failing after 1.5 hours of training with an OOM error on big CSV files, using the standard Dataset input pipeline with some preprocessing, batching, prefetching etc. The memory graph shows slow but steady increase of memory use until total RAM is filled. I observe the same behavior on my local machine.\r\n\r\nI've distilled it down to a minimal test case with use of Estimator and Dataset input and tested on my local machine, where I also get slowly increasing memory use over time. It seems most pronounced when using a big shuffle buffer, but after all this time staring at it I'm not so sure of anything any more.\r\n\r\nTest script (first `pip install -U memory_usage`):\r\n```\r\nimport tempfile, time, argparse, os\r\n\r\n# Install with pip install -U memory_usage\r\nfrom memory_profiler import memory_usage\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import device_lib\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--apply-shuffle-repeat', action='store_true')\r\nparser.add_argument('--shuffle', action='store_true')\r\nparser.add_argument('--gpu', action='store_true')\r\nargs = parser.parse_args()\r\n\r\n# Turn on/off gpu\r\nif not args.gpu:\r\n    print(\"Turning off GPU\")\r\n    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\r\n\r\nprint(f\"Tensorflow version: {tf.GIT_VERSION} {tf.VERSION}\")\r\n\r\nprint(f\"Devices: {device_lib.list_local_devices()}\")\r\n\r\ntmpdir = tempfile.mkdtemp()\r\n\r\n_input = [1] * 5000000\r\n_target = [1] * 5000000\r\n\r\ndef input_fn(batch_size=4096):\r\n    data = tf.data.Dataset.from_tensor_slices(\r\n        ({'input': _input}, _target))\r\n    if args.shuffle:\r\n        data = data.shuffle(1000000)\r\n    elif args.apply_shuffle_repeat:\r\n        data = data.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=1000000, count=1))\r\n    data = data.batch(batch_size)\r\n    return data\r\n\r\nestimator = tf.estimator.DNNRegressor(\r\n    [64],\r\n    [tf.feature_column.numeric_column(key='input')],\r\n    model_dir=tmpdir)\r\n\r\ntrain_spec = tf.estimator.TrainSpec(input_fn=input_fn)\r\n\r\neval_spec = tf.estimator.EvalSpec(input_fn=input_fn)\r\n\r\n# Train and evaluate forever\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n```\r\n\r\nOutput of `mprof run tf_estimator_memoryleak_minimal.py --apply-shuffle-repeat\r\n` (so it runs on CPU, for GPU use `--gpu` option) and plotting with `mprof plot` shows memory usage slowly but surely creeping upward:\r\n![tf-memoryuse](https://user-images.githubusercontent.com/5527529/42563920-b7986b62-84ff-11e8-9fa4-304f319927a0.png)\r\n\r\nI would expect memory usage after every train/evaluate loop to return to the initial level.\r\n\r\nAm I using the Dataset in the wrong way? Should I convert to an Iterator first? Is slightly increasing memory use normal and should I restart my train script every once in a while?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "Interesting. This looks like memory increases as more of the dataset is read (in order to repeat the dataset has to hang onto all points), and then it levels off which presumably is when it is repeating. Based on my reading of .train_and_evaluate(), it doesn't seem to be equivalent to:\r\n```\r\nwhile True:\r\n  my_estimator.train(...)\r\n  my_estimator.evaluate(...)\r\n```\r\n\r\nOne simple thing you can try is to put a `print` statement in the input_fn to see if it is called once or repeatedly. If it is just called once for training and once for eval, then this behavior makes sense. (I would expect a memory leak to be linearly increasing, not asymptotic.)", "Thanks @The-Fonz for opening this issue.\r\n\r\nI'm have similar observations with `train_and_evaluate`. It is mostly visible when using buffered Dataset operators like `shuffle` but it seems to level off after some steps:\r\n\r\n![image](https://user-images.githubusercontent.com/4805513/42679991-0392b902-8684-11e8-9235-ec7c75720223.png)\r\n\r\n(Each increase corresponds to a new training phase.)\r\n\r\nAfter more investigation, this appears to be fixed by https://github.com/tensorflow/tensorflow/commit/3edb609926f2521c726737fc1efeae1572dc6581. However, I'm not sure about the availability of this change: GitHub says it's part of the `1.9.0rc2` tag but the commit is not on the `r1.9` branch?\r\n\r\nAnyway, I can confirm this is no more an issue in the current nightly package.", "Thanks @guillaumekln for pointing that out, with the latest tf-nightly I can confirm that this problem is gone! I can happily train and evaluate forever now.\r\n\r\n@robieta the input_fn was indeed called repeatedly for every train and evaluate cycle. With the new behavior, the input_fn is only called once for all train cycles, and repeatedly for the evaluate cycles.\r\n\r\nClosing as this seems to be solved by 3edb609.", "I meet similar question, under watching.", "I'm seeing a similar issue, and it seems to be [documented as expected behavior](https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate):\r\n`Note that in current implementation estimator.evaluate will be called multiple times. This means that evaluation graph (including eval_input_fn) will be re-created for each evaluate call. estimator.train will be called only once.`\r\n\r\nThe question is whether the graph and `eval_input_fn` are release/de-allocated after each call\r\n\r\nPs: I'm happy to move this discussion to a different place if it helps", "Dear @The-Fonz ,\r\nI got few questions need your help.\r\n- Do you mean that the problem could be solve by train_and_evaluate()? as you said, input_fn() will be called repeatedly while evaluate(), won't it be a leaking situation?\r\n- I meet the same issues when iterates train() and evaluate() separately, does anyone have idea how to solve the problem? (train_and_evaluate() seems not work with horovod multi gpu training so I iterate train() and evaluate() instead)", "Hi @chychen, has been some time since I worked on this but I recall that it was fixed and that you need to use `train_and_evaluate()` as it only runs `input_fn()` once, see comments above."]}, {"number": 20698, "title": "tf.keras multi input models don't work when using tf.data.Dataset", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.5 and Debian GNU/Linux 9 (stretch)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.9.0-rc2-359-g95cfd8b3d9 1.10.0-dev20180711 also reproduces on v1.9.0\r\n- **Python version**: 3.6.5 and 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: see below\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n`tf.keras` multi input models don't work when used together with `tf.data.Dataset` due to input broken validation checks. This problem reproduces both on tf@1.9.0 and the latest nightly.\r\n\r\n@fchollet Do you have any ideas what's going on here, or am I missing something obvious?\r\n\r\n### Source code / logs\r\n\r\n#### Multi input model\r\nConsider the following toy model:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ndata_a = np.array([300, 455, 350, 560, 700, 800, 200, 250], dtype=np.float32)\r\nlabels = np.array([455, 350, 560, 700, 800, 200, 250, 300], dtype=np.float32)\r\ndata_b = np.array([200, 255, 350, 470, 600, 300, 344, 322], dtype=np.float32)\r\ndata_a = np.reshape(data_a, (8, 1, 1))\r\ndata_b = np.reshape(data_b, (8, 1, 1))\r\n\r\nx = keras.layers.Input(shape=(1, 1), name='input_x')\r\ny = keras.layers.Input(shape=(1, 1), name='input_y')\r\nadmi = keras.layers.LSTM(40, return_sequences=False)(x)\r\npla = keras.layers.LSTM(40, return_sequences=False)(y)\r\nout = keras.layers.concatenate([admi, pla], axis=-1)\r\noutput = keras.layers.Dense(1, activation='sigmoid')(out)\r\nmodel = keras.models.Model(inputs=[x, y], outputs=output)\r\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n```\r\n\r\n#### Using `numpy` data\r\nWhen fitting using `numpy` data this works as expected when passing a list or dictionary of inputs:\r\n```python\r\nmodel.fit([data_a, data_b], labels, batch_size=2, epochs=10)\r\nmodel.fit({'input_x': data_a, 'input_y': data_b}, labels, batch_size=2, epochs=10)\r\n```\r\n#### Using `tf.data.Dataset.from_tensor_slices` dictionary\r\nWhen trying the same with a `tf.data.Dataset` the following fails due to incorrect input validation:\r\n```python\r\ndataset = tf.data.Dataset.from_tensor_slices(({'input_x': data_a, 'input_y': data_b}, labels)).batch(2).repeat()\r\nmodel.fit(dataset, epochs=10, steps_per_epoch=4)\r\n````\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-d35bacd274cc> in <module>()\r\n      1 dataset = tf.data.Dataset.from_tensor_slices(({'input_x': data_a, 'input_y': data_b}, labels)).batch(2).repeat()\r\n----> 2 model.fit(dataset, epochs=10, steps_per_epoch=4)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1276         steps_name='steps_per_epoch',\r\n   1277         steps=steps_per_epoch,\r\n-> 1278         validation_split=validation_split)\r\n   1279 \r\n   1280     # Prepare validation data.\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\r\n    915           feed_output_shapes,\r\n    916           check_batch_axis=False,  # Don't enforce the batch size.\r\n--> 917           exception_prefix='target')\r\n    918 \r\n    919       # Generate sample-wise weight values given the `sample_weight` and\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    180                            ': expected ' + names[i] + ' to have ' +\r\n    181                            str(len(shape)) + ' dimensions, but got array '\r\n--> 182                            'with shape ' + str(data_shape))\r\n    183         if not check_batch_axis:\r\n    184           data_shape = data_shape[1:]\r\n\r\nValueError: Error when checking target: expected dense to have 2 dimensions, but got array with shape (None,)\r\n```\r\n\r\n#### Using `tf.data.Dataset.from_generator` dictionary\r\nHowever using the same network together with `tf.data.Dataset.from_generator` works. Probably because less validation is done:\r\n```python\r\ndef generator():\r\n    while True:\r\n        for i in np.random.permutation(8):\r\n            yield {'input_x': data_a[i], 'input_y': data_b[i]}, labels[i]\r\n\r\ndataset = tf.data.Dataset.from_generator(generator, ({'input_x': tf.float32, 'input_y': tf.float32}, tf.float32)).batch(2)\r\nmodel.fit(dataset, epochs=10, steps_per_epoch=4)\r\n```\r\n\r\n#### Using `tf.data.Dataset` tuple\r\nPassing the multi-input as a tuple to the model both datasets generated with `from_tensor_slices` and `from_generator` fail:\r\n```python\r\ndataset = tf.data.Dataset.from_tensor_slices(((data_a, data_b), labels)).batch(2).repeat()\r\nmodel.fit(dataset, epochs=10, steps_per_epoch=4)\r\n```\r\n```python\r\ndef generator():\r\n    while True:\r\n        for i in np.random.permutation(8):\r\n            yield (data_a[i], data_b[i]), labels[i]\r\n\r\ndataset = tf.data.Dataset.from_generator(generator, ((tf.float32, tf.float32), tf.float32)).batch(2)\r\nmodel.fit(dataset, epochs=10, steps_per_epoch=4)\r\n```\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-7-512a95f0c2a7> in <module>()\r\n      1 dataset = tf.data.Dataset.from_tensor_slices(((data_a, data_b), labels)).batch(2).repeat()\r\n----> 2 model.fit(dataset, epochs=10, steps_per_epoch=4)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1276         steps_name='steps_per_epoch',\r\n   1277         steps=steps_per_epoch,\r\n-> 1278         validation_split=validation_split)\r\n   1279 \r\n   1280     # Prepare validation data.\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\r\n    876         feed_input_shapes,\r\n    877         check_batch_axis=False,  # Don't enforce the batch size.\r\n--> 878         exception_prefix='input')\r\n    879 \r\n    880     if y is not None:\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    141     data = data.values if data.__class__.__name__ == 'DataFrame' else data\r\n    142     data = [data]\r\n--> 143   data = [standardize_single_array(x) for x in data]\r\n    144 \r\n    145   if len(data) != len(names):\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in <listcomp>(.0)\r\n    141     data = data.values if data.__class__.__name__ == 'DataFrame' else data\r\n    142     data = [data]\r\n--> 143   data = [standardize_single_array(x) for x in data]\r\n    144 \r\n    145   if len(data) != len(names):\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in standardize_single_array(x)\r\n     79   elif tensor_util.is_tensor(x):\r\n     80     return x\r\n---> 81   elif x.ndim == 1:\r\n     82     x = np.expand_dims(x, 1)\r\n     83   return x\r\n\r\nAttributeError: 'tuple' object has no attribute 'ndim'\r\n```", "comments": ["I have the same problem and I  have also multiple input dataset. But not sure if this problem  caused by the multiple input datset. And I am using tensorflow 1.9 In order to be able to use dataset iterator in model.fit \r\n\r\nSo\r\n**1-**  If I do the following : \r\n\r\n`dataset = tf.data.TFRecordDataset(train.tf_records).map(_parse_function).batch(20).repeat()`\r\n`  model.fit(dataset) `\r\n\r\nI got : \r\n    `AttributeError: \"'RepeatDataset' object has no attribute 'ndim'\"`\r\n\r\n**2-** If I do the following : \r\n`dataset=tf.data.TFRecordDataset(train.tf_records).map(_parse_function).batch(20).repeat().make_initializable_iterator()`\r\n`  model.fit(dataset) `\r\n\r\nI got : \r\n    ` AttributeError: \"'Iterator' object has no attribute 'ndim'\"`\r\n\r\n**3-** If I do the following : \r\n`dataset=tf.data.TFRecordDataset(train.tf_records).map(_parse_function).batch(20).repeat().make_initializable_iterator().get_next()`\r\n`  model.fit(dataset) `\r\n\r\nI got : \r\n    ` AttributeError: \"'tuple' object has no attribute 'ndim'\"`\r\n \r\n**Note:**\r\nif I run get_next() for the iterator, it should give me data and label and other information I put it in tfrecords. So my input pair in  `iterator.get_next()[0]` , and labels in `iterator.get_next()[1]`. ", "I opened #20753 to fix the issues not related to multi input models.", "I could reproduce the error.", "Thanks for taking the time and reproducing it. Did you have a chance to checked out my fix in #20753?", "Theres also a related PR that adds support for using tuples as multi dim inputs: #20136", "My situation seems similar. The iterator of dataset fed to `model.fit` is made from `tf.data.Dataset.zip()`\r\n```python\r\nxy_ds = (\r\n        tf.data.Dataset.zip((audio_ds, label_ds))\r\n            .batch(\r\n            batch_size=batch_size,\r\n            # drop_remainder=True if is_training else False\r\n            )\r\n        .repeat(repeat)\r\n        .prefetch(tf.contrib.data.AUTOTUNE)\r\n    )\r\n```\r\nBoth `audio_ds` (input) and `label_ds` (output) are instances of `tf.data.TextLineDataset`.\r\n```python\r\ntf.data.TextLineDataset(id_path)\r\n            .map(load_audio, num_parallel_calls=N_READ_THREAD)\r\n```\r\nBefore fed to the model, its iterator is created.\r\n```python\r\ntr_iterator = tr_set.make_one_shot_iterator()\r\ntr_iterator.get_next()\r\n(<tf.Tensor 'IteratorGetNext:0' shape=<unknown> dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=<unknown> dtype=float32>)\r\n```\r\nAnd this is the error message when `model.fit()` is called.\r\n```python\r\n  File \"data_io.py\", line 127, in <module>\r\n    model.fit(\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 950, in fit\r\n    batch_size=batch_size)\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 749, in _standardize_user_data\r\n    exception_prefix='input')\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\", line 91, in standardize_input_data\r\n    data = [standardize_single_array(x) for x in data]\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\", line 91, in <listcomp>\r\n    data = [standardize_single_array(x) for x in data]\r\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\", line 26, in standardize_single_array\r\n    elif x.ndim == 1:\r\nAttributeError: 'Iterator' object has no attribute 'ndim'\r\n```\r\n\r\ntensorflow: 1.9.0, keras:2.2.2\r\n", "I think I discovered the problem fro my situation. The problem was I am using the standalone `Keras`. Not the one imported from `tendorflow.` So the new features of feeding the `iterator` directly to `model.fit() `is valid only when you are using` tf.Keras `not the standalone Keras. ", "@was84san Wow, same here, and now it seems solved. Thanks! ", "@lgeiger is this issue of passing multiple input to keras model vi tf.dataset api fixed?", "Hi, @was84san. \r\nAs you mentioned, I am using `tf.kera`. But the problem still exists. Do you have any idea? \r\nThanks!", "Which problem exactly!, feeding multiple inputs, or feeding the iterator directly to model.fit. I figure out only the last one. ", "@hhwxxx I was also unable to use `model.fit()` with a nested Dataset iterator for multi-input and multi-output models (while using `tf.keras`) on version 1.10. Installing `tf-gpu-nightly`  (my specific version is now `1.12.0-dev20180918`) seemed to resolve this problem for me.\r\n", "@gabrielibagon Could you post a snippet how you got a nested dataset iterator with multiple inputs working?", "The final example at [here](https://www.tensorflow.org/guide/datasets) is interesting:\r\n\r\n```\r\ndef dataset_input_fn():\r\n  filenames = [\"/var/data/file1.tfrecord\", \"/var/data/file2.tfrecord\"]\r\n  dataset = tf.data.TFRecordDataset(filenames)\r\n\r\n  # Use `tf.parse_single_example()` to extract data from a `tf.Example`\r\n  # protocol buffer, and perform any additional per-record preprocessing.\r\n  def parser(record):\r\n    keys_to_features = {\r\n        \"image_data\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n        \"date_time\": tf.FixedLenFeature((), tf.int64, default_value=\"\"),\r\n        \"label\": tf.FixedLenFeature((), tf.int64,\r\n                                    default_value=tf.zeros([], dtype=tf.int64)),\r\n    }\r\n    parsed = tf.parse_single_example(record, keys_to_features)\r\n\r\n    # Perform additional preprocessing on the parsed data.\r\n    image = tf.image.decode_jpeg(parsed[\"image_data\"])\r\n    image = tf.reshape(image, [299, 299, 1])\r\n    label = tf.cast(parsed[\"label\"], tf.int32)\r\n\r\n    return {\"image_data\": image, \"date_time\": parsed[\"date_time\"]}, label\r\n\r\n  # Use `Dataset.map()` to build a pair of a feature dictionary and a label\r\n  # tensor for each example.\r\n  dataset = dataset.map(parser)\r\n  dataset = dataset.shuffle(buffer_size=10000)\r\n  dataset = dataset.batch(32)\r\n  dataset = dataset.repeat(num_epochs)\r\n\r\n  # Each element of `dataset` is tuple containing a dictionary of features\r\n  # (in which each value is a batch of values for that feature), and a batch of\r\n  # labels.\r\n  return dataset\r\n```\r\n\r\nnow, how to define a model that accepts and trains correctly with that datase? Is the full example available somewhere?", "@JanRuettinger @ricoms Sorry for the delayed response.\r\n\r\nI drafted up a toy example using MNIST in order to train a model with two inputs and two outputs. The model is simply two identical models fused together, which takes in two copies of the MNIST data (two inputs) and outputs a prediction for each (two outputs). You can adapt this to more complex models and input pipelines.\r\n\r\n**Note**: This is still using  `tf-nightly-gpu` version `1.12.0-dev20180918`. I assume this will work in tensorflow 1.12 and above.\r\n\r\n```\r\nbatch_size = 512\r\n\r\n# -- Data Setup -- #\r\n(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\ny_train = tf.keras.utils.to_categorical(y_train)\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n# Create two inputs and two outputs (for demonstration)\r\nx_train1 = x_train2 = x_train\r\ny_train1 = y_train2 = y_train\r\n\r\n# -- Dataset API -- #\r\n# Create a Dataset for multiple inputs and Dataset for multiple outputs\r\ninput_set = tf.data.Dataset.from_tensor_slices((x_train1, x_train2))\r\noutput_set = tf.data.Dataset.from_tensor_slices((y_train1, y_train2))\r\n# Create Dataset pipeline\r\ninput_set = input_set.batch(batch_size).repeat()\r\noutput_set = output_set.batch(batch_size).repeat()\r\n# Group the input and output dataset\r\ndataset = tf.data.Dataset.zip((input_set, output_set))\r\n# Initialize the iterator to be passed to the model.fit() function\r\ndata_iter = dataset.make_one_shot_iterator()\r\n\r\n# -- Model Definition -- #\r\n# Multiple Inputs\r\ninput1 = tf.keras.layers.Input(shape=(28,28))\r\ninput2 = tf.keras.layers.Input(shape=(28,28))\r\n# Input 1 Pathway\r\nx1 = tf.keras.layers.Flatten()(input1)\r\nx1 = tf.keras.layers.Dense(512, activation=tf.nn.relu)(x1)\r\nx1 = tf.keras.layers.Dropout(0.2)(x1)\r\n# Input 2 Pathway\r\nx2 = tf.keras.layers.Flatten()(input2)\r\nx2 = tf.keras.layers.Dense(512, activation=tf.nn.relu)(x2)\r\nx2 = tf.keras.layers.Dropout(0.2)(x2)\r\n# Multiple Outputs\r\noutput1 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x1)\r\noutput2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(x2)\r\n# Create Model\r\nmodel = tf.keras.models.Model(inputs=[input1, input2], outputs=[output1, output2])\r\n# Compile\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\r\n\r\n# -- Train -- #\r\nmodel.fit(data_iter, steps_per_epoch=len(x_train)//batch_size, epochs=5)\r\n```\r\n\r\n**Update**: As @jashshopin mentions below, the `dataset` object can be passed directly to `model.fit()` if you have no need for an iterator.", "Is it necessary to use `dataset.make_one_shot_iterator()`?", "@jashshopin Thanks for pointing that out, apparently you can pass the zipped `dataset` directly into `model.fit()`. The example should still work for those who might want to use a one-shot iterator or initializable iterator as well.", "thanks, @gabrielibagon.\r\n\r\nI have something like that [here](https://github.com/ricoms/deep_memorability/blob/master/deep_memorability/trainer2/experiment.py)., although I used the keras generator format because I could not deal with a video input pipeline using tensorflow methods.\r\n\r\nI might refactor it to tf.Dataset someday but it's working for now. :)", "Nagging Assignee @fchollet: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This isn't an issue on tensorflow 1.12 and above anymore. Thanks for the help everybody.", "@ Igeiger, I tried to pass multiple inputs as a list of tf.dataset api to model fit directly,  like this\r\n`model.fit ( [dataset1_iterator, dataset2_iterator] , .....)`\r\n\r\nthen I got this error \r\n```\r\n\r\n /home/wassan/tensorflow/venv/lib/python2.7/site- \r\n packages/tensorflow/python/keras/engine/training.pyc in _standardize_user_data(self, x, y, sample_weight, cla$s_weight, batch_size, check_steps, steps_name, steps, validation_split)\r\n    990         x, y, sample_weight = next_element\r\n    991     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\r\n--> 992                                                      class_weight, batch_size)\r\n    993     return x, y, sample_weights\r\n    994 \r\n\r\n/home/wassan/tensorflow/venv/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc in _standardize_weights(self, x, y, sample_weight, class$weight, batch_size)\r\n   1115         feed_input_shapes,\r\n   1116         check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 1117         exception_prefix='input')\r\n   1118 \r\n   1119     if y is not None:\r\n\r\n/home/wassan/tensorflow/venv/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_utils.pyc in standardize_input_data(data, names, shapes, che$k_batch_axis, exception_prefix)\r\n    282     data = data.values if data.__class__.__name__ == 'DataFrame' else data\r\n    283     data = [data]\r\n--> 284   data = [standardize_single_array(x) for x in data]\r\n    285 \r\n    286   if len(data) != len(names):\r\n\r\n/home/wassan/tensorflow/venv/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_utils.pyc in standardize_single_array(x)\r\n    216   if x is None:\r\n    217     return None\r\n--> 218   if x.shape is not None and len(x.shape) == 1:\r\n    219     if tensor_util.is_tensor(x):\r\n    220       return array_ops.expand_dims(x, axis=1)\r\n\r\nAttributeError: 'PrefetchDataset' object has no attribute 'shape\r\n```\r\n\r\nAnd this is with tensorflow 1.12, so how you can pass multiple input using tf.dataset api with model fit not with model.fit_generator?\r\n`", "> @ Igeiger, I tried to pass multiple inputs as a list of tf.dataset api to model fit directly, like this\r\nmodel.fit ( [dataset1_iterator, dataset2_iterator] , .....)\r\n\r\nReturning a list of tensors in a single dataset and then passing it to `model.fit` should work. Checkout this example: https://colab.research.google.com/drive/1h3FUGBhVsXnj6oEE3JDnC0WRFF-Zu__c#scrollTo=cjvaKWOqAQ3e", "@lgeiger  what about using dictionaries as targets? https://github.com/tensorflow/tensorflow/issues/25299#issue-404556539", "I can confirm this works in tensorflow 2.0.0-rc0. Multiple input and output, even without all the zipping:\r\n```\r\n(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\r\n\r\nds = tf.data.Dataset.from_tensor_slices( ((train_images, dummydata), train_images) )\r\nds.shuffle(TRAIN_BUF).repeat().batch(BATCH_SIZE)\r\n\r\nmodel.fit(train_dataset, steps_per_epoch=n_trainsamples//BATCH_SIZE)\r\n```\r\n\r\n", "This still seems broken to me (in tensorflow 2.0.0-rc0). See this snippet:\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ninputs = [keras.Input((1,), name=\"a\"), keras.Input((1,), name=\"b\")]\r\noutputs = inputs[0] + inputs[1]\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n\r\nlist_input = [tf.zeros((10, 1)), tf.ones((10, 1))]\r\ndict_input = {\"a\": tf.zeros((10, 1)), \"b\": tf.ones((10, 1))}\r\n\r\nprint(model.predict(list_input))\r\nprint(model.predict(dict_input))\r\nprint(model.predict(tf.data.Dataset.from_tensors(dict_input)))\r\n\r\n# error here\r\nprint(model.predict(tf.data.Dataset.from_tensors(list_input)))\r\n```\r\nwhich gives\r\n```\r\nValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor: id=47, shape=(2, 10, 1), dtype=float32, numpy=\r\narray([[[0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.],\r\n        [0.]],...\r\n```", "@drasmuss \r\n\r\nworkaround could be to convert list to dictionary in Dataset \r\n\r\n\r\nds=tf.data.Dataset.from_tensors(list_input)\r\n\r\ndef to_dict(lst):\r\n    return {'a':lst[0], 'b':lst[1]}\r\n\r\nds=ds.map(to_dict)\r\n\r\nprint(model.predict(ds))\r\n", "> I think I discovered the problem fro my situation. The problem was I am using the standalone `Keras`. Not the one imported from `tendorflow.` So the new features of feeding the `iterator` directly to `model.fit() `is valid only when you are using`tf.Keras`not the standalone Keras.\r\n\r\nThx, my problem solved! Just have changed \r\n`import keras`\r\n`import tensorflow as tf`\r\nto \r\n`import tensorflow as tf`\r\n`from tensorflow import keras`\r\n", "I am not finding documentation for feeding models with multiple inputs with different dimensions with tf.data.  \r\nThe above exchange leaves me still struggling for an understanding on feeding such models.  May I asked for clarification?\r\n\r\n```\r\nprint(f\"tensoflow.__version__ = {tensorflow.__version__}\")\r\n# tensoflow.__version__ = 2.1.0-rc2\r\n\r\n# A toy keras model with 2 inputs of different size\r\ninput_1 = tensorflow.keras.layers.Input(name='input_1', shape=(2,), dtype=numpy.float32)\r\ninput_2 = tensorflow.keras.layers.Input(name='input_2', shape=(3,), dtype=numpy.float32)\r\noutput = tensorflow.keras.layers.Concatenate(name='output_1')([input_1, input_2])\r\ntoy_model = tensorflow.keras.Model(inputs=[input_1, input_2], outputs=[output])\r\ntoy_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n\r\n# in memory data, 2 samples for input_1\r\ninput_1_sample_1 = numpy.asarray ( [2,2], dtype=numpy.float32 )\r\ninput_1_sample_2 = numpy.asarray ( [22,22], dtype=numpy.float32 )\r\ninput_1_data = numpy.asarray( [ input_1_sample_1, input_1_sample_2 ] )\r\nprint(f\"input_1_data.shape = {input_1_data.shape}\")\r\n# input_1_data.shape = (2, 2)\r\n\r\n# in memory data, 2 samples for input_2\r\ninput_2_sample_1 = numpy.asarray ( [3,3,3], dtype=numpy.float32 )\r\ninput_2_sample_2 = numpy.asarray ( [33,33,33], dtype=numpy.float32 )\r\ninput_2_data = numpy.asarray( [ input_2_sample_1, input_2_sample_2 ] )\r\nprint(f\"input_2_data.shape = {input_2_data.shape}\")\r\n# input_2_data.shape = (2, 3)\r\n\r\n# in memory data, 2 samples for output 1\r\noutput_1_sample_1 = numpy.asarray( [2,2,3,3,3], dtype=numpy.float32 )\r\noutput_1_sample_2 = numpy.asarray( [22,22,33,33,33], dtype=numpy.float32 )\r\noutput_1_data = numpy.asarray( [ output_1_sample_1, output_1_sample_2], dtype=numpy.float32 )\r\nprint(f\"output_1_data.shape = {output_1_data.shape}\")\r\n# output_1_data.shape = (2, 5)\r\n\r\ndef toy_generator_list():\r\n    while True:\r\n        yield [input_1_data, input_2_data], output_1_data, []\r\n\r\n```\r\nI can use the generator directly, but my goal is to move the  generator to a full tf.data pipleline, but I am missing something fundamental to get started.\r\n\r\nThis works, but does not use tf.data:\r\n\r\n`toy_model.fit(x=toy_generator_list(), steps_per_epoch=3, epochs=2) `\r\n\r\nThe following as close to a solution I have gotten to, but it fails\r\n\r\n```\r\ntoy_dataset_from_generator = tensorflow.data.Dataset.from_generator(toy_generator_list, \\\r\n    output_types=(tensorflow.float32, tensorflow.float32, tensorflow.float32), \\\r\n        output_shapes=(([2,2],[2,3]), [2,5]) )\r\n\r\n\r\ntoy_model.fit(x=toy_dataset_from_generator, steps_per_epoch=3, epochs=2) \r\n```\r\n\r\nGenerates error \r\n\r\n`ValueError: The two structures don't have the same sequence length. Input structure has length 2, while the shallow structure has length 3.`\r\n\r\nI know that my request smells like \"a request for help\", it is, but please interpret it as a request for improved documentation.  Stack overflow does not have anything on multiple inputs of different shapes.\r\n\r\nbtw:\r\n- The real model input is an image (255, 255, 3) and a document type (20,) with output 1-hot(40, 60) into a ctc.\r\n- The ideal tf.data chain would cache the preliminary processing, then augment this cache version for delivery to model.fit, where the model is fit across a network of servers.\r\n\r\n\r\n\r\n\r\n\r\n", "@johngrabner \r\nThe problem in your code is that your `output_type` and `output_shape` definitions differ.\r\nChanging the `output_type` to `((tensorflow.float32, tensorflow.float32), tensorflow.float32)` should to the trick.\r\n\r\nFor the sake of completeness, here is a minimal example of a dataset that expects two inputs (shapes (1,32) and (1,128)):\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef random_generator():\r\n    for i in range(100):\r\n        x1, x2, y = np.random.random((1,32)), np.random.random((1,128)), np.random.random((1,1))\r\n        yield (x1, x2), y\r\n        \r\ntoy_dataset = tf.data.Dataset.from_generator(\r\n    random_generator,\r\n    output_types=((tf.float32, tf.float32), tf.float32),\r\n    output_shapes=(((1,32), (1,128)), (1,1))\r\n)\r\n```", "hey! guys.\r\nI have been in trouble, the error below was thrown when the model with double inputs predicted.\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"practice.py\", line 279, in <module>\r\n    action = np.argmax([0.1, 1, 0.2]*agent.get_qs(current_state))\r\n  File \"practice.py\", line 186, in get_qs\r\n    return self.model.predict(state)[0]\r\n  File \"C:\\Users\\liuzhen\\.conda\\envs\\python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1380, in predict\r\n    x, _, _ = self._standardize_user_data(x)\r\n  File \"C:\\Users\\liuzhen\\.conda\\envs\\python37\\lib\\site-packages\\keras\\engine\\training.py\", line 757, in _standardize_user_data\r\n    exception_prefix='input')\r\n  File \"C:\\Users\\liuzhen\\.conda\\envs\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 95, in standardize_input_data\r\n    data = [standardize_single_array(x) for x in data]\r\n  File \"C:\\Users\\liuzhen\\.conda\\envs\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 95, in <listcomp>\r\n    data = [standardize_single_array(x) for x in data]\r\n  File \"C:\\Users\\liuzhen\\.conda\\envs\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 30, in standardize_single_array\r\n    elif x.ndim == 1:\r\nAttributeError: 'list' object has no attribute 'ndim'\r\n```\r\nthe 'state' is a list of two nd-arrays there\r\n```python\r\nmodel = Model(inputs=[input1, input2], outputs=predictions)\r\n```\r\nI would really appreciate it if anyone is willing to give some tips", "hey!\r\n\r\nconsider trying this:\r\n\r\n```\r\nrelu = tf.keras.activations.relu;\r\nlayers = tf.keras.layers;\r\n\r\n## Input 1\r\n\r\ninputs = layers.Input(shape=(1)); # First input for 'data_a'\r\noutputs = layers.Dense(128, activation=relu)(inputs);\r\n\r\nmodel_data_a = tf.keras.Model(inputs, outputs); # Build 'model_data_a' for 'data_a'\r\n\r\n## Input 2\r\n\r\ninputs = layers.Input(shape=(1)); # Second input for 'data_b'\r\noutputs = layers.Dense(128, activation=relu)(inputs);\r\n\r\nmodel_data_b = tf.keras.Model(inputs, outputs); # Build 'model_data_b' for 'data_b'\r\n\r\n## Model\r\n\r\ninputs = layers.Concatenate()([model_data_a.output, model_data_b.output]); ### Get the outputs of 'model_data_a' , 'model_data_b' and combine the outputs  \r\noutputs = layers.Dense(1, activation=relu)(inputs);\r\n\r\nmodel = tf.keras.Model([model_data_a.input, model_data_b.input], outputs); ## Add both inputs\r\n\r\n## Compile and fit the model\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\r\n              loss=tf.keras.losses.mae,\r\n              metrics=tf.keras.metrics.mse);\r\n\r\nmodel.fit([data_a, data_b], labels, epochs=5);\r\n```\r\nhope this helps!"]}, {"number": 20697, "title": "terminate called after throwing an instance of 'std::bad_alloc'", "body": "```\r\n2018-07-11 09:31:19.563525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-07-11 09:31:19.564174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.721\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.93GiB freeMemory: 7.55GiB\r\n2018-07-11 09:31:19.564193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-07-11 09:31:20.828223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-07-11 09:31:20.829019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0\r\n2018-07-11 09:31:20.829029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N\r\n2018-07-11 09:31:20.839815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7296 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce"]}, {"number": 20696, "title": "ValueError when loading multiple tf.contrib.keras models in the same scope at different times", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version**: N/A\r\n- **CUDA/cuDNN version**: CUDA 7.5, cuDNN 9.0\r\n- **GPU model and memory**: GTX1080 (8GB)\r\n- **Exact command to reproduce**: See [**this snippet**](https://gist.github.com/Sergio0694/aa36c7ed94091ce5503ad908b142aaf0)\r\n\r\n### Describe the problem\r\nTensorFlow throws a `ValueError: You are trying to load a weight file containing 16 layers into a model with 0 layers` when trying to create multiple instances of a pretrained Keras model from within the same scope. This only happens if the instances are created one at a time, reopening the same scope multiple times, and works if all the instances are created consecutively, after opening the scope a single time.\r\n\r\nOf course, in a real world scenario these instances are created from different places and not all at the same time while building the model, so one would actually need to reopen that scope multiple times.\r\nHope this helps and that the snippet is clear enough!\r\n\r\n### Source code / logs\r\nSee [**this snippet**](https://gist.github.com/Sergio0694/aa36c7ed94091ce5503ad908b142aaf0), same one posted under system information.\r\n\r\nHere's the stack trace for the snippet above:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/sergio/Documents/code/keras_repro.py\", line 21, in <module>\r\n    vgg2 = load_vgg19(t)\r\n  File \"/home/sergio/Documents/code/keras_repro.py\", line 12, in load_vgg19\r\n    m = tf.contrib.keras.applications.VGG19(weights='imagenet', include_top=False, input_tensor=x)\r\n  File \"/home/sergio/.local/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/applications/vgg19.py\", line 234, in VGG19\r\n    model.load_weights(weights_path)\r\n  File \"/home/sergio/.local/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/network.py\", line 1190, in load_weights\r\n    saving.load_weights_from_hdf5_group(f, self.layers)\r\n  File \"/home/sergio/.local/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/saving.py\", line 697, in load_weights_from_hdf5_group\r\n    ' layers.')\r\nValueError: You are trying to load a weight file containing 16 layers into a model with 0 layers.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "Done \ud83d\udc4d\r\nNot sure how to trigger the bot to re-check the message, or if it's just automatic @tensorflowbutler ", "Looks related to https://github.com/tensorflow/tensorflow/issues/20073", "This is fixed with tf-nightly version '1.15.0-dev20190726'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=20696\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=20696\">No</a>\n"]}, {"number": 20695, "title": "TF1.9 - Wheels for Python 3.6 (Linux) are missing on PyPi", "body": "The following wheel files are missing on PyPi:\r\n\r\ntensorflow: \r\n- tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl\r\n\r\ntensorflow_gpu:\r\n- tensorflow_gpu-1.9.0-cp36-cp36m-manylinux1_x86_64.whl", "comments": ["I have the same issue ! \r\n\r\nOn PyPI: https://pypi.org/project/tensorflow/#files\r\n\r\n![image](https://user-images.githubusercontent.com/10923599/42576014-d6934e20-8521-11e8-8821-03062c566c42.png)\r\n\r\n", "\ud83d\udc4d ", "Mike could you take a look?", "Thanks for bringing this to our attention. Should be fixed now. Thanks!"]}, {"number": 20694, "title": "tf.contrib.quantize bug: errors within weights/activations quantization", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, provided\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: - \r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: python quantization_test.py (file provided)\r\n\r\n### Describe the problem\r\n**tf.contrib.quantize** (experimental and non-experimental) automatic quantization produce close to but not quantized results as when you manually introduce fakequant operations.\r\nWeights and/or activations are close to the quantized values, but they are not correct.\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\nD_SIZE = 2048\r\nBATCH_SIZE = 128\r\nLR = 1e-2\r\nEPOCHS = 2000\r\n\r\nSHOW_INTERVAL = 20\r\nOUT_CH = 8\r\n\r\n\r\ndef create_dummy_model(is_training=True):\r\n    # prepare dataset\r\n    np_features = np.arange(-int(D_SIZE) / 2, int(D_SIZE / 2))\r\n    features_arr = tf.constant(np_features, dtype=tf.float32)\r\n    np_labels = np.zeros((D_SIZE, OUT_CH), dtype=float)\r\n    print(np_labels.shape)\r\n    for i in range(OUT_CH):\r\n        np_labels[:, i] = 2 * (i + 1) * np_features\r\n    print('np_features:')\r\n    print(np_features[0:8])\r\n    print('np_labels:')\r\n    print(np_labels[0:8])\r\n\r\n    labels_arr = tf.constant(np_labels, dtype=tf.float32)\r\n    trn_data = tf.data.Dataset.zip(\r\n        (tf.data.Dataset.from_tensor_slices(features_arr),\r\n         tf.data.Dataset.from_tensor_slices(labels_arr))\r\n    )\r\n    trn_data = trn_data.shuffle(D_SIZE)\r\n    trn_data = trn_data.batch(BATCH_SIZE)\r\n    trn_data = trn_data.repeat(1)\r\n    trn_data = trn_data.prefetch(1)\r\n\r\n    iterator = tf.data.Iterator.from_structure(trn_data.output_types,\r\n                                               trn_data.output_shapes)\r\n    features, labels = iterator.get_next()\r\n    data_init_op = iterator.make_initializer(trn_data)\r\n\r\n    # global step\r\n    global_step = tf.train.get_or_create_global_step()\r\n\r\n    # simple model dense, WITH ACTIVATION TO TEST QUANTIFICATION\r\n    input = tf.reshape(features, (BATCH_SIZE, 1))\r\n    flow = tf.identity(input, name='input_tensor')\r\n    # batch_size x INPUT_CH\r\n    flow = tf.reshape(flow, (-1, 1))\r\n    flow = tf.layers.dense(flow, units=OUT_CH, name='dense')\r\n    flow = tf.reshape(flow, (-1, OUT_CH), name='out')\r\n\r\n    # Build forward pass of model.\r\n    # Make the loss op\r\n    with tf.variable_scope('loss'):\r\n        tf.logging.debug('[loss] size of out: %s',\r\n                         flow.get_shape().as_list())\r\n        power = tf.pow(labels - flow, 2)\r\n        power = tf.reduce_sum(power, 1)\r\n        # power = tf.reduce_sum(power)\r\n        loss = tf.reduce_mean(power, name='m_loss')\r\n    tf.summary.scalar('loss', loss)\r\n\r\n    # Optimizer\r\n    if is_training:\r\n        opt_op = tf.train.AdamOptimizer(LR).minimize(loss, global_step)\r\n        # opt_op = tf.train.GradientDescentOptimizer(1e-4).minimize(loss, global_step)\r\n    else:\r\n        opt_op = False\r\n    # Merge all the summaries\r\n    merged = tf.summary.merge_all()\r\n\r\n    return {\r\n        'iterator': iterator,\r\n        'features': features,\r\n        'labels': labels,\r\n        'data_init_op': data_init_op,\r\n        'global_step': global_step,\r\n        'flow': flow,\r\n        'loss': loss,\r\n        'opt_op': opt_op,\r\n        'merged': merged\r\n    }\r\n\r\n\r\ndef quantize_tensor(np_array, n_bits):\r\n    \"\"\"Quantizes an np_array\"\"\"\r\n    min_wt = np.min(np_array)\r\n    max_wt = np.max(np_array)\r\n    # clap values if required\r\n    if min_wt < -2**(n_bits-1):\r\n        min_wt = -2**(n_bits-1)\r\n    if max_wt > (2**(n_bits-1) - 1) :\r\n        max_wt = (2**(n_bits-1) - 1)\r\n    # find number of integer bits to represent this range\r\n    int_bits = int(np.ceil(np.log2(max(abs(min_wt), abs(max_wt)))))\r\n    print('int_bits: ', int_bits)\r\n    # remaining bits are fractional bits (1-bit for sign)\r\n    frac_bits = n_bits -1 - int_bits\r\n    # floating point weights are scaled and rounded to [-128,127], which are used in\r\n    # the fixed-point operations on the actual hardware (i.e., microcontroller)\r\n    quantized = np.round(np_array * (2**frac_bits))\r\n    # To quantify the impact of quantized weights, scale them back to\r\n    # original range to run inference using quantized weights\r\n    return quantized / (2**frac_bits)\r\n\r\n\r\ndef train_quantization(quantize=True, w_b=3, a_b=3):\r\n\r\n    g_tr = tf.Graph()\r\n    with g_tr.as_default():\r\n\r\n        model = create_dummy_model(True)\r\n\r\n        # Call the training rewrite which rewrites the graph in-place with\r\n        # FakeQuantization nodes and folds batchnorm for training. It is\r\n        # often needed to fine tune a floating point model for quantization\r\n        # with this training tool. When training from scratch, quant_delay\r\n        # can be used to activate quantization after training to converge\r\n        # with the float graph, effectively fine-tuning the model.\r\n        if quantize:\r\n            quant_delay = int((D_SIZE / BATCH_SIZE) * EPOCHS * 3 / 4)\r\n            print('quant_delay: ', quant_delay)\r\n            print('w_b: ', w_b)\r\n            print('a_b: ', a_b)\r\n            tf.contrib.quantize.experimental_create_training_graph(weight_bits=w_b,\r\n                                                                   activation_bits=a_b,\r\n                                                                   quant_delay=quant_delay)\r\n\r\n        with tf.Session(graph=g_tr) as sess:\r\n            # global variables Initializing\r\n            sess.run(tf.global_variables_initializer())\r\n            # local variables Initializing\r\n            sess.run(tf.local_variables_initializer())\r\n\r\n            if quantize:\r\n                train_writer = tf.summary.FileWriter(\r\n                    './tmp/train_quantized_w' + str(w_b) + '_a_' + str(a_b),\r\n                    sess.graph)\r\n            else:\r\n                train_writer = tf.summary.FileWriter('./tmp/train_normal',\r\n                                                     sess.graph)\r\n\r\n            epoch_counter = 0\r\n            nn_in = None\r\n            nn_out = None\r\n            nn_loss = None\r\n            for epoch_counter in range(EPOCHS):\r\n\r\n                # re-initialize the dataset iterator\r\n                sess.run(model['data_init_op'])\r\n\r\n                try:\r\n                    while True:\r\n                        _, nn_in, nn_out, nn_labels, nn_loss, gs, summary = sess.run(\r\n                            [model['opt_op'],\r\n                             model['features'],\r\n                             model['flow'],\r\n                             model['labels'],\r\n                             model['loss'],\r\n                             model['global_step'],\r\n                             model['merged']])\r\n\r\n                        # tensorboard and  statistics\r\n                        train_writer.add_summary(summary, gs)\r\n                except tf.errors.OutOfRangeError:\r\n                    # do nothing\r\n                    if epoch_counter % SHOW_INTERVAL == 0:\r\n                        print(epoch_counter,  '/', EPOCHS,\r\n                              ': loss ', nn_loss,\r\n                              '. Global step: ', gs)\r\n\r\n            weights = sess.run(tf.get_default_graph().get_tensor_by_name(\r\n                'dense/kernel:0'))\r\n            saver = tf.train.Saver()\r\n            if quantize:\r\n                trained_model_path = './tmp/quantized_w' + \\\r\n                    str(w_b) + '_a_' + str(a_b) + '.ckpt'\r\n            else:\r\n                trained_model_path = './tmp/normal.ckpt'\r\n\r\n            saver.save(sess, trained_model_path)\r\n\r\n        # debug\r\n        print('nn_out shape: ', nn_out.shape)\r\n        print('nn_labels shape: ', nn_labels.shape)\r\n        print('nn_out different values in OUT_CH (', OUT_CH, ') elements:',\r\n              len(np.unique(nn_out)))\r\n        print('weights shape: ', weights.shape)\r\n        print('weights: ', weights)\r\n        print('weights different values in OUT_CH (', OUT_CH, ') elements:',\r\n              len(np.unique(weights)))\r\n\r\n        plt.plot(nn_in[:], nn_out[:, 0], label='nn_out',\r\n                 marker='o', markersize=5)\r\n        plt.plot(nn_in[:], nn_labels[:, 0], label='labels',\r\n                 marker='*', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n        plt.plot(nn_in[:], nn_out[:, 5], label='nn_out',\r\n                 marker='o', markersize=5)\r\n        plt.plot(nn_in[:], nn_labels[:, 5], label='labels',\r\n                 marker='*', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n\r\n        plt.plot(weights[0, :], label='weights',\r\n                 marker='o', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n\r\n        print('[debug] exit training')\r\n        return trained_model_path\r\n\r\n\r\ndef inference_quantization(trained_model_path, quantize=True, w_b=3, a_b=3):\r\n\r\n    #################################\r\n    # Reset default graph\r\n    tf.reset_default_graph()\r\n    #################################\r\n\r\n    g_inf = tf.Graph()\r\n    with g_inf.as_default():\r\n\r\n        model = create_dummy_model(False)\r\n\r\n        with tf.Session(graph=g_inf) as sess:\r\n            # Call the eval rewrite which rewrites the graph in-place with\r\n            # FakeQuantization nodes and fold batchnorm for eval.\r\n            if quantize:\r\n                print('w_b: ', w_b)\r\n                print('a_b: ', a_b)\r\n                tf.contrib.quantize.experimental_create_eval_graph(\r\n                    weight_bits=w_b,\r\n                    activation_bits=a_b)\r\n\r\n            saver = tf.train.Saver()\r\n            saver.restore(sess, trained_model_path)\r\n            # frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n            #       sess, sess.graph_def, [\"out\"])\r\n            print('[debug] restored')\r\n\r\n            # re-initialize the iterator, but this time with training data\r\n\r\n            sess.run(model['data_init_op'])\r\n\r\n            nn_in, nn_out, nn_labels, nn_loss = sess.run([\r\n                model['features'],\r\n                model['flow'],\r\n                model['labels'],\r\n                model['loss']])\r\n            weights = sess.run(tf.get_default_graph(\r\n            ).get_tensor_by_name('dense/kernel:0'))\r\n\r\n        # debug\r\n        print('nn_out shape: ', nn_out.shape)\r\n        print('nn_labels shape: ', nn_labels.shape)\r\n        print('nn_out different values in OUT_CH (', OUT_CH, ') elements:',\r\n              len(np.unique(nn_out)))\r\n        print('weights shape: ', weights.shape)\r\n        # print('weights: ', weights)\r\n        print('weights different values in OUT_CH (', OUT_CH, ') elements:',\r\n              len(np.unique(weights)))\r\n        print('weights: ', weights)\r\n        q_weights = quantize_tensor(weights, w_b)\r\n        print('q_weights: ', q_weights)\r\n        plt.plot(nn_in[:], nn_out[:, 0], label='nn_out',\r\n                 marker='o', markersize=5)\r\n        plt.plot(nn_in[:], nn_labels[:, 0], label='labels',\r\n                 marker='*', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n        plt.plot(nn_in[:], nn_out[:, 5], label='nn_out',\r\n                 marker='o', markersize=5)\r\n        plt.plot(nn_in[:], nn_labels[:, 5], label='labels',\r\n                 marker='*', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n\r\n        plt.plot(weights[0, :], label='weights',\r\n                 marker='o', markersize=5)\r\n        plt.legend(loc='lower right')\r\n        plt.show()\r\n\r\n\r\ndef test_quantization():\r\n\r\n    # train_quantization(False)\r\n    trained_model_path = train_quantization(quantize=True, w_b=2, a_b=2)\r\n    inference_quantization(\r\n        trained_model_path=trained_model_path, quantize=True, w_b=2, a_b=2)\r\n\r\ntest_quantization()\r\n```\r\n\r\n", "comments": ["Nagging Assignees @suharshs, @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is because the FakeQuant operations do more than just quantize. First its very important that floating point 0.0 maps directly to a quantized value, otherwise padding errors can propagate. This nudging can be seen here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fake_quant_ops_functor.h#L41\r\n\r\nAlso we restrict the weight values to being quantized from [1,255] instead of [0,255] to enable a ARM Neon optimization for our kernels.\r\n\r\nThus, this is working as intended, please do reopen and correct me if I am misunderstanding or mistaken.", "Dear @suharshs , thank you for your response, but I don't think I can relate your information to the problem I am concerned with: both after a training operation and more especially, after the inference operation, weights and activations can acquire more values than those quantized.\r\nTo summarize, the weights/activations acquire more values than those that they should, 2^b bits.\r\n\r\nIt is my understanding that the expected behavior should be that the maximum number of values they can be map to should be less or equal 2^b bits.\r\nIf you manually place a FakeQuant operation after a tensor, the  quantization takes place correctly. Therefore I would expect the same for the whole graph quantization.\r\n\r\nIn the code above, you can see the problem with\r\n\r\n```\r\n        print('weights different values in OUT_CH (', OUT_CH, ') elements:',\r\n              len(np.unique(weights)))\r\n```\r\n\r\nThank you", "@suharshs , @poxvoculi , \r\nDue to Github flow, I cannot reopen the issue, so I would appreciate if you could consider my previous comment and reopen the issue. \r\n\r\nThank you", "Are your sure you are running the FakeQuant nodes after the weights. The weights will still retain their full precision but the output fo the following FakeQuant will emulate the correct quantization. So make sure for each weight you are actually checking the 'weight_quant/FakeQuantWithMinMaxVars' operation following it.", "You were completely right. only the Bias nodes were not quantized.\r\nThanks."]}, {"number": 20693, "title": "tf.train.MonitoredTrainingSession get error when data is large", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac 10.13.5\r\n- **TensorFlow installed from (source or binary)**: pip install --upgrade tensorflow\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**:  2.7.10\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nwith tf.train.MonitoredTrainingSession(master=server.target, is_chief=(FLAGS.task_index == 0),\r\n                                               hooks=[saver_hooks],\r\n                                               config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True,\r\n                                                                     log_device_placement=True)) as sess:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nIt is a distributed model, there are 1 ps and 10 worker.\r\nWhen train with low-dimensional model, everything is fine.\r\nBut if trained with high-dimensional model, the error occur and traceback shows it happen in tf.train.MonitoredTrainingSession.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n18/07/10 18:44:02 INFO XLearningContainer: weights/truncated_normal/mean: (Const): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: weights/truncated_normal/shape: (Const): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: weights/random_uniform/max: (Const): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: weights/random_uniform/min: (Const): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: weights/random_uniform/shape: (Const): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: input/Placeholder_1: (Placeholder): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: input/Placeholder: (Placeholder): /job:worker/replica:0/task:2/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: train/Adagrad/value: (Const): /job:ps/replica:0/task:0/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: global_step/Initializer/zeros: (Const): /job:ps/replica:0/task:0/device:CPU:0\r\n18/07/10 18:44:02 INFO XLearningContainer: Traceback (most recent call last):\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"location_embedding_tf.py\", line 203, in <module>\r\n18/07/10 18:44:02 INFO XLearningContainer:     tf.app.run(main=main)\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n18/07/10 18:44:02 INFO XLearningContainer:     _sys.exit(main(argv))\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"location_embedding_tf.py\", line 90, in main\r\n18/07/10 18:44:02 INFO XLearningContainer:     log_device_placement=True)) as sess:\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 370, in MonitoredTrainingSession\r\n18/07/10 18:44:02 INFO XLearningContainer:     stop_grace_period_secs=stop_grace_period_secs)\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 816, in __init__\r\n18/07/10 18:44:02 INFO XLearningContainer:     stop_grace_period_secs=stop_grace_period_secs)\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 539, in __init__\r\n18/07/10 18:44:02 INFO XLearningContainer:     self._sess = _RecoverableSession(self._coordinated_creator)\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1002, in __init__\r\n18/07/10 18:44:02 INFO XLearningContainer:     _WrappedSession.__init__(self, self._create_session())\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1007, in _create_session\r\n18/07/10 18:44:02 INFO XLearningContainer:     return self._sess_creator.create_session()\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 696, in create_session\r\n18/07/10 18:44:02 INFO XLearningContainer:     self.tf_sess = self._session_creator.create_session()\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 509, in create_session\r\n18/07/10 18:44:02 INFO XLearningContainer:     max_wait_secs=self._max_wait_secs\r\n18/07/10 18:44:02 INFO XLearningContainer:   File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 421, in wait_for_session\r\n18/07/10 18:44:02 INFO XLearningContainer:     \"Session was not ready after waiting %d secs.\" % (max_wait_secs,))\r\n18/07/10 18:44:02 INFO XLearningContainer: tensorflow.python.framework.errors_impl.DeadlineExceededError: Session was not ready after waiting 7200 secs.\r\n18/07/10 18:44:03 ERROR XLearningContainer: XLearningContainer run failed!", "comments": ["Nagging Assignee @angersson: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "I meet the same requestion, did you resole it ?"]}, {"number": 20692, "title": "ImportError: cannot import name 'build_info' when using command import tensorflow as tf", "body": "I can successfully follow the tutorial of installing tensorflow (CPU version) with Anaconda yesterday. However, after trying to apply the GPU version and download CUDA9.0, CuDNN v7.1.4 for CUDA9.0, suddenly everything gets wrong,,,\r\n\r\n![default](https://user-images.githubusercontent.com/41112671/42566657-d220b842-8539-11e8-8ad1-c475621cee5c.PNG)\r\n\r\n\r\nPLEASE CAN ANYONE HELP ME...T_T  I am new to it as I work for it new because of my final year project.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I'm not sure how this happened, but it sounds like a messed up installation.\r\nNote that the `conda` packages are community supported (see https://www.tensorflow.org/install/install_linux#use_pip_in_anaconda).\r\n\r\nCould you use `pip` instead?", "@asimshankar thank you for your reply! I am so happy that people are so helpful!! \r\nI solve the problem by deleting the tensorflow folder in my C:\\user\\myusername and download it again and now the GPU version work for me!\r\n\r\nHowever, when I follow the Simple Audio Recognition tutorial from https://www.tensorflow.org/tutorials/sequences/audio_recognition to the last step, I need to run these command \"python tensorflow/examples/speech_commands/freeze.py \\\r\n--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000 \\\r\n--output_file=/tmp/my_frozen_graph.pb\"\r\n\r\nWhen I just enter \"python tensorflow/examples/speech_commands/freeze.py \\\" my cmd got python error and show OP_REQUIRES failed at save_restore_tensor.cc:170 : Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on : Unknown: FindFirstFile failed for: ./Application Data : \u5b58\u53d6\u88ab\u62d2\u3002\r\n; Input/output error\r\n\r\nWhat does it mean? Can anyone help me please!!\r\n\r\n\r\n", "@polariskying,\r\n\r\nCan you confirm if you're still facing the issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20692\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20692\">No</a>\n"]}]