[{"number": 23149, "title": "Remove the unnecessary namespace aliases", "body": "This PR removes some namespace aliases in `dataset.h` as the related files have been moved over to the `tensorflow::data` namespace.", "comments": ["Nagging Reviewer @mrry, @wt-huang: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "Sorry for the delay on responding to this. We need to keep these aliases for now, because there are certain third-party users of the C++ `Dataset` API that will break if we remove them. Since there's no ETA on when that will cease to be the case, I'm going to close this PR for now."]}, {"number": 23148, "title": "Doc Request: Better Documentation for TFRecords", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.11.0\r\n- Doc Link: NA\r\n\r\n\r\n**Describe the documentation issue**\r\nWith the introduction of `tf.data` and deprecation of `QueueRunner`, TFRecords seem to play a major role if you want to effeciently use accelerators while training on large datasets. Unfortunately, the current `tf.data` [documentation](https://www.tensorflow.org/guide/datasets) starts off assuming we already have `TFRecords` on disk without even linking how we could convert images, say `tiny imagenet` or even arbitrary images to the `TFRecord`s format. \r\n\r\nTo be precise, there is no documentation for `TFRecord` , `TFExample` or even the readers and writers. Moreover, the examples do not cover how these things would work in eager execution mode. It would be great if these could be fixed as it would improve adoption of TFRecords and help more people use the tf.data pipelines.\r\n\r\nPS, I am aware of code examples in the repo such as [1](https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/research/deeplab/datasets/build_voc2012_data.py) and [2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py) but would prefer to have better documentation and maybe a guide for this. \r\n\r\nThanks\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** no\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Related to this issue [Request: Better documentation on TFRecords and their use](https://github.com/tensorflow/tensorflow/issues/1749) .", "Since the `awaiting response` label is still applied\r\nHave I written custom code: N/A\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\nMobile device: N/A", "Hi @gokul-uf, \r\n\r\nThere is a new tutorial for this in review right now.\r\n\r\nhttps://colab.sandbox.google.com/github/raskutti/docs/blob/master/site/en/tutorials/load_data/tf-records.ipynb\r\n\r\nTry it out, and add comments to the pr if anything is unclear:\r\n\r\nhttps://github.com/tensorflow/docs/pull/130\r\n\r\n\r\n", "We desperately need some simple documentation describing what the TFRecord format actually is. If you cannot use an existing writer / reader, it's very hard to find any notes on how to create or how to read the format yourself. Maybe I'm missing something obvious in the existing documentation, but searches for a description just lead me to a multitude of blog posts.\r\n\r\n[A description like this](https://en.wikipedia.org/wiki/Portable_Network_Graphics#File_format) would be incredibly helpful when building tools that interact with TFRecords outside of a TensorFlow environment", "Added, WDYT?\r\n"]}, {"number": 23146, "title": "The same code which is fine on Android 6.0.1, but an error(\"The model is not a valid Flatbuffer file\") is reported on Android 8.0.0", "body": "**OS Platform and Distribution**\r\nWin 10\r\nAndroid Studio 3.0.1\r\nsdk version 26\r\n**TensorFlow installed from**\r\nN/A\r\n**TensorFlow version**\r\nN/A\r\n**Bazel version**\r\nN/A\r\n**CUDA/cuDNN version**\r\nN/A\r\n**GPU model and memory**\r\nN/A\r\n**Exact command to reproduce**\r\nN/A\r\n**Mobile devic**\r\nHuawei Honor 8 & Gome K1\r\n\r\n**Describe the problem**\r\nI am using the TFLite demo for Android. Since there are two ways to initialize an Interpreter with a model file:\r\nThe Interpreter can be initialized with a model file using the constructor:\r\n`public Interpreter(@NotNull File modelFile);`\r\nor with a MappedByteBuffer:\r\n`public Interpreter(@NotNull MappedByteBuffer mappedByteBuffer);`\r\nThe official TFLite demo uses the second way(MappedByteBuffer) to initialize an Interpreter. I change it to the first way(using File) and The modified code is as follows(the constructor of ImageClassifier):\r\n```\r\n//tflite = new Interpreter(loadModelFile(activity));  //official code. The second way to initialize.\r\nFile modelFile = new File(\"/storage/emulated/0/DCIM/\" + getModelPath());   //the first way\r\ntflite = new Interpreter(modelFile);            //the first way\r\n```\r\nWhen I run it on Gome K1 mobile phone(Android 6.0.1), it works fine. However, when I run it on Huawei Honor 8(Android 8.0.0), an error occurred:\r\n`java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.tflite_pure/com.example.tflite_pure.MainActivity}: java.lang.IllegalArgumentException: Contents of /storage/emulated/0/DCIM/mobilenet_v1_1.0_224.tflite does not encode a valid TensorFlowLite model: Could not open '/storage/emulated/0/DCIM/mobilenet_v1_1.0_224.tflite'.The model is not a valid Flatbuffer file`\r\n\r\nI am not sure if this problem is caused by different versions of Android(6.0.1 vs 8.0.0). So any help would grateful. Thanks.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Thanks, The problem description has been updated according to the issue template.", "Did you verify that the file is on the same path on both phones ?", "This is likely an issue with storage access and permission changes. I would recommend using the MappedByteBuffer path on Android."]}, {"number": 23145, "title": "Could not initialize a memory descriptor when using softmax layer", "body": "I have both CPU and GPU version installed by Miniconda, each with a unique environment. While GPU version works fine, the CPU version seems to throw an error when I try to add a softmax layer after a convolution layer.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Manjaro 4.14.74\r\n- TensorFlow installed from (source or binary): binary from Miniconda\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: Python 3.6.6 :: Anaconda, Inc.\r\n- CUDA/cuDNN version: CPU version, no CUDA/cuDNN\r\n- Bazel version: N/A\r\n- GPU model and memory: N/A\r\n- Mobile device: N/A\r\n- Exact command to reproduce: python code.py\r\n\r\n**Describe the current behavior**\r\n\r\nRun the test code, the program throws AbortedError, info is:\r\n\r\n```\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:163\r\n\t [[{{node Softmax}} = _MklSoftmax[T=DT_FLOAT, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/BiasAdd, conv2d/BiasAdd:2)]]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe program should finish with no error.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nsess = tf.Session()\r\ninputs = tf.placeholder(dtype=tf.float32, shape=(1, 300, 300, 3))\r\nnet = tf.layers.Conv2D(filters=2, kernel_size=3)(inputs)\r\nnet = tf.nn.softmax(net, axis=-1)\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(net, feed_dict={inputs: np.zeros(shape=(1, 300, 300, 3), dtype=np.float32)})\r\n```\r\n\r\n**Other info / logs**\r\n\r\n* I set up the environment by ```conda create -n xxx pip python=3 tensorflow```\r\n\r\n* Traceback is:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:163\r\n         [[{{node Softmax}} = _MklSoftmax[T=DT_FLOAT, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/BiasAdd, conv2d/BiasAdd:2)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 10, in <module>\r\n    sess.run(net, feed_dict={inputs: np.zeros(shape=(1, 300, 300, 3), dtype=np.float32)})\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:163\r\n         [[{{node Softmax}} = _MklSoftmax[T=DT_FLOAT, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/BiasAdd, conv2d/BiasAdd:2)]]\r\n\r\nCaused by op 'Softmax', defined at:\r\n  File \"test.py\", line 7, in <module>\r\n    net = tf.nn.softmax(net, axis=-1)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1746, in softmax\r\n    return _softmax(logits, gen_nn_ops.softmax, axis, name)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1685, in _softmax\r\n    return compute_op(logits, name=name)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7138, in softmax\r\n    \"Softmax\", logits=logits, name=name)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/home/kwy/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:163\r\n         [[{{node Softmax}} = _MklSoftmax[T=DT_FLOAT, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/BiasAdd, conv2d/BiasAdd:2)]]\r\n```\r\n\r\n* GPU version works fine.\r\n\r\n* If i set axis to 0, 1 or 2, the program finishes with no error, but with it set to  -1 or 3, the error occurs.\r\n\r\n* If the softmax layer is added after a dense layer, it also works fine.\r\n\r\n* I've also tested on another server with CentOS 7 and a Quadro P2000, the problem still occurs. (GPU version works fine while CPU version not)\r\n\r\n* This code still not work:\r\n```\r\nnet = tf.layers.Conv2D(filters=2, kernel_size=3, activation=tf.nn.softmax)(inputs)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nGPU model and memory\nExact command to reproduce\nMobile device", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Bazel version\r\n> GPU model and memory\r\n> Exact command to reproduce\r\n> Mobile device\r\n\r\n* Bazel version: N/A\r\n* GPU model and memory: N/A\r\n* Mobile device: N/A\r\n* Exact command to reproduce: python code.py\r\n\r\nThanks.", "@kawaiiQ Please refer to #17494.", "@kawaiiQ  - Hi, please feel free to close this issue if this no longer exists. If the problem still persists, request you to submit all the information asked by the tensorflowbutler. Thank you !", "\r\nI swiched to system python3, and it seems the problem has disappeared. However, the problem still exists on Anaconda.\r\nAnd I think I have submitted all the required information.", "I can reproduce this on my system, with Tensorflow 1.11.0 and Python 3.6.7 :: Anaconda, Inc. \r\nHowever, code.py can successfully run with Python 3.5.6 :: Anaconda, Inc. ", "@kawaiiQ @ikarth : The conda binaries are not built by the TensorFlow maintainers, but by the Anaconda folks. According to [their recent blog post](https://www.anaconda.com/blog/developer-blog/tensorflow-in-anaconda/) those builds require Intel's MKL libraries.\r\n\r\nThe error message suggests that there is something amiss with the MKL initialization.\r\n\r\n@wei-v-wang @tatianashp - Any quick ideas here?", "Thanks @kawaiiQ for reporting and the reproducer and for trying TF w/ MKL-DNN. \r\nThanks @asimshankar for including me. I could reproduce the error with build from src with TF v1.11 w/ MKL-DNN, so we take the responsibility to fix the bug. Please stay tuned. Thank you! \r\n\r\nEigen will exit silently (i.e. no error). TF w/ MKL-DNN errors out with the above error. \r\n", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "@wei-v-wang @kawaiiQ \r\nwere you able to solve this? I'm using python 3.6.5 and tensorflow 1.9\r\n", "@appyfizzA this bug seems to be fixed with latest TF. Can you please try? \r\n@TensorFlow-MKL please help confirm/double check on this. Thank you!", "@wei-v-wang @appyfizzA \r\nI've just tried it using python 3.6.8 and tensorflow 1.12.0 on CentOS, Windows10 and WSL(based on Debian), all installed using the lastest Miniconda.\r\nIt seems that Windows version works fine, but Linux (CentOS and Debian) version still not work.", "Yes it's definitely broken from 1.6 to 1.12, we gave up building with MKL here ", "BTW I uploaded on one of the MKL related bug a snippet producing the issue if I recall correctly", "@eLvErDe sorry for the issues. Indeed 1.12 the issue is there. \r\nThe good news is I have tested, e.g. this commit id: 07d5d08579bbbff910653a59163b4f8f180d16ac (master branch, tagged with v1.13.0-rc2  v1.13.0-rc1 v1.13.0-rc0), that the issue is gone. Can you please try one last time with this commit id with MKL? \r\n\r\nBelow is what I got: \r\n\r\n2019-02-25 00:20:09.309341: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n2019-02-25 00:20:09.335924: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nWARNING:tensorflow:From TF_Public_07d5d08579bbbff910653a59163b4f8f180d16ac/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n\r\ni.e. No errors were thrown. ", "> @eLvErDe sorry for the issues. Indeed 1.12 the issue is there.\r\n> The good news is I have tested, e.g. this commit id: [07d5d08](https://github.com/tensorflow/tensorflow/commit/07d5d08579bbbff910653a59163b4f8f180d16ac) (master branch, tagged with v1.13.0-rc2 v1.13.0-rc1 v1.13.0-rc0), that the issue is gone. Can you please try one last time with this commit id with MKL?\r\n> \r\n> Below is what I got:\r\n> \r\n> 2019-02-25 00:20:09.309341: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n> 2019-02-25 00:20:09.335924: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n> WARNING:tensorflow:From TF_Public_07d5d08579bbbff910653a59163b4f8f180d16ac/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Colocations handled automatically by placer.\r\n> \r\n> i.e. No errors were thrown.\r\n\r\nSorry for my late reply. I've tried the latest version and the problem is fixed. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=23145\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=23145\">No</a>\n", "Yes it's fixed with 1.13 but again, I'd like to get commit id fixing the issue, it would make sense for us to backport the fix to 1.11....", "Hi Adam @eLvErDe , sorry for the delay. But this PR fixed the issue: https://github.com/tensorflow/tensorflow/pull/24057 \r\n\r\nThe exact commit id is: https://github.com/tensorflow/tensorflow/commit/15deae5c7957861f912b12cce47956c979f2c11c \r\n\r\nPlease confirm if the above resolves your issue completely. Thanks!"]}, {"number": 23144, "title": "Update the tests and benchmark for tf.data.Dataset.list_files", "body": "This PR uses [MatchingFilesDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L2702) to replace `matching_files` in  `tf.data.Dataset.list_files`. Besides, it adds a benchmarking test and changes some variable names to be more readable in the test file.\r\n\r\nHere is the benchmarking results:\r\n\r\n`list_files` with `matching_files`:\r\n```\r\nNested directory size (width*depth): 1024*16 Median wall time: 10.502532s (read first filename), 0.000377s (read second filename), avg 0.000147s (read 2046 more filenames)\r\nentry {\r\n  name: \"ListFilesDatasetBenchmark.benchmark_list_files_dataset_nesteddirectory(1024*16)\"\r\n  iters: 3\r\n  wall_time: 10.803346157073975\r\n  extras {\r\n    key: \"avg time for reading 2046 more filenames:\"\r\n    value {\r\n      double_value: 0.00014684125708228565\r\n    }\r\n  }\r\n  extras {\r\n    key: \"read first file:\"\r\n    value {\r\n      double_value: 10.502532243728638\r\n    }\r\n  }\r\n  extras {\r\n    key: \"read second file:\"\r\n    value {\r\n      double_value: 0.00037670135498046875\r\n    }\r\n  }\r\n}\r\n```\r\n`list_files` with `MatchingFilesDataset`:\r\n```\r\nNested directory size (width*depth): 1024*16 Median wall time: 0.039578s (read first filename), 0.001617s (read second filename), avg 0.001562s (read 2046 more filenames)\r\nentry {\r\n  name: \"ListFilesDatasetBenchmark.benchmark_list_files_dataset_nesteddirectory(1024*16)\"\r\n  iters: 3\r\n  wall_time: 3.2369956970214844\r\n  extras {\r\n    key: \"avg time for reading 2046 more filenames:\"\r\n    value {\r\n      double_value: 0.0015619748498687297\r\n    }\r\n  }\r\n  extras {\r\n    key: \"read first file:\"\r\n    value {\r\n      double_value: 0.03957796096801758\r\n    }\r\n  }\r\n  extras {\r\n    key: \"read second file:\"\r\n    value {\r\n      double_value: 0.0016171932220458984\r\n    }\r\n  }\r\n}\r\n```\r\n ", "comments": ["@mrry As `MatchingFilesDataset` could not well support the uniform shuffle, I remove the update of `list_files`. Now, this PR adds a benchmark test and revises two variable names `full_filenames` -> `expected_filenames` and `produced_filenames` -> `actual_filenames`(as suggested by @jsimsa in another PR) to be more readable. Could you please help review it when you have time? ", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@jsimsa any chance to take a look?", "The benchmark tests have been moved to a separated folder, which causes the file conflicts in this PR. So I split this PR into two small PRs #24085 and #24087. This PR will be closed.  "]}, {"number": 23142, "title": "CAN'T BUILD TENSORFLOW", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):WINDOWS 7 64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.11\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: PIP\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:  not using\r\n- GPU model and memory:\r\n\r\n\r\n\r\nI cant build tensorflow because happens some error about@png_archive\r\n\r\n`C:\\Users\\00\\tensorflow>bazel build --config=opt //tensorflow/tools/pip_package:\r\nuild_pip_package\r\nWARNING: Processed legacy workspace file c:\\users\\00\\tensorflow/tools/bazel.rc.\r\nThis file will not be processed in the next release of Bazel. Please read https\r\n//github.com/bazelbuild/bazel/issues/6319 for further information, including ho\r\n to upgrade.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nLoading:\r\nLoading: 0 packages loaded\r\nINFO: Build options have changed, discarding analysis cache.\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: comando n\u251c\u00fao encontrado\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: comando n\u251c\u00fao encontrado\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: comando n\u251c\u00fao encontrado\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: comando n\u251c\u00fao encontrado\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nINFO: 0 processes.\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (0 packages\r\noaded)\r\nERROR: C:/users/00/tensorflow/tensorflow/core/platform/default/build_config/BUI\r\nD:188:1: no such package '@png_archive//': Traceback (most recent call last):\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 106\r\n                _apply_patch(ctx, ctx.attr.patch_file)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 73, in _apply_\r\natch\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/users/00/tensorflow/third_party/repo.bzl\", line 52, in _execut\r\n_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'E:\\MSYS2\\usr\\bin\\bash.exe -l -c patch\r\n-p1 -d C:/users/00/_bazel_00/xjibpket/external/png_archive -i C:/users/00/tenso\r\nflow/third_party/png_fix_rpi.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\n and referenced by '//tensorflow/core/platform/default/build_config:png'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fa\r\nled; build aborted: Analysis failed\r\nINFO: Elapsed time: 9,864s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n`\r\n", "comments": ["Seems like you don't have the `patch` command installed", "You should use pacman to install patch of msys2 and should ensure that the path to patch is available. msys2 should use the path of the system", "I installed patch with pacman , but it still not working..\r\n\r\n`1 error detected in the compilation of \"C:/Users/00/AppData/Local/Temp/nvcc_inter_files_tmp_dir/extract_image_patches_op_gpu.cu.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 427,427s, Critical Path: 77,24s\r\nINFO: 368 processes: 368 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\nC:\\Users\\00\\tensorflow>`\r\n\r\n\r\nEdit1:\r\nIf i install tensorflow only cpy through pip , it works perfectly", "I think this is a duplicate issue, assigning to @meteorcloudy, who took a look at the other ones.", "@WagnerCaetano Can you show me the exact compilation error?", "Compilation Error: https://pastebin.com/WtdtJNke", "Looks like you are encountering https://github.com/tensorflow/tensorflow/issues/19198", "We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.5  version or later and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23142\">No</a>\n"]}, {"number": 23141, "title": "1.12.0-rc2 cherry-pick request: Support fp16 types in ScatterNd GPU version", "body": "PiperOrigin-RevId: 217749577", "comments": []}, {"number": 23140, "title": "openrave gives me segfaults", "body": "Hello Everyone. First of all I have to apologize if my question may not be clear. Because I'm a newbie in Ubuntu.  I tried to install pymanoid package and I was using openrave to test Inverse Kinematic example. After everything was installed correctly when I opened Inverse Kinematic python example I could see the robot but there was something that I thought was an error in terminal:\r\n[0;34mIn [[1;34m1[0;34m]: [0m\r\n\r\nI searched about it and someone was suggesting to install lib32ncurses5-dev. After that whenver I open the same python file(IK example) I get segmentation fault and I can't solve the problem. I tried to remove lib32ncurses5-dev and its dependencies, but still I have the same problem. \r\nDoes anyone know how can I fix it?\r\n\r\nThis is what happens:\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 2.4.1 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\nSegmentation fault (core dumped)\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@mohamadmahdavian Hi, we request you to post this issue in the relevant github repository as this repo is for Tensorflow related issues. If you think this is a tensorflow issue, please provide further details as asked by tensorflowbutler. Thank you !"]}, {"number": 23139, "title": "1.12.0-rc2 cherry-pick request: Async checkpointing: Save the graph in a background thread.", "body": "PiperOrigin-RevId: 217747382", "comments": []}, {"number": 23138, "title": "1.12.0-rc2 cherry-pick request: Fix triggering of asynchronous checkpoints.", "body": "PiperOrigin-RevId: 217570792", "comments": []}, {"number": 23137, "title": "`ImportError: No module named 'tensorboardX'`", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux dlvm 4.9.0-8-amd64 #1 SMP Debian 4.9.110-3+deb9u5 (2018-09-30) x86_64 GNU/Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nGoogle Cloud VM\r\n- TensorFlow installed from (source or binary):\r\npip3 install --upgrade tensorflow\r\n- TensorFlow version: 1.11.0\r\n- Python version: 3.5.3\r\n- Installed using virtualenv? pip? conda?: pip3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\n\r\nTrying to import the tensorboardX module in a cell within Python 3 Jupyter Notebook\r\n`from tensorboardX import SummaryWriter`\r\n\r\nReceived the following error:\r\n`ImportError: No module named 'tensorboardX'`\r\n\r\nRan a `pip3 freeze` to check if the packages were installed:\r\n```\r\ntensorboard==1.11.0\r\ntensorboardX==1.4\r\ntensorflow==1.11.0\r\n```\r\n", "comments": ["Have you tried posting this https://github.com/lanpa/tensorboardX ? \r\nIsn't tensorboardX for pyTorch?", "Yes, i did -thank you\n\nOn Sat, Oct 20, 2018 at 7:17 PM Imran Paruk <notifications@github.com>\nwrote:\n\n> Have you tried posting this https://github.com/lanpa/tensorboardX ?\n> Isn't tensorboardX for pyTorch?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23137#issuecomment-431632790>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AhpqQCWfXeWWWIKu_ToJ8QzUSj-PDRhtks5um9kmgaJpZM4XyLsT>\n> .\n>\n\n\n-- \n--------------------------------------------\nQ: Why is this email three sentences or less?\nA: http://three.sentenc.es\n", "@edtky since this isn't Tensorflow related could you close this?"]}, {"number": 23136, "title": "Estimators Siamese Model Peformance Issue ", "body": "tf.esitmators producing poor performance vs TF & Keras.  \r\n\r\n* System information\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n    TensorFlow installed from (source or binary):\r\n    pip3 install --upgrade tensorflow-gpu==1.12.0-rc1\r\n    TensorFlow version: 1.12.0-rc1\r\n    Python version: Python 3.6.5 \r\n    Installed using virtualenv? pip? conda?: pip3\r\n    CUDA/cuDNN version: 9.0 / 7.0.5\r\n    GPU model and memory: nvidia gtx 1050 (Lenovo Laptop)\r\n\r\n* Code to reproduce performance issue:\r\n\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom keras.datasets import mnist\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nimport random\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef cnn_cnn_model(features, reuse=False):\r\n    \"\"\"Model function for CNN.\"\"\"\r\n\r\n    # Flat 1\r\n    flat_1 = tf.layers.flatten(\r\n        features,\r\n        name=\"flattern\",\r\n    )\r\n\r\n    # dense 1\r\n    dense_1 = tf.layers.dense(\r\n        flat_1,\r\n        1024,\r\n        activation=tf.nn.relu,\r\n        reuse=reuse,\r\n        name='dense_1',\r\n    )\r\n\r\n    # drop 1\r\n    drop_1 = tf.layers.dropout(\r\n        dense_1,\r\n        rate=0.1,\r\n        name=\"drop_1\",\r\n    )\r\n\r\n    # dense 2\r\n    dense_2 = tf.layers.dense(\r\n        drop_1,\r\n        512,\r\n        activation=tf.nn.relu,\r\n        reuse=reuse,\r\n        name='dense_2',\r\n    )\r\n\r\n    # drop 2\r\n    drop_2 = tf.layers.dropout(\r\n        dense_2,\r\n        rate=0.1,\r\n        name=\"drop_2\",\r\n    )\r\n\r\n    # dense 3\r\n    dense_3 = tf.layers.dense(\r\n        drop_2,\r\n        128,\r\n        activation=None,\r\n        reuse=reuse,\r\n        name='dense_3',\r\n    )\r\n\r\n    return dense_3\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n\r\n    return tf.metrics.mean(tf.equal(y_true, tf.cast(y_pred < tf.cast(0.5, 'float64'), y_true.dtype)))\r\n\r\ndef compute_accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    pred = y_pred.ravel() < 0.5\r\n    return np.mean(pred == y_true)\r\n\r\n\r\ndef my_loss(dist, y_true, margin=1.0):\r\n\r\n    y_true = tf.cast(y_true, 'float64')\r\n    margin = tf.cast(margin, 'float64')\r\n    dist = tf.cast(dist, 'float64')\r\n\r\n    # Loss function\r\n    loss_pos = tf.multiply(y_true, tf.pow(dist, 2), name='constrastive_loss_1')\r\n    loss_neg = tf.multiply(tf.subtract(tf.cast(1.0, 'float64'), y_true),\r\n                           tf.pow(tf.maximum(tf.subtract(margin, dist), 0), 2),\r\n                           name='constrastive_loss_2')\r\n    loss = tf.reduce_mean(tf.add(loss_neg, loss_pos), name='constrastive_loss')\r\n\r\n    return loss\r\n\r\n\r\ndef euclidean_distance(x1, x2):\r\n    x1 = tf.cast(x1, 'float64')\r\n    x2 = tf.cast(x2, 'float64')\r\n    epsilon = tf.cast(1e-7, 'float64')\r\n\r\n    eucd2 = tf.pow(tf.subtract(x1, x2), 2, name='eucd2')\r\n    eucd2 = tf.reduce_sum(eucd2, 1)\r\n\r\n    eucd2 = tf.maximum(eucd2, epsilon)\r\n    eucd = tf.sqrt(eucd2, name='eucd')\r\n\r\n    return eucd\r\n\r\n\r\n\r\ndef create_siamese(features, labels, mode):\r\n    # Input Layers\r\n    input_layer_a = tf.reshape(features[\"x_1\"], [-1, 28, 28])\r\n    input_layer_b = tf.reshape(features[\"x_2\"], [-1, 28, 28])\r\n\r\n    with tf.variable_scope(\"siamese\") as scope:\r\n\r\n        network_a = cnn_cnn_model(input_layer_a, reuse=False)\r\n        network_b = cnn_cnn_model(input_layer_b, reuse=True)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        dist = euclidean_distance(network_a, network_b)\r\n        loss = my_loss(dist, labels)\r\n\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n        train_op = optimizer.minimize(\r\n            loss=loss,\r\n            global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n    elif mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            \"eucl\": euclidean_distance(network_a, network_b)\r\n        }\r\n\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n\r\ndef create_pairs(x, digit_indices, num_classes):\r\n    '''Positive and negative pair creation.\r\n    Alternates between positive and negative pairs.\r\n    '''\r\n    pairs = []\r\n    labels = []\r\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\r\n    for d in range(num_classes):\r\n        for i in range(n):\r\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\r\n            pairs += [[x[z1], x[z2]]]\r\n            inc = random.randrange(1, num_classes)\r\n            dn = (d + inc) % num_classes\r\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\r\n            pairs += [[x[z1], x[z2]]]\r\n            labels += [1, 0]\r\n    return np.array(pairs), np.array(labels)\r\n\r\ndef main(unused_argv):\r\n\r\n    path_ = '/media/imran/bigboy/datasets/my_smallVoxCeleb/updated_datasets/split_datasets/3d_cnn/smallest_dataset.hdf5'\r\n    num_classes = 10\r\n\r\n    # the data, split between train and test sets\r\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n    x_train = x_train.astype('float64')\r\n    x_test = x_test.astype('float64')\r\n    y_train = y_train.astype('float64')\r\n    y_test = y_test.astype('float64')\r\n\r\n\r\n    x_train /= 255\r\n    x_test /= 255\r\n\r\n    # create training+test positive and negative pairs\r\n    digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\r\n    tr_pairs, tr_y = create_pairs(x_train, digit_indices, num_classes)\r\n\r\n    digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\r\n    te_pairs, te_y = create_pairs(x_test, digit_indices, num_classes)\r\n\r\n\r\n    # Create the Estimator\r\n    mnist_classifier = tf.estimator.Estimator(\r\n      model_fn=create_siamese)\r\n\r\n    # Train the model\r\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n      x={\"x_1\": tr_pairs[:, 0],\r\n         \"x_2\": tr_pairs[:, 1]},\r\n      y=tr_y,\r\n      batch_size=128,\r\n      num_epochs=1,\r\n      shuffle=True)\r\n\r\n    test_input_fn_train = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"x_1\": tr_pairs[:, 0],\r\n           \"x_2\": tr_pairs[:, 1]},\r\n        shuffle=False\r\n       )\r\n\r\n    test_input_fn_test = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"x_1\": te_pairs[:, 0],\r\n           \"x_2\": te_pairs[:, 1]},\r\n        shuffle=False\r\n       )\r\n\r\n    mnist_classifier.train(\r\n        input_fn=train_input_fn,\r\n        steps=None)\r\n\r\n    predictions_test = list(mnist_classifier.predict(input_fn=test_input_fn_test))\r\n    predictions_train = list(mnist_classifier.predict(input_fn=test_input_fn_train))\r\n\r\n    preds_test = []\r\n    for item in predictions_test:\r\n        preds_test.append(item['eucl'])\r\n\r\n    preds_train = []\r\n    for item in predictions_train:\r\n        preds_train.append(item['eucl'])\r\n\r\n    print(\"Accuracy on train set: \", compute_accuracy(tr_y, np.array(preds_train)))\r\n    print(\"Accuracy on test set: \", compute_accuracy(te_y, np.array(preds_test)))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```\r\n\r\nWith Keras model.fit(), this yields:\r\n```\r\nAccuracy on training set: 95.70%\r\nAccuracy on test set: 95.33%\r\n```\r\nWith TF this yields:\r\n```\r\nAccuracy on training set: 94.56%\r\nAccuracy on test set: 94.53%\r\n```\r\nWith tf.estimators this yields:\r\n```\r\nAccuracy on training set: 61.32%\r\nAccuracy on test set: 62.74%\r\n```\r\n\r\nThe code for the benchmark code for Keras and TF can be found here:\r\n+ Keras:\r\nhttps://gist.github.com/imranparuk/25963eb3b2db1540ead684271de6f5a8\r\n+ TF:\r\nhttps://gist.github.com/imranparuk/4fe48323a006ff030bf2037136db7868\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nExact command to reproduce\nMobile device", "@tensorflowbutler \r\n+ Have I written custom code: Yes, provide above\r\n+ Bazel version: N/A\r\n+ Exact command to reproduce: N/A\r\n+ Mobile device: N/A\r\n", "Apologies for the delay in response. Is this still an issue?\r\nIn order to expedite the trouble-shooting process, please provide a minimal code snippet to reproduce the issue reported here. Thanks!\r\n", "I've moved my code to pytorch, so yeah my issue is solved."]}, {"number": 23135, "title": "start Jupyter Notebook in nightly-devel tag", "body": "When running `docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-devel` the docker runs in bash. How can I run the same tag but with Jupyter notebook as in the Dockerfile 'cpu-devel-jupyter.Dockerfile'?", "comments": []}, {"number": 23134, "title": "AttributeError: 'CuDNNLSTM' object has no attribute '_num_inputs' | Tflite", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 (I think), I used the nightly docker: \r\ndocker run --runtime=nvidia -it tensorflow/tensorflow:nightly-gpu-py3 bash\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): docker:\r\ndocker run --runtime=nvidia -it tensorflow/tensorflow:nightly-gpu-py3 bash\r\n- TensorFlow version (use command below): nightly (v1.12.0-rc0-1214-g6802f29084' 1.13.0-dev20181020)\r\n- Python version: py3\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: \r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI am trying to convert a model.h5 keras model using tflite. Command used: \r\n`tflite_convert --output_file=./model_tflite --keras_model_file=./model.h5\r\n`\r\nError: \r\n`root@7580fbf40640:/DNA_Compression/encoder_decoder# tflite_convert --output_file=./model_tflite --keras_model_file=./model.h5\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 412, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 408, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 100, in _convert_model\r\n    converter = _get_toco_converter(flags)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 87, in _get_toco_converter\r\n    return converter_fn(**converter_kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 368, in from_keras_model_file\r\n    keras_model = _keras.models.load_model(model_file)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\r\n    model = model_from_config(model_config, custom_objects=custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 340, in from_config\r\n    model.add(layer)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 474, in _method_wrapper\r\n    method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 175, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/recurrent.py\", line 706, in __call__\r\n    self._num_inputs)\r\nAttributeError: 'CuDNNLSTM' object has no attribute '_num_inputs'\r\n`\r\n**Describe the expected behavior**\r\nIdeally there should be no error, as it is a model which works fine in keras (TF backend)\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`root@7580fbf40640:/DNA_Compression/encoder_decoder# tflite_convert --output_file=./model_tflite --keras_model_file=./model.h5'\r\n(I can upload the model somewhere, if needed!)\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "@kedartatwawadi  -  Hi, thanks for the post. Please refer #20878", "@kedartatwawadi  -  Hi, is this still an issue ?", "I am able to run the TFLite tool (using the nightly build) with FullyConnected layers. But, on adding embedding and LSTM layers, TFLite is giving issues. are LSTMs currently unsupported? \r\n\r\nMy model details: \r\n\r\n`       model = Sequential()\r\n        model.add(Embedding(alphabet_size, 32, batch_input_shape=(bs, time_steps)))\r\n        model.add(Bidirectional(CuDNNLSTM(32, stateful=False, return_sequences=True)))\r\n        model.add(Bidirectional(CuDNNLSTM(32, stateful=False, return_sequences=False)))\r\n        model.add(Dense(64, activation='relu'))\r\n        model.add(Dense(alphabet_size, activation='softmax'))`", "LSTMs are currently hard to convert, we are actively working on this. We have a workaround here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/unidirectional_sequence_lstm_test.py \r\nWill close this issue since this is the current path, but future simpler paths will be added. Thanks!"]}, {"number": 23133, "title": "Keras to Estimators Siamese Issue", "body": "Hi there, I wounder if anyone could assist me. Forgive me if this isn't the correct place for this or it is not in the perfect format...\r\n\r\nI am trying to convert the Keras Siamese example into an estimator, however it does not seem to be working...\r\n\r\n* System information\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n    TensorFlow installed from (source or binary):\r\n    pip3 install --upgrade tensorflow-gpu==1.12.0-rc1\r\n    TensorFlow version: 1.12.0-rc1\r\n    Python version: Python 3.6.5 \r\n    Installed using virtualenv? pip? conda?: pip3\r\n    CUDA/cuDNN version: 9.0 / 7.0.5\r\n    GPU model and memory: nvidia gtx 1050 (Lenovo Laptop)\r\n\r\n```python\r\n'''Trains a Siamese MLP on pairs of digits from the MNIST dataset.\r\nIt follows Hadsell-et-al.'06 [1] by computing the Euclidean distance on the\r\noutput of the shared network and by optimizing the contrastive loss (see paper\r\nfor mode details).\r\n# References\r\n- Dimensionality Reduction by Learning an Invariant Mapping\r\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\r\nGets to 97.2% test accuracy after 20 epochs.\r\n2 seconds per epoch on a Titan X Maxwell GPU\r\n'''\r\nfrom __future__ import absolute_import\r\nfrom __future__ import print_function\r\nimport numpy as np\r\n\r\nimport random\r\nimport tensorflow as tf\r\n#from tf.keras.models import Sequential  # This does not work!\r\nfrom tensorflow.python.keras.datasets import mnist\r\n\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, Callback\r\nfrom tensorflow.python.keras.utils import HDF5Matrix, to_categorical\r\nfrom tensorflow.python.keras.losses import categorical_crossentropy\r\nfrom tensorflow.python.keras.optimizers import RMSprop\r\nfrom tensorflow.python.keras import backend as K\r\n\r\nnum_classes = 10\r\nepochs = 20\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef euclidean_distance(vects):\r\n    x, y = vects\r\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\r\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\r\n\r\n\r\ndef eucl_dist_output_shape(shapes):\r\n    shape1, shape2 = shapes\r\n    return (shape1[0], 1)\r\n\r\n\r\ndef contrastive_loss(y_true, y_pred):\r\n    '''Contrastive loss from Hadsell-et-al.'06\r\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\r\n    '''\r\n    margin = 1\r\n    sqaure_pred = K.square(y_pred)\r\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\r\n    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\r\n\r\n\r\ndef create_pairs(x, digit_indices):\r\n    '''Positive and negative pair creation.\r\n    Alternates between positive and negative pairs.\r\n    '''\r\n    pairs = []\r\n    labels = []\r\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\r\n    for d in range(num_classes):\r\n        for i in range(n):\r\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\r\n            pairs += [[x[z1], x[z2]]]\r\n            inc = random.randrange(1, num_classes)\r\n            dn = (d + inc) % num_classes\r\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\r\n            pairs += [[x[z1], x[z2]]]\r\n            labels += [1, 0]\r\n    return np.array(pairs), np.array(labels)\r\n\r\n\r\ndef create_base_network(input_shape):\r\n    '''Base network to be shared (eq. to feature extraction).\r\n    '''\r\n\r\n    input = Input(shape=input_shape)\r\n    x = Flatten()(input)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    return Model(input, x)\r\n\r\n\r\ndef compute_accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    pred = y_pred.ravel() < 0.5\r\n    return np.mean(pred == y_true)\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\r\n\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\ninput_shape = x_train.shape[1:]\r\n\r\n# create training+test positive and negative pairs\r\ndigit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\r\ntr_pairs, tr_y = create_pairs(x_train, digit_indices)\r\n\r\ndigit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\r\nte_pairs, te_y = create_pairs(x_test, digit_indices)\r\n\r\n\r\n# network definition\r\nbase_network = create_base_network(input_shape)\r\n\r\ninput_a = Input(shape=input_shape, name='input_a')\r\ninput_b = Input(shape=input_shape, name='input_b')\r\n\r\n# because we re-use the same instance `base_network`,\r\n# the weights of the network\r\n# will be shared across the two branches\r\nprocessed_a = base_network(input_a)\r\nprocessed_b = base_network(input_b)\r\n\r\ndistance = Lambda(euclidean_distance,\r\n                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\r\n\r\nmodel = Model([input_a, input_b], distance)\r\n\r\n# train\r\nrms = RMSprop()\r\nmodel.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\r\n\r\n# model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\r\n#           batch_size=128,\r\n#           epochs=1,\r\n#           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\r\n\r\nestimata = tf.keras.estimator.model_to_estimator(keras_model=model)\r\n\r\n\r\ninput_name1 = model.input_names[0]\r\ninput_name2 = model.input_names[1]\r\n\r\n\r\n\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={input_name1: tr_pairs[:,0],\r\n           input_name2: tr_pairs[:,1]},\r\n        y=tr_y,\r\n        batch_size=128,\r\n        num_epochs=1,\r\n        shuffle=True)\r\n#\r\nestimata.train(\r\n    input_fn=train_input_fn,\r\n    steps=None)  # ,\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={input_name1: te_pairs[:, 0],\r\n       input_name2: te_pairs[:, 1]},\r\n    y=te_y,\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\neval_results = estimata.evaluate(input_fn=eval_input_fn)\r\n\r\n# compute final accuracy on training and test sets\r\ny_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\r\ntr_acc = compute_accuracy(tr_y, y_pred)\r\n\r\ny_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\r\nte_acc = compute_accuracy(te_y, y_pred)\r\n\r\nprint('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\r\nprint('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\r\n```\r\n\r\nWith Keras model.fit(), this yields:\r\n```\r\nAccuracy on training set: 95.70%\r\nAccuracy on test set: 95.33%\r\n```\r\n\r\nHowever With Estimators tf.estimator.train() the results are much worse:\r\n```\r\nAccuracy on training set: 53.11%\r\nAccuracy on test set: 53.80%\r\n```", "comments": ["Is this mainly the [Shared vision](https://github.com/keras-team/keras/blob/master/docs/templates/getting-started/functional-api-guide.md#shared-vision-model) approach? ", "It looks quite similar, however that approch uses a soft-max on layer output merge. In the Siamese paper I read they use euclidean distance, I have this function from the Keras Siamese example code:\r\n\r\n```python\r\ndef euclidean_distance(vects):\r\n    x, y = vects\r\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\r\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\r\n```", "@imranparuk I modified your Keras Siamese code and tf.estimator.train() works as expected. Here are the accuracy results:\r\n```\r\n* Accuracy on training set: 95.86%\r\n* Accuracy on test set: 95.71%\r\n```\r\n\r\nCode to produce the above results:\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import print_function\r\nimport numpy as np\r\n\r\nimport random\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python import keras\r\nfrom keras.models import Sequential  \r\nfrom tensorflow.python.keras.datasets import mnist\r\n\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, Callback\r\nfrom tensorflow.python.keras.utils import HDF5Matrix, to_categorical\r\nfrom tensorflow.python.keras.losses import categorical_crossentropy\r\nfrom tensorflow.python.keras.optimizers import RMSprop\r\nfrom tensorflow.python.keras import backend as K\r\n\r\nnum_classes = 10\r\nepochs = 20\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef euclidean_distance(vects):\r\n    x, y = vects\r\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\r\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\r\n\r\n\r\ndef eucl_dist_output_shape(shapes):\r\n    shape1, shape2 = shapes\r\n    return (shape1[0], 1)\r\n\r\n\r\ndef contrastive_loss(y_true, y_pred):\r\n    '''Contrastive loss from Hadsell-et-al.'06\r\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\r\n    '''\r\n    margin = 1\r\n    sqaure_pred = K.square(y_pred)\r\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\r\n    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\r\n\r\n\r\ndef create_pairs(x, digit_indices):\r\n    '''Positive and negative pair creation.\r\n    Alternates between positive and negative pairs.\r\n    '''\r\n    pairs = []\r\n    labels = []\r\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\r\n    for d in range(num_classes):\r\n        for i in range(n):\r\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\r\n            pairs += [[x[z1], x[z2]]]\r\n            inc = random.randrange(1, num_classes)\r\n            dn = (d + inc) % num_classes\r\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\r\n            pairs += [[x[z1], x[z2]]]\r\n            labels += [1, 0]\r\n    return np.array(pairs), np.array(labels)\r\n\r\n\r\ndef create_base_network(input_shape):\r\n    '''Base network to be shared (eq. to feature extraction).\r\n    '''\r\n\r\n    input = Input(shape=input_shape)\r\n    x = Flatten()(input)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    return Model(input, x)\r\n\r\n\r\ndef compute_accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    pred = y_pred.ravel() < 0.5\r\n    return np.mean(pred == y_true)\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\r\n\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\ninput_shape = x_train.shape[1:]\r\n\r\n# create training+test positive and negative pairs\r\ndigit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\r\ntr_pairs, tr_y = create_pairs(x_train, digit_indices)\r\n\r\ndigit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\r\nte_pairs, te_y = create_pairs(x_test, digit_indices)\r\n\r\n\r\n# network definition\r\nbase_network = create_base_network(input_shape)\r\n\r\ninput_a = Input(shape=input_shape, name='input_a')\r\ninput_b = Input(shape=input_shape, name='input_b')\r\n\r\n# because we re-use the same instance `base_network`,\r\n# the weights of the network\r\n# will be shared across the two branches\r\nprocessed_a = base_network(input_a)\r\nprocessed_b = base_network(input_b)\r\n\r\ndistance = Lambda(euclidean_distance,\r\n                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\r\n\r\nmodel = Model([input_a, input_b], distance)\r\n\r\n# train\r\nrms = RMSprop()\r\nmodel.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\r\n\r\nmodel.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\r\n           batch_size=128,\r\n           epochs=1,\r\n           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\r\n\r\nestimata = tf.keras.estimator.model_to_estimator(keras_model=model)\r\n\r\n\r\ninput_name1 = model.input_names[0]\r\ninput_name2 = model.input_names[1]\r\n\r\n\r\n\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={input_name1: tr_pairs[:,0],\r\n           input_name2: tr_pairs[:,1]},\r\n        y=tr_y,\r\n        batch_size=128,\r\n        num_epochs=1,\r\n        shuffle=True)\r\n#\r\nestimata.train(\r\n    input_fn=train_input_fn,\r\n    steps=None)  # ,\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={input_name1: te_pairs[:, 0],\r\n       input_name2: te_pairs[:, 1]},\r\n    y=te_y,\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\neval_results = estimata.evaluate(input_fn=eval_input_fn)\r\n\r\n# compute final accuracy on training and test sets\r\ny_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\r\ntr_acc = compute_accuracy(tr_y, y_pred)\r\n\r\ny_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\r\nte_acc = compute_accuracy(te_y, y_pred)\r\n\r\nprint('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\r\nprint('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\r\n```", "@wt-huang thank you for your reply and for pointing out that error. I have re-run the code and I have noticed some strange errors that might be a good clue.\r\n\r\n```\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpqco1ytuk/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: ('/tmp/tmpqco1ytuk/keras/keras_model.ckpt',)\r\nINFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: RMSprop/lr; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: RMSprop/rho; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: RMSprop/decay; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: RMSprop/iterations; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable_1; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable_2; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable_3; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable_4; prev_var_name: Unchanged\r\nINFO:tensorflow:Warm-starting variable: training/RMSprop/Variable_5; prev_var_name: Unchanged\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n```\r\n\r\nI have updated the code as I noticed in my original script, the code is being trained in keras, trained again as an estimator and then evaluated. In my current code, its just being trained as an estimator. It results in the original poor accuracy. \r\n\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import print_function\r\nimport numpy as np\r\n\r\nimport random\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python import keras\r\nfrom keras.models import Sequential\r\nfrom tensorflow.python.keras.datasets import mnist\r\n\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\n\r\nfrom tensorflow.python.keras.optimizers import RMSprop\r\nfrom tensorflow.python.keras import backend as K\r\n\r\nnum_classes = 10\r\nepochs = 20\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\ndef euclidean_distance(vects):\r\n    x, y = vects\r\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\r\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\r\n\r\ndef eucl_dist_output_shape(shapes):\r\n    shape1, shape2 = shapes\r\n    return (shape1[0], 1)\r\n\r\ndef contrastive_loss(y_true, y_pred):\r\n    '''Contrastive loss from Hadsell-et-al.'06\r\n    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\r\n    '''\r\n    margin = 1\r\n    sqaure_pred = K.square(y_pred)\r\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\r\n    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\r\n\r\ndef create_pairs(x, digit_indices):\r\n    '''Positive and negative pair creation.\r\n    Alternates between positive and negative pairs.\r\n    '''\r\n    pairs = []\r\n    labels = []\r\n    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\r\n    for d in range(num_classes):\r\n        for i in range(n):\r\n            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\r\n            pairs += [[x[z1], x[z2]]]\r\n            inc = random.randrange(1, num_classes)\r\n            dn = (d + inc) % num_classes\r\n            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\r\n            pairs += [[x[z1], x[z2]]]\r\n            labels += [1, 0]\r\n    return np.array(pairs), np.array(labels)\r\n\r\ndef create_base_network(input_shape):\r\n    '''Base network to be shared (eq. to feature extraction).\r\n    '''\r\n\r\n    input = Input(shape=input_shape)\r\n    x = Flatten()(input)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    x = Dropout(0.1)(x)\r\n    x = Dense(128, activation='relu')(x)\r\n    return Model(input, x)\r\n\r\ndef compute_accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    pred = y_pred.ravel() < 0.5\r\n    return np.mean(pred == y_true)\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\ninput_shape = x_train.shape[1:]\r\n\r\n# create training+test positive and negative pairs\r\ndigit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\r\ntr_pairs, tr_y = create_pairs(x_train, digit_indices)\r\n\r\ndigit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\r\nte_pairs, te_y = create_pairs(x_test, digit_indices)\r\n\r\n# network definition\r\nbase_network = create_base_network(input_shape)\r\n\r\ninput_a = Input(shape=input_shape, name='input_a')\r\ninput_b = Input(shape=input_shape, name='input_b')\r\n\r\n# because we re-use the same instance `base_network`,\r\n# the weights of the network\r\n# will be shared across the two branches\r\nprocessed_a = base_network(input_a)\r\nprocessed_b = base_network(input_b)\r\n\r\ndistance = Lambda(euclidean_distance,\r\n                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\r\n\r\nmodel = Model([input_a, input_b], distance)\r\n\r\n# train\r\nrms = RMSprop()\r\nmodel.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\r\n\r\n# model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\r\n#            batch_size=128,\r\n#            epochs=1)\r\n\r\nestimata = tf.keras.estimator.model_to_estimator(keras_model=model)\r\n\r\ninput_name1 = model.input_names[0]\r\ninput_name2 = model.input_names[1]\r\n\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={input_name1: tr_pairs[:,0],\r\n           input_name2: tr_pairs[:,1]},\r\n        y=tr_y,\r\n        batch_size=128,\r\n        num_epochs=1,\r\n        shuffle=True)\r\n#\r\nestimata.train(\r\n    input_fn=train_input_fn,\r\n    steps=None)  # ,\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={input_name1: te_pairs[:, 0],\r\n       input_name2: te_pairs[:, 1]},\r\n    y=te_y,\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\neval_results = estimata.evaluate(input_fn=eval_input_fn)\r\n\r\n# compute final accuracy on training and test sets\r\ny_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\r\ntr_acc = compute_accuracy(tr_y, y_pred)\r\n\r\ny_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\r\nte_acc = compute_accuracy(te_y, y_pred)\r\n\r\nprint('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\r\nprint('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\r\n```\r\n\r\nrun this code and see if it works your side?", "Solved this issue, moved my code to pytorch.", "@imranparuk Great! We could put your solution in the Tensorflow FAQ :smile: ", "@harshini-gadige Funny :smile:  /cc @ewilderj ", "Is this even going to apply after 2.0 and Eager? We all over it now, just close it \r\n:laughing:\r\n"]}, {"number": 23131, "title": "Failed to achieve MobileNet V2 reported latency on Pixel Phone", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\nHost: Mac OS High Sierra / Ubuntu 16.04\r\nPhone: Google Pixel, Android 9.0\r\nMeasure tool: build from [TF-Benchmark](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/benchmark)\r\nModel: [mobilenet_v2_1.0_224 from TF-Slim](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)\r\n  \r\n**Describe the current behavior**\r\n\r\nNet   | Paper Report | Measured\r\n--- | --- | ---\r\nMobileNet v2 1.0 224 | 73.8ms | 93.9ms\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\n```\r\nadb push $bin /data/local/tmp\r\nadb shell chmod +x /data/local/tmp/$bin\r\n\r\nbin=benchmark_tflite_model\r\nmodel=model.tflite\r\nadb shell rm /data/local/tmp/$model\r\nadb push $model /data/local/tmp\r\n\r\nadb shell /data/local/tmp/$bin \\\r\n    --graph=/data/local/tmp/$model \\\r\n    --input_layer=\"input\" \\\r\n    --input_layer_shape=\"1,224,224,3\" \\\r\n    --input_layer_type=\"float\" \\\r\n    --num_runs=200 --warmup_runs=50\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n\u279c  mobilenet_v2_1.0_224 adb shell\r\nsailfish:/ $ getprop | grep -e 'model' -e 'version.sdk' -e 'manufacturer' -e 'hardware' -e 'platform' -e 'revision' -e 'serialno' -e 'product.name' -e 'brand'\r\n[media.recorder.show_manufacturer_and_model]: [true]\r\n[ro.board.platform]: [msm8996]\r\n[ro.boot.hardware]: [sailfish]\r\n[ro.boot.hardware.color]: [SLV00]\r\n[ro.boot.hardware.ddr]: [4096MB,Samsung,LPDDR4]\r\n[ro.boot.hardware.revision]: [PVT]\r\n[ro.boot.hardware.ufs]: [32GB,Samsung]\r\n[ro.boot.serialno]: [FA68X0302645]\r\n[ro.build.version.sdk]: [28]\r\n[ro.frp.pst]: [/dev/block/platform/soc/624000.ufshc/by-name/frp]\r\n[ro.hardware]: [sailfish]\r\n[ro.hardware.power]: [marlin]\r\n[ro.product.brand]: [google]\r\n[ro.product.manufacturer]: [Google]\r\n[ro.product.model]: [Pixel]\r\n[ro.product.name]: [sailfish]\r\n[ro.product.vendor.brand]: [google]\r\n[ro.product.vendor.manufacturer]: [Google]\r\n[ro.product.vendor.model]: [Pixel]\r\n[ro.revision]: [0]\r\n[ro.serialno]: [FA68X0302645]\r\n\r\n\r\n\r\n\u279c  mobilenet_v2_1.0_224 bin=benchmark_tflite_model\r\nmodel=model.tflite\r\nadb push $model /data/local/tmp\r\nadb shell /data/local/tmp/$bin \\\r\n    --graph=/data/local/tmp/$model \\\r\n    --input_layer=\"input\" \\\r\n    --input_layer_shape=\"1,224,224,3\" \\\r\n    --input_layer_type=\"float\" \\\r\n    --num_runs=200 --warmup_runs=50\r\nmodel.tflite: 1 file pushed. 27.7 MB/s (13978596 bytes in 0.481s)\r\nSTARTING!\r\nNum runs: [200]\r\nInter-run delay (seconds): [-1]\r\nNum threads: [1]\r\nBenchmark name: []\r\nOutput prefix: []\r\nWarmup runs: [50]\r\nGraph: [/data/local/tmp/model.tflite]\r\nInput layers: [input]\r\nInput shapes: [1,224,224,3]\r\nUse nnapi : [0]\r\nLoaded model /data/local/tmp/model.tflite\r\nresolved reporter\r\nInitialized session in 34.432ms\r\nRunning benchmark for 50 iterations\r\ncount=50 first=117086 curr=93140 min=93027 max=117086 avg=94640.8 std=3362\r\n\r\nRunning benchmark for 200 iterations\r\ncount=200 first=93564 curr=93170 min=92931 max=96389 avg=93925 std=963\r\n\r\n============================== Run Order ==============================\r\n\t             [node type]\t  [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t                 CONV_2D\t    0.000\t    4.325\t    4.320\t  4.601%\t  4.601%\t     0.000\t        1\t[MobilenetV2/Conv/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t    4.321\t    2.222\t    2.304\t  2.455%\t  7.056%\t     0.000\t        1\t[MobilenetV2/expanded_conv/depthwise/Relu6]\r\n\t                 CONV_2D\t    6.626\t    2.075\t    2.017\t  2.148%\t  9.204%\t     0.000\t        1\t[MobilenetV2/expanded_conv/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t    8.643\t    6.103\t    6.153\t  6.554%\t 15.758%\t     0.000\t        1\t[MobilenetV2/expanded_conv_1/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   14.798\t    3.621\t    3.705\t  3.946%\t 19.704%\t     0.000\t        1\t[MobilenetV2/expanded_conv_1/depthwise/Relu6]\r\n\t                 CONV_2D\t   18.503\t    1.865\t    1.898\t  2.021%\t 21.725%\t     0.000\t        1\t[MobilenetV2/expanded_conv_1/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   20.402\t    3.190\t    3.193\t  3.401%\t 25.126%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   23.595\t    2.271\t    2.255\t  2.402%\t 27.528%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/depthwise/Relu6]\r\n\t                 CONV_2D\t   25.851\t    2.882\t    2.875\t  3.062%\t 30.591%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   28.728\t    0.068\t    0.052\t  0.056%\t 30.647%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/add]\r\n\t                 CONV_2D\t   28.780\t    3.169\t    3.180\t  3.387%\t 34.034%\t     0.000\t        1\t[MobilenetV2/expanded_conv_3/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   31.961\t    0.811\t    0.837\t  0.891%\t 34.925%\t     0.000\t        1\t[MobilenetV2/expanded_conv_3/depthwise/Relu6]\r\n\t                 CONV_2D\t   32.799\t    1.275\t    1.261\t  1.343%\t 36.268%\t     0.000\t        1\t[MobilenetV2/expanded_conv_3/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   34.060\t    1.281\t    1.243\t  1.324%\t 37.592%\t     0.000\t        1\t[MobilenetV2/expanded_conv_4/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   35.303\t    0.708\t    0.723\t  0.770%\t 38.362%\t     0.000\t        1\t[MobilenetV2/expanded_conv_4/depthwise/Relu6]\r\n\t                 CONV_2D\t   36.027\t    1.714\t    1.642\t  1.749%\t 40.110%\t     0.000\t        1\t[MobilenetV2/expanded_conv_4/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   37.669\t    0.022\t    0.022\t  0.023%\t 40.133%\t     0.000\t        1\t[MobilenetV2/expanded_conv_4/add]\r\n\t                 CONV_2D\t   37.691\t    1.229\t    1.260\t  1.343%\t 41.476%\t     0.000\t        1\t[MobilenetV2/expanded_conv_5/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   38.952\t    0.723\t    0.738\t  0.786%\t 42.262%\t     0.000\t        1\t[MobilenetV2/expanded_conv_5/depthwise/Relu6]\r\n\t                 CONV_2D\t   39.690\t    1.719\t    1.633\t  1.739%\t 44.001%\t     0.000\t        1\t[MobilenetV2/expanded_conv_5/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   41.325\t    0.026\t    0.021\t  0.023%\t 44.024%\t     0.000\t        1\t[MobilenetV2/expanded_conv_5/add]\r\n\t                 CONV_2D\t   41.346\t    1.223\t    1.258\t  1.340%\t 45.364%\t     0.000\t        1\t[MobilenetV2/expanded_conv_6/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   42.604\t    0.221\t    0.225\t  0.240%\t 45.604%\t     0.000\t        1\t[MobilenetV2/expanded_conv_6/depthwise/Relu6]\r\n\t                 CONV_2D\t   42.829\t    0.695\t    0.693\t  0.738%\t 46.342%\t     0.000\t        1\t[MobilenetV2/expanded_conv_6/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   43.523\t    1.173\t    1.135\t  1.208%\t 47.550%\t     0.000\t        1\t[MobilenetV2/expanded_conv_7/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   44.658\t    0.328\t    0.334\t  0.356%\t 47.906%\t     0.000\t        1\t[MobilenetV2/expanded_conv_7/depthwise/Relu6]\r\n\t                 CONV_2D\t   44.992\t    1.253\t    1.258\t  1.340%\t 49.246%\t     0.000\t        1\t[MobilenetV2/expanded_conv_7/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   46.251\t    0.014\t    0.013\t  0.014%\t 49.260%\t     0.000\t        1\t[MobilenetV2/expanded_conv_7/add]\r\n\t                 CONV_2D\t   46.264\t    1.104\t    1.123\t  1.196%\t 50.456%\t     0.000\t        1\t[MobilenetV2/expanded_conv_8/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   47.387\t    0.407\t    0.352\t  0.375%\t 50.831%\t     0.000\t        1\t[MobilenetV2/expanded_conv_8/depthwise/Relu6]\r\n\t                 CONV_2D\t   47.740\t    1.249\t    1.252\t  1.334%\t 52.164%\t     0.000\t        1\t[MobilenetV2/expanded_conv_8/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   48.993\t    0.010\t    0.012\t  0.012%\t 52.177%\t     0.000\t        1\t[MobilenetV2/expanded_conv_8/add]\r\n\t                 CONV_2D\t   49.004\t    1.103\t    1.127\t  1.200%\t 53.377%\t     0.000\t        1\t[MobilenetV2/expanded_conv_9/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   50.131\t    0.336\t    0.344\t  0.366%\t 53.743%\t     0.000\t        1\t[MobilenetV2/expanded_conv_9/depthwise/Relu6]\r\n\t                 CONV_2D\t   50.475\t    1.295\t    1.250\t  1.331%\t 55.074%\t     0.000\t        1\t[MobilenetV2/expanded_conv_9/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   51.726\t    0.013\t    0.013\t  0.014%\t 55.088%\t     0.000\t        1\t[MobilenetV2/expanded_conv_9/add]\r\n\t                 CONV_2D\t   51.739\t    1.107\t    1.128\t  1.201%\t 56.289%\t     0.000\t        1\t[MobilenetV2/expanded_conv_10/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   52.867\t    0.333\t    0.340\t  0.362%\t 56.652%\t     0.000\t        1\t[MobilenetV2/expanded_conv_10/depthwise/Relu6]\r\n\t                 CONV_2D\t   53.208\t    1.818\t    1.780\t  1.896%\t 58.548%\t     0.000\t        1\t[MobilenetV2/expanded_conv_10/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   54.989\t    2.735\t    2.701\t  2.877%\t 61.424%\t     0.000\t        1\t[MobilenetV2/expanded_conv_11/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   57.690\t    0.539\t    0.547\t  0.582%\t 62.007%\t     0.000\t        1\t[MobilenetV2/expanded_conv_11/depthwise/Relu6]\r\n\t                 CONV_2D\t   58.238\t    2.642\t    2.653\t  2.825%\t 64.832%\t     0.000\t        1\t[MobilenetV2/expanded_conv_11/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   60.891\t    0.015\t    0.015\t  0.016%\t 64.848%\t     0.000\t        1\t[MobilenetV2/expanded_conv_11/add]\r\n\t                 CONV_2D\t   60.906\t    2.671\t    2.713\t  2.889%\t 67.737%\t     0.000\t        1\t[MobilenetV2/expanded_conv_12/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   63.620\t    0.502\t    0.513\t  0.546%\t 68.284%\t     0.000\t        1\t[MobilenetV2/expanded_conv_12/depthwise/Relu6]\r\n\t                 CONV_2D\t   64.133\t    2.640\t    2.648\t  2.820%\t 71.104%\t     0.000\t        1\t[MobilenetV2/expanded_conv_12/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   66.782\t    0.016\t    0.019\t  0.020%\t 71.124%\t     0.000\t        1\t[MobilenetV2/expanded_conv_12/add]\r\n\t                 CONV_2D\t   66.801\t    2.710\t    2.721\t  2.898%\t 74.022%\t     0.000\t        1\t[MobilenetV2/expanded_conv_13/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   69.523\t    0.146\t    0.149\t  0.159%\t 74.181%\t     0.000\t        1\t[MobilenetV2/expanded_conv_13/depthwise/Relu6]\r\n\t                 CONV_2D\t   69.672\t    1.130\t    1.156\t  1.231%\t 75.412%\t     0.000\t        1\t[MobilenetV2/expanded_conv_13/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   70.829\t    2.117\t    2.120\t  2.258%\t 77.670%\t     0.000\t        1\t[MobilenetV2/expanded_conv_14/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   72.950\t    0.201\t    0.207\t  0.221%\t 77.891%\t     0.000\t        1\t[MobilenetV2/expanded_conv_14/depthwise/Relu6]\r\n\t                 CONV_2D\t   73.157\t    2.105\t    2.092\t  2.228%\t 80.119%\t     0.000\t        1\t[MobilenetV2/expanded_conv_14/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   75.250\t    0.007\t    0.008\t  0.009%\t 80.128%\t     0.000\t        1\t[MobilenetV2/expanded_conv_14/add]\r\n\t                 CONV_2D\t   75.258\t    2.048\t    2.100\t  2.237%\t 82.365%\t     0.000\t        1\t[MobilenetV2/expanded_conv_15/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   77.360\t    0.201\t    0.204\t  0.217%\t 82.583%\t     0.000\t        1\t[MobilenetV2/expanded_conv_15/depthwise/Relu6]\r\n\t                 CONV_2D\t   77.564\t    2.113\t    2.094\t  2.231%\t 84.813%\t     0.000\t        1\t[MobilenetV2/expanded_conv_15/project/BatchNorm/FusedBatchNorm]\r\n\t                     ADD\t   79.659\t    0.007\t    0.008\t  0.008%\t 84.821%\t     0.000\t        1\t[MobilenetV2/expanded_conv_15/add]\r\n\t                 CONV_2D\t   79.667\t    2.118\t    2.096\t  2.232%\t 87.054%\t     0.000\t        1\t[MobilenetV2/expanded_conv_16/expand/Relu6]\r\n\t       DEPTHWISE_CONV_2D\t   81.764\t    0.196\t    0.199\t  0.212%\t 87.266%\t     0.000\t        1\t[MobilenetV2/expanded_conv_16/depthwise/Relu6]\r\n\t                 CONV_2D\t   81.963\t    4.196\t    4.249\t  4.526%\t 91.792%\t     0.000\t        1\t[MobilenetV2/expanded_conv_16/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   86.213\t    6.016\t    6.110\t  6.507%\t 98.299%\t     0.000\t        1\t[MobilenetV2/Conv_1/Relu6]\r\n\t         AVERAGE_POOL_2D\t   92.324\t    0.034\t    0.035\t  0.037%\t 98.336%\t     0.000\t        1\t[MobilenetV2/Logits/AvgPool]\r\n\t                 CONV_2D\t   92.359\t    1.408\t    1.524\t  1.623%\t 99.960%\t     0.000\t        1\t[MobilenetV2/Logits/Conv2d_1c_1x1/BiasAdd]\r\n\t                 RESHAPE\t   93.884\t    0.003\t    0.003\t  0.003%\t 99.963%\t     0.000\t        1\t[MobilenetV2/Logits/Squeeze]\r\n\t                 SOFTMAX\t   93.887\t    0.034\t    0.035\t  0.037%\t100.000%\t     0.000\t        1\t[MobilenetV2/Predictions/Reshape_1]\r\n\r\n============================== Top by Computation Time ==============================\r\n\t             [node type]\t  [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t                 CONV_2D\t    8.643\t    6.103\t    6.153\t  6.554%\t  6.554%\t     0.000\t        1\t[MobilenetV2/expanded_conv_1/expand/Relu6]\r\n\t                 CONV_2D\t   86.213\t    6.016\t    6.110\t  6.507%\t 13.061%\t     0.000\t        1\t[MobilenetV2/Conv_1/Relu6]\r\n\t                 CONV_2D\t    0.000\t    4.325\t    4.320\t  4.601%\t 17.663%\t     0.000\t        1\t[MobilenetV2/Conv/Relu6]\r\n\t                 CONV_2D\t   81.963\t    4.196\t    4.249\t  4.526%\t 22.189%\t     0.000\t        1\t[MobilenetV2/expanded_conv_16/project/BatchNorm/FusedBatchNorm]\r\n\t       DEPTHWISE_CONV_2D\t   14.798\t    3.621\t    3.705\t  3.946%\t 26.135%\t     0.000\t        1\t[MobilenetV2/expanded_conv_1/depthwise/Relu6]\r\n\t                 CONV_2D\t   20.402\t    3.190\t    3.193\t  3.401%\t 29.536%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/expand/Relu6]\r\n\t                 CONV_2D\t   28.780\t    3.169\t    3.180\t  3.387%\t 32.923%\t     0.000\t        1\t[MobilenetV2/expanded_conv_3/expand/Relu6]\r\n\t                 CONV_2D\t   25.851\t    2.882\t    2.875\t  3.062%\t 35.985%\t     0.000\t        1\t[MobilenetV2/expanded_conv_2/project/BatchNorm/FusedBatchNorm]\r\n\t                 CONV_2D\t   66.801\t    2.710\t    2.721\t  2.898%\t 38.884%\t     0.000\t        1\t[MobilenetV2/expanded_conv_13/expand/Relu6]\r\n\t                 CONV_2D\t   60.906\t    2.671\t    2.713\t  2.889%\t 41.773%\t     0.000\t        1\t[MobilenetV2/expanded_conv_12/expand/Relu6]\r\n\r\nNumber of nodes executed: 66\r\n============================== Summary by node type ==============================\r\n\t             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\r\n\t                 CONV_2D\t       36\t    79.637\t    84.851%\t    84.851%\t     0.000\t       36\r\n\t       DEPTHWISE_CONV_2D\t       17\t    13.970\t    14.885%\t    99.736%\t     0.000\t       17\r\n\t                     ADD\t       10\t     0.177\t     0.189%\t    99.924%\t     0.000\t       10\r\n\t                 SOFTMAX\t        1\t     0.035\t     0.037%\t    99.962%\t     0.000\t        1\r\n\t         AVERAGE_POOL_2D\t        1\t     0.034\t     0.036%\t    99.998%\t     0.000\t        1\r\n\t                 RESHAPE\t        1\t     0.002\t     0.002%\t   100.000%\t     0.000\t        1\r\n\r\nTimings (microseconds): count=200 first=93531 curr=93135 min=92902 max=96356 avg=93888.1 std=962\r\nMemory (bytes): count=0\r\n66 nodes observed\r\n\r\n\r\nAverage inference timings in us: Warmup: 94640.8, Init: 34432, no stats: 93925\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hi @harshini-gadige , any thoughts? ", "Nagging Assignee @liyunlu0618: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Can you try again with single big core as said in the instruction?\r\n\r\nadb shell taskset f0 /data/local/tmp/$bin ...", "Hi @liyunlu0618 , Pixel 1 does not have big/small cores. This command only works for Pixel 2 and later phones. ", "Looks like @shashishekhar has resolved this in a private email thread. Pasting the response here for public reference:\r\n\r\nI see that the attached binary for benchmark_model is 32 bit build. You should build it with --config=android_arm64, this should help in resolving the discrepancy. If you have any difficulties when building with 64 bit, try this [workaround](https://github.com/tensorflow/tensorflow/issues/20192#issuecomment-404971539) for upgrading the version of NDK.", "Thanks. After rebuilding the binary with 64 bit, the speed matches."]}, {"number": 23130, "title": "Keras-GPU Fail to create cudnn handle", "body": "Hi,\r\n\r\nJust quick question regarding using Keras-GPU on Windows. Essentially I was playing with implementation of one of the Deep Reinforcement Learning algorithms (DQN) using Keras with Tensorflow-GPU backend for AirSim self-driving car simulation. All good but when it comes to training the NN the TF Fails with the error below. I tried to see if there is something wrong with my script by running simple MNSIT NN example and it fails with exact same reason. What I've noticed is that this ONLY happens when the environment (AirSim application) is running in the background, nothing fails if its not running. Additionally (since I have access to more than one GPU), when the GPUs are not SLI connected and work as 2 separate units it also works just fine by using GPU1 for application and GPU2 for training. Already posted this on AirSim git but was redirected here. Anyone else encountered this issue before?\r\n\r\nI'm using CUDA 9 with and TF 1.5.0 on Windows 10 if that helps, updating TF didn't help etc, as I said all works when the app is not running\r\n\r\nEpoch 1/1\r\n2018-09-28 15:02:31.247055: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n\r\n2018-09-28 15:02:33.168438: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n\r\n2018-09-28 15:02:33.173026: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n\r\n2018-09-28 15:02:33.178209: F C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\kernels\\conv_ops.cc:717] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms)\r\n\r\nCheers", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@Gaduu AimSim should work on DQN using Keras with TensorFlow-GPU. \r\nYou can check the GPU setup on Windows 10. More detailed information or filling out the issue template would be helpful.", "Closing, feel free to reopen if problem persists"]}, {"number": 23129, "title": "ModuleNotFoundError: No module named 'tensorflow.core.protobuf'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 Pro 1803 (OS BUILD:17134.112\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n- TensorFlow installed from (source or binary):pip,using conda. Followed instructions from [this page](https://www.tensorflow.org/install/pip)\r\n- TensorFlow version:1.11.0\r\n- Python version:3.6.6\r\n- Installed using virtualenv? pip? conda?:conda and pip [using this page](https://www.tensorflow.org/install/pip)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n- GPU model and memory: nvidia Geforce GTX 1060 3GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n![image](https://user-images.githubusercontent.com/36691630/47257924-eb7df300-d4b1-11e8-9733-68079dbdf3fd.png)\r\nExecuting the first line shows an error\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nNothing, just tried to execute the line for my model and it started showing an error. Googled the problem but the solutions were mainly for \"google.protobuf\"and [this one](https://github.com/tensorflow/tensorflow/issues/890). Both didn't work.\r\nTried to create a new conda env and followed the above installation link, activated the environment, opened jupyter notebook, and still it is showing the error.\r\n\r\n\r\n**Any other info / logs**\r\n![image](https://user-images.githubusercontent.com/36691630/47257981-9db5ba80-d4b2-11e8-8749-e59d27d1157c.png)\r\nThe above image is of the new environment I tried to create, but still it showed the error.\r\nBelow packages is of the original env(the one which opens when you first open anaconda prompt, idk what it is called)\r\n![image](https://user-images.githubusercontent.com/36691630/47258011-f38a6280-d4b2-11e8-9d1f-62b3709b1e8c.png)\r\n![image](https://user-images.githubusercontent.com/36691630/47258027-13ba2180-d4b3-11e8-9d4b-7f9293a66ee7.png)\r\n![image](https://user-images.githubusercontent.com/36691630/47258035-1fa5e380-d4b3-11e8-9b51-44de97595079.png)\r\n![image](https://user-images.githubusercontent.com/36691630/47258040-2a607880-d4b3-11e8-9745-11a955402ab2.png)\r\n![image](https://user-images.githubusercontent.com/36691630/47258047-449a5680-d4b3-11e8-8251-155899f74e41.png)\r\n![image](https://user-images.githubusercontent.com/36691630/47258059-5c71da80-d4b3-11e8-842b-811186508874.png)\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce", "Hi, i don't know how, but it is working now. I think i needed to restart my pc or something. I'll update if any problem show up."]}, {"number": 23128, "title": "Difference in higher order tf.gradients()", "body": "**System information**\r\n\r\n- OS: OS X 10.13.6\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 1.11\r\n- Python version: 3.6.6\r\n- Have I written custom code: No\r\n- Bazel version: N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n- Exact command to reproduce: See below.\r\n- Mobile device: N/A\r\n\r\n**Describe the current behavior**\r\nI have a cost function based on the derivative of the output of the network c w.r.t to the inputs of the network x and t.  I wish to replace x and t by one input tensor X=[x,t]. To test my code, I have the written the following function which returns the gradients:\r\n\r\n`def cost_diffusion_test(x, t, X ,c):\r\n    c_t = tf.gradients(c, t)[0]\r\n    c_x = tf.gradients(c, x)[0]\r\n    c_xx = tf.gradients(c_x, x)[0]\r\n\r\n    dc = tf.gradients(c, X)[0]\r\n    d2c = tf.gradients(dc[:, 0:1], X)[0]\r\n\r\n    return c_t, c_x, c_xx, dc, d2c`\r\n\r\nc_t and dc[:,1:2], c_x and dc[:,0:1] are the same as expected through np.array_equal(). c_xx and d2c[:,0:1] are not. When I study the difference d2c[:,0:1]-c_xx the I observe many zeros and a few terms on the order of e-08. Intriguingly, the maximum and minimum difference is 5.9604645e-08. If this would be a tensorflow-> numpy error, why is the first order derivative correct?\r\n\r\n**Describe the expected behavior**\r\nnp.array_equal(d2c[:,0:1], c_xx)==True\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Have I written custom code\r\n> OS Platform and Distribution\r\n> Bazel version\r\n> CUDA/cuDNN version\r\n> GPU model and memory\r\n> Exact command to reproduce\r\n> Mobile device\r\n\r\nUpdated my original comment.", "In order to expedite the trouble-shooting process, please provide a minimum example to reproduce the issue reported here so that we can quickly identify the source. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23127, "title": "Problems when building tensorflow with CUDA", "body": "When I built tensorflow from source with CUDA using bazel,I got the following errors:\r\n\r\n    external/com_google_absl/absl/strings/string_view.h(496): warning: expression has no effect\r\n    external/com_google_absl/absl/strings/str_cat.h(259): error: expression must have a constant value\r\n    external/com_google_absl/absl/strings/str_cat.h(259): error: expression must have a constant value\r\n\r\nI add some codes like `std::cout<<\"using cpu for Launch<Device>\"<<std::endl;`.Is there anything wrong? Thanks for any help.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "also met this problem when compiling tensorflow serving with GPU\uff1a\r\nOS: CentOS 7.5.1804\r\nBazel: 0.18.0\r\nCUDA: 8.0\r\ncuDNN: 7.1.3 for CUDA 8.0\r\nGCC: 4.8.5\r\n\r\n\r\n", "You can try to install [tensorflow-gpu from anaconda](https://anaconda.org/anaconda/tensorflow-gpu)", "We want to install from source rather than anaconda. Still, I have exactly the same errors when compiling on centos7 too.  @wt-huang ", "I also have same issue...\r\nOS: ubuntu 16.04\r\nBazel: 0.16.0\r\nCUDA: 8.0\r\ncuDNN: 7.1.3 for CUDA 8.0\r\nGCC: 4.9", "Also for me:\r\nOS: ubuntu 16.04\r\nBazel: 0.19.2\r\nCUDA: 8.0\r\ncuDNN: 7.1.3 for CUDA 8.0\r\nGCC: 5.4\r\n\r\nbuilding inside a nvidia/cuda:8.0-cudnn7-devel container.", "i met same issue. I use cuda8.0. Is it due to cuda8.0?", "> i met same issue. I use cuda8.0. Is it due to cuda8.0?\r\n\r\nI couldn't address the exact issue but I can confirm that the build goes on when switching to cuda 9.0 (or at least to the corresponding docker image)", "Latest version of TensorFlow is tested against CUDA 9.0. If you are using a different version of CUDA you have to build TF from sources yourself. Feel free to open a new and fill all the information provided by the template if you are facing problems. This will help us to focus on a specific issues since system configurations can vary widely from user to user. Thanks!", "Why closing... The bug is here for sure and it's probably not that hard to fix....", "Yes, I still meet this bug.\r\nOS:gentoo \r\ncommand:emerge  1.12.0\r\nCUDA:cuda 8.0\r\nCUDNN:6.0\r\ngcc:4.9\r\nbazel: 0.20.0\r\n\r\nI can cmake the abseil-cpp , there is no error. maybe someone can help to fix it.", "I have no problem building tensorflow_model_server with only cpu support, but gpu (--config=cuda) fails at link time.\r\n\r\nBuild Command: \r\n```\r\nexport TF_NCCL_VERSION=1.3\r\nexport TF_NEED_CUDA=1\r\nexport NCCL_INSTALL_PATH=/usr/local/cuda\r\nbazel clean --expunge &&  bazel build -c opt --config=cuda --action_env PYTHON_BIN_PATH=~/tf/bin/python tensorflow_serving/model_servers/...\r\n\r\n```\r\nAlso tried building tensorflow_serving/model_servers:tensorflow_model_server alone, and got the same error below.\r\n\r\nHere is an excerpt of the linking error:\r\n```\r\nLinking of rule '//tfs/tensorflow_serving/model_servers:tensorflow_model_server' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n...\r\n/usr/bin/ld: external/com_3rd_party/zlib/lib/libz.a(inflate.o): relocation R_X86_64_32S against `zcfree' can not be used when making a shared object; recompile with -fPIC\r\nexternal/com_3rd_party/zlib/lib/libz.a: error adding symbols: Bad value\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tfs/tensorflow_serving/model_servers:tensorflow_model_server failed to build\r\nINFO: Elapsed time: 1.149s, Critical Path: 0.15s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nMy environment:\r\nOS: Centos 7\r\nCUDA: 9.0\r\nCudnn: 7.0\r\ngcc 4.8.5\r\nbazel: 0.16.1\r\n", "@yunjiangster try clean previous build and add `--copt=\"-fPIC\"` and then build again.  I can successfully build tf-serving with CUDA 9 on CentOS 7 using script like bellow (change the values of env variables according to your system):\r\n```\r\n#!/bin/sh\r\nexport PATH=/usr/local/sbin:/usr/local/bin:/sbin:/usr/sbin:/usr/bin:/bin:/root/bin\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64/\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\nexport BAZEL_VERSION=0.23.1\r\nexport CUDNN_VERSION=7.5.0\r\nexport TF_TENSORRT_VERSION=5.0.2\r\nexport TF_NEED_CUDA=1\r\nexport TF_NEED_TENSORRT=1\r\nexport TENSORRT_INSTALL_PATH=/usr/local/tensorRT/lib\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,5.2,6.0,6.1\r\nexport TF_CUDA_VERSION=9.0\r\nexport TF_CUDNN_VERSION=7\r\nexport TF_NCCL_VERSION=\r\nexport TMP=\"/home/tcheng/serving/tmp\"\r\n\r\nbazel build --color=yes --curses=yes --config=cuda --copt=\"-fPIC\" --copt=-O3 --verbose_failures --output_filter=DONT_MATCH_ANYTHING --config=nativeopt --incompatible_disallow_data_transition=false tensorflow_serving/model_servers:tensorflow_model_server\r\n```", "@troycheng thank you for the thorough advice, very helpful for future reference.  I think the problem was due to other third-party dependencies we added to the build rule, like com_3rd_party/zlib/lib/libz.a. I tried --copt=\"-fPIC\" in the past and that resulted in similar error. ", "@yunjiangster It's a pleasure. Since the libz.a is compiled standalone, just add -fPIC and recompile zlib again. It's a common problem when building shared/static library.  There are some explanations here, [https://stackoverflow.com/questions/5311515/gcc-fpic-option](url)"]}, {"number": 23126, "title": "Tensorflow - Disaccording TF METRICS (Accuracy, Precision, Recall)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.10.1\r\n- Python version: 2.7\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: release 7.5\r\n- GPU model and memory: Tesla K80 - 11.17GiB\r\n- Bazel version: N/A\r\n- Exact command to reproduce: N/A\r\n- Mobile device: N/A\r\n\r\nI am working with a CNN for an instrument recognition problem, using **IRMAS** dataset. \r\n\r\nThe **IRMAS** dataset has a clear **training** set, based only on singular instruments, therefore each instrument (guitar, violin, etc) has its own directory with multiple samples (*multi-classification*). The **testing** set, differently, contains polyphonic music, therefore multiple classes of instruments may appear in the same song (*multi-classification*, *multi-label*).\r\n\r\nThis is the final part of my network with the prediction and loss calculation, I am using the `Estimator API`.\r\n\r\n    \r\n\r\n    ### previous part of network is omitted\r\n    \r\n    # logits layer\r\n    logits = tf.layers.dense(inputs=dropout, units=labels.shape[1])\r\n\r\n    print('Shape Logits:', logits.shape)\r\n       \r\n   \r\n    predictions = {\r\n        \"classes\": tf.argmax(input=logits, axis=1),\r\n        \"probabilities\": tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels, tf.float32), logits=tf.cast(logits, tf.float32), name=\"sigmoid_tensor\")\r\n    }\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\n    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n        #optimizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.96)\r\n        train_op = optimizer.minimize(\r\n                                  loss=loss,\r\n                                  global_step=tf.train.get_global_step())\r\n        logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss}, every_n_iter=10)\r\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\r\n\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"]),\r\n\r\n        \"recall\": tf.metrics.recall(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"]),\r\n\r\n        \"precision\": tf.metrics.precision(\r\n        labels=tf.argmax(input=labels, axis=1),\r\n        predictions=predictions[\"classes\"])\r\n    }\r\n\r\n\r\nAfter few epochs, the training process seems to work since the loss goes down quite smoothly. However, the tensorflow metrics needed to evaluate the model does not seem to agree.\r\n\r\nThese are my results on the evaluation set (15% of the training set):\r\n\r\n`{'recall': 0.9989496, 'accuracy': 0.40656063, 'global_step': 1428, 'precision': 0.95004994, 'loss': 0.2432195}`\r\n\r\nThese are the results obtained from the testing set:\r\n\r\n`{'recall': 0.9981618, 'accuracy': 0.26530612, 'global_step': 1428, 'precision': 0.96533334, 'loss': 0.46097097}`\r\n\r\nIn my opinion, the accuracy value seems to be the only right, since decreases in the testing set, which is composed by polyphonic music rather than singular instruments. I don't understand why I get these results for precision and recall, they should be lower compared to the accuracy I get. \r\n\r\nI've tried to display the FP, FN, TN and TP and they seem to be in accord with precision and recall. In fact, by computing the accuracy with them I got around 0.97 (too high for this classification problem).\r\n\r\nMy question is why the metrics of tensorflow are so in disaccord? I could not find any useful information in the documentation.\r\n\r\nThank you in advance\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "It has been 17 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 23125, "title": "Update feature_column_v2.py", "body": "Or should be:\r\ny_0 = 1.0 / 2.0 * ( w_a + w_ b) + w_d + b\r\ny_1 = w_c + 1.0 / 3.0 * ( w_e + w_ f + w_g) + b", "comments": ["I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 23124, "title": "Update feature_column_v2_test.py", "body": "", "comments": ["Thanks @larrytin  Can you please resolve the conflicts?", "@larrytin could you please resolve the conflict?", "@larrytin  gentle ping ", "closing this PR based on latest comments from reviewer."]}, {"number": 23123, "title": "TensorFlow 1.11 CUDA 9.0 with CUDNN7.3 CUDA_ERROR_LAUNCH_TIMEOUT", "body": "Here is my information first:\r\n- cuda: CUDA 9.0\r\n- cudnn: cudnn7.3 for CUDA9.0\r\n- Nvidia GTX 1080Ti\r\n- TensorFlow 1.11 from pip3 with GPU support\r\n\r\nThe library can work and tensorflow successfully import from python. **but everytime inference or train a dataset only a while it will got this error**:\r\n\r\n```\r\n2018-10-20 16:47:07.055721: E tensorflow/stream_executor/cuda/cuda_driver.cc:981] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated\r\n2018-10-20 16:47:07.055749: E tensorflow/stream_executor/cuda/cuda_timer.cc:55] Internal: error destroying CUDA event in context 0xff40eb0: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated\r\n2018-10-20 16:47:07.055755: E tensorflow/stream_executor/cuda/cuda_timer.cc:60] Internal: error destroying CUDA event in context 0xff40eb0: CUDA_ERROR_LAUNCH_TIMEOUT: the launch timed out and was terminated\r\n2018-10-20 16:47:07.055789: F tensorflow/stream_executor/cuda/cuda_dnn.cc:211] Check failed: status == CUDNN_STATUS_SUCCESS (7 vs. 0)Failed to set cuDNN stream.\r\n[1]    3276 abort (core dumped)  python3 demo.py\r\n\r\n```\r\n\r\nIs this a bug or the driver issue? I have ever got this error before, if anyone got this error leave a comment below to let me know!! I am stuck here right now", "comments": ["I wanna install cuda 10 to have a try, but there is not support for cuda 10 now for tensorflow", "What OS, have you tried with any other versions of tensorflow?", "@imranparuk  Ubuntu 18.04. Tried, always got this error", "@jinfagang  Hi, request you to provide the following information. Thank you !\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:", "@jinfagang  - In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n"]}, {"number": 23122, "title": "Failing to build tensorflow c++ api on raspberry pi model 3 b+", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Stretch kernel 4.14\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): used this command git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\n- TensorFlow version:r1.11\r\n- Python version:3.5.3\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source):6.3.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen I follow this guide (https://gist.github.com/EKami/9869ae6347f68c592c5b5cd181a3b205) and attempt to build the c++ api using bazel, it fails.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI followed the guide above except for the portion where it says to replace:\r\nnative.new_http_archive(\r\n      name = \"eigen_archive\",\r\n      urls = [\r\n          \"http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n          \"https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\r\n      ],\r\n      sha256 = \"ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4\",\r\n      strip_prefix = \"eigen-eigen-f3a22f35b044\",\r\n      build_file = str(Label(\"//third_party:eigen.BUILD\")),\r\n  )\r\nbecause doing so gave me problems. I also made sure to use the newest versions of the software involved for bazel and other dependent software. I then attempted to build tensorflow using the command: bazel build -c opt --config=monolithic --local_resources 1024,1.0,1.0 --verbose_failures //tensorflow:libtensorflow_cc.so\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nERROR: /home/pi/tf/tensorflow/tensorflow/BUILD:558:1: Linking of rule '//tensorflow:libtensorflow_cc.so' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/pi/.cache/bazel/_bazel_pi/4770c5ca1786316d370c900c0b614a6d/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /usr/bin/gcc -shared -o bazel-out/arm-opt/bin/tensorflow/libtensorflow_cc.so -z defs -Wl,--version-script tensorflow/tf_version_script.lds '-Wl,-rpath,$ORIGIN/' -Wl,-soname,libtensorflow_cc.so -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,@bazel-out/arm-opt/bin/tensorflow/libtensorflow_cc.so-2.params)\r\nbazel-out/arm-opt/bin/tensorflow/core/kernels/_objs/list_kernels/list_kernels.pic.o:list_kernels.cc:function tensorflow::TensorListStack<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'void tensorflow::ConcatCPU<tensorflow::bfloat16>(tensorflow::DeviceBase*, std::vector<std::unique_ptr<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix, std::default_delete<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix> >, std::allocator<std::unique_ptr<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix, std::default_delete<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix> > > > const&, tensorflow::TTypes<tensorflow::bfloat16, 2, int>::Matrix*)'\r\nbazel-out/arm-opt/bin/tensorflow/core/kernels/_objs/list_kernels/list_kernels.pic.o:list_kernels.cc:function tensorflow::TensorListGather<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'void tensorflow::ConcatCPU<tensorflow::bfloat16>(tensorflow::DeviceBase*, std::vector<std::unique_ptr<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix, std::default_delete<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix> >, std::allocator<std::unique_ptr<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix, std::default_delete<tensorflow::TTypes<tensorflow::bfloat16, 2, int>::ConstMatrix> > > > const&, tensorflow::TTypes<tensorflow::bfloat16, 2, int>::Matrix*)'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 21254.436s, Critical Path: 1956.26s\r\nINFO: 2708 processes: 2708 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nExact command to reproduce", "@ahilleary Your bazel version is likely the issue that some modifications may be needed.\r\nTry using bazel 0.5.1 and gcc 4.8 to build TensorFlow on raspberry pi model 3.", "For anyone who is having this same issue, follow this guide, this worked for me : https://www.youtube.com/watch?v=WqCnW_2XDw8&t=680s"]}, {"number": 23121, "title": "Remove duplicate variable assignment.", "body": "", "comments": ["@larrytin sorry could you pull rebase and push again?", "@larrytin could you please resolve the conflict?", "@larrytin  gentle ping to rebase the branch.", "@larrytin reminder to rebase the branch.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "closing this PR due to lack of activity."]}, {"number": 23120, "title": "[Bug fix] Cancelling adding suffix to assign function from outside.", "body": "This is a small bug fix about naming `assign functions`. It is unnecessary to adding suffix to name outside because the naming conflict will be automatically handled within the framework when declaring an op.\r\n\r\nAdditionally,  we will get names like `None_0`, `None_1` when preserving the default parameters if we follow the old logic.", "comments": ["Hi, @alextp:\r\n  This is a small fix. Please have a look. \r\nThanks. "]}, {"number": 23119, "title": "global name 'cuda_toolkit_path_full' is not defined", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 18.04.1 LTS  64 bit\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**:   Source\r\n- **TensorFlow Version**:  r.1.11  \r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**:  0.15.2 (tried/same problem with 0.15.2, 1.16.1, 0.18.0)\r\n- **GCC/Compiler version (if compiling from source)**:  7.3.0\r\n- **CUDA/cuDNN version**:  10.0 / 7.7.3\r\n- **GPU model and memory**: RTX 2080 TI 11GB\r\n- **Exact command to reproduce**:  ./configure with answers below\r\n\r\n### Describe the problem\r\nconfigure fails with following error:\r\n\r\nanatolii@workstation:~/tensorflow$ ./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.15.2 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: \r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: \r\nGoogle Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: \r\nHadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon AWS Platform support? [Y/n]: \r\nAmazon AWS Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: \r\nApache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: \r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: \r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: \r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with nGraph support? [y/N]: \r\nNo nGraph support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: CUDA 10.0\r\n\r\n\r\nPlease specify the location where CUDA CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"./configure.py\", line 1592, in <module>\r\n    main()\r\n  File \"./configure.py\", line 1527, in main\r\n    set_tf_cuda_version(environ_cp)\r\n  File \"./configure.py\", line 855, in set_tf_cuda_version\r\n    (tf_cuda_version, cuda_toolkit_path_full))\r\nNameError: global name 'cuda_toolkit_path_full' is not defined\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nTensorFlow version", "TensorFlow officially supports CUDA 9.0. However it is compatible with CUDA 10.0 but not supported currently. For using TF with cuda 10, you have to build it from sources yourself. You need to update the **\"./configure.py\"** file with appropriate CUDA, cuDNN versions. You can also take a look at [installations](https://medium.com/@vitali.usau/install-cuda-10-0-cudnn-7-3-and-build-tensorflow-gpu-from-source-on-ubuntu-18-04-3daf720b83fe) done by another users to make it work.", "@ymodak  - sorry I don't see any notes on modifying configure.py at the installations link you mentioned, perhaps you meant that CUDA version is to be typed when running `configure` ? - because that I did, as shown in the issue description above. Please clarify. thanks!\r\n", "Yes, I see now that you have already mentioned CUDA version 10. Did you add CUDA path variable in the bashrc file? The link in previous comments mentions the changes you need to adopt to build successfully for CUDA 10. I recommend that you follow the tutorial and build again, since I may be missing some points.", "yep, I had modified PATH and LD_LIBRARY_PATH in ~/.profile to reflect /usr/local/cuda-10.0/bin and lib64 respectively.", "@toli-belo\r\nI think you need to specify \"10.0\" instead of \"CUDA 10.0\" when it asks you for cuda version ", "Is this still an issue? Did you get a chance to follow the tutorial I sent in previous comment?", "I met the same error.\r\nI looked into `configure.py` and found the code below\r\n```python\r\ncuda_toolkit_paths_full = [os.path.join(cuda_toolkit_path, x) for x in cuda_rt_lib_paths]\r\n......(4 lines here)\r\nprint('Invalid path to CUDA %s toolkit. %s cannot be found' %\r\n      (tf_cuda_version, cuda_toolkit_path_full))\r\n```\r\nThe `print` is where the error happened, so I think it's just a misspelling\u2026\r\nThe script wants to tell you that your path to CUDA is invalid, so maybe check again the location you tell the script where CUDA is installed.", "@Sergei-Lebedev , thank you, I specified 10.0 instead of CUDA 10.0 and it went through.\r\nI did see a warning though on my ubuntu:\r\n\r\n`Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default`\r\nmy bazel command was:\r\n`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\nI need to find how to fix the TMP env variable issue.\r\n\r\n", "thanks everyone! I was able to build tensorflow with cuda 10"]}, {"number": 23118, "title": "Pure Virtual Method called - build for ARMv7 ", "body": "**System information**\r\n- OS Platform and Distribution:  Linux Debian 8 Jessie\r\n- TensorFlow installed from: source\r\n- TensorFlow version: r1.12\r\n- Python version: 3.4.2\r\n- compiled and built as per instructions on Ubuntu 18.04.1 cross-compile for Raspberry Pi: https://www.tensorflow.org/install/source_rpi\r\n\r\n\r\n**Problem**\r\nWhen running tensorflow on my device, the following error is thrown when accessing any cameras using the tensorflow.python.keras.layers.Input() method:\r\n```\r\npure virtual method called\r\nterminate called without an active exception\r\nAborted\r\n```\r\nThe device uses an R8 ARMv7 processor \r\n\r\n\r\n**Commands / Steps**\r\n```\r\nfrom tensorflow.python.keras.layers import Input\r\n```\r\n\r\n```\r\nimg_in = Input(shape=(120, 160, 3), name='img_in')\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n\r\nComplete system output:\r\n```\r\nchip@chip:~/mycar$ python3\r\nPython 3.4.2 (default, Sep 26 2018, 05:38:50)\r\n[GCC 4.9.2] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.python.keras.layers import Input\r\n>>> img_in = Input(shape=(120, 160, 3), name='img_in')\r\npure virtual method called\r\nterminate called without an active exception\r\nAborted\r\n```\r\n\r\nWe have done some research on this issue and have not found too many similar cases.  We found one similar issue that stated that removing the marsh flag from compile would resolve the issue, however, this was not the case.\r\n\r\nAny help would be greatly appreciated.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@wallarug See if you can upgrade to Raspbian 9 Stretch from Jessie.\r\nAlso, try to use pre-built binaries for TensorFlow installation.", "Closing as this should be resolved by the approach suggested, free to reopen if problem persists\r\n\r\n\r\n", "The target device is not a raspberry pi, it is a CHIP. Please reopen the issue."]}, {"number": 23117, "title": "Build fail on Windows with compute capability 6.1", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:  source \r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**: 1.18.0\r\n- **GCC/Compiler version (if compiling from source)**: Visual C++ Build Tools 2015\r\n- **CUDA/cuDNN version**: CUDA 9.2, cuDNN 7.2.1\r\n- **GPU model and memory**: NVIDIA 1080 GTX \r\n- **Exact command to reproduce**: bazel build --config=opt --config=cuda --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nI am trying to build tensorflow from source. \r\nBuild fail if compiling with compute capability 6.1 (but build fine with compute capability 3.7).\r\nI am getting the following error when I run bazel build command.\r\n\r\n### Source code / logs\r\n```\r\nERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:4714:1: C++ compilation of rule '//tensorflow/core/kernels:multinomial_op_gpu' failed (Exit 1): msvc_wrapper_for_nvcc.bat failed: error executing command\r\n  cd C:/users/em/_bazel_em/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.2\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\shared;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\WINDOWS\\Microsoft.NET\\Framework64\\;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/em/AppData/Local/Programs/Python/Python35/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/em/AppData/Local/Programs/Python/Python35/lib/site-packages\r\n    SET TEMP=C:\\Users\\em\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=9.2\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\em\\AppData\\Local\\Temp\r\n  external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.bat /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include/crt /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w /arch:AVX2 -nvcc_options=disable-warnings -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/multinomial_op_gpu/multinomial_op_gpu.cu.o /c tensorflow/core/kernels/multinomial_op_gpu.cu.cc\r\nc:\\users\\em\\_bazel_em\\xv6zejqw\\execroot\\org_tensorflow\\external\\eigen_archive\\eigen\\src/Core/arch/CUDA/Half.h(212): error: more than one instance of overloaded function \"__hadd\" matches the argument list:\r\n            function \"__hadd(int, int)\"\r\n            function \"__hadd(__half, __half)\"\r\n            argument types are: (const Eigen::half, const Eigen::half)\r\n\r\n1 error detected in the compilation of \"C:/Users/em/AppData/Local/Temp/nvcc_inter_files_tmp_dir/multinomial_op_gpu.cu.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 772.580s, Critical Path: 147.05s\r\nINFO: 1931 processes: 1931 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["duplicate #19198"]}]