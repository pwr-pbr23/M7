[{"number": 10133, "title": "Segmentation fault: `help(tf.ConfigProto)` failed on python3", "body": "tensorflow for python3 failed while ran the following code:\r\n\r\n    $ python3\r\n    Python 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  2 2016, 17:53:06) \r\n    [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\n    >>> import tensorflow as tf\r\n    >>> tf.__version__\r\n    '1.1.0'\r\n    >>> help(tf.ConfigProto)\r\n    \u6bb5\u9519\u8bef (\u6838\u5fc3\u5df2\u8f6c\u50a8) In English: Segmentation fault (core dumped)\r\n\r\n    $ python3\r\n    Python 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  2 2016, 17:53:06) \r\n    [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n    >>> import tensorflow as tf\r\n    >>> tf.__version__\r\n    '1.2.0-rc0'\r\n    >>> help(tf.ConfigProto)\r\n    \u6bb5\u9519\u8bef (\u6838\u5fc3\u5df2\u8f6c\u50a8) In English: Segmentation fault (core dumped)\r\n\r\ntensorflow for python2 worked fine.\r\n\r\n    $ python2\r\n    Python 2.7.12 (default, Nov 19 2016, 06:48:10) \r\n    [GCC 5.4.0 20160609] on linux2\r\n    >>> import tensorflow as tf\r\n    >>> tf.__version__\r\n    '1.1.0-rc1'\r\n    >>> help(tf.ConfigProto)\r\n\r\n    >>> \r\n\r\n", "comments": ["You seem to be using RHEL 4. TensorFlow only supports RHEL 7+.", "@jart My OS is Ubuntu 16.04. The following result was on python3 without Anaconda. Failed\r\n\r\n    $ python3\r\n    Python 3.5.2 (default, Nov 17 2016, 17:05:23) \r\n    [GCC 5.4.0 20160609] on linux\r\n    >>> import tensorflow as tf\r\n    >>> tf.__version__\r\n    '1.1.0'\r\n    >>> help(tf.ConfigProto)\r\n    \u6bb5\u9519\u8bef (\u6838\u5fc3\u5df2\u8f6c\u50a8)\r\n"]}, {"number": 10132, "title": "TF ignore the computation graph and output the feeding value directly.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.1.0-rc0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n  a = tf.placeholder(dtype=tf.float32, shape=[1])\r\n  a = tf.multiply(a, 2)\r\n  with tf.Session() as sess:\r\n    output = sess.run(a, feed_dict={a: [1]})\r\n    print(output)\r\n```\r\n```\r\n[ 1.]\r\n```\r\n\r\n### Describe the problem\r\nAs the code above, I feed a value into the graph to do some computation. Notice that the input tensor's name is the same as the output tensor's name.\r\nMaybe the naming is a little confusing, but I think it is used quite often. \r\nI think it is a bug of tensorflow.\r\n", "comments": ["This is not a bug, you overwrote your value of \"a\" with `tf.multiply`, so you are feeding the output of tf.multiply and reading the same output simultaneously"]}, {"number": 10131, "title": "tf.contrib.distributions.Logistic   log_cdf method has wrong sign", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes?\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.3\r\n- **TensorFlow installed from (source or binary)**: binary, via pip\r\n- **TensorFlow version (use command below)**: 1.1.0 (v1.1.0-rc0-61-g1ec6ed5)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n```python\r\nimport tensorflow as tf\r\nlogistic = tf.contrib.distributions.Logistic(loc = 0., scale = 1.) \r\nlogistic.log_cdf(0.).eval(session = tf.Session())\r\n```\r\n### Describe the problem\r\n`tf.contrib.distributions.Logistic`'s `log_cdf()` method has the wrong sign. The above code returns `0.69314718`, but it should be `-0.69314718` (i.e. `log(0.5`).\r\nAppears to be the same for all parameters and values.\r\nThe `cdf()` method is fine.\r\nI've not seen this problem with `log_cdf()` in any of the other distributions, so it looks like an isolated bug.", "comments": ["@langmore Could you take a look at this one?", "Punting this issue to @jvdillon. PTAL.", "Thanks for finding this bug! I have created a fix and it should be in head within a few days."]}, {"number": 10130, "title": "tf.contrib.data: No op named OneShotIterator in defined operations", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary (nightly build from May 23rd)\r\n- **TensorFlow version (use command below)**: v1.2.0-rc0-172-g9e25de3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```\r\npython3 save.py\r\npython3 load.py\r\n```\r\n\r\n### Describe the problem\r\nI'm playing around with the new `tf.contrib.data` stuff because it looks awesome and can make a lot of my code a lot simpler. However, I'm trying to save and restore a graph that contains these new ops. Saving works fine, but loading doesn't work. If I inspect the saved file, it seems to be serializing everything correctly, I recognize the structure of all the data set ops I added in the code so that seems fine. In the case of the below example, I'm getting an error `No op named OneShotIterator in defined operations` when trying to load the graph again.\r\n\r\n### Source code / logs\r\nsave.py\r\n```python\r\nimport tensorflow as tf\r\n\r\ndataset = tf.contrib.data.Dataset.range(10)\r\ndataset = dataset.map(lambda x: x + 2)\r\nbatched_dataset = dataset.batch(4)\r\n\r\niterator = batched_dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\ntf.add_to_collection('next', next_element)\r\ntf.train.export_meta_graph(filename='graph', as_text=True)\r\n```\r\nload.py\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.train.import_meta_graph('graph')\r\nnext_element = tf.get_collection('next')[0]\r\n\r\nsess = tf.Session()\r\n\r\nprint(sess.run(next_element))\r\n```\r\n\r\nload.py output\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/ede/test/load.py\", line 3, in <module>\r\n    tf.train.import_meta_graph('graph')\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1683, in import_meta_graph\r\n    **kwargs)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 504, in import_scoped_meta_graph\r\n    producer_op_list=producer_op_list)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 283, in import_graph_def\r\n    raise ValueError('No op named %s in defined operations.' % node.op)\r\nValueError: No op named OneShotIterator in defined operations.\r\n```", "comments": ["Here's the saved graph file (in text format)\r\n[graph.txt](https://github.com/tensorflow/tensorflow/files/1021408/graph.txt)\r\n", "I think this is a general problem with ops defined in the `tf.contrib` namespace, because they are lazily registered on the first use of any `tf.contrib` module. If you add the statement `dir(tf.contrib)` (or something else that uses `tf.contrib`) before calling `tf.train.import_meta_graph()`, it should work.", "Wow really. Will try that first thing tomorrow. ", "Yes, that fixed it. Thanks!", "@EdeMeijer Could you please share the code that made it work? Because I face similar problem for a quantized graph of inception resnet model. I get .\r\nI get \"ValueError: No op named QuantizedAdd in defined operations\"\r\n\r\n I tried using \"dir(tf.contrib)\". However, it didn't work for me. I am not sure if I am using it right way.", "@rajnamitha the Python file I used it in literally starts like this\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Force load contrib ops\r\ndir(tf.contrib)\r\n\r\n```\r\nand the rest is just ordinary TensorFlow code. If you're doing the same thing and still running into your problem my advise would be to open a new issue.", "@EdeMeijer : It is still not solving the problem in my case, so opened an issue. Hope to get a solution. Thanks for your information :)", "I get this: ValueError: No op named SSTableReader in defined operations when trying to freeze resnet_v2 graph. \r\nSearching by all tensorflow code doesn't find 'SSTableReader' anywhere. Some help, please?\r\n", "@1int : I didn't face \"No op named... \" error while freezing though. But maybe it is similar case as mine, where I got \"No op named...\" error while loading the quantized graph. \r\nWith what helped me, I suggest you to build tensorflow from latest source code rather than binary version.\r\nAs maybe you are using latest script  for freezing the graph but the tensorflow version you are using could be a older one. Building tensorflow from source code could help to avoid this problem.  ", "I get the same error-\r\nValueError: No op named SSTableReader in defined operations.\r\nwhile running tf.train.import_meta_graph on the meta file. The dir(tf.contrib) solution did not help.\r\n\r\nI am using a pre-trained model from-\r\nhttps://github.com/openimages/dataset\r\n\r\nThanks.", "@1int @sxs4337 What was the source of the graph/metagraph containing an `SSTableReader` op? That is not part of the TensorFlow API, so it sounds like whoever built that graph inadvertently included some proprietary/custom ops in the graph....", "I had used the graph from pre-trained model on OpenImages dataset. I was able to get a workaround as discussed in this post-\r\nhttps://github.com/openimages/dataset/issues/21\r\n\r\nThanks.\r\n", "OK, judging by the comments that issue, it's a bug in the released graph, which shouldn't contain an `SSTableReader` op in the first place. Glad to hear that you've found a workaround!", "@EdeMeijer your solution worked for my VGG16 graph: https://gist.github.com/eggie5/7d9c31c08462ec42ed8d927f2c0c3e55\r\n\r\n```\r\nimport tensorflow as tf\r\ndir(tf.contrib) #hack per https://github.com/tensorflow/tensorflow/issues/10130\r\nwith tf.Session() as sess:  \r\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], 'model/export/1509295446/')\r\n    print [n.name for n in tf.get_default_graph().as_graph_def().node]\r\n```\r\n\r\nBefore I was getting that same error as you."]}, {"number": 10129, "title": "ZeroDivisionError: integer division or modulo by zero", "body": "I got this error messsage when trying to train the images. FYI my images is more than 20.\r\n\r\nMy command\r\n\r\n```\r\nsudo python retrain.py --bottleneck_dir=tf_files/bottlenecks --how_many_training_steps=500 --model_dir=tf_files/inception --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir /Users/ZERO/Documents/Github/tensorflow-python/tf_files/images/..\r\n```\r\n\r\nError message\r\n\r\n```\r\nLooking for images in 'bottlenecks'\r\nNo files found\r\nLooking for images in 'images'\r\nLooking for images in 'inception'\r\nWARNING: Folder has less than 20 images, which may cause issues.\r\nLooking for images in 'images'\r\nLooking for images in 'inception'\r\nWARNING: Folder has less than 20 images, which may cause issues.\r\n2017-05-23 13:00:12.940135: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 13:00:12.940170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 13:00:12.940177: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 13:00:12.940184: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 13:00:12.940190: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 13:00:21.462092: Step 0: Train accuracy = 100.0%\r\n2017-05-23 13:00:21.462469: Step 0: Cross entropy = 0.427569\r\nCRITICAL:tensorflow:Label inception has no images in the category validation.\r\nTraceback (most recent call last):\r\n  File \"retrain.py\", line 1107, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"retrain.py\", line 910, in main\r\n    bottleneck_tensor))\r\n  File \"retrain.py\", line 515, in get_random_cached_bottlenecks\r\n    image_dir, category)\r\n  File \"retrain.py\", line 227, in get_image_path\r\n    mod_index = index % len(category_list)\r\nZeroDivisionError: integer division or modulo by zero\r\n```\r\n\r\n![screenshot 2017-05-23 13 39 48](https://cloud.githubusercontent.com/assets/5416242/26339821/52177d42-3fbd-11e7-88a2-17e6df781d52.png)\r\n\r\nPlease advice. Thank you.", "comments": ["`CRITICAL:tensorflow:Label inception has no images in the category validation.` \r\nand warning says you need more images in inception.\r\nSo instead of \"images\" folder, can you share what's in \"inception\" folder?", "Here is the inception folder.\r\n\r\n![screenshot 2017-05-23 15 18 47](https://cloud.githubusercontent.com/assets/5416242/26342595/56176534-3fcb-11e7-8a50-f7bdda4eb3e7.png)\r\n\r\n", "See if this link helps\r\nhttps://stackoverflow.com/questions/41542706/tensorflow-label-inception-has-no-images-in-the-category-training?rq=1", "Thank you for supporting our friend @shitian-ni.", "@jart You are welcome.\r\n\r\n@datomnurdin I think the actual error reason is in your command argument `--image_dir /Users/ZERO/Documents/Github/tensorflow-python/tf_files/images/..`.\r\nThe `..` in the end means the parent folder of images folder. So it also find images in folder bottlenecks and inception.\r\nYou should delete `..` from the argument.\r\nAnother point is that I think you should put images in folder \"images\" in subfolders with folder name as category names", "@shitian-ni The problem still occur even I already put more than 2++ images. Still generate this error message\r\n\r\n```\r\n2017-05-27 19:52:29.487781: Step 0: Train accuracy = 100.0%\r\n2017-05-27 19:52:29.489798: Step 0: Cross entropy = 0.440165\r\nCRITICAL:tensorflow:Label inception has no images in the category validation.\r\nTraceback (most recent call last):\r\n  File \"retrain.py\", line 1107, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"retrain.py\", line 910, in main\r\n    bottleneck_tensor))\r\n  File \"retrain.py\", line 515, in get_random_cached_bottlenecks\r\n    image_dir, category)\r\n  File \"retrain.py\", line 227, in get_image_path\r\n    mod_index = index % len(category_list)\r\nZeroDivisionError: integer division or modulo by zero\r\n```\r\n\r\nPlease advice.", "@datomnurdin Did you remove `..` from `--image_dir ` argument?", "@shitian-ni yeah, its fixed. worked now. thanks.", "good day for datomnurdin \r\nfinally... can you write the working list of params?\r\nbecause I have the same problem with the \"Label inception has no images in the category validation\"", "Hello datomnurdin ,\r\n\r\nCan you please highlight what worked, Im facing same issue.\r\n\r\nThank You", "It worked, pls ignore.\r\n\r\nThanks ", "Instead of using \r\n\r\n`--image_dir=fruits`\r\n\r\nuse \r\n\r\n`--image_dir=./fruits`\r\n\r\n"]}, {"number": 10128, "title": "tensorflow 1.2 release will support python 3.6\uff1f", "body": "tensorflow 1.2 release will support python 3.6\uff1f", "comments": ["Would love to know this too....", "Closing as a duplicate of #6999 "]}, {"number": 10127, "title": "Implement IRFFT as a CPU kernel", "body": "Mentioned in issue #386 and #9029. TF is now supporting FFT operators. However, there still remains IRFFT as a CPU kernel unimplemented. In this PR I made up the missing part of `FFTCPU` class, and get the CPU kernel for IRFFT work.\r\nI remove the limitation of `if test.is_gpu_available(cuda_only=True):` in `fft_ops_test.py`, and passed all test cases by `bazel test --config=opt -k //tensorflow/python/kernel_tests:fft_ops_test`.\r\n\r\nThe code is linted by clang-format 3.8 using google code style.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@tensorflow-jenkins test this please.", "Jenkins test this please.", "```\r\n\r\n99% tests passed, 1 tests failed out of 281\r\n\r\nTotal Test time (real) = 738.47 sec\r\n\r\nThe following tests FAILED:\r\n\t231 - C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/training/saver_test.py (Failed)\r\nErrors while running CTest\r\n\r\nc:\\tf_jenkins\\home\\workspace\\tensorflow-pr-win-cmake-py\\cmake_build>exit 8 \r\nBuild step 'Execute Windows batch command' marked build as failure\r\n[Set GitHub commit status (universal)] ERROR on repos [] (sha:7a9126c) with context:tensorflow-pr-win-cmake-py\r\nUnable to get pull request builder trigger!!\r\nSetting status of 538e0ce284abadcbfd58ed8e0aa04715020d5add to FAILURE with url https://ci.tensorflow.org/job/tensorflow-pr-win-cmake-py/2493/ and message: 'FAILURE\r\n '\r\nUsing context: Windows Cmake Tests\r\nFinished: FAILURE\r\n```\r\nIt seems the failure of Windows Cmake Tests is unrelated to this PR."]}, {"number": 10126, "title": "cudnn: Fix symlink includes handling", "body": "Following a change to symlink creation for cuda_configure.bzl, the cudnn\r\ninclude path symlink would try to link to a path ending with\r\n'includeinclude/cudnn.h' rather than the correct path, 'include/cudnn.h'.\r\nIt appears this is caused by the way _symlink_genrule_for_dir handles\r\nparticular source header files. Since the cudnn library only exports a single\r\ninclude file, cuda_configure.bzl can just use _symlink_genrule_for_dir\r\nwithout explicitly specifying the header files to symlink.", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "@jart @caisq can you comment on this?\r\n\r\n@jthestness There's a conflict, likely because someone else solved the same problem, can you rebase and see whether this is still needed?", "@jthestness Bazel recommends against a genrule specifying a directory as an input or output. It's best to have individual files be listed. I read your commit message, but I don't 100% understand yet what's going on here.\r\n\r\nOne thing that might help is if you run the following command:\r\n\r\n```sh\r\nless $(bazel info output_base)/external/local_config_cuda/cuda/BUILD\r\n```\r\n\r\nThat will show you the generated BUILD file so we can get a better idea of what this genrule looks like, and why it's behaving poorly.", "I was able to rebuild current mainline without this PR, so it does seem that someone else fixed this issue. This PR can be closed.", "Thanks for the info, @jthestness "]}, {"number": 10125, "title": "Feature request: weight normalization", "body": "Is it possible to incorporate Weight Normalization (https://arxiv.org/abs/1602.07868) into tensorflow itself?\r\n\r\nhttps://github.com/openai/weightnorm/tree/master/tensorflow", "comments": ["@rmlarsen Any thoughts on this feature request?", "@appierys that's just a link to a file with helper utilities, there no actual implementation of the algorithm there", "@yaroslavvb I do think the file contains the implementation of WN. For example, here is the implementation of weight norm in a fully connected layer: https://github.com/openai/weightnorm/blob/master/tensorflow/nn.py#L166", "@appierys that indeed looks like one of the formulas, but some other ones are missing. (ie, equation for updating the step length parameter)", "Hi\r\nSeconding @appierys 's request, we have also been experimenting with weight-normalisation in RNNs with great results. It seems to be significantly helpful in stabilising training and reducing its dependence on hyperparameters. Seeing as this has become a default RNN configuration for us, we are quite keen on integrating it with the tensorflow rnn machinery. \r\n\r\nOur implementation is based on \r\nhttps://github.com/openai/generating-reviews-discovering-sentiment/blob/master/encoder.py\r\n\r\nwhich requires a few lines of additional code in tensorflow core. This is because in the current setup (dynamic_rnn etc.) RNN weights are created via the cell's call() function which is called from within tf.while(). Based on the above link, weight-normalised cells require weight creation and normalisation before entering the while loop. \r\n\r\nThis may not be the best way to implement it, but for the moment we have sent in a pull request:\r\nhttps://github.com/tensorflow/tensorflow/pull/11573\r\n\r\nWe'd be keen to hear your thoughts and/or to engage in further testing/discussing a different implementation structure.\r\n", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "We'd be interested in considering a contribution adding this support.", "@discoveredcheck Thanks for your contribution, and I have read your PR about \"WeightNormLSTMCell\".\r\n\r\nI notice that you define variables in the functions self._linear and self._normalize, and do not set tf.AUTO_REUSE flag. So, I wonder how to ensure the variables are reused when self.call are invoked multiple times? I test your code, and it works well. I just want to know how it works.", "@llan-ml Apologies for the late reply. `WeightNormCell` follows convention from other `RNNCell`sand relies on the caller to use `call()` only once. From the doc - \"Note that while_loop calls cond and body exactly once (inside the call to `while_loop`, and not at all during `Session.run()`)\"\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/while_loop \r\n\r\nHope this helps.\r\n\r\nAshwini", "Thanks for your explanations @discoveredcheck. \r\n\r\nOn the other hand, to enable weight normalization for dense and convolutional layers, can we just add the weight normalization in the `self.build()` method of `tf.Layer`.\r\nFor example, in the scenario of `Dense` layer, we can add weight normalization by modifying https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/core.py#L132 as follows:\r\n<pre>\r\nkernel = self.add_variable(\"kernel\", ...)\r\nif self._weight_norm:\r\n    g = self.add_variable(\"wn/g\", ...)\r\n    self.kernel = nn_impl.l2_normalize(kernel, axis=0) * g\r\nelse:\r\n    self.kernel = kernel\r\n</pre>\r\nSimilar modifications could be also made for `tensorflow.python.layers.convolutional._Conv`.\r\nDo you have any suggestions?", "Yes, adding the weight-norm update in `self.build()` seems to be the correct pattern. It is also correct to omit out `with tf.control_dependencies(None)` compared to the RNN weight-norm code. \r\n\r\nYour link, however, revers to L152 which is inside `self.call()`. I assume you mean L132?", "Yeah, it should be L132, and I have corrected the link.", "I write some simple wrappers for dense and conv2d layers with weight normalization.\r\nhttps://github.com/llan-ml/weightnorm", "Duplicate of #14070 \r\n\r\nThis has been implemented in tensorflow/addons. Issue can be closed.\r\n\r\n[Code](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/layers/wrappers.py)\r\n[Example](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/examples/layers_weightnormalization.ipynb)", "Thanks, Sean :-)"]}, {"number": 10124, "title": "[feature request] decode_raw for uint16 and other dtype", "body": "### System information\r\n- NO\r\n- NOT RELATED\r\n- NOT RELATED\r\n- NOT RELATED\r\n- NOT RELATED\r\n- NOT RELATED\r\n- NOT RELATED\r\n- NOT RELATED\r\n\r\n\r\n### Describe the problem\r\nCurrent decode_raw only supports `tf.half, tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.int64`. It would be helpful if more types are available.\r\n\r\n", "comments": ["@keveman Could you take a look at this please? Thanks.", "Added PR #12719 to support uint16 for tf.decode_raw."]}, {"number": 10123, "title": "why inputs transpose to inputs_transposed in fc_layer model? I think it not need to do this, and it just change sort of dim_1, dim_2, dim_3 ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Thinks.\r\n\r\n\u53d1\u9001\u81ea Windows 10 \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u5e94\u7528\r\n\r\n\u53d1\u4ef6\u4eba: Justine Tunney<mailto:notifications@github.com>\r\n\u53d1\u9001\u65f6\u95f4: 2017\u5e745\u670824\u65e5 9:52\r\n\u6536\u4ef6\u4eba: tensorflow/tensorflow<mailto:tensorflow@noreply.github.com>\r\n\u6284\u9001: Jinlong Xu<mailto:issxjl2015@outlook.com>; Author<mailto:author@noreply.github.com>\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] why inputs transpose to inputs_transposed in fc_layer model? I think it not need to do this, and it just change sort of dim_1, dim_2, dim_3 (#10123)\r\n\r\n\r\nThis question is better asked on StackOverflow<http://stackoverflow.com/questions/tagged/tensorflow> since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\n\u2015\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/10123#issuecomment-303595462>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ASz9p9R-MnAm7PCmkyQ7Qy5f48WcfydXks5r841pgaJpZM4NjIvK>.\r\n\r\n"]}, {"number": 10122, "title": "Allow disabling password and token auth on jupyter notebooks", "body": "Closes: https://github.com/tensorflow/tensorflow/issues/10045\r\n\r\n/CC @mrry @ali01", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10121, "title": "Use file DLL of tensorflow on window", "body": "Anyone have example to use file DLL of tensorflow on window, please help me! I working with VS 2015, thanks in advance.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 10120, "title": "Update vulcanized output of TensorBoard to fix health pill errors.", "body": "The previous version of TensorBoard in release 1.2 had outputted console errors related to debugger health pills (a currently internal feature). This new vulcanized output fixes that bug in release 1.2 by adding guards.\r\n\r\nMy text editor also removed some blank characters.", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10119, "title": "Memory leak in Java API due to missing TF_DeleteStatus", "body": "This is a leak confirmed on [StackOverflow](https://stackoverflow.com/questions/44082297/memory-leak-using-tensorflow-for-java) by [ash](https://stackoverflow.com/users/6708503/ash).\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.  There's a short example in the above StackOverflow link and a [working JUNIT test written in a maven project on github](https://github.com/jpangburn/tensorflowmemorytest) that demonstrates the problem.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS Sierra using TF 1.1, and CentOS7 using both TF 1.1 and TF 1.2_rc0.\r\n- **TensorFlow installed from (source or binary)**: binary from Maven\r\n- **TensorFlow version (use command below)**: On Mac uses Maven `<version>1.1.0</version>`, on CentOS7 `<version>1.2.0-rc0</version>`\r\n\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See above for the short example on the StackOverflow link or the full Java file at the github example project.\r\n\r\n### Describe the problem\r\nRunning the example code given causes the process memory (outside the JDK, not heap space) to grow until the process exits.  Leaked was agreed to be in TensorFlow by ash at StackOverflow:\r\n\r\n> I believe there is indeed a leak (in particular a missing TF_DeleteStatus corresponding to the [allocation in JNI code](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/java/src/main/native/session_jni.cc#L191)) \r\n\r\n### Source code / logs\r\nThe test file is [here](https://github.com/jpangburn/tensorflowmemorytest/blob/master/src/test/java/com/jessepangburn/tftest/tensorflowtest/AppTest.java) within the above reference github project.\r\n\r\nThank you for providing this amazing tool!\r\n", "comments": ["Thanks for pointing this out and the detailed report (and ability to reproduce).\r\nThis has been fixed internally and should be reflected in Github during our next sync (within the next day) and will be part of the next release candidate for 1.2. ", "Very glad to be able to give back a tiny bit!  Thanks again!", "For the record, https://github.com/tensorflow/tensorflow/commit/24f243deee41d8008bf37ae98d825f8f9f050de4 fixes this.\r\n", "Does this fix apply to the GPU version of the libraries as well? Specifically, I'm wonder about `libtensorflow_jni-gpu-linux-x86_64-1.3.0-rc1.tar.gz`. I run out of memory when running with that library on an Nvidia card. ", "Yes, the fix applies to both. You might be running into something else. Please file a new issue, ideally with steps to reproduce the problem. Thanks!", "@asimshankar, see #11948 "]}, {"number": 10118, "title": "Incorrect behavior from `tf.layers.batch_normalization()` when `training=0`", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8/5\r\n- **GPU model and memory**: Nvidia Titan X \r\n- **Exact command to reproduce**: [gist](https://gist.github.com/zo7/87735a3f06a41e0f2b3c10f9950d07a3)\r\n\r\n### Describe the problem\r\n\r\nI've noticed that `tf.layers.batch_normalization` doesn't seem to give reasonable results when `training=0` (i.e. use distribution statistics instead of just the batch), especially if you apply BN *before* activations (e.g. ResNet-like architectures).\r\n\r\nUsing the Gist above, if you try to fit a model to noise with SGD (lr=0.01) using repeated applications of dense matrix multiplication -> batch normalization -> ReLU activations, you get this loss for the _same_ inputs over time: (blue: `training=1`, green: `training=0`)\r\n\r\n![image](https://cloud.githubusercontent.com/assets/3229244/26330609/9f3fa0ca-3f01-11e7-8f73-81d67e64be97.png)\r\n\r\nUsing an Adam (lr=0.001) optimizer instead gets even weirder results:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/3229244/26330754/49c94eb0-3f02-11e7-9ff6-7d48ad471ea2.png)\r\n\r\nHowever, if I use my own implementation of batch norm (included in gist) I get reasonable results, with the loss for each being similar to each other: (Adam has similar behavior)\r\n\r\n![image](https://cloud.githubusercontent.com/assets/3229244/26330911/1922c81c-3f03-11e7-86bf-56f0e38e3ff3.png)\r\n\r\n(Interestingly this doesn't seem to be as much of a problem if you have ReLU before BN, I haven't thought too deeply about why.)\r\n\r\nAm I seeing things and just have some misunderstanding about what that function is doing, or is this actually a bug?", "comments": ["The document of `tf.layers.batch_normalization` said this:\r\n```\r\nNote: the operations which update the moving_mean and moving_variance variables will not be added as dependencies of your training operation and so must be run separately. For example:\r\nextra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nsess.run([train_op, extra_update_ops], ...)\r\n```\r\nBut you didn't use it in your code.", "Where did you find that? The [API reference](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization) says *nothing* about needing to run extra operations or adding extra operations to `UPDATE_OPS`.\r\n\r\nThe entire description:\r\n\r\n> Defined in tensorflow/python/layers/normalization.py.\r\n>\r\n> Functional interface for the batch normalization layer.\r\n>\r\n> Reference: http://arxiv.org/abs/1502.03167\r\n>\r\n> \"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"\r\n>\r\n> Sergey Ioffe, Christian Szegedy", "Sorry I was reading an old version of the doc. The way to run the update may have changed.", "No. I was actually reading a newer version of doc. See here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/normalization.py#L338", "Oh wow, surprised that's not on the website... I'll close this then, since it looks like the change to the doc has already been made.", "Just for the sake of completeness, here is the recommended code from the docs:\r\n\r\n          update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n          with tf.control_dependencies(update_ops):\r\n            train_op = optimizer.minimize(loss)", "I am using \r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nthen..\r\nsess.run(train_step,update_ops,feed_dict={x: batch[0], y_: batch[1],istrain:True})\r\n\r\nbut it is showing error as \r\nTypeError: run() got multiple values for argument 'feed_dict'.\r\n\r\nIf I don't include \"update_ops\" in the sess.run() then it works fine but i need to create a dependency.\r\nCould anyone tell that what's wrong:", "@akssieg 1. You should make `update_ops` a dependency as mentioned above, and 2. you're not calling `sess.run()` correctly \u2013 all of your fetches/ops should be a single list/dict, not multiple arguments.\r\n\r\nTry using:\r\n```python\r\nsess.run([train_step, update_ops], feed_dict={...})\r\n```\r\n(notice the square brackets)"]}, {"number": 10117, "title": "Merge pull request #1 from tensorflow/master", "body": "Update from original", "comments": []}, {"number": 10116, "title": "Merge pull request #1 from tensorflow/master", "body": "Update from original", "comments": ["Can one of the admins verify this patch?", "Hey,\n\nI am sorry I am new to the pull request. I just want to update tensorflow\nin my fork from tensorflow/tensorflow and not sure if I did it right.\nThanks!\n\nNathan\n\nOn 22 May 2017 at 15:05, Tensorflow Jenkins <notifications@github.com>\nwrote:\n\n> Can one of the admins verify this patch?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/10116#issuecomment-303232520>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AC9NF4MefYRrSXRv1KW5VctSFdn1ADhYks5r8ga-gaJpZM4Ni8W4>\n> .\n>\n\n\n\n-- \n\u6b63\u80fd\nwww.qiuzhengneng.com\n"]}, {"number": 10115, "title": "Fix TF windows bazel tests.", "body": " - Ignore errors in shutil.rmtree until we figure out why rmtree fails.\r\n - Do not run neon_depthwise_conv_op, as we already omit linking in\r\n the op.", "comments": ["The rmtree fails because the SummaryWriterCache keeps open file handles around which causes Windows to disallow removing the directory.\r\n\r\nLook at estimator_test: test_train_save_copy_reload for an example of how to fix.\r\n\r\n@ispirmustafa should we call SummaryWriterCache.clear() after each train()/eval() call? There's little we gain from this cache between invocations.", "we need to keep cache for some edge cases. For example let's say there are two threads one for training and one for evaluation.", "But that doesn't prevent us from clearing the cache, right? All that would\ndo is force us to reopen the writer, which is a performance hit but should\notherwise be harmless.\n", "http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/10/consoleFull\r\nLooks like adding `ignore_errors=True` didn't fix the shutil.rmtree error.", "I can try, but for the said edge cases, multiple threads can also be causing the failures to remove files.", "Running windows presubmits here:\r\nhttp://ci.tensorflow.org/job/tensorflow-pr-win-bazel/11/", "Well that didn't work -- There shouldn't be multiple thread unless several methods inside DNNRegressorEvaluateTest run in multiple threads, and even then, the directory is unique to that test case. ", "It did not work because there were >1 `shutil.rmtree` calls, I now updated them all.\r\nTrying again.\r\nhttp://ci.tensorflow.org/job/tensorflow-pr-win-bazel/12/", "Looks like some machines had some missing libraries?\r\nhttp://ci.tensorflow.org/job/tensorflow-pr-win-bazel/13/\r\n\r\nRetrying tests.", "There were some new tests added to this file.\r\nAlso modified them, and rerunning tests:\r\nhttp://ci.tensorflow.org/job/tensorflow-pr-win-bazel/14/", "OK, now I got all the tests. Looks like while I was fixing testcases, more cases were added to dnn_test.\r\n\r\nhttp://ci.tensorflow.org/job/tensorflow-pr-win-bazel/16/console"]}, {"number": 10114, "title": "Fix code example in supervisor.md", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10113, "title": "Merging rc0 back into master.", "body": "Merging 1.2.0-rc0 back into the master branch.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Jenkins, test this please."]}, {"number": 10112, "title": "Updated libxsmm kernels", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "Just to make sure. do we have a CLA in place for @hfp?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "We have a CLA in place with @hfp"]}, {"number": 10111, "title": "ImportError: No module named '_pywrap_tensorflow_internal'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 7 \r\n- **TensorFlow installed from (source or binary)**:\r\nUsing pip3 \r\n- **TensorFlow version (use command below)**:\r\n1.1\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n8.0 \r\n- **GPU model and memory**:\r\nQuadro K620\r\n- **Exact command to reproduce**:\r\nimport tensorflow as tf\r\n\r\nI have installed everything following the instructions and opened a [ post on SO ](https://stackoverflow.com/questions/44080677/no-module-named-pywrap-tensorflow-internal) but haven't receieved many responses. I have looked at multiple other posts with the same keywords but was unable to solve the issue from there. I used the standard installation instructions using pip3 for windows. \r\n\r\nThe following is the stacktrace when I run \"import tensorflow as tf\" in python command line. \r\n\r\n```\r\nMicrosoft Windows [Version 6.1.7601]\r\nCopyright (c) 2009 Microsoft Corporation.  All rights reserved.\r\n\r\nC:\\Users\\aagarwal>python\r\nPython 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AM\r\nD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_hel\r\nper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\_\r\n_init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_hel\r\nper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\_\r\n_init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_hel\r\nper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\_\r\n_init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 914, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packag\r\nes\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_hel\r\nper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\aagarwal\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\_\r\n_init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_probl\r\nems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>\r\n```", "comments": ["It is possible some of the files did not get installed properly.\r\nCould you try reinstalling TF, maybe that will resolve the problem?", "Same problem . \r\nWindows 10 / Python 3.5.3 / CPU mode", "Solved. \r\n\r\nIssue was with CuDNN version. Version 6.0 does not work. You need to install version 5.1. ", "@amtagrwl thanks, worked for me too (python 3.5.3 with Pycharm community, CuDA 8.0, windows 10, CuDNN 5.1 - works now)", "Worked for me too ! (python 3.5.3, windows 10, Cuda 8.0 and TITAN xp", "CuDNN 5.1 (not 6.0) solved the problem!\r\nFor windows, you also need to make sure to add path for CuDNN.", "I still get this error even though I have CUDNN 5.1 installed. What environment variables do I need specified?", "Would it be possible to improve the error messaging to give developers more guidance?\r\n\r\nFor example, if the cuDNN DLL isn't found, the error message could recommend installing the version 5.1 and adding its bin/ directory to the system path.", "@nectario Did you try adding the cuDNN's bin/ directory to your system's \"Path\" environment variable?\r\n\r\n![cuda-bin-path](https://user-images.githubusercontent.com/1216762/27255268-c3c4e9fc-534f-11e7-968e-af673f5e3493.png)\r\n", "Let me do that! Than you!", "Check installed Microsoft Visual C++ 2015 Redistributable Update 3\r\nYou may install this DLL by downloading Microsoft Visual\r\nC++ 2015 Redistributable Update 3 from this URL:\r\nhttps://www.microsoft.com/en-us/download/details.aspx?id=53587\r\n\r\nit's helped me", "@ChrisAntaki It worked for me, too! Thank you!", "If you are using tensorflow 1.3 then you want to use the cuDNN v6.0 dll https://github.com/tensorflow/tensorflow/issues/7705", "@chriswbarrett  Thanks alot,I have wasted a day looking where I went wrong.Using the cuDNN v6.0 dll worked for me.Thank you!!!", "Had the same problem. Resolved using CUDA 9.0 and tf-nightly-gpu as suggested above. I have put up instructions here: https://github.com/rohit-patel/Install_Instructions-Win10-Deeplearning-Keras-Tensorflow"]}, {"number": 10110, "title": "Python bindings to CTC Beam Search do not allow a dictionary to be specified", "body": "In the underlying C++ code, tested here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_beam_search_test.cc#L103\r\n\r\na dictionary can be used.  However, the python bindings do not expose the ability to specify a dictionary scorer at all.  See here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/ctc_ops.py#L219", "comments": ["@andrewharp Could you take a look please? Thanks.", "Is this issue resolved? Please update here If it was not resolved already. Thanks!", "Please check with the latest version of TensorFlow. Feel free to reopen if the issues still persists."]}, {"number": 10109, "title": "TensorFlow 1.2.0rc0 strange behavior with Benchmark scripts", "body": "I'm running https://github.com/tensorflow/benchmarks/ scripts by @tfboyd and I'm observing strange behavior and crashes.\r\n\r\n1. There's a LOT of messages like these (below).  These messages happen in both standalone and distributed runs.\r\n\r\n```\r\n2017-05-22 17:21:00.589871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P40, pci bus id: 0000:85:00.0)\r\n2017-05-22 17:21:00.600723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)\r\n2017-05-22 17:21:00.600741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P40, pci bus id: 0000:05:00.0)\r\n2017-05-22 17:21:00.600746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P40, pci bus id: 0000:84:00.0)\r\n2017-05-22 17:21:00.600750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P40, pci bus id: 0000:85:00.0)\r\n2017-05-22 17:21:00.619525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)\r\n2017-05-22 17:21:00.619543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P40, pci bus id: 0000:05:00.0)\r\n2017-05-22 17:21:00.619548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P40, pci bus id: 0000:84:00.0)\r\n2017-05-22 17:21:00.619552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P40, pci bus id: 0000:85:00.0)\r\n2017-05-22 17:21:00.629770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)\r\n2017-05-22 17:21:00.629786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P40, pci bus id: 0000:05:00.0)\r\n2017-05-22 17:21:00.629807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P40, pci bus id: 0000:84:00.0)\r\n2017-05-22 17:21:00.629811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P40, pci bus id: 0000:85:00.0)\r\n2017-05-22 17:21:00.649854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)\r\n2017-05-22 17:21:00.649871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P40, pci bus id: 0000:05:00.0)\r\n2017-05-22 17:21:00.649892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P40, pci bus id: 0000:84:00.0)\r\n```\r\n\r\n2. ~~In distributed mode, TF 1.2.0 rc0 is not able to handle batch size 64 for Inception V3:~~ - This was figured out.\r\n\r\nSlave worker crashes with:\r\n```\r\n2017-05-22 17:22:25.411569: W tensorflow/core/framework/op_kernel.cc:1158] Resource exhausted: OOM when allocating tensor with shape[64,32,149,149]\r\n```\r\n\r\nChief worker crashes with:\r\n```\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\r\n    self.run()\r\n  File \"tf_cnn_benchmarks.py\", line 226, in run\r\n    global_step_val, = self.sess.run([self.global_step_op])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 925, in _run\r\n    raise RuntimeError('Attempted to use a closed Session.')\r\nRuntimeError: Attempted to use a closed Session.\r\n```\r\n\r\nMy command:\r\n```\r\npython -u tf_cnn_benchmarks.py --model inception3 --batch_size 64 --num_gpus 4 --worker_hosts {worker_hosts} --ps_hosts {ps_hosts} --task_index {task_index} --job_name {job_name} --local_parameter_device cpu\r\n```\r\n\r\nThis worked perfectly fine on hash cae8ed1ca54a9fd4f9cc64d08cadebce31fd4607 (just a little bit past TF 1.1 release).", "comments": ["Thanks Alex.  I will take a look and thank you.  I can definitely help and will take a look but I cannot take credit for the scripts.  I was just the person that did the commit to github  :-) .\r\n\r\nOne quick note before I dig in.  My guess is it is creating multiple copies on each GPU.  Check nvidia-smi to see how many python processes are running on each GPU.  it should be 1 on each GPU so 4 total in your situation.  Sometimes if you kill the script it will not kill the processes on the GPUs and you end up doubling up.  Worth a quick check.  I also made a mistake in the documents and when you start the PS server you want to do this, which I assume you likely already know.  Even if your ps_server is set to CPU TensorFlow ill still try to take memory from the GPUs when starting the stand alone ps_server:  \r\n\r\n```bash\r\nCUDA_VISIBLE_DEVICES='' python tf_cnn_benchmarks.py\r\n```\r\n\r\nI do not know a lot about the P40 other than it seems to be a card usually used for inference and has 24GB of memory which should be more than enough for batch 64.  I have used Batch-Size 128 on the P100 and it only has 16GB.  Not with TF 1.2, so I will give that a try to see if I can repo.\r\n\r\nThank you for the heads up.\r\n", "@tfboyd sorry, I found the reason for crash - rogue process was running on the host that locked GPU memory.  Apologies for ruckus.\r\n\r\nAny idea about all those `Creating TensorFlow device` lines?\r\n```\r\n2017-05-22 17:21:00.600746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P40, pci bus id: 0000:84:00.0)\r\n```\r\n\r\nI originally suspected that's what was causing OOM.", "I do not know.  No bother on the ruckus.  It is unlikely I will find time to figure out who makes that message but if I do I will update this post.  Not lack of desire, just a lack of time.  I am closing this issue but again will update if I find out that message purpose / reason.  "]}, {"number": 10108, "title": "Reverting the manual tags added to problem tests.", "body": " Hopefully we can fix them by rc1.", "comments": ["Are these fixed?\r\nIf they are not fixed yet, let's wait on this until we have a fix.", "Is it okay to merge 1.2 back into master then? This would disable these tests from nightly as well. "]}, {"number": 10107, "title": "Tensorflow Library not loading in macOS (ImportError)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo. I've strictly followed the on-site tutorial\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nmacOS Sierra\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary (https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py2-none-any.whl)\r\n- **TensorFlow version (use command below)**:\r\nlatest (same as that of on-site tutorial version)\r\n- **Bazel version (if compiling from source)**:\r\nNot used as it isn't given in tutorial\r\n- **CUDA/cuDNN version**:\r\nCUDA - 8.0\r\ncuDNN - 6.0\r\n- **GPU model and memory**:\r\nGPU: NVIDIA GeForce GTX 775M 2048 MB\r\nMemory: 8 GB 1600 MHz DDR3\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\nYou can obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: dlopen(/Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcudnn.5.dylib\r\n  Referenced from: /Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n  Reason: image not found\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n\r\n", "comments": ["We have dropped support for Mac-GPU setups, starting with 1.2 release.\r\nBut your problem is caused by mismatch in cuDNN versions.\r\n\r\nAll TF binaries are built with cuDNN 5 support.\r\nFor use with cuDNN 6, you will need to build from sources.", "I had the same problem 'ImportError: dlopen(/Users/dwdcw/miniconda3/envs/tf27/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, ' .\r\nI solved this by using VirtualEnv to install tensorflow and then success.\r\nI think maybe VirtualEnv can provide more clear enviroment. You can try", "I have tried tensorflow-1.10 but got the same problem.\r\nIt works on tensorflow-1.9.0", "Same problem. tensorflow-1.9.0 works but 1.10 doesn't."]}, {"number": 10106, "title": "Feature request: improve tensorboard embeddings search", "body": "Currently, when making a search query using a custom variable, let's say a relevance score, then results display relevance scores. This is not always helpful. In my application, I have word embeddings that I would like to filter by a custom variable (relevance score), and I can't see what word is corresponding to each relevance score (see screenshot).\r\n\r\nIt would be better to have a separate field so that users can define how they would like to see the results of their search query.\r\n![screen shot 2017-05-22 at 11 54 44](https://cloud.githubusercontent.com/assets/12895366/26317930/3acefc0e-3ee7-11e7-8f17-5b9866679e5f.png)\r\n\r\n", "comments": ["I've migrated this to tensorflow/tensorboard."]}, {"number": 10105, "title": "Feature request: polarized gradient in tensorboard embeddings", "body": "Currently, default tensorboard color gradient goes from light yellow to dark blue (see screenshot), which works great for highlighting positive values (yellow dots become nearly invisible).\r\n\r\nBut it doesn't work well for displaying, let's say, sentiment scales (going from -1 to +1). The ability to choose a gradient going from red to blue would be helpful for visualizing polarized scales.\r\n![screen shot 2017-05-22 at 11 39 04](https://cloud.githubusercontent.com/assets/12895366/26317262/e66f4c88-3ee4-11e7-8cb8-7bfad7cd5a35.png)\r\n", "comments": ["@dsmilkov Thoughts on this feature request?", "I have migrated this issue to tensorflow/tensorboard#45 because TensorBoard has migrated to a different repo. Lets continue discussion there - sorry about how this issue is still open."]}, {"number": 10104, "title": "Tensorflow - No valid folders of images found at XXXXX", "body": "I got this error message when trying to train the images using this command\r\n\r\n```\r\nsudo python retrain.py --bottleneck_dir=tf_files/bottlenecks --how_many_training_steps=500 --model_dir=tf_files/inception --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir=tf_files/data/\r\n```\r\n\r\nThe python script is here, https://github.com/datomnurdin/tensorflow-python/blob/master/retrain.py.\r\n\r\nPlease advice. Thank you.", "comments": ["Check the path to your images and that you are pointing to a collection of named folders containing images and not to a folder of images. If you believe the content of the destination to be correct then try using absolute paths.", "TQ, its working if I'm using command below.\r\n\r\n```\r\nsudo python retrain.py --bottleneck_dir=tf_files/bottlenecks --how_many_training_steps=500 --model_dir=tf_files/inception --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir /Users/XXXXX/Documents/Github/tensorflow-python/tf_files/images/..\r\n```", "I am having this literal exact problem, I am trying to retrain after multiple runs and I am running into this problem now. I have all of my folders named properly, no spaces or dashes, I am using only jpgs in the folders with no other files located in the sub folders. I am truly lost on how to get this error to go away as I have tried to edit nearly everything in the retrain.py code to get it running and to no avail, still receiving 'No valid folders of images found at'", "_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nAs this is a pretty popular example and people have little trouble with it I will assume that this isn't a bug with Tensorflow. As such it might be better on Stack Overflow. Can you please post the directory structure of the files and also the code/command you are running. The default retrain.py should do the job just fine there is no need to edit. You'll probably get more issues when troubleshooting unless you're comfortable with the code. Also any info on your system (OS, tf version etc.) would be great.\r\n\r\nIf you decide to move this to Stack Overflow please post the link here and we can move the conversation there.", "I had the same issue, so the problem was that I had folders named not in English, so just changing folder names to English helped.", "# Am Getting this Error \r\n> ERROR:tensorflow:Only one valid folder of images found at tf_files/finger - multiple classes are needed for classification.\r\nI have one dir in tf_files/finger \r\n", "You need multiple classes/directories to train inception as the error message states? What is the issue exactly?", "@jubjamie Am also facing the same issue, \r\nINFO:tensorflow:Looking for images in 'female'\r\nWARNING:tensorflow:No files found\r\nINFO:tensorflow:Looking for images in 'male'\r\nINFO:tensorflow:Looking for images in 'shoes'\r\nWARNING:tensorflow:No files found\r\nERROR:tensorflow:Only one valid folder of images found at tf_files2/images - multiple classes are needed for classification.\r\n\r\nTwo folders images are not able to recognize by  tensorflow, I kept images from male folder to other two folders , then it was working fine, so am assuming the problem is with images, My question is , is there any restriction for images? What kind of images we can keep for inception, any vallidation for images?", "I had this error and noticed that the images did not include the extension at the end of the filename. After changing my image generating to include the extension at the end of the image, it worked flawlessly.\r\n\r\nMaybe tensorflow checks the file extension when looking for the image?", "I had the same problem. Tensorflow wants at least two categories. After that, I still had an issue and realized that my second folder only contained PNG files. I exported one of the PNG files as a Jpeg and the problem was solved. So in short, it needs at least two folders and it seems to be partial to Jpeg files. ", "I came across the same issue. All my images were PNGs so I ended up converting them to JPGs with this ImageMagick command: ```mogrify -format jpg *.png``` and then ```rm -f *.png``` in each directory containing images. After that, retraining the model worked just fine.", "As said @corneel, using JPG instead of some other fancy formats fixes the issue. \ud83d\ude4c", "https://colab.research.google.com/drive/1hFte7dNUZGVukuR0OY02t0atJgMzn6oc#scrollTo=Bl-yFZqKeezp&forceEdit=true&offline=true&sandboxMode=true\r\n\r\n\r\n**Step 0** \r\n\r\nReplace retrain.py with downloading file from following link and uploading it to same folder in Google drive.\r\n\r\nhttps://raw.githubusercontent.com/tensorflow/hub/master/examples/image_retraining/retrain.py\r\n\r\n\r\n**Step 1**\r\n\r\nGo to this link : \r\n\r\nhttps://colab.research.google.com/drive/1hFte7dNUZGVukuR0OY02t0atJgMzn6oc#scrollTo=Bl-yFZqKeezp&forceEdit=true&offline=true&sandboxMode=true\r\n\r\n**Step 2**\r\n\r\nGo to chapter Two\r\n\r\n**Step 3** \r\n\r\n**Worked by adding two lines as given following before the script section : LOL**\r\n\r\n**It's a LOL that just added following two lines and it worked before script section and it worked.**\r\n\r\n**Two Lines:**\r\n\r\n\r\n    if not os.path.isdir(\"../Pokemons-subset\"):\r\n  \r\n         print('Error')\r\n\r\n\r\n**Script Section:**\r\n\r\n\r\n     %run scripts/retrainn.py   \\\r\n\r\n       --bottleneck_dir=tf_files/bottlenecks   \\\r\n\r\n       --how_many_training_steps=4000   \\\r\n\r\n       --model_dir=tf_files/models/   \\\r\n\r\n       --summaries_dir=tf_files/training_summaries/mobilenet_0.50_160   \\\r\n\r\n       --output_graph=tf_files/retrained_graph.pb   \\\r\n\r\n       --output_labels=tf_files/retrained_labels.txt   \\\r\n\r\n       --learning_rate=0.01   \\\r\n\r\n       --architecture=mobilenet_0.50_160   \\\r\n\r\n       --image_dir=../Pokemons-subset \\\r\n\r\n       --flip_left_right \\\r\n\r\n       --random_crop=10 \\\r\n\r\n       --random_scale=10 \\\r\n\r\n       --random_brightness=10\r\n\r\n\r\n", "I encountered this issue . The main problem here was the program couldn't process png files . So had to convert them to Jpeg.\r\nThis was done using the following commands: as suggested by @corneel \r\n\r\nOpened wsl on the images/(folder_name) on my windows 10 \r\nRan this \" mogrify -format jpg *.png \"\r\nwsl suggested me to install a package , installed the first one.\r\nEncountered some problems so i executed \" sudo apt-get update \"\r\n\r\nThen ran these two commands as suggested by  @Samin100 \r\nmogrify -format jpg *.png  # made a copy of all the pngs and converted them to jpg files\r\nrm -f *.png  # removed the png files.\r\n\r\nAnd then boom ! problem Solved."]}]