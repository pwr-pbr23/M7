[{"number": 37064, "title": "[Intel Mkl] Upgrade Sqlite3 to fix CVE-2019-19880 CVE-2019-19244 and \u2026", "body": "\u2026CVE-2019-19645\r\n\r\n(Just so we don't forget these when we do a new patch release)", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37064) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37064) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 37063, "title": "[Intel Mkl] Upgrade Sqlite3 to fix CVE-2019-19880 CVE-2019-19244 and \u2026", "body": "\u2026CVE-2019-19645\r\n\r\n(Just so we don't forget these when we do a new patch release)", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37063) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37063) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 37062, "title": "[Intel Mkl] Upgrade Sqlite3 to fix CVE-2019-19880 CVE-2019-19244 and \u2026", "body": "\u2026CVE-2019-19645\r\n\r\n(Just so we don't forget these when we do a new patch release)", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37062) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37062) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 37061, "title": "tf.keras.Model with nested dictionary inputs fails to serialize/deserialize", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  `macOS Catalina 10.15.2 (19C57)`\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): nightly binary (`v1.12.1-25814-g2e81bc66c5 2.2.0-dev20200225`)\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: - GPU model and memory: n/a\r\n\r\n\r\nNote: This is a very recent regression; *the code below works* with both `tensorflow==2.1.0` and `tf-nightly-2.2.0.dev20200219`. Would be nice to get it fixed for 2.2 release.\r\n\r\n\r\n**Describe the current behavior**\r\nWhen trying to serialize/deserialize a `tf.keras.Model` that has an inner `tf.keras.Sequential` model, nested input shapes cause an error.\r\n\r\n**Describe the expected behavior**\r\nThe model serializes/deserializes correctly.\r\n\r\n**Standalone code to reproduce the issue** \r\n```python\r\nfrom collections import OrderedDict\r\nimport tensorflow as tf\r\n\r\n\r\nbatch_size = 3\r\ninput_values = (\r\n    OrderedDict((\r\n        ('a', tf.random.uniform((batch_size, 1))),\r\n        ('b', tf.random.uniform((batch_size, 4))),\r\n    )),\r\n    (\r\n        tf.random.uniform((batch_size, 3)),\r\n        tf.random.uniform((batch_size, 4)),\r\n    ),\r\n)\r\n\r\ninputs = tf.nest.map_structure(\r\n    lambda x: tf.keras.layers.Input(tf.shape(x)[1:]), input_values)\r\n\r\n\r\ndef create_model(inputs):\r\n    sequential_model = tf.keras.Sequential((\r\n        tf.keras.layers.Lambda(\r\n            lambda x: tf.concat(tf.nest.flatten(x), axis=-1)),\r\n    ))\r\n    out = sequential_model(inputs)\r\n    model = tf.keras.Model(inputs, out)\r\n    return model\r\n\r\n\r\nmodel_1 = create_model(inputs[0])\r\nmodel_2 = create_model(inputs)\r\n\r\n# Works\r\nmodel_1_2 = tf.keras.models.Model.from_config(model_1.get_config())\r\n# Does not work\r\nmodel_2_2 = tf.keras.models.Model.from_config(model_2.get_config())\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n$ python ./tests/test_dict_inputs.py\r\n2020-02-25 19:08:12.872582: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-25 19:08:12.886642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa017864140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-25 19:08:12.886660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 211, in make_shape\r\n    shape = tensor_shape.as_shape(v)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 1218, in as_shape\r\n    return TensorShape(shape)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 771, in __init__\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 771, in <listcomp>\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 716, in as_dimension\r\n    return Dimension(value)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 195, in __init__\r\n    self._value = int(value.__index__())\r\nTypeError: 'collections.OrderedDict' object cannot be interpreted as an integer\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./tests/test_dict_inputs.py\", line 37, in <module>\r\n    model_2_2 = tf.keras.models.Model.from_config(model_2.get_config())\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 950, in from_config\r\n    config, custom_objects)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1982, in reconstruct_from_config\r\n    process_layer(layer_data)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1964, in process_layer\r\n    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\", line 109, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 373, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\", line 393, in from_config\r\n    model.build(build_input_shape)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\", line 266, in build\r\n    super(Sequential, self).build(input_shape)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 647, in build\r\n    x = base_layer_utils.generate_placeholders_from_shape(input_shape)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 165, in generate_placeholders_from_shape\r\n    return array_ops.placeholder(shape=shape, dtype=backend.floatx())\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 3006, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6674, in placeholder\r\n    shape = _execute.make_shape(shape, \"shape\")\r\n  File \"/Users/hartikainen/conda/envs/variational-option-discovery/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 213, in make_shape\r\n    raise TypeError(\"Error converting %s to a TensorShape: %s.\" % (arg_name, e))\r\nTypeError: Error converting shape to a TensorShape: 'collections.OrderedDict' object cannot be interpreted as an integer.\r\n```\r\n", "comments": ["Just guessing here, but maybe this is related to the changes in https://github.com/tensorflow/tensorflow/commit/0225ad8ca1749219635dd780b9a2507957bfeac6? @k-w-w ", "@hartikainen,\r\nI was able to run the given code without any issues with the latest nightly for Linux i.e. 2.2.0-dev20200218. Please find the Gist of it [here](https://colab.sandbox.google.com/gist/amahendrakar/8579739947b58db0869cb2b759ae77ea/37061.ipynb). Thanks!", "@amahendrakar yeah, as mentioned above, mine works too for `tf-nightly-2.2.0.dev20200219`, so something changed between that and `dev20200225`. ", "Was able to reproduce the issue with TF 2.2.0-dev20200226. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/a28410e3b9567b97835b01cbc9827c81/37061.ipynb). Thanks!", "Is there any way to still get this fixed in the tf 2.2 release? It seems like a regression from tf 2.1.", "@hartikainen Thanks for the issue!\r\n\r\n`Sequential` is only supported for Models with one input. If you have a nested input structure, you should be using the `Functional API` or Model subclassing:\r\n\r\n```python\r\nfrom collections import OrderedDict\r\nimport tensorflow as tf\r\n\r\n\r\nbatch_size = 3\r\ninput_values = (\r\n    OrderedDict((\r\n        ('a', tf.random.uniform((batch_size, 1))),\r\n        ('b', tf.random.uniform((batch_size, 4))),\r\n    )),\r\n    (\r\n        tf.random.uniform((batch_size, 3)),\r\n        tf.random.uniform((batch_size, 4)),\r\n    ),\r\n)\r\n\r\ninputs = tf.nest.map_structure(\r\n    lambda x: tf.keras.layers.Input(tf.shape(x)[1:]), input_values)\r\n\r\n\r\ndef create_model(inputs):\r\n    out = tf.concat(tf.nest.flatten(inputs), axis=-1)\r\n    model = tf.keras.Model(inputs, out)\r\n    return model\r\n\r\n\r\nmodel = create_model(inputs)\r\nmodel_2 = tf.keras.models.Model.from_config(model.get_config())\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37061\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37061\">No</a>\n", "@omalleyt12, this seems weird to me. The original script above used to work with tf 2.1. Also, I'm still able to use Sequential with multiple inputs:\r\n```python\r\nfrom collections import OrderedDict\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nbatch_size = 3\r\ninput_values = (\r\n    OrderedDict((\r\n        ('a', tf.random.uniform((batch_size, 1))),\r\n        ('b', tf.random.uniform((batch_size, 4))),\r\n    )),\r\n    (\r\n        tf.random.uniform((batch_size, 3)),\r\n        tf.random.uniform((batch_size, 4)),\r\n    ),\r\n)\r\n\r\ninputs = tf.nest.map_structure(\r\n    lambda x: tf.keras.layers.Input(tf.shape(x)[1:]), input_values)\r\n\r\n\r\nsequential_model = tf.keras.Sequential((\r\n    tf.keras.layers.Lambda(\r\n        lambda x: tf.concat(tf.nest.flatten(x), axis=-1)),\r\n))\r\n\r\noutputs = sequential_model(inputs)\r\n\r\nprint(outputs)\r\n```\r\noutputs\r\n```\r\nTensor(\"sequential/Identity:0\", shape=(None, 12), dtype=float32)\r\n```\r\n\r\nThe problem only occurs when passing the output of the sequential model through `tf.keras.Model`, as shown in the example above."]}, {"number": 37060, "title": "fix comment typo in Histogram::Remap", "body": "minor typo 'onto' instead of 'unto' in `Histogram::Remap` comment", "comments": ["Can you please fix multiple typos? There are PRs that fix all possible typos using a script for example (see PRs with title \"NFC: Fix typos..\")\r\n\r\nThis way, we don't spin hours of CI for just one tiny letter change.", "@mihaimaruseac that's fair, I'll add multiple spelling corrections together in a PR. Scripting though may not always be possible, 'unto' is a word but 'onto' was meant for the surjection."]}, {"number": 37059, "title": "TensorFlow 1.8 Issues with GPU availability always returns false", "body": "Hi,\r\n\r\nI have been facing issues lately with getting tensorflow to use GPU, I have setup a jupyterhub application on AWS cloud with a P3 type Instance which has cuda and drivers installed also tensorflow python packages, but whenever i check the gpu availability tensorflow returns False\r\n![tensorflow jupyterhub](https://user-images.githubusercontent.com/32424190/75277684-770a4100-57d6-11ea-985c-87b12ba6a645.png)\r\n![nvidia smi](https://user-images.githubusercontent.com/32424190/75277713-89847a80-57d6-11ea-87e1-55718b4602d0.png)\r\n![tensorflow jupyterhub](https://user-images.githubusercontent.com/32424190/75277710-88534d80-57d6-11ea-96ce-dc9b471bbf7b.png)\r\n![Uploading nvidia smi.png\u2026]()\r\n\r\nHere is the version information  below:\r\n\r\nNvidia Driver Version: 396.26\r\nCUDA Version 9.2.88\r\nCUDNN_VERSION 7.1.4\r\nTensorflow : 1.8.0\r\nTensorflow_gpu : 1.8.0\r\n\r\nHere is the compatibility list from Tensorflow website which doesn't point out the cuda and cudnn minor versions only major version https://www.tensorflow.org/install/source#linux\r\n\r\nCan someone please help me with this issue, Thanks in advance!\r\n", "comments": ["@rajkpammi,Thanks for reporting this issue.\r\nCan you try with this command to know Tensorflow-GPU availability\r\n`tf.config.list_physical_devices('GPU')`. Thanks", "@rajkpammi, Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37058, "title": "TensorFlow 1.8 Issues with GPU availability always returns false", "body": "Hi,\r\n\r\nI have been facing issues lately with getting tensorflow to use GPU, I have setup a jupyterhub application on AWS cloud with a P3 type Instance which has cuda and drivers installed also tensorflow python packages, but whenever i check the gpu availability tensorflow returns False\r\n\r\nHere is the version information  below:\r\n\r\nNvidia Driver Version: 396.26\r\nCUDA Version 9.2.88\r\nCUDNN_VERSION 7.1.4\r\nTensorflow : 1.8.0\r\nTensorflow_gpu : 1.8.0\r\n\r\nHere is the compatibility list from Tensorflow website which doesn't point out the cuda and cudnn minor versions only major version https://www.tensorflow.org/install/source#linux\r\n\r\nCan someone please help me with this issue, Thanks in advance!\r\n", "comments": ["@rajkpammi \r\nCan you try with this command to know Tensorflow-GPU availability\r\ntf.config.list_physical_devices('GPU').Looks like duplicate of #37059. Thanks!", "@rajkpammi \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37057, "title": "MultiWorkerMirroredStrategy OOM - Ubuntu 18.04 ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): **Linux Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): **pip install tensorflow==2.1.0** - TensorFlow version (use command below): \r\n- Python version: **python=3.6.9** - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: **10.2** - GPU model and memory: **NVIDIA T4 16GB (g4dn.xlarge) (REPRODUCABLE ON CPU)**\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen training a trivial model with `MultiWorkerMirroredStrategy` over `cifar10` the memory consumption of all workers grows over time until eventually the system runs out of memory.\r\n\r\nMemory consumption grows while `model.fit` is running.\r\n\r\nI ran into this issue on the AWS Deep Learning AMI, but was also able to reproduce it with a manually configured AWS Ubuntu 18.04 AMI. Could not reproduce on a Mac laptop.\r\n\r\nNote: A more complicated model will run out of memory a lot faster, the toy example I provide for reproduction was deliberately downscaled for simplicity, but takes a few minutes to double RAM consumption.\r\n\r\nCluster setup:\r\n- 4 CPU workers (`CUDA_AVAILABLE_DEVICES=''`) on a **single** g4dn.xlarge instance (was able to reproduce with multiple instances, and with GPU training)\r\n- Using `ray` to run the processes for convenience, not using any of its distributed features\r\n\r\n**Describe the expected behavior**\r\nMemory consumption is stable/the system does not run out of memory.\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://gist.github.com/maximsmol/ac2aeb5582600cd8b3fc6952cfd040a1\r\n^ the issue requires a multi-worker setup (ips+ports) so it's not possible to provide a notebook\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe way I track the memory consumption is openning `top` and watch the RES RAM column for the workers. It very visibly grows.", "comments": ["@maximsmol Does this OOM memory only happen for multiple workers? Do you see this behavior on a single machine as well?", "I was able to reproduce this at the time with a single amazon instance running multiple python processes in a \"distributed\" cluster (everything on localhost). I am not exactly sure if a single python process (in a \"cluster\" made up of this single worker) would also OOM since it takes a while for memory consumption to grow significantly in such a configuration.", "This behavior happens for single machine as well. I ran my code which initially(for first two epochs) takes about 3 GB memory and afterwards takes up more and shows up OOM after epoch 15. I ran the code with both tf2.0 and tf2.1 on ubuntu18.04. The same code works well in windows10. The memory alloted for the entire 100 epochs in this case is about 3GB.", "Is this still an issue with latest version of TF 2.5?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37057\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37057\">No</a>\n"]}, {"number": 37056, "title": "tf.keras.layers.Lambda deserialization fails due to `KeyError: 'name'`", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  `macOS Catalina 10.15.2 (19C57)`\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): nightly binary (`v1.12.1-25814-g2e81bc66c5 2.2.0-dev20200225`)\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: - GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nTrying to serialize and then deserialize a simple `tf.keras.layers.Lambda` results in `KeyError: 'name'`.\r\n\r\n**Describe the expected behavior**\r\nNo `KeyError: 'name'` exception is thrown and the model is deserialized correctly.\r\n\r\n**Standalone code to reproduce the issue** \r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ninputs = tf.random.uniform((4, 3))\r\n\r\nsequential_model = tf.keras.Sequential((\r\n    tf.keras.layers.Lambda(lambda x: tf.concat(tf.nest.flatten(x), axis=-1)),\r\n))\r\n\r\n_ = sequential_model(inputs)\r\n\r\nsequential_model_2 = tf.keras.Model.from_config(sequential_model.get_config())\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n$ python ./tests/test_lambda_layer_serialization.py\r\nTraceback (most recent call last):\r\n  File \"./tests/test_lambda_layer_serialization.py\", line 12, in <module>\r\n    sequential_model_2 = tf.keras.Model.from_config(sequential_model.get_config())\r\n  File \"/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 950, in from_config\r\n    config, custom_objects)\r\n  File \"/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1987, in reconstruct_from_config\r\n    process_layer(layer_data)\r\n  File \"/Users/hartikainen/conda/envs/softlearning-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1956, in process_layer\r\n    layer_name = layer_data['name']\r\nKeyError: 'name'\r\n```\r\n", "comments": ["Just realized that the code works with `tf.keras.Sequential.from_config(sequential_model.get_config())`, so maybe this is a user error.", "@hartikainen, Can we close this, since the issue is resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37056\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37056\">No</a>\n", "@gadagashwini yeah, I'm closing it. I wonder what the difference between `tf.keras.Sequential.from_config` and `tf.keras.Model.from_config` is? Why does the latter one fail in this case? I'd imagine that `Sequential` models could be safely deserialized through `tf.keras.Model.from_config`? I might be wrong though.", "@jvishnuvardhan, Can you PTAL. Thanks"]}, {"number": 37055, "title": "bi test", "body": "sdfdssdfdssdsdfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsfsdfsdfsdfdsfsdfsdfsdfsdfsdfdsf load_dynamic return _load(spec)\r\nCUDA/cuDNN version: 434\r\n**Provide the exact sequence", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37055\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37055\">No</a>\n"]}, {"number": 37054, "title": "TPU scope valuerror", "body": "I want to run this code support TPU\r\nIt's my function and [colab:](https://colab.research.google.com/drive/1aysV-1Vur5Wp8BKD64bwWLNNue60MV2-)\r\n```\r\ndef build_model(params_path = 'test/params', enc_lstm_units = 128, unroll = True, use_gru=False, optimizer='adam', display_summary=True):\r\n    \"\"\"\r\n    Build keras model\r\n\r\n    Parameters:\r\n\r\n    params_path (str): Path for saving/loading the params.\r\n\r\n    enc_lstm_units (int): Positive integer, dimensionality of the output space.\r\n\r\n    unroll (bool): Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\r\n\r\n    use_gru (bool): GRU will be used instead of LSTM\r\n\r\n    optimizer (str): optimizer to be used\r\n\r\n    display_summary (bool): Set to true for verbose information.\r\n\r\n\r\n    Returns:\r\n\r\n    model (keras model): built model object.\r\n    \r\n    params (dict): Generated params (encoding, decoding dicts ..).\r\n\r\n    \"\"\"\r\n    # generateing the encoding, decoding dicts\r\n    params = build_params(params_path = params_path)\r\n\r\n    input_encoding = params['input_encoding']\r\n    input_decoding = params['input_decoding']\r\n    input_dict_size = params['input_dict_size']\r\n    output_encoding = params['output_encoding']\r\n    output_decoding = params['output_decoding']\r\n    output_dict_size = params['output_dict_size']\r\n    max_input_length = params['max_input_length']\r\n    max_output_length = params['max_output_length']\r\n\r\n\r\n    if display_summary:\r\n        print('Input encoding', input_encoding)\r\n        print('Input decoding', input_decoding)\r\n        print('Output encoding', output_encoding)\r\n        print('Output decoding', output_decoding)\r\n\r\n\r\n    # We need to define the max input lengths and max output lengths before training the model.\r\n    # We pad the inputs and outputs to these max lengths\r\n    encoder_input = Input(shape=(max_input_length,))\r\n    decoder_input = Input(shape=(max_output_length,))\r\n\r\n    # Need to make the number of hidden units configurable\r\n    encoder = Embedding(input_dict_size, enc_lstm_units, input_length=max_input_length, mask_zero=True)(encoder_input)\r\n    # using concat merge mode since in my experiments it g ave the best results same with unroll\r\n    if not use_gru:\r\n        encoder = Bidirectional(LSTM(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)\r\n        encoder_outs, forward_h, forward_c, backward_h, backward_c = encoder\r\n        encoder_h = concatenate([forward_h, backward_h])\r\n        encoder_c = concatenate([forward_c, backward_c])\r\n    \r\n    else:\r\n        encoder = Bidirectional(GRU(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)        \r\n        encoder_outs, forward_h, backward_h= encoder\r\n        encoder_h = concatenate([forward_h, backward_h])\r\n    \r\n\r\n    # using 2* enc_lstm_units because we are using concat merge mode\r\n    # cannot use bidirectionals lstm for decoding (obviously!)\r\n    \r\n    decoder = Embedding(output_dict_size, 2 * enc_lstm_units, input_length=max_output_length, mask_zero=True)(decoder_input)\r\n\r\n    if not use_gru:\r\n        decoder = LSTM(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=[encoder_h, encoder_c])\r\n    else:\r\n        decoder = GRU(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=encoder_h)\r\n\r\n\r\n    # luong attention\r\n    attention = dot([decoder, encoder_outs], axes=[2, 2])\r\n    attention = Activation('softmax', name='attention')(attention)\r\n\r\n    context = dot([attention, encoder_outs], axes=[2,1])\r\n\r\n    decoder_combined_context = concatenate([context, decoder])\r\n\r\n    output = TimeDistributed(Dense(enc_lstm_units, activation=\"tanh\"))(decoder_combined_context)\r\n    output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(output)\r\n\r\n    model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\r\n    \r\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n    tf.config.experimental_connect_to_cluster(resolver)\r\n    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n    strategy = tf.distribute.experimental.TPUStrategy(resolver) \r\n    with strategy.scope():\r\n      model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\r\n      model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\n    if display_summary:\r\n        model.summary()\r\n    \r\n    return model, params\r\n```\r\nError:\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-66476e79d8c4> in <module>()\r\n    501     build_params(input_data = input_data, output_data = output_data, params_path = 'params', max_lenghts=(10, 10))\r\n    502 \r\n--> 503     model, params = build_model(params_path='params')\r\n    504 \r\n    505     input_data, output_data = convert_training_data(input_data, output_data, params)\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    398                 'with strategy.scope():\\n'\r\n    399                 '  model=_create_model()\\n'\r\n--> 400                 '  model.compile(...)'% (v, strategy))\r\n    401 \r\n    402   @trackable.no_automatic_dependency_tracking\r\n\r\nValueError: Variable (<tf.Variable 'embedding_2_1/embeddings:0' shape=(39, 128) dtype=float32>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.tpu_strategy.TPUStrategyV1 object at 0x7f9e623bef98>). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\r\nwith strategy.scope():\r\n  model=_create_model()\r\n  model.compile(...)\r\n```", "comments": ["Was able to reproduce the issue. Please find the Gist [here](https://colab.research.google.com/gist/amahendrakar/86e9cfb03c7eba411b5b88b4011218f8/37054.ipynb). Thanks!", "@muhammetfaik `model` creation needs to be inside the `scope`. Please follow [the tutorial](https://www.tensorflow.org/guide/tpu) on `distribution strategy` and update your code. I have updated some parts but still some coding needs to be updated. \r\nPlease check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/b1b7e6f717f7b52fb1f86f829eee7c70/37054.ipynb). Thanks!\r\n\r\nPlease post support related questions on stackoverflow. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37054\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37054\">No</a>\n"]}, {"number": 37053, "title": "Cannot wrap GradientTape.batch_jacobian with tf.function on tf.keras model with LSTM cells", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  macOS Mojave\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\n\r\nThe @tf.function wrapper is not able to convert LSTM cells correctly for use in the `batch_jacobian` function (or `jacobian`, tested both). These functions work correctly without the decorator.\r\n```\r\n    ValueError: No converter defined for VariableShape\r\n    name: \"loop_body/VariableShape_2\"\r\n    op: \"VariableShape\"\r\n    input: \"binary_classification_lstm/lstm/while:10\"\r\n    attr {\r\n      key: \"out_type\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    } \r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThis should run without throwing an error\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\n\r\nclass BinaryClassificationLSTM(tf.keras.Model):\r\n    def __init__(self, units, name=None):\r\n        super(BinaryClassificationLSTM, self).__init__(name=name)\r\n        self.lstm_layer = tf.keras.layers.LSTM(units, activation='softsign')\r\n        self.dense = tf.keras.layers.Dense(1)\r\n        self.sigmoid = tf.keras.layers.Activation('sigmoid')\r\n\r\n    def call(self, x):\r\n        sequence = self.lstm_layer(x)\r\n        logit = self.dense(sequence)\r\n        prob = self.sigmoid(logit)\r\n\r\n        return prob\r\n    \r\n\r\n@tf.function\r\ndef get_jacobian(model, tensor_in):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(tensor_in)\r\n        predictions = model(tensor_in)\r\n    \r\n    return tape.batch_jacobian(predictions, tensor_in)\r\n\r\ninp = tf.zeros((1, 10, 5))\r\nlstm = BinaryClassificationLSTM(10)\r\njacobian = get_jacobian(lstm, inp)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 29, in <module>\r\n    jacobian = get_jacobian(lstm, inp)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 615, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n\r\n    test.py:24 get_jacobian  *\r\n        return tape.batch_jacobian(predictions, tensor_in)\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:1246 batch_jacobian\r\n        sys.exc_info()[2])\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/six.py:702 reraise\r\n        raise value.with_traceback(tb)\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:1238 batch_jacobian\r\n        parallel_iterations=parallel_iterations)\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:189 pfor\r\n        return f()\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f\r\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl\r\n        outputs.append(converter.convert(loop_fn_output))\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert\r\n        output = self._convert_helper(y)\r\n    /Users/henryprior/anaconda3/envs/test/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1460 _convert_helper\r\n        (y_op.type, y_op, converted_inputs))\r\n\r\n    ValueError: No converter defined for VariableShape\r\n    name: \"loop_body/VariableShape_2\"\r\n    op: \"VariableShape\"\r\n    input: \"binary_classification_lstm/lstm/while:10\"\r\n    attr {\r\n      key: \"out_type\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    }\r\n\r\n    inputs: [WrappedTensor(t=<tf.Tensor 'binary_classification_lstm/lstm/while:10' shape=() dtype=resource>, is_stacked=False, is_sparse_stacked=False)].\r\n    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n    Encountered an exception while vectorizing the batch_jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.\r\n```", "comments": ["@henry-prior, I tried replicating the reported issue but getting different error, can help us to reproduce the issue. Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/abd23e0998d1b89c6e880e6f94ca78b6/untitled406.ipynb). Thanks!", "@gadagashwini I got the same error when running the code in a notebook, but when I ran it as a `.py` script (using a fresh venv) I got the error I posted in the issue. From briefly checking the tf code I believe the error in the gist is caused by the underlying problem from the error in the script. Let me know if you're able to reproduce this.", "I could replicate the issue on local system as a `.py`  with Tf 2.1. Thanks!", "Addin Rohan from core team. I think it might be an issue for tape. get_jacobian()\r\n\r\nValueError: No converter defined for VariableShape", "Unassign myself since I don't think this is a LSTM issue. Feel free to assign back if you feel there is anything need to be fixed on RNN side. Thanks.", "Support for VariableShape was added some time back. Can you check if this is still broken, and if so, does it give a different error.\r\nPlease test it against the nightly version, not 2.1.", "I tested in nightly and got the following (different) error message:\r\n\r\n```\r\nNotImplementedError: Vectorization tried to stack variant tensor\r\nTensor(\"gradient_tape/binary_classification_lstm/lstm/while/gradients/grad_ys_3/pfor/Identity:0\", shape=(), dtype=variant). \r\nThis is likely because vectorization of that variant is not fully supported yet\r\n```\r\n\r\nAnd I see the same message in nightly when I swap `batch_jacobian` for `jacobian`", "Should be fixed now (fix in https://github.com/tensorflow/tensorflow/commit/a20b5857915cd573f595942eab6a928ae3837639 integration test in https://github.com/tensorflow/tensorflow/commit/d5b5e1148ab3ef1817fadb864694ec3139746400), thank you for the report.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37053\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37053\">No</a>\n"]}, {"number": 37052, "title": "Can't convert the model into \".tflite\". I've tried every possible way from APIs to command lines. I tried to change layers as per tflite, but I couldn't understand the working and ended up with errors.", "body": "**System information**\r\n- Google Colab\r\n- TensorFlow: 1.15 \r\n\r\n**Code link with dataset**\r\nhttps://github.com/Kiranendra/Project\r\n\r\nBy trying different types of conversion like from saved model, from Keras model, freeze graphs, I am facing errors like with \"input shape\"( is none),  embedding layer. If I change the layer GRU to LSTM then input errors with the decoder output and it goes.", "comments": ["@Kiranendra \r\n\r\nCan you go through the [link](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/lite/TFLiteConverter) and see if it helps you in converting the model into TF lite .Thanks!", "Yes, I've already tried those methods. The model successfully saves. But, it doesn't convert to \".pb\" or \".pbtxt\" (no matter which way I try - python API or command line). I can't convert my model either with saving or without saving (not even into \".pb\" or \".pbtxt\"). \r\n\r\nThank you.", "@Kiranendra \r\n\r\nCan you please let us know what are the steps you followed for converting the model into TFLite.\r\nThanks!", "@ravikyram \r\n\r\nI followed the steps that were said to be followed, in the link:\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/lite/TFLiteConverter\r\n\r\nAs I am using \"RNN\" layers I also tried these steps, in the link:\r\nhttps://www.tensorflow.org/lite/convert/rnn\r\nI tried changing the layer (GRU) to the layers that were recommended by \"TensorFlow\" in the link above. Honestly, I am new to neural networks (You can call me as a beginner). So, I can't understand how to change the layers without actually disturbing the model. After, trying everything I figured out that the model saves in \".h5\" format, but fails to convert to \".pb\". \r\n\r\nThank you.", "@Kiranendra Can you please try with tf-nightly and use experimental flag for converter?\r\nSee https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter\r\n", "@ymodak \r\nYes. I've tried them.\r\n1. If I use \".from_keras_model()\" then, I am getting the error (when using **.convert()** ):\r\n_\"NotImplementedError: numpy() is only available when eager execution is enabled.\"_\r\n\r\nIf I enabled the eager execution then I will get the error at line no. 273 (in model.compile method) in the notebook, stating that _\" with eager execution enabled target_tensors is not....\"_ \r\nI had to disable v2 behavior also because I have used _\"tf.placeholder\"_\r\n\r\n2. I can't use _\".from_saved_model()\"_: It says \r\n\"_the SavedModel file does not exist at: /content/mymodel.pb/{saved_model.pbtxt|saved_model.pb}_\"\r\nI don't understand why it shows that even though I have the file.\r\n\r\nIf you don't mind can you please try to convert the model into _\".tflite\"_ on your side with my code and dataset [here](https://github.com/Kiranendra/Project) so that you can understand where the problem lies as I am a very much new to RNNs (and also machine learning). It won't take much time to train(the data set is small). Please !!!\r\nThank you.", "@Kiranendra Can you please create a standalone code to reproduce the issue. I tried to create model but it throws an error in this line `data_dest.append(start_stop_tags(preprocess_text(line[1])))`. The error is as follows. Basically `line` was empty but we are trying to access line[1]. Thanks!\r\n\r\n```\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-10-3d0de97b644f> in <module>()\r\n      6   line = lines.split('\\t')[:2]\r\n      7   data_src.append(preprocess_text(line[0]))\r\n----> 8   data_dest.append(start_stop_tags(preprocess_text(line[1])))\r\n\r\nIndexError: list index out of range\r\n```\r\n", "I am using Google Colab. I've split the code and tested it. But, not really getting the error. Here is the output **snap** for one iteration.\r\n-------------------\r\n![image](https://user-images.githubusercontent.com/47424842/76050660-407ab600-5f8e-11ea-865e-f180aec51f4e.png)\r\n-------------------\r\nThank you @jvishnuvardhan ", "@Kiranendra Can you please try running your entire colab. There was another error with checkpoints also. Can you please run your colab with another google colab account? Or mention clearly what steps need to be carried out to reproduce your error. I will try again with tensorflow on my local. Thanks!", "I've gone through everything again and didn't find any error. So, I made a new notebook and split the code into parts. Here is the ZIP file with the notebook and dataset.\r\n\r\n[tflite_file_conversion.zip](https://github.com/tensorflow/tensorflow/files/4301726/tflite_file_conversion.zip)\r\n\r\nI forgot to change the file paths(for dataset and checkpoint). As you said that you will try local, please change the file paths accordingly.\r\n\r\nP.S: If you are saving the checkpoints in a folder then, make sure that the folder already exists. The model can't create a folder by itself to save the checkpoint files. "]}, {"number": 37051, "title": "Tensorflow Docker Image with Jupyter Notebook Runs in HTTP", "body": "Looks like the official image in [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/gpu-jupyter.Dockerfile) runs the container as `root` and runs jupyter notebook with `http`. Is there a version that does not run as a `root` and also supports `https` (self signed certs would be fine)? ", "comments": ["Anyway, I created my own in here: https://github.com/bulutmf/tf-jupyter-https-2.0.1", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37051\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37051\">No</a>\n"]}, {"number": 37050, "title": "tflite | interpreter->AllocateTensors() fails", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): docker image (nightly)\r\n- TensorFlow version (use command below): TensorFlow 2.2.0-dev20200218\r\n\r\n**Describe the current behavior**\r\nIn Python (tf.lite.Interpreter), everything works as expected. In C++, however, interpreter->AllocateTensors() fails when using the attached model (see link to minimal example below). Absolutely no clue is given. No error. I have no idea why this happens. I'm not using any custom ops.\r\n\r\n**Describe the expected behavior**\r\nThe C++ code should give the same result as the python code (tf.lite.Interpreter).\r\n\r\n**Standalone code to reproduce the issue** \r\n[Can be found here](https://drive.google.com/open?id=1kKUP-bIizhWNtA8xt8X3DV1M7h8AJGD_)", "comments": ["Update: I also exported the .tflite file with `converter.experimental_new_converter = True` but `interpreter->AllocateTensors()` still fails. Problem persists with the new converter. Link to minimal example with both .tflite exports: https://drive.google.com/open?id=13xqynDb8cEJCv45x73m0nUUmY_Vc06lP", "`AllocateTensors` is succeeding fine, as far as I can tell.\r\n\r\n`kTfLiteOk`, the returned value from `interpreter->AllocateTensors();` has the enum value of 0, because of which `!allocationStatus` returns True.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37050\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37050\">No</a>\n"]}, {"number": 37049, "title": "Can't use RaggedTensor in @tf.function input_signature.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `no`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 18.04`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `no`\r\n- TensorFlow installed from (source or binary): `no`\r\n- TensorFlow version (use command below): `2.0.1`\r\n- Python version: `3.7.3`\r\n- Bazel version (if compiling from source): `-`\r\n- GCC/Compiler version (if compiling from source): `-`\r\n- CUDA/cuDNN version: `-`\r\n- GPU model and memory: `-`\r\n\r\n**Describe the current behavior**\r\nIt is not possible to pass a tf.RaggedTensor as a tf.function input signature, and therefore use it with e.g. Tensorflow Serving.\r\n\r\n**Describe the expected behavior**\r\nIt should be possible to pass a tf.RaggedTensor as a tf.function input signature.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nclass MyModule(tf.Module):\r\n    def __init__(self):\r\n        super(MyModule, self).__init__()\r\n        tf.saved_model.save(\r\n            self,\r\n            \"/tmp/foomodel/001\",\r\n            signatures={\r\n                tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY: self.some_method,\r\n            },\r\n        )\r\n\r\n    @tf.function(input_signature=[\r\n        tf.TensorSpec((None, ), dtype=tf.int64),\r\n        tf.RaggedTensorSpec((None, None), dtype=tf.string),\r\n    ])\r\n    def some_method(self, dense, ragged):\r\n        return tf.constant([\"foobar\"], dtype=tf.string)\r\n\r\nm = MyModule()\r\ndense = tf.constant([[1,2]], dtype=tf.int64)\r\nragged = tf.ragged.constant([[\"foo\"], [\"foo\", \"bar\"]], dtype=tf.string)\r\nsome_result = m.some_method(dense, ragged)\r\nprint(f\"some_result => {some_result}\")\r\n\r\n#ValueError: Python inputs incompatible with input_signature:\r\n# inputs: (\r\n#    tf.Tensor([[1 2]], shape=(1, 2), dtype=int64),\r\n#    <tf.RaggedTensor [[b'foo'], [b'foo', b'bar']]>)\r\n#  input_signature: (\r\n#    TensorSpec(shape=(None,), dtype=tf.int64, name=None),\r\n#    RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64))\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.0 ,2.2.0-dev20200218 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/212bd1d7e2bdd3bf0a5fdee0ba5af463/untitled676.ipynb). Thanks!", "@stefanondisponibile I am able to pass  tf.RaggedTensor as a tf.function input signature. Please find the gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/69074ae99fbe5ca41513a4cb2416001b/untitled21.ipynb).", "@gowthamkpr  yeah, you're right, but the problem is (if I'm not missing something here), that once exported and loaded into `Tensorflow Serving`, you won't be able to pass a `RaggedTensor` directly: you can see this also in your example by adding a cell doing this:\r\n\r\n```python\r\nloaded = tf.saved_model.load(\"/tmp/foomodel/001\")\r\nprint(loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]._arg_keywords)\r\n# ['ragged', 'ragged_1']\r\n\r\n# Or inspect with saved_model_cli:\r\n# !saved_model_cli show --dir /tmp/foomodel/001 --all\r\n#\r\n# MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n# \r\n# signature_def['__saved_model_init_op']:\r\n#   The given SavedModel SignatureDef contains the following input(s):\r\n#   The given SavedModel SignatureDef contains the following output(s):\r\n#     outputs['__saved_model_init_op'] tensor_info:\r\n#         dtype: DT_INVALID\r\n#         shape: unknown_rank\r\n#         name: NoOp\r\n#   Method name is: \r\n# \r\n# signature_def['serving_default']:\r\n#   The given SavedModel SignatureDef contains the following input(s):\r\n#     inputs['ragged'] tensor_info:\r\n#         dtype: DT_STRING\r\n#         shape: (-1)\r\n#         name: serving_default_ragged:0\r\n#     inputs['ragged_1'] tensor_info:\r\n#         dtype: DT_INT64\r\n#         shape: (-1)\r\n#         name: serving_default_ragged_1:0\r\n#   The given SavedModel SignatureDef contains the following output(s):\r\n#     outputs['output_0'] tensor_info:\r\n#         dtype: DT_STRING\r\n#         shape: (1)\r\n#         name: PartitionedCall:0\r\n#   Method name is: tensorflow/serving/predict\r\n# \r\n# Defined Functions:\r\n#   Function Name: 'some_method'\r\n#     Option #1\r\n#       Callable with:\r\n#         Argument #1\r\n#           DType: RaggedTensorSpec\r\n#           Value: RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64)\r\n``` \r\n\r\nAs you can see, the ragged input will be split into two different dense ones: `ragged` and `ragged_1`, respectively representing the ragged _values_ and _row splits_.\r\n\r\nI am currently working around this by computing values and row splits from my ragged inputs, and then building up my [`tf.RaggedTensor.from_row_splits`](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#from_row_splits) inside the served function, but I found it strange that the compatibility with ragged tensors wasn't full.\r\n\r\nWhat do you think?", "@stefanondisponibile This issue title and the initial description was misleading. Based on the initial description of the issue, the problem has been resolved. Please create a new issue pointing to the issue that you are facing now as it would be helpful for us to discuss this as a separate problem. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37049\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37049\">No</a>\n"]}, {"number": 37048, "title": "The output of the Conv2D layer in backend TensorFlow is different from that in Theano and CNTK", "body": "## System Information\r\n\r\n- CUDA Version 10.1.168\r\n- Python==3.6.8\r\n- numpy==1.14.6\r\n- tensorflow-gpu==1.14.0\r\n- theano==1.0.4\r\n- cntk-gpu==2.7\r\n- gcc== 5.4.0\r\n- Linux version 4.15.0-52-generic\r\n\r\n## Description\r\n\r\nHi, I encountered a problem when I used a variant of the AlexNet model for image classification task. The prediction result of backend TensorFlow is different from backend Theano and backend CNTK in  Keras. The input picture is sampled from the CIFAR10 DataSet. \r\n\r\nThe outputs ( Top-1 prediction) of three backends are shown below\uff08Prediction label id and  Probability \uff09:\r\n\r\n**TensorFlow**: 2, 0.9999998807907104\r\n\r\n**CNTK**:  6,1.0\r\n\r\n**Theano**: 6,1.0\r\n\r\nIt seems that there is something wrong with Tensorflow. Then I put image into the model and recorded the ouputs of each layers to see how this happens. It seems that the outputs on CNTK and Theano are very close, but for Tensorflow, the outputs of a conv2d layer and all the layers after this layer are very different from CNTK and Theano.\r\n\r\nThe results are attached below.\r\n\r\nTheano vs CNTK\r\n![image-20200225181539716](https://user-images.githubusercontent.com/15032308/75246315-7d1a1500-580a-11ea-978e-93224948d974.png)\r\n\r\n\r\nTensorFlow vs Theano\r\n\r\n![image-20200225181451774](https://user-images.githubusercontent.com/15032308/75246369-94f19900-580a-11ea-871e-a401d652fbc4.png)\r\n\r\nTensorFlow vs CNTK\r\n![image-20200225181519926](https://user-images.githubusercontent.com/15032308/75246356-8efbb800-580a-11ea-9efe-a8c29708465f.png)\r\n\r\n\r\nThe delta column shows the discrepancy, which is calculated as:\r\n![MAD](https://user-images.githubusercontent.com/15032308/75246389-9f139780-580a-11ea-8c41-ae22458272f7.png)\r\n\r\n\r\nBased on the results, the deviation seems to be caused by conv2d of tensorflow backend.\r\n\r\n## To Reproduce\r\nThe code of getting prediction result of each backend  is really simple. \r\n\r\nget_prediction.py :\r\n\r\n```python\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nfrom PIL import Image\r\nbk = sys.argv[1]\r\nos.environ['KERAS_BACKEND'] = bk\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\nimport keras\r\nfrom keras import backend as K\r\nprint(\"Using backend :{}\".format(K.backend()))\r\n\r\n\r\ndef custom_objects():\r\n\r\n    def no_activation(x):\r\n        return x\r\n\r\n    def leakyrelu(x):\r\n        import keras.backend as K\r\n        return K.relu(x, alpha=0.01)\r\n\r\n    objects = {}\r\n    objects['no_activation'] = no_activation\r\n    objects['leakyrelu'] = leakyrelu\r\n    return objects\r\n\r\n\r\ndef image_resize(x, shape):\r\n    x_return = []\r\n    for x_test in x:\r\n        tmp = np.copy(x_test)\r\n        img = Image.fromarray(tmp.astype('uint8')).convert('RGB')\r\n        img = img.resize(shape, Image.ANTIALIAS)\r\n        x_return.append(np.array(img))\r\n    return np.array(x_return)\r\n\r\n\r\nbase_model = keras.models.load_model(\"alexnet-cifar10_origin0-ARep4-ARep6-ARem1-LC6.h5\",custom_objects=custom_objects())\r\nadam = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\r\nbase_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n\r\n\r\nimagename = 'cifar10-1042.png'\r\nimg = Image.open(imagename)\r\nimg = img.resize((32,32), Image.ANTIALIAS)\r\nx_test = np.array(img)\r\nselect_data = np.expand_dims(x_test, axis=0)\r\n\r\nprediction = base_model.predict(select_data)\r\npred = np.argsort(prediction[0])\r\nprint(pred)\r\nprint(f\"Prediction of {bk}: {pred[-1]},{prediction[0][pred[-1]]}\")\r\n```\r\n\r\nYou can run the script like this ():\r\n\r\n> python get_prediction.py tensorflow\r\n\r\nChange tensorflow to 'theano' and 'cntk'\r\n\r\nI provide scripts to get outputs of the middle layers and calculate the difference:\r\n[tensorflow-conv2d.zip](https://github.com/tensorflow/tensorflow/files/4256311/tensorflow-conv2d.zip)\r\n\r\nThe model used in scripts can be downloads from\uff1ahttps://send.firefox.com/download/c01db9a2b4773d8b/#ME176P7KQp4J6DmB46xBBg\r\nThanks in advance.\r\n\r\n\r\n\r\n", "comments": ["@Justobe,\r\nI am facing an error stating `ValueError: Unknown activation function:no_activation` while loading the given h5 file. Please find the Gist of it [here](https://colab.research.google.com/gist/amahendrakar/f3c6871c8d8a1bbc9e7b27321ab600eb/37048.ipynb). \r\n\r\nI am facing the same error while running it on the local environment too. Thanks!\r\n", "@amahendrakar  Thank you very much for your reply. I'm so sorry that I missed the definition of the no_activation function in custom_objects. I have updated the code of the custom_objects function in the issue and re-uploaded the attachment.  ^_^\r\n\r\n", "@Justobe Sorry for the late response. Is this still an issue for you? Did you try with recent `TF` versions? Can you please share the *.h5 file and a standalone code to reproduce the issue? Thanks!\r\n\r\nPlease close the issue if this was resolved already for you. Thanks!", "@jvishnuvardhan Thanks for your reply! I re-run the scripts on tensorflow 1.15.3, and I found that the difference between tensorflow 1.15.3 and theano and cntk is still very large. I provided a new model and a new input to reproduce: [onedrive](https://1drv.ms/u/s!Aj6dGBsJFcs0jnjZ2WpjS42a-4cF?e=DWxP2y)\r\n\r\nThis is the picture in the cifar10 test set (No.119, starting from 0)\r\n![cifar10-119](https://user-images.githubusercontent.com/15032308/83827120-190fc280-a710-11ea-8a95-3995a5d2574b.png)\r\n\r\nIt can be seen that the picture is a horse, and its label index is 7.\r\n\r\nIf I use the model and this picture in tensorflow, the output is 5. But the output of theano and cntk are both 7 (same as groundtruth)\r\n\r\nYou can use the following script to get the output of the three backends:\r\n```\r\npip install keras==2.2.4\r\n\r\npip install tensorflow-gpu==1.14.0\r\n\r\npip install cntk-gpu==2.7\r\n\r\npip install theano==1.0.4\r\n\r\npip install pillow\r\n```\r\n> python get_prediction.py backend_name\r\n\r\nChange backend_name to tensorflow, theano and cntk\r\n\r\nPlease let me know if you have any problems when you run the scripts. ^_^\r\nThanks in advance!\r\n", "Hi~ @jvishnuvardhan @tensorflowbutler The problem seems to still exist on TensorFlow 2.2. The results of TensorFlow \uff08tf1.x and tf2.x\uff09are different from cntk and theano, but the results of cntk and theano are the same. I confirmed again that the script I provided in [ondedrive ](https://1drv.ms/u/s!Aj6dGBsJFcs0jnjZ2WpjS42a-4cF?e=DWxP2y)can help to reproduce this result.\r\n\r\nYou can visit this [google-drive](https://drive.google.com/file/d/1YVg8M08rzUYo8Mz7UmOdmlYhfr1khib-/view?usp=sharing) to get the scripts if the OneDrive link fails.\r\n\r\nPlease let me know if you have any problems with the scripts. \r\nThanks in advance!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37048\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37048\">No</a>\n", "@Justobe  Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37048\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37048\">No</a>\n"]}, {"number": 37047, "title": "Request for documents of tf.compat.v1.profiler.Profiler", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/profiler/Profiler?hl=zh-TW\r\n\r\n## Description of issue (what needs changing):\r\nThe README link for this function is 404, so there is no support for usage. The sample code is not complete either.\r\n\r\n### Clear description\r\n![image](https://user-images.githubusercontent.com/33815430/75243362-b64f8680-5804-11ea-8bf6-2888306b1a38.png)\r\nFor example\r\n```python\r\nprofiler.profile_name_scope(options=(option_builder.ProfileOptionBuilder\r\n          .trainable_variables_parameter()))\r\n```\r\nNo declarence of option_builder. It's hard for me to reproduce the result by this sample code.\r\nCould tensorflow provide new support to this function??", "comments": []}, {"number": 37046, "title": "Fixed typo and improved vebosity in opcode registration error", "body": "", "comments": []}, {"number": 37045, "title": "reshuffle_each_iteration=False ignored on validation (tf.dataset + Keras)", "body": "When using .shuffle on some `tf.Dataset.from_generator`, it appears that the `reshuffle_each_iteration=False` is ignored by Keras.  \r\nIf you run the following example, you would expect to see the train_set and val_set buffer filling at the start of the session, and then you would no longer see it between each epoch. The buffers are large enough to cover more than one epoch and can be refilled in parallel during the epoch.    \r\n\r\nHowever, what seems to happen is that the val_set shuffle buffer is filled at the end of each epoch.  \r\nThe terminal shows \"Filling shuffle buffer\" at the end of each epoch.  \r\nYou can see that it is specifically the val_set buffer by removing the shuffle on val_set. Doing so, you will no longer see a \"Filling shuffle\" at each epoch, only at the start of the session.  \r\n\r\nAdditionally, [issue 35100](https://github.com/tensorflow/tensorflow/issues/35100 ) will spam the terminal on this example, with or without shuffle.  \r\n\r\nSeen on Win10, with tensorflow 2.10.  \r\nCode to reproduce the problem:  \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\ndef random_gen():\r\n    while True:\r\n        time.sleep(0.01)\r\n        yield (np.random.rand(1,), np.random.rand(1,))\r\n\r\ndataset = tf.data.Dataset.from_generator(\r\n        random_gen,\r\n        (tf.float32, tf.float32),\r\n        (tf.TensorShape((None,)), tf.TensorShape((None,))),\r\n    )\r\n\r\ntrain_set =   (dataset\r\n               .shuffle(2000, reshuffle_each_iteration=False)\r\n               .batch(32))\r\nval_set =    (dataset\r\n               .shuffle(2000, reshuffle_each_iteration=False) # Problem is here\r\n               .batch(32))\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Dense(3))\r\nmodel.compile(loss='mse', optimizer='adam')\r\n\r\nmodel.fit(x=train_set,\r\n          epochs= 5,\r\n          steps_per_epoch= 10,\r\n          validation_data= val_set,\r\n          validation_steps= 5,\r\n)\r\n```", "comments": ["@Kerybas \r\nI have tried on colab with TF version 2.1.0 on val_set with `reshuffle_each_iteration=False` and `reshuffle_each_iteration=True`. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/3523fea5be768181e2950328745819cf/untitled674.ipynb). Is this the expected behavior? Thanks!", "@ravikyram \r\nThe issue won't show up on a Notebook. I don't know why but Notebooks do not show the buffer filling outputs that you get in the terminal.", "Hi, I'm facing the same issue when I'm running my training module via terminal. Even though the `reshuffle_each_iteration=False`, In each epoch, it starts filling the shuffle buffer due to which training time is getting highly affected. Any update on this to how to overcome this?", "`reshuffle_each_iteration` does not control whether to shuffle each iteration or not. It controls whether different order of shuffling should be used.\r\n\r\nIf your input pipeline contains `shuffle`, then each epoch will perform shuffling. If you wish to overlap filling up of shuffle buffer with computation, you should put `repeat` after `shuffle`. This will result in the filling up of the shuffle buffer needed for the 2nd epoch to be amortized over the 1st epoch (as opposed to happening at the beginning of each epoch) and so on. You might also want to put `prefetch` at the end of your input pipeline to overlap training computation with preprocessing computation (see [tf.data performance guide](https://www.tensorflow.org/guide/data_performance) for more details).", "I'm also experiencing this issue. \r\nI'm training a keras model with `model.fit` and `steps_per_epoch` argument set to a way lower value than the actual size of the dataset, and the dataset gets shuffled at each model epoch (while `reshuffle_each_iteration = False`). I can see that because when I'm using a large shuffle buffer size, a message is printed in the terminal stating that the buffer is currently being filled (and that it may take a while ...). Also I'm already using `repeat(-1)` and `prefetch` when I create the dataset. \r\nOn my side, it seems to be the training dataset that gets shuffled and not the validation one as it is cached. \r\n\r\nI would need the dataset to be reshuffled only when it has been completely iterated through and not when I'm starting a new model epoch (that I defined to be n steps with `steps_per_epoch`).\r\n\r\nIs there a way to do this and still use `model.fit` ? If it is not the case, I think it would be a very useful feature to have, to be able to disconnect \"dataset epochs\" (when the dataset have completely iterated through) and \"model epochs\" (after n_steps_per_epoch in `model.fit`), to be able to shuffle only after each \"dataset epochs\" .\r\n\r\nThe only solution I see now is to abandon `model.fit` and create a custom training loop receiving data from an iterator on the `tf.Dataset`.\r\n\r\nIn case it is needed, I'm using tensorflow 2.2.0 installed with anaconda (build: gpu_py37h1a511ff_0) on Ubuntu 20.04. \r\n\r\n", "While reproducing your issue in Tf Nightly, faced different error, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/75b97702d11b3b800d617e622acea69a/35650.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37045\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37045\">No</a>\n"]}, {"number": 37044, "title": "Deep Training with Tensorflow", "body": "Hello,\r\n\r\ni'm trying to make an experiment about performance with Keras and Tensorflow. I'm interested in training some parts of the networks. In my case, my objective is training some connections (neurons) of certains layers. Is it possible to do that experiment? I know that re-training layers is possible with trainable=True, but I would like to do it in a deeper way, going to the connections (fully connected phase) and filters (convolutional phase)\r\n\r\nThanks,\r\n\r\nJavier\r\n", "comments": ["@javipa1995 Can you please describe your use case or the reason behind this specific experiment? Thanks!", "We probably needs more context than this, for example, do you have existing example (written in TF), or the problems to solve?", "@javipa1995 I think you can monitor filters and see how they get updated during training. There are couple of resources like [this](https://stackoverflow.com/questions/39361943/how-can-visualize-tensorflow-convolution-filters) and [this](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/). You can find many more when you search.\r\n\r\nTF website has lot of resources for performance. You can check [this resource](https://www.tensorflow.org/guide/profiler) to profile the model performance. In future, post this kind of questions in Stackoverflow as there is a huge community helping each other.\r\n\r\nGitHub is mainly for bug and performance related issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this as this was resolved with the above comment. Please feel free to reopen if I am mistaken. Thanks! ", "Hi,\r\nWhile we lack context (and responses) from @javipa1995, I do not think that this is actually solved. If I understand well, the question is to know whether there is a mechanism to selectively set some of the weights within a layer trainable, while the other weights would not change. In other words, the question is to know whether there is a straightforward way to have a more granular approach of the `layer.trainable` API.\r\nAs far as I know, there is no such mechanism, but it could be achieved by selectively applying no-gradient ops, which would probably be somewhat tedious... @jvishnuvardhan - or anyone else on the TF team - would you have some additional thoughts, insights or knowledge as to that?\r\nThank you."]}, {"number": 37043, "title": "An error is reported when the nested tf.keras.Model subclass model is converted to a tflite file", "body": "My environment:\r\ntensorflow-gpu 2.1\r\nwindows 10\r\npython 3.7\r\n\r\ntensorflow is installed using pip\r\n\r\n**The following is a simple demo I wrote to illustrate this problem.\uff1a**\r\n`\r\n    import tensorflow as tf\r\n    \r\n    @tf.function\r\n    def Hswish(x):\r\n        return x * tf.nn.relu6(x + 3) / 6\r\n    \r\n    tf.keras.utils.get_custom_objects().update({'custom_activation': tf.keras.layers.Activation(Hswish)})\r\n    \r\n    class Conv2d_BN(tf.keras.Model):\r\n        def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):\r\n            super(Conv2d_BN, self).__init__(name=name)\r\n            self.conv2d_bn = tf.keras.Sequential([tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,\r\n                                                                   padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones),\r\n                                                  tf.keras.layers.BatchNormalization()], name=\"conv2d_bn\")\r\n    \r\n        def call(self, inputs):\r\n            return self.conv2d_bn(inputs)\r\n    \r\n    class test_model2(tf.keras.Model):\r\n        def __init__(self, layer_name, layer_filters, name=\"test_model2\"):\r\n            super(test_model2, self).__init__(name=name)\r\n            self.convs = []\r\n            for n, f in zip(layer_name, layer_filters):\r\n                if \"2\" in n:\r\n                    continue\r\n                self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding=\"valid\", is_use_bias=False,\r\n                                            name=self.name + n + \"/conv1\"))\r\n            self.empty_layer = None\r\n    \r\n        @tf.function\r\n        def call(self, inputs):\r\n            output1 = inputs[0]\r\n            for c_layer in self.convs:\r\n                output1 = c_layer(output1)\r\n    \r\n            output2 = inputs[1]\r\n            for c_layer in self.convs:\r\n                output2 = c_layer(output2)\r\n            if self.empty_layer is None:\r\n                print(\"None\")\r\n            return output1, output2\r\n    \r\n    \r\n    layer_name = [\"layer1\", \"layer2\", \"layer3\", \"layer4\", \"layer5\"]\r\n    layer_filters = [3, 4, 5, 6, 7]\r\n    model = test_model2(layer_name, layer_filters)\r\n    test_input1 = tf.ones((1, 2, 2, 1))\r\n    test_input2 = tf.zeros((1, 2, 2, 1))\r\n    input_list = [test_input1, test_input2]\r\n    test_output1, test_output2 = model(input_list)\r\n    print(test_output1)\r\n    print(test_output2)\r\n    \r\n    model._set_inputs(input_list)\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    tflite_model = converter.convert()\r\n    open(\"./save4/converted_model.tflite\", \"wb\").write(tflite_model)\r\n`\r\n**The following is the error message\uff1a**\r\n\tC:\\software\\Anaconda3\\envs\\TF2_1_GPU\\python.exe C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_\u6a21\u578b\u4fdd\u5b58_\u8fdb\u96364.py\r\n\t2020-02-25 17:50:15.295174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n\t2020-02-25 17:50:17.612336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n\t2020-02-25 17:50:18.876900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\n\tpciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\n\tcoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n\t2020-02-25 17:50:18.877178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n\t2020-02-25 17:50:18.886768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n\t2020-02-25 17:50:18.893842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n\t2020-02-25 17:50:18.898386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n\t2020-02-25 17:50:18.905867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n\t2020-02-25 17:50:18.911441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n\t2020-02-25 17:50:18.924981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\t2020-02-25 17:50:18.925736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n\t2020-02-25 17:50:18.926051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n\t2020-02-25 17:50:18.926915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\n\tpciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\n\tcoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n\t2020-02-25 17:50:18.927189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n\t2020-02-25 17:50:18.927331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n\t2020-02-25 17:50:18.927466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n\t2020-02-25 17:50:18.927601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n\t2020-02-25 17:50:18.927736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n\t2020-02-25 17:50:18.927875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n\t2020-02-25 17:50:18.928013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\t2020-02-25 17:50:18.928571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n\t2020-02-25 17:50:19.461309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n\t2020-02-25 17:50:19.461461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n\t2020-02-25 17:50:19.461550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n\t2020-02-25 17:50:19.462190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\tNone\r\n\tNone\r\n\t2020-02-25 17:50:20.090133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\t2020-02-25 17:50:20.855562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\n\tRelying on driver to perform ptx compilation. This message will be only logged once.\r\n\t2020-02-25 17:50:20.874969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n\ttf.Tensor(\r\n\t[[[[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]\r\n\t   [89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]\r\n\r\n\t  [[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]\r\n\t   [89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]]], shape=(1, 2, 2, 7), dtype=float32)\r\n\ttf.Tensor(\r\n\t[[[[0. 0. 0. 0. 0. 0. 0.]\r\n\t   [0. 0. 0. 0. 0. 0. 0.]]\r\n\r\n\t  [[0. 0. 0. 0. 0. 0. 0.]\r\n\t   [0. 0. 0. 0. 0. 0. 0.]]]], shape=(1, 2, 2, 7), dtype=float32)\r\n\tNone\r\n\t2020-02-25 17:50:21.348618: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n\t2020-02-25 17:50:21.348841: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n\t2020-02-25 17:50:21.350171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\n\tpciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\n\tcoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n\t2020-02-25 17:50:21.350427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n\t2020-02-25 17:50:21.350557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n\t2020-02-25 17:50:21.350687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n\t2020-02-25 17:50:21.350815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n\t2020-02-25 17:50:21.350943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n\t2020-02-25 17:50:21.351072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n\t2020-02-25 17:50:21.351205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\t2020-02-25 17:50:21.351611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n\t2020-02-25 17:50:21.351751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n\t2020-02-25 17:50:21.351889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n\t2020-02-25 17:50:21.351976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n\t2020-02-25 17:50:21.352364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\t2020-02-25 17:50:21.378422: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n\t2020-02-25 17:50:21.378569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (156), 365 edges (338), time = 7.223ms.\r\n\t2020-02-25 17:50:21.378731: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (0), 365 edges (0), time = 3.522ms.\r\n\t2020-02-25 17:50:21.378885: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_true_940\r\n\t2020-02-25 17:50:21.379063: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.379206: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.379345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_false_829\r\n\t2020-02-25 17:50:21.379524: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.379663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.379799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_false_811\r\n\t2020-02-25 17:50:21.379978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.380119: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.380258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_false_764\r\n\t2020-02-25 17:50:21.380435: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.380575: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.380712: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_false_894\r\n\t2020-02-25 17:50:21.380889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.381028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.381166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_false_746\r\n\t2020-02-25 17:50:21.381344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.381482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.381624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_false_674\r\n\t2020-02-25 17:50:21.381805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.381943: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.382079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_true_763\r\n\t2020-02-25 17:50:21.391040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.391189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.391329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_true_893\r\n\t2020-02-25 17:50:21.391507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.391679: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.391817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_true_550\r\n\t2020-02-25 17:50:21.391994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.392136: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.392274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_true_828\r\n\t2020-02-25 17:50:21.392453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.392591: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.392729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_true_1005\r\n\t2020-02-25 17:50:21.392910: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.393057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.393200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_true_478\r\n\t2020-02-25 17:50:21.393374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.393512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.393649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_false_530\r\n\t2020-02-25 17:50:21.393827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.393965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.394105: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_true_810\r\n\t2020-02-25 17:50:21.394282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.394423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.394562: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_false_479\r\n\t2020-02-25 17:50:21.394740: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.406638: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.406786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_false_602\r\n\t2020-02-25 17:50:21.406966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.407107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.407247: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_true_673\r\n\t2020-02-25 17:50:21.407427: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.407565: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.407703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_false_941\r\n\t2020-02-25 17:50:21.407884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.408027: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.408166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_true_958\r\n\t2020-02-25 17:50:21.408344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.408489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.408634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_false_695\r\n\t2020-02-25 17:50:21.408870: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.409096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.409238: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_true_694\r\n\t2020-02-25 17:50:21.409416: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.409558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.409696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_true_529\r\n\t2020-02-25 17:50:21.409874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.410015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.410154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_false_1006\r\n\t2020-02-25 17:50:21.410340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.410486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.422249: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_true_745\r\n\t2020-02-25 17:50:21.422437: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.422581: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.422722: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_false_876\r\n\t2020-02-25 17:50:21.422905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.423048: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.423187: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_true_622\r\n\t2020-02-25 17:50:21.423366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.423508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.423646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_false_959\r\n\t2020-02-25 17:50:21.423825: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.423965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.424103: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_false_551\r\n\t2020-02-25 17:50:21.424283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.424425: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.424567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_true_601\r\n\t2020-02-25 17:50:21.424745: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.424886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.425024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_true_875\r\n\t2020-02-25 17:50:21.425204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\t2020-02-25 17:50:21.425344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.425487: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_false_623\r\n\t2020-02-25 17:50:21.425668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\t2020-02-25 17:50:21.425810: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\tTraceback (most recent call last):\r\n\t  File \"C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_\u6a21\u578b\u4fdd\u5b58_\u8fdb\u96364.py\", line 57, in <module>\r\n\t\ttflite_model = converter.convert()\r\n\t  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 423, in convert\r\n\t\tself._funcs[0], lower_control_flow=False)\r\n\t  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py\", line 437, in convert_variables_to_constants_v2\r\n\t\ttensor_data = _get_tensor_data(func)\r\n\t  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py\", line 209, in _get_tensor_data\r\n\t\tdata = val_tensor.numpy()\r\n\tAttributeError: 'Tensor' object has no attribute 'numpy'\r\n\r\n\tProcess finished with exit code 1\r\n\r\nAfter debugging, it was found that the problem is that the val_tensor variable at line 209 of convert_to_constants.py is keras_learning_phase, it is not a tensor, so there is no numpy () method.\r\n\r\nSo in this case, if you want to nest the Model and save it as a tflite file, what should you do?\r\n", "comments": ["In addition, I saved the model in SaveModel format and I got the following error:\r\n```\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_\u6a21\u578b\u4fdd\u5b58_\u8fdb\u96364.py\", line 57, in <module>\r\n    tf.saved_model.save(model, \"./save4\")\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 909, in save\r\n    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 553, in _fill_meta_graph_def\r\n    object_map, resource_map, asset_info = saveable_view.map_resources()\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 285, in map_resources\r\n    \"supported.\").format(concrete_function.name, capture))\r\nValueError: Attempted to save a function b'__inference__wrapped_model_797' which references a symbolic Tensor Tensor(\"keras_learning_phase:0\", shape=(), dtype=bool) that is not a simple constant. This is not supported.\r\n```\r\nSo is it not supported to save nested custom keras models?", "I seem to find the problem, the main problem is reflected in the BN layer. I deleted the BN layer and was able to save the model correctly.\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass Conv2d_BN(tf.keras.layers.Layer):\r\n    def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):\r\n        super(Conv2d_BN, self).__init__(name=name)\r\n        self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,\r\n                                             padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones)\r\n        # self.bn = tf.keras.layers.BatchNormalization(name=name+\"/bn\")\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output = self.conv2d(inputs)\r\n        # output = self.bn(output)\r\n        return output\r\n\r\n\r\nclass test_model2(tf.keras.Model):\r\n    def __init__(self, layer_name, layer_filters, name=\"test_model2\"):\r\n        super(test_model2, self).__init__(name=name)\r\n        self.convs = []\r\n        for n, f in zip(layer_name, layer_filters):\r\n            if \"2\" in n:\r\n                continue\r\n            self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding=\"valid\", is_use_bias=False,\r\n                                        name=self.name + \"/\" + n + \"/conv1\"))\r\n        self.empty_layer = None\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output1 = inputs[0]\r\n        for c_layer in self.convs:\r\n            output1 = c_layer(output1)\r\n\r\n        output2 = inputs[1]\r\n        for c_layer in self.convs:\r\n            output2 = c_layer(output2)\r\n        if self.empty_layer is None:\r\n            print(\"None\")\r\n        return output1, output2\r\n\r\n\r\nlayer_name = [\"layer1\", \"layer2\", \"layer3\", \"layer4\", \"layer5\"]\r\nlayer_filters = [3, 4, 5, 6, 7]\r\nmodel = test_model2(layer_name, layer_filters)\r\ntest_input1 = tf.ones((1, 2, 2, 1))\r\ntest_input2 = tf.zeros((1, 2, 2, 1))\r\ninput_list = [test_input1, test_input2]\r\n# tf.keras.backend.set_learning_phase(True)\r\ntest_output1, test_output2 = model(input_list)\r\nprint(test_output1)\r\nprint(test_output2)\r\nmodel._set_inputs(input_list)\r\n\r\n# tf.saved_model.save(model, \"./save4\")\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(\"./save4/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nIn addition, I also found that the keras_learning_phase variable also seems to come from the BN layer. As long as I set tf.keras.backend.set_learning_phase (True) or set it to False can avoid this error. But then another error occurred.\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass Conv2d_BN(tf.keras.layers.Layer):\r\n    def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):\r\n        super(Conv2d_BN, self).__init__(name=name)\r\n        self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,\r\n                                             padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones)\r\n        self.bn = tf.keras.layers.BatchNormalization(name=name+\"/bn\")\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output = self.conv2d(inputs)\r\n        output = self.bn(output)\r\n        return output\r\n\r\n\r\nclass test_model2(tf.keras.Model):\r\n    def __init__(self, layer_name, layer_filters, name=\"test_model2\"):\r\n        super(test_model2, self).__init__(name=name)\r\n        self.convs = []\r\n        for n, f in zip(layer_name, layer_filters):\r\n            if \"2\" in n:\r\n                continue\r\n            self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding=\"valid\", is_use_bias=False,\r\n                                        name=self.name + \"/\" + n + \"/conv1\"))\r\n        self.empty_layer = None\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output1 = inputs[0]\r\n        for c_layer in self.convs:\r\n            output1 = c_layer(output1)\r\n\r\n        output2 = inputs[1]\r\n        for c_layer in self.convs:\r\n            output2 = c_layer(output2)\r\n        if self.empty_layer is None:\r\n            print(\"None\")\r\n        return output1, output2\r\n\r\n\r\nlayer_name = [\"layer1\", \"layer2\", \"layer3\", \"layer4\", \"layer5\"]\r\nlayer_filters = [3, 4, 5, 6, 7]\r\nmodel = test_model2(layer_name, layer_filters)\r\ntest_input1 = tf.ones((1, 2, 2, 1))\r\ntest_input2 = tf.zeros((1, 2, 2, 1))\r\ninput_list = [test_input1, test_input2]\r\ntf.keras.backend.set_learning_phase(True)\r\ntest_output1, test_output2 = model(input_list)\r\nprint(test_output1)\r\nprint(test_output2)\r\nmodel._set_inputs(input_list)\r\n\r\n# tf.saved_model.save(model, \"./save4\")\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(\"./save4/converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\n ```\r\nFile \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 423, in convert\r\n    self._funcs[0], lower_control_flow=False)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py\", line 622, in convert_variables_to_constants_v2\r\n    converted_input_indices)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py\", line 398, in _construct_concrete_function\r\n    new_output_names)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\wrap_function.py\", line 631, in function_from_graph_def\r\n    wrapped_import = wrap_function(_imports_graph_def, [])\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\wrap_function.py\", line 609, in wrap_function\r\n    collections={}),\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\wrap_function.py\", line 85, in __call__\r\n    return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\wrap_function.py\", line 91, in wrapped\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\wrap_function.py\", line 629, in _imports_graph_def\r\n    importer.import_graph_def(graph_def, name=\"\")\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\", line 405, in import_graph_def\r\n    producer_op_list=producer_op_list)\r\n  File \"C:\\software\\Anaconda3\\envs\\TF2_1_GPU\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\", line 501, in _import_graph_def_internal\r\n    raise ValueError(str(e))\r\nValueError: Input 1 of node test_model2/StatefulPartitionedCall/test_model2/layer1/conv1/StatefulPartitionedCall/test_model2/layer1/conv1/bn/cond was passed resource from Func/test_model2/StatefulPartitionedCall/test_model2/layer1/conv1/StatefulPartitionedCall/input/_29:0 incompatible with expected float.\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\nThis error still comes from the BN layer. What is the correct way to use the BN layer? How can I properly save to tflite format?", "I tried to convert the model to SaveModel format, and then converted to tflite format also had the same error.", "I tried to write a simple BN layer by myself without any parameters such as renorm, virtual_batch_size. My BN layer only uses fused, and changed tf_utils.smart_cond to if ... else. It can be converted to tflite format normally, so I guess tflite and tf.keras.layers.BatchNormalization are not compatible.\r\n\r\nThe following is the BN layer code I wrote. I have only briefly tested that its output is normal. I have not tested whether it performs normally during training.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras import initializers\r\nfrom tensorflow.python.keras import regularizers\r\nfrom tensorflow.python.keras import constraints\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.python.ops import variables as tf_variables\r\nfrom tensorflow.python.keras.engine.input_spec import InputSpec\r\nfrom tensorflow.python.keras.utils import tf_utils\r\n\r\n\r\nclass BatchNorm(tf.keras.layers.Layer):\r\n    def __init__(self,\r\n                 axis=-1,\r\n                 momentum=0.99,\r\n                 epsilon=1e-3,\r\n                 center=True,\r\n                 scale=True,\r\n                 beta_initializer='zeros',\r\n                 gamma_initializer='ones',\r\n                 moving_mean_initializer='zeros',\r\n                 moving_variance_initializer='ones',\r\n                 beta_regularizer=None,\r\n                 gamma_regularizer=None,\r\n                 beta_constraint=None,\r\n                 gamma_constraint=None,\r\n                 trainable=True,\r\n                 virtual_batch_size=None,\r\n                 name=None,\r\n                 **kwargs):\r\n        super(BatchNorm, self).__init__(\r\n            name=name, **kwargs)\r\n        if isinstance(axis, list):\r\n            self.axis = axis[:]\r\n        elif isinstance(axis, int):\r\n            self.axis = axis\r\n        else:\r\n            raise TypeError('axis must be int or list, type given: %s'\r\n                            % type(axis))\r\n        self.momentum = momentum\r\n        self.epsilon = epsilon\r\n        self.center = center\r\n        self.scale = scale\r\n        self.beta_initializer = initializers.get(beta_initializer)\r\n        self.gamma_initializer = initializers.get(gamma_initializer)\r\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\r\n        self.moving_variance_initializer = initializers.get(\r\n            moving_variance_initializer)\r\n        self.beta_regularizer = regularizers.get(beta_regularizer)\r\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\r\n        self.beta_constraint = constraints.get(beta_constraint)\r\n        self.gamma_constraint = constraints.get(gamma_constraint)\r\n        self.virtual_batch_size = virtual_batch_size\r\n\r\n        self.fused = True\r\n        self._bessels_correction_test_only = True\r\n        self._trainable_var = None\r\n        self.trainable = trainable\r\n\r\n    def build(self, input_shape):\r\n        if not input_shape.ndims:\r\n            raise ValueError('Input has undefined rank:', input_shape)\r\n        ndims = len(input_shape)\r\n\r\n        # Convert axis to list and resolve negatives\r\n        if isinstance(self.axis, int):\r\n            self.axis = [self.axis]\r\n\r\n        for idx, x in enumerate(self.axis):\r\n            if x < 0:\r\n                self.axis[idx] = ndims + x\r\n\r\n        # Validate axes\r\n        for x in self.axis:\r\n            if x < 0 or x >= ndims:\r\n                raise ValueError('Invalid axis: %d' % x)\r\n        if len(self.axis) != len(set(self.axis)):\r\n            raise ValueError('Duplicate axis: %s' % self.axis)\r\n\r\n        if self.virtual_batch_size is not None:\r\n            if self.virtual_batch_size <= 0:\r\n                raise ValueError('virtual_batch_size must be a positive integer that '\r\n                                 'divides the true batch size of the input Tensor')\r\n            # If using virtual batches, the first dimension must be the batch\r\n            # dimension and cannot be the batch norm axis\r\n            if 0 in self.axis:\r\n                raise ValueError('When using virtual_batch_size, the batch dimension '\r\n                                 'must be 0 and thus axis cannot include 0')\r\n\r\n        if self.fused:\r\n            if self.axis == [1]:\r\n                self._data_format = 'NCHW'\r\n            elif self.axis == [3]:\r\n                self._data_format = 'NHWC'\r\n            else:\r\n                raise ValueError('Unsupported axis, fused batch norm only supports '\r\n                                 'axis == [1] or axis == [3]')\r\n\r\n        axis_to_dim = {x: input_shape.dims[x].value for x in self.axis}\r\n        for x in axis_to_dim:\r\n            if axis_to_dim[x] is None:\r\n                raise ValueError('Input has undefined `axis` dimension. Input shape: ',\r\n                                 input_shape)\r\n        self.input_spec = InputSpec(ndim=ndims, axes=axis_to_dim)\r\n\r\n        if len(axis_to_dim) == 1 and self.virtual_batch_size is None:\r\n            # Single axis batch norm (most common/default use-case)\r\n            param_shape = (list(axis_to_dim.values())[0],)\r\n        else:\r\n            # Parameter shape is the original shape but with 1 in all non-axis dims\r\n            param_shape = [axis_to_dim[i] if i in axis_to_dim else 1 for i in range(ndims)]\r\n            if self.virtual_batch_size is not None:\r\n                # When using virtual batches, add an extra dim at index 1\r\n                param_shape.insert(1, 1)\r\n                for idx, x in enumerate(self.axis):\r\n                    self.axis[idx] = x + 1  # Account for added dimension\r\n\r\n        if self.scale:\r\n            self.gamma = self.add_weight(\r\n                name='gamma',\r\n                shape=param_shape,\r\n                dtype=self._param_dtype,\r\n                initializer=self.gamma_initializer,\r\n                regularizer=self.gamma_regularizer,\r\n                constraint=self.gamma_constraint,\r\n                trainable=True,\r\n                experimental_autocast=False)\r\n        else:\r\n            self.gamma = None\r\n            if self.fused:\r\n                self._gamma_const = K.constant(1.0, dtype=self._param_dtype, shape=param_shape)\r\n\r\n        if self.center:\r\n            self.beta = self.add_weight(\r\n                name='beta',\r\n                shape=param_shape,\r\n                dtype=self._param_dtype,\r\n                initializer=self.beta_initializer,\r\n                regularizer=self.beta_regularizer,\r\n                constraint=self.beta_constraint,\r\n                trainable=True,\r\n                experimental_autocast=False)\r\n        else:\r\n            self.beta = None\r\n            if self.fused:\r\n                self._beta_const = K.constant(0.0, dtype=self._param_dtype, shape=param_shape)\r\n\r\n        # Disable variable partitioning when creating the moving mean and variance\r\n        self.moving_mean = self.add_weight(\r\n            name='moving_mean',\r\n            shape=param_shape,\r\n            dtype=self._param_dtype,\r\n            initializer=self.moving_mean_initializer,\r\n            synchronization=tf_variables.VariableSynchronization.ON_READ,\r\n            trainable=False,\r\n            aggregation=tf_variables.VariableAggregation.MEAN,\r\n            experimental_autocast=False)\r\n\r\n        self.moving_variance = self.add_weight(\r\n            name='moving_variance',\r\n            shape=param_shape,\r\n            dtype=self._param_dtype,\r\n            initializer=self.moving_variance_initializer,\r\n            synchronization=tf_variables.VariableSynchronization.ON_READ,\r\n            trainable=False,\r\n            aggregation=tf_variables.VariableAggregation.MEAN,\r\n            experimental_autocast=False)\r\n        self.built = True\r\n\r\n    def call(self, inputs, training=None):\r\n        training = self._get_training_value(training)\r\n        if self.fused:\r\n            outputs = self._fused_batch_norm(inputs, training=training)\r\n            return outputs\r\n\r\n    def _get_training_value(self, training=None):\r\n        if training is None:\r\n            training = K.learning_phase()\r\n\r\n        if isinstance(training, int):\r\n            training = bool(training)\r\n        return training\r\n\r\n    def _fused_batch_norm(self, inputs, training):\r\n        \"\"\"Returns the output of fused batch norm.\"\"\"\r\n        beta = self.beta if self.center else self._beta_const\r\n        gamma = self.gamma if self.scale else self._gamma_const\r\n\r\n        inputs_size = None\r\n\r\n        def _fused_batch_norm_training():\r\n            return tf.compat.v1.nn.fused_batch_norm(\r\n                inputs,\r\n                gamma,\r\n                beta,\r\n                epsilon=self.epsilon,\r\n                data_format=self._data_format)\r\n\r\n        def _fused_batch_norm_inference():\r\n            return tf.compat.v1.nn.fused_batch_norm(\r\n                inputs,\r\n                gamma,\r\n                beta,\r\n                mean=self.moving_mean,\r\n                variance=self.moving_variance,\r\n                epsilon=self.epsilon,\r\n                is_training=False,\r\n                data_format=self._data_format)\r\n\r\n        if training:\r\n            output, mean, variance = _fused_batch_norm_training()\r\n        else:\r\n            output, mean, variance = _fused_batch_norm_inference()\r\n\r\n        training_value = tf_utils.constant_value(training)\r\n        if training_value is None:\r\n            if training:\r\n                momentum = self.momentum\r\n            else:\r\n                momentum = 1.0\r\n        else:\r\n            momentum = tf.convert_to_tensor(self.momentum)\r\n        if training_value or training_value is None:\r\n            def mean_update():\r\n                return self._assign_moving_average(self.moving_mean, mean, momentum,\r\n                                                   inputs_size)\r\n\r\n            def variance_update():\r\n                return self._assign_moving_average(self.moving_variance, variance,\r\n                                                   momentum, inputs_size)\r\n\r\n            self.add_update(mean_update)\r\n            self.add_update(variance_update)\r\n\r\n        return output\r\n\r\n    def _assign_moving_average(self, variable, value, momentum, inputs_size):\r\n        decay = tf.convert_to_tensor(1.0 - momentum, name='decay')\r\n        if decay.dtype != variable.dtype.base_dtype:\r\n            decay = tf.cast(decay, variable.dtype.base_dtype)\r\n        update_delta = (variable - tf.cast(value, variable.dtype)) * decay\r\n        return tf.compat.v1.assign_sub(variable, update_delta)\r\n\r\n    @property\r\n    def _param_dtype(self):\r\n        # Raise parameters of fp16 batch norm to fp32\r\n        if self.dtype == dtypes.float16 or self.dtype == dtypes.bfloat16:\r\n            return dtypes.float32\r\n        else:\r\n            return self.dtype or dtypes.float32\r\n```\r\n", "I added my custom BN layer to MobileNetV3 and trained with ImageNet. I found that my custom BN layer did not seem to affect the convergence performance of the model.\r\nHowever, the original bug has not been resolved, so I do not intend to close this issue.", "@TCBocean You have described multiple issues here. Can you please separate the issues so that it will be easy for the community to follow your issue?  It will be easy for us to resolve issues faster if they are focused on one topic in each post. \r\n\r\nAlso, in each of the post, provide standalone code and also full error trace. Adding links to colab would be very helpful (but not required). Also, check with recently `tf-nightly`, some of the issue related to `BatchNorm` were resolved in the `tf-nightly`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/7390fea36d8257122a97a3036a99adc6/untitled861.ipynb) for the last-but-one-code that works without any error. Thanks!", "@jvishnuvardhan Thanks for your advice.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37043\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37043\">No</a>\n"]}, {"number": 37042, "title": "ImportError: DLL load failed: The specified module could not be found. Failed to load the native TensorFlow runtime.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- Mobile device : none\r\n- TensorFlow installed from): through Pycharm package installer\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6\r\n- Installed using: pip\r\n\r\nI cant import any tensorflow or keras libraries. I get this error. \r\nI tried importing these:\r\n\r\nimport tensorflow as tf \r\nfrom keras.layers import Dense, Activation, Dropout\r\nfrom keras.models import Sequential\r\nfrom keras.utils import to_categorical\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\uvide\\Anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\uvide\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"C:/Users/uvide/PycharmProjects/demo/test.py\", line 4, in <module>\r\n    from Potentiostat import Pot\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\Potentiostat.py\", line 5, in <module>\r\n    from keras.layers import Dense, Activation, Dropout\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\uvide\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.3.3\\plugins\\python-ce\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\uvide\\PycharmProjects\\demo\\venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\uvide\\Anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\uvide\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["@uvinidesilva \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions to install from pip using [Tensorflow website](https://www.tensorflow.org/install/pip).\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you. Thanks!", "@ravikyram I had the same issue and fixed it by downloading the microsoft visual c++ redistributable package. Shouldn't this information be present in the install instructions on the official website?\r\n\r\nAlso, the traceback is pretty much useless in determining which DLL is missing. There would be room for improvement there as well.", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37042\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37042\">No</a>\n"]}, {"number": 37040, "title": " Typofix: in docstring of Keras Model:fit", "body": "A tiny typofix for docstring of Keras Model:fit", "comments": []}, {"number": 37039, "title": "Shape information is lost with DepthwiseConv2D", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or\r\nbinary): source \r\n- TensorFlow version (use command below): 1.15 \r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: RTX 2060\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nIn some cases (use_bias=False, dilation_rate > 1, data_format='channels_first'), the shape information is lost after DepthwiseConv2D. \r\n\r\n**Describe the expected behavior**\r\n\r\nIt should behave the same way for channels_last and channels_first.\r\nWhen running the code below, channels_last prints `shape=(?, ?, ?, 32)` and channels_first prints `shape=(?, ?, ?, ?)`. It should be `shape=(?, 32, ?, ?)`\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n[Here for the gist](https://colab.research.google.com/gist/jnd77/84932ac25671f8b5b59acdcb2f0e5afd/untitled1.ipynb) \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce this issue with Tensorflow 2.0. Heres the [gist](https://colab.sandbox.google.com/gist/gowthamkpr/ac206fc5c714a86002377c7eb180a4fd/untitled1.ipynb).", "Executing the script on cpu gives the correct results:\r\n```python\r\nTensor(\"depthwise_conv2d/Identity:0\", shape=(None, None, None, 32), dtype=float32)\r\nTensor(\"depthwise_conv2d_1/Identity:0\", shape=(None, 32, None, None), dtype=float32)\r\n```", "Thanks for the report! We wouldn't be able to make 1.x changes at this moment (or back-porting). This works find in tf-nightly, please check the below code:\r\n```python\r\n# Try first with channels_last\r\ninput_tensor = np.random.random((32, 12, 12, 32)).astype(np.float32)\r\ninput_tensor_shape = (None, None, None, 32)\r\ndepthwise_conv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3), data_format='channels_last',\r\n                                                  dilation_rate=(2, 2), use_bias=False, input_shape=input_tensor_shape[1:])\r\nprint(depthwise_conv(input_tensor).shape)\r\n\r\n# Then with channels_first\r\ninput_tensor = np.random.random((32, 32, 12, 12)).astype(np.float32)\r\ninput_tensor_shape = (None, 32, None, None)\r\ndepthwise_conv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3), data_format='channels_first',\r\n                                                  dilation_rate=(2, 2), use_bias=False, input_shape=input_tensor_shape[1:])\r\nprint(depthwise_conv(input_tensor).shape)\r\n```\r\n\r\n```\r\n(32, 8, 8, 32)\r\n(32, 32, 8, 8)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37039\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37039\">No</a>\n", "@tanzhenyu Thanks for looking at the ticket.\r\nBut your code runs in eager execution, so obviously the numpy array has a shape.\r\nPlease check the [gist](https://colab.sandbox.google.com/gist/gowthamkpr/ac206fc5c714a86002377c7eb180a4fd/untitled1.ipynb) @gowthamkpr pepared with TF 2 (and still fails with tf-nightly)", "Looks like the issue comes from backend.depthwise_conv2d, using tf.transpose(x, (0, 3, 1, 2))", "@tanzhenyu @gadagashwini Possible to add the flag TF 2.2 so this ticket does not get forgotten ? Thanks a lot. :) ", "> Looks like the issue comes from backend.depthwise_conv2d, using tf.transpose(x, (0, 3, 1, 2))\r\n\r\n@tanzhenyu Indeed the issue comes from `backend.depthwise_conv2d`, but I don't think is due to the transpose since the issues doesn't seem to appear when using `dilation_rate=1`.", "@jnd77 the issue seems to be resolved with the latest tf-nightly, here is a [gist](https://colab.research.google.com/gist/goldiegadde/3ab3465eb24bfb800861cd8990851235/github-issue-37039.ipynb)\r\nCan you please take a look and close if this is indeed resolved ?", "Thanks @goldiegadde.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37039\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37039\">No</a>\n"]}, {"number": 37038, "title": "UnsatisfiedLinkError on nightly build of tensorflow-lite", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Mobile device: Android\r\n- TensorFlow installed from: Gradle (jcenter)\r\n\r\n**Describe the current behavior**\r\nOn sample project, we ran into UnsatisfiedLinkError \"/lib/arm64/libtensorflowlite_gpu_jni.so\" using nightly build. If we switch to 2.1.0 that doesn't have the problem.\r\nOn Android guide to tensorflow-lite it also suggest to use nightly build, and I don't think this is good for production builds.\r\nhttps://www.tensorflow.org/lite/guide/android\r\n\r\n**Describe the expected behavior**\r\nDoesn't run into UnsatisfiedLinkError at runtime.\r\n\r\n**Standalone code to reproduce the issue** \r\nYour sample project\r\n\r\n", "comments": ["I have the same problem, couldn't find any soultion yet. It comes up when I try to create a new GPU delegate.", "> I have the same problem, couldn't find any soultion yet. It comes up when I try to create a new GPU delegate.\r\n\r\nYou can just use \"org.tensorflow:tensorflow-lite:2.1.0\" and \"org.tensorflow:tensorflow-lite-gpu:2.1.0\", nightly build will break.", "Odd, I haven't been able to repro. Can you try [clearing your gradle cache](https://stackoverflow.com/questions/23025433/how-to-clear-gradle-cache) and rebulding? Also, what device are you using to test?\r\n\r\nI successfully built and deployed using:\r\n```\r\ncd examples/lite/examples/image_classification/android\r\n./gradlew cleanBuildCache\r\n./gradlew build\r\nadb install -r -d  ./app/build/outputs/apk/debug/app-debug.apk\r\n```\r\n", "Also note that the GPU and base TFLite dependencies must have matching versions, i.e.,\r\n```\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n```\r\nor\r\n```\r\n    implementation 'org.tensorflow:tensorflow-lite:2.1.0'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:2.1.0'\r\n```", "I guess this is the same as issue https://github.com/tensorflow/tensorflow/issues/37161. And it's addressed by PR https://github.com/tensorflow/tensorflow/pull/37033.", "https://github.com/tensorflow/tensorflow/pull/37033 was merged. Let us know if you still have the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37038\">No</a>\n", "Thanks, the mentioned PR has solved the problem for me!"]}, {"number": 37037, "title": "tf_sess.run takes long time to excute", "body": "I have using mobilenet coco model ,but it takes 5 seconds to finish the function anyone please help me to solve this  or describe why it takes this much of time\r\n\r\ntf_config = tf.ConfigProto()\r\ntf_config.gpu_options.allow_growth = True\r\ntf_sess = tf.Session(config=tf_config)\r\ntf.import_graph_def(trt_graph, name='')\r\n\r\ntf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\r\ntf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\r\ntf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\r\ntf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\r\ntf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')\r\n\r\ntf_input.shape.as_list()\r\n\r\n\r\n\r\n\r\ndef detection(IMAGE_PATH):\r\n    start_time = datetime.datetime.now()\r\n\r\n\r\n    image = cv2.imread(IMAGE_PATH)\r\n    image = cv2.resize(image, (300, 300))\r\n\r\n    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={\r\n    tf_input: image[None, ...]\r\n})\r\n    boxes = boxes[0]  # index by 0 to remove batch dimension\r\n    scores = scores[0]\r\n    classes = classes[0]\r\n    num_detections = int(num_detections[0])\r\n\r\n    #print(boxes)\r\n    #print(scores)\r\n    #print(classes)\r\n    #print(num_detections)\r\n    for num in range(num_detections):\r\n       if classes[num]==1:\r\n          print('person')\r\n          #return 'person'\r\n       if classes[num]==62:\r\n          print('chair')\r\n          #return 'chair'\r\n       if classes[num] != 1 and classes[num] != 62 :\r\n          print(classes[num])\r\n    end_time = datetime.datetime.now()\r\n    diff = (end_time - start_time)\r\n    print(diff)\r\n\r\n\r\ndetection(IMAGE_PATH)\r\n", "comments": ["This issue is resolved by below close\r\nhttps://github.com/tensorflow/models/issues/4355#issuecomment-437536894"]}, {"number": 37036, "title": "tf_sess.run takes 5 seconds", "body": "# tf_sess.run very slow \r\ntf_config = tf.ConfigProto()\r\ntf_config.gpu_options.allow_growth = True\r\ntf_sess = tf.Session(config=tf_config)\r\ntf.import_graph_def(trt_graph, name='')\r\n\r\ntf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\r\ntf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\r\ntf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\r\ntf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\r\ntf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')\r\n\r\ntf_input.shape.as_list()\r\n\r\n\r\n\r\n\r\ndef detection(IMAGE_PATH):\r\n    start_time = datetime.datetime.now()\r\n\r\n\r\n    image = cv2.imread(IMAGE_PATH)\r\n    image = cv2.resize(image, (300, 300))\r\n\r\n    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={\r\n    tf_input: image[None, ...]\r\n})\r\n    boxes = boxes[0]  # index by 0 to remove batch dimension\r\n    scores = scores[0]\r\n    classes = classes[0]\r\n    num_detections = int(num_detections[0])\r\n\r\n    #print(boxes)\r\n    #print(scores)\r\n    #print(classes)\r\n    #print(num_detections)\r\n    for num in range(num_detections):\r\n       if classes[num]==1:\r\n          print('person')\r\n          #return 'person'\r\n       if classes[num]==62:\r\n          print('chair')\r\n          #return 'chair'\r\n       if classes[num] != 1 and classes[num] != 62 :\r\n          print(classes[num])\r\n    end_time = datetime.datetime.now()\r\n    diff = (end_time - start_time)\r\n    print(diff)\r\n\r\n\r\ndetection(IMAGE_PATH)\r\n\r\n\r\nthis code takes around 5 seconds.Could it be reduce in timing?", "comments": ["@HebeVinny, Can you provide the complete standalone code and tensorflow version to analyze the reported issue.Thanks", "@HebeVinny, Please update for the above comment. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 37035, "title": "absl.flags._exceptions.UnparsedFlagAccessError if used flags in tf.TensorSpec", "body": "**System information** \r\n- Have I written custom code \r\nYes: \r\n- OS Platform and Distribution \r\nWin10: \r\n- Mobile device\r\nNo: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: 2.1.0\r\n\r\n**Standalone code to reproduce the issue** \r\ncode snippets url: https://gitee.com/songhaohao2018/codes/cmunjs6zqbe895y7h0gpa21", "comments": ["@songs18 \r\n\r\nAs i understand , you are using TF version 2.1.0.Please provide details about what platform you are using (operating system, architecture). \r\n\r\nThe url you have provided is not working. Request you to provide colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!\r\n\r\n\r\n\r\n\r\n", "OS : Win10 PRO 1903\r\nCPU : i5-4210U\r\nMemory : 8G\r\nTF version : 2.1.0 python CPU version\r\n\r\nreproduce code:\r\n\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom absl import app, logging, flags\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_integer('height', 28, help='image height')\r\nflags.DEFINE_integer('width', 28, help='image width')\r\n\r\nflags.DEFINE_integer('num_classes', default=10, help='class number')\r\nflags.DEFINE_integer('num_futures', default=784, help='num futures')\r\n\r\nflags.DEFINE_float('lr', default=0.001, help='learning rate')\r\nflags.DEFINE_integer('training_steps', default=1000, help='training steps')\r\nflags.DEFINE_integer('batch_size', default=100, help='batch size')\r\n\r\nflags.DEFINE_integer('display_step', default=100, help='display step')\r\n\r\nflags.DEFINE_integer('num_input', default=28, help='number input')\r\nflags.DEFINE_integer('timesteps', default=28, help='tiemsteps')\r\nflags.DEFINE_integer('num_units', default=32, help='num_units')\r\n\r\n\r\ndef get_data():\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n    x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\r\n    x_train, x_test = x_train.reshape([-1, 28, 28]), x_test.reshape([-1, FLAGS.num_futures])\r\n    x_train, x_test = x_train / 255., x_test / 255.\r\n    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n    train_data = train_data.repeat().shuffle(5000).batch(FLAGS.batch_size).prefetch(1)\r\n\r\n    return train_data\r\n\r\n\r\nclass BiRNN(tf.keras.Model):\r\n    def __init__(self):\r\n        super(BiRNN, self).__init__()\r\n\r\n        lstm_fw = tf.keras.layers.LSTM(units=FLAGS.num_units)\r\n        lstm_bw = tf.keras.layers.LSTM(units=FLAGS.num_units, go_backwards=True)\r\n\r\n        self.bi_lstm = tf.keras.layers.Bidirectional(lstm_fw, backward_layer=lstm_bw)\r\n        self.out = tf.keras.layers.Dense(FLAGS.num_classes)\r\n\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, FLAGS.height, FLAGS.width], dtype=tf.float32)])\r\n    def call(self, x):\r\n        x = self.bi_lstm(x)\r\n        x = self.out(x)\r\n\r\n        x = tf.nn.softmax(x)\r\n        return x\r\n\r\n\r\ndef cross_entropy_loss(x, y):\r\n    y = tf.cast(y, tf.int64)\r\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\r\n    return tf.reduce_mean(loss)\r\n\r\n\r\ndef accuracy(y_pred, y_true):\r\n    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\r\n    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\r\n\r\n\r\ndef run_optimization(birnn_net, optimizer, x, y):\r\n    with tf.GradientTape() as tape:\r\n        pred = birnn_net(x)\r\n        loss = cross_entropy_loss(pred, y)\r\n    trainable_variables = birnn_net.trainable_variables\r\n    gradients = tape.gradient(loss, trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, trainable_variables))\r\n\r\n\r\ndef main(argv):\r\n    del argv\r\n\r\n    train_data = get_data()\r\n    birnn_net = BiRNN()\r\n    optimizer = tf.optimizers.Adam(FLAGS.lr)\r\n\r\n    for step, (batch_x, batch_y) in enumerate(train_data.take(FLAGS.training_steps), 1):\r\n        run_optimization(birnn_net, optimizer, batch_x, batch_y)\r\n        if step % FLAGS.display_step == 0:\r\n            pred = birnn_net(batch_x)\r\n            loss = accuracy(pred, batch_y)\r\n            acc = accuracy(pred, batch_y)\r\n            logging.info('step: {}, loss: {}, accuracy: {}'.format(step, loss, acc))\r\n\r\n\r\nif __name__ == '__main__':\r\n    app.run(main)", "@songs18 \r\n\r\nRequest you to share colab link or simple standalone code with proper indentation to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "https://gitee.com/songhaohao2018/tf_issues/blob/master/absl_202002.py", "I have tried on colab with TF version 2.1.0 and i am able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/7b0655f72b550f1789d328f63800b5b4/untitled697.ipynb).Thanks!", "This is expected. The flag is parsed when app.run(main) is executed. However, the @tf.function annotation is parsed when the class BiRNN and all its methods are parsed. Note that method body is not parsed until it get invoked, but method signature is parsed when class is parsed. This means that you can't have FLAG.hight in the annotation for the typespec.\r\n\r\nNote that input_signature is used to control the shape and dtype of the tensor passed to the function. It's fine to be None, and it won't cause any issue / retrace, as long as the data passed are with same dtype and shape.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37035\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37035\">No</a>\n"]}, {"number": 37034, "title": "Feature: add utils for keras saving/loading format detection", "body": "Add utils for Keras saving/loading format detection", "comments": ["@k-w-w Please take a look. Thank you!", "Sorry for the extremely late review! Thanks for adding this PR, can you rebase onto master? There shouldn't be too many merge conflicts.\r\n\r\nAlso, the TODO(b/130258301) refers to detecting whether the model is subclassed (rather than created with the functional/Sequential APIs), so it should be left in the code.\r\n", "@k-w-w Sure! I will update this PR later.", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37034) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37034) for more info**.\n\n<!-- ok -->", "@k-w-w I already update the PR, please take a look!", "@howl-anderson  Any update on this PR? Please. Thanks!", "@gbaned I have been unexpectedly busy in recent days and I will update this PR early next week.", "@howl-anderson Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@howl-anderson Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}]