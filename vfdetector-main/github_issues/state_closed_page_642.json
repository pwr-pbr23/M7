[{"number": 34362, "title": "TF Speech recognition issue", "body": "When I debugg the TF apk file and after installing speech recognition after pressing Start button it's just not working ...", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@singh728om \r\n\r\nAny update on this issue please? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34361, "title": "module 'keras.applications' has no attribute 'resnet'", "body": "I tried to google the whole day and nothing worked for me.\r\n\r\nSo in the beginning I got this:\r\nmodule 'keras.applications' has no attribute 'resnet'\r\n\r\nThen I tried a few ways that I got from googling, I got this:\r\nmodule 'tensorflow' has no attribute 'get_default_graph'\r\n\r\nseems like related but I can't understand what's wrong here. My keras version is 2.2.4.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Thanks for your reply ravikyram.\r\n\r\nOS: Windows 10\r\nPython 3.6 with Anaconda\r\nTensorFlow version: 2.0.0\r\nkeras version: 2.2.4\r\n\r\nI installed tensorflow in Anaconda with conda install xxxxx. And then I got into the tensorflow environment in Anaconda and installed keras. I was provided these codes but they didn't seem to work. The purpose here is to download the ResNet50 model.\r\n\r\nimport numpy as np\r\nimport keras\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom keras.applications.resnet50 import ResNet50, decode_predictions\r\nfrom keras import layers\r\nfrom keras.models import Model, Sequential\r\nfrom keras.callbacks.callbacks import ModelCheckpoint, EarlyStopping\r\nresnet = keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\r\n\r\nI tried keras_application. I tried tensorflow.keras.xxxx. Nothing worked for me. I'm totally lost... Thanks!", "@mimimichelle \r\nI tried with tf.keras and it was working fine. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/b7bc35d73f7a8238119f0340103ea120/untitled381.ipynb).Thanks!", "@mimimichelle \r\nPlease, let us know if this issue still persists?.Thanks!", "Thanks for trying to help. I figured out it's a version/Windows-Anaconda default setting problem. ", "> Thanks for trying to help. I figured out it's a version/Windows-Anaconda default setting problem.\r\n\r\nHello @mimimichelle , can you specify what was that exactly?"]}, {"number": 34360, "title": "Update array_ops.py", "body": "Update documentation, formatting and fix typos for several methods.", "comments": ["Batching fixes together. Will add commits on top of this.", "@steph-en-m Looking good? ", "Looks good to me. @k-w-w \r\n", "Sorry, I had made this PR on `master`, so moved it to https://github.com/tensorflow/tensorflow/pull/34864. Please see that. Closing this now."]}, {"number": 34359, "title": "Updating/setting xcode version to 10.3", "body": "PiperOrigin-RevId: 280756701\r\nChange-Id: I3b4c8ce78ef5a68a0a23f32ac25caf527597c700", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34359) for more info**.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34359) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 34358, "title": "Dynamic Batch size ( Bucketing ) for GPU in MirrorStrategy in TF 2.0 and avoid NaN .", "body": "\r\n\r\nTensorflow - version 2 \r\n\r\nHi All, I am trying to do bucketing my tensorflow datasets, so that I can change my batch size (dynamic batch size) based on different sequence length, so that I can exploit GPU performance better. I am using ```strategy = tf.distribute.MirroredStrategy()``` . \r\n\r\nAssume I am having 8 GPUs ```n_gpus=8```, according to mirror strategy if we are having a batch size of 16 ```batch_size=16```, it will distribute ```2 ( batch_size / n_gpus ) ``` batch datasets to each of the GPUs. Now, assume ```batch_size``` is dynamic and changing in each iteration over the ```dataset iterator```. In order to make it distributed, whenever  ```batch_size``` is not a multiple of ```n_gpus```, I will pad it and make it to the nearest possible multiple of ```n_gpus```. (If ```batch_size = 6```, I will pad with ```2 rows of zeros``` to make it ```8``` ).  Everything works well in CPUs. But when I am using ```iterator = strategy.experimental_distribute_dataset(input_data)```, things becomes difficult. I am providing the code .\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef create_dummy_squad_data(max_seq_length,n,vocab_size=30000):\r\n    np.random.seed(1)\r\n    input_ids   = np.random.randint(1, vocab_size-1, (n,max_seq_length))\r\n    input_mask  = np.random.randint(0, 2, (n,max_seq_length))\r\n    token_type_ids   = np.random.randint(1, 2, (n,max_seq_length))\r\n    start_labels = np.random.randint(1, max_seq_length-1, (n))\r\n    end_labels = np.random.randint(1, max_seq_length-1, (n))\r\n\r\n    return (input_ids, input_mask, token_type_ids, start_labels, end_labels)\r\n\r\n\r\ndef map_to_dict(input_ids, input_mask, token_type_ids, start_labels, end_labels):\r\n    inputs = {}\r\n    inputs['input_ids']   = input_ids\r\n    inputs['input_mask']  = input_mask\r\n    inputs['segment_ids'] = token_type_ids\r\n\r\n    labels = {}\r\n    labels['start_positions'] = start_labels\r\n    labels['end_positions'] = end_labels\r\n\r\n    return inputs, labels\r\n\r\ndef pad_batch(inputs, labels, batch_multiple=8):\r\n    batch_size = tf.shape(inputs['input_ids'])[0]\r\n    mod = batch_size % batch_multiple\r\n    has_mod = tf.cast(tf.cast(mod, tf.bool), tf.int32)\r\n    batch_padding = batch_multiple * has_mod - mod\r\n\r\n    inputs_padded = {}\r\n    for k, feature in inputs.items():\r\n        rank = len(feature.shape)\r\n        paddings = [[0, 0] for _ in range(rank)]\r\n        paddings[0][1] = batch_padding\r\n        padded_feature = tf.pad(feature, paddings)\r\n        inputs_padded[k] = padded_feature\r\n\r\n    labels_padded = {}\r\n    for k, feature in labels.items():\r\n        rank = len(feature.shape)\r\n        paddings = [[0, 0] for _ in range(rank)]\r\n        paddings[0][1] = batch_padding\r\n        padded_feature = tf.pad(feature, paddings)\r\n        labels_padded[k] = padded_feature\r\n    return inputs_padded, labels_padded\r\n\r\n#### Main code starts from here (CPU code)\r\ninput_ids, input_mask, token_type_ids, start_labels, end_labels = create_dummy_squad_data(5, 100)\r\nd = tf.data.Dataset.from_tensor_slices((input_ids, input_mask, token_type_ids, start_labels, end_labels))\r\nd = d.map(map_to_dict)\r\n\r\nbatch_size_per_gpu = 1\r\nnum_gpus       = 8\r\n\r\nbatch_size = batch_size_per_gpu * num_gpus\r\n\r\nd = d.batch(batch_size)\r\nd = d.map(pad_batch)\r\nfor item in d:\r\n    pass\r\n```\r\nLast batch of ```item``` is having ```batch_size = 4 ( if we dont pad )```. As I am using padding, things are good\r\n\r\nSample output ( item[0]['input_ids'] )\r\n------------------------------------\r\n```\r\n<tf.Tensor: id=1801, shape=(8, 5), dtype=int64, numpy=\r\narray([[29865,  5139,  4322,  7079, 24896],\r\n       [ 2548,  1583,  7529, 14554, 21480],\r\n       [20593,  2560, 27139, 26397, 28367],\r\n       [25292, 23995, 26283,  4891, 28905],\r\n       [    0,     0,     0,     0,     0],\r\n       [    0,     0,     0,     0,     0],\r\n       [    0,     0,     0,     0,     0],\r\n       [    0,     0,     0,     0,     0]])>\r\n```\r\n\r\n#### Code in GPU ( This is what I want )\r\n\r\n````\r\n    with strategy.scope():\r\n        iterator = strategy.experimental_distribute_dataset(d)\r\n    all_batch_data = [] #### was curious to know how things work\r\n    with strategy.scope():\r\n        for batch_data in iterator:\r\n            all_batch_data.append(batch_data)\r\n            print(\"Batch  Data shape per gpus\", batch_data[0]['input_ids'].values[0].shape)\r\n````\r\nAs you see below, ```GPU [0,1,2,3]``` takes each 4 elements and padded it individually ( which was not I expected ). and ```GPU[4,5,6,7]```, not receiving anything. At the time of modeling, the last 4 GPUs, returns ```nan``` as loss, and when I am using ```strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\r\n                               axis=None)```, it becomes ```nan``` . Here, ```per_replica_losses``` is losses from ```8 GPUs```. First 4 is having values, but last 4 is ```nan```. \r\n\r\nSample output ( batch_data[0]['input_ids'])\r\n------------------------------------------\r\n\r\n```\r\n'input_ids': PerReplica:{\r\n    0 /job:localhost/replica:0/task:0/device:GPU:0: <tf.Tensor: id=123188, shape=(8, 5), dtype=int64, numpy=\r\n  array([[29865,  5139,  4322,  7079, 24896],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0]])>,\r\n    1 /job:localhost/replica:0/task:0/device:GPU:1: <tf.Tensor: id=123194, shape=(8, 5), dtype=int64, numpy=\r\n  array([[ 2548,  1583,  7529, 14554, 21480],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0]])>,\r\n    2 /job:localhost/replica:0/task:0/device:GPU:2: <tf.Tensor: id=123200, shape=(8, 5), dtype=int64, numpy=\r\n  array([[20593,  2560, 27139, 26397, 28367],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0]])>,\r\n    3 /job:localhost/replica:0/task:0/device:GPU:3: <tf.Tensor: id=123206, shape=(8, 5), dtype=int64, numpy=\r\n  array([[25292, 23995, 26283,  4891, 28905],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0],\r\n         [    0,     0,     0,     0,     0]])>,\r\n    4 /job:localhost/replica:0/task:0/device:GPU:4: <tf.Tensor: id=123214, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,\r\n    5 /job:localhost/replica:0/task:0/device:GPU:5: <tf.Tensor: id=123230, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,\r\n    6 /job:localhost/replica:0/task:0/device:GPU:6: <tf.Tensor: id=123246, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>,\r\n    7 /job:localhost/replica:0/task:0/device:GPU:7: <tf.Tensor: id=123262, shape=(0, 5), dtype=int64, numpy=array([], shape=(0, 5), dtype=int64)>\r\n  }}\r\n```\r\n\r\nExpected behaviour\r\n--------------------\r\n\r\nIf I am not using ```pad_batch```, when ```batch_size = 8```, each GPU gets ```1 dataset``` each and things are good. But, as I am having ```dynamic batch size```, all batch sizes are not multiple of ```n_gpus=8```. Now, when i am trying to make sure that, ```batch_size``` is multiple of ```n_gpus```, things get messed up. \r\n\r\nIf the last batch is 4, we pad 4 zeros to make it 8. and I expect it will be distribute to each GPU ( 1 dataset each ) and last 4 GPUs get zero padded rows each, so that they wont return ```nan``` and things are good. But, how could I achieve it. @guptapriya \r\n\r\nMight be an extension of https://github.com/tensorflow/tensorflow/issues/29975 . \r\n\r\nSorry if I confuse you with long explanation .\r\n", "comments": ["You don't need to pad your dataset. TF can handle a partial batch for MirroredStrategy (MultiWorkerMirroredStrategy is working in progress). \r\n\r\nI'm curious how you achieve dynamic batch size though. Are you creating one dataset per bucket?", "FYI I was told that the partial batch support was a recent development. Could you try 2.2 or nightly?", "@s4sarath   Closing this issue as we don't have enough information to reproduce it. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34358\">No</a>\n"]}, {"number": 34357, "title": "object_detection  dataset could not be checkpointed", "body": "Hi, guys:\r\nfor TF1.14/1.15 used with tensorflow_model object_detction,\r\n\r\nif I tried to save the state of the dataset for next restoring, I would encounter an issue.\r\n\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: Op[name: RandomHorizontalFlip/random_uniform/RandomUniform, type: RandomUniform] in function Dataset_map_process_fn_70 is stateful. Saving stateful functions is not supported yet.\r\n         [[node SerializeIterator (defined at /local/mnt/workspace/zhanghao/download/tensorflow_model/research/object_detection/inputs.py:588) ]]\r\n  (1) Invalid argument: Op[name: RandomHorizontalFlip/random_uniform/RandomUniform, type: RandomUniform] in function Dataset_map_process_fn_70 is stateful. Saving stateful functions is not supported yet.\r\n         [[node SerializeIterator (defined at /local/mnt/workspace/zhanghao/download/tensorflow_model/research/object_detection/inputs.py:588) ]]\r\n         [[FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1/_7416]]\r\n\r\nAnd the try is just adding the code to \"<dir>/tensorflow_model/research/object_detection/inputs.py::train_input\"\r\n\r\n`  dataset = INPUT_BUILDER_UTIL_MAP['dataset_build'](\r\n      train_input_config,\r\n      transform_input_data_fn=transform_and_pad_input_data_fn,\r\n      batch_size=params['batch_size'] if params else train_config.batch_size)\r\n\r\n  iterator = dataset.make_initializable_iterator()\r\n  tf.add_to_collection(tf.GraphKeys.TABLE_INITIALIZERS, iterator.initializer)\r\n\r\n  saveable_obj = tf.data.experimental.make_saveable_from_iterator(iterator)\r\n\r\n  tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable_obj)\r\n\r\n  return dataset`\r\n\r\nAnd if I adopt \"tf.data.experimental.CheckpointInputPipelineHook\", got the same issue.", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "yep, thank you."]}, {"number": 34356, "title": "Updated typo (?) on documentation for Attention layer", "body": "Isn't value_input should be used instead query_input in value_embeddings? It feels like a typo error?", "comments": ["Please open PR against `master` branch. We don't update release branches (`r...`) after the final release of the corresponding TF version (i.e., we won't update `r2.1` after TF2.1 is released).\r\n\r\nThe only time release branches are updated is when we make a patch release to fix a security vulnerability. As that requires expediency, we only accept minimal changes even then."]}, {"number": 34355, "title": "Error Massage: tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.", "body": " - python version: 3.6.7\r\n - tensorflow-gpu version: 2.0.0 \r\n - keras version: 2.3.1 \r\n - cuDNN version:10.0 \r\n - CUDA version:10.0\r\n\r\n\r\nmnist_mlp.py (https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) works perfectly but code which is given below gives me this error:\r\n\r\n```\r\n    tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n             [[node conv2d_7/convolution (defined at C:\\Users\\ACSECKIN\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_keras_scratch_graph_4815]\r\n    \r\n    Function call stack:\r\n    keras_scratch_graph\r\n```\r\n\r\nProject code derived from https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\r\n\r\ncode:\r\n\r\n    ```\r\n    from numpy import load\r\n    from numpy import zeros\r\n    from numpy import ones\r\n    from numpy.random import randint\r\n    from keras.optimizers import Adam\r\n    from keras.initializers import RandomNormal\r\n    from keras.models import Model\r\n    from keras.models import Input\r\n    from keras.layers import Conv2D\r\n    from keras.layers import Conv2DTranspose\r\n    from keras.layers import LeakyReLU\r\n    from keras.layers import Activation\r\n    from keras.layers import Concatenate\r\n    from keras.layers import Dropout\r\n    from keras.layers import BatchNormalization\r\n    from keras.layers import LeakyReLU\r\n    from matplotlib import pyplot\r\n    \r\n    # define the discriminator model\r\n    def define_discriminator(image_shape):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# source image input\r\n    \tin_src_image = Input(shape=image_shape)\r\n    \t# target image input\r\n    \tin_target_image = Input(shape=image_shape)\r\n    \t# concatenate images channel-wise\r\n    \tmerged = Concatenate()([in_src_image, in_target_image])\r\n    \t# C64\r\n    \td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C128\r\n    \td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C256\r\n    \td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# C512\r\n    \td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# second last output layer\r\n    \td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\r\n    \td = BatchNormalization()(d)\r\n    \td = LeakyReLU(alpha=0.2)(d)\r\n    \t# patch output\r\n    \td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\r\n    \tpatch_out = Activation('sigmoid')(d)\r\n    \t# define model\r\n    \tmodel = Model([in_src_image, in_target_image], patch_out)\r\n    \t# compile model\r\n    \topt = Adam(lr=0.0002, beta_1=0.5)\r\n    \tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\r\n    \treturn model\r\n    \r\n    # define an encoder block\r\n    def define_encoder_block(layer_in, n_filters, batchnorm=True):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# add downsampling layer\r\n    \tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\r\n    \t# conditionally add batch normalization\r\n    \tif batchnorm:\r\n    \t\tg = BatchNormalization()(g, training=True)\r\n    \t# leaky relu activation\r\n    \tg = LeakyReLU(alpha=0.2)(g)\r\n    \treturn g\r\n    \r\n    # define a decoder block\r\n    def decoder_block(layer_in, skip_in, n_filters, dropout=True):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# add upsampling layer\r\n    \tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\r\n    \t# add batch normalization\r\n    \tg = BatchNormalization()(g, training=True)\r\n    \t# conditionally add dropout\r\n    \tif dropout:\r\n    \t\tg = Dropout(0.5)(g, training=True)\r\n    \t# merge with skip connection\r\n    \tg = Concatenate()([g, skip_in])\r\n    \t# relu activation\r\n    \tg = Activation('relu')(g)\r\n    \treturn g\r\n    \r\n    # define the standalone generator model\r\n    def define_generator(image_shape=(256,256,3)):\r\n    \t# weight initialization\r\n    \tinit = RandomNormal(stddev=0.02)\r\n    \t# image input\r\n    \tin_image = Input(shape=image_shape)\r\n    \t# encoder model\r\n    \te1 = define_encoder_block(in_image, 64, batchnorm=False)\r\n    \te2 = define_encoder_block(e1, 128)\r\n    \te3 = define_encoder_block(e2, 256)\r\n    \te4 = define_encoder_block(e3, 512)\r\n    \te5 = define_encoder_block(e4, 512)\r\n    \te6 = define_encoder_block(e5, 512)\r\n    \te7 = define_encoder_block(e6, 512)\r\n    \t# bottleneck, no batch norm and relu\r\n    \tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\r\n    \tb = Activation('relu')(b)\r\n    \t# decoder model\r\n    \td1 = decoder_block(b, e7, 512)\r\n    \td2 = decoder_block(d1, e6, 512)\r\n    \td3 = decoder_block(d2, e5, 512)\r\n    \td4 = decoder_block(d3, e4, 512, dropout=False)\r\n    \td5 = decoder_block(d4, e3, 256, dropout=False)\r\n    \td6 = decoder_block(d5, e2, 128, dropout=False)\r\n    \td7 = decoder_block(d6, e1, 64, dropout=False)\r\n    \t# output\r\n    \tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\r\n    \tout_image = Activation('tanh')(g)\r\n    \t# define model\r\n    \tmodel = Model(in_image, out_image)\r\n    \treturn model\r\n    \r\n    # define the combined generator and discriminator model, for updating the generator\r\n    def define_gan(g_model, d_model, image_shape):\r\n    \t# make weights in the discriminator not trainable\r\n    \td_model.trainable = False\r\n    \t# define the source image\r\n    \tin_src = Input(shape=image_shape)\r\n    \t# connect the source image to the generator input\r\n    \tgen_out = g_model(in_src)\r\n    \t# connect the source input and generator output to the discriminator input\r\n    \tdis_out = d_model([in_src, gen_out])\r\n    \t# src image as input, generated image and classification output\r\n    \tmodel = Model(in_src, [dis_out, gen_out])\r\n    \t# compile model\r\n    \topt = Adam(lr=0.0002, beta_1=0.5)\r\n    \tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\r\n    \treturn model\r\n    \r\n    # load and prepare training images\r\n    def load_real_samples(filename):\r\n    \t# load compressed arrays\r\n    \tdata = load(filename)\r\n    \t# unpack arrays\r\n    \tX1, X2 = data['arr_0'], data['arr_1']\r\n    \t# scale from [0,255] to [-1,1]\r\n    \tX1 = (X1 - 127.5) / 127.5\r\n    \tX2 = (X2 - 127.5) / 127.5\r\n    \treturn [X1, X2]\r\n    \r\n    # select a batch of random samples, returns images and target\r\n    def generate_real_samples(dataset, n_samples, patch_shape):\r\n    \t# unpack dataset\r\n    \ttrainA, trainB = dataset\r\n    \t# choose random instances\r\n    \tix = randint(0, trainA.shape[0], n_samples)\r\n    \t# retrieve selected images\r\n    \tX1, X2 = trainA[ix], trainB[ix]\r\n    \t# generate 'real' class labels (1)\r\n    \ty = ones((n_samples, patch_shape, patch_shape, 1))\r\n    \treturn [X1, X2], y\r\n    \r\n    # generate a batch of images, returns images and targets\r\n    def generate_fake_samples(g_model, samples, patch_shape):\r\n    \t# generate fake instance\r\n    \tX = g_model.predict(samples)\r\n    \t# create 'fake' class labels (0)\r\n    \ty = zeros((len(X), patch_shape, patch_shape, 1))\r\n    \treturn X, y\r\n    \r\n    # generate samples and save as a plot and save the model\r\n    def summarize_performance(step, g_model, dataset, n_samples=3):\r\n    \t# select a sample of input images\r\n    \t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\r\n    \t# generate a batch of fake samples\r\n    \tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\r\n    \t# scale all pixels from [-1,1] to [0,1]\r\n    \tX_realA = (X_realA + 1) / 2.0\r\n    \tX_realB = (X_realB + 1) / 2.0\r\n    \tX_fakeB = (X_fakeB + 1) / 2.0\r\n    \t# plot real source images\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_realA[i])\r\n    \t# plot generated target image\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_fakeB[i])\r\n    \t# plot real target image\r\n    \tfor i in range(n_samples):\r\n    \t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\r\n    \t\tpyplot.axis('off')\r\n    \t\tpyplot.imshow(X_realB[i])\r\n    \t# save plot to file\r\n    \tfilename1 = 'plot_%06d.png' % (step+1)\r\n    \tpyplot.savefig(filename1)\r\n    \tpyplot.close()\r\n    \t# save the generator model\r\n    \tfilename2 = 'model_%06d.h5' % (step+1)\r\n    \tg_model.save(filename2)\r\n    \tprint('>Saved: %s and %s' % (filename1, filename2))\r\n    \r\n    # train pix2pix models\r\n    def train(d_model, g_model, gan_model, dataset, n_epochs=50, n_batch=1):\r\n    \t# determine the output square shape of the discriminator\r\n    \tn_patch = d_model.output_shape[1]\r\n    \t# unpack dataset\r\n    \ttrainA, trainB = dataset\r\n    \t# calculate the number of batches per training epoch\r\n    \tbat_per_epo = int(len(trainA) / n_batch)\r\n    \t# calculate the number of training iterations\r\n    \tn_steps = bat_per_epo * n_epochs\r\n    \t# manually enumerate epochs\r\n    \tfor i in range(n_steps):\r\n    \t\t# select a batch of real samples\r\n    \t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\r\n    \t\t# generate a batch of fake samples\r\n    \t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\r\n    \t\t# update discriminator for real samples\r\n    \t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\r\n    \t\t# update discriminator for generated samples\r\n    \t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\r\n    \t\t# update the generator\r\n    \t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\r\n    \t\t# summarize performance\r\n    \t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\r\n    \t\t# summarize model performance\r\n    \t\tif (i+1) % (bat_per_epo * 10) == 0:\r\n    \t\t\tsummarize_performance(i, g_model, dataset)\r\n    \r\n    \r\n    # load image data\r\n    dataset = load_real_samples('fabric_256.npz')\r\n    print('Loaded', dataset[0].shape, dataset[1].shape)\r\n    # define input shape based on the loaded dataset\r\n    image_shape = dataset[0].shape[1:]\r\n    # define the models\r\n    d_model = define_discriminator(image_shape)\r\n    g_model = define_generator(image_shape)\r\n    # define the composite model\r\n    gan_model = define_gan(g_model, d_model, image_shape)\r\n    # train model\r\n    train(d_model, g_model, gan_model, dataset)\r\n\r\n```\r\n", "comments": ["@acseckin \r\n\r\nCan you please go through TensorFlow GPU instructions [page](https://www.tensorflow.org/install/gpu#ubuntu_1604_cuda_10) and see if it helps you.I guess the problem with the compatibility.\r\nUpgrade libcudnn packages to 7.6.2 and Initialize your code with following code and let us know how it progresses.\r\n```\r\nimport tensorflow as tf\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\n```\r\nThanks!", "@acseckin \r\n\r\nAny update on this issue please? Thanks!", "Still same. Can you share a working/ compatible versions. I think some version of tensorflow doesnt support higer cuda versions. I tried a lot of combinations (tensorflow, keras cuda and cudnn) but no response for gpu. code works fine for cpu.\r\n", "Hope this helps. I was facing the similar issue with:\r\ntensorlfow 2.0\r\nCUDA 10.0\r\ncuDNN 7.6.5\r\n\r\nI downgraded to cuDNN 7.6.2 and my model is training now. I tried cuDNN 7.5.1 before cuDNN 7.6.2, but that complained that source was built with 7.6 +", "I was having this issue when running with TensorFlow v1.15, CUDA 10.0.130,  CUDNN 7.6.0.64 in eager mode. Adding ```allow_growth``` as @acseckin suggested fixed the problem.", "@acseckin Can I close this issue as it has been solved. Thanks!", "Also just a note, I saw the error again when running another piece of code. Upgrading CUDNN solved it:\r\n\r\n```sudo apt-get install --no-install-recommends libcudnn7=7.6.2.24-1+cuda10.0```", "I guess this should be updated in the documentation especially [here ](https://www.tensorflow.org/install/source#gpu)so  there is no confusion progressing furthur.", "For TF-GPU , CUDA, CUDNN compatibility refer [tested build config](https://www.tensorflow.org/install/source#gpu) chart.\r\nClosing this issue since it's resolved. Feel free to reopen if necessary. Thanks!"]}, {"number": 34354, "title": "tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found", "body": "hello = tf.constant('Hello, TensorFlow!')\r\n----\r\nTraceback (most recent call last):\r\n  File \"<pyshell#5>\", line 1, in <module>\r\n    hello = tf.constant('Hello, TensorFlow!')\r\n  File \"C:\\Users\\yang kil ho\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 227, in constant\r\n    allow_broadcast=True)\r\n  File \"C:\\Users\\yang kil ho\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 235, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"C:\\Users\\yang kil ho\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 95, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"C:\\Users\\yang kil ho\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 492, in ensure_initialized\r\n    self._context_handle = pywrap_tensorflow.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.\r\n\r\n\r\nI updated my CUDA version to 10.1, but it doesn't work.", "comments": ["TensorFlow supports CUDA 10.0 (TensorFlow >= 1.13.0)\r\nPlease switch to cuda 10.0 and update cuda paths.\r\nSee [software requirements](https://www.tensorflow.org/install/gpu#software_requirements)\r\nAlso see which TF binary suits your case https://www.tensorflow.org/install/pip?lang=python3#older-versions-of-tensorflow ", "so... how to I downgrade CUDA to 10.0? ", "@yangis1019 ,\r\nPlease refer this [link](https://www.tensorflow.org/install/gpu).Thanks!", "OK", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34354\">No</a>\n"]}, {"number": 34353, "title": "Merging two RT graphs throughs an error", "body": "I want to merge two RT graphs into a single graph. But while merging I'm getting error.\r\nMy code is as follows:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nsaved_model1 = \"/home/xavier2/saved_model/ssd_tomato_l1\"\r\nsaved_model2 = \"/home/xavier2/saved_model/faster_rcnn_tomato_l2_grid_750x750\"\r\n\r\ndef create_trt_inference_graph(graph_path):\r\n    converter = trt.TrtGraphConverter(input_saved_model_dir=graph_path , \r\n        precision_mode=trt.TrtPrecisionMode.FP16)\r\n    converted_graph_def = converter.convert()\r\n    return converted_graph_def\r\n\r\ndef get_serialized_graph(graph_path):\r\n    converted_graph_def = create_trt_inference_graph(graph_path)\r\n    serial_def = converted_graph_def.SerializeToString()\r\n    return serial_def\r\n\r\ndef get_frozen_graph(graph_path):\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(get_serialized_graph(graph_path))\r\n    return graph_def\r\n\r\ndef rename_frame_name(graphdef, suffix):\r\n    # Bug reported at https://github.com/tensorflow/tensorflow/issues/22162#issuecomment-428091121\r\n    for n in graphdef.node:\r\n        if \"while\" in n.name:\r\n            if \"frame_name\" in n.attr:\r\n                n.attr[\"frame_name\"].s = str(n.attr[\"frame_name\"]).replace(\"while_context\",\"while_context\" + suffix).encode('utf-8')\r\n\r\nl1_graph = tf.Graph()\r\nwith l1_graph.as_default():\r\n    trt_graph1 = get_frozen_graph(saved_model1)\r\n    [tf_input1, tf_scores1, tf_boxes1, tf_classes1, tf_num_detections1] = tf.import_graph_def(trt_graph1, \r\n            return_elements=['import/image_tensor:0', 'import/detection_scores:0', 'import/detection_boxes:0', 'import/detection_classes:0','import/num_detections:0'])\r\n\r\nconnected_graph = tf.Graph()\r\nwith connected_graph.as_default():\r\n    l1_graph_def = l1_graph.as_graph_def()\r\n    g1name = 'ved'\r\n    rename_frame_name(l1_graph_def, g1name)\r\n    tf.import_graph_def(l1_graph_def, name=g1name)\r\n    trt_graph2 = get_frozen_graph(saved_model2)\r\n    g2name = 'level2'\r\n    rename_frame_name(trt_graph2, g2name)\r\n    [tf_scores, tf_boxes, tf_classes, tf_num_detections] = tf.import_graph_def(trt_graph2,\r\n            return_elements=['import/detection_scores:0', 'import/detection_boxes:0', 'import/detection_classes:0','import/num_detections:0'])\r\n```\r\n\r\nIt throws following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 427, in import_graph_def\r\n    graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot add function 'TRTEngineOp_1_native_segment' because a different function with the same name already exists.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 10, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 431, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Cannot add function 'TRTEngineOp_1_native_segment' because a different function with the same name already exists.\r\n```\r\n\r\nMy specs are:\r\n\r\nTensorflow: 1.14.0\r\nPython: 3.6.8\r\nPlatform: Ubuntu 18.04.2 LTS (GNU/Linux 4.9.140-tegra aarch64)", "comments": ["@anshkumar,\r\n Can you please share `saved_model1` and `saved_model2` so that we can reproduce the issue at our end. Thanks!", "Here is the [link](https://drive.google.com/open?id=1lgZB27bdv7qFMfMwTETv11PCq-BZszcg).", "@anshkumar,\r\nWhen trying to reproduce your error, below error encountered. Can you please help us reproduce the your error. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/2bf30137a4eaca38d4754ca411b74f5e/34353.ipynb#scrollTo=ajJCK4F_HDO8). Thanks!\r\n\r\n`ValueError: Requested return tensor 'import/detection_scores:0' not found in graph def` ", "You need to have [tensorRT](https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html) installed. It's showing in the info that it's not able to find tensorRT version:\r\n\r\n```\r\nINFO:tensorflow:Linked TensorRT version: (0, 0, 0)\r\nINFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\r\nINFO:tensorflow:Running against TensorRT version 0.0.0\r\n...\r\n```", "As mentioned by @aaroey in another related issue, can you try with `TF1.15` and let us know whether the issue persists with the newer version or not. Thanks!\r\n\r\n> In 1.14 TF-TRT was disable by default accidentally due to some release problem, and we're fixing the it in 1.15. In fact 1.15rc1 and 2.0rc1 were out and TF-TRT was enabled in both, please try with that and let me know.", "My platform is NVIDIA Jetson AGX Xavier; tensorflow is provided by nvidia. The list of version provided by them is [here](https://developer.download.nvidia.com/compute/redist/jp/v42/tensorflow-gpu/). (TF-TRT is enabled with the version of tensorflow in the link.) On google colabs, I don't know how to enable TF-TRT. ", "Hi @anshkumar, it currently doesn't support merging two TF-TRT converted graphs into one, the main reason is, both graph will have TRTEngineOps with the same name. Please let me know why this is useful and provide more info about your use case. Thanks.\r\n\r\nAlso @sanjoy ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34353\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34353\">No</a>\n"]}, {"number": 34352, "title": "Update array_ops.py", "body": "Update and format documentation for some methods. ", "comments": ["I will be batching it up with more edits in `array_ops.py` in few more commits."]}, {"number": 34351, "title": "tf-nightly: Cannot import name 'tensorflow' from 'opt_einsum.backends'", "body": "`pip install tf-nightly` --> `pip install tf-nightly-gpu`, or in reverse order, fails in a fresh Anaconda virtual environment w/ error shown below - install/uninstall steps also shown. Any workarounds?\r\n\r\n<hr>\r\n\r\n**Installation**:\r\n\r\n 1. Clone Anaconda base environment (which doesn't have TF or Keras) as `tf3_env`\r\n 2. Delete any files/folders in env w/ name substring \"tensorflow\", \"nightly\", or \"keras\" (just in case)\r\n 3. Run Anaconda Powershell Prompt:\r\n     - `conda activate tf3_env`\r\n     - `conda clean --all` (removes TF, Keras, cudatoolkit, cudnn, others from Anaconda/pkgs)\r\n     - `pip uninstall grpcio`\r\n     - `pip install grpcio` (tf-nightly asks for >=1.24)\r\n     - `pip install tf-nightly-gpu`\r\n 4. Run Spyder, `import tensorflow` --> ERR\r\n 5. Run Anaconda Powershell Prompt:\r\n     - `pip install keras`\r\n     - `pip install tf-nightly`\r\n 6. Run Spyder, `import tensorflow` --> ERR\r\n\r\n<hr>\r\n\r\n**Environment**: \r\n - Win-10 OS, GTX 1070, i7-7700HQ 2.8 GHz CPU\r\n - CUDA 10.1.243, cuDNN 7.6.4, Python 3.7.5, Anaconda 11/2019, Spyder 3.3.6\r\n\r\n<hr>\r\n\r\n**ERR: Full Error Trace** (error is printed repeatedly and can only be stopped by restarting the kernel -- restarting the kernel only stops the error, but doesn't restart the kernel, unless restarted a second time)\r\n\r\n```python\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 538, in post_execute_hook\r\n  _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 184, in filename_and_mtime\r\n  if not hasattr(module, '__file__') or module.__file__ is None:\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n  module = self._load()\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n  module = _importlib.import_module(self.__name__)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n  return _bootstrap._gcd_import(name[level:], package, level)\r\nFile \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\nFile \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\nFile \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\nFile \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nFile \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\nFile \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\nFile \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\nFile \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\nFile \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\nFile \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 46, in <module>\r\n  from ._api.v2 import compat\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n  from . import v1\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n  from . import compat\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n  from . import v1\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 29, in <module>\r\n  from tensorflow._api.v2.compat.v1 import app\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 39, in <module>\r\n  from . import v1\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 32, in <module>\r\n  from . import compat\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\", line 39, in <module>\r\n  from . import v1\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\", line 35, in <module>\r\n  from tensorflow._api.v2.compat.v1 import debugging\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\debugging\\__init__.py\", line 10, in <module>\r\n  from . import experimental\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\debugging\\experimental\\__init__.py\", line 10, in <module>\r\n  from tensorflow.python.debug.lib.dumping_callback import disable_dump_debug_info\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\debug\\lib\\dumping_callback.py\", line 31, in <module>\r\n  from tensorflow.python.debug.lib import debug_events_writer\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\debug\\lib\\debug_events_writer.py\", line 24, in <module>\r\n  from tensorflow.python import _pywrap_debug_events_writer\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n  module = self._load()\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n  module = _importlib.import_module(self.__name__)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n  return _bootstrap._gcd_import(name[level:], package, level)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 83, in <module>\r\n  from tensorflow.python.ops.standard_ops import *\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 48, in <module>\r\n  from tensorflow.python.ops.special_math_ops import *\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\special_math_ops.py\", line 30, in <module>\r\n  import opt_einsum\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\opt_einsum\\__init__.py\", line 9, in <module>\r\n  from .contract import contract, contract_path, contract_expression\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\opt_einsum\\contract.py\", line 10, in <module>\r\n  from . import backends\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\opt_einsum\\backends\\__init__.py\", line 7, in <module>\r\n  from .dispatch import (get_func, has_einsum, has_tensordot, build_expression, evaluate_constants, has_backend)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\opt_einsum\\backends\\dispatch.py\", line 13, in <module>\r\n  from . import tensorflow as _tensorflow\r\n\r\nImportError: cannot import name 'tensorflow' from 'opt_einsum.backends' \r\n(D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\opt_einsum\\backends\\__init__.py)\r\n```\r\n ", "comments": ["Are you able to import TF in the anaconda prompt after installation?", "@yacoder No, exact same error", "You may try installing TF in virtual environment using ```conda create```\r\nSee [Create virtual environments for python with conda](https://uoa-eresearch.github.io/eresearch-cookbook/recipe/2014/11/20/conda/)", "@ymodak It's what I did, as shown under \"Installation\" - my base env is clean, so creating a new one would be same as cloning base env", "Same error for `tf-nightly 2.2.0`; any resolution?", "So, `site-packages\\opt_einsum\\backends\\tensorflow.py` was missing - adding it from the `tf2` virtual environment made the error go away. Unsure if things are stable now, will close issue if they are.", "Severe performance degradation relative to 2.1-stable: one `LSTM(500, return_sequences=True)` layer runs **15.6x** slower.", "Nevermind, didn't know `tf-nightly-gpu` is still needed for GPU.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34351\">No</a>\n", "Simply try uninstalling and reinstalling 'opt-einsum' package from your env. Worked for me."]}, {"number": 34350, "title": "ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.", "body": "when I convert pre-trained mobilenet model to tflite, there is a error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/project/pyenv/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py\", line 400, in convert\r\n    raise ValueError(\"This converter can only convert a single \"\r\nValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.\r\n```\r\n\r\nmy code is\r\n\r\n```python \r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.mobilenet import MobileNet\r\nmodel = MobileNet(weights='imagenet')\r\nsaved_model_path = \"./saved_models/{}\".format(int(time.time()))\r\ntf.keras.experimental.export_saved_model(model, saved_model_path)\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\ntflite_model = converter.convert()\r\n```\r\n\r\nmy os is \r\nUbuntu 16.04.6 LTS\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> \r\n> Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n> \r\n> We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nI use both Ubuntu 16.04.6 LTS x_86 and macOS Mojave x_64, there is same error.\r\nand I use python virtualenv and pip command to install tensorflow2.0\r\n", "Can you use `tf.keras.models.save_model` instead. `tf.keras.experimental.export_saved_model` has been [deprecated](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model). I was able to get the following code working on `tf-nightly` (version: `2.1.0.dev20191118`).\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.mobilenet import MobileNet\r\nmodel = MobileNet(weights='imagenet')\r\nsaved_model_path = \"/tmp/saved_models/\"\r\ntf.keras.models.save_model(model, saved_model_path)\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\r\ntflite_model = converter.convert()\r\n```", "> Can you use `tf.keras.models.save_model` instead. `tf.keras.experimental.export_saved_model` has been [deprecated](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model). I was able to get the following code working on `tf-nightly` (version: `2.1.0.dev20191118`).\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> from tensorflow.keras.applications.mobilenet import MobileNet\r\n> model = MobileNet(weights='imagenet')\r\n> saved_model_path = \"/tmp/saved_models/\"\r\n> tf.keras.models.save_model(model, saved_model_path)\r\n> converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\r\n> tflite_model = converter.convert()\r\n> ```\r\n\r\nit works, thanks", "Hi, I am getting the same error : \r\n **File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\", line 421\r\nin convert\r\nraise ValueError(\"This converter can only convert a single \"\r\nValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.**\r\n\r\nI am trying to convert SSD_ResNet50_fpn architecture with tf-nighty version. \r\n\r\nThanks in advance. ", "I'm having the same issue as @skulhare ", "the same issue when convert deeplab mobilenetv2 version.", "having the same issue when trying to convert efficientnet_edge", "The same problem when trying to convert saved **DNNClassifier estimator** model.\r\n\r\nTensorFlow version:  2.0.0\r\n```python\r\ndef construct_feature_columns():\r\n    return set([tf.feature_column.numeric_column('pixels', shape=NUMBER_OF_PIXELS)])\r\n...\r\n\r\nmy_optimizer = partial(tf.optimizers.Adam, learning_rate=learning_rate, clipnorm=5.0)\r\nclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=construct_feature_columns(),\r\n    n_classes=NUMBER_OF_CLASSES,\r\n    hidden_units=hidden_units,\r\n    optimizer=my_optimizer,\r\n    config=tf.estimator.RunConfig(keep_checkpoint_max=1),\r\n    model_dir=MODEL_DIR\r\n)\r\n...\r\n\r\nfor period in range(0, periods):\r\n    classifier.train(\r\n        input_fn=training_input_fn,\r\n        steps=steps_per_period\r\n    )\r\n...\r\n\r\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\r\n            tf.feature_column.make_parse_example_spec(construct_feature_columns()))\r\nsaved_model_path = classifier.export_saved_model(MAIN_DIR + 'saved_models/', serving_input_fn)\r\n...\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(MAIN_DIR + 'saved_models/1579340040')\r\ntflite_model = converter.convert()\r\n```\r\n\r\n```\r\nWARNING:tensorflow:From /home/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"/home/venv/tf_lite_converter.py\", line 5, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/venv/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 400, in convert\r\n    raise ValueError(\"This converter can only convert a single \"\r\n**ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.**\r\n```\r\n\r\n@GodsDusk could you please reopen the issue?\r\n@gargn would you please explain what exactly \"This converter can only convert a single ConcreteFunction.\" means? Why it happens and what can I change to avoid it? Will it be the same if I use a linear model? Sorry, Tensorflow is new to me.", "There is documentation on concrete functions [here](https://www.tensorflow.org/guide/concrete_function). You will need to use `TFLiteConverter.from_concrete_functions` directly. There is an example of how to do that [here](https://github.com/tensorflow/tensorflow/issues/35736#issuecomment-573814435).", "@gargn thank you for your answer!\r\nI've read concrete_function documentation and tried the code from your comment:\r\n```python\r\n# Load the SavedModel.\r\nsaved_model_obj = tf.saved_model.load(export_dir=saved_model_dir)\r\n\r\n# Load the specific concrete function from the SavedModel.\r\nconcrete_func = saved_model_obj.signatures['serving_default']\r\n\r\n# Set the shape of the input in the concrete function.\r\nconcrete_func.inputs[0].set_shape([])\r\n\r\n# Convert the model to a TFLite model.\r\nconverter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\nconverter.optimizations =  [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n```\r\nIt returns:\r\n```\r\nValueError: Shapes must be equal rank, but are 1 and 0\r\n```\r\nIf I try with `concrete_func.inputs[0].set_shape([1024])` for example it says:\r\n```\r\n2020-01-22 00:16:54.071217: F tensorflow/lite/toco/import_tensorflow.cc:2690] Check failed: status.ok() Input_content string_val doesn't have the right dimensions for this string tensor\r\n```\r\nAs far as I understand you save only one concrete_function with the following code:\r\n```python\r\n# Generate concrete function.\r\nroot = Pow(3)\r\nconcrete_func = root.__call__.get_concrete_function(tf.constant(2.))\r\n# Save the generated concrete function as a SavedModel.\r\nsaved_model_dir = '/tmp/pow'\r\ntf.saved_model.save(root, saved_model_dir, signatures=concrete_func)\r\n```\r\nBut how to get a concrete_function, to save, from a DNNClasiffier estimator?\r\n```python\r\ndef construct_feature_columns():\r\nreturn set([tf.feature_column.numeric_column('pixels', shape=NUMBER_OF_PIXELS)])\r\n\r\nclassifier = tf.estimator.DNNClassifier(...)\r\n\r\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\r\ntf.feature_column.make_parse_example_spec(construct_feature_columns()))\r\n\r\nsaved_model_path = classifier.export_saved_model(MAIN_DIR + 'saved_models/', serving_input_fn)\r\n```\r\n", "For the first code snippet, try removing the `concrete_func.inputs[0].set_shape([])` line. That was only necessary because the user in the previous example wanted to set the shape of their input. For your conversion, let's assume it is correct. If that still leads to an error, then can you add `converter.experimental_new_converter = True` since that converter supports more use cases.\r\n\r\nFor the last code snippet, try printing out `saved_model_obj.signatures.keys()` (the `saved_model_obj` is from the first snippet). Each of the keys is a signature that maps to a concrete function. Usually you want to use the one with `serve` in it.", "If I remove `concrete_func.inputs[0].set_shape([])` the error is:\r\n```\r\n2020-01-22 10:21:41.306469: F tensorflow/lite/toco/import_tensorflow.cc:2690] Check failed: status.ok() Input_content string_val doesn't have the right dimensions for this string tensor\r\n\t (while processing node 'head/AsString')\r\nFatal Python error: Aborted\r\n```\r\nWhen add `converter.experimental_new_converter = True` the error is:\r\n```\r\nerror: failed while converting: 'main'\r\nOps that need custom implementation (enabled via setting the -emit-custom-ops flag): ParseExampleV2\r\ntensorflow_core/python/saved_model/load.py:559:7: error: 'tf.ParseExampleV2' op is neither a custom op nor a flex op\r\n      root = load_v1_in_v2.load(export_dir, tags)\r\n```\r\nHere are the signatures (I need \"predict\" I guess?):\r\n```python\r\nprint(saved_model_obj.signatures.keys())\r\nKeysView(_SignatureMap({\r\n'serving_default': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f2ea00c6a20>,\r\n'predict': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f2ea00ebda0>,\r\n'classification': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f2ea00989b0>,\r\n'regression': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f2ea003fd30>}))\r\n```\r\n\r\nMaybe the model is not correctly saved?\r\nHere is how I create DNNClassifier estimator and save the model:\r\n```python\r\nclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=[tf.feature_column.numeric_column('pixels', shape=1024)],\r\n    n_classes=2,\r\n    hidden_units=[1024, 1024, 1024],\r\n    optimizer=partial(tf.optimizers.Adam, learning_rate=0.000001, clipnorm=5.0),\r\n    config=tf.estimator.RunConfig(keep_checkpoint_max=1),\r\n    model_dir=MODEL_DIR\r\n\r\n# Training\r\nfor period in range(0, periods):\r\n    classifier.train(\r\n        input_fn=create_training_input_fn(training_examples,\r\n                                          training_targets,\r\n                                          batch_size),\r\n        steps=steps_per_period\r\n    )\r\n\r\n    # Take a break and compute probabilities.\r\n    training_predictions = list(classifier.predict(\r\n        input_fn=create_predict_input_fn(training_examples,\r\n                                         training_targets,\r\n                                         batch_size)))\r\n    ...\r\n\r\n\r\n# Saving the model\r\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\r\n    tf.feature_column.make_parse_example_spec(\r\n        [tf.feature_column.numeric_column('pixels', shape=1024)]))\r\n\r\nclassifier.export_saved_model(MAIN_DIR + 'saved_models/', serving_input_fn)\r\n\r\n\r\ndef create_training_input_fn(features, labels, batch_size):\r\n    def _input_fn(num_epochs=None, shuffle=True):\r\n        rand = np.random.RandomState(28)\r\n        idx = rand.permutation(features.index)\r\n        raw_features = {\"pixels\": features.reindex(idx)}\r\n        raw_targets = np.array(labels[idx])\r\n\r\n        ds = Dataset.from_tensor_slices((raw_features, raw_targets))\r\n        ds = ds.batch(batch_size).repeat(num_epochs)\r\n\r\n        if shuffle:\r\n            ds = ds.shuffle(buffer_size=NUMBER_OF_IMAGES, seed=28)\r\n\r\n        # Return the next batch of data.\r\n        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\r\n        return feature_batch, label_batch\r\n\r\n    return _input_fn\r\n\r\n\r\ndef create_predict_input_fn(features, labels, batch_size):\r\n    def _input_fn():\r\n        raw_features = {\"pixels\": features.values}\r\n        raw_targets = np.array(labels)\r\n\r\n        ds = Dataset.from_tensor_slices((raw_features, raw_targets))\r\n        ds = ds.batch(batch_size)\r\n\r\n        # Return the next batch of data.\r\n        feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\r\n        return feature_batch, label_batch\r\n\r\n    return _input_fn\r\n```", "First off, I recommend using `experimental_new_converter` given that the older converter seems to be resulting in additional errors. With the new converter, it becomes clear that your example uses an unsupported operation - `tf.ParseExampleV2`.\r\n\r\nGiven that `tf.ParseExampleV2` is not supported as a built-in op in TFLite your options are to:\r\n1. Remove `tf.ParseExampleV2` from your graph.\r\n2. Implement `tf.ParseExampleV2` as a custom operation.\r\n3. [Recommended] Use TF Select ops. If you download tomorrow's `tf-nightly` (released on 01-28 PST), I have added `ParseExampleV2` to the [TF Select ops](https://www.tensorflow.org/lite/guide/ops_select).\r\n\r\nAssuming you choose option 3 (which will the easiest but will lead to a binary size increase), you should use the following flags during conversion:\r\n```\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\n\r\nIf the suggestion does not fix your issue, can you provide a fully reproducible example with the imports and the conversion code. The example you provided had some errors, so I was not able to run it in order to debug the code.", "Thank you @gargn!\r\nI've added the 'supported_ops' and conversion passed without errors. Here is the final code.\r\n```Python\r\n        # TensorFlow version:  2.2.0-dev20200128\r\n        # Load the SavedModel.\r\n        saved_model_obj = tf.saved_model.load(export_dir=saved_model_dir)\r\n        print(saved_model_obj.signatures.keys())\r\n\r\n        # Load the specific concrete function from the SavedModel.\r\n        concrete_func = saved_model_obj.signatures['serving_default']\r\n\r\n        # Set the shape of the input in the concrete function.\r\n        # concrete_func.inputs[0].set_shape([])\r\n\r\n        # Convert the model to a TFLite model.\r\n        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n        converter.experimental_new_converter = True\r\n        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n        tflite_model = converter.convert()\r\n\r\n        open(\"converted.tflite\", \"wb\").write(tflite_model)\r\n```\r\nNow there is a problem when try to infer: **\"Node number 0 (FlexParseExampleV2) failed to prepare\"**\r\n```Python\r\n    dataframe = pd.read_csv('file:////training_data_sample.csv', sep=\",\", header=None)\r\n    features = dataframe.loc[0, 1:]\r\n    features = features / 255\r\n\r\n    # Load TFLite model and allocate tensors.\r\n    interpreter = tf.lite.Interpreter(model_path=\"/converted.tflite\")\r\n    interpreter.allocate_tensors()\r\n\r\n    # Get input and output tensors.\r\n    input_details = interpreter.get_input_details()\r\n    output_details = interpreter.get_output_details()\r\n\r\n    # Test model.\r\n    input_shape = input_details[0]['shape']\r\n    input_data = np.array(features, dtype=np.float32)\r\n    input_data = np.reshape(input_data, input_shape)\r\n    interpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\n    interpreter.invoke()\r\n\r\n    output_data = interpreter.get_tensor(output_details[0]['index'])\r\n    results = np.squeeze(output_data)\r\n    print(results)\r\n```\r\n```\r\nTensorFlow version:  2.2.0-dev20200128\r\nTraceback (most recent call last):\r\n  File \"/home/PycharmProjects/ML/test_tflite_file.py\", line 15, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"/home/PycharmProjects/ML/venv/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 242, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/home/PycharmProjects/ML/venv/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 110, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 0 (FlexParseExampleV2) failed to prepare.\r\n\r\nProcess finished with exit code 1\r\n```\r\nI should apply \"Flex delegate\" somehow, I guess?", "Unfortunately, models converted with TensorFlow select ops cannot be run in Python interpreters. There is more information on running your model available [here](https://www.tensorflow.org/lite/guide/ops_select#running_the_model).", "Thank you @gargn! You helped a lot!\r\nMaybe we can close the issue now?\r\nMy fight to run the model on an Android device continue! \\m/", "@gargn @trayanmomkov \r\nI am getting the same error and I tried the code snippet provided above, however my KeysView(_SignatureMap({})) is empty and I get `KeyError: 'serving_default\u00b8`.\r\n\r\nHow do I get around this ? \r\n\r\nI am trying to quantize my .pb file obtained from my checkpoints using this script \r\nhttps://blog.csdn.net/zmlovelx/article/details/100511406", "> @gargn @trayanmomkov\r\n> I am getting the same error and I tried the code snippet provided above, however my KeysView(_SignatureMap({})) is empty and I get `KeyError: 'serving_default\u00b8`.\r\n> \r\n> How do I get around this ?\r\n> \r\n> I am trying to quantize my .pb file obtained from my checkpoints using this script\r\n> https://blog.csdn.net/zmlovelx/article/details/100511406\r\n\r\nme too"]}, {"number": 34349, "title": "Serialization support for RaggedTensor", "body": "**System information**\r\n- TensorFlow version (you are using):2.0.0\r\n- Are you willing to contribute it (Yes/No):No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, there is no support for serializing RaggedTensors similiraly to tf.io.serialize_tensor\r\n\r\n**Will this change the current api? How?**\r\nThis shouldn't affect any other functionality\r\n\r\n**Who will benefit with this feature?**\r\nUsers of ragged tensors wishing to use TFrecords\r\n", "comments": ["Here's some simple code to serialize and deserialize ragged tensors (or any other composite tensors, like SparseTensor), by breaking them into component tensors and serializing those.\r\n\r\n```\r\ndef serialize_composite(rt):\r\n  components = tf.nest.flatten(rt, expand_composites=True)\r\n  return tf.stack([tf.io.serialize_tensor(t) for t in components])\r\n\r\ndef deserialize_composite(serialized, type_spec):\r\n  component_specs = tf.nest.flatten(type_spec, expand_composites=True)\r\n  components = [tf.io.parse_tensor(serialized[i], spec.dtype) \r\n                   for i, spec in enumerate(component_specs)]\r\n  return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\r\n```\r\n\r\nExample use:\r\n\r\n```\r\n>>> rt = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\r\n>>> serialized = serialize_composite(rt)\r\n>>> print(serialized)\r\ntf.Tensor(\r\n[b'\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x06\"...etc])\r\n>>> rt_spec = tf.RaggedTensorSpec(dtype=tf.int32, ragged_rank=1)\r\n>>> deserialized = deserialize_composite(serialized, rt_spec)\r\n>>> print(deserialized)\r\n<tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]>\r\n```\r\n\r\nA couple notes:\r\n\r\n* The tensor returned by `serialize_composite` will be a vector with shape `[num_components]`.  For a RaggedTensor with `ragged_rank=1`, `num_components=2`.\r\n* You need to specify the TypeSpec when deserializing.  For RaggedTensorSpec, you'll need to at least provide the dtype of values and the ragged_rank (i.e., the number of ragged dimensions).\r\n* If you want to use RaggedTensors with TFRecords, you may also consider using [tf.io.RaggedFeature](https://www.tensorflow.org/api_docs/python/tf/io/RaggedFeature) with `tf.io.parse_example`.", "Closing this issue; but please re-open if you feel it's not addressed.", "@edloper \r\nHi! I am currently writing ragged tensors to and from TFRecords using slight modifications to your functions:\r\n\r\n```python\r\ndef serialize_composite(rt):\r\n    components = tf.nest.flatten(rt, expand_composites=True)\r\n    return tf.io.serialize_tensor(\r\n        tf.stack([tf.io.serialize_tensor(t) for t in components])\r\n    ).numpy()\r\n\r\ndef deserialize_composite(serialized, type_spec):\r\n    serialized = tf.io.parse_tensor(serialized, tf.string)\r\n    component_specs = tf.nest.flatten(type_spec, expand_composites=True)\r\n    components = [\r\n        tf.io.parse_tensor(serialized[i], spec.dtype)\r\n        for i, spec in enumerate(component_specs)\r\n    ]\r\n    return tf.nest.pack_sequence_as(type_spec, components, expand_composites=True)\r\n```\r\n\r\nBut with this method, I am having to write the ragged tensors as bytes and read them as `FixedLenFeature` of type `tf.string`. Is there anyway I can directly read them from the TFRecords as `RaggedTensor`?"]}, {"number": 34348, "title": "save method shows buggy/confusing behaviour", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NN\r\n- TensorFlow installed from (source or binary): NN\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): NN\r\n- GCC/Compiler version (if compiling from source): NN\r\n- CUDA/cuDNN version: NN\r\n- GPU model and memory: NN\r\n\r\n**Describe the current behavior**\r\ntf.keras.Model.save shows confusing behavior with the save_format argument.\r\nSee [gist](https://colab.research.google.com/gist/nikochiko/7a624ae90563b831d5229eb0ee5b0d41/tf_model_save_buggy.ipynb).\r\nEven when save_format is set as  'tf', the model is saved as 'h5' if the filepath ends in suffix '.h5'\r\nAlso, it defaults random string arguments to tf format. \r\n\r\n**Describe the expected behavior**\r\nThe value of the save_format argument should be the format of the saved file irrespective of the filepath. \r\nOr else, there should be a boolean argument like 'save_as_h5' instead.\r\n\r\n**Code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/nikochiko/7a624ae90563b831d5229eb0ee5b0d41/tf_model_save_buggy.ipynb#scrollTo=1H73RxH5sTgl\r\n\r\n**Other info / logs**\r\n[Source code](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/network.py#L923-L975)\r\n[Outdated documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)\r\nUpdated docs for current behavior in [PR](https://github.com/tensorflow/tensorflow/pull/34347/files)\r\n\r\n**More details**\r\nmodel.save_weights handles it better: see [gist](https://colab.research.google.com/gist/nikochiko/ff693562546dbda5d5868ec7e7d75bad/tf_save_weights.ipynb)", "comments": ["Could reproduce the issue with TF Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/565a2bee7543a888a9677813b9e0447a/tf_model_save_buggy.ipynb).", "@rmothukuru @k-w-w I can make a fix for this in accordance with the `save_weights` method. Shall I start working?", "That would be great! Reviewing the PR now", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34348\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34348\">No</a>\n"]}, {"number": 34347, "title": "Updated `save` docstring", "body": "Updated docstring for `save` function according to https://github.com/tensorflow/tensorflow/issues/33856 . Also made some corrections.", "comments": ["Please open PR against `master` branch. We don't update release branches (`r...`) after the final release of the corresponding TF version (i.e., we won't update `r2.1` after TF2.1 is released).\r\n\r\nThe only time release branches are updated is when we make a patch release to fix a security vulnerability. As that requires expediency, we only accept minimal changes even then."]}, {"number": 34345, "title": "TFLite allocate tensors fails: (CONCATENATION) failed to prepare after input shape resize", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **OSX**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **binary** \r\n- TensorFlow version (use command below):  **2.1.0-dev20191113**\r\n- Python version: **3.7.4**\r\n\r\n**Describe the current behavior**\r\n\r\nI create a fully convolutional simple model using tf.keras API.\r\nI convert the model to TFlite.\r\nI resize the shape of the input tensor, but when I ask the interpreter to allocate the tensors, I get this error:\r\n\r\n`RuntimeError: tensorflow/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (24 != 52)Node number 12 (CONCATENATION) failed to prepare.\r\n`\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect the interpreter to be able to resize all the tensors.\r\nBelow you can find the simple model I've built to reproduce this issue.\r\nWhat I've notice is that without the `Concatenate` op the allocation works correctly.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate\r\nfrom tensorflow.keras import Model, layers\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\n\r\n# Encoder\r\nencoder_input = keras.Input(shape=(28, 28, 1), name='img')\r\nconv1 = layers.Conv2D(16, 3, activation='relu')(encoder_input)\r\nconv2 = layers.Conv2D(32, 3, activation='relu')(conv1)\r\nmax1 = layers.MaxPooling2D(3)(conv2)\r\nconv3 = layers.Conv2D(32, 3, activation='relu')(max1)\r\nconv4 = layers.Conv2D(16, 3, activation='relu')(conv3)\r\nencoder_output = layers.GlobalMaxPooling2D()(conv4)\r\nencoder = keras.Model(encoder_input, encoder_output, name='encoder')\r\n\r\n# Decoder\r\nresh = layers.Reshape((4, 4, 1))(encoder_output)\r\nupconv1 = layers.Conv2DTranspose(16, 3, activation='relu')(resh)\r\nupconv2 = layers.Conv2DTranspose(32, 3, activation='relu')(upconv1)\r\nupsample = layers.UpSampling2D(3)(upconv2)\r\nconc = layers.Concatenate()([conv2,upsample])\r\nconv5 = layers.Conv2DTranspose(16, 3, activation='relu')(conc)\r\ndecoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(conv5)\r\n\r\n# autoencoder\r\nautoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')\r\n\r\n# conversion\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)\r\ntflite_model = converter.convert()\r\nopen(\"model.tflite\", \"wb\").write(tflite_model)\r\n\r\n# inference\r\ninterpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\ninput_details = interpreter.get_input_details()\r\ninterpreter.resize_tensor_input(input_details[0][\"index\"],[1,56,56,1])\r\ninterpreter.allocate_tensors()\r\n```\r\n", "comments": ["WIthout resizing the input does your model convert fine?", "@liyunlu0618 Yes. Without resizing it works fine.\r\nI think I've managed to find the issue.\r\nThe problems is not the concatenation, but the UpSampling2D layer.\r\n\r\nWhen the graph is converted, the shape of the input tensor that is used by the UpSampling2D layer to resize the image is converted to a constant and hardcoded in the UpSampling2D layer.\r\nSo, when the Input of the graph is resized, the transformation it is not propagated to the UpSampling2D layer since the OPs used to calculate the new size have been folded.\r\nSo, since the UpSampling2D layer is not resized, the Concatenation produces an error\r\n\r\nThe solution would be to prevent the converter to convert to constant the part of the graph that is used by the UpSampling2D layer to calculate the new size.\r\n\r\nAs a workaround, I've coded a custom UpSampling2D layer that takes as a resize shape the value of another Input tensor instead of calculating it using the input image.\r\n", "@Angtrim , can you explain a bit about the workaround\r\nDid you use,  upsample = tflite_interpreter.get_tensor_details() and then maually change the shapes according to the inputs, using resize_tensor_input ? ", "@harsh306 To apply my workaround, these are the steps you have to follow:\r\n1) Edit your model input: you should add a second input tensor (a proper one, like if it was another input image), made just of 2 floats, so that during training and inference you can pass the size of your image. \r\n2) Edit the resize nodes: now that you have a second input, you should connect it to the resize node passing it as the \"size\" parameter (if you look [here](https://www.tensorflow.org/api_docs/python/tf/image/resize), the \"size\" param is a tensor).\r\nSince you probably have more than one upsampling layers, every resize node should take a multiplied version of the \"size\" tensor.\r\n3) During training you add to your data the size of the image (probably constant in all the dataset) and pass it to the network.\r\n4) After training, you can convert it to tflite. Thanks to this workaround, the converter can't hardcode the size of the resize nodes, since it's not anymore calculated on the size of the previous node but it is expected to arrive as data.\r\n5) During tflite inference, you use `resize_tensor_input` on the image input tensor, and in the size tensore you have added you pass the image size.", "@Angtrim, Hi, I am trying to follow the same approach and able to infer the pb file as well. Because to infer pb file we specify size in feeddict.. But, while converting to tflite it doesnt know the value of size. Hence, it cant make resizebilinear layer. And I am not able to convert to tflite successfully. How did you tackle this issue? Can u share code snippet if possible for tflite conversion?\r\nThanks.", "Hi @Angtrim , was able to replicate in 2.1 and resolve in 2.6 without any error . Providing [Gist ](https://colab.research.google.com/gist/mohantym/220523097c97de4508281fa9931adbc9/github_34345.ipynb)for reference.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34345\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34345\">No</a>\n"]}, {"number": 34344, "title": "tf2.0: tf.image.resize_with_pad fails with \u201cusing a `tf.Tensor` as a Python `bool\u201d with tf.keras.Input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA (CPU)\r\n- GPU model and memory: NA (CPU)\r\n\r\n**Describe the current behavior**\r\nWith tensorflow 2.0, `resize_with_pad` does not seem to work when `tf.keras.Input` is given as an input, although `resize` works nicely.\r\n\r\n**Describe the expected behavior**\r\nThere should not be an error.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow as tf\r\n\r\n# with tensorflow constant\r\nimg_arr = tf.zeros([1,100,100,3])\r\ntf.image.resize(img_arr, [224, 224]) # works\r\ntf.image.resize_with_pad(img_arr, 224, 224) # works\r\n\r\n# with keras input\r\nimg_arr = tf.keras.Input(shape = (100,100,3))\r\ntf.image.resize(img_arr, [224, 224]) # works\r\ntf.image.resize_with_pad(img_arr, 224, 224) # doesn't work\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n---------------------------------------------------------------------------\r\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n<ipython-input-29-aee2cbd13944> in <module>\r\n      9 img_arr = tf.keras.Input(shape = (100,100,3))\r\n     10 tf.image.resize(img_arr, [224, 224]) # works\r\n---> 11 tf.image.resize_with_pad(img_arr, 224, 224) # doesn't work\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in resize_image_with_pad_v2(image, target_height, target_width, method, antialias)\r\n   1472 \r\n   1473   return _resize_image_with_pad_common(image, target_height, target_width,\r\n-> 1474                                        _resize_fn)\r\n   1475 \r\n   1476 \r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _resize_image_with_pad_common(image, target_height, target_width, resize_fn)\r\n   1337       raise ValueError('\\'image\\' must have either 3 or 4 dimensions.')\r\n   1338 \r\n-> 1339     assert_ops = _CheckAtLeast3DImage(image, require_static=False)\r\n   1340     assert_ops += _assert(target_width > 0, ValueError,\r\n   1341                           'target_width must be > 0.')\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _CheckAtLeast3DImage(image, require_static)\r\n    226         check_ops.assert_positive(\r\n    227             array_ops.shape(image),\r\n--> 228             [\"all dims of 'image.shape' \"\r\n    229              'must be > 0.']),\r\n    230         check_ops.assert_greater_equal(\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_positive(x, data, summarize, message, name)\r\n    266           'x (%s) = ' % name, x]\r\n    267     zero = ops.convert_to_tensor(0, dtype=x.dtype)\r\n--> 268     return assert_less(zero, x, data=data, summarize=summarize)\r\n    269 \r\n    270 \r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/check_ops.py in assert_less(x, y, data, summarize, message, name)\r\n    865       ]\r\n    866     condition = math_ops.reduce_all(math_ops.less(x, y))\r\n--> 867     return control_flow_ops.Assert(condition, data, summarize=summarize)\r\n    868 \r\n    869 \r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)\r\n    196   \"\"\"\r\n    197   def wrapped(*args, **kwargs):\r\n--> 198     return _add_should_use_warning(fn(*args, **kwargs))\r\n    199   return tf_decorator.make_decorator(\r\n    200       fn, wrapped, 'should_use_result',\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)\r\n    147   \"\"\"\r\n    148   if context.executing_eagerly():\r\n--> 149     if not condition:\r\n    150       xs = ops.convert_n_to_tensor(data)\r\n    151       data_str = [_summarize_eager(x, summarize) for x in xs]\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __bool__(self)\r\n    763       `TypeError`.\r\n    764     \"\"\"\r\n--> 765     self._disallow_bool_casting()\r\n    766 \r\n    767   def __nonzero__(self):\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_bool_casting(self)\r\n    532     else:\r\n    533       # Default: V1-style Graph execution.\r\n--> 534       self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n    535 \r\n    536   def _disallow_iteration(self):\r\n\r\n/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _disallow_in_graph_mode(self, task)\r\n    521     raise errors.OperatorNotAllowedInGraphError(\r\n    522         \"{} is not allowed in Graph execution. Use Eager execution or decorate\"\r\n--> 523         \" this function with @tf.function.\".format(task))\r\n    524 \r\n    525   def _disallow_bool_casting(self):\r\n\r\nOperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n```", "comments": ["@kojino ,\r\nHi,looks like the issue is fixed in latest `tf-nightly 2.1.0.dev20191117 `version, Can you try running the code in the same ? kindly find the gist of [colab](https://colab.sandbox.google.com/gist/oanush/6e6acdf102edddaf7c4ed2292b0e43b0/34344.ipynb) for your reference.", "Seems to work, thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34344\">No</a>\n"]}, {"number": 34343, "title": "Modified documentation for SparseCategoricalCrossentropy", "body": "The documentation example for SparseCategoricalCrossentropy is mathematically inconsistent with a parallel example given for CategoricalCrossentropy and also is confusing.  In particular the second element in the original SparseCategoricalCrossentropy example function call has component given by [.5, .89, .6] which is not normalized to be a probability (i.e. doesn't sum to 1.0).  I modified it to be [.05, .89, .06] which does sum to 1.0 and also recomputed the loss to be 0.09458992, preserving all the precision from the function call.  I hope this helps clarify things for users.  Thanks.", "comments": ["@td2014 Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Closing this PR as the docs have been updated."]}, {"number": 34342, "title": "Add `abs` builtin support for dataset in autograph", "body": "This PR add `abs` builtin support for dataset in autograph.\r\nBefore this PR, some of the builtin ops in autograph already\r\nsupport dataset (e.g., any, all, zip, filter, map).\r\n\r\nSince `abs` could be considered as a straightforward\r\n`map(abs)`, it might make sense to add `abs`\r\nas the supported list of ops as well.\r\n\r\n\r\nNote as dataset could consist of a structure, this PR adds\r\nthe structured dataset support for abs with autograph,\r\nby using nest.map_structure if applicable.\r\n\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 34341, "title": "Adam weight decay optimizer for TF 2.0", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am looking to migrate some optimization code I forked from BERT to TF 2.0. The optimization involves the Adam weight decay optimizer and is implemented in TF 1.15 according to\r\nhttps://github.com/artitw/text2class/blob/master/text2class/optimization.py\r\n\r\n**Will this change the current api? How?**\r\nFor the TF 2.0 API, we can specify the Adam optimizer like below. However, it is unclear how the weight decay component can be implemented as it requires keeping track of the global step. \r\n```\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(\r\n    learning_rate=2e-5,\r\n    beta_1=0.9,\r\n    beta_2=0.999,\r\n    epsilon=1e-6,),\r\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\r\n```\r\n\r\n**Who will benefit with this feature?**\r\nResearchers and engineers working with BERT and BERT-based models will benefit. The original BERT repo has almost 20k stars, but it has yet to be migrated to TF 2.0.\r\n\r\n**Any Other info.**\r\nIf the capability to achieve what I describe above already exists, please let me know!\r\n", "comments": ["Hi @artitw,\r\nsorry, I just saw your post now. AdamW has been migrated to [tf-addons](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/weight_decay_optimizers.py).\r\nRegarding the global step: I'm not too familiar with the keras interface but the weight decay extension is just a wrapper around the vanilla Adam. The weight decay part doesn't need the global step. If you're using a learning rate schedule that depends on the global step, you should apply the same schedule to the weight decay.\r\n\r\nCheers,\r\nPhil", "Hi Phil,\r\n\r\nThanks for the update and tips! I'll close this now.\r\n\r\nBest,\r\nArt"]}, {"number": 34340, "title": "Image preprocessing for transfer learning confusing", "body": "I'm really confused about what preprocessing to apply on image data when working with pre-trained models for transfer learning. Of course, this is very specific for each model, but I thought Keras brought some disambiguation by bringing the _**preprocess_input**_ function. By using it, users should normally not worry about how to transform an image before pushing it into the pre-trained model.\r\n\r\nI recently tried to use one of such model provided in Tensorflow 2.Keras. Even if this function exists, the related documentation is, let's say, minimal:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input\r\n\r\nBut what is very disturbing is that this function is not used at all in the provided tutorials. For example, this one (https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) pre-processes images by dividing raw pixels by 255.\r\n\r\n> image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\r\n\r\nIn this other tutorial (https://www.tensorflow.org/tutorials/images/transfer_learning), pre-processing is done like this: \r\n\r\n> image = (image/127.5) - 1\r\n\r\nHowever, both tutorial are supposed to use a **mobilenet_v2** model pre-trained on _ImageNet_\r\n\r\nThis makes **3 different ways to process an image**, without any helping documentation to shed some light on what appears to me like \"black magic\". Any help would be welcome, along with an appropriate documentation of course.\r\n", "comments": ["HI, interested in solving your issue.", "check if its fine", "@jsgonsette,\r\nThank you for the detailed explanation. This issue seems to be related to reusing Pre-Trained Models. So, it is better raised in [TF Hub Repository](https://github.com/tensorflow/hub/issues), as the issues in that Repo will be looked into by the experts in Pre-Trained Models. Thanks!", "Ok, I'm doing that.", "@jsgonsette,\r\nClosing the issue as it has been raised in TF Hub Repo. Thanks! "]}, {"number": 34339, "title": "TensorRT not working due to eager execution", "body": "I'm trying to convert my saved model to tensorRT but I'm failing due to following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 911, in __init__\r\n    assert context.executing_eagerly()\r\nAssertionError\r\n```\r\n\r\nHere, is my code\r\n```\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert\r\n\r\nconversion_params = trt_convert.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt_convert.TrtPrecisionMode.FP16, max_batch_size=1, max_workspace_size_bytes=8000000000)\r\n\r\ntrt_converter = trt_convert.TrtGraphConverterV2(input_saved_model_dir='/home/xavier2/apple_trt_l1/nonRT',  conversion_params=conversion_params)\r\n```\r\n\r\nHere are my specs:\r\nTensorflow version: 1.14.0\r\nPlatform: NVIDIA Jetson AGX Xavier developer kit\r\nPython: 3.6.8\r\n", "comments": ["@anshkumar ,\r\nHi, looks like the issue is fixed in TF version-2.0. Can you try running the code in 2.0? kindly find the gist of [colab](https://colab.sandbox.google.com/gist/oanush/76966638dba18670472226ba0dac6607/34339.ipynb) for your reference. Thanks!", "My platform is NVIDIA Jetson AGX Xavier; tensorflow is provided by nvidia. The list of version provided by them is [here](https://developer.download.nvidia.com/compute/redist/jp/v42/tensorflow-gpu/). NVIDIA does not provide Tensorflow-2.0 for Jetson.", "TrtGraphConverterV2 only converts TF 2.0 SavedModels as shown [here](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/compiler/tensorrt/trt_convert.py#L851)\r\n\r\nAre you using Tensorflow 2.0 Saved model or Tensorflow 1.14 saved model? If you are using a saved model that is other than 2.0 then this throws an error.", "Yes I was using Tensorflow lower than 2.0. Using following command I'm able to convert properly,\r\n\r\n`trt_converter = trt_convert.TrtGraphConverter(input_saved_model_dir='/home/xavier3/single_model', precision_mode=\"FP16\", is_dynamic_op=True)`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34339\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34339\">No</a>\n", "Hi,\r\nI am facing the same issue with tensorflow==2.1.0+nv20.4", "Ran into same issue after fresh install of Jetpack 4.4 on Jetson Nano  which contains tensorflow==2.1.0+nv20.4. Loaded and built pycuda and got the same error. After looking into code, found the exception was due to tf.executing_eagerly() == False. \r\n##-- Work around --\r\nimport tensorflow as tf\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n    ....\r\n    ....\r\n    tf.compat.v1.enable_eager_execution()\r\n    print('Using Tensorflow version: {0}'.format(tf.version.VERSION))   \r\n    print(tf.executing_eagerly()) \r\n   Was able to execute trt.TrtGraphConverterV2 on keras models\r\n\r\n## I was under the impression that all TF 2.x versions ran with executing_eagerly == TRUE as default. When I import tensorflow 2.1.0+nv20.4 it seems that execute_eagerly is initialized as false in JP 4.4\r\n\r\n>>> import tensorflow as tf\r\n2020-05-08 22:22:59.965357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n2020-05-08 22:23:07.427738: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\r\n2020-05-08 22:23:07.474677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7\r\n>>> print(tf.executing_eagerly())\r\nFalse\r\n\r\n## When I do the same thing on JP 4.3 with tensorflow 2.1.0+nv20.3.tf2\r\n\r\nPython 3.6.9 (default, Apr 18 2020, 01:56:04)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-05-08 22:47:32.666516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-05-08 22:47:37.064950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-05-08 22:47:37.067243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n>>> print(tf.executing_eagerly())\r\nTrue\r\n>>>\r\n### Anyone have any thoughts ? Or is this a bug \r\n\r\n"]}, {"number": 34338, "title": "not had an installation in the kali linux ova filed os on the python3.8 version", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nhad said that the suitable version was not available on doing pip install tensorflow.", "comments": ["i work on the network security and the backdoor attacks in the hardware for the computation I also work on Deep Learning Hardware.", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nCan you please elaborate about the issue & the context.Make sure you also include the exact command if possible to produce the output included in your test case. \r\n\r\nWe ask for this information in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@vishwas1234567 \r\n\r\nAny update on this issue please?. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34337, "title": "Improve tf.batch_to_space documentation. Refer issue #34005", "body": "Made minor changes to make code more suitable for GCI challenge. Refer https://github.com/tensorflow/tensorflow/issues/34005 .", "comments": ["The changes have been made in order to make the code suitable for a Google Code-In Documentation and Research challenge. \r\nThe task now is to clean the documentation so that it is more clear. There are too many code blocks in-between the text. \r\nSome examples are placed in the args section for illustration. A better way to handle that would be to add those examples in a separate \"Examples\" section (consistent with other docs) and add pointers in the \"Args\" section.\r\nSimilarly, some other code elements could be eliminated from the text by adding pointers.\r\nClarify the `crops` part in the \"Args\" section further.", "Please open PR against `master` branch. We don't update release branches (`r...`) after the final release of the corresponding TF version (i.e., we won't update `r2.1` after TF2.1 is released).\r\n\r\nThe only time release branches are updated is when we make a patch release to fix a security vulnerability. As that requires expediency, we only accept minimal changes even then."]}, {"number": 34336, "title": "Example where softmax_cross_entropy_with_logits_v2 fails but softmax_cross_entropy_with_logits works", "body": "**System information**\r\n- Have I written custom code: ?\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- Python version: Python 3.6.5 :: Anaconda, Inc.\r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: CPU\r\n\r\n**Describe the current behavior**\r\nWhile implementing this paper [1] I found that using `softmax_cross_entropy_with_logits` leads to convergence and the correct results, whereas `softmax_cross_entropy_with_logits_v2` fails.\r\n[1]: https://arxiv.org/abs/1906.07748\r\n\r\n**Describe the expected behavior**\r\nI suppose that `softmax_cross_entropy_with_logits_v2` should work just as `softmax_cross_entropy_with_logits`.\r\n\r\n**Code to reproduce the issue**\r\nHere a notebook:\r\nhttps://github.com/Rassibassi/claude/blob/master/examples/tf_AutoEncoderForProbabilisticShapingAndAwgn.ipynb\r\n\r\nIn cell [8], just uncomment this line\r\n```\r\n# loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=s, logits=dec) # v2 does not work :(\r\n```\r\nand run for the code to fail, yet with `softmax_cross_entropy_with_logits` the result looks fine.\r\n\r\n\r\nWith `softmax_cross_entropy_with_logits`\r\n```\r\nepoch: 5 - outLossHat: -3.35 - always 1: 1.0\r\nepoch: 10 - outLossHat: -4.08 - always 1: 1.0\r\nepoch: 15 - outLossHat: -4.38 - always 1: 1.0\r\nepoch: 20 - outLossHat: -4.47 - always 1: 1.0\r\nepoch: 25 - outLossHat: -4.51 - always 1: 1.0\r\nepoch: 30 - outLossHat: -4.51 - always 1: 1.0\r\nepoch: 35 - outLossHat: -4.53 - always 1: 1.0\r\nepoch: 40 - outLossHat: -4.53 - always 1: 1.0\r\nepoch: 45 - outLossHat: -4.53 - always 1: 1.0\r\nepoch: 50 - outLossHat: -4.53 - always 1: 1.0\r\n```\r\n\r\nwith `softmax_cross_entropy_with_logits_v2`\r\n```\r\nepoch: 5 - outLossHat: -3.41 - always 1: 1.0\r\nepoch: 10 - outLossHat: -3.7 - always 1: 1.0\r\nepoch: 15 - outLossHat: -0.603 - always 1: 1.0\r\nepoch: 20 - outLossHat: -0.00371 - always 1: 1.0\r\nepoch: 25 - outLossHat: -0.0017 - always 1: 1.0\r\nepoch: 30 - outLossHat: -0.00103 - always 1: 1.0\r\nepoch: 35 - outLossHat: -0.000673 - always 1: 1.0\r\nepoch: 40 - outLossHat: -0.00049 - always 1: 1.0\r\nepoch: 45 - outLossHat: -0.000398 - always 1: 1.0\r\nepoch: 50 - outLossHat: -0.000311 - always 1: 1.0\r\n```\r\n", "comments": ["@Rassibassi Please go through the answer for this question [here](https://stats.stackexchange.com/questions/327348/how-is-softmax-cross-entropy-with-logits-different-from-softmax-cross-entropy-wi) and it explains the clear difference between `softmax_cross_entropy_with_logits ` and `softmax_cross_entropy_with_logits_v2` and this should give an intuition of why the error is occuring and let me know if it helps. Thanks! ", "Thank you very much. And sorry, I thought this was an actual bug. I should have searched a bit more or read the doc's.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34336\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34336\">No</a>\n"]}, {"number": 34335, "title": "[TF 2.0] Nested Gradient Tape - unconnected graphs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: MacOS 10.15.1\r\n- TensorFlow installed from binary (pip 19.3.1)\r\n- TensorFlow version: v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: Python 3.6.5\r\n\r\n**Describe the current behavior**\r\nA copy of my model (model_copy) should be trained one step, then I need my meta_model to be trained with the loss of my model_copy. It seems, that the graphs are unconnected.\r\nIt only works, if I use the meta_model for the training step.\r\n\r\n**Describe the expected behavior**\r\nI would expect, that model_copy is known to both gradient tapes and can be used w/o using meta_model.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras.backend as keras_backend\r\nimport tensorflow.keras as keras\r\n\r\nclass MetaModel(keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.hidden1 = keras.layers.Dense(5, input_shape=(1,))\r\n        self.out = keras.layers.Dense(1)\r\n    def forward(self, x):\r\n        x = keras.activations.relu(self.hidden1(x))\r\n        x = self.out(x)\r\n        return x\r\n\r\ndef copy_model(model, x):\r\n    copied_model = MetaModel()\r\n    copied_model.forward(x)\r\n    copied_model.set_weights(model.get_weights())\r\n    return copied_model\r\n\r\ndef compute_loss(model, x, y):\r\n    logits = model.forward(x)  # prediction of my model\r\n    mse = keras_backend.mean(keras.losses.mean_squared_error(y, logits))  # compute loss between prediciton and label/truth\r\n    return mse, logits\r\n\r\noptimizer_outer = keras.optimizers.Adam()\r\nalpha = 0.01\r\nwith tf.GradientTape() as g:\r\n    # meta_model to learn in outer gradient tape\r\n    meta_model = MetaModel()\r\n    # inputs for training\r\n    x = tf.constant(3.0, shape=(1, 1, 1))\r\n    y = tf.constant(3.0, shape=(1, 1, 1))\r\n\r\n    meta_model.forward(x)\r\n    model_copy = copy_model(meta_model, x)\r\n    with tf.GradientTape() as gg:\r\n        loss, _ = compute_loss(model_copy, x, y)\r\n        gradients = gg.gradient(loss, model_copy.trainable_variables)\r\n        k = 0\r\n        for layer in range(len(model_copy.layers)):\r\n            \"\"\" If I use meta-model for updating, this works \"\"\"\r\n            # model_copy.layers[layer].kernel = tf.subtract(meta_model.layers[layer].kernel,\r\n            #                                               tf.multiply(alpha, gradients[k]))\r\n            # model_copy.layers[layer].bias = tf.subtract(meta_model.layers[layer].bias,\r\n            #                                             tf.multiply(alpha, gradients[k + 1]))\r\n\r\n            \"\"\" If I use model-copy for updating instead, gradients_meta always will be [None,None,...]\"\"\"\r\n            model_copy.layers[layer].kernel = tf.subtract(model_copy.layers[layer].kernel,\r\n                                                          tf.multiply(alpha, gradients[k]))\r\n            model_copy.layers[layer].bias = tf.subtract(model_copy.layers[layer].bias,\r\n                                                        tf.multiply(alpha, gradients[k + 1]))\r\n\r\n            k += 2\r\n\r\n    # calculate loss of model_copy\r\n    test_loss, _ = compute_loss(model_copy, x, y)\r\n    # build gradients for meta_model update\r\n    gradients_meta = g.gradient(test_loss, meta_model.trainable_variables)\r\n    \"\"\" gradients always None !?!!11 elf \"\"\"\r\n    optimizer_outer.apply_gradients(zip(gradients_meta, meta_model.trainable_variables))\r\n```\r\n\r\n**Other info / logs**\r\nIs it intended to work as above? This would force me not to be able to use a different optimizer in the inner loop, as the networks need somehow to be connected.\r\n", "comments": ["@janbolle,\r\nWhen trying to reproduce your issue, I encounter the error, `ValueError: No gradients provided for any variable: ['dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0'].`. Can you please help us reproduce the issue. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/aef8241a042b30a26f55ea519204719a/34335.ipynb). Thanks! ", "@rmothukuru , thanks for your reply.\r\nThis is my problem. `gradients_meta` are always [None, None, ...].\r\nSo TF tells me that there are no gradients provided..", "@janbolle,\r\nSo do you mean you are encountering same error as that of mine. Please confirm. ", "@rmothukuru , yes, same error on my side.", "Chandan Kumar\n\n\nOn Nov 18, 2019 6:24 PM, \"Jan Bollenbacher\" <notifications@github.com>\nwrote:\n\n@rmothukuru <https://github.com/rmothukuru> , yes, same error on my side.\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/issues/34335?email_source=notifications&email_token=AMUWCJI3UKK2QVZRZWSF4ODQUKGA5A5CNFSM4JOEEYF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEKKIUI#issuecomment-555000913>,\nor unsubscribe\n<https://github.com/notifications/unsubscribe-auth/AMUWCJJLEZ5UJYBX3FEMQZ3QUKGA5ANCNFSM4JOEEYFQ>\n.\n", "Could reproduce the error with TF Version 2.0. Here is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/aef8241a042b30a26f55ea519204719a/34335.ipynb). Thanks!", "Also what is very odd: if I print the weights of the layers before and after the training, they are available. But if I use the function model_copy.get_weights() it results in an empty array.\r\n\r\nFollowing code:\r\n```python\r\n        k = 0\r\n        for layer in range(len(model_copy.layers)):\r\n            # calculate adapted parameters w/ gradient descent\r\n            # \\theta_i' = \\theta - \\alpha * gradients\r\n            print(\"pre: \", model_copy.layers[layer].kernel.shape, model_copy.layers[layer].kernel)\r\n            model_copy.layers[layer].kernel = tf.subtract(model_copy.layers[layer].kernel,\r\n                                                          tf.multiply(alpha, gradients[k]))\r\n            model_copy.layers[layer].bias = tf.subtract(model_copy.layers[layer].bias,\r\n                                                        tf.multiply(alpha, gradients[k + 1]))\r\n            print(\"post: \", model_copy.layers[layer].kernel.shape, model_copy.layers[layer].kernel)\r\n            k += 2\r\n    print(model_copy.get_weights())  # results in empty array\r\n```\r\n", "@jvishnuvardhan do you need further information?\r\n@rmothukuru did you connect the right person?\r\n\r\nAlso, I think this is a bug, not a support case :-/\r\n\r\nMaybe related to #29535", "I was able to replicate the issue with Tf-nightly==2.2.0.dev20200318.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5c1654e6125652cc42a3acb19d383e29/untitled470.ipynb). Thanks!", "I was able to replicate the issue with Tf-nightly==2.3.0-dev20200612.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/585e308194a2d6eb504c272e52b4c804/untitled14.ipynb).Thanks!.", "\r\nI was able to replicate the issue with Tf-nightly==2.4.0-dev20200806, Please, find the [gist here](https://colab.research.google.com/gist/Saduf2019/a0c3c0623ab485b71d2ea7a75b79cd0a/untitled333.ipynb). \r\n", "Have there been any updates with this issue? Running into a similar `None` gradients case when using nested `tf.GradientTape`s.", "Looking for updates on this as well! I am able to get my U-Net model to do an inner update, but this issue shows its only possible to do one inner update.", "Was able to replicate the issue in TF v2.5,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/880a891c65b627c2e17428ea07a23523/untitled81.ipynb)..Thanks !", "Was able to replicate the issue with TF 2.6.0-dev20210606,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/8d6d2da0729572f18b6e52296a253e1b/untitled246.ipynb) ..Thanks!", "I could reproduce the issue with TF 2.6 .Please, find the gist [**`here`**](https://colab.research.google.com/gist/kumariko/c5cd669d9e978f5cd929d169c65b29c9/untitled246.ipynb#scrollTo=mnFk1ZuTu7ak).Thanks!", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Still an issue with TF 2.7. Gist [here](https://colab.research.google.com/gist/kumariko/c5cd669d9e978f5cd929d169c65b29c9/untitled246.ipynb#scrollTo=mnFk1ZuTu7ak)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34335\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34335\">No</a>\n"]}, {"number": 34334, "title": "default installed version of tensorflow lite arduino library is pre-compiled, causing confusing error reports", "body": "hiya @petewarden ive been re-porting my demos (hooray) for Arduino boards\r\nhttps://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart\r\n\r\nright now when folks install the TensorFlow library it defaults to the pre-compiled version, which causes very obscure errors about register arguments if they are not using the exact same processor.\r\n\r\nhttps://learn.adafruit.com/tensorflow-lite-for-edgebadge-kit-quickstart/troubleshooting#uses-vfp-register-arguments-and-libtensorflowlite-dot-a-does-not-error-10-2\r\n\r\nplease make the default non-pre-compiled...Arduino IDE has a huge collection of supported boards, and as is, will confuse a lot of people :)", "comments": ["Sorry, I missed this one originally! I will dig into this, since we are keen to have widespread support.", "thank u \ud83d\udc4d ", "I've contacted the Arduino IDE team for help on this, I hope to have more progress to report soon.", "hihi checkin' in on this issue - i saw also SFE bumped into the same issue\r\n\r\nhttps://learn.sparkfun.com/tutorials/programming-the-sparkfun-edge-with-arduino\r\n\r\n`NOTE: It is imperative that you install the non-precompiled version of the library. Installing the pre-compiled library will only lead to failure and sadness.`", "The Arduino team now have a pending PR which they believe should fix this problem:\r\nhttps://github.com/arduino/arduino-cli/pull/512\r\n\r\nCould you take a look and provide feedback? Thanks for your patience!", "super rad! i will! :) i published a guide this weekend - https://learn.adafruit.com/tensorflow-lite-for-circuit-playground-bluefruit-quickstart", "I think this is now fixed and checked in, so closing! Let me know if I'm wrong and I'll reopen, thanks for your work on this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34334\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34334\">No</a>\n"]}, {"number": 34333, "title": "Tensorflow 1.14 GPU hanging when running models", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code: yes, I have coded an AEGAN that used to work but no longer.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Conda install tensorflow-gpu==1.14.0\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:Installed by Anaconda, unknown\r\n- GPU model and memory: Geforce GTX 1070 8G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nN/A, issue is described exactly by this stackoverflow question:\r\nhttps://stackoverflow.com/questions/47272869/tensorflow-stops-training-and-hanged-on-gpu-randomly/58887825#58887825\r\n", "comments": ["Note: I made sure the select feature of the command prompt isn't it, and this is definitely a bios/other issue. Any ideas?", "@MayhemGang ,\r\nThanks for reporting the issue, Can you share a standalone code to reproduce the error reported here?Thanks!", "@MayhemGang ,\r\nAny update on the issue?thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34332, "title": "AutoCastVariable.assign returns wrapped variable instead of casted version", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0, 2.1-nightly\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\n`AutoCastVariable` variable forwards `assign` and `scatter` to the underlying `float32` variable:\r\nhttps://github.com/tensorflow/tensorflow/blob/cee2a43b8184e92ba26ec0e3d6e00a3f8ca6e3c8/tensorflow/python/keras/mixed_precision/experimental/autocast_variable.py#L187-L188\r\nThus, the return value of `assign` methods with `read_value=True` is a normal `tf.Variable` and not an `AutoCastVariable`. This means that calculations directly depending on the assign operation, might run in `float32` instead of `float16`, or am I missing something?\r\n\r\n**Describe the expected behavior**\r\n`AutoCastVariable.assign*` should return an `AutoCastVariable` variable instead `tf.Variable` so that the `dtype` is preserved.\r\n\r\n@reedwm Is this intended behaviour?\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.mixed_precision.experimental import autocast_variable\r\n\r\nvar = tf.Variable(0., dtype=tf.float32)\r\nvar = autocast_variable.AutoCastVariable(var)\r\n\r\nwith tf.compat.v1.get_default_graph()._enable_auto_casting_variables(tf.float16):\r\n    assert var.dtype == tf.float16\r\n    # assign should return an AutoCastVariable but returns tf.Variable\r\n    var_assign = var.assign(5.)\r\n    assert not isinstance(var_assign, autocast_variable.AutoCastVariable)\r\n    assert var_assign.dtype == tf.float32\r\n```", "comments": ["I have tried on colab with TF version 2.0 ,2.1.0-dev20191111 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/4f70bc0621bc1d362ed8d465b7cb054a/untitled377.ipynb). Thanks!", "The current behavior was intended, but on second thought, I think you are right and that this behavior is incorrect. I previously incorrectly believed `Variable.assign` returned a tensor, not a Variable, and wanted the returned tensor to have the same dtype as the input tensor (float32).\r\n\r\nLuckily, this issue occurs relatively rarely. AutoCastVariables act identically to Variables outside `Layer.call`, and inside `Layer.call`, variables are rarely assigned to. Still, the current behavior is very confusing and so this should be fixed.\r\n\r\n@alextp, do you know what the purpose of the  [`_UnreadVariable`](https://github.com/tensorflow/tensorflow/blob/2692ea8ec1953e42952597adb5b5099181a679b2/tensorflow/python/ops/resource_variable_ops.py#L1806) is, which is returned from [`ResourceVariable.assign`](https://github.com/tensorflow/tensorflow/blob/2692ea8ec1953e42952597adb5b5099181a679b2/tensorflow/python/ops/resource_variable_ops.py#L799)? Why not simply return the ResourceVariable? Do you think I should I create a `_UnreadAutoCastVariable` subclass?", "@reedwm Thanks for taking a look.\r\n\r\nThe reason why I am looking deeper at the implementation of `AutoCastVariable` is because we are in the process of subclassing `tf.Variable` in https://github.com/larq/larq/issues/306 with the goal to have a `QuantizedVariable` that can be used to define arbitrary fake quantizations like binary or ternary  quantization which would allow easy research on extreme quantization. For this we are looking closely at the implementation of `AutoCastVariable`.\r\n\r\n@reedwm @alextp Do you think it makes sense to have a more formalized way to easily subclass `tf.Variable` or `tf.Tensor` in userland? It seams this already happens in a few places (e.g. `AutoCastVariable` or #34379) and would allow quite powerful use cases.", "@reedwm the purpose of `_UnreadVariable` is allowing code like `x = tf.assign_add(x, foo); x = tf.assign_add(x, bar)` which was possible with ref variables and so to ease the transition to resource variables I made `_UnreadVariable`\r\n\r\n@lgeiger I'm with you, I really don't like how complex variables are right now. I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module which implements the variable interface and has a tf.register_tensor_conversion_function for itself (so it can be implicitly cast to a tensor). If you cannot control the variable creation site I mostly recommend the same thing but you might want to use a variable_creation_scope to intercept variable creation and return your custom class. Just make sure to use the underlying creator when creating the variables inside your fake-variable.\r\n\r\nRe subclassing tensors, the answer is an emphatic no. We need to have Tensor be a C type (at least in eager mode) for performance in many places, as eventually tensors will have to be passed to kernels.", "> The reason why I am looking deeper at the implementation of AutoCastVariable is because we are in the process of subclassing tf.Variable in larq/larq#306\r\n\r\nI think having an implementation similar to `AutoCastVariable` is the way to go. I agree it would be nice to have a more formalized way to subclass `tf.Variable` but it currently doesn't exist unfortunately.\r\n\r\n> I think if you control the variable creation site I recommend instead of subclassing variable you implement a tf.Module\r\n\r\n@alextp, I would still recommend subclassing tf.Variable. I used to subclass Trackable, but I switched to tf.Variable in 74c52531846cc10a63fb244966ab6bfd000af747 as many parts of the code have isinstance checks on tf.Variable. DistributedVariable also subclasses Variable for a similar reason. And tf.Module has some extraneous properties that don't make a lot of sense on a Variable, such as `Module.trainable_variables`.\r\n\r\n> the purpose of _UnreadVariable is allowing code like x = tf.assign_add(x, foo); x = tf.assign_add(x, bar) \r\n\r\nAh I see, returning an `_UnreadVariable` instead of `self` allows this to properly work with Sessions and Graphs, which don't have automatic control dependencies. Otherwise, if `self` is returned, the variable assignment might not run.\r\n\r\nI could fix this by copying or subclassing `_UnreadVariable`. I could also just return `self`, which has slightly incorrect semantics when Sessions/Graphs are used with `tf.compat.v1`. I'll try to think of a better solution, especially considering QuantizedVariable will have the same issue. I'm pretty sure DistributedVariables also has this issue.\r\n\r\n", "Thanks a lot for the insights. It would be cool if we could come up with a simple solution for this.", "> I could fix this by copying or subclassing `_UnreadVariable`. I could also just return `self`, which has slightly incorrect semantics when Sessions/Graphs are used with `tf.compat.v1`\r\n\r\n@reedwm Since `AutoCastVariable` just wraps an other variable, what about returning a new instance wrapping the `_UnreadVariable` returned by the assign op. Would something like the following work?\r\n```python\r\ndef assign(self, value, use_locking=None, name=None, read_value=True):\r\n    assign_op_or_var = self._variable.assign(value, use_locking, name, read_value)\r\n    return self.__class__(assign_op_or_var) if read_value else assign_op_or_var\r\n#   return AutoCastVariable(assign_op_or_var) if read_value else assign_op_or_var\r\n```", "I think that would work, and is very simple. I didn't think of that before. Thanks for the suggestion!\r\n\r\nDo you want to implement it for AutoCastVariable? If not, I'd be happy to.", "> I think that would work, and is very simple.\r\n\r\nGreat!\r\n\r\n> Do you want to implement it for AutoCastVariable? If not, I'd be happy to.\r\n\r\n:+1: Will send a PR and add some tests once TensorFlow finishes compiling on my machine.", "I opened a small PR: #34779", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332\">No</a>\n", "#34779 doesn't fully close this issue since Distribution Strategy is not fully supported yet (see https://github.com/tensorflow/tensorflow/pull/34779#discussion_r353481035)", "You're right, reopening.\r\n\r\nOnce Distribution Strategy returns a variable from `DistributionVariable.assign`, this issue can be fixed.", ":+1: Thanks for the help with debugging", "@lgeiger Is this still an issue? Can you please check with `tf-nightly` and let us know. Thanks!", "This is still an issue. The `tf.distribute.Strategy` team is working on a way to return a variable from `DistributionVariable.assign` and until then, this issue cannot be fully fixed.", "@jvishnuvardhan Sorry for the late response. Indeed this is still an issue in the latest nightly. Here is an updated code example for the distribution case:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.mixed_precision.experimental import autocast_variable\r\nfrom tensorflow.python.distribute import strategy_combinations\r\n\r\nstrategy_combinations.set_virtual_cpus_to_at_least(3)\r\nwith tf.distribute.MirroredStrategy(['/cpu:1', '/cpu:2']).scope():\r\n    var = tf.Variable(0., dtype=tf.float32)\r\n    var = autocast_variable.AutoCastVariable(var)\r\n\r\n    with tf.compat.v1.get_default_graph()._enable_auto_casting_variables(tf.float16):\r\n        assert var.dtype == tf.float16\r\n        # assign should return an AutoCastVariable but returns tf.Variable\r\n        var_assign = var.assign(5.)\r\n        assert not isinstance(var_assign, autocast_variable.AutoCastVariable)\r\n        assert var_assign.dtype == tf.float32\r\n```", "Can we close this?", "> Can we close this?\r\n\r\nThis is still an issue in the latest nightly, but now only shows up in non eager mode. Before this happened in both execution contexts. Here is some updated code that reproduces the failure with the new API:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.mixed_precision import autocast_variable\r\nfrom tensorflow.python.distribute import strategy_combinations\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nstrategy_combinations.set_virtual_cpus_to_at_least(3)\r\nwith tf.distribute.MirroredStrategy(['/cpu:1', '/cpu:2']).scope():\r\n    var = tf.Variable(0., dtype=tf.float32)\r\n    var = autocast_variable.AutoCastVariable(var)\r\n    with autocast_variable.enable_auto_cast_variables(tf.float16):\r\n        assert tf.identity(var).dtype == tf.float16\r\n        # assign should return an AutoCastVariable but returns tf.Variable\r\n        var_assign = var.assign(5.)\r\n        assert isinstance(var_assign, autocast_variable.AutoCastVariable)\r\n        assert tf.identity(var).dtype == tf.float16\r\n```\r\n        ", "@lgeiger Do you think that you could add this with a minimal refactoring as a [DISABLED test](https://github.com/google/googletest/blob/master/docs/advanced.md#temporarily-disabling-tests)?", "> Do you think that you could add this with a minimal refactoring as a DISABLED test?\r\n\r\n@bhack These cases are already covered in [`tensorflow/python/keras/mixed_precision/autocast_variable_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/mixed_precision/autocast_variable_test.py).\r\n\r\nIn fact I just opened #49856 earlier today to enable the distribution strategy tests in eager mode which have been fixed.", "What I mean is that if we have DISABLED tests referencing specific tickets we could regularly check what is \"still not\" working as we expected and running the CI with an extra step on DISABLED tests (or any other semantic filter we want to use). \r\n\r\nIn this way we could see if the behavior is changed or if it solved when the specific test is failing. \r\nIn that case we could comment again or close the related ticket.\r\n\r\nSo in DISABLED tests we assert the BUG not the correct behavior.\r\n\r\nE.g. In this way we could have covered the evolution of this bug since 2019.\r\n\r\nThis is just an idea cause we currently don't run specific DISABLED tests (or any special test filter semantics) in the CI. \r\n\r\n/cc @mihaimaruseac @reedwm \r\n", "This is a good idea, but I personally don't think it's worth the infrastructure complexity of running DISABLED tests to check whether a bug is fixed. Typically if a bug is fixed, someone will write a corresponding unit test. This bug is an exception, but even so, it was not fully fixed (it still doesn't work with distribution strategies in graph mode).", "@reedwm I have an initial draft proposal about this internally, please ping me if you are interested.\r\n\r\n>  Typically if a bug is fixed, someone will write a corresponding unit test.\r\n\r\nBut we still have some good side effects with DISABLED tests. \r\n\r\nJust to mention a few of these:\r\n\r\n- Improved triage. We will have a good proxy of the final test (the one when \"a bug is fixed, someone will write a corresponding unit test\")\r\n- We have for sure a more isolated code gist to reproduce the bug specially over the time axis (some tickets stay open for months, years).\r\n- We don't need to periodically ping and review all the old tickets about reproducibility with master or with last release often with an not so isolated gist or without the original submitter/subscribers availability.\r\n- We could run this on tf-nightly wheels without compiling TF.\r\n- If we exclude some complex env we could run these test on Github Action directly or on Self-hosted Github Action runners.", "Hi There,\r\n\r\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \r\n\r\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34332\">No</a>\n"]}]