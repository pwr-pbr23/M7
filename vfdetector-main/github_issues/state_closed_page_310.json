[{"number": 44944, "title": "tflite_runtime got installed successfully, however getting error while importing interpreter.", "body": "Environment:\r\nPython 3.7\r\narmv7l (ARM 32).\r\ntflite_runtime (installed version) : 2.5.0\r\n\r\nIssues:\r\n\r\nSteps followed:\r\n1. Followed steps from Python Quickstart document available on tensorflow site , below is the document.\r\n      https://www.tensorflow.org/lite/guide/python\r\n\r\n2. it was stated in the above document To quickly run TensorFlow Lite models with Python, you can install just the TensorFlow Lite interpreter, instead of all TensorFlow packages.\r\n\r\n3. So I didn't install the whole tensorflow package , indeed just installed the wheel available for my armv7l (ARM 32) machine having Python 3.7.\r\n\r\nSteps to reproduce the issue:\r\n\r\n1. Have ARM 32 (armv7l) system with Python 3.7.\r\n2. pip3 install --install-option=\"/mnt/persistent_data/tfinter\" tflite_runtime-2.5.0-cp37-cp37m-linux_armv7l.whl\r\n3. wheel package installed: https://github.com/google-coral/pycoral/releases/download/release-frogfish/tflite_runtime-2.5.0-cp37-cp37m-linux_armv7l.whl\r\n3. Install tflite_rutime only (not the whole tensorflow) using above command.\r\n4. tflite_runtime got installed correctly (no error while installation).\r\n5. tflute_runtime version 2.5.0.\r\n\r\nExpected Behaviour:\r\n\r\nimport tflite_runtime.interpreter as tflite\r\nAbove command should get executed without error.\r\n\r\nError:\r\nHowever trying to import  tflite_runtime.interpreter returns following error:\r\n\r\n>>> import tflite_runtime.interpreter\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 36, in <module>\r\n    from tflite_runtime import _pywrap_tensorflow_interpreter_wrapper as _interpreter_wrapper\r\nImportError: cannot import name '_pywrap_tensorflow_interpreter_wrapper' from 'tflite_runtime' (/usr/lib/python3.7/site-packages/tflite_runtime/__init__.py).\r\n\r\nNote:\r\nDoing ls in installed tflite_runtime folder returns following files:\r\n\r\n[nilesh_kumar@localhost tflite_runtime]$ ls\r\n__init__.py\r\n__pycache\r\ninterpreter.py\r\n_pywrap_tensorflow_interpreter_wrapper.cpython-37m-arm-linux-gnueabihf.so\r\n", "comments": ["@Neel1994 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "> @Neel1994\r\n> We see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nHi @Saduf2019 have updated the issue as per your requirement.", "@Neel1994 \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/3217#issuecomment-231289660) and let us know if it helps resolve.\r\nalso try ```from tflite_runtime.interpreter import Interpreter``` refer to #31369", "**Hi @Saduf2019 , still giving the same error.**\r\n\r\n>>> from tflite_runtime.interpreter import Interpreter\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 36, in <module>\r\n    from tflite_runtime import _pywrap_tensorflow_interpreter_wrapper as _interpreter_wrapper\r\nImportError: cannot import name '_pywrap_tensorflow_interpreter_wrapper' from 'tflite_runtime' (/usr/lib/python3.7/site-packages/tflite_runtime/__init__.py)\r\n\r\nWent through the chats and tried executing all posible commands still same error.\r\n", "@Neel1994 Did you use correct wheel for the platform? I didn't dace any issues when I tried with Mac OS and Windows when I used correct wheels for my python and platform. Thanks!", "@jvishnuvardhan , Yes I used the correct wheel my system is ARM32 (armv7l) and python version 3.7\r\nIt is a linux distrib and not Mac/Windows.\r\n**Additional System details:**\r\nOperating System: **Poky (Yocto Project Reference Distro) 3.0.1 (zeus)**\r\nKernel: **Linux 4.19.112**\r\nArchitecture: **arm**\r\nmodel name      : **ARMv7 Processor rev 1 (v7l)**\r\nHardware        : NPCM7XX Chip family\r\n\r\n/home/root# python3\r\nPython 3.7.5 (default, Nov 17 2020, 09:50:47)\r\n[GCC 9.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import numpy\r\n>>> import tflite_runtime\r\n>>> from tflite_runtime.interpreter import Interpreter\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 36, in <module>\r\n    from tflite_runtime import _pywrap_tensorflow_interpreter_wrapper as _interpreter_wrapper\r\nImportError: cannot import name '_pywrap_tensorflow_interpreter_wrapper' from 'tflite_runtime' (/usr/lib/python3.7/site-packages/tflite_runtime/__init__.py)\r\n\r\nYou can see above tflite_runtime is imported successfully, however importing Interpreter is throwing error.\r\n\r\nWheel used for install: https://github.com/google-coral/pycoral/releases/download/release-frogfish/tflite_runtime-2.5.0-cp37-cp37m-linux_armv7l.whl\r\n\r\nAbove is the correct wheel as trying to install with any other wheel throws (platform not compatible) error while installation.\r\n", "The PIP package was generated with arm-linux-gnueabihf-gcc toolchain. I guess your system has an ABI compatibility issue with it. If you have a cross compilation toolchain for your target, you'd better generate PIP package by yourself.\r\n\r\nYou might want to modify this\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/setup.py#L55\r\nand use the following document.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package", "@Neel1994 - Was it solved? I am facing exact issue in Linux. ", "@Neel1994 Could you please refer to the [comment](https://github.com/tensorflow/tensorflow/issues/44944#issuecomment-730877334)  and try on the latest TF v2.6.0 ,please let us know if the issue still persists ?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44944\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44944\">No</a>\n", "@Neel1994 I got around this error by installing the tflite_tuntime 2.4 from [here ](https://github.com/iCorv/tflite-runtime). I installed the required pybind dependency from [here](https://pypi.org/project/pybind11/#files)."]}, {"number": 44943, "title": "UnrecognizedFlagError: Unknown command line flag 'pdb_post_mortem'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): https://pypi.tuna.tsinghua.edu.cn\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:CUDA 10.0,cuDNN\r\n- GPU model and memory: 6GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\ni successfully installed tensorflow-gpu==1.14.0,when i import tensorflow as tf, raise the flowing exception,how can i sovle it?\r\nmy cuda version si 10.0, and cudnn  is cudnn64_7.dll\r\n\r\n\r\nimport tensorflow as tf\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nD:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\framework_lib.py\", line 25, in <module>\r\n    from tensorflow.python.framework.ops import Graph\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 54, in <module>\r\n    from tensorflow.python.platform import app\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 23, in <module>\r\n    from absl.app import run as _run\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\absl\\app.py\", line 54, in <module>\r\n    flags.DEFINE_alias('pdb', 'pdb_post_mortem')\r\n  File \"D:\\ProgramFile\\python\\lib\\site-packages\\absl\\flags\\_defines.py\", line 754, in DEFINE_alias\r\n    raise _exceptions.UnrecognizedFlagError(original_name)\r\nabsl.flags._exceptions.UnrecognizedFlagError: Unknown command line flag 'pdb_post_mortem'\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Honestly I don't think will be enough bandwidth here to support `1.14.0` tickets.\r\n\r\nCan you try to use an updated TF version?", "Thank you. No error was reported after upgrading to TF 2.0", "> Honestly I don't think there will enough bandwidth here to support `1.14.0` tickets.\r\n> \r\n> Can you try to use an updated TF version?\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44943\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44943\">No</a>\n"]}, {"number": 44942, "title": "Keras Model.compile() exception text is unclear when a loss method is not specified during compile()", "body": "**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.** User is not given an obvious error message when  tensorflow.keras.models.Sequential.compile() is called and a loss function is omitted.\r\n\r\n```\r\n# Build the model\r\ntf_model = Sequential()\r\ntf_model.add(LSTM(\r\n    units=32,\r\n    input_shape=[window, 1],    \r\n))\r\ntf_model.add(Dense(units=1))\r\ntf_model.compile()\r\ntf_model.fit(rolling_x, rolling_y, epochs=100)\r\n```\r\n\r\nTriggers the following exception:\r\n\r\n```\r\n\\env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1270 _filter_grads\r\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n```\r\n\r\n**Will this change the current api? How?** No\r\n\r\n**Who will benefit with this feature?** New users", "comments": ["Can you try with `tf-nighlty`?", "Yes, this still occurs with nightly. PS. Due to Nvidia software mismatch this was run on CPU and not GPU. I don't think that matters.", "Can you fill variables  in your code example so that I could run the same code quickly?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44941, "title": "Learn ML", "body": "<removed as it was spam>", "comments": ["Please don't spam"]}, {"number": 44940, "title": "TF 2.3.1. Custom Metrics are not shown", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary):Docker tag 2.3.1\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):x\r\n- GCC/Compiler version (if compiling from source):x\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: K80\r\n\r\n**Describe the current behavior**\r\nI used to be able _(TF 2.0.0)_ to log custom metrics using a Callback, putting the calculated logs into the `logs` variable. Now _(using TF 2.3.1)_ it seems these are not displayed anymore. Is this adjusted? It seems all that is visualized now is: \r\n```\r\nI 2020-11-17T12:47:08.315319004Z master-replica-0 Epoch 1/150\r\n master-replica-0 \r\nI 2020-11-17T12:47:08.315363796Z master-replica-0 160/160 - 532s - loss: 29.2287 - val_loss: 15.1582\r\n master-replica-0 \r\nI 2020-11-17T12:55:48.016732616Z master-replica-0 Epoch 2/150\r\n master-replica-0 \r\nI 2020-11-17T12:55:48.016795954Z master-replica-0 160/160 - 519s - loss: 10.9081 - val_loss: 18.8457\r\n master-replica-0 \r\nI 2020-11-17T13:04:21.477356137Z master-replica-0 Epoch 3/150\r\n master-replica-0 \r\nI 2020-11-17T13:04:21.477408088Z master-replica-0 160/160 - 513s - loss: 9.3685 - val_loss: 8.4681\r\n master-replica-0 \r\nI 2020-11-17T13:12:53.997353683Z master-replica-0 Epoch 4/150\r\n master-replica-0 \r\nI 2020-11-17T13:12:53.997419829Z master-replica-0 160/160 - 512s - loss: 10.4035 - val_loss: 8.9458\r\n master-replica-0 \r\nI 2020-11-17T13:21:18.459229170Z master-replica-0 Epoch 5/150\r\n master-replica-0 \r\nI 2020-11-17T13:21:18.459279180Z master-replica-0 160/160 - 504s - loss: 9.8809 - val_loss: 9.3682\r\n master-replica-0 \r\nI 2020-11-17T13:29:43.330040354Z master-replica-0 Epoch 6/150\r\n master-replica-0 \r\nI 2020-11-17T13:29:43.330108120Z master-replica-0 160/160 - 504s - loss: 9.5458 - val_loss: 8.8212\r\n master-replica-0 \r\n```\r\n\r\n", "comments": ["Can you share a very minimal code example to reproduce this?", "https://colab.research.google.com/drive/1lUCnZrgUzH77okiyDNdNkHRMU1pYkMNf?usp=sharing\r\n\r\niirc, this should yield the result:\r\n```\r\n4/4 [==============================] - 0s 22ms/step - loss: 232.9125 - val_loss: 7.3053 - test_val: 0.8\r\n```\r\n\r\nwhich it doesn't, e.g.:\r\n```\r\n4/4 [==============================] - 0s 22ms/step - loss: 232.9125 - val_loss: 7.3053\r\n```", "In your colab ` 'metric' is not defined`", "Adjusted", "Is this like https://github.com/tensorflow/tensorflow/issues/37187?", "It seems so. I know that it has worked for me in the past. ", "I think you can close this, upvote and subscribe to that one", "Duplicate of #37187", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44940\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44940\">No</a>\n"]}, {"number": 44939, "title": "TFlu: Add unit test for multiple inputs", "body": "This is fixing issue: https://issuetracker.google.com/u/1/issues/173420462\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 44938, "title": "RuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare. Node number 30 (WHILE) failed to invoke.", "body": "**System information**\r\n-  Linux Ubuntu 16.04\r\n- TensorFlow installed from 2.3:\r\n- Tf-nightly: 2..4.0a20201112\r\n- Keras = 2.4.3\r\n\r\n** I am able to convert to the tflite model but i am getting error while conversion.\r\nError: \"Traceback (most recent call last):\r\n  File \"/home/PycharmProjects/keras-ctpn/test.py\", line 74, in <module>\r\n    interpreter.invoke()\r\n  File \"/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\", line 540, in invoke\r\n    self._interpreter.Invoke()\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\"\r\n\r\n\r\n\r\nMy python Script:\r\n##\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport cv2\r\nimport keras\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport keras.backend as K\r\nimport keras.layers as KL\r\nimport keras.models as KM\r\nfrom keras.applications.vgg16 import VGG16 as vgg\r\nfrom keras.layers import TimeDistributed\r\nfrom keras.models import Sequential\r\n\r\n\r\ninput_image = KL.Input(shape=[512, 512, 3], name=\"input_image\")\r\nvgg = vgg(input_tensor=input_image, include_top=False)\r\nx = vgg.get_layer('block5_conv3').output\r\nx = KL.Conv2D(512, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)\r\ntemp = KL.Bidirectional(KL.LSTM(128, return_sequences=True))\r\nx = KL.TimeDistributed(temp)(x)\r\nnew_output = KL.Dense(10, activation=\"sigmoid\")(x)\r\nheadModel = KL.Flatten(name=\"flatten\")(new_output)\r\nheadModel = KL.Dense(2, activation=\"softmax\")(headModel)\r\nprint(K.int_shape(x))\r\nmodel = KM.Model(inputs=input_image, outputs=headModel )\r\nmodel.compile(loss='mean_squared_error', optimizer='adam')\r\nmodel.save('i_bilstm.h5')\r\n\r\nmodel = keras.models.load_model('i_bilstm.h5')\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\nopen(\"i_bilstm.tflite\", \"wb\").write(tflite_model)\r\n\r\ninterpreter = tf.lite.Interpreter(\r\n    model_path='i_bilstm.tflite')\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\nprint(input_details)\r\nprint(output_details)\r\nfloating_model = input_details[0]['dtype'] == np.float32\r\nheight = input_details[0]['shape'][1]\r\nwidth = input_details[0]['shape'][2]\r\nimg = cv2.imread('006.jpg')\r\nimg = cv2.resize(img, (512, 512))\r\ninput_data = np.expand_dims(img, axis=0)\r\n\r\nprint(img.shape)\r\nimg = img.reshape(1, 512, 512, 3)\r\nprint('shape ', img.shape)\r\nif floating_model:\r\n    img = (np.float32(img) - 127.5) / 127.5\r\n\r\nprint('input_details[0]', input_details[0]['index'])\r\ninterpreter.set_tensor(input_details[0]['index'], img)\r\ninterpreter.invoke()\r\nrects = interpreter.get_tensor(\r\n    output_details[0]['index'])\r\nprint('score ', rects)\r\nscores = interpreter.get_tensor(\r\n    output_details[0]['index'])\r\nprint('score ', scores)\r\n\r\n##\r\nAlso I have attached the file:\r\n\r\n# Full console log:\r\n\r\n/home/anaconda3/envs/sentiment_analysis/bin/python /home/PycharmProjects/keras-ctpn/test.py\r\n2020-11-17 16:55:41.346730: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2020-11-17 16:55:41.346748: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-11-17 16:55:42.364414: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-17 16:55:42.364557: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-11-17 16:55:42.364568: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-11-17 16:55:42.364584: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (PC13): /proc/driver/nvidia/version does not exist\r\n2020-11-17 16:55:42.364708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-17 16:55:42.365362: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n\r\nWARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\r\n/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2342: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\r\n2020-11-17 16:55:44.987273: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\n/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1395: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`layer.updates` will be removed in a future version. '\r\nWARNING:absl:Found untraced functions such as bidirectional_layer_call_fn, bidirectional_layer_call_and_return_conditional_losses, forward_lstm_layer_call_fn, forward_lstm_layer_call_and_return_conditional_losses, backward_lstm_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\r\n2020-11-17 16:55:49.339432: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored output_format.\r\n2020-11-17 16:55:49.339456: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:322] Ignored drop_control_dependency.\r\n2020-11-17 16:55:49.340091: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /tmp/tmp9mpttm0t\r\n2020-11-17 16:55:49.353959: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\r\n2020-11-17 16:55:49.353980: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /tmp/tmp9mpttm0t\r\n2020-11-17 16:55:49.354016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-17 16:55:49.391851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:251] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n2020-11-17 16:55:49.404005: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2020-11-17 16:55:49.433978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\r\n2020-11-17 16:55:49.540582: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/tmp9mpttm0t\r\n2020-11-17 16:55:49.598145: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 258055 microseconds.\r\n2020-11-17 16:55:49.758440: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2020-11-17 16:55:49.921397: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n[{'name': 'serving_default_input_image:0', 'index': 0, 'shape': array([  1, 512, 512,   3], dtype=int32), 'shape_signature': array([ -1, 512, 512,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n[{'name': 'StatefulPartitionedCall:0', 'index': 87, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\nTraceback (most recent call last):\r\n  File \"/home/PycharmProjects/keras-ctpn/test.py\", line 71, in <module>\r\n    interpreter.invoke()\r\n  File \"/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\", line 540, in invoke\r\n    self._interpreter.Invoke()\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n[tflite_conv.py.txt](https://github.com/tensorflow/tensorflow/files/5553142/tflite_conv.py.txt)\r\n\r\n", "comments": ["Session crashes on running the code with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/ad9f99c922f71ec262e15ba5fa7df1a8/44938.ipynb). \r\n\r\nWhereas running with [TF v2.4.0rc1](https://colab.research.google.com/gist/amahendrakar/4116e8c9cb359db4af5c5f70a5f3b38d/44938-2-4.ipynb#scrollTo=aao5xPEIKJN2) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/ca8643cc1e01ff9940317e99ba07771f/44938-tf-nightly.ipynb#scrollTo=6LlvVYtMGDLK) throws an error stating `error: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'`\r\n\r\nPlease find the attached gist. Thanks!", "@amahendrakar Thank you for reply. I have attached the sample image. Sorry for the missing file. Now i am able to reproduce the error using the image file. Can you please take a look now.\r\n\r\n![006](https://user-images.githubusercontent.com/14245664/99519704-354ea580-29b8-11eb-9426-ef464ca11079.jpg)\r\n", "@Angel3636 I can reproduce the error. Interpreter is throwing the following error. [Here](https://colab.research.google.com/gist/jvishnuvardhan/078848a173cc7cb58874cea4959468cb/44938-tf-nightly.ipynb) is the gist for our reference.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-21-066e1310d25e> in <module>()\r\n      6 interpreter.set_tensor(input_details[0]['index'], input_data)\r\n      7 # interpreter.set_tensor(input_details[0]['index'], img)\r\n----> 8 interpreter.invoke()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in invoke(self)\r\n    538     \"\"\"\r\n    539     self._ensure_safe()\r\n--> 540     self._interpreter.Invoke()\r\n    541 \r\n    542   def reset_all_variables(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\ntensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\ntensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\ntensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\ntensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke.\r\n```\r\n\r\nI am not sure whether the Bidirectional LSTM completely implemented or not. @srjoglekar246 Any thoughts on this? Thanks!", "I am not sure whether the Bidirectional LSTM completely implemented or not. @srjoglekar246 Any thoughts on this? Thanks!\r\n\r\n# \r\n@jvishnuvardhan  How can i check this?, because if i do the  inference using save model 'bilstm.h5' i get the results without any problem, but if i try with tflite,  i am getting error that shown in gist\r\n \"tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.\r\nNode number 30 (WHILE) failed to invoke\"", "Hi Haoliang,\r\n\r\ncan you help take a look?\r\n\r\nthanks!", "Bidi-LSTM is fully supported by the new converter. Could you share your .tflite file? This seems to be some shape mismatch that just get messed up.", "Hi @haozha111, Thanks for reply, My file size is to big, So i have uploaded on drive. Here is the link:\r\nhttps://drive.google.com/file/d/1B_laiJYNHzHDgvxwKqrAQerctXzad6so/view?usp=sharing\r\n\r\n\r\n\r\n\r\n\r\n", "seems that i dont have access, could you grant permission?", "> \r\n> \r\n> seems that i dont have access, could you grant permission?\r\n\r\nSorry for that, can you please check it now. ", "Hi @Angel3636!\r\nCould you please try on latest stable version of tf 2.6  and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44938\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44938\">No</a>\n", "Think I'm experiencing the same (on tf-nightly, too), was this fixed?"]}, {"number": 44937, "title": "model.evaluate() and keras.losses.MSE() returning significantly different values", "body": "**System information**\r\n- custom code \r\n- macOS High Sierra 10.13.6\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.8.1\r\n\r\n\r\n**Describe the current behavior**\r\nAfter training a LSTM Sequential model for univariate time series prediction, the values returned by model.evaluate(test_set) and tf.keras.losses.MSE(y, model.predict(test_set)), where y is the ground truth and test_set is tf.data.Dataset structure, are different in scale: mode.evaluate() returns a value around a unit or two, whereas tf.keras.losses.MSE returns a value of hundreds.\r\n\r\nDifferently from apparently similar issues, I am not performing Transfer Learning, I am not using Dropout layers and I am not doing batch normalisation.\r\n\r\n**Describe the expected behavior**\r\nAfter training a LSTM Sequential model for univariate time series prediction on the training set in the format of tf.data.Dataset, the evaluation with model.evaluate(test_set), where test_set is a tf.data.Dataset structure, is expected to give the same result of tf.keras.losses.MSE(y, y_hat) where y is the ground truth and y_hat are the values returned by model.predict(test_set)\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport datetime\r\nfrom pandas_datareader import data;\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n#get data\r\neverSince = datetime.date(1980, 1, 1)\r\ntoday = datetime.date(2020, 11, 16)\r\ndf = data.get_data_yahoo(\"CORN\", start=everSince,\r\n        end=today);\r\n\r\n# extract only 'Close' column\r\ndf_close = df[['Close']]\r\n\r\n#Convert to TFDataset\r\nWINDOW_SIZE = 10\r\ndataset = tf.data.Dataset.from_tensor_slices((df_close.values))\r\nd = dataset.window(WINDOW_SIZE, shift=1, drop_remainder=True)\r\nd2 = d.flat_map(lambda window: window.batch(WINDOW_SIZE))\r\nlen_ds = 0\r\nfor item in d2:\r\n    len_ds +=1\r\nd3 = d2.map(lambda window: (window[:-1], window[-1:]))\r\nd_shuffled = d3.shuffle(buffer_size=len_ds, reshuffle_each_iteration=False)\r\n\r\n#Split train/val/test\r\ny_targets = np.array([ target.numpy() for _, target in iter(d_shuffled) ])\r\nX_indices = np.arange(len(y_targets))\r\n\r\ny_targets = y_targets.reshape((-1,))\r\n\r\n#stratify array-like, default=None If not None, data is split in a stratified\r\n#fashion, using this as the class labels.\r\nX_train_indices, X_val_indices, y_train_targets, y_val_targets = train_test_split(\r\n    X_indices, y_targets, test_size=0.15, stratify=None, random_state=53)\r\n\r\nX_test_indices, X_val_indices, y_test_targets, y_val_targets = train_test_split(\r\n    X_val_indices, y_val_targets, test_size=0.5, stratify=None, random_state=53)\r\n\r\ndef get_selected_dataset(ds, X_indices_np):\r\n    # Make a tensor of type tf.int64 to match the one by Dataset.enumerate().\r\n    X_indices_ts = tf.constant(X_indices_np, dtype=tf.int64)\r\n\r\n    def is_index_in(index, rest):\r\n        # Returns True if the specified index value is included in X_indices_ts.\r\n        #\r\n        # '==' compares the specified index value with each values in X_indices_ts.\r\n        # The result is a boolean tensor, looks like [ False, True, ..., False ].\r\n        # reduce_any() returns Ture if True is included in the specified tensor.\r\n        return tf.math.reduce_any(index == X_indices_ts)\r\n\r\n    def drop_index(index, rest):\r\n        return rest\r\n\r\n    # Dataset.enumerate() is similter to Python's enumerate().\r\n    # The method adds indices to each elements. Then, the elements are filtered\r\n    # by using the specified indices. Finally unnecessary indices are dropped.\r\n    selected_ds = ds.enumerate().filter(is_index_in).map(drop_index)\r\n    return selected_ds\r\n\r\nsplitted_train_ds = get_selected_dataset(d_shuffled, X_train_indices)\r\nsplitted_val_ds   = get_selected_dataset(d_shuffled, X_val_indices)\r\nsplitted_test_ds  = get_selected_dataset(d_shuffled, X_test_indices)\r\n\r\n\r\ndef create_model():\r\n    MODEL_ARCH = [\r\n        tf.keras.layers.GRU(50, return_sequences=True, input_shape=( WINDOW_SIZE-1, 1)),\r\n        tf.keras.layers.GRU(50,),\r\n        tf.keras.layers.Dense(10, activation='tanh'),\r\n        tf.keras.layers.Dense(1, activation='tanh'),\r\n        tf.keras.layers.Lambda(lambda x: x*100)\r\n\r\n    ]\r\n    model = tf.keras.models.Sequential(MODEL_ARCH)\r\n    return model\r\n\r\n\r\nmodel = create_model()\r\nLR = 1e-3\r\noptimizer = tf.keras.optimizers.Adagrad(lr=LR)\r\nmodel.compile(loss='mse', optimizer=optimizer)\r\n\r\nhistory = model.fit(splitted_train_ds.batch(32), epochs=5,\r\n    validation_data=splitted_val_ds.batch(32), batch_size=32)\r\nmodel_err = model.evaluate(splitted_test_ds.batch(1), verbose=2)\r\ny_hat = model.predict(splitted_test_ds.batch(1))\r\ny_hat = y_hat.reshape((-1,))\r\nprint(\"model.evaluate(): \", model_err )\r\nprint(\"tf.keras.losses.MSE: \", tf.keras.losses.MSE(y_test_targets, y_hat).numpy())\r\n\r\n```\r\n\r\nlink to Colab/Jupyter/any notebook:\r\nhttps://colab.research.google.com/drive/1PFGXNpAn2NC53LR9vK40lTO0Fw-dFnZK?usp=sharing\r\n\r\n\r\n", "comments": ["This is a support request not a bug so I think that it is ok to close this and waiting for a reply at:\r\nhttps://stackoverflow.com/questions/64837634/tensorflow-model-evaluate-and-tf-keras-losses-mse-returning-completely-differ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44937\">No</a>\n"]}, {"number": 44935, "title": "tf.TensorArray not working", "body": "\r\n**System information**\r\ntf version- 2.3\r\nsystem - colab\r\n\r\n```\r\n@tf.function\r\ndef blah():\r\n  stackin=tf.TensorArray(tf.float32,size=1,dynamic_size=True)\r\n  i=tf.Variable(0,tf.float32)\r\n  for i,(x,y) in test.take(10).enumerate():\r\n    if True:\r\n      y_=model(tf.expand_dims(x,axis=0))\r\n      y_=tf.squeeze(y_,axis=0)\r\n    else :\r\n      y_=model(x)\r\n    stackin.write(i,y_)\r\n```\r\non running\r\n```\r\nTypeError: in user code:\r\n\r\n    <ipython-input-146-3e5e999f0677>:11 blah  *\r\n        stackin.write(i,y_)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:247 wrapped  **\r\n        return _add_should_use_warning(fn(*args, **kwargs),\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:1159 write\r\n        return self._implementation.write(index, value, name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:543 write\r\n        name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/list_ops.py:166 tensor_list_set_item\r\n        index >= input_list_size,\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:4076 greater_equal\r\n        \"GreaterEqual\", x=x, y=y, name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper\r\n        inferred_from[input_arg.type_attr]))\r\n\r\n    TypeError: Input 'y' of 'GreaterEqual' Op has type int32 that does not match type int64 of argument 'x'.\r\n```", "comments": ["Can you share the colab with very minimal code lines to reproduce this?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44935\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44935\">No</a>\n"]}, {"number": 44934, "title": "[Intel MKL] Enable MklConv/MklFusedConv with explicit padding", "body": "This MR is to enable MklConv/MklFusedConv with `explicit_padding` attribute. It reused the logic of PadConv because `explicit_padding` is equal to Pad + Conv(VALID).\r\n\r\nChanges:\r\n* Support `explicit_padding` in MklConv/MklFuseConv definition and compute function\r\n* Enable rewrite rule in layout pass, and use generic copy function to check whether we missed any attribute while copying from Eigen op\r\n* Add new unit test\r\n\r\nNote the feature can be checked by UT `//tensorflow/python/kernel_tests:conv_ops_test`, I only added new C++ case for fusion kernel.\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["Seems an internal error was happened when migrate this PR, is anything I can do to help it like merging master?", "@Zantares Apologies for the delay. It should show up as merged soon.", "> @Zantares Apologies for the delay. It should show up as merged soon.\r\n\r\nNever mind, thanks for your follow up :)"]}, {"number": 44932, "title": "ERROR: tensorflow", "body": "\r\n**System information**\r\ntf version =2.3.0-rc\r\nSystem- colab-gpu\r\n\r\nReproduce error\r\n`y=tf.TensorArray(tf.float32,size=1,dynamic_size=True)`\r\n```\r\ny.write(0,[[20,1,10]])\r\ny.write(1,[[22,1,10]])\r\ny.write(2,[[23,1,10]])\r\ny.write(3,[[24,1,10]])\r\n```\r\n\r\nERROR\r\n```\r\nERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\r\n<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n    if self.run_code(code, result):  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)  File \"<ipython-input-38-cf79ca55289e>\", line 1, in <module>\r\n    y.write(0,[[20,1,10]])  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\r\n    error_in_function=error_in_function)\r\n==================================\r\nERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\r\n<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n    if self.run_code(code, result):  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)  File \"<ipython-input-38-cf79ca55289e>\", line 2, in <module>\r\n    y.write(1,[[22,1,10]])  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\r\n    error_in_function=error_in_function)\r\n==================================\r\nERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\r\n<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n    if self.run_code(code, result):  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)  File \"<ipython-input-38-cf79ca55289e>\", line 3, in <module>\r\n    y.write(2,[[23,1,10]])  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\r\n    error_in_function=error_in_function)\r\n==================================\r\n<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7f6e011c99e8>\r\n```", "comments": ["I have tried in colab with TF version 2.2, 2.3 and nightly version(`2.5.0-dev20201116`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/1d473053fe135af066190e050a90b658/untitled521.ipynb). Thanks!", "@maxkaustav,\r\nAs per the [Example of TensorArray](https://www.tensorflow.org/api_docs/python/tf/TensorArray#used-in-the-notebooks_1), it should be \r\n\r\n`y = y.write(0,[[20,1,10]])` instead of `y.write(0,[[20,1,10]])`\r\n\r\nbecause it will not modify the Tensor in Place.\r\n\r\nPlease find the [Gist of Working Code](https://colab.research.google.com/gist/rmothukuru/f3761d531c0aa73f38b15e94959967ad/untitled521.ipynb). Thanks!", "@maxkaustav,\r\nCan you please respond to the above comment. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44932\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44932\">No</a>\n", "Hi,\r\n\r\nI use (with TensorFlow 2.6.0):\r\n\r\n```\r\n\r\nimages_array = tf.TensorArray(tf.uint16, size=0, dynamic_size=True, clear_after_read=False) \r\nimages_array = images_array.write(0, images) \r\n```\r\n\r\nand still getting that same error.\r\n", "Reopening as there's a comment that this still reproduces", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi @Arregator! I was able to replicate this issue in 2.7 version too .Attaching [Gist](https://colab.sandbox.google.com/gist/mohantym/7272e8316d3fc5cd251487789890e340/untitled521.ipynb#scrollTo=iO67RlSsh5Pd) for reference . Thanks!", "@maxkaustav,\r\nGiven code works with Tf v 2.8.0. Please take a look at [gist](https://colab.research.google.com/drive/1ZTrFDPRwmwAulu3eQfWKTYD8pon0yy95?usp=sharing). \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\nimages = np.array([[122_222]])\r\nimages_array = tf.TensorArray(tf.uint16, size=0, dynamic_size=True, clear_after_read=False)\r\nimages_array = images_array.write(0, images)\r\n```", "@maxkaustav,\r\nClosing this issue, since its resolved .\r\nPlease feel free to reopen if issue still persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44932\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44932\">No</a>\n"]}, {"number": 44931, "title": "Inconsistent code logic for Model.build", "body": "In this function [`Model.build`](https://github.com/tensorflow/tensorflow/blob/b858de3779cab56d9788b0e87ff437d5dffbd942/tensorflow/python/keras/engine/training.py#L324), the code logic seems buggy. It says that it does not accept `dict` as the type of `input_shape`, and reject the `dict` type [here](https://github.com/tensorflow/tensorflow/blob/b858de3779cab56d9788b0e87ff437d5dffbd942/tensorflow/python/keras/engine/training.py#L359).\r\n\r\nBut then it has [further code](https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/python/keras/engine/training.py#L397) to check for the `dict` type, which makes me wonder that the purpose is to actually allow the usage of `dict` type...\r\n\r\nI post this issue because I want to use `dict` type for the `input_shape` in my project. Right now, I have to override this function in my subclassed model and transform `dict` to `list` in a hard-coded order.", "comments": [">  It says that it does not accept dict as the type of input_shape, and reject the dict type here.\r\n\r\nIt seems to me that `dict` is in `valid_types`\r\nhttps://github.com/tensorflow/tensorflow/blob/d02bdf70273341cb41adc6f6f177b045dca1e470/tensorflow/python/keras/engine/training.py#L358-L359", "Sorry, as @bhack pointed out, the problem has been fixed in the newest version.\r\nI actually encountered this problem in version 2.3.0 here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/python/keras/engine/training.py#L377-L378\r\n"]}, {"number": 44930, "title": "TFLu - refactor apollo3", "body": "first step in revamping ambiq apollo3 support in TFLu as discussed in #44737\r\n\r\nthis PR, applied in isolation, breaks examples. it requires the three accompanying PRs listed below to fix the corresponding examples:\r\n* person detection #44954\r\n* magic wand #44955 \r\n* micro speech #44957 ", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "applied the awaiing response label so that the @gbaned role doesn't request review from me.\r\n\r\n@oclyke feel free to let me know when this is ready for review again. No rush, thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@oclyke  Any update on this PR? Please. Thanks!", "It has been 29 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 44929, "title": "UnimplementedError:  Fused conv implementation does not support grouped convolutions for now. \t", "body": "I am using the FERN 2013 dataset from kaggle for the emojify project. The dataset consists of 48X48 grayscale images. \r\nWhen I go to train the model, I get an error as shown below. I am using tensorflow version 2.3.0\r\n\r\nUnimplementedError:  Fused conv implementation does not support grouped convolutions for now.\r\n\t [[node sequential_3/conv2d_6/Relu (defined at <ipython-input-16-994f59dc933f>:1) ]] [Op:__inference_train_function_3421]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\n\r\nMy code is as follows : \r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\n\r\n\r\ntrain_datagen = ImageDataGenerator(horizontal_flip=True)\r\ntraining_set = train_datagen.flow_from_directory('train/', batch_size=32, class_mode='categorical')\r\n\r\ntest_datagen = ImageDataGenerator(horizontal_flip=True)\r\ntest_set = test_datagen.flow_from_directory('test/', batch_size=32, class_mode='categorical')\r\n\r\n\r\n\r\ncnn = tf.keras.models.Sequential()\r\n\r\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(48, 48, 1)))\r\n\r\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n\r\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(48, 48, 1)))\r\n\r\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n\r\n\r\ncnn.add(tf.keras.layers.Flatten())\r\n\r\ncnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n\r\ncnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\r\n\r\ncnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n\r\ncnn.fit(x=training_set, validation_data=test_set, epochs=25)\r\n\r\n\r\n", "comments": ["@abhishekkuber \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "Please check if it isn't a duplicate of https://github.com/tensorflow/tensorflow/issues/41107", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44929\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44929\">No</a>\n"]}, {"number": 44928, "title": "1.15: Can't write summaries in eager mode", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6eef7e 1.15.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nWriting summaries does not seem to be working. A 40 byte `*.tfevents.*.v2` is created. It does no grow when I call `scalar`. TensorBoard does not see any data in it.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe summary file should get the scalars I am trying to write.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\nfrom tensorflow.python.ops import summary_ops_v2\r\n\r\nwriter = summary_ops_v2.create_file_writer('.')\r\nfor i in range(10):\r\n    with writer.as_default():\r\n        summary_ops_v2.scalar('i', tf.constant(i), step=tf.constant(i))\r\n\r\nwriter.flush()\r\nwriter.close()\r\n```\r\n\r\n**Other info / logs**\r\nNo errors reported", "comments": ["I also tried\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\nwriter = tf.contrib.summary.create_file_writer('.')\r\n\r\nfor i in range(100):\r\n    with writer.as_default():\r\n        tf.contrib.summary.scalar('i', tf.constant(i), step=tf.constant(i))\r\n\r\nwriter.flush()\r\nwriter.close()\r\n```\r\n\r\nwith the same result.", "NVM. The loop needed to be wrapped in `with summary_ops_v2.always_record_summaries():`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44928\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44928\">No</a>\n"]}, {"number": 44927, "title": "[INTEL MKL]Register Eigen bf16 kernels with NoOps to make bf16 kernels(which In clear and infer list) can go through auto-mixed-precision pass.", "body": "This PR is to make user run bf16 models soft and easy.  \r\n  1. target: Register Eigen bf16 kernels with NoOps,for this Ops, they have MKL bf16 kerenels but do not have Eigen bf16 kernels.\r\nin auto-mixed-precision pass,\r\n2.  for clear and infer nodes, if do not register bf16 Eigen kerenls, `SupportsF16` will be False, \r\n  so clear and infer nodes which could be added into allow_set will not be added into allow_set.   so we need to make clear and infer nodes to go through this pass.\r\n3. if we do not register  NoOps for Eigen bf16 kernels, User must understand their Models' detailed messages.  add their ops to ALLOWLIST and remove ops FORM INFERLIST or CLEARLIST.", "comments": ["@penpornk please review this PR, thanks very much.", "@cantonios  Any update on this PR? Please. Thanks!", "Doesn't look like there's any update.  I don't think we're allowing registering of `NoOp`s anymore, unless we can guarantee that they are never called.", "@penpornk Can you please take a look on above comments from @cantonios. Thanks!", "@penpornk  Any update on this PR? Please. Thanks!", "@penpornk Any update on this PR? Please. Thanks!", "@penpornk Any update on this PR? Please. Thanks!", "@penpornk Any update on this PR? Please. Thanks!"]}, {"number": 44926, "title": "bazel build TFLite C++ libtensorflowlite_gpu_delegate.so on OSX clang: error: unsupported option '--linkopt'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.4.0-rc0\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): bazel 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n#### clang --version\r\n```\r\nclang version 9.0.0 (tags/RELEASE_900/final)\r\nTarget: x86_64-apple-darwin19.3.0\r\nThread model: posix\r\nInstalledDir: /usr/local/opt/llvm/bin\r\n```\r\n#### gcc --version\r\n```\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\r\nApple clang version 11.0.0 (clang-1100.0.33.17)\r\nTarget: x86_64-apple-darwin19.3.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n```\r\nclang: error: unsupported option '--linkopt'\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel build --verbose_failures -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\n```\r\n\r\n**Any other info / logs**\r\n```\r\n\u2717 bazel build --verbose_failures -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=308\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --action_env PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages --python_path=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.3 --action_env ANDROID_SDK_API_LEVEL=29 --action_env ANDROID_SDK_HOME=/Users/corey/library/Android/sdk --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /Users/corey/Desktop/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:android_arm64 in file /Users/corey/Desktop/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /Users/corey/Desktop/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Analyzed target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:api2 [action 'Compiling tensorflow/lite/delegates/gpu/gl/api2.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)\r\nSUBCOMMAND: # @ruy//ruy:system_aligned_alloc [action 'Compiling external/ruy/ruy/system_aligned_alloc.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.o' -fPIC -iquote external/ruy -iquote bazel-out/arm64-v8a-opt/bin/external/ruy -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' -Wall -Wextra -Wc++14-compat -Wundef -O3 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c external/ruy/ruy/system_aligned_alloc.cc -o bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu:delegate [action 'Compiling tensorflow/lite/delegates/gpu/delegate.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.o' -fPIC -DEGL_EGLEXT_PROTOTYPES -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DTFLITE_WITH_RUY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/farmhash_archive -iquote bazel-out/arm64-v8a-opt/bin/external/farmhash_archive -iquote external/gemmlowp -iquote bazel-out/arm64-v8a-opt/bin/external/gemmlowp -iquote external/eigen_archive -iquote bazel-out/arm64-v8a-opt/bin/external/eigen_archive -iquote external/ruy -iquote bazel-out/arm64-v8a-opt/bin/external/ruy -iquote external/cpuinfo -iquote bazel-out/arm64-v8a-opt/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/arm64-v8a-opt/bin/external/clog -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/clog/_virtual_includes/clog -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -isystem tensorflow/lite/delegates/gpu/cl -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl -isystem external/farmhash_archive/src -isystem bazel-out/arm64-v8a-opt/bin/external/farmhash_archive/src -isystem external/eigen_archive -isystem bazel-out/arm64-v8a-opt/bin/external/eigen_archive -isystem tensorflow/lite/schema -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/schema -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/delegate.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:preprocessor [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/preprocessor.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/preprocessor.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/workgroups:ideal_workgroup_picker [action 'Compiling tensorflow/lite/delegates/gpu/gl/workgroups/ideal_workgroup_picker.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/workgroups/ideal_workgroup_picker.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:fuse_inline [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:runtime [action 'Compiling tensorflow/lite/delegates/gpu/gl/runtime.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/runtime.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/cl/kernels:converter [action 'Compiling tensorflow/lite/delegates/gpu/cl/kernels/converter.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DVK_NO_PROTOTYPES -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/farmhash_archive -iquote bazel-out/arm64-v8a-opt/bin/external/farmhash_archive -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -isystem tensorflow/lite/delegates/gpu/cl -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl -isystem external/farmhash_archive/src -isystem bazel-out/arm64-v8a-opt/bin/external/farmhash_archive/src -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/cl/kernels/converter.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.o)\r\nERROR: /Users/corey/Desktop/tensorflow/tensorflow/lite/delegates/gpu/gl/BUILD:48:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu/gl:api2' failed (Exit 1): clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nclang: error: unsupported option '--linkopt'\r\nTarget //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build\r\nINFO: Elapsed time: 0.500s, Critical Path: 0.09s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["I tried putting `/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin` in the front of my path so the Apple clang version came first (version 11) but I get the same error:\r\n```\r\nclang --version\r\nApple clang version 11.0.0 (clang-1100.0.33.17)\r\nTarget: x86_64-apple-darwin19.3.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n\r\n```\r\n\u2717 bazel build --verbose_failures -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=308\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --action_env PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages --python_path=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.3 --action_env ANDROID_SDK_API_LEVEL=29 --action_env ANDROID_SDK_HOME=/Users/corey/library/Android/sdk --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /Users/corey/Desktop/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:android_arm64 in file /Users/corey/Desktop/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /Users/corey/Desktop/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Analyzed target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so (1 packages loaded, 2 targets configured).\r\nINFO: Found 1 target...\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:compiler [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/compiler/compiler.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/compiler/compiler.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/compiler/compiler.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:fuse_inline [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:api2 [action 'Compiling tensorflow/lite/delegates/gpu/gl/api2.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:float16_conversions [action 'Compiling tensorflow/lite/delegates/gpu/gl/float16_conversions.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/float16_conversions/float16_conversions.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/float16_conversions/float16_conversions.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/float16_conversions.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/float16_conversions/float16_conversions.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite:external_cpu_backend_context [action 'Compiling tensorflow/lite/external_cpu_backend_context.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/external_cpu_backend_context/external_cpu_backend_context.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/external_cpu_backend_context/external_cpu_backend_context.pic.o' -fPIC -iquote . -iquote bazel-out/arm64-v8a-opt/bin -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' -Wall -Wno-comment -Wno-extern-c-compat '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/external_cpu_backend_context.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/external_cpu_backend_context/external_cpu_backend_context.pic.o)\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:object_accessor [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/object_accessor.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/object_accessor/object_accessor.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/object_accessor/object_accessor.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/object_accessor.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/object_accessor/object_accessor.pic.o)\r\nSUBCOMMAND: # @flatbuffers//grpc/src/compiler:python_generator_private [action 'Compiling external/flatbuffers/grpc/src/compiler/python_generator.cc [for host]', configuration: 15158559fc5b1944e4ce6e035aee82b461449e5710eee080d71036f08292fe25]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=10.15 \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    XCODE_VERSION_OVERRIDE=11.3.1.11C504 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-std=c++11' -iquote external/flatbuffers -iquote bazel-out/host/bin/external/flatbuffers -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/python_generator_private -Ibazel-out/host/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/host/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -MD -MF bazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_objs/python_generator_private/python_generator.d '-frandom-seed=bazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_objs/python_generator_private/python_generator.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=10.15' -g0 -g0 '-std=c++14' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/flatbuffers/grpc/src/compiler/python_generator.cc -o bazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_objs/python_generator_private/python_generator.o)\r\nSUBCOMMAND: # @flatbuffers//src:flatc [action 'Compiling external/flatbuffers/src/idl_gen_text.cpp [for host]', configuration: 15158559fc5b1944e4ce6e035aee82b461449e5710eee080d71036f08292fe25]\r\n(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM=MacOSX \\\r\n    APPLE_SDK_VERSION_OVERRIDE=10.15 \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    XCODE_VERSION_OVERRIDE=11.3.1.11C504 \\\r\n  external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-std=c++11' -iquote external/flatbuffers -iquote bazel-out/host/bin/external/flatbuffers -Ibazel-out/host/bin/external/flatbuffers/src/_virtual_includes/flatc -Ibazel-out/host/bin/external/flatbuffers/src/_virtual_includes/flatc_library -Ibazel-out/host/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/cpp_generator -Ibazel-out/host/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/go_generator -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/java_generator -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/python_generator -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/python_generator_private -Ibazel-out/host/bin/external/flatbuffers/grpc/src/compiler/_virtual_includes/swift_generator -MD -MF bazel-out/host/bin/external/flatbuffers/src/_objs/flatc/idl_gen_text.d '-frandom-seed=bazel-out/host/bin/external/flatbuffers/src/_objs/flatc/idl_gen_text.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=10.15' -g0 -g0 '-std=c++14' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/flatbuffers/src/idl_gen_text.cpp -o bazel-out/host/bin/external/flatbuffers/src/_objs/flatc/idl_gen_text.o)\r\nERROR: /Users/corey/Desktop/tensorflow/tensorflow/lite/delegates/gpu/gl/BUILD:48:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu/gl:api2' failed (Exit 1): clang failed: error executing command \r\n  (cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \\\r\n    PATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \\\r\n    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nclang: error: unsupported option '--linkopt'\r\nTarget //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build\r\nINFO: Elapsed time: 0.937s, Critical Path: 0.13s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "```\r\nbazel build --verbose_failures -c opt --config android_arm64 --copt \\\r\n  -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt \\\r\n  -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\n```\r\nIt does not work because you have `--copt --linkopt` in the build command which pass the `--linkopt` as a c++ build option to clang.", "@vnvo2409 I got that from the suggested build command in the file here: https://github.com/tensorflow/tensorflow/blob/v2.4.0-rc0/tensorflow/lite/delegates/gpu/BUILD#L144\r\n\r\nI can omit that `--linkopt` flag and can build it, but when I use the .so in my android JNI app I get linking errors:\r\n```\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/build/intermediates/ndkBuild/debug/obj/local/arm64-v8a/objs-debug/model/model.o: In function `load_model':\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:26: undefined reference to `tflite::DefaultErrorReporter()'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:26: undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:39: undefined reference to `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:40: undefined reference to `tflite::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:41: undefined reference to `tflite::InterpreterBuilder::operator()(std::__ndk1::unique_ptr<tflite::Interpreter, std::__ndk1::default_delete<tflite::Interpreter> >*)'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:46: undefined reference to `tflite::Interpreter::ModifyGraphWithDelegate(TfLiteDelegate*)'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:49: undefined reference to `tflite::Interpreter::AllocateTensors()'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:52: undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/build/intermediates/ndkBuild/debug/obj/local/arm64-v8a/objs-debug/model/model.o: In function `clean_batch':\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/model.cc:77: undefined reference to `tflite::Interpreter::Invoke()'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/build/intermediates/ndkBuild/debug/obj/local/arm64-v8a/objs-debug/model/model.o: In function `~MutableOpResolver':\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/tensorflow/lite/mutable_op_resolver.h:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD2Ev]+0xc): undefined reference to `vtable for tflite::MutableOpResolver'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/src/main/jni/tensorflow/lite/mutable_op_resolver.h:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD2Ev]+0x10): undefined reference to `vtable for tflite::MutableOpResolver'\r\n/Users/corey/Workspace/omnivor-io/gst-sync-android/app/build/intermediates/ndkBuild/debug/obj/local/arm64-v8a/objs-debug/model/model.o: In function `std::__ndk1::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':\r\n/Users/corey/Library/Android/sdk/ndk/21.3.6528147/sources/cxx-stl/llvm-libc++/include/memory:2338: undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [/Users/corey/Library/Android/sdk/ndk/21.3.6528147/build/core/build-binary.mk:725: /Users/corey/Workspace/omnivor-io/gst-sync-android/app/build/intermediates/ndkBuild/debug/obj/local/arm64-v8a/libmodel.so] Error 1\r\n```", "I am not familiar with TFLite, but I think the problem arises because of dynamic linking. Did you copy all the `.so` file to the right folder ?\r\n\r\n@amahendrakar Could you tag someone else for this issue since I am not familiar with TFLite ? Thank you !", "I fixed those undefined reference errors by building the dependency:\r\n```\r\nbazel build //tensorflow/lite:libtensorflowlite.so --config=android_arm64 --cxxopt='--std=c++11' -c opt\r\n```\r\nand linking it in my android.mk:\r\n```\r\ninclude $(CLEAR_VARS)\r\n\r\nLOCAL_CPP_EXTENSION := .cc\r\nLOCAL_MODULE    := model\r\nLOCAL_SRC_FILES := model.cc\r\nLOCAL_SHARED_LIBRARIES := tensorflowlite\r\nLOCAL_CPPFLAGS := -std=c++14\r\n\r\ninclude $(BUILD_SHARED_LIBRARY)\r\n\r\ninclude $(CLEAR_VARS)\r\n\r\nLOCAL_MODULE    := tensorflowlite\r\nifeq ($(TARGET_ARCH_ABI),armeabi-v7a)\r\n  LOCAL_SRC_FILES := $(LOCAL_PATH)/libtensorflowlite/armv7/libtensorflowlite.so\r\nelse ifeq ($(TARGET_ARCH_ABI),arm64-v8a)\r\n  LOCAL_SRC_FILES := $(LOCAL_PATH)/libtensorflowlite/arm64/libtensorflowlite.so\r\nelse\r\n  $(error Target arch ABI not supported: $(TARGET_ARCH_ABI))\r\nendif\r\n```\r\n\r\nBut, I'd like to resolve this issue by clarifying what the `--linkopt` is for and if it is OK to omit it?", "> But, I'd like to resolve this issue by clarifying what the `--linkopt` is for and if it is OK to omit it?\r\n\r\nI looked around and found \r\nhttps://github.com/tensorflow/tensorflow/blob/5e5730ba9d15a3b328d2b20a01bf8a9762f3711c/tensorflow/lite/delegates/gpu/BUILD#L169\r\n\r\nI think it should be `--copt -fvisibility=hidden --linkopt` but we have already added them in `cc_binary`\r\nhttps://github.com/tensorflow/tensorflow/blob/5e5730ba9d15a3b328d2b20a01bf8a9762f3711c/tensorflow/lite/delegates/gpu/BUILD#L144-L153\r\nso it is omitted and causes an error.\r\n\r\nAs I said above, I know just a little about TF Lite so I think it is OK to omit the option but I am not sure. I think you could make a PR addresses these comments and you could learn more about it through the review process.\r\nhttps://github.com/tensorflow/tensorflow/blob/5e5730ba9d15a3b328d2b20a01bf8a9762f3711c/tensorflow/lite/delegates/gpu/BUILD#L144\r\nhttps://github.com/tensorflow/tensorflow/blob/5e5730ba9d15a3b328d2b20a01bf8a9762f3711c/tensorflow/lite/delegates/gpu/BUILD#L119", "Okay, thank you for the help and information @vnvo2409. I truly appreciate how supportive the tensorflow community is :)\r\n\r\nI've opened [a PR](https://github.com/tensorflow/tensorflow/pull/45049) so I'll close this issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44926\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44926\">No</a>\n"]}, {"number": 44925, "title": "Requantize: Return when we have traced opt path", "body": "We do not need to do whole operation again once we have used optimized path.\r\n\r\nReturned from the function if we trace optimized path.", "comments": ["@advaitjain PTAL.\r\n\r\nCommit picked up from https://github.com/tensorflow/tensorflow/pull/44580\r\n\r\nDiscussion: https://github.com/tensorflow/tensorflow/pull/44580/commits/075e436a5777b50e04d500e9491b0e3360d7e57c "]}, {"number": 44924, "title": "ESP32 build: Fix function prototype warning", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain PTAL.\r\n\r\nMoved this warning fix commit from https://github.com/tensorflow/tensorflow/pull/44580 "]}, {"number": 44923, "title": "[Intel MKL] Improve CNMS performance by removing unnecessary allocation", "body": "Remove unnecessary Tensor allocation in shard function of `NonMaxSuppressionOp` to improve performance.\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["It showed aver 1.13x boost for TF benchmark on Xeon 24 cores sever:\r\n* cmd: \r\nnumactl -N 0 -l bazel run --distdir ./ --config=mkl --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512dq --copt=-DENABLE_INTEL_MKL_BFLOAT16 -c opt //tensorflow/core/kernels/image:non_max_suppression_op_benchmark_test -- --benchmarks=..\r\n* performance (time: ns):\r\n\r\n|  | Before | After |  | Ratio |\r\n|--|--------|-------|--|-------|\r\n| BM_CombinedNMS_cpu_1_500_25_1 | 399481 | 358987 |  | 1.112800742 |\r\n| BM_CombinedNMS_cpu_28_500_25_1 | 5486440 | 4519875 |  | 1.213847728 |\r\n| BM_CombinedNMS_cpu_32_500_25_1 | 6213090 | 5097290 |  | 1.218900632 |\r\n| BM_CombinedNMS_cpu_64_500_25_1 | 9561710 | 7412150 |  | 1.290004924 |\r\n| BM_CombinedNMS_cpu_1_1000_25_1 | 424179 | 396422 |  | 1.070018818 |\r\n| BM_CombinedNMS_cpu_28_1000_25_1 | 5314250 | 4552808 |  | 1.167246675 |\r\n| BM_CombinedNMS_cpu_32_1000_25_1 | 6004140 | 5162220 |  | 1.163092623 |\r\n| BM_CombinedNMS_cpu_64_1000_25_1 | 10013500 | 8462440 |  | 1.183287562 |\r\n| BM_CombinedNMS_cpu_1_1917_25_1 | 512438 | 457544 |  | 1.119975347 |\r\n| BM_CombinedNMS_cpu_28_1917_25_1 | 5885610 | 5407800 |  | 1.088355708 |\r\n| BM_CombinedNMS_cpu_32_1917_25_1 | 6518970 | 6329720 |  | 1.029898637 |\r\n| BM_CombinedNMS_cpu_64_1917_25_1 | 11559360 | 10572240 |  | 1.09336905 |\r\n| BM_CombinedNMS_cpu_1_2500_25_1 | 541120 | 499459 |  | 1.083412252 |\r\n| BM_CombinedNMS_cpu_28_2500_25_1 | 6370380 | 5909860 |  | 1.077924012 |\r\n| BM_CombinedNMS_cpu_32_2500_25_1 | 7378890 | 7020690 |  | 1.051020626 |\r\n| BM_CombinedNMS_cpu_64_2500_25_1 | 12880470 | 12045010 |  | 1.069361503 |\r\n| BM_CombinedNMS_cpu_1_500_25_25 | 386858 | 372761 |  | 1.037817797 |\r\n| BM_CombinedNMS_cpu_28_500_25_25 | 5336070 | 4094011 |  | 1.303384383 |\r\n| BM_CombinedNMS_cpu_32_500_25_25 | 5922370 | 4636258 |  | 1.277403026 |\r\n| BM_CombinedNMS_cpu_64_500_25_25 | 10117390 | 7634420 |  | 1.325233613 |\r\n| BM_CombinedNMS_cpu_1_1000_25_25 | 427361 | 401976 |  | 1.063150536 |\r\n| BM_CombinedNMS_cpu_28_1000_25_25 | 5736430 | 4679833 |  | 1.225776646 |\r\n| BM_CombinedNMS_cpu_32_1000_25_25 | 6296340 | 5358570 |  | 1.175003779 |\r\n| BM_CombinedNMS_cpu_64_1000_25_25 | 11137800 | 9140020 |  | 1.218575014 |\r\n| BM_CombinedNMS_cpu_1_1917_25_25 | 509098 | 470119 |  | 1.08291305 |\r\n| BM_CombinedNMS_cpu_28_1917_25_25 | 6582940 | 5951600 |  | 1.106079038 |\r\n| BM_CombinedNMS_cpu_32_1917_25_25 | 7407920 | 6943350 |  | 1.066908625 |\r\n| BM_CombinedNMS_cpu_64_1917_25_25 | 13471330 | 12545080 |  | 1.073833726 |\r\n| BM_CombinedNMS_cpu_1_2500_25_25 | 551232 | 514749 |  | 1.07087532 |\r\n| BM_CombinedNMS_cpu_28_2500_25_25 | 7313120 | 6974780 |  | 1.048509057 |\r\n| BM_CombinedNMS_cpu_32_2500_25_25 | 8537640 | 8144550 |  | 1.048264177 |\r\n| BM_CombinedNMS_cpu_64_2500_25_25 | 15696100 | 14923410 |  | 1.05177704 |\r\n| BM_CombinedNMS_cpu_1_500_90_1 | 1221129 | 1033969 |  | 1.18101123 |\r\n| BM_CombinedNMS_cpu_28_500_90_1 | 17773180 | 13545650 |  | 1.312095027 |\r\n| BM_CombinedNMS_cpu_32_500_90_1 | 19798990 | 15726650 |  | 1.258945166 |\r\n| BM_CombinedNMS_cpu_64_500_90_1 | 33247360 | 25415620 |  | 1.308146722 |\r\n| BM_CombinedNMS_cpu_1_1000_90_1 | 1268092 | 1091060 |  | 1.162256888 |\r\n| BM_CombinedNMS_cpu_28_1000_90_1 | 18112730 | 15478740 |  | 1.170168244 |\r\n| BM_CombinedNMS_cpu_32_1000_90_1 | 20904650 | 17330430 |  | 1.206239545 |\r\n| BM_CombinedNMS_cpu_64_1000_90_1 | 34740030 | 28996410 |  | 1.198080383 |\r\n| BM_CombinedNMS_cpu_1_1917_90_1 | 1354685 | 1211288 |  | 1.118383902 |\r\n| BM_CombinedNMS_cpu_28_1917_90_1 | 20054770 | 18842380 |  | 1.064343782 |\r\n| BM_CombinedNMS_cpu_32_1917_90_1 | 22062790 | 21464570 |  | 1.027870113 |\r\n| BM_CombinedNMS_cpu_64_1917_90_1 | 39840120 | 36784590 |  | 1.08306549 |\r\n| BM_CombinedNMS_cpu_1_2500_90_1 | 1439269 | 1300566 |  | 1.106648182 |\r\n| BM_CombinedNMS_cpu_28_2500_90_1 | 22530720 | 21259850 |  | 1.059777938 |\r\n| BM_CombinedNMS_cpu_32_2500_90_1 | 24931120 | 23433440 |  | 1.063912085 |\r\n| BM_CombinedNMS_cpu_64_2500_90_1 | 44466850 | 42247150 |  | 1.052540822 |\r\n| BM_CombinedNMS_cpu_1_500_90_90 | 1238081 | 1033964 |  | 1.197412096 |\r\n| BM_CombinedNMS_cpu_28_500_90_90 | 17994650 | 13973010 |  | 1.287814866 |\r\n| BM_CombinedNMS_cpu_32_500_90_90 | 20242910 | 15910030 |  | 1.272336382 |\r\n| BM_CombinedNMS_cpu_64_500_90_90 | 33717970 | 25963350 |  | 1.298675633 |\r\n| BM_CombinedNMS_cpu_1_1000_90_90 | 1282994 | 1112613 |  | 1.153135906 |\r\n| BM_CombinedNMS_cpu_28_1000_90_90 | 18776890 | 16019540 |  | 1.172124168 |\r\n| BM_CombinedNMS_cpu_32_1000_90_90 | 21687930 | 18517860 |  | 1.171189868 |\r\n| BM_CombinedNMS_cpu_64_1000_90_90 | 37452810 | 30763630 |  | 1.217437929 |\r\n| BM_CombinedNMS_cpu_1_1917_90_90 | 1400636 | 1227029 |  | 1.141485654 |\r\n| BM_CombinedNMS_cpu_28_1917_90_90 | 22196240 | 20366790 |  | 1.089825152 |\r\n| BM_CombinedNMS_cpu_32_1917_90_90 | 24578110 | 23156770 |  | 1.061379027 |\r\n| BM_CombinedNMS_cpu_64_1917_90_90 | 43925690 | 41190350 |  | 1.066407302 |\r\n| BM_CombinedNMS_cpu_1_2500_90_90 | 1490548 | 1332396 |  | 1.118697444 |\r\n| BM_CombinedNMS_cpu_28_2500_90_90 | 25294320 | 24141060 |  | 1.047771722 |\r\n| BM_CombinedNMS_cpu_32_2500_90_90 | 28325010 | 26895800 |  | 1.05313878 |\r\n| BM_CombinedNMS_cpu_64_2500_90_90 | 51468900 | 48630660 |  | 1.058363181 |\r\n| BM_CombinedNMS_cpu_1_500_200_1 | 2542996 | 2275922 |  | 1.117347607 |\r\n| BM_CombinedNMS_cpu_28_500_200_1 | 32535650 | 25230710 |  | 1.289525741 |\r\n| BM_CombinedNMS_cpu_32_500_200_1 | 36313270 | 28010680 |  | 1.296408013 |\r\n| BM_CombinedNMS_cpu_64_500_200_1 | 66712080 | 50281100 |  | 1.326782429 |\r\n| BM_CombinedNMS_cpu_1_1000_200_1 | 2589411 | 2476350 |  | 1.045656309 |\r\n| BM_CombinedNMS_cpu_28_1000_200_1 | 34554490 | 28495390 |  | 1.212634395 |\r\n| BM_CombinedNMS_cpu_32_1000_200_1 | 38779680 | 32299400 |  | 1.200631591 |\r\n| BM_CombinedNMS_cpu_64_1000_200_1 | 69986130 | 58272440 |  | 1.201015952 |\r\n| BM_CombinedNMS_cpu_1_1917_200_1 | 2817826 | 2848849 |  | 0.989110339 |\r\n| BM_CombinedNMS_cpu_28_1917_200_1 | 38400100 | 35810370 |  | 1.072317879 |\r\n| BM_CombinedNMS_cpu_32_1917_200_1 | 43073010 | 40816310 |  | 1.055289172 |\r\n| BM_CombinedNMS_cpu_64_1917_200_1 | 80942860 | 75330740 |  | 1.074499733 |\r\n| BM_CombinedNMS_cpu_1_2500_200_1 | 3057867 | 3053973 |  | 1.00127506 |\r\n| BM_CombinedNMS_cpu_28_2500_200_1 | 42819500 | 40763070 |  | 1.050448359 |\r\n| BM_CombinedNMS_cpu_32_2500_200_1 | 48542000 | 46098590 |  | 1.053004007 |\r\n| BM_CombinedNMS_cpu_64_2500_200_1 | 91955950 | 86301920 |  | 1.065514533 |\r\n| BM_CombinedNMS_cpu_1_500_200_200 | 2518033 | 2288389 |  | 1.10035182 |\r\n| BM_CombinedNMS_cpu_28_500_200_200 | 33508650 | 25080850 |  | 1.336025294 |\r\n| BM_CombinedNMS_cpu_32_500_200_200 | 37701400 | 28373620 |  | 1.328748323 |\r\n| BM_CombinedNMS_cpu_64_500_200_200 | 68328880 | 51300380 |  | 1.331937112 |\r\n| BM_CombinedNMS_cpu_1_1000_200_200 | 2629243 | 2509021 |  | 1.0479159 |\r\n| BM_CombinedNMS_cpu_28_1000_200_200 | 36563570 | 29430330 |  | 1.242377167 |\r\n| BM_CombinedNMS_cpu_32_1000_200_200 | 40873050 | 33361410 |  | 1.225159548 |\r\n| BM_CombinedNMS_cpu_64_1000_200_200 | 75398850 | 61409020 |  | 1.227813927 |\r\n| BM_CombinedNMS_cpu_1_1917_200_200 | 2874390 | 2864331 |  | 1.003511815 |\r\n| BM_CombinedNMS_cpu_28_1917_200_200 | 42019360 | 38978110 |  | 1.078024563 |\r\n| BM_CombinedNMS_cpu_32_1917_200_200 | 47758630 | 44354850 |  | 1.076739748 |\r\n| BM_CombinedNMS_cpu_64_1917_200_200 | 90200620 | 83625010 |  | 1.078632098 |\r\n| BM_CombinedNMS_cpu_1_2500_200_200 | 3150977 | 3135167 |  | 1.005042794 |\r\n| BM_CombinedNMS_cpu_28_2500_200_200 | 49284490 | 46001940 |  | 1.071356773 |\r\n| BM_CombinedNMS_cpu_32_2500_200_200 | 54909810 | 51926370 |  | 1.057455201 |\r\n| BM_CombinedNMS_cpu_64_2500_200_200 | 104415320 | 98301830 |  | 1.062191009 |", "Thank you very much for the detailed performance comparison as well! It's very helpful! :)"]}, {"number": 44922, "title": "[CherryPick:2.4]Do not use fused batch norm in the 5D case.", "body": null, "comments": []}, {"number": 44921, "title": "tensorflow.keras.layers.Softmax axis parameter not behaving as described in documentation.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS: Archlinux\r\n- TensorFlow installed from: archlinux repository\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8.6\r\n- CUDA/cuDNN version: not relevant\r\n- GPU model and memory: not relevant\r\n\r\n**Current behavior:**\r\nThe example code raises TypeError: '<=' not supported between instances of 'int' and 'tuple'\r\n\r\n**Expected behavior**\r\nNo error in example code. Both softmax layer and activation from softmax should have the same result (within eps). \r\n\r\nAccording to [documentation](https://keras.io/api/layers/activation_layers/softmax/) axis can be a single value or list of values. keras.activations.softmax is customly written to handle many axis, while the layer uses tensorflow.nn.softmax which treats axis parameter as a single value. I report it as a bug, since I think it should behave as described in documentation, and not the other way around.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nt = tf.convert_to_tensor(np.random.rand(4,2,2))\r\nassert np.all(tf.keras.layers.Softmax(axis=(1,2))(t) - tf.keras.activations.softmax(t, axis=(1,2)) < tf.keras.backend.epsilon()) \r\n```\r\n\r\n", "comments": ["@Lasica \r\nI ran the code shared and face [this issue](https://colab.research.google.com/gist/Saduf2019/f0f3041fb7af9e4325788153148671b4/untitled461.ipynb), please confirm.", "This is weird, I do not have your issue.\r\n\r\nHere's what I get in ipython3:\r\n\r\n```\r\nIn [1]: import tensorflow as tf\r\n   ...: import numpy as np\r\n   ...: t = tf.convert_to_tensor(np.random.rand(4,2,2))\r\n   ...: assert np.all(tf.keras.layers.Softmax(axis=(1,2))(t) - tf.keras.activations.softmax(t, axis=(1,2)) < tf.keras.backend.epsilon())\r\nWARNING:tensorflow:Layer softmax is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\r\n\r\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\r\n\r\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-58e4e0196866> in <module>\r\n      2 import numpy as np\r\n      3 t = tf.convert_to_tensor(np.random.rand(4,2,2))\r\n----> 4 assert np.all(tf.keras.layers.Softmax(axis=(1,2))(t) - tf.keras.activations.softmax(t, axis=(1,2)) < tf.keras.backend.epsilon())\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    983 \r\n    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):\r\n--> 985           outputs = call_fn(inputs, *args, **kwargs)\r\n    986 \r\n    987         if self._activity_regularizer:\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/layers/advanced_activations.py in call(self, inputs)\r\n    282 \r\n    283   def call(self, inputs):\r\n--> 284     return K.softmax(inputs, axis=self.axis)\r\n    285 \r\n    286   def get_config(self):\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/keras/backend.py in softmax(x, axis)\r\n   4607       A tensor.\r\n   4608   \"\"\"\r\n-> 4609   return nn.softmax(x, axis=axis)\r\n   4610 \r\n   4611 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py in softmax(logits, axis, name, dim)\r\n   3638   if axis is None:\r\n   3639     axis = -1\r\n-> 3640   return _softmax(logits, gen_nn_ops.softmax, axis, name)\r\n   3641 \r\n   3642 \r\n\r\n/usr/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py in _softmax(logits, compute_op, dim, name)\r\n   3561   if isinstance(dim, ops.Tensor):\r\n   3562     dim_val = tensor_util.constant_value(dim)\r\n-> 3563   if dim_val is not None and not -shape.ndims <= dim_val < shape.ndims:\r\n   3564     raise errors_impl.InvalidArgumentError(\r\n   3565         None, None,\r\n\r\nTypeError: '<=' not supported between instances of 'int' and 'tuple'\r\n\r\nIn [2]: tf.version\r\nOut[2]: <module 'tensorflow._api.v2.version' from '/usr/lib/python3.8/site-packages/tensorflow/_api/v2/version/__init__.py'>\r\n\r\nIn [3]: tf.version.COMPILER_VERSION\r\nOut[3]: '9.3.0'\r\n\r\nIn [4]: tf.version.VERSION\r\nOut[4]: '2.3.1'\r\n```", "```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nt = tf.convert_to_tensor(np.random.rand(4,2,2), dtype=tf.dtypes.float32)\r\nassert np.all(tf.keras.layers.Softmax(axis=(1,2))(t) - tf.keras.activations.softmax(t, axis=(1,2)) < tf.keras.backend.epsilon())\r\n```\r\nHere's version without the warning that could have caused some issues for you due to default float numpy and epsilon type mismatch.", "@Lasica Agree with you. Looks like this was a bug in `TF 2.3`. However, this was resolved in `tf-nightly`.   \r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/b3336de39d7121952651948a62c3d868/untitled65.ipynb) is a gist with `TF2.3` and [here](https://colab.research.google.com/gist/jvishnuvardhan/88687303fc215c773e83a99cf597b1fa/untitled.ipynb) is a gist with `tf-nightly`. Thanks!\r\n\r\nPlease verify once and close the issue. Thanks!", "I am closing this issue as this was resolved in `tf-nightly`. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44921\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44921\">No</a>\n"]}, {"number": 44920, "title": "[Intel MKL] Updating mkl_layout_test to test for native format mode (Part 1)", "body": "This PR (Part 1)  updates mkl_layout_test to test for native format mode. Also since the file is getting very big, it splits the file into two based on type of test case, fusion vs non-fusion cases.", "comments": ["@mahmoud-abuzaina  Can you please resolve conflicts? Thanks!", "@gbaned I have resolved the conflicts. Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@gbaned We are planning to create a simpler version of this PR. Closing this for now. "]}, {"number": 44919, "title": "Refactor SparseApply[Proximal]Adagrad into classes", "body": "- This is a NFC in preparation for adding GPU implementations.\r\n- It also combines the SparseApplyAdagrad[V2] kernels into a single implementation distinguished by a has_epsilon template parameter.\r\n\r\ncc @nluehr ", "comments": ["Sorry for commenting on this PR. I implemented the GPU kernel of ResourceSparseApplyAdadelta which is still waiting for review (#44347). And I found Adagrad optimizer will also encounter the same problem when dealing with sparse tensor on GPU. So I wonder do you consider implementing the GPU kernel of ResourceSparseApplyAdagrad as a good way to solve it and if this a good part to contribute? Thank you very much. @sanjoy @benbarsdell ", "@irvineoy thanks for your interest. I have implemented a GPU version of the ops in this PR and will be submitting it in a follow-up PR as soon as this one is merged."]}, {"number": 44917, "title": "Slowdown training LSTM on TensorFlow 2.4+", "body": "We are noticing a significant slowdown during training with TensorFlow when using the Tensorflow-Privacy LSTM and GRU optimizers on TF 2.4. In tetsing, this only happens when using the TF-privacy optimizers, but it appears related to a change in the recurrent_v2 module of TensorFlow. \r\n\r\nDoing some testing, it looks like the slowdown was introduced in between these two tf-nightly builds.\r\n\r\n**Describe the expected behavior**\r\nTraining can go from 15 sec/epoch to 2 mins+ per epoch with the latest TF release candidate (tensorflow==2.4.0rc1).\r\ntf-nightly==2.4.0.dev20201019 - 15 sec/epoch\r\n\r\n**Describe the current behavior**\r\ntf-nightly==2.4.0.dev20201020 and TensorFlow RC1 - 2 mins+/epoch\r\n\r\n**System information**\r\nGCP, running on Tesla V100, 16GB RAM, Ubuntu, 8 vCPU, Python 3.8, cuda11, TensorFlow 2.4.0rc0 and nightly installed via PIP. \r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://gist.github.com/zredlined/72305ab04670197869e470b232d22ed4\r\n\r\nIn tensorflow/python/keras/layers/recurrent_v2.py \r\nI think this TensorFlow commit is the culprit-- changing use_new_code() back to True speeds the code back up. The only reference I can find is in the issue above for what looks like an internal Google issue? Any help would be hugely appreciated, on most datasets we have tested with slowdowns are 10-20x. Thanks!\r\n\r\ntensorflow/tensorflow@73b7097.\r\n```\r\ndef _use_new_code():\r\n  return False  # NOTE: changed to False in @73b7097. Changing back to True speeds training up.\r\n\r\n```\r\n\r\n**Other notes/logs**\r\nOriginally posted at https://github.com/tensorflow/privacy/issues/141, opening an issue here as it appears to be an issue within TensorFlow.\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Hi @zredlined, thanks for reporting the issue! Currently, the new code path is disabled due to some other internal issues. In theory, enabling the new code of LSTM/GRU will boost eager performance a lot, but should have little affect to other modes.\r\n\r\nDo you run the training with pure eager mode?", "Yes, we are running the training in eager mode. Can you help me understand what the internal issues are? \r\n\r\nWe use this for a production library, and need to use TF 2.4.x+ to support differentially private training. Any options to re-enable the codepath (as an optional argument, or whatever you recommend) would be awesome. Thanks!", "@amahendrakar Is there any way we can make the codepath for _use_new_code() a user facing option, defaulted to \"off\" like it is now, but that we can enable to true to speed up eager mode training?", "@yhliang2018 the training is run via a call to `model.fit` which IIUC should execute the actual training in graph mode. However, the function optimizer is reporting the failure `function_optimizer failed: Invalid argument: Input 0 of node RMSprop/gradients/loop_body/PartitionedCall_1/pfor/PartitionedCall/gradients/zeros_like/pfor/ZerosLike was passed float from sequential/lstm/PartitionedCall:6 incompatible with expected variant.` so some of the graph mode optimizations seem to not get applied. The above optimizer failure message doesn't appear when monkey-patching `_use_new_code()` to return `True`.", "+ Andreas Terzis from the TF-Privacy team @aterzis-google\r\n\r\n", "@zredlined The new code path with new Case op causes some failures internally, so it's disabled for now. We are working on the fix, and will enabled the new code path eventually. \r\n\r\nIn terms of the training mode, as @misberner mentioned, in your repro, `model.compile` with `run_eagerly=None` is used, so the model training with `model.fit` will be wrapped within `tf.function` which is in graph mode. The main change in the new code path is to warp the layer call on CPU into `tf.function`, which in theory only affects pure eager performance on CPU, and should have no effect on graph performance.\r\n\r\nI see there is a recent change on `apply_gradients` of `DPKerasAdamOptimizer`, and this might affect model performance as well. @schien1729 any insights into it?", "> @yhliang2018 the training is run via a call to `model.fit` which IIUC should execute the actual training in graph mode. However, the function optimizer is reporting the failure `function_optimizer failed: Invalid argument: Input 0 of node RMSprop/gradients/loop_body/PartitionedCall_1/pfor/PartitionedCall/gradients/zeros_like/pfor/ZerosLike was passed float from sequential/lstm/PartitionedCall:6 incompatible with expected variant.` so some of the graph mode optimizations seem to not get applied. The above optimizer failure message doesn't appear when monkey-patching `_use_new_code()` to return `True`.\r\n\r\n@misberner Where is this error message from? Could you provide a colab link for a mini repro?", "@yhliang2018 unfortunately I am unable to reproduce this in a Colab notebook even with GPU enabled (or the native library messages are suppressed). I am able to reproduce it on my box by running the code from the gist linked in the original issue w/o any further modifications.\r\n```\r\n$ pip list | grep -E '^(tf-nightly|tensorflow-privacy)'\r\ntensorflow-privacy                 0.5.1\r\ntf-nightly                         2.4.0.dev20201020\r\n$ curl 'https://gist.githubusercontent.com/zredlined/72305ab04670197869e470b232d22ed4/raw/4d9cd113fe38cce4d0b6494595fea143096541d4/tf_privacy_basic.py' -o tf_privacy_basic.py\r\n$ python tf_privacy_basic.py\r\n[...]\r\nWARNING:tensorflow:Converting IndexedSlices(indices=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/Reshape_1:0\", shape=(1600,), dtype=int32), values=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/Reshape:0\", shape=(1600, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/VariableShape:0\", shape=(2,), dtype=int32)) to a dense representation may make it slow. Alternatively, output the indices and values of the IndexedSlices separately, and handle the vectorized outputs directly.\r\nWARNING:tensorflow:Converting IndexedSlices(indices=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/Reshape_1:0\", shape=(1600,), dtype=int32), values=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/Reshape:0\", shape=(1600, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/embedding/embedding_lookup/VariableShape:0\", shape=(2,), dtype=int32)) to a dense representation may make it slow. Alternatively, output the indices and values of the IndexedSlices separately, and handle the vectorized outputs directly.\r\n2020-11-19 11:46:07.364349: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-19 11:46:07.428010: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\r\n2020-11-19 11:46:07.480035: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:592] function_optimizer failed: Invalid argument: Input 0 of node Adam/gradients/loop_body/PartitionedCall/pfor/PartitionedCall/gradients/zeros_like/pfor/ZerosLike was passed float from sequential/lstm/PartitionedCall:6 incompatible with expected variant.\r\n2020-11-19 11:46:07.707187: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:592] function_optimizer failed: Invalid argument: Input 0 of node Adam/gradients/loop_body/PartitionedCall/pfor/PartitionedCall/gradients/zeros_like/pfor/ZerosLike was passed float from sequential/lstm/PartitionedCall:6 incompatible with expected variant.\r\n2020-11-19 11:46:07.795195: W tensorflow/core/common_runtime/process_function_library_runtime.cc:805] Ignoring multi-device function optimization failure: Invalid argument: Input 0 of node Adam/gradients/loop_body/PartitionedCall/pfor/PartitionedCall/gradients/zeros_like/pfor/ZerosLike was passed float from sequential/lstm/PartitionedCall:6 incompatible with expected variant.\r\n```\r\nNote that I do see the first two warnings when running it in Colab as well, but they don't seem to come from native code. Another possibly relevant piece of information is that the errors disappear when running with `CUDA_VISIBLE_DEVICES=-1`.", "@amahendrakar can we make the codepath selection for _use_new_code() user selectable and defaulted to \"false\"? ", "Is the proposed solution above of making `use_new_code()` user selectable and defaulted to `False` acceptable? Happy to submit a pull request. Thanks!", "@zredlined Sure, making it as a private flag which users can enable it accordingly seems fine to me. Feel free to submit the PR! Thank you!", "@misberner Which TF version do you use in your box? Could you try tf-nightly to see if the error still exists? Feel free to open another issue if it still doesn't work.", "@yhliang2018 this was with `tf-nightly==2.4.0.dev20201020`. I'll try with a more recent nightly and update here. Also note that all 2.4 versions doesn't currently work on Colab with GPU acceleration because of https://github.com/tensorflow/tensorflow/issues/42957", "@misberner Sounds great. Thanks! Does the error happen only on GPU? Given [#42957](https://github.com/tensorflow/tensorflow/issues/42957), How about trying the latest tf-nightly + CPU?", "@zredlined, Sorry for the late response. Is this still an issue for you?\r\n\r\nCan you please try recent TF2.6 or tf-nightly and let us know whether it is persisting? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44916, "title": "undefined reference in tensorflow-lite shared library generated by cmake", "body": "**System information**\r\n- OS Platform and Distribution: macOS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5.0 (from git clone latest)\r\n- Python version: Python 3.8.6\r\n- Installed using virtualenv? pip? conda?: \r\n- CMake version (if compiling from source): 3.18.0\r\n- GCC/Compiler version (if compiling from source): Android ndk r21\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Radeon Pro 555X 4 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI compiled tensorflow-lite with cmake on android. I created an android JNI project. In this application I tried to link together all .a files (compiled by tensorflow-lite) into an .so shared library. In the cpp code I just get the version of the tensorflow-lite lib.\r\nI got this linker error:\r\n```\r\nlibtensorflow-lite.a(platform_profiler.cc.o): In function `tflite::profiling::MaybeCreatePlatformProfiler()':\r\ntensorflow/tensorflow/lite/profiling/platform_profiler.cc:30: undefined reference to\r\n`tflite::profiling::MaybeCreateATraceProfiler()'\r\n```\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\ngit clone --recursive git@github.com:tensorflow/tensorflow.git\r\ncd tensorflow\r\nmkdir tf_build\r\ncd tf_build\r\ncmake -DCMAKE_TOOLCHAIN_FILE=~/Library/Android/sdk/ndk-bundle/build/cmake/android.toolchain.cmake -DANDROID_ABI=arm64-v8a ../tensorflow/lite\r\ncmake --build . -j\r\n```\r\n\r\nIn the cpp source I just get the version of the lib:\r\n```\r\n#include <tensorflow/lite/c/c_api.h>\r\n```\r\n```\r\nprintf(\"TensorFlow C library version %s\\n\", TfLiteVersion());\r\n```\r\n\r\n**Any other info / logs**\r\nI think the problem is in the `tensorflow/tensorflow/lite/CMakeLists.txt`:\r\n```\r\n# TFLite library\r\nadd_library(tensorflow-lite\r\n  ${TFLITE_CORE_API_SRCS}\r\n  ${TFLITE_CORE_SRCS}\r\n  ${TFLITE_C_SRCS}\r\n  ${TFLITE_DELEGATES_FLEX_SRCS}\r\n  ${TFLITE_DELEGATES_GPU_SRCS}\r\n  ${TFLITE_DELEGATES_NNAPI_SRCS}\r\n  ${TFLITE_DELEGATES_SRCS}\r\n  ${TFLITE_DELEGATES_XNNPACK_SRCS}\r\n  ${TFLITE_EXPERIMENTAL_RESOURCE_SRCS}\r\n  ${TFLITE_EXPERIMENTAL_RUY_PROFILER_SRCS}\r\n  ${TFLITE_EXPERIMENTAL_RUY_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_OPT_INTEGER_OPS_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_OPT_SPARSE_OPS_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_OPT_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_REF_INTEGER_OPS_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_REF_SPARSE_OPS_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_REF_SRCS}\r\n  ${TFLITE_KERNEL_INTERNAL_SRCS}\r\n  ${TFLITE_KERNEL_SRCS}\r\n  ${TFLITE_NNAPI_SRCS}\r\n  ${TFLITE_SRCS}\r\n  ${TFLITE_SOURCE_DIR}/profiling/platform_profiler.cc\r\n  ${TFLITE_SOURCE_DIR}/schema/schema_utils.cc\r\n  ${TFLITE_SOURCE_DIR}/tools/optimize/sparsity/format_converter.cc\r\n)\r\n```\r\n\r\nIt includes `${TFLITE_SOURCE_DIR}/profiling/platform_profiler.cc` and this file uses `MaybeCreateATraceProfiler` function. But the implementation of this function is not added to the tensorflow-lite library.\r\nI think a solution can be adding  `${TFLITE_SOURCE_DIR}/profiling/atrace_profiler.cc` to the tensorflow-lite library.", "comments": ["Just verified. I'm working on this.", "It's fixed now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44916\">No</a>\n", "Same problem happens with the Makefile build (``tensorflow/lite/tools/make/Makefile). `profiling/atrace_profiler.cc` is not being built when building for android. But I guess the Makefile build should not support android builds?"]}, {"number": 44915, "title": "Patch the downloaded flatbuffer code to make compatible with TFLM.", "body": "See http://b/173239141 for more details.\r\n\r\nThe modified lines flexbuffers.h as a result of this patching are:\r\n```cc\r\n#if 1\r\n          // TODO(b/173239141): Patched via micro/tools/make/flexbuffers_download.sh\r\n          // Introduce a segfault for an unsupported code path for TFLM.\r\n          return *(static_cast<double*>(nullptr));\r\n#else\r\n          // This is the original code\r\n          double d;\r\n          flatbuffers::StringToNumber(AsString().c_str(), &d);\r\n          return d;\r\n#endif\r\n\r\n```", "comments": ["Once the current PR is merged, we should be able to revert https://github.com/tensorflow/tensorflow/pull/43566/commits/18ec320a50bb491e28d9a7f129fdc02ed50d0b3e and then merge https://github.com/tensorflow/tensorflow/pull/43566"]}, {"number": 44914, "title": "podman tensorflow doesn't work", "body": "I'm using the latest tensorflow image, but the gpu support doesn't work.\r\n\r\nconfigs:\r\n```bash\r\n$ cat /etc/nvidia-container-runtime/config.toml\r\ndisable-require = false\r\n#swarm-resource = \"DOCKER_RESOURCE_GPU\"\r\n#accept-nvidia-visible-devices-envvar-when-unprivileged = true\r\n#accept-nvidia-visible-devices-as-volume-mounts = false\r\n\r\n[nvidia-container-cli]\r\n#root = \"/run/nvidia/driver\"\r\n#path = \"/usr/bin/nvidia-container-cli\"\r\nenvironment = []\r\n#debug = \"/var/log/nvidia-container-toolkit.log\"\r\n#ldcache = \"/etc/ld.so.cache\"\r\nload-kmods = true\r\nno-cgroups = true\r\n#user = \"root:video\"\r\nldconfig = \"@/sbin/ldconfig.real\"\r\n\r\n[nvidia-container-runtime]\r\n#debug = \"/var/log/nvidia-container-runtime.log\"\r\n```\r\n```bash\r\n$ ls /usr/share/containers/oci/hooks.d\r\n01-nvhook.json\r\n```\r\n```bash\r\n$ cat /usr/share/containers/oci/hooks.d/01-nvhook.json\r\n{\r\n  \"version\": \"1.0.0\",\r\n  \"hook\": {\r\n    \"path\": \"/usr/bin/nvidia-container-toolkit\",\r\n    \"args\": [\"nvidia-container-toolkit\", \"prestart\"],\r\n    \"env\": [\"NVIDIA_REQUIRE_CUDA=cuda>=10.1\"]\r\n  },\r\n  \"when\": {\r\n    \"always\": true\r\n  },\r\n  \"stages\": [\"prestart\"]\r\n}\r\n```\r\nInstalled software:\r\n```bash\r\n$ uname -a\r\nLinux pop-os 5.8.0-7630-generic #32~1605108806~20.10~7e52b13-Ubuntu SMP Wed Nov 11 19:10:30 UTC  x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n```bash\r\n$ nvidia-container-cli -V\r\nversion: 1.3.0\r\nbuild date: 2020-10-02T22:32+00:00\r\nbuild revision: 0000000000000000000000000000000000000000\r\nbuild compiler: x86_64-linux-gnu-gcc-10 10.2.0\r\nbuild platform: x86_64\r\nbuild flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -Wdate-time -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -I/usr/include/tirpc -g -O2 -fdebug-prefix-map=/build/libnvidia-container-M6TLiQ/libnvidia-container-1.3.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections -Wl,-Bsymbolic-functions -Wl,-z,relro\r\n```\r\n\r\n```bash\r\n$podman --version\r\npodman version 2.0.6\r\n```\r\nWhat i've tried:\r\nnvidia/cuda (works):\r\n```bash\r\n$ sudo podman run --rm nvidia/cuda nvidia-smi\r\nMon Nov 16 19:31:00 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.38       Driver Version: 455.38       CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 107...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   32C    P8     5W /  N/A |      6MiB /  8119MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nTensorflow CPU(works), GPU (doesn't work): \r\n1:\r\n```bash\r\n$ podman run -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter\r\n[I 19:31:42.533 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\njupyter_http_over_ws extension initialized. Listening on /http_over_websocket\r\n[I 19:31:42.918 NotebookApp] Serving notebooks from local directory: /tf\r\n[I 19:31:42.918 NotebookApp] Jupyter Notebook 6.1.4 is running at:\r\n[I 19:31:42.918 NotebookApp] http://ca7653f39cdb:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe\r\n[I 19:31:42.918 NotebookApp]  or http://127.0.0.1:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe\r\n[I 19:31:42.918 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n[C 19:31:42.924 NotebookApp] \r\n    \r\n    To access the notebook, open this file in a browser:\r\n        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html\r\n    Or copy and paste one of these URLs:\r\n        http://ca7653f39cdb:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe\r\n     or http://127.0.0.1:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe\r\n[I 19:31:46.360 NotebookApp] 302 GET /?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe (127.0.0.1) 1.37ms\r\n[I 19:31:49.905 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret\r\n[W 19:31:49.909 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted\r\n[I 19:31:51.178 NotebookApp] Kernel started: 84611cfd-ff0b-402c-a665-e1ba49828a5f, name: python3\r\n[I 19:31:51.945 NotebookApp] Adapting from protocol version 5.1 (kernel 84611cfd-ff0b-402c-a665-e1ba49828a5f) to 5.3 (client).\r\n2020-11-16 19:31:54.837001: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-11-16 19:31:54.837110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n[I 19:33:52.000 NotebookApp] Saving file at /tensorflow-tutorials/classification.ipynb\r\n```\r\n2:\r\n```bash\r\n$ podman run --gpus all -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter\r\nError: unknown flag: --gpus\r\n```\r\n3:\r\n```bash\r\n$ podman run --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uv -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter\r\n[I 20:00:04.852 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\njupyter_http_over_ws extension initialized. Listening on /http_over_websocket\r\n[I 20:00:05.145 NotebookApp] Serving notebooks from local directory: /tf\r\n[I 20:00:05.145 NotebookApp] Jupyter Notebook 6.1.4 is running at:\r\n[I 20:00:05.146 NotebookApp] http://0c86b063117d:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf\r\n[I 20:00:05.146 NotebookApp]  or http://127.0.0.1:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf\r\n[I 20:00:05.146 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n[C 20:00:05.150 NotebookApp] \r\n    \r\n    To access the notebook, open this file in a browser:\r\n        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html\r\n    Or copy and paste one of these URLs:\r\n        http://0c86b063117d:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf\r\n     or http://127.0.0.1:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf\r\n[I 20:00:10.034 NotebookApp] 302 GET /?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf (127.0.0.1) 1.16ms\r\n[I 20:00:13.545 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret\r\n[W 20:00:13.547 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted\r\n[I 20:00:14.779 NotebookApp] Kernel started: 07ad74de-a8a8-451e-a579-af2a04dd54ca, name: python3\r\n[I 20:00:15.596 NotebookApp] Adapting from protocol version 5.1 (kernel 07ad74de-a8a8-451e-a579-af2a04dd54ca) to 5.3 (client).\r\n2020-11-16 20:00:17.797706: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-11-16 20:00:17.797761: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n```\r\n4:\r\n```bash\r\npodman run --hooks-dir /usr/share/containers/oci/hooks.d  -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter\r\n[I 20:43:01.225 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\njupyter_http_over_ws extension initialized. Listening on /http_over_websocket\r\n[I 20:43:01.535 NotebookApp] Serving notebooks from local directory: /tf\r\n[I 20:43:01.535 NotebookApp] Jupyter Notebook 6.1.4 is running at:\r\n[I 20:43:01.535 NotebookApp] http://91398c24ef54:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6\r\n[I 20:43:01.535 NotebookApp]  or http://127.0.0.1:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6\r\n[I 20:43:01.535 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n[C 20:43:01.540 NotebookApp] \r\n    \r\n    To access the notebook, open this file in a browser:\r\n        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html\r\n    Or copy and paste one of these URLs:\r\n        http://91398c24ef54:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6\r\n     or http://127.0.0.1:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6\r\n[I 20:43:08.599 NotebookApp] 302 GET /?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6 (127.0.0.1) 0.62ms\r\n[I 20:43:11.836 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret\r\n[W 20:43:11.845 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted\r\n[I 20:43:13.118 NotebookApp] Kernel started: 686ca286-3d4f-4323-b2c2-dbb27f5ad297, name: python3\r\n[I 20:43:13.897 NotebookApp] Adapting from protocol version 5.1 (kernel 686ca286-3d4f-4323-b2c2-dbb27f5ad297) to 5.3 (client).\r\n2020-11-16 20:43:16.871350: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-11-16 20:43:16.871395: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n```\r\nProblem:\r\n```bash\r\nCould not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n```\r\nQuestion:\r\nWhat am i doing wrong?\r\n\r\nPS: I've never made a support ticket so I don't know if i shared enough information.", "comments": ["Have to run it like this: \r\n\r\npodman run --hooks-dir /usr/share/containers/oci/hooks.d  -it -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\r\n\r\nSorry for bothering. "]}, {"number": 44913, "title": "Issue in Bazel build for CUDA 11.1", "body": "\r\n**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5.0 (from git clone latest)\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): bazel 3.7.0\r\n- CUDA/cuDNN version: 11.1 with CuDNN 8.0.5\r\n- GPU model and memory: GTX 1070\r\n\r\nSince I want PTX compilation in Windows (available with CUDA 11.1), I was building TensorFlow with Bazel. I get the following error after a while\r\n```\r\nERROR: C:/users/joehr/_bazel_joehr/6zdjxw7k/external/com_google_protobuf/BUILD:866:17: ProtoCompile external/com_google_protobuf/python/google/protobuf/compiler/plugin_pb2.py failed (Exit -1073741795): protoc.exe failed: error executing command\r\n  cd C:/users/joehr/_bazel_joehr/6zdjxw7k/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.1\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\Windows;C:\\Windows\\System32;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Users/joehr/anaconda3/envs/bleedingEdge38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/joehr/anaconda3/envs/bleedingEdge38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0\r\n    SET TF_NEED_CUDA=1\r\n  bazel-out/x64_windows-opt/bin/external/com_google_protobuf/protoc.exe --python_out=bazel-out/x64_windows-opt/bin/external/com_google_protobuf/python -Iexternal/com_google_protobuf/python -Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/python bazel-out/x64_windows-opt/bin/external/com_google_protobuf/python/google/protobuf/compiler/plugin.proto\r\nExecution platform: @local_execution_config_platform//:platform\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 19.771s, Critical Path: 2.68s\r\nINFO: 11 processes: 10 internal, 1 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nI tried to install protoc windows thinking that the protoc is not working but there's no difference. \r\n\r\nI used [this](https://medium.com/@dev.ashurai/protoc-protobuf-installation-on-windows-linux-mac-d70d5380489d) link for installing protoc and it tested fine as below\r\n```\r\nprotobuf:x64-windows                               3.13.0#2         Protocol Buffers - Google's data interchange format\r\nprotobuf:x86-windows                               3.13.0#2         Protocol Buffers - Google's data interchange format\r\n```\r\n\r\nI looked up the section mentioned by the code \"866:17\" and got this particular function\r\n```\r\npy_proto_library(\r\n    name = \"protobuf_python\",\r\n    srcs = COPIED_WELL_KNOWN_PROTOS,\r\n    include = \"python\",\r\n    data = select({\r\n        \"//conditions:default\": [],\r\n        \":use_fast_cpp_protos\": [\r\n            \":python/google/protobuf/internal/_api_implementation.so\",\r\n            \":python/google/protobuf/pyext/_message.so\",\r\n        ],\r\n    }),\r\n    default_runtime = \"\",\r\n    protoc = \":protoc\",\r\n    py_libs = [\r\n        \":python_srcs\",\r\n        \"//external:six\",\r\n    ],\r\n    py_extra_srcs = glob([\"python/**/__init__.py\"]),\r\n    srcs_version = \"PY2AND3\",\r\n    visibility = [\"//visibility:public\"],\r\n)\r\n```\r\n \r\nTo my knowledge, it looks fine and no broken links. Please help.", "comments": ["Are you using `TensorFlow version: 2.5.0` source as you claimed in ticket template?", "@JoeHRIsaac,\r\nAlso, could you please let us know if you are using a proxy? Please take a look at similar issue [tink/issues/360](https://github.com/google/tink/issues/360) for reference.\r\n\r\nThanks!", "@bhack I used the code from git like I said. I ran the following on 17th November which is supposedly TF 2.5.0. Am I wrong?\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\n```\r\n\r\n@amahendrakar No I'm not using any proxy. Direct download of Bazel and Git clone of tensorflow master. Also direct install of CUDA 11.1 and CudNN\r\n\r\n", "> @bhack I used the code from git like I said. I ran the following on 17th November which is supposedly TF 2.5.0. Am I wrong?\r\n\r\nYes it is ok", "Does it build file without CUDA?  If not, then CUDA 11.1 is probably a red herring.\r\n\r\n@mihaimaruseac have you seen this before?", "I haven't tried building without the CUDA. I required cuda for my work. Should I try to build without cuda?", "Even if you ultimately need CUDA, building without CUDA will let us establish if this is a CUDA-specific issue.", "Haven't seen this before. Can you try running a `bazel clean --expunge` before building again?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44913\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44913\">No</a>\n"]}, {"number": 44911, "title": "Add GPU implementation for tf.segment_mean", "body": "According to @sanjoy 's [suggestion](https://github.com/tensorflow/tensorflow/pull/44436#pullrequestreview-523916485) in #44436 , I split out the implementation of segment mean and now proposal this pr.\r\n\r\nSince these two pr have some common codes, and the other one is currently approved (but not yet merged), I have included all relevant codes in this pr. If the previous code is changed, I will make the corresponding modification here in time.", "comments": ["@sanjoy Could you please have a look?", "@sanjoy Thanks for your review! Before making the corresponding changes, maybe we can further discuss the implementation of this op.\r\n\r\n\r\n> Instead of writing something custom, have you considered implementing segment mean as:\r\n\r\n\r\n\r\nDo you mean that we can implement `tf.segment_mean` just like the implementation of [tf.math.unsorted_segment_mean](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L4126), i.e. realize the equivalent function of `tf.segment_mean` through `tf.segment_sum` & `tf.ones` at the python level?\r\n\r\nIf so, I do have considered in fact. However, what defeated me was, that tensorflow had a stable cpu op implementation for `tf.segment_mean` already but this idea should remove the existing `tf.segment_mean` cpu implementation (right?). I think deleting an existing implementation may encounter greater verification costs, WDYT?", "> Do you mean that we can implement `tf.segment_mean` just like the implementation of [tf.math.unsorted_segment_mean](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L4126), i.e. realize the equivalent function of `tf.segment_mean` through `tf.segment_sum` & `tf.ones` at the python level?\r\n\r\nNo, I meant doing it as an implementation detail of the `OpKernel`.", "@firejq  Any update on this PR? Please. Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n", "@sanjoy Sorry that I replied so late because some other jobs haunt me before.. \r\n\r\n> No, I meant doing it as an implementation detail of the `OpKernel`.\r\n\r\nAccording to my previous test, although this implementation is simpler, the performance is not good due to the introduction of multiple kernels startup overhead, so I choose to implement it separately.  If we reach a consensus on this point, I would be nice to reopen and continue to improve this pr code. :)\r\n\r\n", "> the performance is not good due to the introduction of multiple kernels startup overhead\r\n\r\nI don't think you need to launch multiple kernels -- you can conceptually \"fuse\" the `tf.ones` into the `tf.segment_sum`, avoiding the temporary array and the kernel launch.\r\n\r\nMore concretely, I'm suggesting you parameterize the segment sum CUDA kernel on a `bool inputs_are_ones` template parameter which states whether the input is a real buffer or whether the kernel should pretend it is all ones (i.e. when `inputs_are_ones` is `true` the kernel won't load from the input (and the input buffer can just be null) and instead use `1`).  This can then be used to implement `SetSegmentFreq` more simply I think."]}]