[{"number": 49978, "title": "TFlite conversion incompatibility with tf.Data", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Big Sur (11.4)\r\n- TensorFlow installation (pip package or built from source): Pip package\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0\r\n\r\n### 2. Code\r\n\r\nThis code has been tested on a colab instance with TF 2.5.0 and reproduces the error.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nbatch_size = 100\r\nds = tf.data.Dataset.from_tensor_slices((np.random.normal(size=(10000,10)), np.zeros(10000))) \\\r\n.batch(batch_size) \\\r\n.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(256),\r\n  tf.keras.layers.Dense(1)\r\n])\r\n\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\nmodel.compile(optimizer=optimizer,\r\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False))\r\nmodel.fit(ds,\r\n          epochs=1)\r\n\r\n\r\nmodel.save(\"test_model\",save_format=\"tf\")\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('test_model',signature_keys=['serving_default'])\r\ntflite_model = converter.convert()\r\n```\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nThe code fails to convert the above TF model, and yields the following exception:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    293                                                  debug_info_str,\r\n--> 294                                                  enable_mlir_converter)\r\n    295       return model_str\r\n\r\n4 frames\r\nException: <unknown>:0: error: loc(callsite(callsite(\"sequential/dense/Cast@__inference__wrapped_model_711\" at \"StatefulPartitionedCall@__inference_signature_wrapper_888\") at \"StatefulPartitionedCall\")): 'tf.Cast' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': \r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \r\nTF Select ops: Cast\r\nDetails:\r\n\ttf.Cast {Truncate = false, device = \"\"}\r\n\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    295       return model_str\r\n    296     except Exception as e:\r\n--> 297       raise ConverterError(str(e))\r\n    298 \r\n    299   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: <unknown>:0: error: loc(callsite(callsite(\"sequential/dense/Cast@__inference__wrapped_model_711\" at \"StatefulPartitionedCall@__inference_signature_wrapper_888\") at \"StatefulPartitionedCall\")): 'tf.Cast' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': \r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \r\nTF Select ops: Cast\r\nDetails:\r\n\ttf.Cast {Truncate = false, device = \"\"}\r\n```\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nConverting the above model works fine if the tf.Data input pipeline is replaced with numpy arrays. Is it possible to get this to work with the tf.Data API? It seems minimally complex, it's unclear where the issue is arising. Thank you.", "comments": ["Please use the Select TF option during conversion. https://www.tensorflow.org/lite/guide/ops_select"]}, {"number": 49977, "title": "Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64bit)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.15.0\r\n- Python version: `Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)] on win32`\r\n- Installed using virtualenv? pip? conda?: I installed tensorflow-gpu==1.15 inside a conda environment, and this automatically installed cuDNN too, but I had installed manually the Cuda Computing Toolkit and I also added the following environment variables `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin` and `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64`, and there's also this system variable `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0` and `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3` (with different names: yes, I installed 2 versions of the Cuda Computing Toolkit because, after having installed the latest one, v11.3, I realised that TF 1.15 requires version 10.0)\r\n- CUDA/cuDNN version: `cudatoolkit               10.0.130                      0` and `cudnn                     7.6.5                cuda10.0_0`  (shown with `conda list`)\r\n- GPU model and memory: `NVIDIA Quadro RTX 4000 major: 7 minor: 5 memoryClockRate(GHz): 1.545`\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am getting the following errors\r\n\r\n```\r\nname: NVIDIA Quadro RTX 4000 major: 7 minor: 5 memoryClockRate(GHz): 1.545\r\npciBusID: 0000:01:00.0\r\n2021-06-01 19:41:45.931750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2021-06-01 19:41:45.931822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2021-06-01 19:41:45.931893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\r\n2021-06-01 19:41:45.931965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\r\n2021-06-01 19:41:45.932036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\r\n2021-06-01 19:41:45.932109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\r\n2021-06-01 19:41:45.932181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-06-01 19:41:45.932274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2021-06-01 19:41:45.932356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-06-01 19:41:45.932427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2021-06-01 19:41:45.932472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2021-06-01 19:41:45.932569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6710 MB memory) -> physical GPU (device: 0, name: NVIDIA Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2021-06-01 19:41:51.889919: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.\r\n2021-06-01 19:41:51.889989: W tensorflow/core/profiler/lib/profiler_session.cc:213] Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.\r\n2021-06-01 19:41:51.893350: I tensorflow/core/platform/default/device_tracer.cc:588] Collecting 0 kernel records, 0 memcpy records.\r\n2021-06-01 19:41:51.893617: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.\r\n2021-06-01 19:41:52.546494: I tensorflow/core/profiler/lib/profiler_session.cc:205] Profiler session started.\r\n```\r\n\r\nalthough, as I said, cuDNN seems to be installed (by conda automatically when installing tensorflow-gpu 1.15), the Cuda Computing Toolkit is also installed, and I added the following paths to the system variables\r\n\r\n1.  `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin` (only to my user variables),\r\n2.  `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64` (user variables)\r\n3.  `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0` (system variable)\r\n4.  `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3` (system variable)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI don't have the exact sequence because I cannot share my code right now. But, as you can see above, the DDLs like `cudart64_100.dll` are successfully loaded, so I don't understand why I get this error\r\n\r\n> CUPTI error: CUPTI could not be loaded or symbol could not be found.\r\n\r\nIt's so annoying because I don't know whether I am actually using the GPU. Right now, my experiments take a long time and I don't know if this is due to the fact that I am or not using the GPU.\r\n\r\n**Any other info / logs**\r\n\r\nI need to use tensorflow v 1.15 because I am using another library that use this version. Moreover, I am aware of similar questions/issues on the web, but people seem to suggest to add `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64` to the system variables (e.g. [here](https://stackoverflow.com/a/57592360)), which I already did. \r\n", "comments": ["@nbro \r\nThere is no active support for tf 1.x, please upgrade to 2.x and ensure you have the path variable updated for cuda and let us know in case you face any issues.", "@Saduf2019 I said above that I cannot update to TF 2.0 because I am using a library that requires TF 1.15, i.e. stable-baselines. So, could you please help me with this issue? This was a very common issue in the past, so there must be a solution to this problem (I guess).", "@nbro \r\nInside your CUDA installation directory, there is an extras\\CUPTI\\lib64 directory that contains the cupti64_101.dll that is trying to be loaded. Adding that directory to your path should resolve the issue,please refer to this [link](https://stackoverflow.com/questions/56860180/tensorflow-cuda-cupti-error-cupti-could-not-be-loaded-or-symbol-could-not-be).\r\n\r\nIssues with same error: #33002, [link](https://forum.level1techs.com/t/fix-cuda-for-tensorflow-2-0/155135/2),[link2](https://github.com/tensorflow/tensorflow/issues/43030#issuecomment-736206189)", "@Saduf2019 I said in the post above that `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64` was added to my environment variables. Inside my folder `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64`, I have `cupti64_100.dll` (rather than `cupti64_101.dll`), but I don't think this is the problem because, as far as I understood, TF 1.15 requires CUDA v10.0, which seems to come with `cupti64_100.dll`. Anyway, I already said above that I looked at that Stack Overflow post. Those 2 last links are for TF 2.", "@Saduf2019 Ok, I found the problem. I was indeed adding `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64` as a **user** variable, but I was adding this path as a separate variable named something like `CUPTI (for TensorFlow)`, while what I had to do was to add this path to the user variable called `Path` that is (or should be) already there as a user variable.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49977\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49977\">No</a>\n"]}, {"number": 49976, "title": "model.layers is empty after upgrading to 2.5.0", "body": "**System information**\r\n- custom CNN model\r\n- Linux Ubuntu 20.04\r\n- TensorFlow installed from pip\r\n- TensorFlow version: v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: Quadro K5200\r\n\r\nI upgraded Tensorflow  to 2.5.0 through pip so I could get support from Cuda 11.1.\r\nAfter this upgrade, when I tried to access keras.optimizers.Adam, it wasn't there anymore, so I switched to tf.keras as it's recommended I see, but doing so I then realized that model.layers is now an empty list after building my model:\r\n\r\n        self.model = keras.models.Model(inputs=[input_img], outputs=[outputs])\r\n        self.model.compile(optimizer=keras.optimizers.Adam(),\r\n                           loss=\"binary_crossentropy\",\r\n                           metrics=[\"accuracy\"])\r\n        print(self.model.layers) -> returns empty list\r\n\r\nTried updating tensorflow to a different computer, same issue with model.layers but I can still access keras.optimizers.Adam (this one has a slightly different setup as I'm using miniconda).", "comments": ["@Earl7Fx3 Did you train the model? Can you please share a simple standalone code to reproduce the issue? Thanks!", "Thanks for your reply!\r\nI actually trained the model earlier, and had issues whiles trying to save it... Debugging it, I ended up figuring that model.layers was empty.\r\nHere is a simple standalone code:\r\n\r\n```python\r\nimport keras\r\nimport keras.layers as kl\r\n\r\ndef cv2d(input_tensor, n_filters, kernel_size=3, batchnorm=True):\r\n    # first layer\r\n    cv = kl.convolutional.Conv2D(filters=n_filters,\r\n                                 kernel_size=(kernel_size, kernel_size),\r\n                                 kernel_initializer=\"he_normal\",\r\n                                 padding=\"same\")(input_tensor)\r\n    if batchnorm:\r\n        cv = kl.BatchNormalization()(cv)\r\n    cv = kl.Activation(\"relu\")(cv)\r\n    # second layer\r\n    cv = kl.convolutional.Conv2D(filters=n_filters,\r\n                                 kernel_size=(kernel_size, kernel_size),\r\n                                 kernel_initializer=\"he_normal\",\r\n                                 padding=\"same\")(cv)\r\n    if batchnorm:\r\n        cv = kl.BatchNormalization()(cv)\r\n    cv = kl.Activation(\"relu\")(cv)\r\n    return cv\r\n\r\n\r\ndef run():\r\n    params = {'img_size': (256, 256, 1),\r\n                  'n_filters': 16,\r\n                  'batchnorm': True,\r\n                  'dropout': 0.5}\r\n    img_size = params['img_size']\r\n    n_filters = params['n_filters']\r\n    batchnorm = params['batchnorm']\r\n    dropout = params['dropout']\r\n    input_img = kl.Input(img_size, name='img')\r\n    c1 = cv2d(input_img, n_filters=n_filters*1,\r\n                                kernel_size=3, batchnorm=batchnorm)\r\n    p1 = kl.pooling.MaxPooling2D((2, 2))(c1)\r\n    p1 = kl.Dropout(dropout*0.5)(p1)\r\n    \r\n    c2 = cv2d(p1, n_filters=n_filters*2, kernel_size=3,\r\n                                batchnorm=batchnorm)\r\n    \r\n    outputs = kl.convolutional.Conv2D(1, (1, 1), activation='sigmoid')(c2)\r\n    model = keras.models.Model(inputs=[input_img], outputs=[outputs])\r\n    model.compile(optimizer=keras.optimizers.Adam(),\r\n                  loss=\"binary_crossentropy\",\r\n                  metrics=[\"accuracy\"])\r\n    print(model.layers)\r\n```\r\n\r\nwhich oututs:\r\n\r\n```python\r\n[<keras.engine.input_layer.InputLayer object at 0x7f2e96abb1c0>, <keras.layers.convolutional.Conv2D object at 0x7f2f2c176310>, <keras.layers.normalization_v2.BatchNormalization object at 0x7f2ec1d75e50>, <keras.layers.core.Activation object at 0x7f2e9c3009d0>, <keras.layers.convolutional.Conv2D object at 0x7f2e9c34ae20>, <keras.layers.normalization_v2.BatchNormalization object at 0x7f2e9c070370>, <keras.layers.core.Activation object at 0x7f2ec1349a60>, <keras.layers.pooling.MaxPooling2D object at 0x7f2ec1bf9dc0>, <keras.layers.core.Dropout object at 0x7f2ec1bf9820>, <keras.layers.convolutional.Conv2D object at 0x7f2e96fa45e0>, <keras.layers.normalization_v2.BatchNormalization object at 0x7f2e96fa4a00>, <keras.layers.core.Activation object at 0x7f2e9c304e50>, <keras.layers.convolutional.Conv2D object at 0x7f2e96aa55b0>, <keras.layers.normalization_v2.BatchNormalization object at 0x7f2e96aa5d30>, <keras.layers.core.Activation object at 0x7f2e9c4ff5b0>, <keras.layers.convolutional.Conv2D object at 0x7f2e9c4ff430>]\r\n```\r\n\r\nReplacing \"import keras\" by \"import tensorflow.keras as keras\" outputs an empty list.\r\n", "@Earl7Fx3 I updated couple of lines and imported `keras` and `keras.layers`  from `tensorflow`. With those modiications, i don't see any difference in the output from `keras` or `tensorflow.keras`. As `tf.keras.` has no `convolutional` attribute,  I updated `Conv2D` layer in your code.  Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/28bcd8d72ff42b2177bff08354e3bbf4/untitled.ipynb).\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers as kl\r\n```\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n", "I just checked, it now works with your modifications.\r\nThanks a lot for going through this!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49976\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49976\">No</a>\n"]}, {"number": 49975, "title": "terminate called after throwing an instance of 'std::bad_alloc'   what():  std::bad_alloc", "body": " I have  Cross-compile the  .a file and Cross-compile the label_image , but when I put  files  in the armv7, it is a error that _[./label_iamge:cannot execute binary file :Exec format error](url). I have check  the Cross-compile process ,it is seem that's ok.\r\nCross-compile tools :  g++-arm-linux-gnueabihf \u3001gcc-arm-linux-gnueabihf\r\narm: NXP i.MX6Q Cortex-A9 \r\nroot@EmbedSky-Board:/xzy/mix# lscpu\r\n_Architecture:          armv7l\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nModel name:            ARMv7 Processor rev 10 (v7l)\r\nCPU max MHz:           996.0000\r\nCPU min MHz:           792.0000\r\nroot@EmbedSky-Board:/xzy/mix# cat /proc/cpuinfo\r\nprocessor       : 0 \r\nmodel name      : ARMv7 Processor rev 10 (v7l)\r\nBogoMIPS        : 6.00\r\nFeatures        : half thumb fastmult vfp edsp neon vfpv3 tls vfpd32\r\nCPU implementer : 0x41\r\nCPU architecture: 7\r\nCPU variant     : 0x2\r\nCPU part        : 0xc09\r\nCPU revision    : 10_\r\n", "comments": ["@xzy-666 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem\r\nThanks!", "hello\uff0c\r\n PC platform is linux ubuntu 16.04 ,python3.5.2 and armv7 is   Linux version 4.1.15  ,python3.5.2 . \r\nit is not  Mobile device that andriod or ios . it is arm-linux.\r\nsorry, I not install TensorFlow, so , i just Cross-compile TF lite, tensorflow version 2.3.2\r\nNow , I have knowed that this error is because using gcc compiler. The board needs to use gcc-linaro-5.3-20190918.tar.bz2 compiler. I have installed this compiler. Do You know how to compile tflite with the compiler? Thanks!", "@xzy-666 ,\r\n\r\nCan you please provide the error you are facing which helps us to analyse the issue.\r\nAlso please take a look at this link for more information.[Link](https://www.tensorflow.org/lite/guide/build_arm).  Thanks!", "@tilakrayal \r\nhello\uff0cI have use the command that is \"**./tensorflow/lite/tools/make/build_rpi_lib.sh** '' and \"**./tensorflow/lite/tools/make/build_rpi_lib.sh label_image** ''. I have get libtensorflow-lite.a and label_image.but, I put the files on the arm . using the conmmand that is  ''.**/label_image -v 4 -m ./mobilenet_v1_1.0_224.tflite -i ./grace_hopper.jpg    -l labels.txt**'' \uff0c I get the error .\r\n_resolved reporter\r\ntensors size: 88\r\nnodes size: 31\r\ninputs: 1\r\ninput(0) name: input\r\n0: MobilenetV1/Conv2d_0/weights, 3456, 1, 0, 0\r\n1: MobilenetV1/Conv2d_10_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n2: MobilenetV1/Conv2d_10_pointwise/weights, 1048576, 1, 0, 0\r\n3: MobilenetV1/Conv2d_11_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n4: MobilenetV1/Conv2d_11_pointwise/weights, 1048576, 1, 0, 0\r\n5: MobilenetV1/Conv2d_12_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n6: MobilenetV1/Conv2d_12_pointwise/weights, 2097152, 1, 0, 0\r\n7: MobilenetV1/Conv2d_13_depthwise/depthwise_weights, 36864, 1, 0, 0\r\n8: MobilenetV1/Conv2d_13_pointwise/weights, 4194304, 1, 0, 0\r\n9: MobilenetV1/Conv2d_1_depthwise/depthwise_weights, 1152, 1, 0, 0\r\n10: MobilenetV1/Conv2d_1_pointwise/weights, 8192, 1, 0, 0\r\n11: MobilenetV1/Conv2d_2_depthwise/depthwise_weights, 2304, 1, 0, 0\r\n12: MobilenetV1/Conv2d_2_pointwise/weights, 32768, 1, 0, 0\r\n13: MobilenetV1/Conv2d_3_depthwise/depthwise_weights, 4608, 1, 0, 0\r\n14: MobilenetV1/Conv2d_3_pointwise/weights, 65536, 1, 0, 0\r\n15: MobilenetV1/Conv2d_4_depthwise/depthwise_weights, 4608, 1, 0, 0\r\n16: MobilenetV1/Conv2d_4_pointwise/weights, 131072, 1, 0, 0\r\n17: MobilenetV1/Conv2d_5_depthwise/depthwise_weights, 9216, 1, 0, 0\r\n18: MobilenetV1/Conv2d_5_pointwise/weights, 262144, 1, 0, 0\r\n19: MobilenetV1/Conv2d_6_depthwise/depthwise_weights, 9216, 1, 0, 0\r\n20: MobilenetV1/Conv2d_6_pointwise/weights, 524288, 1, 0, 0\r\n21: MobilenetV1/Conv2d_7_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n22: MobilenetV1/Conv2d_7_pointwise/weights, 1048576, 1, 0, 0\r\n23: MobilenetV1/Conv2d_8_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n24: MobilenetV1/Conv2d_8_pointwise/weights, 1048576, 1, 0, 0\r\n25: MobilenetV1/Conv2d_9_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n26: MobilenetV1/Conv2d_9_pointwise/weights, 1048576, 1, 0, 0\r\n27: MobilenetV1/Logits/AvgPool_1a/AvgPool, 4096, 1, 0, 0\r\n28: MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd, 4004, 1, 0, 0\r\n29: MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias, 4004, 1, 0, 0\r\n30: MobilenetV1/Logits/Conv2d_1c_1x1/weights, 4100096, 1, 0, 0\r\n31: MobilenetV1/Logits/SpatialSqueeze, 4004, 1, 0, 0\r\n32: MobilenetV1/MobilenetV1/Conv2d_0/Conv2D_bias, 128, 1, 0, 0\r\n33: MobilenetV1/MobilenetV1/Conv2d_0/Relu6, 1605632, 1, 0, 0\r\n34: MobilenetV1/MobilenetV1/Conv2d_10_depthwise/Relu6, 401408, 1, 0, 0\r\n35: MobilenetV1/MobilenetV1/Conv2d_10_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n36: MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n37: MobilenetV1/MobilenetV1/Conv2d_10_pointwise/Relu6, 401408, 1, 0, 0\r\n38: MobilenetV1/MobilenetV1/Conv2d_11_depthwise/Relu6, 401408, 1, 0, 0\r\n39: MobilenetV1/MobilenetV1/Conv2d_11_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n40: MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n41: MobilenetV1/MobilenetV1/Conv2d_11_pointwise/Relu6, 401408, 1, 0, 0\r\n42: MobilenetV1/MobilenetV1/Conv2d_12_depthwise/Relu6, 100352, 1, 0, 0\r\n43: MobilenetV1/MobilenetV1/Conv2d_12_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n44: MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Conv2D_bias, 4096, 1, 0, 0\r\n45: MobilenetV1/MobilenetV1/Conv2d_12_pointwise/Relu6, 200704, 1, 0, 0\r\n46: MobilenetV1/MobilenetV1/Conv2d_13_depthwise/Relu6, 200704, 1, 0, 0\r\n47: MobilenetV1/MobilenetV1/Conv2d_13_depthwise/depthwise_bias, 4096, 1, 0, 0\r\n48: MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Conv2D_bias, 4096, 1, 0, 0\r\n49: MobilenetV1/MobilenetV1/Conv2d_13_pointwise/Relu6, 200704, 1, 0, 0\r\n50: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/Relu6, 1605632, 1, 0, 0\r\n51: MobilenetV1/MobilenetV1/Conv2d_1_depthwise/depthwise_bias, 128, 1, 0, 0\r\n52: MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Conv2D_bias, 256, 1, 0, 0\r\n53: MobilenetV1/MobilenetV1/Conv2d_1_pointwise/Relu6, 3211264, 1, 0, 0\r\n54: MobilenetV1/MobilenetV1/Conv2d_2_depthwise/Relu6, 802816, 1, 0, 0\r\n55: MobilenetV1/MobilenetV1/Conv2d_2_depthwise/depthwise_bias, 256, 1, 0, 0\r\n56: MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Conv2D_bias, 512, 1, 0, 0\r\n57: MobilenetV1/MobilenetV1/Conv2d_2_pointwise/Relu6, 1605632, 1, 0, 0\r\n58: MobilenetV1/MobilenetV1/Conv2d_3_depthwise/Relu6, 1605632, 1, 0, 0\r\n59: MobilenetV1/MobilenetV1/Conv2d_3_depthwise/depthwise_bias, 512, 1, 0, 0\r\n60: MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Conv2D_bias, 512, 1, 0, 0\r\n61: MobilenetV1/MobilenetV1/Conv2d_3_pointwise/Relu6, 1605632, 1, 0, 0\r\n62: MobilenetV1/MobilenetV1/Conv2d_4_depthwise/Relu6, 401408, 1, 0, 0\r\n63: MobilenetV1/MobilenetV1/Conv2d_4_depthwise/depthwise_bias, 512, 1, 0, 0\r\n64: MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Conv2D_bias, 1024, 1, 0, 0\r\n65: MobilenetV1/MobilenetV1/Conv2d_4_pointwise/Relu6, 802816, 1, 0, 0\r\n66: MobilenetV1/MobilenetV1/Conv2d_5_depthwise/Relu6, 802816, 1, 0, 0\r\n67: MobilenetV1/MobilenetV1/Conv2d_5_depthwise/depthwise_bias, 1024, 1, 0, 0\r\n68: MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Conv2D_bias, 1024, 1, 0, 0\r\n69: MobilenetV1/MobilenetV1/Conv2d_5_pointwise/Relu6, 802816, 1, 0, 0\r\n70: MobilenetV1/MobilenetV1/Conv2d_6_depthwise/Relu6, 200704, 1, 0, 0\r\n71: MobilenetV1/MobilenetV1/Conv2d_6_depthwise/depthwise_bias, 1024, 1, 0, 0\r\n72: MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n73: MobilenetV1/MobilenetV1/Conv2d_6_pointwise/Relu6, 401408, 1, 0, 0\r\n74: MobilenetV1/MobilenetV1/Conv2d_7_depthwise/Relu6, 401408, 1, 0, 0\r\n75: MobilenetV1/MobilenetV1/Conv2d_7_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n76: MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n77: MobilenetV1/MobilenetV1/Conv2d_7_pointwise/Relu6, 401408, 1, 0, 0\r\n78: MobilenetV1/MobilenetV1/Conv2d_8_depthwise/Relu6, 401408, 1, 0, 0\r\n79: MobilenetV1/MobilenetV1/Conv2d_8_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n80: MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n81: MobilenetV1/MobilenetV1/Conv2d_8_pointwise/Relu6, 401408, 1, 0, 0\r\n82: MobilenetV1/MobilenetV1/Conv2d_9_depthwise/Relu6, 401408, 1, 0, 0\r\n83: MobilenetV1/MobilenetV1/Conv2d_9_depthwise/depthwise_bias, 2048, 1, 0, 0\r\n84: MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Conv2D_bias, 2048, 1, 0, 0\r\n85: MobilenetV1/MobilenetV1/Conv2d_9_pointwise/Relu6, 401408, 1, 0, 0\r\n86: MobilenetV1/Predictions/Reshape_1, 4004, 1, 0, 0\r\n87: input, 602112, 1, 0, 0\r\nlen: 61306\r\nwidth, height, channels: -16842752, 1766213120, 246279780\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\nAborted_\r\nI have looked up the data, and it seems that it is caused by insufficient memory. So I checked the memory of arm, and its _memory usage is as follows:\r\nMemTotal:        2061132 kB\r\nMemFree:         1794816 kB\r\nMemAvailable:    1867312 kB\r\nBuffers:            5924 kB\r\nCached:            87248 kB\r\nSwapCached:            0 kB\r\nActive:            68852 kB\r\nInactive:          34884 kB\r\nActive(anon):      10688 kB\r\nInactive(anon):     9524 kB\r\nActive(file):      58164 kB\r\nInactive(file):    25360 kB\r\nUnevictable:           0 kB\r\nMlocked:               0 kB\r\nHighTotal:        278528 kB\r\nHighFree:         262148 kB\r\nLowTotal:        1782604 kB\r\nLowFree:         1532668 kB\r\nSwapTotal:             0 kB\r\nSwapFree:              0 kB\r\nDirty:                 0 kB\r\nWriteback:             0 kB\r\nAnonPages:         10576 kB\r\nMapped:            15880 kB\r\nShmem:              9640 kB\r\nSlab:              16204 kB\r\nSReclaimable:       7048 kB\r\nSUnreclaim:         9156 kB\r\nKernelStack:         840 kB\r\nPageTables:          396 kB\r\nNFS_Unstable:          0 kB\r\nBounce:                0 kB\r\nWritebackTmp:          0 kB\r\nCommitLimit:     1030564 kB\r\nCommitted_AS:      67364 kB\r\nVmallocTotal:     253952 kB\r\nVmallocUsed:        9772 kB\r\nVmallocChunk:     167732 kB\r\nCmaTotal:         393216 kB\r\nCmaFree:          257532 kB_\r\n\r\nIn order to find out the reason, I run the command that is \"**./minimal mobilenet_v1_1.0_224.tflite**\". It seems that there is no problem. Some of the results are as follows:\r\n_input(0) name: input\r\n0: MobilenetV1/Conv2d_0/weights, 3456, 1, 0, 0\r\n1: MobilenetV1/Conv2d_10_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n2: MobilenetV1/Conv2d_10_pointwise/weights, 1048576, 1, 0, 0\r\n3: MobilenetV1/Conv2d_11_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n4: MobilenetV1/Conv2d_11_pointwise/weights, 1048576, 1, 0, 0\r\n5: MobilenetV1/Conv2d_12_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n6: MobilenetV1/Conv2d_12_pointwise/weights, 2097152, 1, 0, 0\r\n7: MobilenetV1/Conv2d_13_depthwise/depthwise_weights, 36864, 1, 0, 0\r\n8: MobilenetV1/Conv2d_13_pointwise/weights, 4194304, 1, 0, 0\r\n9: MobilenetV1/Conv2d_1_depthwise/depthwise_weights, 1152, 1, 0, 0\r\n10: MobilenetV1/Conv2d_1_pointwise/weights, 8192, 1, 0, 0\r\n11: MobilenetV1/Conv2d_2_depthwise/depthwise_weights, 2304, 1, 0, 0\r\n12: MobilenetV1/Conv2d_2_pointwise/weights, 32768, 1, 0, 0\r\n13: MobilenetV1/Conv2d_3_depthwise/depthwise_weights, 4608, 1, 0, 0\r\n14: MobilenetV1/Conv2d_3_pointwise/weights, 65536, 1, 0, 0\r\n15: MobilenetV1/Conv2d_4_depthwise/depthwise_weights, 4608, 1, 0, 0\r\n16: MobilenetV1/Conv2d_4_pointwise/weights, 131072, 1, 0, 0\r\n17: MobilenetV1/Conv2d_5_depthwise/depthwise_weights, 9216, 1, 0, 0\r\n18: MobilenetV1/Conv2d_5_pointwise/weights, 262144, 1, 0, 0\r\n19: MobilenetV1/Conv2d_6_depthwise/depthwise_weights, 9216, 1, 0, 0\r\n20: MobilenetV1/Conv2d_6_pointwise/weights, 524288, 1, 0, 0\r\n21: MobilenetV1/Conv2d_7_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n22: MobilenetV1/Conv2d_7_pointwise/weights, 1048576, 1, 0, 0\r\n23: MobilenetV1/Conv2d_8_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n24: MobilenetV1/Conv2d_8_pointwise/weights, 1048576, 1, 0, 0\r\n25: MobilenetV1/Conv2d_9_depthwise/depthwise_weights, 18432, 1, 0, 0\r\n26: MobilenetV1/Conv2d_9_pointwise/weights, 1048576, 1, 0, 0\r\n27: MobilenetV1/Logits/AvgPool_1a/AvgPool, 4096, 1, 0, 0\r\n28: MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd, 4004, 1, 0, 0\r\n29: MobilenetV1/Logits/Conv2d_1c_1x1/Conv2D_bias, 4004, 1, 0, 0\r\n30: MobilenetV1/Logits/Conv2d_1c_1x1/weights, 4100096, 1, 0, 0_\r\n\r\nSo\uff0cMy cross compiled label_ image doesn't seem to be a problem either, because it's similar to minimal compilation, although I don't know how to test it. It took me a lot of time to solve this error, but I still couldn't find a way to solve it.Thanks!", "unassigning myself as this is a TfLite issue and I am focused on TfLite Micro.", "@xzy-666 ,\r\n\r\nCan you please refer the above [comment](https://github.com/tensorflow/tensorflow/issues/49975#issuecomment-853905088) also please try to install the latest stable tf v2.6 and let us know if the issue still persists.Thanks\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49975\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49975\">No</a>\n"]}, {"number": 49974, "title": "Ensure default types are accurate: fix `int` given for `float` args", "body": "I'm writing a parser/emitter that goes from Python to Python (and also OpenAPI). I found some type inconsistencies, when I would run `type(func_argument)` it would not match the argument type referenced in the docstring. This PR solves one such problem.", "comments": ["For the keras code update, the keras code has been moved to keras-team/keras as its new code repository. Please split this PR and move the keras related code as a new PR to keras-team/keras. Thanks.", "Adding Dan from tf core team for reviewing the code the rest of the PR.", "Merged master. I ran `git checkout master tensorflow/python/keras`.\r\n\r\nPS: There are naturally other occurrences of incorrect types used throughout the TensorFlow codebase\u2014and others in the TenosrFlow [and greater Google] ecosystem\u2014tempting me to extend my [`ast`](https://docs.python.org/3/library/ast.html) parser/emitter to automatically make numeric types consistent (between docstring and default/provided argument). What do you think, worth the effort?", "I think it's good to be consistent, though docstring is probably not as important than code typings, so maybe we can revisit once your main typing refactoring is done?", "@mdanatg, @kkimdev  Can you please review this PR ? Thanks!", "@SamuelMarks thanks again for the contribution, sorry for the delay. We're moving this forward now."]}, {"number": 49973, "title": "How to do inference when using tf.lite model when input is string ", "body": "tf ver: 2.5.0\r\n\r\nI previously post a thread : https://github.com/tensorflow/tensorflow/issues/48449\r\n to discuss how to convert model with tf.hub layers to tf.lite model. In 2.5.0 version, it succeed.\r\n\r\nI run the whole process, where I use tf.data flow as input for the large text data. The task is just text classification where the input sentences are string but not natural language.(It does not matter).\r\n\r\nMy code:\r\n```\r\nimport sys,os, logging,argparse,math,string,json,gzip\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport pandas as pd \r\nfrom tensorflow.keras import layers\r\nimport glob,pickle,random\r\nfrom sklearn.metrics import *\r\nfrom tensorflow.keras.callbacks import *\r\nfrom tensorflow.keras.metrics import *\r\nfrom tensorflow.python.keras.metrics import sparse_top_k_categorical_accuracy\r\n\r\nprint(tf.__version__)\r\n\r\nfrom transblock import * \r\ndef acc_top4(y_true, y_pred):\r\n    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=4)\r\n\r\ndef acc_top8(y_true, y_pred):\r\n    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=8)\r\n\r\n\r\nwith open('./app_map_5000.json','r') as f:\r\n    white_5000 = json.load(f)\r\n\r\ninit = tf.lookup.KeyValueTensorInitializer(\r\n    keys=tf.constant(list(white_5000.keys())),\r\n    values=tf.constant(list([ int(i) for i in white_5000.values()]), dtype=tf.int64))\r\n\r\ntable = tf.lookup.StaticVocabularyTable(\r\n   init, lookup_key_dtype=tf.string,\r\n   num_oov_buckets=5)\r\n\r\ndef parser(x):\r\n    x_ = tf.strings.regex_replace(x, '\"','')\r\n    tokens = tf.strings.split(x_, sep=',')\r\n    #label = \r\n    #label = tf.strings.to_number(tokens[-1], tf.int32)\r\n    #features = []\r\n    #words = tf.strings.split(tokens[0], sep=' ')\r\n    #f = table.lookup(words)\r\n    #features.append(tf.concat([f1, tf.expand_dims(f2,-1)], axis=0))\r\n    return tokens[0], table.lookup(tokens[-1])\r\n\r\ndef get_ds(files, val):\r\n    ds = tf.data.TextLineDataset(files, buffer_size=12800, num_parallel_reads=48 ,compression_type='GZIP')\r\n    ds = ds.map(lambda x: parser(x), tf.data.experimental.AUTOTUNE )\r\n    if not val:\r\n        ds = ds.shuffle(12800)#.repeat()\r\n    ds = ds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\r\n    return ds\r\n\r\n\r\nds_train = get_ds(files=glob.glob('./sents_0420_0428_nofil/part-*.csv.gz'),  val=False)\r\nds_test =  get_ds(files=glob.glob('./sents_0429_nofil/part-*.csv.gz'),  val=True)\r\n\r\nfor features in ds_test.take(10):\r\n    print(features)\r\n\r\ndef get_model_transormer(num_classes):\r\n    preprocessor_file = \"./albert_en_preprocess_3\" # https://tfhub.dev/tensorflow/albert_en_preprocess/3\r\n    preprocessor_layer = hub.KerasLayer(preprocessor_file)\r\n    preprocessor = hub.load(preprocessor_file)\r\n    vocab_size = preprocessor.tokenize.get_special_tokens_dict()['vocab_size'].numpy()\r\n\r\n    embed_dim = 32  # Embedding size for each token\r\n    num_heads = 2  # Number of attention heads\r\n    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\r\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) \r\n\r\n    encoder_inputs = preprocessor_layer(text_input)['input_word_ids']\r\n\r\n    embedding_layer = TokenAndPositionEmbedding(encoder_inputs.shape[1], vocab_size, embed_dim)\r\n    x = embedding_layer(encoder_inputs)\r\n    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\r\n    x = transformer_block(x)\r\n    x = layers.GlobalAveragePooling1D()(x)\r\n    x = layers.Dense(512, activation=\"relu\")(x)\r\n\r\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\r\n    model = keras.Model(inputs=text_input, outputs=outputs)\r\n    model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\", acc_top4, acc_top8])\r\n    return model\r\n\r\n# def get_model_bert(num_classes, m='albert'):\r\n\r\n#     text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) # shape=(None,) dtype=string\r\n#     m_file = {'albert':\"./albert_en_base_2\", 'electra':'./electra_base_2', 'dan':\"./universal-sentence-encoder_4\"}\r\n\r\n#     encoder = hub.KerasLayer(m_file[m], trainable=True)\r\n\r\n#     if m in ['albert', 'electra']:\r\n#         encoder_inputs = preprocessor_layer(text_input)\r\n#         outputs = encoder(encoder_inputs)\r\n#         embed = outputs[\"pooled_output\"]  \r\n#     elif m in ['dan']:\r\n#         embed = encoder(text_input)\r\n#     else:\r\n#         raise KeyError(\"model illegal!\")\r\n\r\n#     out = layers.Dense(num_classes, activation=\"softmax\")(embed)\r\n#     model = tf.keras.Model(inputs=text_input, outputs=out)\r\n#     model.compile(Adam(learning_rate=1e-5), \"sparse_categorical_crossentropy\", metrics=[\"acc\", acc_top4, acc_top8])\r\n#     return model\r\n\r\n# x_train, y_train = df_train['content'].values.reshape(-1,1), df_train['label'].values\r\n# x_test, y_test = df_test['content'].values.reshape(-1,1), df_test['label'].values\r\n\r\n#model = get_model_bert(df_train['label'].max()+1)\r\n\r\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n    filepath='./checkpoint_epoch{epoch}',\r\n    save_weights_only=False,\r\n    monitor='val_acc_top8',\r\n    mode='max',\r\n    save_best_only=False)\r\n\r\nmodel = get_model_transormer(5001)\r\nmodel.save('checkpoint__')\r\n\r\nhistory = model.fit(\r\n    ds_train, validation_data=ds_test, epochs=1, \\\r\n     steps_per_epoch=1000, validation_steps=1000,\r\n     verbose=1, callbacks=[model_checkpoint_callback]\r\n)\r\n\r\n# transform to another model which use the dense_2 layer as output\r\nmodel_file = './checkpoint_epoch'\r\nmodel = tf.keras.models.load_model(model_file, \\\r\n                        custom_objects={\"acc_top4\":acc_top4, \"acc_top8\":acc_top8, \\\r\n                       \"softmax\":tf.keras.activations.softmax})\r\nintermediate_layer_model = tf.keras.Model(inputs=model.input,\r\n                                 outputs=model.get_layer('dense_2').output)\r\nintermediate_layer_model.save(model_file+\"_inter\")\r\ny = intermediate_layer_model.predict(ds_test, verbose=1, steps=10)\r\n\r\n# save the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_file+\"_inter\")\r\n\r\n#### ver: 2.5.0\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\n\r\n# write the tflite model\r\ntflite_model = converter.convert()\r\nopen(\"{}.tflite\".format(model_file+\"_inter\"), \"wb\").write(tflite_model)\r\n\r\n########## reload \r\n#model = tf.keras.models.load_model('./model_transoformer_1216_epoch_1')\r\ninterpreter = tf.lite.Interpreter(model_path= \"{}.tflite\".format(model_file+\"_inter\") )    \r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\nThe code can run without any error. In the final stage, I saved the model in tf.lite format. Then it can be reloaded again as \r\n`interpreter`. \r\nI want it to do inference when the input is `sentence`\r\n`sentence = 'ysbang.cn dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 curdow3 curhour8'`\r\n\r\n`sentence` is the string type, same as when I do training. \r\n `sentence` is processed by the tf.hub `preprocessor_layer` in the model.\r\n\r\nHere I want `interpreter` to do inference with `sentence` as input.\r\n\r\nI tries this :\r\n```\r\ninterpreter.set_tensor(input_details[0]['index'], tf.convert_to_tensor([sentence]) )\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\npred = output_data[0][0]\r\n```\r\nbut it crashed with error: \r\n\r\n> segmentation fault (core dumped)\r\n\r\nMy question is how to set the input to get the output when using `interpreter` ?\r\n\r\n\r\n", "comments": ["I guess there are two solutions:\r\n\r\n1) Adding the preprocessor_layer into the model to take string inputs can be a solution.\r\n2) Before the TFLite interpreter invocation, the given string input should be preprocessed, which is required by the model.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49973\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49973\">No</a>\n"]}, {"number": 49971, "title": "Fix _Arg op diagnostic for _handle_dtypes attribute", "body": "Fix typo in _Arg op diagnostic for _handle_dtypes attribute.", "comments": ["CC: @jpienaar @joker-eph "]}, {"number": 49970, "title": "[MLIR][DISC] bufferize DynamicReshape and DynamicBroadcastInDim", "body": "1, add hlo-to-lhlo support for DynamicReshape and DynamicBroadcastInDim\r\n\r\n2, add a flag `convert-to-lmhlo-only` to seperate following two case:\r\n   - hlo-to-lhlo only. Simply lowers all mhlo ops to their lmhlo\r\n     counterparts, do not apply any optimization (e.g. elide any\r\n     buffer copy). Buffer optimization is not easy in dynamic\r\n     shape world especially when involving control flow, thus we\r\n     leave this to another dedicated pass.\r\n\r\n   - hlo-to-lhlo-or-memref-directly. Lowers some metadata-only mhlo\r\n     ops (e.g. reshape) to memref dialect directly and Lowers others\r\n     to their lmhlo counterparts.", "comments": ["@joker-eph I see you remove the tag `ready to pull`. Is there something wrong about the CI again\uff1fOr simply because this pr need another round of review?", "> @joker-eph I see you remove the tag `ready to pull`. Is there something wrong about the CI again\uff1fOr simply because this pr need another round of review?\r\n\r\nWe have infrastructure issues around the automation driving all the integration, I was trying to force it to restart its process..."]}, {"number": 49969, "title": "'tf.Mul' op is neither a custom op nor a flex op when I convert saved_model to tflite model", "body": "Environment is NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0 tensorflow-2.5/2.6 python3.8.\r\n\r\nMy net contain the ops: matmul, multiply. When I convert the saved model to tflite model, it report that\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: loc(callsite(callsite(callsite(callsite(\"Mul_1@__inference_call_8437\" at \"conformer_encoder/conformer_block_3/mhsa_module/multi_head_attention_3/StatefulPartitionedCall@__inference_call_8638\") at \"transducer_encoder/StatefulPartitionedCall@__inference__wrapped_model_8931\") at \"StatefulPartitionedCall@__inference_signature_wrapper_18974\") at \"StatefulPartitionedCall\")): 'tf.Mul' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': \r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \r\nTF Select ops: Mul\r\nDetails:\r\n        tf.Mul {device = \"\"}\r\n\r\nHow can l solve it?\r\n", "comments": ["Please consider using the Select TF option to fallback unsupported TF ops in the TensorFlow Lite builtin op set.\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select"]}, {"number": 49968, "title": "Can not convert to tf.lite when feeding model with tf.data", "body": "tf ver: 2.5.0\r\n\r\nI previously post a thread : https://github.com/tensorflow/tensorflow/issues/48449\r\n to discuss how to convert model with tf.hub layers to tf.lite model. In 2.5.0 version, it succeed.\r\n\r\nI run the whole process, where I use tf.data flow as input for the large text data.\r\nMy code:\r\n```\r\nimport sys,os, logging,argparse,math,string,json,gzip\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport pandas as pd \r\nfrom tensorflow.keras import layers\r\nimport glob,pickle,random\r\nfrom sklearn.metrics import *\r\nfrom tensorflow.keras.callbacks import *\r\nfrom tensorflow.keras.metrics import *\r\nfrom tensorflow.python.keras.metrics import sparse_top_k_categorical_accuracy\r\n\r\nprint(tf.__version__)\r\n\r\nfrom transblock import * \r\ndef acc_top4(y_true, y_pred):\r\n    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=4)\r\n\r\ndef acc_top8(y_true, y_pred):\r\n    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=8)\r\n\r\n\r\nwith open('./app_map_5000.json','r') as f:\r\n    white_5000 = json.load(f)\r\n\r\ninit = tf.lookup.KeyValueTensorInitializer(\r\n    keys=tf.constant(list(white_5000.keys())),\r\n    values=tf.constant(list([ int(i) for i in white_5000.values()]), dtype=tf.int64))\r\n\r\ntable = tf.lookup.StaticVocabularyTable(\r\n   init, lookup_key_dtype=tf.string,\r\n   num_oov_buckets=5)\r\n\r\ndef parser(x):\r\n    x_ = tf.strings.regex_replace(x, '\"','')\r\n    tokens = tf.strings.split(x_, sep=',')\r\n    #label = \r\n    #label = tf.strings.to_number(tokens[-1], tf.int32)\r\n    #features = []\r\n    #words = tf.strings.split(tokens[0], sep=' ')\r\n    #f = table.lookup(words)\r\n    #features.append(tf.concat([f1, tf.expand_dims(f2,-1)], axis=0))\r\n    return tokens[0], table.lookup(tokens[-1])\r\n\r\ndef get_ds(files, val):\r\n    ds = tf.data.TextLineDataset(files, buffer_size=12800, num_parallel_reads=48 ,compression_type='GZIP')\r\n    ds = ds.map(lambda x: parser(x), tf.data.experimental.AUTOTUNE )\r\n    if not val:\r\n        ds = ds.shuffle(12800)#.repeat()\r\n    ds = ds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)\r\n    return ds\r\n\r\n\r\nds_train = get_ds(files=glob.glob('./sents_0420_0428_nofil/part-*.csv.gz'),  val=False)\r\nds_test =  get_ds(files=glob.glob('./sents_0429_nofil/part-*.csv.gz'),  val=True)\r\n\r\nfor features in ds_test.take(10):\r\n    print(features)\r\n\r\ndef get_model_transormer(num_classes):\r\n    preprocessor_file = \"./albert_en_preprocess_3\" # https://tfhub.dev/tensorflow/albert_en_preprocess/3\r\n    preprocessor_layer = hub.KerasLayer(preprocessor_file)\r\n    preprocessor = hub.load(preprocessor_file)\r\n    vocab_size = preprocessor.tokenize.get_special_tokens_dict()['vocab_size'].numpy()\r\n\r\n    embed_dim = 32  # Embedding size for each token\r\n    num_heads = 2  # Number of attention heads\r\n    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\r\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) \r\n\r\n    encoder_inputs = preprocessor_layer(text_input)['input_word_ids']\r\n\r\n    embedding_layer = TokenAndPositionEmbedding(encoder_inputs.shape[1], vocab_size, embed_dim)\r\n    x = embedding_layer(encoder_inputs)\r\n    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\r\n    x = transformer_block(x)\r\n    x = layers.GlobalAveragePooling1D()(x)\r\n    x = layers.Dense(512, activation=\"relu\")(x)\r\n\r\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\r\n    model = keras.Model(inputs=text_input, outputs=outputs)\r\n    model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\", acc_top4, acc_top8])\r\n    return model\r\n\r\n# def get_model_bert(num_classes, m='albert'):\r\n\r\n#     text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) # shape=(None,) dtype=string\r\n#     m_file = {'albert':\"./albert_en_base_2\", 'electra':'./electra_base_2', 'dan':\"./universal-sentence-encoder_4\"}\r\n\r\n#     encoder = hub.KerasLayer(m_file[m], trainable=True)\r\n\r\n#     if m in ['albert', 'electra']:\r\n#         encoder_inputs = preprocessor_layer(text_input)\r\n#         outputs = encoder(encoder_inputs)\r\n#         embed = outputs[\"pooled_output\"]  \r\n#     elif m in ['dan']:\r\n#         embed = encoder(text_input)\r\n#     else:\r\n#         raise KeyError(\"model illegal!\")\r\n\r\n#     out = layers.Dense(num_classes, activation=\"softmax\")(embed)\r\n#     model = tf.keras.Model(inputs=text_input, outputs=out)\r\n#     model.compile(Adam(learning_rate=1e-5), \"sparse_categorical_crossentropy\", metrics=[\"acc\", acc_top4, acc_top8])\r\n#     return model\r\n\r\n# x_train, y_train = df_train['content'].values.reshape(-1,1), df_train['label'].values\r\n# x_test, y_test = df_test['content'].values.reshape(-1,1), df_test['label'].values\r\n\r\n#model = get_model_bert(df_train['label'].max()+1)\r\n\r\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n    filepath='./checkpoint_epoch{epoch}',\r\n    save_weights_only=False,\r\n    monitor='val_acc_top8',\r\n    mode='max',\r\n    save_best_only=False)\r\n\r\nmodel = get_model_transormer(5001)\r\nmodel.save('checkpoint__')\r\n\r\nhistory = model.fit(\r\n    ds_train, validation_data=ds_test, epochs=1, \\\r\n     steps_per_epoch=1000, validation_steps=1000,\r\n     verbose=1, callbacks=[model_checkpoint_callback]\r\n)\r\n\r\n# transform to another model which use the dense_2 layer as output\r\nmodel_file = './checkpoint_epoch'\r\nmodel = tf.keras.models.load_model(model_file, \\\r\n                        custom_objects={\"acc_top4\":acc_top4, \"acc_top8\":acc_top8, \\\r\n                       \"softmax\":tf.keras.activations.softmax})\r\nintermediate_layer_model = tf.keras.Model(inputs=model.input,\r\n                                 outputs=model.get_layer('dense_2').output)\r\nintermediate_layer_model.save(model_file+\"_inter\")\r\ny = intermediate_layer_model.predict(ds_test, verbose=1, steps=10)\r\n\r\n# save the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_file+\"_inter\")\r\n\r\n#### ver: 2.5.0\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\n\r\n# write the tflite model\r\ntflite_model = converter.convert()\r\nopen(\"{}.tflite\".format(model_file+\"_inter\"), \"wb\").write(tflite_model)\r\n\r\n########## reload \r\n#model = tf.keras.models.load_model('./model_transoformer_1216_epoch_1')\r\ninterpreter = tf.lite.Interpreter(model_path= \"{}.tflite\".format(model_file+\"_inter\") )    \r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\nThe code can run without any error. In the final stage, I saved the model in tf.lite format. Then it can be reloaded again as \r\n`interpreter`. \r\nI want it to do inference when the input is `sentence`\r\n`sentence = 'ysbang.cn dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 com.tencent.mm dow3 hour8 curdow3 curhour8'`\r\n\r\n`sentence` is the string type, same as when I do training. I suppose `sentence` is processed by the tf.hub `preprocessor_layer`.\r\n\r\nHere I want `interpreter` to do inference with `sentence` as input.\r\n\r\nI tries this :\r\n```\r\ninterpreter.set_tensor(input_details[0]['index'], tf.convert_to_tensor([sentence]) )\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\npred = output_data[0][0]\r\n```\r\nbut it crashed with error: \r\n\r\n> segmentation fault (core dumped)\r\n\r\nMy question is how to set the input to get the output when using `interpreter` ?\r\n\r\n\r\n", "comments": ["@abattery please take a look. Thanks.", "The op library including the custom `NormalizeUTF8` op should be linked to the program, that performs the above TensorFlow Lite conversion.\r\n\r\nTensorFlow library requires the necessary operator library to be linked in order to load the serialized TF saved model.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49968\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49968\">No</a>\n", "> The op library including the custom `NormalizeUTF8` op should be linked to the program, that performs the above TensorFlow Lite conversion.\r\n> \r\n> TensorFlow library requires the necessary operator library to be linked in order to load the serialized TF saved model.\r\n\r\nThanks for your reply. `NormalizeUTF8` is solved. \r\n\r\nI just changed the question to another topic where I want the tflite model to do inference.  Could you please take a look ?", "> The op library including the custom `NormalizeUTF8` op should be linked to the program, that performs the above TensorFlow Lite conversion.\r\n> \r\n> TensorFlow library requires the necessary operator library to be linked in order to load the serialized TF saved model.\r\n\r\nShould I reopen another issue ?", "It would be nice to have a separate post to keep each thread focused. Thanks!", "Closing this issue for now. Please upload a new issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49968\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49968\">No</a>\n"]}, {"number": 49967, "title": "Fix tf.raw_ops.SparseCross failing CHECK.", "body": null, "comments": []}, {"number": 49966, "title": "Fix heap-buffer-overflow issue with .", "body": null, "comments": []}, {"number": 49965, "title": "Fix heap-buffer-overflow issue with .", "body": null, "comments": []}, {"number": 49964, "title": "Fix heap-buffer-overflow issue with .", "body": null, "comments": []}, {"number": 49963, "title": "Fix heap-buffer-overflow issue with .", "body": null, "comments": []}, {"number": 49962, "title": "AutoGraph could not transform call method of keras.Model subclass", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    - I am following along with a tutorial provided by TensorFlow:\r\n        - https://www.tensorflow.org/tutorials/structured_data/time_series\r\n        - The error messages arise when compiling/evaluating the \"Baseline\" model.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    - Ubuntu 20.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n    - N/A\r\n- TensorFlow installed from (source or binary):\r\n    - Anaconda\r\n- TensorFlow version (use command below):\r\n    - After running the command `conda list --export`:\r\n        ```\r\n        # This file may be used to create an environment using:\r\n        # $ conda create --name <env> --file <this file>\r\n        # platform: linux-64\r\n        _libgcc_mutex=0.1=main\r\n        _tflow_select=2.3.0=mkl\r\n        absl-py=0.12.0=py39h06a4308_0\r\n        aiohttp=3.7.4=py39h27cfd23_1\r\n        anyio=2.2.0=py39h06a4308_1\r\n        argon2-cffi=20.1.0=py39h27cfd23_1\r\n        astor=0.8.1=py39h06a4308_0\r\n        astunparse=1.6.3=py_0\r\n        async-timeout=3.0.1=py39h06a4308_0\r\n        async_generator=1.10=pyhd3eb1b0_0\r\n        attrs=21.2.0=pyhd3eb1b0_0\r\n        babel=2.9.1=pyhd3eb1b0_0\r\n        backcall=0.2.0=pyhd3eb1b0_0\r\n        blas=1.0=mkl\r\n        bleach=3.3.0=pyhd3eb1b0_0\r\n        blinker=1.4=py39h06a4308_0\r\n        brotlipy=0.7.0=py39h27cfd23_1003\r\n        c-ares=1.17.1=h27cfd23_0\r\n        ca-certificates=2021.5.25=h06a4308_1\r\n        cachetools=4.2.2=pyhd3eb1b0_0\r\n        certifi=2021.5.30=py39h06a4308_0\r\n        cffi=1.14.5=py39h261ae71_0\r\n        chardet=3.0.4=py39h06a4308_1003\r\n        click=8.0.1=pyhd3eb1b0_0\r\n        coverage=5.5=py39h27cfd23_2\r\n        cryptography=3.4.7=py39hd23ed53_0\r\n        cycler=0.10.0=py39h06a4308_0\r\n        cython=0.29.23=py39h2531618_0\r\n        dbus=1.13.18=hb2f20db_0\r\n        decorator=5.0.9=pyhd3eb1b0_0\r\n        defusedxml=0.7.1=pyhd3eb1b0_0\r\n        entrypoints=0.3=py39h06a4308_0\r\n        expat=2.4.1=h2531618_2\r\n        fontconfig=2.13.1=h6c09931_0\r\n        freetype=2.10.4=h5ab3b9f_0\r\n        gast=0.4.0=py_0\r\n        glib=2.68.2=h36276a3_0\r\n        google-auth=1.30.1=pyhd3eb1b0_0\r\n        google-auth-oauthlib=0.4.4=pyhd3eb1b0_0\r\n        google-pasta=0.2.0=py_0\r\n        grpcio=1.36.1=py39h2157cd5_1\r\n        gst-plugins-base=1.14.0=h8213a91_2\r\n        gstreamer=1.14.0=h28cd5cc_2\r\n        h5py=2.10.0=py39hec9cf62_0\r\n        hdf5=1.10.6=hb1b8bf9_0\r\n        icu=58.2=he6710b0_3\r\n        idna=2.10=pyhd3eb1b0_0\r\n        importlib-metadata=3.10.0=py39h06a4308_0\r\n        importlib_metadata=3.10.0=hd3eb1b0_0\r\n        intel-openmp=2021.2.0=h06a4308_610\r\n        ipykernel=5.3.4=py39hb070fc8_0\r\n        ipython=7.22.0=py39hb070fc8_0\r\n        ipython_genutils=0.2.0=pyhd3eb1b0_1\r\n        jedi=0.17.2=py39h06a4308_1\r\n        jinja2=3.0.0=pyhd3eb1b0_0\r\n        jpeg=9b=h024ee3a_2\r\n        json5=0.9.5=py_0\r\n        jsonschema=3.2.0=py_2\r\n        jupyter-packaging=0.7.12=pyhd3eb1b0_0\r\n        jupyter_client=6.1.12=pyhd3eb1b0_0\r\n        jupyter_core=4.7.1=py39h06a4308_0\r\n        jupyter_server=1.4.1=py39h06a4308_0\r\n        jupyterlab=3.0.14=pyhd3eb1b0_1\r\n        jupyterlab_pygments=0.1.2=py_0\r\n        jupyterlab_server=2.4.0=pyhd3eb1b0_0\r\n        keras-preprocessing=1.1.2=pyhd3eb1b0_0\r\n        kiwisolver=1.3.1=py39h2531618_0\r\n        lcms2=2.12=h3be6417_0\r\n        ld_impl_linux-64=2.33.1=h53a641e_7\r\n        libffi=3.3=he6710b0_2\r\n        libgcc-ng=9.1.0=hdf63c60_0\r\n        libgfortran-ng=7.3.0=hdf63c60_0\r\n        libpng=1.6.37=hbc83047_0\r\n        libprotobuf=3.14.0=h8c45485_0\r\n        libsodium=1.0.18=h7b6447c_0\r\n        libstdcxx-ng=9.1.0=hdf63c60_0\r\n        libtiff=4.2.0=h85742a9_0\r\n        libuuid=1.0.3=h1bed415_2\r\n        libwebp-base=1.2.0=h27cfd23_0\r\n        libxcb=1.14=h7b6447c_0\r\n        libxml2=2.9.10=hb55368b_3\r\n        lz4-c=1.9.3=h2531618_0\r\n        markdown=3.3.4=py39h06a4308_0\r\n        markupsafe=2.0.1=py39h27cfd23_0\r\n        matplotlib=3.3.4=py39h06a4308_0\r\n        matplotlib-base=3.3.4=py39h62a2d02_0\r\n        mistune=0.8.4=py39h27cfd23_1000\r\n        mkl=2021.2.0=h06a4308_296\r\n        mkl-service=2.3.0=py39h27cfd23_1\r\n        mkl_fft=1.3.0=py39h42c9631_2\r\n        mkl_random=1.2.1=py39ha9443f7_2\r\n        multidict=5.1.0=py39h27cfd23_2\r\n        nbclassic=0.2.6=pyhd3eb1b0_0\r\n        nbclient=0.5.3=pyhd3eb1b0_0\r\n        nbconvert=6.0.7=py39h06a4308_0\r\n        nbformat=5.1.3=pyhd3eb1b0_0\r\n        ncurses=6.2=he6710b0_1\r\n        nest-asyncio=1.5.1=pyhd3eb1b0_0\r\n        notebook=6.4.0=py39h06a4308_0\r\n        numpy=1.20.2=py39h2d18471_0\r\n        numpy-base=1.20.2=py39hfae3a4d_0\r\n        oauthlib=3.1.0=py_0\r\n        olefile=0.46=py_0\r\n        openssl=1.1.1k=h27cfd23_0\r\n        opt_einsum=3.3.0=pyhd3eb1b0_1\r\n        packaging=20.9=pyhd3eb1b0_0\r\n        pandas=1.2.4=py39h2531618_0\r\n        pandoc=2.12=h06a4308_0\r\n        pandocfilters=1.4.3=py39h06a4308_1\r\n        parso=0.7.0=py_0\r\n        pcre=8.44=he6710b0_0\r\n        pexpect=4.8.0=pyhd3eb1b0_3\r\n        pickleshare=0.7.5=pyhd3eb1b0_1003\r\n        pillow=8.2.0=py39he98fc37_0\r\n        pip=21.1.1=py39h06a4308_0\r\n        prometheus_client=0.10.1=pyhd3eb1b0_0\r\n        prompt-toolkit=3.0.17=pyh06a4308_0\r\n        protobuf=3.14.0=py39h2531618_1\r\n        ptyprocess=0.7.0=pyhd3eb1b0_2\r\n        pyasn1=0.4.8=py_0\r\n        pyasn1-modules=0.2.8=py_0\r\n        pycparser=2.20=py_2\r\n        pygments=2.9.0=pyhd3eb1b0_0\r\n        pyjwt=2.1.0=py39h06a4308_0\r\n        pyopenssl=20.0.1=pyhd3eb1b0_1\r\n        pyparsing=2.4.7=pyhd3eb1b0_0\r\n        pyqt=5.9.2=py39h2531618_6\r\n        pyrsistent=0.17.3=py39h27cfd23_0\r\n        pysocks=1.7.1=py39h06a4308_0\r\n        python=3.9.5=hdb3f193_3\r\n        python-dateutil=2.8.1=pyhd3eb1b0_0\r\n        python-flatbuffers=1.12=pyhd3eb1b0_0\r\n        pytz=2021.1=pyhd3eb1b0_0\r\n        pyzmq=20.0.0=py39h2531618_1\r\n        qt=5.9.7=h5867ecd_1\r\n        readline=8.1=h27cfd23_0\r\n        requests=2.25.1=pyhd3eb1b0_0\r\n        requests-oauthlib=1.3.0=py_0\r\n        rsa=4.7.2=pyhd3eb1b0_1\r\n        scipy=1.6.2=py39had2a1c9_1\r\n        seaborn=0.11.1=pyhd3eb1b0_0\r\n        send2trash=1.5.0=pyhd3eb1b0_1\r\n        setuptools=52.0.0=py39h06a4308_0\r\n        sip=4.19.13=py39h2531618_0\r\n        six=1.15.0=py39h06a4308_0\r\n        sniffio=1.2.0=py39h06a4308_1\r\n        sqlite=3.35.4=hdfb4753_0\r\n        tensorboard=2.4.0=pyhc547734_0\r\n        tensorboard-plugin-wit=1.6.0=py_0\r\n        tensorflow=2.4.1=mkl_py39h4683426_0\r\n        tensorflow-base=2.4.1=mkl_py39h43e0292_0\r\n        tensorflow-estimator=2.5.0=pyh7b7c402_0\r\n        termcolor=1.1.0=py39h06a4308_1\r\n        terminado=0.9.4=py39h06a4308_0\r\n        testpath=0.4.4=pyhd3eb1b0_0\r\n        tk=8.6.10=hbc83047_0\r\n        tornado=6.1=py39h27cfd23_0\r\n        traitlets=5.0.5=pyhd3eb1b0_0\r\n        typing-extensions=3.7.4.3=hd3eb1b0_0\r\n        typing_extensions=3.7.4.3=pyh06a4308_0\r\n        tzdata=2020f=h52ac0ba_0\r\n        urllib3=1.26.4=pyhd3eb1b0_0\r\n        wcwidth=0.2.5=py_0\r\n        webencodings=0.5.1=py39h06a4308_1\r\n        werkzeug=1.0.1=pyhd3eb1b0_0\r\n        wheel=0.36.2=pyhd3eb1b0_0\r\n        wrapt=1.12.1=py39he8ac12f_1\r\n        xz=5.2.5=h7b6447c_0\r\n        yarl=1.6.3=py39h27cfd23_0\r\n        zeromq=4.3.4=h2531618_0\r\n        zipp=3.4.1=pyhd3eb1b0_0\r\n        zlib=1.2.11=h7b6447c_3\r\n        zstd=1.4.9=haebb681_0\r\n        ```\r\n- Python version:\r\n    - 3.9.5\r\n- Bazel version (if compiling from source):\r\n    - N/A\r\n- GCC/Compiler version (if compiling from source):\r\n    - N/A\r\n- CUDA/cuDNN version:\r\n    - After running the command `nvcc  --version`:\r\n        ```\r\n        nvcc: NVIDIA (R) Cuda compiler driver\r\n        Copyright (c) 2005-2020 NVIDIA Corporation\r\n        Built on Mon_Oct_12_20:09:46_PDT_2020\r\n        Cuda compilation tools, release 11.1, V11.1.105\r\n        Build cuda_11.1.TC455_06.29190527_0\r\n        ```\r\n- GPU model and memory:\r\n    - GeForce RTX 3090, 24 GB\r\n    - NVIDIA-SMI: 460.73.01\r\n    - Driver Version: 460.73.01\r\n    - CUDA Version: 11.2\r\n\r\n**Describe the current behavior**\r\nWhen I  execute the following code:\r\n```\r\ntf.autograph.set_verbosity(10)\r\n\r\nbaseline = Baseline(label_index=column_indices['T (degC)'])\r\n\r\nbaseline.compile(loss=tf.losses.MeanSquaredError(),\r\n                 metrics=[tf.metrics.MeanAbsoluteError()])\r\n\r\nval_performance = {}\r\nperformance = {}\r\nval_performance['Baseline'] = baseline.evaluate(single_step_window.val)\r\nperformance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\r\n```\r\nI receive the following error messages:\r\n```\r\nINFO:tensorflow:Converted call: <function timeseries_dataset_from_array.<locals>.<lambda> at 0x7f3b4c2773a0>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>, <tf.Tensor 'args_1:0' shape=(14017,) dtype=int32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <function timeseries_dataset_from_array.<locals>.<lambda> at 0x7f3b4c2773a0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function sequences_from_indices.<locals>.<lambda> at 0x7f3b4b9509d0>\r\n    args: (<tf.Tensor 'args_0:0' shape=(14018, 19) dtype=float32>, <tf.Tensor 'args_1:0' shape=(None,) dtype=int32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <function sequences_from_indices.<locals>.<lambda> at 0x7f3b4b9509d0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method WindowGenerator.split_window of Total window size: 2\r\nInput indices: [0]\r\nLabel indices: [1]\r\nLabel column name(s): ['T (degC)']>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None, None, 19) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted <bound method WindowGenerator.split_window of Total window size: 2\r\nInput indices: [0]\r\nLabel indices: [1]\r\nLabel column name(s): ['T (degC)']>: from cache\r\nINFO:tensorflow:Converted call: <function Model.make_test_function.<locals>.test_function at 0x7f3b4b950280>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f3b4b954df0>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:<function Model.make_test_function.<locals>.test_function at 0x7f3b4b950280> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Source code of <function Model.make_test_function.<locals>.test_function at 0x7f3b4b950280>:\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\ndef test_function(iterator):\r\n  \"\"\"Runs an evaluation execution with one step.\"\"\"\r\n  return step_function(self, iterator)\r\n\r\n\r\nINFO:tensorflow:Transformed <function Model.make_test_function.<locals>.test_function at 0x7f3b4b950280>:\r\n\r\n# coding=utf-8\r\ndef tf__test_function(iterator):\r\n    'Runs an evaluation execution with one step.'\r\n    with ag__.FunctionScope('test_function', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n        do_return = False\r\n        retval_ = ag__.UndefinedReturnValue()\r\n        try:\r\n            do_return = True\r\n            retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\r\n        except:\r\n            do_return = False\r\n            raise\r\n        return fscope.ret(retval_, do_return)\r\n\r\nINFO:tensorflow:Defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__test_function at 0x7f3b4b7f2310> : None\r\nINFO:tensorflow:KW defaults of <function outer_factory.<locals>.inner_factory.<locals>.tf__test_function at 0x7f3b4b7f2310> : None\r\nINFO:tensorflow:Calling <function outer_factory.<locals>.inner_factory.<locals>.tf__test_function at 0x7f3b4b7f2310> with\r\n    iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f3b4b954df0>\r\n\r\nINFO:tensorflow:Converted call: <function Model.make_test_function.<locals>.step_function at 0x7f3b4b91bca0>\r\n    args: (<__main__.Baseline object at 0x7f3b4b8e75e0>, <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f3b4b954df0>)\r\n    kwargs: None\r\n\r\nINFO:tensorflow:Allowlisted: <function Model.make_test_function.<locals>.step_function at 0x7f3b4b91bca0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function Model.make_test_function.<locals>.step_function.<locals>.run_step at 0x7f3b4b7f2ca0>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 19) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 1, 1) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <function Model.make_test_function.<locals>.step_function.<locals>.run_step at 0x7f3b4b7f2ca0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>>\r\n    args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 19) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Not allowed: <method-wrapper '__call__' of method object at 0x7f3b4b932a80>: default rule\r\nINFO:tensorflow:Not allowed: <class '__main__.Baseline'>: default rule\r\nINFO:tensorflow:Not allowed: <bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>>: default rule\r\nINFO:tensorflow:<bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Source code of <bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>>:\r\n\r\ndef call(self, inputs):\r\n    if self.label_index is None:\r\n        return inputs\r\n    result = inputs[:, :, self.label_index]\r\n    return result[:, :, tf.newaxis]\r\n\r\n\r\nINFO:tensorflow:Error transforming entity <bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>>\r\nTraceback (most recent call last):\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 447, in converted_call\r\n    converted_f = _convert_actual(target_entity, program_ctx)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 284, in _convert_actual\r\n    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 286, in transform\r\n    return self.transform_function(obj, user_context)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 470, in transform_function\r\n    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 363, in transform_function\r\n    result = self.transform_ast(node, context)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 252, in transform_ast\r\n    node = self.initial_analysis(node, ctx)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 239, in initial_analysis\r\n    node = qual_names.resolve(node)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/qual_names.py\", line 252, in resolve\r\n    return QnResolver().visit(node)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/ast.py\", line 407, in visit\r\n    return visitor(node)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/ast.py\", line 483, in generic_visit\r\n    value = self.visit(value)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/ast.py\", line 407, in visit\r\n    return visitor(node)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/ast.py\", line 492, in generic_visit\r\n    new_node = self.visit(old_value)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/ast.py\", line 407, in visit\r\n    return visitor(node)\r\n  File \"/home/mark/anaconda3/envs/tf2/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/qual_names.py\", line 232, in visit_Subscript\r\n    if not isinstance(s, gast.Index):\r\nAttributeError: module 'gast' has no attribute 'Index'\r\nWARNING:tensorflow:AutoGraph could not transform <bound method Baseline.call of <__main__.Baseline object at 0x7f3b4b8e75e0>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Index'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nINFO:tensorflow:Converted call: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.MeanSquaredError object at 0x7f3b4b30ec10>>\r\n    args: (<tf.Tensor 'IteratorGetNext:1' shape=(None, 1, 1) dtype=float32>, <tf.Tensor 'baseline/strided_slice_1:0' shape=(None, 1, 1) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <bound method LossFunctionWrapper.call of <tensorflow.python.keras.losses.MeanSquaredError object at 0x7f3b4b30ec10>>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f3b4b89cb80>>\r\n    args: (<tf.Tensor 'mean_squared_error/weighted_loss/value:0' shape=() dtype=float32>,)\r\n    kwargs: {'sample_weight': <tf.Tensor 'strided_slice:0' shape=() dtype=int32>}\r\n\r\nINFO:tensorflow:Allowlisted: <bound method Reduce.update_state of <tensorflow.python.keras.metrics.Mean object at 0x7f3b4b89cb80>>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method MeanMetricWrapper.update_state of <tensorflow.python.keras.metrics.MeanAbsoluteError object at 0x7f3b4b89c460>>\r\n    args: (<tf.Tensor 'IteratorGetNext:1' shape=(None, 1, 1) dtype=float32>, <tf.Tensor 'baseline/strided_slice_1:0' shape=(None, 1, 1) dtype=float32>)\r\n    kwargs: {'sample_weight': None}\r\n\r\nINFO:tensorflow:Allowlisted: <bound method MeanMetricWrapper.update_state of <tensorflow.python.keras.metrics.MeanAbsoluteError object at 0x7f3b4b89c460>>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f3b4b89cb80>>\r\n    args: ()\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <bound method Reduce.result of <tensorflow.python.keras.metrics.Mean object at 0x7f3b4b89cb80>>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method Reduce.result of <tensorflow.python.keras.metrics.MeanAbsoluteError object at 0x7f3b4b89c460>>\r\n    args: ()\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted <bound method Reduce.result of <tensorflow.python.keras.metrics.MeanAbsoluteError object at 0x7f3b4b89c460>>: from cache\r\n439/439 [==============================] - 0s 514us/step - loss: 0.0135 - mean_absolute_error: 0.0806\r\nINFO:tensorflow:Converted call: <function timeseries_dataset_from_array.<locals>.<lambda> at 0x7f3b4b9500d0>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>, <tf.Tensor 'args_1:0' shape=(7009,) dtype=int32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <function timeseries_dataset_from_array.<locals>.<lambda> at 0x7f3b4b9500d0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function sequences_from_indices.<locals>.<lambda> at 0x7f3b4b3f88b0>\r\n    args: (<tf.Tensor 'args_0:0' shape=(7010, 19) dtype=float32>, <tf.Tensor 'args_1:0' shape=(None,) dtype=int32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted: <function sequences_from_indices.<locals>.<lambda> at 0x7f3b4b3f88b0>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <bound method WindowGenerator.split_window of Total window size: 2\r\nInput indices: [0]\r\nLabel indices: [1]\r\nLabel column name(s): ['T (degC)']>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None, None, 19) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Allowlisted <bound method WindowGenerator.split_window of Total window size: 2\r\nInput indices: [0]\r\nLabel indices: [1]\r\nLabel column name(s): ['T (degC)']>: from cache\r\n```\r\n\r\n**Describe the expected behavior**\r\nI expect to receive zero error messages.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you want to contribute a PR? (yes/no): - Briefly describe your candidate solution (if contributing):\r\nNo.\r\n\r\n**Standalone code to reproduce the issue**\r\nAll of the code is available in the TensorFlow tutorial at: https://www.tensorflow.org/tutorials/structured_data/time_series\r\nThe Anaconda environment may also be created in the \"TensorFlow version\" section above.\r\n", "comments": ["@marktodisco \r\nMake sure you followed the same tested build configurations for [gpu](https://github.com/ContinuumIO/anaconda-issues/issues)\r\n`\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow_gpu-2.5.0 | 3.6-3.9 | MSVC 2019 | Bazel 3.7.2 | 8.1 | 11.2\r\ntensorflow_gpu-2.4.0 | 3.6-3.8 | MSVC 2019 | Bazel 3.1.0 | 8.0 | 11.0\r\n\r\n\r\n<br class=\"Apple-interchange-newline\">`\r\n and\r\nWe don't support for Anaconda Environment,Please post this in this respective [repo](https://github.com/ContinuumIO/anaconda-issues/issues).Thanks", "Apparently, I did not install TensorFlow correctly, so thank you for the clarification. However, I personally think TensorFlow-GPU has an overly complicated installation process when compared with PyTorch. I hope the TensorFlow team can address this issue in the future, opening the doors to a much broader userbase.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49962\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49962\">No</a>\n"]}, {"number": 49960, "title": "Fix one more FPE.", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49960) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49959, "title": "Fix one more FPE.", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49959) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49958, "title": "Fix one more FPE.", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49958) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49957, "title": "Fix one more FPE.", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49957) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49957) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49955, "title": "Prevent yet another division by zero", "body": "", "comments": []}, {"number": 49954, "title": "Prevent yet another division by zero", "body": "", "comments": []}, {"number": 49953, "title": "Prevent yet another division by zero", "body": "", "comments": []}, {"number": 49952, "title": "Prevent yet another division by zero", "body": "", "comments": []}, {"number": 49951, "title": "Wire up set_filesystem_configuration with modular file system", "body": "This PR tries to wire up set_filesystem_configuration with modular file system so that it is possible to set up the file\r\nsystem configuration through modular file system plugins.\r\n\r\nWhile set_filesystem_configuration API has been defined in the past, the API was not wired up with modular file system so it was not possible to use it from plugins.\r\n\r\nThis PR adds the missing implementation.\r\n\r\nThis PR also made several changes:\r\n- values associated with `type_tag` was not defined in the past. This PR adds the definition.\r\n- TF_Filesystem_Option_Value definition has been modified as previous unnamed union was difficult to assign value.\r\n- set_filesystem_configuration_option was removed as it is almost a duplicate of set_filesystem_configuration, and it does not match the description.\r\n\r\nWhile the API was modified, since set_filesystem_configuration was not wired with modular file system, it is not used anyway. So this will not break user or plugins.\r\n\r\nThis PR is needed in order to have gcs-config support in modular file system plugins.\r\n\r\ncc @mihaimaruseac, FYI @vnvo2409 @kvignesh1420 @terrytangyuan @burgerkingeater \r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @mihaimaruseac for the review. The PR has been updated. Please take a look.", "Thanks @mihaimaruseac for the help. The PR has been updated now. Please take a look.", "Thanks @mihaimaruseac for the review. The PR has been updated. Please take a look.", "@mihaimaruseac @gbaned Any update on the import? I see `copybara` reported failure but I am not able to see the failure content?", "The internal CI on the imported change failed. This needs manual import, I'll try to do it this week but probably won't be able to until Friday :( Sorry for delays", "So this fails because Google has an internal FileSystem class which implements a `void SetOption(const string&, const string&)` and this results in a bad override. Fix is similar to https://godbolt.org/z/5zoW3z7G6 (on internal, so **nothing to do here**).\r\n\r\nThere might be failures caused by now ambiguous overloads (in the usage in the link above, now there's an explicit need to call the `std::vector` conversion) so let's wait for a few days after this lands before building on top of it, just in case something breaks.\r\n\r\nEdit: slightly updated link: https://godbolt.org/z/Y85era817", "Thanks @mihaimaruseac for the great help! \ud83d\udc4d "]}, {"number": 49950, "title": "Tensorflow Decove Wav", "body": "Please, help me with tf.audio.decode_wav:https://www.tensorflow.org/api_docs/python/tf/audio/decode_wav\r\n(The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in  float tensor.)\r\n\r\nI want to read 16bit PCM wav file as 8 bit PCM (The -128 to 127 and scaled to -1.0 to 1.0 in  float tensor)\r\n\r\nWhat should i do?", "comments": ["@Astrohaker \r\nCould you please share standalone code/colab gist to analyse the issue reported and tf vesion used along with all the dependencies.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Have you tried lowering the precision first before attempting to tensorize the waveforms ? https://stackoverflow.com/questions/44812553/how-to-convert-a-24-bit-wav-file-to-16-or-32-bit-files-in-python3", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49950\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49950\">No</a>\n"]}, {"number": 49949, "title": "need convert opencv to TfLiteTensorCopyFromBuffer", "body": "https://github.com/tensorflow/examples/blob/master/lite/examples/super_resolution/android/app/src/main/cc/SuperResolution.cpp\r\n\r\nwhy so many python or java references.\r\nwhile C++ is very little.\r\n\r\nI'm angry because why developers don't provide compiled source code, why should we do the compilation ourselves.\r\n\r\nat this line 108 [https://github.com/tensorflow/examples/blob/master/lite/examples/super_resolution/android/app/src/main/cc/SuperResolution.cpp#L108](url) \r\nhow to convert cv::mat to TfLiteTensorCopyFromBuffer\r\n\r\nand then at this line 137 [https://github.com/tensorflow/examples/blob/master/lite/examples/super_resolution/android/app/src/main/cc/SuperResolution.cpp#L137](url)\r\nhow to convert TfLiteTensorCopyToBuffer to cv::mat\r\n\r\ni hope there person, will help,\r\nbecause tensorflow reference on this link [https://github.com/tensorflow/examples/blob/master/lite/examples/super_resolution/android/app/src/main/cc/SuperResolution.cpp](url)\r\nis not structured. Thanks", "comments": ["@lintian06 could you take a look?", "solved"]}, {"number": 49948, "title": "AttributeError: module 'tensorflow._api.v2.nn' has no attribute 'seq2seq'", "body": "Data ready!\r\nBucketing conversation number 9999\r\nBucketing conversation number 19999\r\nBucketing conversation number 9999\r\nBucketing conversation number 19999\r\nBucketing conversation number 29999\r\nBucketing conversation number 39999\r\nBucketing conversation number 49999\r\nBucketing conversation number 59999\r\nBucketing conversation number 69999\r\nBucketing conversation number 79999\r\nBucketing conversation number 89999\r\nBucketing conversation number 99999\r\nBucketing conversation number 109999\r\nBucketing conversation number 119999\r\nBucketing conversation number 129999\r\nBucketing conversation number 139999\r\nBucketing conversation number 149999\r\nBucketing conversation number 159999\r\nBucketing conversation number 169999\r\nBucketing conversation number 179999\r\nBucketing conversation number 189999\r\nNumber of samples in each bucket:\r\n [111977, 37536, 12893, 13731, 8591, 4756]\r\nBucket scale:\r\n [0.5909575478668384, 0.7890534293132929, 0.8570961136560343, 0.9295613349939836, 0.9749002554305377, 1.0]\r\nInitialize new model\r\nCreate placeholders\r\nCreate inference\r\nD:\\Program Files\\python\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:535: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\r\n  warnings.warn(\"`tf.nn.rnn_cell.GRUCell` is deprecated and will be removed \"\r\nWARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.   \r\nWARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\r\nCreating loss...\r\nIt might take a couple of minutes depending on how many buckets you have.\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\ABHAY VERMA\\Documents\\Chatbot\\chatbot.py\", line 243, in <module>\r\n    main()\r\n  File \"c:\\Users\\ABHAY VERMA\\Documents\\Chatbot\\chatbot.py\", line 238, in main\r\n    train()\r\n  File \"c:\\Users\\ABHAY VERMA\\Documents\\Chatbot\\chatbot.py\", line 119, in train\r\n    model.build_graph()\r\n  File \"c:\\Users\\ABHAY VERMA\\Documents\\Chatbot\\model.py\", line 118, in build_graph\r\n    self._create_loss()\r\n  File \"c:\\Users\\ABHAY VERMA\\Documents\\Chatbot\\model.py\", line 79, in _create_loss\r\n    self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\r\nAttributeError: module 'tensorflow._api.v2.nn' has no attribute 'seq2seq'", "comments": ["@ABHAY-05 \r\nWe see that you have not filled in the issue template, please do so, for us to know the tf version and code, if possible share a colab gist with the issue reported.\r\nPlease try on latest version and let us know.\r\n\r\nFrom the error logs please refer to these and let us know: [link](https://github.com/suriyadeepan/practical_seq2seq/issues/21),[link2](https://stackoverflow.com/questions/42619180/tensorflows-api-seq2seq)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49948\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49948\">No</a>\n"]}, {"number": 49945, "title": "TFLM project generation fail, missing gemmlowp ", "body": "@tensorflow/micro\r\n\r\n**System information**\r\nUbuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): f19bfff186754e621d59a65494b04ff9ab4e9ede\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):cortex-m4\r\n\r\n**Describe the problem**\r\n\r\nUsing project genration failed, the log shows that the gemmlowp is missing.  Maybe there's a missing gemlowp download script in the make folder?\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nSTEP1: \r\npython tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py --makefile_options=\"OPTIMIZED_KERNEL_DIR=cmsis_nn TARGET_ARCH=cortex-m4\" \"project\"\r\n\r\nOUTPUT:\r\nTraceback (most recent call last):\r\n  File \"tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py\", line 193, in <module>\r\n    _copy(src_files, dest_files)\r\n  File \"tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py\", line 105, in _copy\r\n    shutil.copy(src, dst)\r\n  File \"/home/yc/anaconda3/lib/python3.8/shutil.py\", line 418, in copy\r\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\r\n  File \"/home/yc/anaconda3/lib/python3.8/shutil.py\", line 264, in copyfile\r\n    with open(src, 'rb') as fsrc, open(dst, 'wb') as fdst:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tensorflow/lite/micro/tools/make/downloads/gemmlowp/fixedpoint/fixedpoint.h'", "comments": ["@youshenmebutuo ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.\r\n\r\nThanks!", "@tilakrayal \r\nWell, this issue does not require the complete code and dataset. I just want to use Project generation in TFLM to output a tree containing only the sources and headers needed to use TFLM for a specific configuration. And my steps are as follows\r\n**STEP1:**\r\n`git clone https://github.com/tensorflow/tensorflow.git`\r\n**STEP2:**\r\n`cd tensorflow`\r\n**STEP3:**\r\n`python3 tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py --makefile_options=\"OPTIMIZED_KERNEL_DIR=cmsis_nn TARGET_ARCH=cortex-m4\" \"project\"`\r\n\r\nThe execution of **STEP3** fails, and the output is as follows:\r\n```\r\nTraceback (most recent call last):\r\n  File \"tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py\", line 193, in <module>\r\n    _copy(src_files, dest_files)\r\n  File \"tensorflow/lite/micro/tools/project_generation/create_tflm_tree.py\", line 105, in _copy\r\n    shutil.copy(src, dst)\r\n  File \"/usr/lib/python3.8/shutil.py\", line 415, in copy\r\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\r\n  File \"/usr/lib/python3.8/shutil.py\", line 261, in copyfile\r\n    with open(src, 'rb') as fsrc, open(dst, 'wb') as fdst:\r\nFileNotFoundError: [Errno 2] No such file or directory: 'tensorflow/lite/micro/tools/make/downloads/gemmlowp/fixedpoint/fixedpoint.h'\r\n```\r\nI think there may be some problems with the  gemmlowp download script\r\n\r\n\r\n\r\n\r\n", "Maybe I found the cause of this problem\uff0c But should I go to the [tensorflow/tflite-micro](https://github.com/tensorflow/tflite-micro) repositories to fix this problem? @advaitjain ", "Yes, please feel free to make a PR in https://github.com/tensorflow/tflite-micro", "I believe https://github.com/tensorflow/tflite-micro/pull/138 addresses this issue. Feel free to reopen if the still persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49945\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49945\">No</a>\n"]}, {"number": 49942, "title": "Added RaggedTensor support to reduce_std", "body": "Fixes #49941 .\r\n\r\nTook help from my similar PRs for `reduce_variance` #37014 and #49609\r\n\r\ncc @mihaimaruseac , @edloper ", "comments": []}]