[{"number": 28260, "title": "Added tests for tensors, inputs, outputs, opcodes", "body": "This was one of the TODO, just complete the same", "comments": ["@alanchiao Could you PTAL and approve.", "@alanchiao can you please review this PR ?  ", "Can one of the admins verify this patch?", "Closing as a duplicate of https://github.com/tensorflow/tensorflow/pull/25809"]}, {"number": 28259, "title": "[2.0] fit exception on precision metric", "body": "v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\n\r\nmnist = k.datasets.mnist\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = k.models.Sequential([\r\n\tk.layers.Flatten(input_shape=(28, 28)),\r\n\tk.layers.Dense(512, activation=tf.nn.elu),\r\n\tk.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=[k.metrics.Precision()])\r\n\r\nmodel.fit(x_train, y_train, epochs=1)\r\n```\r\n\r\n```\r\n\r\n  File \"C:/prj/myshpy/src/mysh/nn/bn2.py\", line 25, in <module>\r\n    model.fit(x_train, y_train, epochs=1)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 873, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 352, in model_iteration\r\n    batch_outs = f(ins_batch)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3217, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 558, in __call__\r\n    return self._call_flat(args)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 627, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 415, in call\r\n    ctx=ctx)\r\n  File \"C:\\prj\\testPrj\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [1,32] vs. [1,320]\r\n\t [[{{node metrics/precision/LogicalAnd}}]] [Op:__inference_keras_scratch_graph_719]\r\n```\r\n", "comments": ["@myshzzx I could reproduce the issue with TF2.0.0-alpha0 and tf-nightly. When I change the metrics to metrics.Accuracy() or metrics.CosineSimilarity() it works without error. Thanks!", "I do not think changing to Accuracy() would work either and will fail with shape compatibility error as well. The issue is y_true/labels has the shape (?, 1) and y_pred/predictions has the shape (?, 10). \r\n\r\nUsing SparseCategoricalAccuracy() will work or you can simple give the string 'accuracy' in compile. Please note that you are using `sparse_categorical_crossentropy` loss for this reason.\r\n\r\nYou can fix example for Accuracy/Precision metric by converting your labels to categorical values like\r\n`y_train = tf.keras.utils.to_categorical(y_train, 10)`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28259\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28259\">No</a>\n"]}, {"number": 28258, "title": "TfLite Compare kernel code refactor to remove duplication", "body": "One of ToDo activity", "comments": ["@alanchiao Could you PTAL and approve.", "@alanchiao can you please review this PR ? ", "Can one of the admins verify this patch?", "Thanks for the contribution, Dayananda-V.\r\nYour change is based on old code. Could you rebase your change for master?", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 28257, "title": "tf.py_function doesn't calculate output shape correctly when using in dataset.map", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac os mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# The tuples are unpacked into the positional arguments of the mapped function\r\ndef load_and_preprocess_from_path_label(path, label):\r\n    \r\n    print(path)\r\n    print(label)\r\n\r\n    target = np.ndarray((2, 128, 128)).astype('float32')\r\n    label = np.ndarray((128, 128)).astype('float32')\r\n    \r\n    return target, label\r\n\r\ninputs_list = sorted(['{:05d}.npy'.format(i) for i in range(50)])\r\ntargets_list = sorted(['{:05d}.npy'.format(i) for i in range(50)])\r\n\r\nds = tf.data.Dataset.from_tensor_slices((inputs_list, targets_list))\r\nimage_label_ds = ds.map(\r\n    load_and_preprocess_from_path_label,\r\n#     lambda single_input, single_target: tuple(\r\n#         tf.py_function(\r\n#             load_and_preprocess_from_path_label,\r\n#             [single_input, single_target],\r\n#             [tf.float32, tf.float32])\r\n#     ),\r\n)\r\nimage_label_ds = image_label_ds.batch(2)\r\nprint(image_label_ds)\r\n\r\ndevices = ['/device:CPU:0']\r\nstrategy = tf.distribute.MirroredStrategy(devices)\r\n\r\nwith strategy.scope():\r\n    image_label_ds_iterator = strategy.make_dataset_iterator(image_label_ds)\r\n\r\n```\r\n\r\nthere is my code above, you can run it directly in jupyter.\r\n\r\nwhen using py_function, the dataset.map function can't calculate output image shape correctly, which will be using in mirrored strategy distribution, and it throw out an error, which i think is caused by last problem.\r\n\r\n```\r\n<BatchDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.float32)>\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-35-f6c2c4912d88> in <module>\r\n     33 \r\n     34 with strategy.scope():\r\n---> 35     image_label_ds_iterator = strategy.make_dataset_iterator(image_label_ds)\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in make_dataset_iterator(self, dataset)\r\n    355       computation.  User should call `initialize` on the returned iterator.\r\n    356     \"\"\"\r\n--> 357     return self._extended._make_dataset_iterator(dataset)  # pylint: disable=protected-access\r\n    358 \r\n    359   def make_input_fn_iterator(self,\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py in _make_dataset_iterator(self, dataset)\r\n    569   def _make_dataset_iterator(self, dataset):\r\n    570     return input_lib.DatasetIterator(\r\n--> 571         dataset, self._input_workers, self._num_replicas_in_sync)\r\n    572 \r\n    573   def _make_input_fn_iterator(\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in __init__(self, dataset, input_workers, split_batch_by)\r\n    247     assert isinstance(input_workers, InputWorkers)\r\n    248     if split_batch_by:\r\n--> 249       dataset = batching._RebatchDataset(dataset, split_batch_by)  # pylint: disable=protected-access\r\n    250 \r\n    251     iterators = []\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/batching.py in __init__(self, input_dataset, num_workers)\r\n    747     input_shapes = dataset_ops.get_legacy_output_shapes(self._input_dataset)\r\n    748     input_classes = dataset_ops.get_legacy_output_classes(self._input_dataset)\r\n--> 749     output_shapes = nest.map_structure(recalculate_output_shapes, input_shapes)\r\n    750 \r\n    751     self._structure = structure.convert_legacy_structure(\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py in map_structure(func, *structure, **check_types_dict)\r\n    245 \r\n    246   return pack_sequence_as(\r\n--> 247       structure[0], [func(*x) for x in entries])\r\n    248 \r\n    249 \r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py in <listcomp>(.0)\r\n    245 \r\n    246   return pack_sequence_as(\r\n--> 247       structure[0], [func(*x) for x in entries])\r\n    248 \r\n    249 \r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/batching.py in recalculate_output_shapes(output_shapes)\r\n    732     def recalculate_output_shapes(output_shapes):\r\n    733       \"\"\"Recalculates the output_shapes after dividing it by num_workers.\"\"\"\r\n--> 734       if len(output_shapes) < 1:\r\n    735         raise ValueError(\"Input shape should have at least one dimension.\")\r\n    736       if (tensor_shape.dimension_value(output_shapes[0]) and\r\n\r\n~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __len__(self)\r\n    792     \"\"\"Returns the rank of this shape, or raises ValueError if unspecified.\"\"\"\r\n    793     if self._dims is None:\r\n--> 794       raise ValueError(\"Cannot take the length of shape with unknown rank.\")\r\n    795     return len(self._dims)\r\n    796 \r\n\r\nValueError: Cannot take the length of shape with unknown rank.\r\n```\r\nbut if u use it not by py_function, it can calculate and distributed correctly. but i don't know how to get the value transfer to this function, it shows as `args_0:0` and `args_1:0`\r\n```\r\nTensor(\"args_0:0\", shape=(), dtype=string)\r\nTensor(\"args_1:0\", shape=(), dtype=string)\r\n<BatchDataset shapes: ((None, 2, 128, 128), (None, 128, 128)), types: (tf.float32, tf.float32)>\r\n```\r\n\r\n", "comments": ["I could reproduce the issue using TF2.0.0-alpha0 and tf-nightly. Thanks!", "> I could reproduce the issue using TF2.0.0-alpha0 and tf-nightly. Thanks!\r\n\r\nthanks for your info.", "https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28257\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28257\">No</a>\n", "This problem has not been solved. Why does the return value be \"unknown\"", "@primejava have you read through the StackOverflow post linked above?"]}, {"number": 28256, "title": "tf.image.decode_png doesn't work for palette-based images", "body": "**System information**\r\n- Have I written custom code\r\n- Linux Ubuntu 18.04\r\n- TensorFlow installed from source \r\n- TensorFlow version:  v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.7\r\n- CUDA/cuDNN version: V10.0.130\r\n- GPU model and memory: RTX2080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nPixel values should be the same regardless if loading the image by PIL or  by TF\r\n\r\n**Describe the expected behavior**\r\n\r\nPixel values are different\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nPATH = '/tmp/42313738-65c10f7c-807e-11e8-8f11-9db821e3c3cc.png'\r\n\r\nim = Image.open(PATH)\r\nar = np.asarray(im)\r\npil_max = np.max(ar)\r\nprint(pil_max)\r\n\r\nim = tf.gfile.FastGFile(PATH, 'rb').read()\r\nar = tf.image.decode_png(im, channels=1)\r\ntf_max = tf.reduce_max(ar)\r\nprint(tf_max)\r\n\r\nassert tf_max == pil_max\r\n```\r\n\r\nimage:\r\n[here](https://user-images.githubusercontent.com/26040/42313738-65c10f7c-807e-11e8-8f11-9db821e3c3cc.png)\r\n\r\n**Other info / logs**\r\nI suspect that the problem is caused by tensorflow loading the first RGB channel, (so the red channel)\r\ninstead of the color indexes, for palette based png images like given example.\r\n\r\nrelated to #20028\r\n\r\n", "comments": ["The Problem is with the `channel=1` parameter.\r\nYou are converting the image to Grayscale, which is nothing but a weighted average of the channels. So this changes the value of the pixels.\r\nThis code works perfectly, for `channel=0` where the number of channels of the original image is preserved, causing no change in the value of the pixels.\r\nFor more info refer to:\r\nhttps://www.tensorflow.org/versions/r1.12/api_docs/python/tf/image/decode_png\r\n", "1. That is not the problem, and the code doesn't work perfectly if I use channel=0.\r\n     if I use channel=0, I get again a RGB image with 3 channels, which I don't want.\r\n     I want the single channel indexed-based image.\r\n\r\n\r\n2. The documentation doesn't mention anything about taking a weighted average of the channels.\r\n\r\n3. I am sorry, the image I have provided it not the best, please try this code:\r\n```\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nPATH = '/tmp/xX4Stvh.png'\r\n\r\nim = tf.gfile.FastGFile(PATH, 'rb').read()\r\nar = tf.image.decode_png(im, channels=0)\r\ntf_max = tf.reduce_max(ar)\r\nprint(tf_max)\r\n\r\nim = Image.open(PATH)\r\nar = np.asarray(im)\r\npil_max = np.max(ar)\r\nprint(pil_max)\r\n```\r\non this image:\r\nhttps://i.imgur.com/xX4Stvh.png\r\n\r\nit has only three colors, so the difference in behaviour will be more apparent", ">     1. That is not the problem, and the code doesn't work perfectly if I use channel=0.\r\n>        if I use channel=0, I get again a RGB image with 3 channels, which I don't want.\r\n>        I want the single channel indexed-based image.\r\n> \r\n>     2. The documentation doesn't mention anything about taking a weighted average of the channels.\r\n> \r\n>     3. I am sorry, the image I have provided it not the best, please try this code:\r\n> \r\n> \r\n> ```\r\n> from PIL import Image\r\n> import numpy as np\r\n> import tensorflow as tf\r\n> tf.enable_eager_execution()\r\n> \r\n> PATH = '/tmp/xX4Stvh.png'\r\n> \r\n> im = tf.gfile.FastGFile(PATH, 'rb').read()\r\n> ar = tf.image.decode_png(im, channels=0)\r\n> tf_max = tf.reduce_max(ar)\r\n> print(tf_max)\r\n> \r\n> im = Image.open(PATH)\r\n> ar = np.asarray(im)\r\n> pil_max = np.max(ar)\r\n> print(pil_max)\r\n> ```\r\n> \r\n> on this image:\r\n> https://i.imgur.com/xX4Stvh.png\r\n> \r\n> it has only three colors, so the difference in behaviour will be more apparent\r\n\r\nSorry for the confusion. The Main reason for this error is, PIL opens images in palette mode. This means the color from the channels are mapped to a color palette and that palette index is provided in each location of the image. However tensorflow, decodes the image into Channels and doesn't use this concept of palette. So, when the Pillow Image object is converted to numpy array, the values at the various positions is not intensity of the pixels of the color channel, which is in the case of tensorflow.\r\n\r\nThe correct way to verify this is:\r\n```python\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nPATH = '/tmp/xX4Stvh.png'\r\n\r\nim = tf.gfile.FastGFile(PATH, 'rb').read()\r\nar = tf.image.decode_png(im, channels=0)\r\ntf_max = tf.reduce_max(ar)\r\nprint(tf_max)\r\n\r\nim = Image.open(PATH).convert('RGB') # This convert() function converts from \r\n                                     # PIL exclusive Palette mode to channel mode\r\nar = np.asarray(im)\r\npil_max = np.max(ar)\r\nprint(pil_max)\r\n```\r\n\r\nAnd about the weighted average thing. When you are loading a color image in channel mode and request it to convert to grayscale (`channels=0` does that). A weighted average on all the channels(R,G,B) is calculated to produce the value for one channel. (That's why the number of channels for grayscaled image is 1 and RGB colored image, is 3)\r\nReference: \r\n1. https://stackoverflow.com/a/52307690/9947584\r\n2. https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale", "thanks for the response capitan-pool\r\nSo the whole point is that I actually only care about these palette indexes, not about the RGB values.\r\nThose palette index values are the target class IDs for semantic segmentation.", "> thanks for the response capitan-pool\r\n> So the whole point is that I actually only care about these palette indexes, not about the RGB values.\r\n> Those palette index values are the target class IDs for semantic segmentation.\r\n\r\nHuh? That has nothing to do with semantic segmentation. You don't care about Palette Values for any sort of deep vision related tasks, in general. You need to use the 3 Channels of RGB, 4 Channels of RGBA, or 1 channel of Grayscale, while working with images.", "ok, forget the segmentation part.\r\n\r\nCould you just answer this question:\r\n*How can I achieve the same behavior with tensorflow as I had with PIL?*\r\n\r\nbecause what you have suggested before is the opposite,\r\nyou modified the PIL code to match the tensorflow implementation", "> ok, forget the segmentation part.\r\n> \r\n> Could you just answer this question:\r\n> _How can I achieve the same behavior with tensorflow as I had with PIL?_\r\n> \r\n> because what you have suggested before is the opposite,\r\n> you modified the PIL code to match the tensorflow implementation\r\n\r\nYou can do something similar using,\r\n```python\r\nimport tensorflow as tf\r\nimg = tf.image.decode_png(tf.io.read_file(/path/to/png/file))\r\n```\r\n", "Could someone else look at this issue, please?\r\nI am sorry, but captain-pool doesn't get it", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "the only way you could do is to re-save your png file in \"RGB\" mode . in this case,  the image datas are the indices of  palette\uff0cwhich you needed to training a semantic segment model , and decoding function in tensorflow works correctly  . side effect is that you cant see anything in preview, because its intensity is too low to be seen", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "I just met the same problem, it looks like there is no way to get the correct palette indexes with native tensorflow. However, I solved my problem with `tf.py_func`. I'll leave my code here in case somebody finds it useful.\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom PIL import Image\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices({\r\n    'image': ['img00.png', 'img01.png'],\r\n    'index': [0, 1]\r\n    })\r\n\r\ndef load_image_func(image, index):\r\n    return np.array(Image.open(image)), index\r\n\r\ndataset = dataset.map(lambda x: (\r\n    tf.py_func(load_image_func, [x['image'], x['index']], [tf.uint8, x['index'].dtype])))\r\n```", "A clean solution would be to re-implement a custom op to decode a PNG without palette conversion.\r\n\r\nCurrently, the conversion is done at [core level](https://github.com/tensorflow/tensorflow/blob/38cdb9ff8548efc920039d68dd94b5581db6314a/tensorflow/core/lib/png/png_io.cc#L284):\r\n```cpp\r\n  // convert palette to rgb(a) if needs be.\r\n  if (context->color_type == PNG_COLOR_TYPE_PALETTE)\r\n    png_set_palette_to_rgb(context->png_ptr);\r\n```\r\n\r\nIf you are at TF 1.X, you can wrap the PIL-call with `py_func` in order to get the desired behavior, like:\r\n\r\n```python\r\ndef read_png(mask):\r\n    def read_fn(p):\r\n        return np.asarray(Image.open(p))\r\n    return tf.py_func(read_fn, [mask], tf.uint8)\r\n```\r\n\r\nand then build your pipe, like:\r\n\r\n```python\r\n\r\nar = read_png(im)\r\ntf_max = tf.reduce_max(ar)\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(tf_max))\r\n```\r\n\r\n**Note**: in TF1.X this works only in graph-mode. In TF2.X a similar trick should be possible with `tf.numpy_function` or `tf.py_function`.", "This is a valid issue that shouldn't be closed and likely drives user away if not properly handled, as it represents an important use case. @adrianstaniec you're right it doesn't work and for exactly the reasons @alar0330 mentioned.\r\nI believe the fix doesn't require any API level change, i.e., tf.image.decode_png(mask_path) should have same behavior as np.array(Image.Open(mask_path))  \r\nBut for now, either use `tf.numpy_function`, or `tf.data.Dataset.from_generator` and let generator use Image.Open(mask_path)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue comes from a redundant ` png_set_rgb_to_gray` call in the C++ kernel for palette-based images. I have created a PR #41472 to fix this issue.", "After the rollback of the fix, this is now again a problem. When loading index PNGs TF should allow the user to choose whether to use the palette to convert the pixel index or choose to load the raw index value themselves. \r\n\r\nThanks to @alar0330 for the workaround."]}, {"number": 28255, "title": "How to run tensorflow C/C++ and python test programs or scripts?", "body": "There are C/C++ and python test programs or scripts corresponding to each tensorflow features, operators, NN layers etc. \r\n\r\nOnce I install Tensorflow using pip command, How to run these test programs or scripts? \r\nDoes these test programs and scripts comes with tensorflow pip installation?\r\n\r\nThanks.", "comments": ["It's better to use StackOverflow for this type of questions. You will the response sooner there.", "This question is better asked on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow). Since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 28254, "title": "E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nanaconda\r\npython3.7\r\ntensorflow 1.13.1\r\nGTX 1080\r\nNVIDIA-SMI 410.48                 Driver Version: 410.48\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nWARNING:tensorflow:From gan-script.py:22: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\r\nWARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease write your own downloading logic.\r\nWARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use tf.data to implement this functionality.\r\nExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nWARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use tf.data to implement this functionality.\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nWARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\r\nWARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n############ Tensor(\"x_placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\r\n############ Tensor(\"Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\r\n2019-04-29 15:30:05.097050: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2019-04-29 15:30:05.106630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3493035000 Hz\r\n2019-04-29 15:30:05.108392: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55aca335a480 executing computations on platform Host. Devices:\r\n2019-04-29 15:30:05.108445: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-04-29 15:30:05.302261: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55aca26f8a80 executing computations on platform CUDA. Devices:\r\n2019-04-29 15:30:05.302336: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5\r\n2019-04-29 15:30:05.302819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\npciBusID: 0000:0a:00.0\r\ntotalMemory: 7.77GiB freeMemory: 7.62GiB\r\n2019-04-29 15:30:05.302848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-04-29 15:30:05.304416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-04-29 15:30:05.304438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-04-29 15:30:05.304447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-04-29 15:30:05.304732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7416 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:0a:00.0, compute capability: 7.5)\r\n2019-04-29 15:30:06.382870: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n2019-04-29 15:30:07.368915: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-04-29 15:30:07.370433: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-04-29 15:30:07.371649: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-04-29 15:30:07.371663: W ./tensorflow/stream_executor/stream.h:2099] attempting to perform DNN operation using StreamExecutor without DNN support\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node Conv2D_3}}]]\r\n\t [[{{node Mean}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"gan-script.py\", line 161, in <module>\r\n    {x_placeholder: real_image_batch, z_placeholder: z_batch})\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node Conv2D_3 (defined at gan-script.py:32) ]]\r\n\t [[node Mean (defined at gan-script.py:118) ]]\r\n\r\nCaused by op 'Conv2D_3', defined at:\r\n  File \"gan-script.py\", line 110, in <module>\r\n    Dx = discriminator(x_placeholder)\r\n  File \"gan-script.py\", line 32, in discriminator\r\n    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node Conv2D_3 (defined at gan-script.py:32) ]]\r\n\t [[node Mean (defined at gan-script.py:118) ]]\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Can you try the solution provided in similar issue [#24496](https://github.com/tensorflow/tensorflow/issues/24496) and let us know if that solves your problem. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28254\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28254\">No</a>\n", "```\r\nimport tensorflow as tf\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n```\r\nAdding these lines in the main file running the model, worked like charm for me. \r\n@humaolin  @achandraa ", "> ```\r\n> import tensorflow as tf\r\n> from tensorflow.compat.v1 import InteractiveSession\r\n> config = tf.ConfigProto()\r\n> config.gpu_options.allow_growth = True\r\n> session = InteractiveSession(config=config)\r\n> ```\r\n> \r\n> Adding these lines in the main file running the model, worked like charm for me.\r\n> @humaolin @achandraa\r\n\r\nBut if i met this issue in command line, how to add these codes ?", "> > ```\r\n> > import tensorflow as tf\r\n> > from tensorflow.compat.v1 import InteractiveSession\r\n> > config = tf.ConfigProto()\r\n> > config.gpu_options.allow_growth = True\r\n> > session = InteractiveSession(config=config)\r\n> > ```\r\n> > \r\n> > \r\n> > Adding these lines in the main file running the model, worked like charm for me.\r\n> > @humaolin @achandraa\r\n> \r\n> But if i met this issue in command line, how to add these codes ?\r\n\r\nGlad my solution helped you. \r\n\r\nYou could add these lines at the top of your main script file and run your python file in the command line too with `python filename.py` \r\n\r\nor you could bash script these lines in your bash rc file. You can search it on google, how to add and run script in the bash file. But I wouldn't recommend that as it might unnecessarily acquire your GPU resource. \r\n@wadewangpower "]}, {"number": 28253, "title": "ImportError: cannot import name 'tflite_convert'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Pip\r\n- TensorFlow version (use command below): v1.13.1-0-g6612da8951\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/ 7.5\r\n- GPU model and memory: Tesla V100\r\n\r\n\r\nHow can i resolve this issue ???\r\n\r\n\r\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File \"./DeepSpeech.py\", line 21, in <module>\r\n    from tensorflow.contrib.lite.python import tflite_convert\r\n\r\n", "comments": ["@beeteax please provide the link which you are refering  and provide the complete log to help you with resolution.", "@beeteax Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28252, "title": "build error with nsync for -Werror=class-memaccess", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.11 and r2.0, or maybe others \r\n- Python version: 3.6.1\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source):  0.19.2\r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nwhen i execute command \"./tensorflow/contrib/makefile/build_all_linux.sh\" , i got this error:\r\n\r\ng++ -M -std=c++11 -DNSYNC_USE_CPP11_TIMEPOINT -DNSYNC_ATOMIC_CPP11 -I../../platform/c++11.futex -I../../platform/c++11 -I../../platform/gcc -I../../platform/posix -pthread -I../../public -I../../internal ../../internal/*.c ../../testing/*.c ../../platform/linux/src/nsync_semaphore_futex.c ../../platform/c++11/src/per_thread_waiter.cc ../../platform/c++11/src/yield.cc ../../platform/c++11/src/time_rep_timespec.cc ../../platform/c++11/src/nsync_panic.cc \\\r\n\t  ../../platform/c++11/src/start_thread.cc > dependfile\r\ng++ -DNSYNC_USE_CPP11_TIMEPOINT -DNSYNC_ATOMIC_CPP11 -I../../platform/c++11.futex -I../../platform/c++11 -I../../platform/gcc -I../../platform/posix -pthread -I../../public -I../../internal -O -std=c++11 -Werror -Wall -Wextra -pedantic -c ../../internal/common.c\r\ng++ -DNSYNC_USE_CPP11_TIMEPOINT -DNSYNC_ATOMIC_CPP11 -I../../platform/c++11.futex -I../../platform/c++11 -I../../platform/gcc -I../../platform/posix -pthread -I../../public -I../../internal -O -std=c++11 -Werror -Wall -Wextra -pedantic -c ../../internal/counter.c\r\n../../internal/counter.c: In function 'nsync::nsync_counter_s_* nsync::nsync_counter_new(uint32_t)':\r\n../../internal/counter.c:39:28: error: 'void* memset(void*, int, size_t)' clearing an object of type 'struct nsync::nsync_counter_s_' with no trivial copy-assignment; use value-initialization instead [-Werror=class-memaccess]\r\n   memset (c, 0, sizeof (*c));\r\n                            ^\r\n../../internal/counter.c:29:8: note: 'struct nsync::nsync_counter_s_' declared here\r\n struct nsync_counter_s_ {\r\n        ^~~~~~~~~~~~~~~~\r\ncc1plus: all warnings being treated as errors\r\nmake: *** [../../platform/posix/make.common:72: counter.o] Error 1\r\nroot@955406e6c46f:/opt/tensorflow-r2.0# gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/8/lto-wrapper\r\nOFFLOAD_TARGET_NAMES=nvptx-none\r\nOFFLOAD_TARGET_DEFAULT=1\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 8.3.0-6ubuntu1' --with-bugurl=file:///usr/share/doc/gcc-8/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-8 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\ngcc version 8.3.0 (Ubuntu 8.3.0-6ubuntu1) \r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@oyegod Please downgrade the GCC version to 4.8. Please find instructions in this [link](https://www.tensorflow.org/install/source#tested_build_configurations) which help you to build Tensorflow from source. Thanks!", " Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I had this issue and the problem was different version for gcc and g++, my gcc version was 7.5 and my g++ version was 9.3\r\nsolution:\r\nsudo apt install gcc-7 g++-7 gcc-8 g++-8 gcc-9 g++-9\r\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9 --slave /usr/bin/g++ g++ /usr/bin/g++-9 --slave /usr/bin/gcov gcov /usr/bin/gcov-9\r\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 --slave /usr/bin/g++ g++ /usr/bin/g++-8 --slave /usr/bin/gcov gcov /usr/bin/gcov-8\r\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 7 --slave /usr/bin/g++ g++ /usr/bin/g++-7 --slave /usr/bin/gcov gcov /usr/bin/gcov-7\r\n\r\n#select gcc-7 as compiler (version) -- press the number that points to gcc-7\r\nsudo update-alternatives --config gcc\r\n\r\n\r\n"]}, {"number": 28251, "title": "Code readability improve and used switch over if conditional", "body": "", "comments": ["@alanchiao Could you PTAL and approve.", "Can one of the admins verify this patch?", "@Dayananda-V Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 28250, "title": "Embedding Layer backpropagation issue during training when using Subclass API", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): There doesn't seem to be any example of using subclass API with model.fit with embedding layer\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):   binary\r\n- TensorFlow version (use command below):  tf-nightly-gpu-2.0-preview (2.0.0.dev20190428)\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory:  Geforce 940M 2GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen using Embedding Layer inside a Subclass Model with variable length between batches, \r\nduring training (model.fit), errors out as expected list of [batch_size, previous_batch_seq_len], received [batch_size, current_batch_seq_len].  Looks like it is unable to backpropagate correctly to the Embedding Layer with variable length.\r\n\r\nHowever there is no error when the Embedding Layer is set to trainable=False, or to use the embedding layer in a Functional API.\r\n\r\n**Describe the expected behavior**\r\nThere should not be any dimension error during back propagation for the Embedding Layer when using subclass API, when the same layer works in functional API with same model/inputs.\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nvocab_size=2\r\nlabel_size = 2\r\nclass Model(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.word_embedding = tf.keras.layers.Embedding(vocab_size, 100, trainable=True)\r\n        self.encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True))\r\n        self.classifier = tf.keras.layers.Dense(label_size)\r\n        \r\n    def call(self, word_ids):\r\n        x = self.word_embedding(word_ids)\r\n        x = self.encoder(x)\r\n        x = self.classifier(x)\r\n        return x\r\n\r\n\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n    from_logits=True, reduction='none')\r\n\r\ndef loss_function(real, pred):\r\n    real = tf.reshape(real, (-1,))\r\n    pred = tf.reshape(pred, (-1, pred.shape[-1]))\r\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n    loss_ = loss_object(real, pred)\r\n\r\n    mask = tf.cast(mask, dtype=loss_.dtype)\r\n    loss_ *= mask\r\n\r\n    return tf.reduce_mean(loss_)\r\n\r\n\r\ndef accuracy(y_true, y_pred):\r\n    y_pred = tf.argmax(tf.reshape(y_pred, (-1, y_pred.shape[-1])), axis=-1)\r\n    y_true = tf.reshape(y_true, (-1,))\r\n    y_pred = y_pred[y_true > 0]\r\n    y_true = y_true[y_true > 0]\r\n    return tf.metrics.categorical_accuracy(y_true[y_true > 0], y_pred[y_true > 0])\r\n\r\n\r\nmodel = Model()\r\nmodel.compile(optimizer=tf.optimizers.Adam(), loss=loss_function, metrics=[accuracy])\r\nmodel.fit(dataset)\r\n```\r\n\r\n\r\ntrain_data would be a tf.dataset produced using padded_batch that produces (word_ids, ner_tags) as inputs, labels.\r\n\r\nHere I created a toy example:\r\n```\r\ndef generator():\r\n    for data in zip([[1, 1, 1], [1, 1, 1, 1]], [[2, 2, 2], [2, 2, 2, 2]]):\r\n        yield data\r\ndataset = tf.data.Dataset.from_generator(generator, output_types=(tf.int64, tf.int64))\r\ndataset = dataset.padded_batch(1, ((None,), (None,)))\r\n```\r\n\r\nwhich will create 2 batches of size 1,  first batch has length 3, second batch has length 4.\r\n\r\nWhen embedding layer trainable set to False, model.fit runs successfully.\r\nWhen trainable set to True, it gets following error:\r\nInvalidArgumentError: Operation expected a list with 3 elements but got a list with 4 elements.", "comments": ["@joelzou925 Could you create a GitHub gist or format the code above so that it is clear so that we can reproduce the issue and resolve it faster. Thanks!", "> @joelzou925 Could you create a GitHub gist or format the code above so that it is clear so the we can reproduce the issue and resolve it faster. Thanks!\r\n\r\nSorry it was late night, I have updated the code and created a toy dataset that reproduces the problem.", "I could reproduce the issue with TF2.0.0-alpha0 and TF-nightly-2.0-preview. I noticed different `InvalidArgumentError' as shown below\r\n\r\n`InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2 2 2\r\n\t [[{{node loss/output_1_loss/SparseCategoricalCrossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_keras_scratch_graph_3574]` . Thanks!", "@joelzou925 I don't see any error with the latest `tf-nightly-gpu-2.0-preview==2.0.0.dev20190723`.\r\nHere is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/d6407dac539bf2b15db7daf205dea360/untitled315.ipynb). \r\n\r\nI am closing the issue. Feel free to open it if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28250\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28250\">No</a>\n"]}, {"number": 28249, "title": "tf.Module name scope nesting does not work as expected", "body": "Consider the following example:\r\n\r\n```Python\r\nimport tensorflow as tf\r\n\r\nwith_name_scope = tf.Module.with_name_scope\r\n\r\n\r\nclass Alpha(tf.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.var = None\r\n\r\n    @with_name_scope\r\n    def __call__(self, x):\r\n        if self.var is None:\r\n            self.var = tf.Variable(42., name='leaf')\r\n        return x + self.var\r\n\r\n\r\nclass Beta(tf.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.alpha = Alpha()\r\n\r\n    @with_name_scope\r\n    def __call__(self, x):\r\n        return self.alpha(x)\r\n\r\n\r\nclass Gamma(tf.Module):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.beta = Beta()\r\n\r\n    @with_name_scope\r\n    def __call__(self, x):\r\n        return self.beta(x)\r\n\r\n\r\ngamma = Gamma()\r\ngamma(1)\r\nprint(gamma.trainable_variables[0].name)\r\n```\r\n\r\nWhile the expected output is `gamma/beta/alpha/leaf:0`, the actual output is `alpha/leaf:0`. This appears to be because `_scope_name` in `tf.Module` has a trailing slash with breaks out of enclosing name scopes. \r\n\r\nIn contrast, substituting the following for `with_name_scope` works correctly:\r\n\r\n```python\r\ndef with_fixed_name_scope(method):\r\n    def wrapped(self, *args, **kwargs):\r\n        with tf.name_scope(self.name):\r\n            method(self, *args, **kwargs)\r\n    return wrapped\r\n\r\n\r\nwith_name_scope = with_fixed_name_scope\r\n```\r\n\r\nTested with TensorFlow 2.0 built from source (`5473bb187efacc3ce26a7203801aebac68045ee0`)", "comments": ["Hey ethereon@, thanks for the report. Module name scopes are fixed at construction time, and re entered whenever you use `@with_name_scope` or `with self.name_scope`. They are intentionally \"fully qualified\" (not sure if that's the right term) such that they don't inherit the scope from the caller. We've been using that pattern for variable naming in Sonnet for a few years now and it seems to be a sensible idea (reasoning about where you construct modules [and thus what name they will have] is often simpler than reasoning about where they will be used for the first time).\r\n\r\nIn this case what you'll want to do is manually enter the name scope in the constructor when creating the inner modules:\r\n\r\n```python\r\nclass Beta(tf.Module):\r\n    def __init__(self):\r\n        super(Beta, self).__init__()\r\n        with self.name_scope:\r\n          self.alpha = Alpha()\r\n\r\n    @with_name_scope\r\n    def __call__(self, x):\r\n        return self.alpha(x)\r\n\r\n\r\nclass Gamma(tf.Module):\r\n    def __init__(self):\r\n        super(Gamma, self).__init__()\r\n        with self.name_scope:\r\n          self.beta = Beta()\r\n\r\n    @with_name_scope\r\n    def __call__(self, x):\r\n        return self.beta(x)\r\n```\r\n\r\nWith that I get `gamma/beta/alpha/leaf:0`.\r\n\r\nIn the RFC we had designed `tf.Module` such that it would automatically enter the name scope for you in all methods (removing the need for the boilerplate). Sadly we found that in practice this makes it ~impossible for existing libraries (e.g. `tf.keras`) to adopt `tf.Module` (since this was backwards incompatible for existing checkpoints) so in e866995aff7d I made the scoping opt-in rather than opt-out (which in turn meant Keras Layer/Model could adopt `tf.Module` in 23c8fd4ca3).\r\n\r\nIf you'd prefer the automatic name scoping (I do) then I'd suggest keeping an eye out for the open source release of Sonnet 2 (c.f. deepmind/sonnet#117). The only real difference between `tf.Module` and `snt.Module` is that in Sonnet name scoping is opt out. We've taken a bit more time than we thought to actually open source the code, but we're working on that right now and I hope to have something public quite soon."]}, {"number": 28248, "title": "[TF 2.0] Using tf.py_function which has tf.string type input in dataset.map() generates dtype warning.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): unknown 2.0.0-dev20190428\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0, cudnn-10.0-windows10-x64-v7.5.0.56\r\n- GPU model and memory: GeForce GTX 1070 8GB\r\n\r\n**Describe the current behavior**\r\nUsing tf.py_function which has tf.string type input generates warning like this:\r\n\r\n> W0429 14:24:18.965364 13252 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\r\n\r\nThis warning did not shown with v1.12.0-9492-g2c319fb415 2.0.0-alpha0, but 2.0.0-dev20190428 does.\r\n\r\n**Describe the expected behavior**\r\ndtype warning should not be shown.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef transform_tag_python(x):\r\n    return 1.0\r\n\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(['tag1'])\r\ndataset = dataset.map(lambda x: tf.py_function(\r\n    transform_tag_python, (x,), (tf.float32,)))\r\n\r\nfor sample in dataset:\r\n    print(sample)\r\n```", "comments": ["Look where tf.py_function is defined there is no such warning file present regarding dtype to be float. So why it is showing this?", "I am facing the same issue.", "@KichangKim There was no warning when `TF2.0.0-alpha0` or `tf-nightly` was used. The issue was reproduced with `tf-nightly-2.0-preview`. We will check for the source of error and resolve it. Thanks for finding this. Thanks!", "Here:\r\nhttps://github.com/tensorflow/tensorflow/blob/88ed9779719b8b2136a596c7b4dda875568894a3/tensorflow/python/eager/backprop.py#L841\r\n\r\nHaving the same issue even though the statement is not within `tf.GradientTape`.\r\n\r\nEven simpler example:\r\n```python\r\nimport tensorflow as tf\r\n\r\ntensor = tf.constant([1,2,3])\r\ntf.py_function(lambda x: x.numpy(), [tensor], tensor.dtype)\r\n```\r\n\r\nI am wondering why this code is called anyways. My example does not even use `GradientTape`.\r\n\r\nCallstack of test.py (just includes code above):\r\n![grafik](https://user-images.githubusercontent.com/9438971/59639047-54f5f480-915a-11e9-916c-a8e958fd6f14.png)\r\n\r\nI am not sure it is intended that a `py_function` has a `GradientTape` by default.\r\n", "It's likely the tape.watch here https://github.com/tensorflow/tensorflow/blob/88520c4dd6aa804330b053a35676eeffc3380d65/tensorflow/python/ops/script_ops.py#L108 which needs to be called only for floating dtypes.", "I'll happily accept a PR to fix this.", "The PR #30107 is submitted to fix this issue.\r\n\r\ncc @alextp ", "Looks like the PR failed a few checks. Is the issue still persisting?", "This issue still exists in tf-2 version beta-1.", "You have to use nightly builds"]}, {"number": 28247, "title": "[TF 2.0] Inconsistent behaviour of tf.io.decode_image() and tf.image.resize() in dataset.map()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0, cudnn-10.0-windows10-x64-v7.5.0.56\r\n- GPU model and memory: GeForce GTX 1070 8GB\r\n\r\n**Describe the current behavior**\r\nUsing tf.io.decode_image() and tf.image.resize() in dataset.map() generates ValueError: 'images' contains no shape. exception. But using it from normal python code, it works without any problem.\r\n\r\n**Describe the expected behavior**\r\ntf.io.decode_image() and tf.image.resize() should work without any exception in dataset.map().\r\n\r\n**Code to reproduce the issue**\r\nYou can see that this code works correctly.\r\n```\r\ndef load_image(x):\r\n    image = tf.io.read_file(x)\r\n    image = tf.io.decode_image(image)\r\n    image = tf.image.resize(image, size=(\r\n        128, 128), preserve_aspect_ratio=True)\r\n\r\n    return image\r\n\r\n\r\nwith tf.device('/cpu:0'):\r\n    image_2 = load_image('test.jpg')\r\n    print(image_2.numpy().shape)\r\n```\r\n\r\nBut this code will be failed.\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef load_image(x):\r\n    image = tf.io.read_file(x)\r\n    image = tf.io.decode_image(image)\r\n    image = tf.image.resize(image, size=(\r\n        128, 128), preserve_aspect_ratio=True)\r\n\r\n    return image\r\n\r\n\r\nwith tf.device('/cpu:0'):\r\n    dataset = tf.data.Dataset.from_tensor_slices(['test.jpg'])\r\n    dataset = dataset.map(load_image)\r\n\r\n    for image in dataset:\r\n        print(image.numpy().shape)\r\n```\r\nChanging tf.io.decode_image() to tf.io.decode_png() or tf.io.decode_jpeg() can be temporary solution.", "comments": ["@KichangKim Able to reproduce the issue with the code provided , attached the log. Changing tf.io.decode_image() to tf.io.decode_png() or tf.io.decode_jpeg() shows no error. Thanks!\r\n\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-2-47f82ea954bc> in <module>()\r\n     13 with tf.device('/cpu:0'):\r\n     14     dataset = tf.data.Dataset.from_tensor_slices(['test.jpg'])\r\n---> 15     dataset = dataset.map(load_image)\r\n     16 \r\n     17     for image in dataset:\r\n\r\n12 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py in _resize_images_common(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\r\n    964     images = ops.convert_to_tensor(images, name='images')\r\n    965     if images.get_shape().ndims is None:\r\n--> 966       raise ValueError('\\'images\\' contains no shape.')\r\n    967     # TODO(shlens): Migrate this functionality to the underlying Op's.\r\n    968     is_batch = True\r\n\r\nValueError: 'images' contains no shape.", "This is expected difference in behavior between eager-mode and graph-mode execution.\r\n\r\nWithout tf.data the `load_image` function is executed eagerly and thus the `decode_image` knows that it is dealing with a JPEG and will be able to determine the shape of the image.\r\n\r\nWhen tf.data, the `load_image` function will be traced (i.e. converted to a graph) and in that case, the shape of the image will not be known.\r\n\r\nIn particular, the following program executing the `load_image` method using a `tf.function` produces the same behavior as tf.data.\r\n\r\n```\r\n@tf.function\r\ndef load_image(x):\r\n    image = tf.io.read_file(x)\r\n    image = tf.io.decode_image(image)\r\n    image = tf.image.resize(image, size=(\r\n        128, 128), preserve_aspect_ratio=True)\r\n\r\n    return image\r\n\r\nwith tf.device('/cpu:0'):\r\n    image_2 = load_image('test.jpg')\r\n    print(image_2.numpy().shape)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28247\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28247\">No</a>\n"]}, {"number": 28246, "title": "[TF 2.0] Using preserve_aspect_ratio=True in tf.image.resize() generates deprecation warning.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0, cudnn-10.0-windows10-x64-v7.5.0.56\r\n- GPU model and memory: GeForce GTX 1070 8GB\r\n\r\n**Describe the current behavior**\r\nUsing preserver_aspect_ratio flag generates deprecation warnings.\r\n0429 13:13:47.903097 23940 deprecation.py:323] From \r\n\r\n> C:\\Users\\XXXXXX\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:993: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nW0429 13:13:47.905097 23940 deprecation.py:323] From \r\n\r\n> C:\\Users\\XXXXXX\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:999: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n\r\n**Describe the expected behavior**\r\nShould not show warning.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef load_image(x):\r\n    image = tf.io.read_file(x)\r\n    image = tf.io.decode_png(image)\r\n    image = tf.image.resize(image, size=(\r\n        128, 128), preserve_aspect_ratio=True)\r\n\r\n    return image\r\n\r\n\r\nwith tf.device('/cpu:0'):\r\n    image_2 = load_image('test.jpg')\r\n    print(image_2.numpy().shape)\r\n```", "comments": ["@KichangKim The warnings should have been fixed in: https://github.com/tensorflow/tensorflow/commit/df3a3375941b9e920667acfe72fb4c33a8f45503", "Thanks for investigation."]}, {"number": 28245, "title": "[feature request] Bidirectional with explict cell_fw & cell_bw parameters", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): all version with `tf.keras.layers.Bidirectional`\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nFor bidirectional rnns, the TF native API EXPLICITLY specifies the forward & backward rnn cells as in `tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw)`, while the high-level keras API `tf.keras.layers.Bidirectional(tf.keras.layers.RNN(cell, unroll=True))` creates forward and backward layers IMPLICITLY, which may cause confusion. \r\n\r\n> Just recall how much confusion `tf.nn.rnn_cell.MultiRNNCell` has caused with TF 0.12: At that time, a list of the **SAME** RNNCell instance is passed but different parameters are created for each RNN layer. Later this behaviour is fixed with a list of **DIFFERENT** RNNCell instances, and a list of the **SAME** RNNCell instance will lead to parameter sharing across layers.\r\n\r\nMy point is, `tf.keras.layers.Bidirectional` should accept two RNNCell instances (one forward and one backward). If both `cell_fw` and `cell_bw` are exposed to users, it will be more consistent with the TF native API and users will know they are using two different RNN cells for forward and backward purpose.\r\n\r\nThis new interface design also enables more complicated use cases, e.g.: using a 2-layer forward LSTM with hidden size 1024 each layer & a 3-layer backward GRU with hidden size 512 each layer, or sharing the parameters between forward & backward RNN if users wish.\r\n\r\n**Will this change the current api? How?**\r\nNo. Due to compatibility concern, the `cell_fw` and `cell_bw` can be designated as key word arguments, making sure normal users are not influenced while higher level users gain more control.\r\n\r\n**Who will benefit with this feature?**\r\nAdvanced RNN users. Or users familiar with the original `tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw)` API.\r\n", "comments": ["Ack, thanks for the feature request, I think it make sense to make this change, will send an update within this week.", "Thanks.", "This should now be fixed by https://github.com/tensorflow/tensorflow/commit/fe5e1f39590f5847a384dcccb33956a5c2606d16", "Such a quick fix."]}, {"number": 28244, "title": "Want the tf.signal.stft function to return the complete output (i.e. both the positive and negative frequencies)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThe STFT Tensorflow function takes into consideration the Hermitian symmetry of the generated output i.e. it only considers the positive frequency elements. Is there a way to recover the entire pre-processed tensor that contains all the calculated elements?\r\n\r\nIn other words, is there a way to calculate the STFT of an input tensor and generate a spectrogram that has dimensions `fft_length * frame_length`?\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis will just add an additional feature to the existing function.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone who is doing audio processing using Tensorflow.\r\n\r\n**Any Other info.**\r\n", "comments": ["Hi @karanpareek96,\r\n\r\nWe follow `scipy.signal.stft`'s behavior here, which is to not return the Hermitian symmetric components. This allows us to use an RFFT instead of an FFT, which is generally 2x faster and uses less memory. The Hermitian symmetric component are duplicated, so you could conjugate and reverse the result from `tf.signal.stft`, and concatenate the two together. \r\n\r\nAlso, it should be easy to define your own stft that uses FFT instead of RFFT. The implementation of `tf.signal.stft` is quite simple, since it calls other functions: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/signal/spectral_ops.py#L68-L92\r\n\r\nExample (that I haven't run, so it might not work :), but hopefully you get the idea).\r\n\r\n```python\r\ndef complex_input_stft(x, frame_length, frame_step, fft_length, window_fn=tf.signal.hann_window, pad_end):\r\n  frames = tf.signal.frame(x, frame_length, frame_step, pad_end=pad_end)\r\n  frames *= window_fn(frame_length, dtype=frames.dtype)\r\n  return tf.signal.fft(frames, [fft_length])\r\n```"]}, {"number": 28243, "title": "Batch_to_space-ND test case added to indicate empty Tensor output beh\u2026", "body": "Batch_to_space-ND test case added to indicate empty Tensor output behavior", "comments": ["@alanchiao Could you PTAL and approve.", "@jianlijianli : Gentle Reminder!!!", "Can one of the admins verify this patch?", "@yyoon : Sorry for late response. I have handled as per your comment, please check and approve. Thanks!"]}, {"number": 28242, "title": "remove duplicate check", "body": "As shown by the function name `CompilationDisallowedByXlaCompileAttr`, I think we should respect `kXlaCompileAttr` first even if there is not a candidate JIT device. Actually,  the JIT device check is done again followed by this check.", "comments": []}, {"number": 28241, "title": "tf.image and eager execution bug", "body": "For tensorflow 1.13 and 2.0.0a, tf.image requires explicit `tf.constant` instead of `numpy` arrays.\r\n\r\nhttps://colab.research.google.com/drive/1CrbsY4L7KJLP3IuB_gs4KJiz2szuVDb9\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\nimage = np.random.random([512, 512, 1])\r\ntf.square(image, image).shape # works\r\n\r\n\r\nimage = np.random.random([512, 512, 1])\r\ntf.image.ssim_multiscale(image, image, max_val=1).shape # fails  \r\n\r\nimage = tf.constant(np.random.random([512, 512, 1]))\r\ntf.image.ssim_multiscale(image, image, max_val=1) # works\r\n```\r\n\r\n", "comments": ["@Ouwen The link is not accessible, could you post the code instead?", "@yongtang my apologies, I've changed the settings on the colab notebook and posted the code above.", "I could reproduce the issue in TF2.0. I think either we need to update the code or update the doc saying the dtype of img should be a tensor. Thanks!", "Added a PR #28274 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28241\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28241\">No</a>\n"]}, {"number": 28240, "title": "tensorflow/lite/experimental/microfrontend/lib/frontend_memmap_genera\u2026", "body": "I added a missing fprintf string argument in tensorflow/lite/experimental/microfrontend/lib/frontend_memmap_generator.c, which probably would have caused a memory fault.  I am currently having a build problem so I have not tried running it, but I did confirm that compiling this file from the command line with g++ originally generated an appropriate warning about this problem and that this change at least eliminates that warning.\r\n\r\nI am not currently a tensorflow user or developer, but just happened to notice this problem when trying out cppcheck on different source trees.  Because of this and the problem I was having with bazel, I have not included the unit test recommended by your coding guidelines.  Because this change is trivial and only effects a code path that probably almost always crashed before, I hope you will merge this patch without the test case for now.\r\n\r\nThanks for considering this patch.", "comments": ["@adamjrichter Please sign CLA in order to proceed with next steps. Thank you !", "I already signed the CLA, earlier this weekend, before I made that pull\nrequest. GitHub seems to know that, judging by the response screen that it\nput up for my pull request that also indicated that I had already signed\nthe CLA.\n\nPlease let me know if there is some specific action I should take that\nwould help resolve this.\n\nThanks for your quick processing of my submission.\n\nAdam\n\n\nOn Sun, Apr 28, 2019, 8:14 PM gbaned <notifications@github.com> wrote:\n\n> @adamjrichter <https://github.com/adamjrichter> Please sign CLA in order\n> to proceed with next steps. Thank you !\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/28240#issuecomment-487441141>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFKY5SC7QRUIG7RYUFESZXDPSZRZBANCNFSM4HI7O5EA>\n> .\n>\n", "Thanks for catching this!"]}, {"number": 28239, "title": "Minor docs fix for is_gpu_available", "body": "Updated minor issues mentioned in https://github.com/tensorflow/tensorflow/pull/27566/files#r277458757\r\n\r\ncc @annarev ", "comments": []}, {"number": 28238, "title": "[TF 2.0 API Docs] tf.audio.encode_wav", "body": "API Doc update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/encode_wav\r\n\r\nCorrect links? No\r\nClear Description? No\r\nUsage Example?\r\nParameters Defined? Yes, not verified against current code\r\nReturns defined? Yes, not verified against current code\r\nRaises listed and defined? No\r\nVisuals, if applicable? No\r\n\r\nI will submit a PR, please assign this bug to me.\r\n\r\nPart of Issue #28237 & Issue #28236 ", "comments": ["@missaugustina Can you please let us know if this is the duplicate of [#28237](https://github.com/tensorflow/tensorflow/issues/28237), if so please let us know so that we will close this issue as the same issue is being referenced in #28237", "This is not a duplicate.", "Updated description with more info. ", "These details are generated through .pbtxt file, you can see the same details [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_EncodeWav.pbtxt). \r\nFor tutorials and usage examples on tf.audio, you can refer this [link](https://github.com/tensorflow/docs/tree/master/site/en/tutorials/audio), Thanks.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28237, "title": "[TF 2.0 API Docs] tf.audio.decode_wav", "body": "API doc update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/decode_wav\r\n\r\nCorrect links? No\r\nClear Description? No\r\nUsage Example?\r\nParameters Defined? Yes, not verified against current code\r\nReturns defined? Yes, not verified against current code\r\nRaises listed and defined? No\r\nVisuals, if applicable? No\r\n\r\nI will submit a PR, please assign this bug to me.\r\n\r\n\r\n", "comments": ["@missaugustina  Could you provide more details about the what you want to work on and context. Thanks!", "Edited issue with more detailed info", "Related to Issue #28236", "@missaugustina Are there any examples of tf.audio.decode_wav out on the web? Appreciate it's a work in progress, but getting a \"Header Mismatch error\" when trying to open a wav.\r\n\r\n`df = tf.audio.decode_wav('Saw.wav')`\r\n\r\nInvalidArgumentError: Header mismatch: Expected RIFF but found Saw. [Op:DecodeWav]", "Just got this answered on SO...\r\n\r\n```\r\nraw_audio = tf.io.read_file(filename)\r\nwaveform = tf.audio.decode_wav(raw_audio)\r\n```\r\n\r\nhttps://stackoverflow.com/questions/58096095/how-does-tf-audio-decode-wav-get-its-contents", "@robgmsn \r\nAs mentioned please use \" tf.enable_eager_execution()\" to get shape of waveform and also confirm if this is still an issue else move tho closed status.\r\n\r\nAlso please upgrade to later versions of tf as many bugs are fixed.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28236, "title": "[TF 2.0 API Docs] tf.audio", "body": "Docs update for https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio\r\n\r\nNeeds high level description & usage example\r\n\r\nI plan to submit a PR for this issue, please assign to me", "comments": ["Found this question on stack overflow - https://stackoverflow.com/questions/48675097/from-audio-to-tensor-back-to-audio-in-tensorflow (search for https://stackoverflow.com/search?q=tensorflow+audio)", "Updated description ", "Asked for help in Gitter - tensorflow/sig-io\r\n\r\nAugustina Ragwitz @missaugustina 12:54\r\nI'm working on updating the tf.audio docs & I was wondering if anyone here had a moment to talk to me about TF's audio encoding implementation? I'm seeing fragments littered throughout the code base & I'm not quite sure how it ties into the api interface.\r\nmy guess is the implementation lives here but something else i found suggested it would be moved to the IO repo... but I haven't found it there (or don't know where to look) contrib/ffmpeg/\r\n\r\nAugustina Ragwitz @missaugustina 13:06\r\nContext: here is the parent api doc for the namespace tf.audio - https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio/\r\n\r\nwhen i started looking for encode_audio & decode_audio this is what i found - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ffmpeg", "Response from sig-io folks:\r\n\r\nYong Tang @yongtang 14:56\r\n@missaugustina Thanks for the interests!\r\n\r\nThe tf.contrib.ffmpeg is being moved to tensorflow-io, with tensorflow_io.video supporting video file formats. The audio functionalities of tf.contrib.ffmpeg has not been moved yet (I was planning to do so but haven't had time yet).\r\n\r\nThe WAV dataset (implemented as tf.data.Dataset) is being added in the PR: tensorflow/io#134\r\n\r\nOne thing to note is that there are some subtle differences between tensorflow_io.video and tf.contrib.ffmpeg. tf.contrib.ffmpeg will spawn an outside process and use the command line ffmpeg to capture the stdout/stderr. The tensorflow_io.video link with ffmpeg (dynamically) and calls ffmpeg's API directly. Also, tensorflow_io.video renders tf.data.Dataset so you could use the dataset directly with tf.keras. For tf.contrib.ffmpeg you could not use it with tf.keras directly.\r\n", "Yong Tang @yongtang 15:09\r\n@missaugustina There is an email thread about tensorflow_io.video and how to use it with tf.keras for easy feature extraction and classification:\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/io/ctHeERQj5nw\r\nThink it might help in using Dataset with tf.keras.\r\n\r\nThe AudioDataset in tensorflow-io (Have been trying to find some time to implement it, but haven't had time yet -- will try to speed up) will likely follow the similar format as video, and will be easily integrated with tf.keras.\r\n\r\n\r\nAugustina Ragwitz @missaugustina 15:10\r\nOK great thanks @yongtang ! Let me know if I can help with it in anyway, even if it's just small busywork stuff like test coverage", "The  Module: `tf.audio` gives the detail about the functions available under that module, for usage example you can check the link specified for each functions [here](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/audio). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 28235, "title": "Fix invalid deprecation pointer for tf.layers.average_pooling1d/max_pooling1d", "body": "In tf.layers the deprecation notice of tf.layers.average_pooling1d/max_pooling1d points to non-existance tf.keras.layers.average_pooling1d/max_pooling1d.\r\n\r\nThis fix updates the notice to point to tf.keras.layers.AveragePooling1D/MaxPooling1D\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 28234, "title": "python 3.6 unable to import tensorflow", "body": "Unable to import tensorflow in python 3.6\r\n#######################\r\npip3 list \r\n:\\Users\\ADMIN>pip3 list\r\nEPRECATION: The default format will switch to columns in the future. You can us\r\n --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.con\r\n under the [list] section) to disable this warning.\r\nbsl-py (0.7.1)\r\nstor (0.7.1)\r\nast (0.2.2)\r\nrpcio (1.20.1)\r\n5py (2.9.0)\r\neras-Applications (1.0.7)\r\neras-Preprocessing (1.0.9)\r\narkdown (3.1)\r\nock (2.0.0)\r\numpy (1.16.3)\r\nbr (5.2.0)\r\nip (9.0.1)\r\nrotobuf (3.7.1)\r\netuptools (28.8.0)\r\nix (1.12.0)\r\nensorboard (1.13.1)\r\nensorflow (1.13.1)\r\nensorflow-estimator (1.13.0)\r\nermcolor (1.1.0)\r\nerkzeug (0.15.2)\r\nheel (0.33.1)\r\nou are using pip version 9.0.1, however version 19.1 is available.\r\nou should consider upgrading via the 'python -m pip install --upgrade pip' comm\r\nnd.\r\n\r\n:\\Users\\ADMIN>\r\n#######################\r\nC:\\Users\\ADMIN>python\r\nPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AM\r\nD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, i\r\nn <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", lin\r\ne 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>\r\n\r\n\r\nC:\\Users\\ADMIN>tensorflowpython -c \"import tensorflow as tf; print(tf.version.GI\r\nT_VERSION, tf.version.VERSION)\r\n'tensorflowpython' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\nC:\\Users\\ADMIN>tensorflow python -c \"import tensorflow as tf; print(tf.version.G\r\nIT_VERSION, tf.version.VERSION)\r\n'tensorflow' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\nC:\\Users\\ADMIN>python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION,\r\n tf.version.VERSION)\r\nTraceback (most recent call last):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, i\r\nn <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", lin\r\ne 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow\r\n_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialisation routin\r\ne failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nC:\\Users\\ADMIN>\r\n\r\n\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 8.1\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.13.1-cp36-cp36m-win_amd64.whl\r\n- **TensorFlow version (use command below)**: pip3 install https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.13.1-cp36-cp36m-win_amd64.whl\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@pardeep3december, Please refer the similar issue on  [#23683](https://github.com/tensorflow/tensorflow/issues/23683). And let us know if that helps.  Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28233, "title": "[tf.keras.layers.ReLU] Layer returns 0 if threshold is negative and max_value is set #28230", "body": "Tried to solve #28230 ", "comments": ["@rthadur please somebody review it?", "Please @mihaimaruseac  can you review it?", "Would be good to also have a test", "Closing as there is no more activity"]}, {"number": 28232, "title": "Warning recommends using unexisting tf.keras.layers.CuDNNLSTM layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce GTX 1080 Ti, 11175MiB\r\n\r\n**Describe the current behavior**\r\nIn TF-GPU 2.0 \r\n\r\n**Describe the expected behavior**\r\nEither have a `tf.keras.layers.CuDNNLSTM` or remove the warning.\r\n\r\n**Code to reproduce the issue**\r\nThis to raise the warning\r\n\r\n    import tensorflow as tf\r\n    import tensorflow.keras.layers as ll\r\n    input_ = ll.Input((100,50))\r\n    x = ll.LSTM(100)(input_)\r\n\r\nThis to try to use CuDNNLSTM \r\n\r\n    import tensorflow as tf\r\n    import tensorflow.keras.layers as ll\r\n    input_ = ll.Input((100,50))\r\n    x = tf.keras.layers.CuDNNLSTM(100)(input_)\r\n\r\n**Other info / logs**\r\n\r\nThe warning message:\r\n\r\n    W0428 17:18:46.256715 140569873639168 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fd8c75a9940>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\r\n\r\nWhen trying to call CuDNNLSTM:\r\n\r\n    AttributeError: module 'tensorflow.keras.layers' has no attribute 'CuDNNLSTM'", "comments": ["@Jsevillamol Able to reproduce the issue. TF 2.0.0-alpha0 uses tf.compat.v1.keras.layers.CuDNNLSTM Please check the reference [link](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/compat/v1/keras/layers/CuDNNLSTM?hl=en)\r\n\r\nI had updated the code with this alias as below and I dont see cuDNNLSTM warning.Please let us know how it progresses. Thanks!\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as ll\r\ninput_ = ll.Input((100,50))\r\nx = tf.compat.v1.keras.layers.CuDNNLSTM(100)(input_)\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.", "I also have encountered this issue.\r\nAs @muddham mentioned, when I used `tf.compat.v1.keras.layers.LSTM` to replace it, the warning message was gone.\r\n\r\nHowever, I found that although the warning appears when using `tf.keras.layers.LSTM`,\r\nthe training efficiency are the same as  `tf.compat.v1.keras.layers.CuDNNLSTM`\r\n(Of course both are many times faster than `tf.compat.v1.keras.layers.LSTM`)\r\n\r\nI wonder if it is just fine to remove the warning.", "@hchungdelta I noticed that I am confused.  In my installation of TF 2.0 there is no longer a `tf.keras.layers.CuDNNLSTM`, just the the `tf.compat.v1.keras.layers.CuDNNLSTM` one.", "@Jsevillamol  You are right. And I must apologize since I misuse the name in previous comment. \r\nI use `tf.keras.layers.LSTM`  not `tf.keras.layers.CuDNNLSTM`.  (I edited the previous comment, sorry about making confusing)\r\n`tf.keras.layers.CuDNNLSTM` no longer exists in TF 2.0. Since it was already combined into LSTM.(So you might see the function name of LSTM is \"UnifiedLSTM\"). \r\n \r\n\r\n\r\n", "@Jsevillamol Please confirm if you are happy to close this issue.", "@muddham I am happy to close the issue if you are - I personally think that the warning should be removed in TF 2.0 since it is misleading for new users, but it is not causing me any major trouble.", "@Jsevillamol I could reproduce the Attribute Error but I don't see any warning as you mentioned. Please check my GitHub [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/8a2b480eefa661f5acd8c93cae10b967/untitled138.ipynb) and try to run it on your system. If you see the warning, please let me know I could work on resolving the `warning`. Thanks", "I Could reproduce the warning message using tensorflow gpu. please see attached\r\n![image](https://user-images.githubusercontent.com/48215502/57275026-c605af00-70ba-11e9-9ff6-a4bb1fe9cabe.png)\r\n", "@Jsevillamol Could check my [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/573ca634e39162eb4c48cabe042b89ca/untitled138.ipynb) and may be upgrade your TF2.0.0-alpha0 and run it again. If you see any error, we would like to resolve that. Thanks!", "@jvishnuvardhan I can no longer reproduce the issue!", " tf.compat.v1.keras.layers.CuDNNLSTM  works for me. Is it going to be available on non-beta1 platforms? What replaces it in TF 2.0.0-beta1 ?"]}, {"number": 28231, "title": "Tensor.graph is meaningless when eager execution is enabled. in TF 2.0, when compiling model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.0.0-alpha0`\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce GTX 1080 Ti, 11175MiB\r\n\r\n**Describe the current behavior**\r\nAfter migrating to TF 2.0, when compiling a custom model I wrote I get an error `AttributeError: Tensor.graph is meaningless when eager execution is enabled.`\r\n\r\nThe model compiled as expected in TF 1.13\r\n\r\n**Describe the expected behavior**\r\ncompile the model without raising any exceptions.\r\n\r\n**Code to reproduce the issue**\r\nRun [this script](https://gist.github.com/Jsevillamol/1db0121e4d8b2b95a13ea14f010169d0) passing as an argument [this file](https://gist.github.com/Jsevillamol/94bbf97e062fff7d6cc95200a6e6d78a) to create an h5 keras model.\r\n\r\nThen `load_model` the resulting h5 file and call `model.compile('adam', 'categorical_crossentropy')`.\r\n\r\n**Other info / logs**\r\n\r\n```\r\nIn [5]: model.compile('adam', 'categorical_crossentropy', ['acc'])                                                                                           \r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-5-9c84ced6c9fd> in <module>\r\n----> 1 model.compile('adam', 'categorical_crossentropy', ['acc'])\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    454     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    455     try:\r\n--> 456       result = method(self, *args, **kwargs)\r\n    457     finally:\r\n    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    428       #                   loss_weight_2 * output_2_loss_fn(...) +\r\n    429       #                   layer losses.\r\n--> 430       self.total_loss = self._prepare_total_loss(skip_target_indices, masks)\r\n    431 \r\n    432       # Functions for train, test and predict will\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _prepare_total_loss(self, skip_target_indices, masks)\r\n   1729 \r\n   1730       # Add regularization penalties and other layer-specific losses.\r\n-> 1731       if self.losses:\r\n   1732         total_loss += losses_utils.scale_loss_for_distribution(\r\n   1733             math_ops.add_n(self.losses))\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in losses(self)\r\n    664     with ops.init_scope():\r\n    665       if context.executing_eagerly():\r\n--> 666         return [loss for loss in losses\r\n    667                 if loss.graph == ops.get_default_graph()]\r\n    668 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in <listcomp>(.0)\r\n    665       if context.executing_eagerly():\r\n    666         return [loss for loss in losses\r\n--> 667                 if loss.graph == ops.get_default_graph()]\r\n    668 \r\n    669     relevant_inputs = []\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in graph(self)\r\n    937   def graph(self):\r\n    938     raise AttributeError(\r\n--> 939         \"Tensor.graph is meaningless when eager execution is enabled.\")\r\n    940 \r\n    941   @property\r\n\r\nAttributeError: Tensor.graph is meaningless when eager execution is enabled.\r\n```\r\n\r\n`model.summary()`\r\n\r\n```\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_1 (InputLayer)            [(None, 4, 108, 108, 0                                            \r\n__________________________________________________________________________________________________\r\nconv2D_0 (TimeDistributed)      (None, 4, 108, 108,  320         input_1[0][0]                    \r\n__________________________________________________________________________________________________\r\nmaxpool_0 (TimeDistributed)     (None, 4, 54, 54, 32 0           conv2D_0[0][0]                   \r\n__________________________________________________________________________________________________\r\nbatchnorm_0 (TimeDistributed)   (None, 4, 54, 54, 32 128         maxpool_0[0][0]                  \r\n__________________________________________________________________________________________________\r\nconv2D_1 (TimeDistributed)      (None, 4, 54, 54, 32 9248        batchnorm_0[0][0]                \r\n__________________________________________________________________________________________________\r\nmaxpool_1 (TimeDistributed)     (None, 4, 27, 27, 32 0           conv2D_1[0][0]                   \r\n__________________________________________________________________________________________________\r\nbatchnorm_1 (TimeDistributed)   (None, 4, 27, 27, 32 128         maxpool_1[0][0]                  \r\n__________________________________________________________________________________________________\r\nconv2D_2 (TimeDistributed)      (None, 4, 27, 27, 64 18496       batchnorm_1[0][0]                \r\n__________________________________________________________________________________________________\r\nmaxpool_2 (TimeDistributed)     (None, 4, 13, 13, 64 0           conv2D_2[0][0]                   \r\n__________________________________________________________________________________________________\r\nbatchnorm_2 (TimeDistributed)   (None, 4, 13, 13, 64 256         maxpool_2[0][0]                  \r\n__________________________________________________________________________________________________\r\nconv2D_3 (TimeDistributed)      (None, 4, 13, 13, 12 73856       batchnorm_2[0][0]                \r\n__________________________________________________________________________________________________\r\nmaxpool_3 (TimeDistributed)     (None, 4, 6, 6, 128) 0           conv2D_3[0][0]                   \r\n__________________________________________________________________________________________________\r\nbatchnorm_3 (TimeDistributed)   (None, 4, 6, 6, 128) 512         maxpool_3[0][0]                  \r\n__________________________________________________________________________________________________\r\nflatten (TimeDistributed)       (None, 4, 4608)      0           batchnorm_3[0][0]                \r\n__________________________________________________________________________________________________\r\ndropout (TimeDistributed)       (None, 4, 4608)      0           flatten[0][0]                    \r\n__________________________________________________________________________________________________\r\nunified_lstm (UnifiedLSTM)      (None, 4, 2048)      54534144    dropout[0][0]                    \r\n__________________________________________________________________________________________________\r\ntime_distributed (TimeDistribut (None, 4, 1)         2049        unified_lstm[0][0]               \r\n__________________________________________________________________________________________________\r\nflatten_1 (Flatten)             (None, 4)            0           time_distributed[0][0]           \r\n__________________________________________________________________________________________________\r\nsoftmax (Softmax)               (None, 4)            0           flatten_1[0][0]                  \r\n__________________________________________________________________________________________________\r\ndot (Dot)                       (None, 2048)         0           unified_lstm[0][0]               \r\n                                                                 softmax[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 1024)         2098176     dot[0][0]                        \r\n__________________________________________________________________________________________________\r\ndropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_2 (Dense)                 (None, 512)          524800      dropout_1[0][0]                  \r\n__________________________________________________________________________________________________\r\ndropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_3 (Dense)                 (None, 2)            1026        dropout_2[0][0]                  \r\n==================================================================================================\r\nTotal params: 57,263,139\r\nTrainable params: 57,262,627\r\nNon-trainable params: 512\r\n__________________________________________________________________________________________________\r\n```\r\n", "comments": ["I believe this bug has been fixed in nightly by @omalleyt12 so upgrade to tf-nightly-2.0-preview or tf-nightly-gpu-2.0-preview and your code will work.", "Specifically, this commit fixed it: https://github.com/tensorflow/tensorflow/commit/809a0332eb53eedf1c3257f2a2b5556ca9320e56", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28231\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28231\">No</a>\n"]}]