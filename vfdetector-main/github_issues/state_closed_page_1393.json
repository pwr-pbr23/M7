[{"number": 11270, "title": "Spelling", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11269, "title": "Build failure for r1.2  & master (r1.1 builds fine)", "body": "### System information\r\n== cat /etc/issue ===============================================\r\nLinux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"25 (Workstation Edition)\"\r\nVERSION_ID=25\r\nREDHAT_BUGZILLA_PRODUCT_VERSION=25\r\nREDHAT_SUPPORT_PRODUCT_VERSION=25\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 6.3.1 20161221 (Red Hat 6.3.1-1)\r\nCopyright (C) 2016 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux Lounge 4.11.8-200.fc25.x86_64 #1 SMP Thu Jun 29 16:13:56 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\ntensorflow-tensorboard (0.1.2)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-1709-g679bb02\r\ntf.COMPILER_VERSION = v1.2.0-1709-g679bb02\r\nSanity check: array([1], dtype=int32)\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\nImportError: No module named pywrap_tensorflow_internal\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda::/usr/local/cuda-7.5/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Jul  4 21:42:35 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 750 Ti  Off  | 0000:01:00.0      On |                  N/A |\r\n|  6%   36C    P8     1W /  38W |    243MiB /  2000MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1490    G   /usr/bin/gnome-shell                           118MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n\r\n### Describe the problem\r\nI've managed to compile tf r1.1 with CUDA support with no problems. Howwever r1.2 and master throw an error at the final link stage (I think). I call the build process from a script (below).\r\n\r\nThe error is pasted below the calling script. The error message says to recompile with -fPIC, so I added that to the --copt and --cxxopt bazel command, but it makes no difference.\r\n\r\nAnd issue  #9149 is affecting me as well, although it doesn't affect build success.\r\n\r\nThanks to all the wonderful TF hackers! You're making the world a better place.\r\n\r\n## Script used to build TF\r\n#! /bin/sh\r\ncd ~/Downloads/Software/tensorflow\r\nexport CUDA_TOOLKIT_PATH=/usr/local/cuda\r\nexport CUDNN_INSTALL_PATH=/lib64\r\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc53\r\nexport LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64\r\nexport PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin\r\nexport PYTHON_BIN_PATH=/usr/bin/python\r\nexport PYTHON_LIB_PATH=/usr/lib64/python2.7/site-packages\r\nexport TF_CUDA_CLANG=0\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=5.2\r\nexport TF_CUDA_VERSION='8' \r\nexport TF_CUDNN_VERSION='6'\r\nexport TF_NEED_CUDA=1\r\nexport TF_NEED_OPENCL=0 \r\nexport CC=/usr/bin/gcc53\r\nexport CXX=/usr/bin/g++-53\r\n\r\nrm -fr ~/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/\r\nbazel clean\r\n\\#git checkout r1.1\r\n./configure\r\nbazel build --config=opt --copt=-O2 ---copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --cxxopt=-O2 --copt=-w --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures \r\n\r\n## Error at final (?) linking\r\n2017-07-04 22:01:21.178045: W tensorflow/core/framework/op_gen_lib.cc:194] Squeeze can't find input squeeze_dims to rename\r\nERROR: /home/john/Downloads/Software/tensorflow/tensorflow/python/BUILD:2638:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command \r\n  (cd /home/john/.cache/bazel/_bazel_john/189563267da147eb81f91b14c734315c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/lib64 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc53 \\\r\n    LD_LIBRARY_PATH=/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda-8.0/lib64 \\\r\n    PATH=/home/john/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/local/sbin:/usr/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \\\r\n    TF_CUDA_VERSION='' \\\r\n    TF_CUDNN_VERSION='' \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccusolver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccublas___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccuda_Udriver___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccufft___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccurand___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib -Wl,--version-script tensorflow/tf_version_script.lds -Wl,-z,muldefs -Wl,-z,muldefs -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -pthread -Wl,-no-as-needed -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n/usr/bin/ld: /usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a(critical.o): relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC\r\n/usr/lib/gcc/x86_64-redhat-linux/5.3.1/libgomp.a: error adding symbols: Bad value\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1865.691s, Critical Path: 223.61s\r\n\r\n", "comments": ["@martinwicke have you seen this one before?", "It looks like it's trying to relocate symbols from libgomp into bss, but libgomp is not relocatable?\r\nHave you tried adding `-fPIC`, or increasing `-mlarge-data-threshold`? \r\n\r\nSee also: `-mcmodel=medium` in https://gcc.gnu.org/onlinedocs/gcc-4.5.3/gcc/i386-and-x86_002d64-Options.html \r\n\r\n@cwhipkey I honestly don't know what we're exactly building with, do you know?", "For sources that bazel generates, the force_pic flag listed here: https://docs.bazel.build/versions/master/bazel-user-manual.html seems to indicate the default is off for static files.\r\n\r\nThis general stack overflow question has some things to try:\r\n  https://stackoverflow.com/questions/29200461/recompile-with-fpic-flag\r\ne.g. - can we find a libgomp.pic.a instead of libgomp.a to use?  Where is the libgomp dependency coming from?", "Thank you both for your help. I've tried adding --force_pic --copt='-mcmodel=medium' to the Bazel command line, but the result is exactly the same error. I did not try -mlarge-data-threshold because I have no idea which number to use. I'm just a hobby coder, not a real software engineer ;-)", "I don't know why you hit this problem and nobody else, but it's likely that Chad is right: we need to either build libgomp or get a PIC version of it -- the libgomp.pic.a.\r\n\r\nI wonder what the difference between your version and the regular build is -- my guess would be the compiler version. It seems that tensorflow does not currently build with 5.3. Can you try a different compiler version? We build with 4.8.4 -- possibly something happened in gcc 5 that makes handling of code relocation stricter.", "Closing this issue due to staleness. Please use the latest version of TensorFlow and build again. Feel free to reopen if the issue still persists. Thanks!"]}, {"number": 11268, "title": "ImportError: No module named google.protobuf ", "body": "hello ,there! when i use C++ to call python program that use tensorflow\uff0creport this error\r\n\r\n\r\nTraceback (most recent call last):\r\n  \r\nFile \"<string>\", line 1, in <module>\r\n \r\nFile \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n\r\n    from tensorflow.python import *\r\n  \r\nFile \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 54, in <module>\r\n\r\n    from tensorflow.core.framework.graph_pb2 import *\r\nFile \"/root/anaconda2/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\r\n\r\n    from google.protobuf import descriptor as _descriptor\r\n\r\nImportError: No module named google.protobuf\r\n\r\ncode is here \uff1a\r\nPyRun_SimpleString(\"sys.path.append('/root/anaconda2/lib/python2.7/site-packages')\");\r\nPyRun_SimpleString(\"sys.path.append('/root/pythoncode/vgg')\");\r\nPyRun_SimpleString(\"import tensorflow as tf\");\r\nPyRun_SimpleString(\"print sys.path\");\r\n\r\nhave anyone meet this question\uff1fplease\uff0chelp! thank you very much!\r\n\r\n ", "comments": ["_Please make sure you fill in the issue template to ensure that your issue can be troubleshooted correctly. Key information includes System Specs and Tensorflow/CUDA/cuDNN versions. Without this it's harder to help!_\r\n\r\nWhat happens when you run it in a normal python environment? Does tensorflow work as expected?", "system is centos 7.tensorflow is 1.1.0. when I run it in a normal python environment it can run correctly", "I'm not familiar enough with C++ or PyRun and don't want to lead you in the wrong direction. Are your tensorflow, protobuf installations in the site-packages area or are they in an environment somewhere? I notice you're using Anaconda so perhaps you are using anaconda incorrectly with this system? You may some package conflicts.\r\n\r\nI presume you're otherwise unable to use the C++ version of Tensorflow for this?", "Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!"]}, {"number": 11267, "title": "Inconsistent default value", "body": "In this doc:\r\n\r\n> https://www.tensorflow.org/api_docs/python/tf/assign\r\n\r\nthe default value for `validate_shape` and `use_locking` is different between the method signature and the explanation below it.\r\n\r\n```\r\nassign(\r\n    ref,\r\n    value,\r\n    validate_shape=None,\r\n    use_locking=None,\r\n    name=None\r\n)\r\n```\r\n\r\nvs. \r\n\r\n```\r\nvalidate_shape: An optional bool. Defaults to True. ...\r\nuse_locking: An optional bool. Defaults to True. ...\r\n```", "comments": ["Hi @minhlab the documentation is correct. When `None` is passed, the operator will get the [default](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/op_def_library.py#L304), which is defined in the op [def](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/state_ops.cc#L162).", "Still, it's counter-intuitive. I think the documentation can be better."]}, {"number": 11266, "title": "how to trace the training time of the layers", "body": "I am training the CNN, I have embedding layer, conv layer, fc layer and etc. I can get the training time per batch, but how can I get the training time of each layer per batch?", "comments": ["_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nDoes this duplicate question help? #1824\r\n\r\nOr these resources found when searching google?\r\nhttps://medium.com/towards-data-science/howto-profile-tensorflow-1a49fb18073d\r\nhttps://stackoverflow.com/a/37774470/7604321\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/timeline.py\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/tfprof"]}, {"number": 11265, "title": "faster-rcnn incompatible shapes randomly during training custom dataset", "body": "I'm trying to train faster-rcnn with resnet101 on a custom dataset, which I have formatted appropriately for tf. When I run training, it can run anywhere from 30-1000 steps before it gives me an error like this:\r\n\r\n ```\r\nFile \"train.py\", line 195, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 192, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"/home/chris/tensorflow/models/slim/deployment/model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 133, in _create_losses\r\n    losses_dict = detection_model.loss(prediction_dict)\r\n  File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1173, in loss\r\n    groundtruth_classes_with_background_list))\r\n  File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1329, in _loss_box_classifier\r\n    batch_reg_targets, weights=batch_reg_weights) / normalizer\r\n  File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 71, in __call__\r\n    return self._compute_loss(prediction_tensor, target_tensor, **params)\r\n  File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 158, in _compute_loss\r\n    diff = prediction_tensor - target_tensor\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 846, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2582, in _sub\r\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n\r\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,61,4] vs. [1,64,4]\r\n\t [[Node: gradients/Loss/BoxClassifierLoss/Loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape, gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape_1)]]\r\n\t [[Node: gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1/_3949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_22091_gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\n\r\n\r\nThe dimension mismatch is from what I can tell from from looking in losses.py the number of anchors, but I really don't know how to try debug this. FWIW, the training on ssd runs without issue so far.\r\n\r\nA bit of info about the dataset, the images all contain multiple (likely crowded) of the same object.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "moved to https://stackoverflow.com/questions/45007328/tensorflow-object-detection-faster-rcnn-randomly-fails", "I am getting same error too.", "You have to configure `num_classes = xx` in **faster_rcnn_resnet101.config** file", " >>> rpn_loss_cls: 0.164899\r\n >>> rpn_loss_box: 0.052974\r\n >>> loss_cls: 0.539121\r\n >>> loss_box: 0.132027\r\n >>> lr: 0.000100\r\nspeed: 20.228s / iter\r\nimage: D:\\tf-faster-rcnn-windows\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\class4_3.PNG\r\nimage: D:\\tf-faster-rcnn-windows\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\class3_93.PNG\r\nimage: D:\\tf-faster-rcnn-windows\\data\\VOCdevkit2007\\VOC2007\\JPEGImages\\class2_50.PNG\r\n> d:\\tf-faster-rcnn-windows\\lib\\layer_utils\\proposal_target_layer.py(138)_sample_rois()\r\n-> keep_inds = np.append(fg_inds, bg_inds)\r\n(Pdb) c\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1323, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1302, in _run_fn\r\n    status, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [0,44] vs. [128,44]\r\n\t [[Node: gradients/LOSS_default/mul_9_grad/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](vgg_16_1/rpn_rois/proposal_target:5, gradients/LOSS_default/Sum_1_grad/Tile)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/tf-faster-rcnn-windows/tools/trainval_net.py\", line 143, in <module>\r\n    max_iters=args.max_iters)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 377, in train_net\r\n    sw.train_model(sess, max_iters)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 294, in train_model\r\n    self.net.train_step(sess, blobs, train_op)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\nets\\network.py\", line 497, in train_step\r\n    feed_dict=feed_dict)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [0,44] vs. [128,44]\r\n\t [[Node: gradients/LOSS_default/mul_9_grad/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](vgg_16_1/rpn_rois/proposal_target:5, gradients/LOSS_default/Sum_1_grad/Tile)]]\r\n\r\nCaused by op 'gradients/LOSS_default/mul_9_grad/mul_1', defined at:\r\n  File \"D:/tf-faster-rcnn-windows/tools/trainval_net.py\", line 143, in <module>\r\n    max_iters=args.max_iters)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 377, in train_net\r\n    sw.train_model(sess, max_iters)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 248, in train_model\r\n    lr, train_op = self.construct_graph(sess)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 131, in construct_graph\r\n    gvs = self.optimizer.compute_gradients(loss)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 414, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 353, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 581, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 747, in _MulGrad\r\n    array_ops.reshape(math_ops.reduce_sum(x * grad, ry), sy))\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 894, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1117, in _mul_dispatch\r\n    return gen_math_ops._mul(x, y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2725, in _mul\r\n    \"Mul\", x=x, y=y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n...which was originally created as op 'LOSS_default/mul_9', defined at:\r\n  File \"D:/tf-faster-rcnn-windows/tools/trainval_net.py\", line 143, in <module>\r\n    max_iters=args.max_iters)\r\n[elided 1 identical lines from previous traceback]\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 248, in train_model\r\n    lr, train_op = self.construct_graph(sess)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\model\\train_val.py\", line 123, in construct_graph\r\n    anchor_ratios=cfg.ANCHOR_RATIOS)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\nets\\network.py\", line 434, in create_architecture\r\n    self._add_losses()\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\nets\\network.py\", line 308, in _add_losses\r\n    loss_box = self._smooth_l1_loss(bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights)\r\n  File \"D:\\tf-faster-rcnn-windows\\tools\\..\\lib\\nets\\network.py\", line 272, in _smooth_l1_loss\r\n    out_loss_box = bbox_outside_weights * in_loss_box\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 894, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1117, in _mul_dispatch\r\n    return gen_math_ops._mul(x, y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2725, in _mul\r\n    \"Mul\", x=x, y=y, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Incompatible shapes: [0,44] vs. [128,44]\r\n\t [[Node: gradients/LOSS_default/mul_9_grad/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](vgg_16_1/rpn_rois/proposal_target:5, gradients/LOSS_default/Sum_1_grad/Tile)]]", "I have been looking for a few days, I have been unable to find a problem, have a friend who knows, thank you."]}, {"number": 11264, "title": "Updating DNNRegressor module directory", "body": "The model is now located at tf.contrib.learn.DNNRegressor and the code will not run without this change. \r\n\r\nDocumentation of the module is available here: https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNRegressor", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 11263, "title": "Image Retrain Inception only check the own specific category not tensor dataset", "body": "\r\nI have retrained the inception model from my data set of traffic sign.Its working fine but when I am trying to check other image e.g panda it's resulting with the name of traffic sign with some probabilities.I don't understand why its doing it.I need both tensor-flow data-set and my own category too. My steps:\r\n\r\n-I have installed the python 3.5.2 in windows 7\r\n\r\n-I installed tensor-flow with pip --install tensorflow\r\n\r\n-I download these two files retrain.py to train my data and label_image.py to check image.\r\n\r\nfiles downloaded from: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/image_retraining", "comments": ["_Warning: As this doesn't appear to be a bug with Tensorflow, the devs may ask for this to be moved to Stack Overflow._\r\n\r\nThis is because when you have trained with your dataset you are retraining the final output layers with new classes (traffic signs). This will not retain the imagenet results. This is a question for S/O.\r\n\r\nIf you decide to move this issue to Stack Overflow, please post the link here so that myself (or others that stumble upon this issue) can find the S/O thread.", "I have posted it in stackover flow please guide i am using windows to do this.\r\nhttps://stackoverflow.com/questions/44897648/image-retrain-inception-only-check-the-own-specific-category-not-tensor-dataset", "Thanks @ManojPabani I will come over and continue the discussion there. Please close this issue to clear the issue tracker for the devs!"]}, {"number": 11262, "title": "[XLA] Add scaffolding to allow XLA unit tests to run for other devices", "body": "This is an indentical change to the one in the compiler/tests directory.  It allows devices other than the CPU and GPU to be available targets when running the tests in compiler/xla/tests.\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@tatatodd WDYT?", "Hi,\r\n\r\nI'd like to think that the failure in a python3 front end test isn't anything to do with my change. \r\n\r\nPerhaps we can test again, or see if other public pull requests are suffering from the same problem?\r\n\r\n", "So, in terms of the effectiveness of this change, I think it is quite important to have a way for non-CPU/GPU devices to be tested against all of XLA.    My device actually fails quite a few of the tests because they are written with the assumption that devices support the full intersection of CPU/GPU types (which out device currently does not).  I will extend type support on our device to unsigned integer types, eliminating most of the problems, but I will probably have to submit another pull request in the future that allows devices to opt out of double precision float tests.  While our compiler supports doubles, it isn't on the timeline to support them in the graph framework.", "Yes, it seems unrelated to your change.", "@DavidNorman Looks good to me, thanks for the PR!\r\n\r\nJust some minor comments; I'll approve and kick off new tests once those are in.", "thanks - will do ASAP", "@tatatodd Done - cheers\r\n", "Jenkins, test this please."]}, {"number": 11261, "title": "Fix TODO avoiding serialization in gRPC/GPU path", "body": "See #10530 and #10531 for the rationale.", "comments": ["Can one of the admins verify this patch?", "Using a [modified version](https://gist.github.com/byronyi/cb4ba0f6c5815ce78924ebcdd56989b9) of local recv_tensor [benchmark script](https://gist.github.com/yaroslavvb/e196107b5e0afc834652bd3153030c42) (thanks to @yaroslavvb), the performance improvement over current master is shown below:\r\n\r\nCurrent master:\r\n```\r\nLocal rate:       23185.76 MB/s\r\nDistributed rate: 196.11 MB/s\r\n```\r\n\r\nWith this patch:\r\n```\r\nLocal rate:       26588.30 MB/s\r\nDistributed rate: 256.12 MB/s\r\n```", "why closed? Seems like an improvement", "Further investigation shows the benchmark difference seems to come from different build options, e.g. AVX, SSE, etc. I suspect the difference is only visible after #6116 is fixed, so I'll revisit this PR then.", "Can one of the admins verify this patch?", "This should be relevant now as we have the gRPC upgrade finished recently. With this change, it should do less work (mainly serialisation) in principle, but I have not checked.", "@tensorflow-jenkins test this please", "Thank you Derek @mrry :)"]}, {"number": 11260, "title": "Add Edward and GPflow to community page", "body": "Edward is a library for probabilistic programming with a few thousand active users. GPflow is a library for Gaussian processes which also has an active user base.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11259, "title": "Update Dockerfile.gpu with python3", "body": "There is already Dockerfile.gpu ( with gpu version ). but it is for python2 users. so I make a Dockerfile.gpu-py3 with python3 users. ( There is no different this from Dockerfile of Image that is on Docker-hub )", "comments": ["Can one of the admins verify this patch?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->"]}, {"number": 11258, "title": "Update Dockerfile.gpu with python3", "body": "There is already Dockerfile.gpu ( with gpu version ). but it is for python2 users. so I make a Dockerfile.gpu-py3 with python3 users. ( There is no different this from Dockerfile of Image that is on Docker-hub )", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "I signed it!"]}, {"number": 11257, "title": "building gexagon_graph_execution for hexagon_DSP failed", "body": "I have followed the build and run script for HVX here, after installing the protobuf and downloading the pre-built libraries the code has failed at :\r\n\r\n`error: undefined reference to 'soc_interface_AllocateInOutNodeBuffers'\r\n`here is the related file:\r\n\r\n```\r\n/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(hexagon_control_wrapper.o):hexagon_control_wrapper.cc:function tensorflow::HexagonControlWrapper::Init(tensorflow::RemoteFusedGraphExecuteInfo const&): error: undefined reference to 'soc_interface_AllocateInOutNodeBuffers'\r\ncollect2: error: ld returned 1 exit status\r\n/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/sub_makefiles/hexagon_graph_execution/Makefile.in:64: recipe for target '/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/bin/hexagon_graph_execution' failed\r\nmake: *** [/home/amir/Documents/tensorflow/tensorflow/contrib/makefile/gen/bin/hexagon_graph_execution] Error 1\r\n```\r\n@satok16 could you help me out here about the linking problem? Running on Ubuntu 16.04.02", "comments": ["The issue resolved when I rebuilt all from source-code (without -p prebuilt library option).", "Sure, thank you for the update.", "@amirjamez @satok16 \r\nI try to build from source-code then run on Snapdragon820 Board. But it failed and reports the following error.\r\n```\r\nPrepare failed! returned 0xffffffff\r\n\r\nNN Id = -904838944\r\nExecute graph!\r\nExecution failed!\r\nexecute got err: -1\r\n\r\nNN Id = -904838944\r\nExecution failed\r\nNN Id = -904838944\r\nFailed to read data.\r\n```\r\nAnd dmesg information is as the following, looks like that ION cannot allocate memory.\r\n```\r\n[  110.941082] platform soc:qcom,ion:qcom,ion-heap@22: Fail to allocate buffer\r\n[  111.581037] platform soc:qcom,ion:qcom,ion-heap@22: Fail to allocate buffer\r\n[  308.621162] platform soc:qcom,ion:qcom,ion-heap@22: Fail to allocate buffer\r\n[  309.221876] platform soc:qcom,ion:qcom,ion-heap@22: Fail to allocate buffer\r\n```\r\n\r\n\r\nAnd if I build with prebuilt library(-p), the issue is gone and I can run the hexagon_execute_graph successfully. And this error is caused by libhexagon_nn_skel.so (after using prebuilt libhexagon_nn_skel.so, the issue is missing). And I guess this error is related to Qualcomm SDK version.\r\n\r\nMy Enviroment:\r\n1. Openq 820 Board.\r\n2. NDK13 and NDK14b (I try both NDK)\r\n3. Hexagon SDK 3.1 and 3.2(I try both Hexagon SDK)\r\n4. nnlib commit id 721b2d58f0f4e2d5b182f41e6b7c4db5356bf0fb\r\n5. tensorflow commit id ca9899fb1da37c8644c447b401663a0b10483c91\r\n\r\nany suggestion is appreciated.\r\nThanks.\r\n", "@kanshuzhi I guess my SDK was 3.0 (7.2.12). You might wanna try that version as well.\r\nFYI: Have you used the testsig instructions mentioned [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx)?", "Thanks.\r\nI see. my sdk version is Hexagon v3.2 and Hexagon v3.0 SDK seems out of date cannot be fully downloaded.\r\n"]}, {"number": 11256, "title": "wide_n_deep  tutorial not work", "body": "Run the wide_n_deep_tutorial.py,  I got the msg like that:\r\n\r\n  **## File \"wide_n_deep_tutorial.py\", line 147, in build_estimator\r\n    m = tf.estimator.DNNLinearCombinedClassifier(\r\nAttributeError: 'module' object has no attribute 'DNNLinearCombinedClassifier'**\r\n\r\n\r\n**## it shows that DNNLinearCombinedClassifier not in estimator, In the previous version, it seems in tf.contrib.learn** \r\n\r\n**## is it a bug ?**", "comments": ["In `wide_n_deep_tutorial.py` (r1.2), I can't find any code looks like `tf.estimator.DNNLinearCombinedClassifier`.\r\n\r\nPlease show me the version which contains `tf.estimator.DNNLinearCombinedClassifier`.\r\n\r\nPS, `tf.contrib.learn.DNNLinearCombinedClassifier` works to me.", "@ScorpioCPH  I use the code from the url :https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py\r\n\r\nin line 147 there is tf.estimator.DNNLinearCombinedClassifier \r\n\r\nand is it the newest?\r\n", "Yes, your code is newest.\r\n\r\nIn this [commit](https://github.com/tensorflow/tensorflow/commit/e766804ba7c711ff785b7e14311b56d0d3c9b487)\r\n 3 days ago.\r\n\r\n- changes: \r\n<img width=\"1020\" alt=\"screen shot 2017-07-04 at 11 24 18\" src=\"https://user-images.githubusercontent.com/5319646/27813891-8da12c5a-60ab-11e7-8e56-2575ee947c51.png\">\r\n\r\nI work on r1.2 instead of `master` branch.", "oh,  @ScorpioCPH is it the bug of the newest tutorial\uff1f and how can I run the newest ? ", "I don't think this is a bug, because master branch is ongoing.\r\n\r\nMaybe you can use `released` version, such as [v1.2.0](https://github.com/tensorflow/tensorflow/releases/tag/v1.2.0).", "OK, I will try the released version, thank you~~:D", "My pleasure~", "@ScorpioCPH when I run `wide_n_deep_tutorial.py` on r1.2, I get a ValueError:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"wide_n_deep_tutorial.py\", line 234, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"wide_n_deep_tutorial.py\", line 197, in main\r\n    FLAGS.train_data, FLAGS.test_data)\r\n  File \"wide_n_deep_tutorial.py\", line 186, in train_and_eval\r\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 455, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 953, in _train_model\r\n    features, labels = input_fn()\r\n  File \"wide_n_deep_tutorial.py\", line 186, in <lambda>\r\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\r\n  File \"wide_n_deep_tutorial.py\", line 148, in input_fn\r\n    for k in CATEGORICAL_COLUMNS}\r\n  File \"wide_n_deep_tutorial.py\", line 148, in <dictcomp>\r\n    for k in CATEGORICAL_COLUMNS}\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 132, in __init__\r\n    indices_shape = indices.get_shape().with_rank(2)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 632, in with_rank\r\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\r\nValueError: Shape (0,) must have rank 2\r\n```\r\n\r\nAny advice on this? Thanks.\r\n", "@amandajliu please see #11328."]}, {"number": 11255, "title": "Feature request:  do not reload latest checkpoint on each DNNRegressor.predict() call", "body": "### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nEach DNNRegressor.predict (or predict_scores) call reloads model parameters from the latest saved model checkpoint, even if the checkpoint hasn't changed between predict() calls.  This slows down generation of predictions.  It will be helpful to be able to disable reloading of model parameters after the initial loading, and/or to be able to reload the latest checkpoint manually via a separate function call.\r\n\r\n", "comments": ["@honkentuber can you comment on this one?", "train, evaluate, and predict always build the full graph and load from checkpoint. You can get multiple predictions, while loading the graph only once, by feeding multiple batches via `input_fn` and iterating over the results.\r\n\r\n@ispirmustafa @martinwicke ", "You can also use the generator_input_fn if your inputs come via a generator. \r\n\r\nWe like to keep the Estimator state 100% on disk. This is crucial for distributed training since we wouldn't want to maintain a consistent state ourselves. ", "The specific use case is:\r\n- input data for prediction arrives at random points in time;\r\n- DNNRegressor.predict() is invoked to generate prediction.\r\nAs it stands, there is approximately 3-4 seconds latency for each prediction when running on Google App Engine flex with model_dir in a Google Storage bucket.  The latency seems to be to a substantial extent due to reloading the model from a gs:// path.   Given that data for prediction arrives in online mode (i.e. it's not available ahead of time), how can input_fn be written to return multiple batches?  The ultimate goal is to minimize latency when generating each prediction, from several seconds down to milliseconds.", "You can also try contrib/predictor. "]}, {"number": 11254, "title": "Import tensorflow with error information\"KeyError: \"Couldn't find field google.protobuf.FileOptions.php_class_prefix\"\"", "body": "here is the error information:\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/shaoyn/anaconda2/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 10, in <module>\r\n    from google.protobuf import descriptor_pb2\r\n  File \"/home/shaoyn/anaconda2/lib/python2.7/site-packages/google/protobuf/descriptor_pb2.py\", line 1003, in <module>\r\n    options=None),\r\n  File \"/home/shaoyn/anaconda2/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 498, in __new__\r\n    return _message.default_pool.FindFieldByName(full_name)\r\nKeyError: \"Couldn't find field google.protobuf.FileOptions.php_class_prefix\"", "comments": ["Reinstall `protobuf` maybe helpful:\r\n\r\n```shell\r\n$ sudo pip uninstall protobuf\r\n$ sudo pip install protobuf\r\n```", "@shaoyn0817 please try @ScorpioCPH 's suggestion, and let us know if it helps. ", "thx~", "thx a lot!"]}, {"number": 11253, "title": "pip or package issues", "body": "Over the past few hours I have tried to run pip install --upgrade tensorflow_gpu  roughly 20 times, and keep getting read time out from pypi.python.org.  I finally added the --verbose and -- timeout 10000 to troubleshoot. Now I get this:\r\n\r\n  Using version 1.2.1 (newest of versions: 1.2.0, 1.2.1)\r\n  Looking up \"https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl\" in the cache\r\n  No cache entry available\r\n  Starting new HTTPS connection (1): pypi.python.org\r\n  \"GET /packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl HTTP/1.1\" 200 51299687\r\n  Downloading tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl (51.3MB)\r\n  Downloading from URL https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f (from https://pypi.python.org/simple/tensorflow-gpu/)\r\n    12% |\u2588\u2588\u2588\u2588                            | 6.3MB 6.4kB/s eta 1:57:37\r\nCleaning up...\r\n**THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n    tensorflow_gpu from https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f:\r\n        Expected md5 46bb283df033c7fb7c233346eb26d40f\r\n             Got        7ba60530da51fdc733b89f9dd3b660fc**\r\n\r\nException information:\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\roger\\envs\\tensorflow_attention_ocr\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"c:\\users\\roger\\envs\\tensorflow_attention_ocr\\lib\\site-packages\\pip\\commands\\install.py\", line 335, in run\r\n    wb.build(autobuilding=True)\r\n  File \"c:\\users\\roger\\envs\\tensorflow_attention_ocr\\lib\\site-packages\\pip\\wheel.py\", line 749, in build\r\n    self.requirement_set.prepare_files(self.finder)\r\n  File \"c:\\users\\roger\\envs\\tensorflow_attention_ocr\\lib\\site-packages\\pip\\req\\req_set.py\", line 386, in prepare_files\r\n    raise hash_errors\r\npip.exceptions.HashErrors: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n    tensorflow_gpu from https://pypi.python.org/packages/47/81/2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92/tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl#md5=46bb283df033c7fb7c233346eb26d40f:\r\n        Expected md5 46bb283df033c7fb7c233346eb26d40f\r\n             Got        7ba60530da51fdc733b89f9dd3b660fc", "comments": ["I think the latest attempt to `Build #227 (Jul 3, 2017 2:25:07 AM) ` failed for `Windows GPU.` \r\n\r\nI believe the most recent and stable version built was `tensorflow_gpu-1.2.0-cp36-cp36m-win_amd64.whl`.\r\n\r\nHowever, the `pip install --upgrade tensorflow_gpu ` is attempting to download the `tensorflow_gpu-1.2.1-cp36-cp36m-win_amd64.whl` which is not the `build : pass` so it's not working I guess.\r\n\r\nHope it answers your question. Also, no one can temper hashes :)", "Ah, ok. Thank you. I am not familiar with pip. Can I change the command to force 1.2.0?", "Still feels like something else is wrong. When I first kick it off, I get fast download speeds. and now:\r\n\r\n` 33% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                     | 17.2MB 530bytes/s eta 17:51:51`\r\n", "I tried and successfully installed the latest release via `pip install --upgrade tensorflow_gpu` . I would suggest the easy way to uninstall everything and try from scratch with `pip uninstall tensorflow` and try again :)\r\n\r\nSee installation @ [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow). In your case choose `Windows GPU build history 3.5 / 3.6)` and find out the build which you want to upgrade. \r\n\r\n", "uninstall? this is virtualenv? there is nothing to uninstall unless I have no clue what I am doing (which is possible.. first time trying all of this)... \r\n\r\nI am on Windows 10... I can do tensorflow 101 examples that can clearly see my GPU. But when I start a virtualenv it cannot see tensorflow. I assume that is by design?\r\n", "The issue here is definitely not related to TF code itself, more user issues around pip and virtualenv. I will therefore close this issue.\r\nPlease reach out to pip and virtualenv user manuals, or stackoverflow for such issues not related to bugs in TF code itself.", "    6% |\u2588\u2588                              | 3.3MB 482bytes/s eta 1 day, 3:40:34\r\n\r\n....\r\n", "@rogerguess Please review guidelines before raising an issue.[https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md](https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md)\r\n\r\nAlso, note that `Anaconda` is not officially supported by tensorflow. It's community maintained\r\npackage in case you have used that for Windows 10.\r\n\r\nI encourage you to follow Installation guidelines with pip. "]}, {"number": 11252, "title": "AttributeError when calling train in tf.estimator.DNNClassifier", "body": "### System information\r\n- I wrote a custom script, using the tf.estimator.DNNclassifier. Source code below.\r\n- **OS Platform and Distribution**: MacOS 10.12.5\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**:  v1.2.0-1741-g88633a8eb 1.2.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.5.2\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n- **Additional libraries**: numpy (1.13.0), protobuf (3.3.0), tensorflow-tensorboard (0.1.2)\r\n\r\n### Describe the problem\r\nWhen using tf.estimator.DNNClassifier train function, I get the an AttributeError listed below in the logs, relate to the definition of `values=tuple(six.itervalues(features))` in `_dnn_model_fn`.\r\nNote: when using `tensorflow.contrib.learn.DNNClassifier` instead (with `fit`, instead of `train`) no error occurs.\r\n\r\n### Source code\r\n\r\n```\r\nimport tensorflow.contrib.learn as skflow\r\nfeature_columns = skflow.infer_real_valued_columns_from_input(totA.astype(np.float32))\r\nclf = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=dnntfDef.hidden_layers,\r\n                               optimizer=dnntfDef.optimizer, n_classes=numTotClasses,\r\n                               activation_fn=dnntfDef.activationFn, model_dir=model_directory)\r\n\r\nclf.train(input_fn=lambda: input_fn(A, Cl2), steps=2000\r\n```\r\n\r\n### logs\r\n\r\n`    \r\nclf.train(input_fn=lambda: input_fn(A, Cl2), steps=dnntfDef.trainingSteps)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 616, in _train_model\r\n    model_fn_lib.ModeKeys.TRAIN)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 601, in _call_model_fn\r\n    features=features, labels=labels, **kwargs)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 265, in _model_fn\r\n    config=config)\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 84, in _dnn_model_fn\r\n    values=tuple(six.itervalues(features)),\r\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/six.py\", line 578, in itervalues\r\n    return iter(d.values(**kw))\r\nAttributeError: 'Tensor' object has no attribute 'values'\r\n`\r\n\r\n", "comments": ["Pardon me for not understanding all of the context, but should totA be defined, or come from an import, in your example? ", "Sorry for the missing information. totA come from an import. In details:\r\n\r\n    `totA = np.vstack((A, A_test))`\r\n\r\nwhere A is my training tensor, and A_test is my validation tensor.\r\n\r\nAs I said, the code is exactly the same for when I run DNNClassifier through tf.estimator or through \r\ntensorflow.contrib.learn\r\n\r\nPlease let me know if you have any more questions.", "OK, I built a stand-in for totA using a random normal numpy array. \r\nNow the example breaks with \"NameError: name 'dnntfDef' is not defined\".\r\nIs there something else I should stub out to replicate? \r\n\r\n", "Sorry about that, those were previously defined variables. Given a train set A, with related classes Cl, and a test set A_test, with related labels Cl_test, the code proceeds as follows:\r\n\r\n```\r\nfrom sklearn import preprocessing\r\nimport tensorflow.contrib.learn as skflow\r\n\r\ntotA = np.vstack((A, A_test))\r\ntotCl = np.append(Cl, Cl_test)\r\nnumTotClasses = np.unique(totCl).size\r\n\r\ntotCl2 = le.fit_transform(totCl)\r\nCl2 = le.transform(Cl)\r\nCl2_test = le.transform(Cl_test)\r\n\r\nfeature_columns = skflow.infer_real_valued_columns_from_input(totA.astype(np.float32))\r\nclf = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[20],\r\n                               optimizer=\"Adagrad\", n_classes=numTotClasses,\r\n                               activation_fn=\"tanh\", model_dir=model_directory)\r\n\r\nclf.train(input_fn=lambda: input_fn(A, Cl2), steps=200)\r\n```\r\n\r\nThe code using tensorflow.contrib.learn is the same other than the last two lines:\r\n```\r\nclf = tensorflow.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[20],\r\n                                        optimizer=\"Adagrad\", n_classes=numTotClasses,\r\n                                        activation_fn=\"tanh\", model_dir=model_directory)\r\nclf.fit(input_fn=lambda: input_fn(A, Cl2), steps=200)\r\n```\r\nI hope this helps. Thanks for your help.", "@jhseu any ideas?", "Since you switched to core canned Estimators, can you try switching to core FeatureColumns as well?\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column", "Interesting suggestion, will try. What is the closest API in tf.feature_column to the one I used from learn: https://www.tensorflow.org/api_docs/python/tf/contrib/learn/infer_real_valued_columns_from_input\r\n\r\nThanks", "OK, instead of using:\r\n`feature_columns = tensorflow.contrib.learn.infer_real_valued_columns_from_input(totA.astype(np.float32))`\r\nI used:\r\n`feature_columns = tf.feature_column.numeric_column(key='totA', shape=totA.shape)`\r\n \r\nThis still gives the exact same error. ", "Can you paste a full runnable example? Specifically I need to see what your input_fn is returning.\r\n\r\nFrom what I can tell, that error shouldn't happen unless you have some mixed Tensor/dict type.", "Here it is. Will provide train and test files to run shortly\r\n\r\n```#!/usr/bin/env python3\r\n\r\nimport numpy as np\r\nimport sys, os.path\r\n#**********************************************\r\n''' Main '''\r\n#**********************************************\r\ndef main():\r\n    print(\" Using training file: \", sys.argv[1],\"\\n\")\r\n        \r\n    En, Cl, A = readLearnFile(sys.argv[1])\r\n    En_test, Cl_test, A_test = readLearnFile(sys.argv[2])\r\n    learnFileRoot = os.path.splitext(sys.argv[1])[0]\r\n    clf_dnntf, le_dnntf  = trainDNNTF(A, Cl, A_test, Cl_test, learnFileRoot)\r\n\r\n#**********************************************\r\n''' DNNClassifier '''\r\n#**********************************************\r\ndef trainDNNTF(A, Cl, A_test, Cl_test, Root):\r\n    import tensorflow as tf\r\n    import tensorflow.contrib.learn as skflow\r\n    from sklearn import preprocessing\r\n    \r\n    model_directory = Root + \"/DNN-TF_\"\r\n    print(\"\\n  Training model saved in: \", model_directory, \"\\n\")\r\n    \r\n    #**********************************************\r\n    ''' Initialize Estimator and training data '''\r\n    #**********************************************\r\n    print(' Initializing TensorFlow...')\r\n    tf.reset_default_graph()\r\n\r\n    totA = np.vstack((A, A_test))\r\n    totCl = np.append(Cl, Cl_test)\r\n    numTotClasses = np.unique(totCl).size\r\n    \r\n    le = preprocessing.LabelEncoder()\r\n    totCl2 = le.fit_transform(totCl)\r\n    Cl2 = le.transform(Cl)\r\n    Cl2_test = le.transform(Cl_test)\r\n    \r\n    feature_columns = skflow.infer_real_valued_columns_from_input(totA.astype(np.float32))\r\n    \r\n    ''' tf.estimator version '''\r\n    clf = tf.estimator.DNNClassifier(feature_columns=[totA], hidden_units=[20],\r\n                               optimizer=\"Adagrad\", n_classes=numTotClasses,\r\n                               activation_fn=\"tanh\", model_dir=model_directory)\r\n    \r\n    ''' tf.contrib.learn version '''\r\n    #clf = skflow.DNNClassifier(feature_columns=feature_columns, hidden_units=[20],\r\n    #                               optimizer=\"Adagrad\", n_classes=numTotClasses,\r\n    #                               activation_fn=\"tanh\", model_dir=model_directory)\r\n\r\n    #**********************************************\r\n    ''' Train '''\r\n    #**********************************************\r\n    \r\n    ''' tf.estimator version '''\r\n    clf.train(input_fn=lambda: input_fn(A, Cl2), steps=2000)\r\n    \r\n    ''' tf.contrib.learn version '''\r\n    #clf.fit(input_fn=lambda: input_fn(A, Cl2), steps=100)\r\n    \r\n    \r\n    accuracy_score = clf.evaluate(input_fn=lambda: input_fn(A_test, Cl2_test), steps=1)\r\n    print('\\n  ================================')\r\n    print('  \\033[1mDNN-TF\\033[0m - Accuracy')\r\n    print('  ================================')\r\n    print(\"\\n  Accuracy: {:.2f}%\".format(100*accuracy_score[\"accuracy\"]))\r\n    print(\"  Loss: {:.2f}\".format(accuracy_score[\"loss\"]))\r\n    print(\"  Global step: {:.2f}\\n\".format(accuracy_score[\"global_step\"]))\r\n    print('  ================================\\n')\r\n\r\n    return clf, le\r\n\r\n#**********************************************\r\n''' Format input data for Estimator '''\r\n#**********************************************\r\ndef input_fn(A, Cl2):\r\n    import tensorflow as tf\r\n    x = tf.constant(A.astype(np.float32))\r\n    y = tf.constant(Cl2)\r\n    return x,y\r\n\r\n#**********************************************\r\n''' Read learn File '''\r\n#**********************************************\r\ndef readLearnFile(learnFile):\r\n    try:\r\n        with open(learnFile, 'r') as f:\r\n            M = np.loadtxt(f, unpack =False)\r\n    except:\r\n        print('\\033[1m' + ' Learning file not found \\n' + '\\033[0m')\r\n        return\r\n    \r\n    En = np.delete(np.array(M[0,:]),np.s_[0:1],0)\r\n    M = np.delete(M,np.s_[0:1],0)\r\n    Cl = ['{:.2f}'.format(x) for x in M[:,0]]\r\n    A = np.delete(M,np.s_[0:1],1)\r\n    return En, Cl, A\r\n\r\n#************************************\r\n''' Main initialization routine '''\r\n#************************************\r\nif __name__ == \"__main__\":\r\n    sys.exit(main())```", "The zipped train+test files can be found here:\r\nhttps://goo.gl/2no9AA\r\n\r\nto run the code above (assuming it's called DNNClassifier.py):\r\n`./DNNClassifier.py train.txt test.txt`\r\n\r\nYou can toggle between the tf.estimator and tf.contrib.learn version within the code.\r\n", "There are many issues with the script, but it works for me with many modifications:\r\n- feature_columns must be an array\r\n- input_fn must return a dictionary for features where the key matches the feature column key.\r\n- activation can't be a string in the new version\r\n- You'll have to get shapes right. It would probably be easier just to change your input_fn to use numpy_input_fn: https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/inputs/numpy_input_fn\r\n\r\nClosing because there's no bug here.", "(Note that we'll have some new tutorials for core estimators up soon. They're not up for core canned estimators because they're not in an official release yet.)", "Actually, will reopen and reassign to improve the error message."]}, {"number": 11251, "title": "Adding generics to the Java API - Phase 1", "body": "Here is an initial cut at enhancing the Java API with generics.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Thanks @andrewcmyers ! Please check the CLA.\r\n\r\nIn the future, if you have large changes, it's best to first file an issue and discuss the implementation plan beforehand.", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "Thanks @andrewcmyers !\r\n\r\n(FYI @karllessard @kbsriram @jhseu )\r\n\r\nWill take a more detailed look at this, but can we avoid the dependency on `perl` and having to generate source files? In this particular case, I feel that manually repeating some lines for each type in the `Tensor` and related classes is worth the benefit of having the `.java` files be checked in and avoiding a complication in the build step. Or do you disagree? :)", "Unfortunately it ends up being more than a few lines repeated, and will get worse once more TF types are supported. It may be quite annoying to maintain without some automation. I know that Karl is aiming to generate the code for ops too.\r\n\r\nAn alternative strategy that still seems better than hand-editing these four files (DataType.java should also be included, but I have not touched it) is to semi-automate it: scripts are used to generate the files manually, but the generated files are manually copied back to the source tree and checked in as regular source files. Then Perl would not be required to build.", "What I was telling to Andrew previously is that the op generator is going to be written in C++ and will have its own templating engine but it would be great to share the same techonology since the final goals are pretty similar, I don't know Asim if you have any good suggestion for this too... \r\n\r\nAlso, about copying the generated files into source trees, current solution for the op generator is to generate those files into an external source jar (.srcjar) that will be included into the library build rule.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "Regarding typed helper constructors - if you decide to support them (either as part of this CL or as a breakout change) then in addition to the classes above, at least the Constant and Variable op-wrappers would want to include such blocks to avoid the caller needing to pass in a Tensor that must then be closed. With these we'd have at least four \"special-case\" classes, so it seems useful to automate their generation as part of the standard build.\r\n\r\nAs @karllessard notes, we'll be using some form of templating in both C++ and Java. An option might be to re-purpose one or the other to generate these - neither would eliminate the extra build-step of course, but it might minimize the number of template systems in use and avoid a dependency on perl.", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "After discussing with Asim, I have broken the update into 3 phases. The first phase seems to be ready for consideration. It mainly just adds things that are not yet used.", "@asimshankar thanks for the very thorough and thoughtful review.", "Jenkins, test this please", "Jenkins, test this please"]}, {"number": 11250, "title": "label_image example does not work with Mobilenetv1 (224)", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.12.5\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n- **TensorFlow version (use command below)**:\r\nGithub tag 1.2 release\r\n- **Python version**: \r\n2.7 (Mac OS X System install)\r\n- **Bazel version (if compiling from source)**:\r\nHomebrew 0.4.5\r\n- **CUDA/cuDNN version**:\r\nNA\r\n- **GPU model and memory**:\r\nNA\r\n\r\n- **Exact command to reproduce**:\r\n`bazel-bin/tensorflow/examples/label_image/label_image --image=/Path/to/image.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Path/To/my/trained/mobilenet.pb --labels=/Path/To/My/labels.txt --input_mean=0  --input_std=255`\r\n\r\n### Describe the problem\r\nIve retrained MobileNetV1 (224) via the TF Slim readme.md and have produced a graph.pb trained against a data set with 5 labels to classify. I am attempting to validate my training by running the exported graph on some validation and training data myself, and have build label_image and specified the above flags  to run.\r\n\r\nIts unclear if label image is expected  able to run MobileNet , but it does not: it errors with:\r\n\r\n` E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2\r\n\t [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]`\r\n\r\n### Source code / logs\r\nFull execution command and output:\r\n\r\n`Mayalls-Object:tensorflow vade$ bazel-bin/tensorflow/examples/label_image/label_image --image=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/data/Framing/original_photos/Extreme\\ Close\\ Up/images_12\\ copy.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/FramingWeekend/CinemaNetFraming.pb --labels=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/datasets/Framing/labels.txt --input_mean=0  --input_std=255\r\n2017-07-03 14:44:05.971869: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:05.972224: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:05.972228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:05.972231: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:06.123365: E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2\r\n\t [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]\r\nMayalls-Object:tensorflow vade$ bazel-bin/tensorflow/examples/label_image/label_image --image=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/data/Framing/converted_photos/Extreme\\ Close\\ Up/images_12\\ copy.jpg --input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1  --graph=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/model/FramingWeekend/CinemaNetFraming.pb --labels=/Volumes/MediaArchive/datasets/SynopsisCinemaNet/datasets/Framing/labels.txt --input_mean=0  --input_std=255\r\n2017-07-03 14:44:47.201141: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:47.201530: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:47.201534: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:47.201538: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-03 14:44:47.365892: E tensorflow/examples/label_image/main.cc:312] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2\r\n\t [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]\r\nMayalls-Object:tensorflow vade$ `", "comments": ["@petewarden can you please comment on whether label_image and MobileNet are supposed to play well together. ", "I think this may be a documentation issue. Here's an example set of arguments I've been able to run on my copies of Mobilenet:\r\n\r\n```\r\n--input_layer=input --output_layer=MobilenetV1/Predictions/Reshape_1 --graph=/tmp/mobilenet_v1_224/frozen_graph.pb --logtostderr --input_mean=-127 --input_std=127 --image=third_party/tensorflow/examples/label_image/data/grace_hopper.jpg --input_width=224 --input_height=224 --labels=/tmp/mobilenet_v1_224/labels.txt\r\n```\r\n\r\nThe key differences from yours are that I'm specifying the width and height explicitly, that I'm using -127 to 127 as the range, and that I'm using the set of labels required for Mobilenet.\r\n\r\nI've recently updated the TF for Poets docs and scripts to support Mobilenet by the way:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/tutorials/image_retraining.md#other-model-architectures", "@vade; does what @petewarden says get you back in business?", "Im out of the office today/tomorrow but will definitely check once I'm back. Thanks in advance @petewarden @cy89 !", "Good day for everyone\r\nif I use   --model_dir=/inception\r\neverything works well\r\n\r\n\r\nbut I have the same problem of using imagenet on Android Studio java project\r\nI retrain the model with help of imagenet\r\npython retrain.py \\\r\n --image_dir /tf_images \\\r\n --architecture mobilenet_1.0_224 \\\r\n  --output_graph=/tf/retrained_graph.pb \\\r\n  --output_labels=/tf/retrained_labels.txt\r\n\r\nand add retrained_graph.pb to /assets/ of android studio and get such result during debug:\r\n\r\njava.lang.IllegalArgumentException: Tried to explicitly squeeze dimension 1 but dimension was not 1: 2\r\nW/System.err: \t [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]\r\nW/System.err:     \r\n\r\nit is look like using of wrong parameters\r\nis anybody knows the right decision?\r\n", "Hi, I'm facing the same kind of problem.\r\nI fine-tuned MobileNetV1_224 on flowers dataset using procedure in [https://www.tensorflow.org/tutorials/image_retraining](url). It seems to works as it generated an output_graph.pb and output_labels.txt as expected. but when I try my fine-tuned model with label_image, it fails (but it works well with a fine-tuned inception v3).\r\nI tried the suggestion made by  petewarden but it did not work. I had the following error:\r\n `ValueError: The name 'MobilenetV1/Predictions/Reshape_1' looks like an (invalid) Operation name, not a Tensor. Tensor names must be of the form \"<op_name>:<output_index>\".`\r\n\r\nSo I tested summarize_graph on my model and it found 1 possible input (name=input) and one possible output (name=final_result). when I put these values as input_layer and output_layer, I have this:\r\n`Traceback (most recent call last):\r\n  File \"label_image_mobilenet.py\", line 149, in <module>\r\n    tf.app.run(main=main, argv=sys.argv[:1]+unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"label_image_mobilenet.py\", line 145, in main\r\n    FLAGS.num_top_predictions)\r\n  File \"label_image_mobilenet.py\", line 107, in run_graph\r\n    predictions, = sess.run(softmax_tensor, {input_layer_name: image_data})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 968, in _run\r\n    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py\", line 531, in asarray\r\n    return array(a, dtype, copy=False, order=order)\r\nValueError: could not convert string to float: \ufffd\ufffd\ufffd\ufffd`\r\n\r\nI really don't understand what is going on.\r\nDo you have any idea? Thanks in advance for your help.\r\n\r\nRegards,\r\nStephane", "Hi, Well, I don't know if it can help but I could make it work with the following command:\r\n`bazel-bin/tensorflow/examples/label_image/label_image --output_layer=final_result --labels=/home/thales/data/fine_tuned_inception_on_flowers/output_labels.txt --image=/home/thales/data/flower_photos_processed/training_results/5547758_eea9edfd54_n.jpg --graph=/home/thales/data/fine_tuned_mobilenet_on_flowers/output_graph.pb --input_mean=-127 --input_std=127 --input_width=224 --input_height=224`\r\nThe output_graph.pb is the one obtained with [https://www.tensorflow.org/tutorials/image_retraining](url)\r\nI had to change a little the suggestion made by petewarden as the tensor `MobilenetV1/Predictions/Reshape_1` could not be found.\r\nAt least, it works but I am still a little confused about these errors.\r\nRegards,\r\nStephane", "Hi, Vade, \r\nI have got same bug:\r\n2017-08-08 14:05:07.302014: E tensorflow/examples/label_image/main.cc:349] Running model failed: Invalid argument: Tried to explicitly squeeze dimension 1 but dimension was not 1: 4\r\n\t [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MobilenetV1/Logits/Conv2d_1c_1x1/BiasAdd)]]\r\n\t [[Node: MobilenetV1/Predictions/Reshape_1/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_613_MobilenetV1/Predictions/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDo you fix it?", "Hey, i used this tutorial to run model on android : https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/index.html?index=..%2F..%2Findex#4 . But after pruning `DecodeJpeg` by command : \r\n\r\n    python -m tensorflow.python.tools.optimize_for_inference \\\r\n    --input=tf_files/retrained_graph.pb \\\r\n    --output=tf_files/optimized_graph.pb \\\r\n    --input_names=\"Cast\" \\\r\n    --output_names=\"final_result\"\r\nI can not check the result with this command : \r\n\r\n    python -m scripts.label_image \\\r\n    tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg \\\r\n    tf_files/optimized_graph.pb\r\n\r\n,it shows error : `TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.`. So how can i check result for optimized android model on computer ?", "Hello ,Everyone\r\nIs there anybody who had ever run the code label_image.py in tensorflow/tensorflow/examples/label_image/label_image.py\r\nI have modify it to run on a dataset and read and calssify image one by one,and as the number of images goes,the speed is slower and slower,at first,that's about ten images per second,and when the number of image goes to 1000,the time is about 7s,Incredibly! I guess the matter is memorry leak?!\r\nAnd I find the problem is in the function read_tensor_from_image_file in label_image.py and this part is read and preprocess images, so what's the matter?So I want to know how to speed up? Still how to modify the code so as to making it run for batches ? @petewarden @cy89 ", "Hello @petewarden! \r\nMay you suggest how to fix the next issue:\r\n\r\n1) I've retrained my own model according to the [Tensorflow guideline](https://www.tensorflow.org/tutorials/image_retraining):\r\n\r\n```shell\r\npython tensorflow/examples/image_retraining/retrain.py --image-dir ../flower_photos --architecture mobilenet_1.0_224\r\n```\r\n\r\nwhere _flower_photos_ is an unarchived flowers set from http://download.tensorflow.org/example_images/flower_photos.tgz\r\n\r\nThis script produces 2 files _/tmp/output_graph.pb_ and _/tmp/output_labels.txt_\r\n\r\n2) Then I tried to recognize some random image:\r\n\r\n```shell\r\npython tensorflow/examples/image_retraining/label_image.py --graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt --image=../flower_photos/daisy/54377391_15648e8d18.jpg\r\n```\r\n\r\nBut I got  the error: \r\n\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/image_retraining/label_image.py\", line 147, in <module>\r\n    tf.app.run(main=main, argv=sys.argv[:1]+unparsed)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"tensorflow/examples/image_retraining/label_image.py\", line 142, in main\r\n    FLAGS.num_top_predictions)\r\n  File \"tensorflow/examples/image_retraining/label_image.py\", line 106, in run_graph\r\n    predictions, = sess.run(softmax_tensor, {input_layer_name: image_data})\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/client/session.py\", line 1071, in _run\r\n    + e.args[0])\r\nTypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\r\n```\r\n\r\nWith default architecture (without _--architecture_ flag on the step 1) everything works correctly. I've tried to find a solution on SO and in the Tensorflow documentation, but I still have no success.\r\n\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Hi @petewarden  , @cy89 ,\r\n\r\nI am facing the same issue with Mobilenet retrained models on flower dataset.\r\nI have tried the suggestions as mentioned by @petewarden \r\nIs there any other script for inferencing Mobilenet retrained model for flowers dataset?\r\nKindly provide your solution .\r\n\r\nThanks and Regards\r\nVishal\r\n", "I am taking images from mobile Gallery, and then calling recognizeImage method of Classifier with InputSize from 224 to 1024, and in all this values its throwing ArrayIndexOutOfBound Exception. \r\nSo to resolve this exception, I passes InputSize as 1600 and more, and then I am getting exception as \"java.lang.IllegalArgumentException: Tried to explicitly squeeze dimension 1 but dimension was not 1: 22 [[Node: MobilenetV1/Logits/SpatialSqueeze = Squeeze[T=DT_FLOAT, squeeze_dims=[1, 2], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](MobilenetV1\u200c\u200b/Logits/Conv2d_1c_1x\u200c\u200b1/BiasAdd)]]\"\r\n\r\nThen I was trying to retrain the model with flag IMAGE_SIZE=2048 and ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\", but its throwing error like:- tensorflow:The Mobilenet input size should be '224', '192', '160', or '128', but found '2048' for architecture 'mobilenet_0.50_2048' ERROR:tensorflow:Did not recognize architecture flag\r\n\r\nAny idea, how to resolve this issue?", "Hi - Sorry for the delayed response, just got back to this.\r\n\r\nI can confirm that Mobile-net training and label classification works in TF Master branch compiled from source (from today 136697e) - ive successfully trained a new graph via @petewarden 's updated documentation of the TF for Poets code.\r\n\r\nhowever, once caveat is that my python command line options varied a touch:\r\n\r\nTo train:\r\n\r\n`python tensorflow/examples/image_retraining/retrain.py --image_dir ~/path/to/images/ --architecture mobilenet_1.0_224 --random_crop 5 --random_scale 5 --random_brightness 5 --flip_left_right --output_graph ~/Graph.pb\r\n`\r\n\r\nTo run inference:\r\n\r\n`python tensorflow/examples/label_image/label_image.py --graph=~/Graph.pb --labels=~/output_labels.txt --input_layer=input --output_layer=final_result --input_height=224 --input_width=224 --input_mean=128 --input_std=128 --image=~/test.jpg \r\n`\r\n\r\nNote; final_result, not final_result:0\r\n\r\nAlso note the input_mean / std varies is stated in some locations to be 127, in others 128. Can we have a confirmation?\r\n\r\nThank you.\r\n", "Also happy to close this once I get a confirmation on the STD values. Appreciate this tool/script being available. Makes working with TF so much easier than making tf records etc. ", "@sumeetguha the input_height / width are not for your \"image\" that you are inputting, but rather the input sizes for the tensor that the model you are using expects. This is basically the 'resize' target the tensor should be resized to prior to running the graph to get your classification result.\r\n\r\nI could be wrong or misunderstand, but I dont think there exists a mobile net mobilenet_0.50_2048 - the graph only supports VERY specific input sizes. \r\n\r\nThe good news is you can resize any image to the graph you have chosen. You make the graph choice based on precision vs execution time vs memory usage (and size of graph on disk). Its a balancing act :) ", "Hi all,\r\n\r\nI was finally able to  inference mobilenet successfully using the label_image.py with slight modifications.\r\nI have modified the part where image is loaded with load_image() function.\r\nThe code of label_image.py which i had modified. \r\nHopefully it will help others in resolving the errors.:)  \r\n`\r\n\r\n    from __future__ import division\r\n    from __future__ import absolute_import\r\n    from __future__ import print_function\r\n    \r\n    import argparse\r\n    import sys\r\n    import PIL\r\n    from PIL import Image\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    from numpy import array\r\n    '''\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\r\n        '--image', required=True, type=str, help='Absolute path to image file.')\r\n    parser.add_argument(\r\n        '--num_top_predictions',\r\n        type=int,\r\n        default=5,\r\n        help='Display this many predictions.')\r\n    parser.add_argument(\r\n        '--graph',\r\n        required=True,\r\n        type=str,\r\n        help='Absolute path to graph file (.pb)')\r\n    parser.add_argument(\r\n        '--labels',\r\n        required=True,\r\n        type=str,\r\n        help='Absolute path to labels file (.txt)')\r\n    parser.add_argument(\r\n        '--output_layer',\r\n        type=str,\r\n        default='final_result:0',\r\n        help='Name of the result operation')\r\n    parser.add_argument(\r\n        '--input_layer',\r\n        type=str,\r\n        default='DecodeJpeg/contents:0',\r\n        help='Name of the input operation')\r\n    \r\n    '''\r\n    def load_image(filename):\r\n      \"\"\"Read in the image_data to be classified.\"\"\"\r\n      #return tf.gfile.FastGFile(filename, 'rb').read()\r\n      \r\n    \r\n      im=Image.open(filename)\r\n      image=np.asarray(im, dtype=\"float32\")\r\n      img=(image-128.0)/128.0\r\n      \r\n      img=array(img).reshape(1,224,224,3)\r\n      return img\r\n    \r\n    def load_labels(filename):\r\n      \"\"\"Read in labels, one label per line.\"\"\"\r\n      return [line.rstrip() for line in tf.gfile.GFile(filename)]\r\n    \r\n    \r\n    def load_graph(filename):\r\n      \"\"\"Unpersists graph from file as default graph.\"\"\"\r\n      with tf.gfile.FastGFile('/home/ubuntu/ML_GIT/TensorFlow/MobileNet_Multi_label/output_graph.pb', 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n        tf.import_graph_def(graph_def, name='')\r\n    \r\n    \r\n    def run_graph(image_data, labels, input_layer_name, output_layer_name,\r\n                  num_top_predictions):\r\n    \r\n    \r\n      with tf.Session() as sess:\r\n        # Feed the image_data as input to the graph.\r\n        #   predictions  will contain a two-dimensional array, where one\r\n        #   dimension represents the input image count, and the other has\r\n        #   predictions per class\r\n        input_node = sess.graph.get_tensor_by_name('input:0')\r\n        output_node = sess.graph.get_tensor_by_name('final_result:0')\r\n    \r\n        softmax_tensor = sess.graph.get_tensor_by_name(output_layer_name)\r\n        predictions, = sess.run(softmax_tensor, {input_layer_name: image_data})\r\n        \r\n        # Sort to show labels in order of confidence\r\n        top_k = predictions.argsort()[-num_top_predictions:][::-1]\r\n        for node_id in top_k:\r\n          human_string = labels[node_id]\r\n          score = predictions[node_id]\r\n          print('%s (score = %.5f)' % (human_string, score))\r\n    \r\n        return 0\r\n    \r\n    \r\n    def main(argv):\r\n      \"\"\"Runs inference on an image.\"\"\"\r\n      '''\r\n      if argv[1:]:\r\n        raise ValueError('Unused Command Line Args: %s' % argv[1:])\r\n    \r\n      if not tf.gfile.Exists(FLAGS.image):\r\n        tf.logging.fatal('image file does not exist %s', FLAGS.image)\r\n    \r\n      if not tf.gfile.Exists(FLAGS.labels):\r\n        tf.logging.fatal('labels file does not exist %s', FLAGS.labels)\r\n    \r\n      if not tf.gfile.Exists(FLAGS.graph):\r\n        tf.logging.fatal('graph file does not exist %s', FLAGS.graph)\r\n      '''\r\n      input_layer='input:0'\r\n      output_layer='final_result:0'\r\n      num_top_predictions=5\r\n      # load image\r\n      image_data = load_image('path-to-image/9_56.JPG')\r\n    \r\n      # load labels\r\n      labels = load_labels('path-to/labels.txt')\r\n    \r\n      # load graph, which is stored in the default session\r\n      load_graph('path-to/output_graph.pb')\r\n    \r\n      run_graph(image_data, labels,input_layer,output_layer,\r\n                num_top_predictions)\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n      #FLAGS, unparsed = parser.parse_known_args()\r\n      tf.app.run(main=main)\r\n    \r\n`  \r\n \r\n  The remaining step remains the same as inceptionv3.\r\n\r\nThanks and regards", "Update: \r\nretrain.py moved to this location from tensorflow 1.7 [https://github.com/tensorflow/hub/tree/master/examples/image_retraining](https://github.com/tensorflow/hub/tree/master/examples/image_retraining)"]}, {"number": 11249, "title": "Revert \"Added assertion error in reset_default_graph() (#11158)\"", "body": "This reverts commit 3db38f15877457c8c2a5c92d66afc0df29fe1f66.\r\n\r\nAppears to fail on Mac, see:\r\nhttp://ci.tensorflow.org/view/Tensorflow%20Jenkins%20Monitored%20builds/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=NO_PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/537/consoleFull\r\n\r\nSee PR thread for more information.", "comments": ["/CC: @Thenerdstation ", "Passed. Let's try again.\r\n\r\nJenkins, test this please.", "@drpngx @Thenerdstation let me try debugging this a little on mac before we do this revert.", "Still no breakthrough... But I've narrowed it down a little: this test failure happens only on Python 3 on Mac. Maybe it has to do with the Python version.", "Sending out https://github.com/tensorflow/tensorflow/pull/11340 to fix the test failures. I think this revert can be avoided."]}, {"number": 11248, "title": "error in freeze_graph.py", "body": "### System information\r\nUbuntu 16.04\r\nPython 2.7.12\r\nTensorflow 1.2.1 installed using pip\r\nGPU: Nvidia Quadro M2000M 4GB\r\nCUDA V 8.0.4\r\n\r\n### Issue\r\nI am trying to recreate the frozen graph using freeze_graph.py from the ssd_mobilenet pretrained model available here:\r\n\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md\r\n\r\nI printed the output nodes using the following command:\r\n\r\n`for n in detection_graph.as_graph_def().node:`\r\n`    print(n.name)`\r\n\r\nI tried running freeze_graph with different output_nodes such as add_6, Postprocessor/BatchMultiClassNonMaxSuppression/stack with following command:\r\n\r\nfreeze_graph.py --input_graph=ssd_mobilenet_v1_coco/graph.pbtxt --input_checkpoint=ssd_mobilenet_v1_coco/model.ckpt --output_graph=./frozen_graph.pb --output_node_names=add_6\r\n\r\nThis is the error that I get:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 202, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 134, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 99, in freeze_graph\r\n    _ = importer.import_graph_def(input_graph_def, name=\"\")\r\n  File \"/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 283, in import_graph_def\r\n    raise ValueError('No op named %s in defined operations.' % node.op)\r\nValueError: No op named SSTableReaderV2 in defined operations.\r\n\r\nWhen I try feeding the old frozen_graph (.pb file) as --input_graph with --input_binary=true to freeze_graph, I get the following error:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 202, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 134, in main\r\n    FLAGS.variable_names_blacklist)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/tools/freeze_graph.py\", line 112, in freeze_graph\r\n    sess.run([restore_op_name], {filename_tensor_name: input_checkpoint})\r\n  File \"/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 789, in run\r\n    run_metadata_ptr)\r\n  File \"/home/adminloc/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 945, in _run\r\n    + e.args[0])\r\nTypeError: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.\r\n\r\nI don't know if this is a bug or lack of documentation, but it would be nice to add some documentation such as the output nodes.\r\n\r\nP.S: I am trying to recreate the frozen graph to be able to create a new frozen graph after fine tuning the model.", "comments": ["The problem is solved, I used export_inference_graph from object_detection using this command:\r\n\r\n`python export_inference_graph \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path path/to/ssd_mobilenets_coco.config \\\r\n    --checkpoint_path path/to/model-ckpt \\\r\n    --inference_graph_path path/to/inference_graph.pb`\r\n\r\nI had to make a new config file for coco, I used ssd_mobilenets_pets and changed the num_classes to 90 as in coco and it exported the frozen graph without any error."]}, {"number": 11247, "title": "Standalone Embedding Projector does not load bookmarks", "body": "The standalone[ Embedding Projector](http://projector.tensorflow.org/) does not open the _Load bookmarks_ window for me all of a sudden. _Save bookmarks_ and everything else still works though. \r\n\r\nI am on Windows 7 (Enterprise) using Chrome (Google Chrome\t59.0.3071.115 (Official Build) (64-bit) (cohort: Stable)).\r\n\r\n", "comments": ["My Chrome Version is `59.0.3071.115 (Official Build) (64-bit)` which is as same as your one. It's working completely fine. I would suggest if the tensor is too big then it takes a while to load.\r\nIf it's not working fine then please provide in-depth insight including options which you have selected while saving a bookmark and loading a bookmark.\r\n", "@printdhruv Thank you for your response, however, maybe I was not really clear about the problem. \r\n\r\nThe issue is that the window to select the saved bookmark does not even appear when clicking on it:\r\n\r\n[link](http://i.imgur.com/knERIxg.gif)\r\n\r\nThe saved bookmark only has 21k vectors (with 300 dimensions), so not that big I suppose. The weird thing is that everything worked perfectly a month ago.\r\n\r\nIn terms of saving and loading, I just used default settings.", "@Deepak- The following log get generated while you are trying to load bookmark!\r\n\r\n`Uncaught TypeError: Cannot read property 'select' of undefined`\r\n    `at HTMLElement.b._uploadFile ((index):10152)`\r\n    `at HTMLElement.d ((index):4668)`\r\n   ` at HTMLElement.fire ((index):4690)`\r\n    `at Object.fire ((index):4678)`\r\n    `at Object.forward ((index):4685)`\r\n    `at Object.touchend ((index):4685)`\r\n    `at HTMLElement.handleNative ((index):4674)`", "@printdhruv Yes exactly! How do I debug it?", "Thanks for your help @printdhruv.  @dandelionmane have you seen this issue before?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi thanks for the bug report.\r\n\r\nThis is a tensorboard problem, and should be moved to that repo (now that it has it's own repo). \r\n\r\nA quick search shows that this has been reported there:\r\n\r\ntensorflow/tensorboard#911\r\ntensorflow/tensorboard#835\r\n\r\nSo I'm closing this as duplicate.\r\n"]}, {"number": 11246, "title": "install cub under external/cub_archive to fix windows gpu build", "body": "Fix cmake/windows gpu build. \r\ninstall cub under external/cub_archive so  where_op_gpu.cu.cc will find it for cmake and bazel in the same place.\r\nhttps://github.com/tensorflow/tensorflow/commit/8280e0ae9083a65b23608b34723f07e028a56dc8\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11245, "title": "The data type conversion between int32 and float32", "body": "My project require convert the data type of tensor (dtype=float32) to int32, and then I need turn the dtype back (from int32 to float32) after some operations.\r\n The code is\r\n\r\n>  y = tf.to_int32(x)\r\n>  bitwiseXor = tf.bitwise.bitwise_xor(y, key)\r\n>  z = tf.to_float(bitwiseXor)\r\n\r\nBut following errors appears, how to solve it?\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 490, in apply_op\r\n>     preferred_dtype=default_dtype)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 675, in internal_convert_to_tensor\r\n>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 121, in _constant_tensor_conversion_function\r\n>     return constant(v, dtype=dtype, name=name)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 364, in make_tensor_proto\r\n>     raise ValueError(\"None values not supported.\")\r\n> ValueError: None values not supported.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 504, in apply_op\r\n>     values, as_ref=input_arg.is_ref).dtype.name\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 675, in internal_convert_to_tensor\r\n>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 121, in _constant_tensor_conversion_function\r\n>     return constant(v, dtype=dtype, name=name)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n>     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 364, in make_tensor_proto\r\n>     raise ValueError(\"None values not supported.\")\r\n> ValueError: None values not supported.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"/win1/Ubuntu_App/RemotePython/EncNN/My_EncML.py\", line 134, in <module>\r\n>     model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\r\n>   File \"/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\", line 1458, in fit\r\n>     self._make_train_function()\r\n>   File \"/usr/local/lib/python3.4/dist-packages/keras/engine/training.py\", line 1002, in _make_train_function\r\n>     self.total_loss)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/keras/optimizers.py\", line 326, in get_updates\r\n>     new_a = self.rho * a + (1. - self.rho) * K.square(g)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py\", line 1225, in square\r\n>     return tf.square(x)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py\", line 428, in square\r\n>     return gen_math_ops.square(x, name=name)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2544, in square\r\n>     result = _op_def_lib.apply_op(\"Square\", x=x, name=name)\r\n>   File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 508, in apply_op\r\n>     (input_name, err))\r\n> ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.\r\n> \r\n> Process finished with exit code 1", "comments": ["Here are some suggestions: -\r\n\r\n(1) `ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.` which implies the value of `x` used in first line of your code `y = tf.to_int32(x)` is missing.\r\n\r\n(2) Please review guidelines for raising an issue here. [https://github.com/printdhruv/tensorflow/blob/master/ISSUE_TEMPLATE.md](https://github.com/printdhruv/tensorflow/blob/master/ISSUE_TEMPLATE.md)", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Answered on StackOverflow [here](https://stackoverflow.com/a/45025025/4126114)"]}, {"number": 11244, "title": "[OpenCL] Adds -Wno-c++11-narrowing to ComputeCpp device compiler", "body": "Adds -Wno-c++11-narrowing to ComputeCpp device compiler flags to avoid build errors on 32-bit targets. (#109)", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11243, "title": "Use custom BUILD file for protobuf", "body": "This change won't be needed after updating protobuf to a version\r\ncontaining google/protobuf@0b059a3", "comments": ["Yeah, that would be better, but the last time I did, it broke the macOS build.\r\nAnyway, let's try again https://github.com/tensorflow/tensorflow/pull/11317", "Closing this because we have #11317 "]}, {"number": 11242, "title": "remove some warning", "body": "remove some c++ compiler warning.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 11241, "title": "[Feature request] add checkpoint_convert.py script to pip package", "body": "In the TensorFlow 1.2.0 pip package (at least for Linux), [checkpoint_convert.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py) is not included. Because of #11168, 92da8abfd35b93488ed7a55308b8f589ee23b622, 157370e5916b85c65958ed8383ae31d727228ed7, it might be useful. Esp., in our framework, I would like to add some automatic handling at runtime when a checkpoint file is loaded and some variables are not found, to automatically try to load variables under different names according to `_RNN_NAME_REPLACEMENTS`. Thus, extending to adding `checkpoint_convert.py` to the pip package, it would also be nice to make `_RNN_NAME_REPLACEMENTS` public (remove the leading underscore).\r\n", "comments": ["@yifeif can you please comment on whether adding checkpoint_convert.py would be OK? ", "SGTM. A PR would be welcome.", "I'm looking into this.", "Created PR https://github.com/tensorflow/tensorflow/pull/11691", "Closing as this is resolved"]}]