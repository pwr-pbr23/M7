[{"number": 4852, "title": "tensorflow.python.framework.errors.PermissionDeniedError: File isn't open for reading", "body": "`\nFile \"./encoder.py\", line 103, in <module>\n tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"./encoder.py\", line 99, in main\n    np.savez_compressed(code_file, shape=int_codes.shape, codes=export)\n  File \"/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py\", line 600, in savez_compressed\n    _savez(file, args, kwds, True)\n  File \"/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py\", line 642, in _savez\n    zipf.write(tmpfile, arcname=fname)\n  File \"/usr/lib/python2.7/zipfile.py\", line 1146, in write\n    zinfo.header_offset = self.fp.tell()    # Start of header bytes\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 139, in tell\n    \"File isn't open for reading\")\ntensorflow.python.framework.errors.PermissionDeniedError: File isn't open for reading\nException tensorflow.python.framework.errors.PermissionDeniedError: PermissionDeniedError() in <bound method ZipFile.__del__ of <zipfile.ZipFile object at 0x7fc6f2011450>> ignored\n`\n", "comments": ["Thanks for reporting this issue. In order for us to help, we need concrete steps to reproduce the bug.\n", "@jart  I think this bug maybe caused by the numpy incompatibilities with the current TensorFlow version (r0.11). The detail refers to : https://github.com/tensorflow/models/pull/510.\nWhen I run the code with tensorflow (r0.10), there is no error occured. \nThank you.\n", "@DaveyTao we encountered a PermissionDeniedError in #4913 where TensorFlow was being configured to save stuff in /tmp rather than creating a special subdirectory. It's possible this could be related to that.\n\nAside from that, I'm going to close this issue, because there isn't enough information here for closer examination or reproduction. I'll reopen this issue if provided new information.\n"]}, {"number": 4851, "title": "missing dependency declarations for the following files included by 'external/protobuf/python/google/protobuf/internal/api_implementation.cc'", "body": "when I install the syntaxnet\u3002I encounter with the error\"missing dependency declarations\". what below is the details.\nERROR: /vol6/home/para11/.cache/bazel/_bazel_para11/05959d3334ad62caf308f1ce677a2caf/external/protobuf/BUILD:516:1: undeclared inclusion(s) in rule '@protobuf//:internal/_api_implementation.so':\nthis rule is missing dependency declarations for the following files included by 'external/protobuf/python/google/protobuf/internal/api_implementation.cc':\n  '/vol6/python2.7/include/python2.7/Python.h'\n  '/vol6/python2.7/include/python2.7/patchlevel.h'\n  '/vol6/python2.7/include/python2.7/pyconfig.h'\n  '/vol6/python2.7/include/python2.7/pymacconfig.h'\n  '/vol6/python2.7/include/python2.7/pyport.h'\n  '/vol6/python2.7/include/python2.7/pymath.h'\n  '/vol6/python2.7/include/python2.7/pymem.h'\n  '/vol6/python2.7/include/python2.7/object.h'\n  '/vol6/python2.7/include/python2.7/objimpl.h'\n  '/vol6/python2.7/include/python2.7/pydebug.h'\n  '/vol6/python2.7/include/python2.7/unicodeobject.h'\n  '/vol6/python2.7/include/python2.7/intobject.h'\n  '/vol6/python2.7/include/python2.7/boolobject.h'\n  '/vol6/python2.7/include/python2.7/longobject.h'\n  '/vol6/python2.7/include/python2.7/floatobject.h'\n  '/vol6/python2.7/include/python2.7/complexobject.h'\n  '/vol6/python2.7/include/python2.7/rangeobject.h'\n  '/vol6/python2.7/include/python2.7/stringobject.h'\n  '/vol6/python2.7/include/python2.7/memoryobject.h'\n  '/vol6/python2.7/include/python2.7/bufferobject.h'\n  '/vol6/python2.7/include/python2.7/bytesobject.h'\n  '/vol6/python2.7/include/python2.7/bytearrayobject.h'\n  '/vol6/python2.7/include/python2.7/tupleobject.h'\n  '/vol6/python2.7/include/python2.7/listobject.h'\n  '/vol6/python2.7/include/python2.7/dictobject.h'\n  '/vol6/python2.7/include/python2.7/enumobject.h'\n  '/vol6/python2.7/include/python2.7/setobject.h'\n  '/vol6/python2.7/include/python2.7/methodobject.h'\n  '/vol6/python2.7/include/python2.7/moduleobject.h'\n  '/vol6/python2.7/include/python2.7/funcobject.h'\n  '/vol6/python2.7/include/python2.7/classobject.h'\n  '/vol6/python2.7/include/python2.7/fileobject.h'\n  '/vol6/python2.7/include/python2.7/cobject.h'\n  '/vol6/python2.7/include/python2.7/pycapsule.h'\n  '/vol6/python2.7/include/python2.7/traceback.h'\n  '/vol6/python2.7/include/python2.7/sliceobject.h'\n  '/vol6/python2.7/include/python2.7/cellobject.h'\n  '/vol6/python2.7/include/python2.7/iterobject.h'\n  '/vol6/python2.7/include/python2.7/genobject.h'\n  '/vol6/python2.7/include/python2.7/descrobject.h'\n  '/vol6/python2.7/include/python2.7/warnings.h'\n  '/vol6/python2.7/include/python2.7/weakrefobject.h'\n  '/vol6/python2.7/include/python2.7/codecs.h'\n  '/vol6/python2.7/include/python2.7/pyerrors.h'\n  '/vol6/python2.7/include/python2.7/pystate.h'\n  '/vol6/python2.7/include/python2.7/pyarena.h'\n  '/vol6/python2.7/include/python2.7/modsupport.h'\n  '/vol6/python2.7/include/python2.7/pythonrun.h'\n  '/vol6/python2.7/include/python2.7/ceval.h'\n  '/vol6/python2.7/include/python2.7/sysmodule.h'\n  '/vol6/python2.7/include/python2.7/intrcheck.h'\n  '/vol6/python2.7/include/python2.7/import.h'\n  '/vol6/python2.7/include/python2.7/abstract.h'\n  '/vol6/python2.7/include/python2.7/compile.h'\n  '/vol6/python2.7/include/python2.7/code.h'\n  '/vol6/python2.7/include/python2.7/eval.h'\n  '/vol6/python2.7/include/python2.7/pyctype.h'\n  '/vol6/python2.7/include/python2.7/pystrtod.h'\n  '/vol6/python2.7/include/python2.7/pystrcmp.h'\n  '/vol6/python2.7/include/python2.7/dtoa.h'\n  '/vol6/python2.7/include/python2.7/pyfpe.h'.\n", "comments": ["Is it possible you forgot to run `./configure` before building? Or forgot to: `sudo apt-get install python-numpy swig python-dev python-wheel`? See also #4926.\n", "Closing this issue due to inactivity. Please reopen if you're still having trouble.\n"]}, {"number": 4850, "title": "Updated the links in docs to match the markdown sytnax.", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@haosdent, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @martinwicke to be potential reviewers.\n", "@tensorflow-jenkins Test this please\n", "Thanks for fixing this @haosdent !\n"]}, {"number": 4849, "title": "Method docs contain unclosed verbatim, which causes exceeding verbatim block in HTML docs", "body": "The HTML docs for `tf.constant_initializer` at  https://www.tensorflow.org/versions/master/api_docs/python/state_ops.html#constant_initializer contain unclosed verbatim block, which continues past the method and contains several following methods -- see for example the `tf.random_normal_initializer`.\n\nI am not much familiar with the process of documentation generation, but my guess is that the verbatim ending block at https://github.com/tensorflow/tensorflow/blob/2c4af2e65a2018540d949cfdba1fcb15d0121f80/tensorflow/python/ops/init_ops.py#L142 has wrong indentation (it is indented by two more spaces than the start of the block).\n", "comments": ["Thank you for reporting this. I've contacted just the right person who will be able to help out with this shortly.\n", "@martinwicke, it looks like the generated markdown is rendering fine on g3doc, so the website generator is doing something strange here.\n", "What are we using to generate the website? There are subtle differences between various Markdown implementations. Particularly when it comes to indentation. The solution could be as simple as decreasing the indent of that closing ``` by two spaces, as @foxik suggests.\n", "The website generator uses the same markdown renderer that we use to view the doc internally, so the problem must be some extra pre- or post-processing the website generator is doing.\n", "This was fixed by https://github.com/tensorflow/tensorflow/commit/8e63535abb29af6f62e65dab624f4a4d3f5581cc. Push to web server is still pending.\n"]}, {"number": 4848, "title": "\"bazel clean\" will undo \"./configure\" when source configured to build for GPU.", "body": "### Environment info\n\nOperating System:\nubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\ncuda 8.0.44, cudnn 5.5\n\nIf installed from binary pip package, provide:\nNo\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   c8d4896e3231c3ac32f174fd0af051867645fbb5\n2. The output of `bazel version`\n   Build label: 0.3.1\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Fri Jul 29 09:09:52 2016 (1469783392)\n   Build timestamp: 1469783392\n   Build timestamp as int: 1469783392\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n./configure   # configure with GPU support)\nbazel test -c opt --config=cuda tensorflow/core:common_runtime_direct_session_test # this one should pass\nbazel clean\nbazel test -c opt --config=cuda tensorflow/core:common_runtime_direct_session_test  # this one fails, complaining no GPU support configured.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@ae\n3629bd' (requested by nodes 'CONFIGURATION_COLLECTION:com.google.devtools.build.lib.skyframe.ConfigurationCollectionValue$ConfigurationCollectionKey@1374ec1e', 'CONFIGURATION_FRAGMENT:com\n.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@3686b55', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue\n$ConfigurationFragmentKey@a93d9174')\n        at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:1070)\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:474)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n\nDavid, Damien, looks like bazel clean undid some output of \"./configure\" at head.\nAny idea where things went wrong?\n", "comments": ["I don't have the code of cuda_configure in my HEAD but it sounds like the repository itself is invalidated by bazel clean which should not happens, @kchodorow might have an idea on why a simple clean would invalidate a remote repository (maybe a bug in the skylark remote repositories).\n\nSide-note: we should fix the failure message that fail at the wrong step (i.e. not have that stack trace, why do even have that lever?)\n", "Ping, any updates, comments on this?", "Is this still happening? I have some in progress change to fix invalidation of skylark remote repository (to avoid the clean --expunge in the configure step) but it shold not affect this one (or maybe it will).", "Yes, I am still running into this if I do bazel clean:\r\n```\r\n...\r\n\t\tfail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /usr/local/google/home/gunan/.cache/bazel/_bazel_gunan/f65fe95058266630d298f8662514e702/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 0.318s\r\n```", "The reason why this is happening is that it looks like `bazel clean` is, as Damien described, invalidating the repository created by `cuda_configure`, and because the environment variables used by `cuda_configure` are no longer set (since they were only set in the subshell when `./configure` ran), we end up re-fetching with all default values and thus configuring the repository to not build with GPU.\r\n\r\nSeems this behavior we are observing where running `bazel clean` without `--expunge` invalidates the repository might be a bug.", "Ok I found out the issue.\r\n\r\n`local = True` from [cuda_configure.bzl#L818](https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda_configure.bzl#L818) basically invalidate the repository for a lot of little things, I suggest removing that local = True.", "Will try the suggestion out locally.", "After removing local=True, I still see the same problem.\r\n@damienmg do you think I missed something, or is this not the full fix?", "I need to investigate a bit more. removing local = True should do the trick... I'll try to reproduce tomorrow, all I need is docker right?", "You actually need a machine with a NVIDIA gpu, docker or not.\nWhen I try on my machine, I can confirm that local = True does not fix the\nproblem for me.\n\nOn Mon, Jan 9, 2017 at 1:56 PM, Damien Martin-Guillerez <\nnotifications@github.com> wrote:\n\n> I need to investigate a bit more. removing local = True should do the\n> trick... I'll try to reproduce tomorrow, all I need is docker right?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4848#issuecomment-271419905>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOdG7NqdrAekh_Phu2swIgtZ6pGYHks5rQq0GgaJpZM4KR74N>\n> .\n>\n", "No `bazel clean` in history:\r\n\r\n    $ history | grep ' bazel'\r\n    ........\r\n    241 bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n    242 bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\nBut then:\r\n\r\n    $ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\n\t......\r\n\tERROR: /home/kit/.cache/bazel/_bazel_kit/5f23834381991ebb87bab85ad8b737c5/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n\t\tFile \"/home/kit/.cache/bazel/_bazel_kit/5f23834381991ebb87bab85ad8b737c5/external/local_config_cuda/crosstool/BUILD\", line 4\r\n\t\t\terror_gpu_disabled()\r\n\t\tFile \"/home/kit/.cache/bazel/_bazel_kit/5f23834381991ebb87bab85ad8b737c5/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n\t\t\tfail(\"ERROR: Building with --config=c...\")\r\n\tERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\n\tERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/kit/.cache/bazel/_bazel_kit/5f23834381991ebb87bab85ad8b737c5/external/local_config_cuda/crosstool/BUILD.\r\n\tINFO: Elapsed time: 0.571s\r\n\r\nSeems like cache invalidation issue to me. AFAIR it's time dependent, i.e. will fail only if looong time passed between builds."]}, {"number": 4847, "title": "input tensor lost in --mode eightbit quantization", "body": "Quantizing with --mode eightbit somehow loses the input tensor, whereas other methods like weights_rounded don't. If I do this:\n\n`python quantize_graph.py --input ~/proc/frozen_inference_optimized.pb --output ~/proc/frozen_inference_optimized_quantized.pb --output_node_names on_logits --mode eightbit`\n\nthe following error pops up in the iOS tensorflow runtime:\n\n`Running model failed:Not found: FeedInputs: unable to find feed output preprocess/centered_bgr`\n\nHere `preprocess/centered_bgr` is the node I want to use as the input. If instead I use something like `--mode weights_rounded` no error is raised and the network functions as expected.\n### Environment info\n\nOperating System: ubuntu / iOS\n\nInstalled version of CUDA and cuDNN: \n\n```\nroot@0f1fd91e29a1:~/w/tensorflow/tensorflow/contrib/quantization/tools# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n```\n\nCommit I'm using: 8915f0f8072c406ae3fe0dff888f51b4cad02d7d. bazel version 0.3.0.\n\ncc @petewarden \n", "comments": ["Does this information help solve your problem?\n\n``` markdown\n### I am getting APP_ERROR(5) during inference, how do I fix that?\n\nHere's a typical error:\n\n`\"APP_ERROR(5) FeedInputs: unable to find feed output x\"`\n\nThis typically means that your model was not exported correctly, or that you've\nnot formatted the request properly. Double check your [signatures](#signatures)\nand request format.\n```\n", "Hi @jart, no, it doesn't because it works with a different quantization of the same frozen model file and the same runtime code on iOS.\n", "Thank you for your patience @tachim.\n\n@petewarden and @cwhipkey would be the best ones to help out with this.\n", "As a temporary workaround, can you try the following to see if it fixes the issue?\n\n`python quantize_graph.py --input ~/proc/frozen_inference_optimized.pb --output ~/proc/frozen_inference_optimized_quantized.pb --output_node_names on_logits,preprocess/centered_bgr --mode eightbit`\n\nHere I've added the input node to the list of outputs. The issue is that it's deciding that the input node 'preprocess/centered_bgr' isn't needed, so I'm forcing it to include it by listing it as an output. If that fixes the immediate issue, it will give more information about what's going wrong.\n", "Is this still an open issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 4846, "title": "Integrating Metal API on iOS?", "body": "Any plans to use the Metal API on iOS? E.g. https://developer.apple.com/reference/metalperformanceshaders/mpscnnconvolution.\n", "comments": ["We don't officially support iOS. We have community supported examples that allow TensorFlow to be used on iOS in CPU mode. Our GPU support is achieved on both Linux and OS X using CUDA. So it seems unlikely that we would integrate with the Metal API. @wicke might have thoughts on this.\n\nSee also: #491\n", "There's [bender](https://github.com/xmartlabs/Bender), that provides an API on top of Metal to build and run neural nets. It also supports running TensorFlow models."]}, {"number": 4845, "title": "Fixed a compilation error with gcc 6.2", "body": "", "comments": ["@benoitsteiner, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yifeif, @keveman and @kirilg to be potential reviewers.\n", "@tensorflow-jenkins test this please\n", "The single failing test is unrelated to this change.\n", "@rohan100jain You can merge this.\n"]}, {"number": 4844, "title": "Tensorboard - Alphabetic ordering of Runs in Graph tab", "body": "In all the tabs in tensorboard, the different runs are neatly ordered. However, this is not the case for the Graph tab. See screenshot.\nI'm going crosseyed looking for the correct model each time.\n![image](https://cloud.githubusercontent.com/assets/7721540/19213241/c1de13a4-8d6e-11e6-9fcb-68c98f743a9f.png)\n", "comments": ["Thanks for reporting this. I just wrote up a change internally fixing it. It should get released in the near future.\n"]}, {"number": 4843, "title": "Add PIL formats(gif,png...) support for retrain.py", "body": "- Add PIL formats(gif,png...) support for retrain.py.\n- Use PIL.Image to read images and io.BytesIO to serialize them.\n", "comments": ["Can one of the admins verify this patch?\n", "@elviswf, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @danmane and @tensorflower-gardener to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "**I signed it!**\nThank you!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@petewarden I have updated the code according to the reviews. Thank you!\n", "Jenkins, test this please.\n", "` Log @: /workspace/pip_test/tests/logs/tensorflow/examples/image_retraining/retrain_test.py.log\n\n============== BEGINS failure log content ==============\nTraceback (most recent call last):\n  File \"/workspace/pip_test/tests/retrain_test.py\", line 23, in <module>\n    from tensorflow.examples.image_retraining import retrain\n  File \"/workspace/pip_test/venv/local/lib/python2.7/site-packages/tensorflow/examples/image_retraining/retrain.py\", line 81, in <module>\n    from PIL import Image\nImportError: No module named PIL\n\n============== ENDS failure log content ==============`\n\nIt shows `No module named PIL`. I wonder if there is a way to read png, gif images without using outside packages like PIL. \nThank you!\n", "@petewarden @gunan Should we install PIL as part of our CI infrastructure and add this as a dependency?\n\nPart of me thinks that, serving as an example, this is not going to do everything that people want to do, so perhaps we leave a comment instead suggesting other ways to read images instead.\n", "I am not a fan of adding the dependency, as I think everyone will have their own favorite ways of reading images. And PIL is not a real requirement to core TF, so I don't think it is right to brand it like a requirement to TF.\n\nAs for installing it to ci, sure.\nBut that means it will be installed to TF docker images.\n", "Okay, closing for now but discussion can continue here if needed.\n", "Actually I fully agree that adding this dependency is not necessary for now. I just used it for a deep learning competition with png, gif data and wanted to shared a way to handle it directly. \n I will go on with excellent TF. Thank you all!\n", "I have the same problem, so this piece code is useful for me."]}, {"number": 4842, "title": "TypeError: The value of a feed cannot be a tf.Tensor object", "body": "Hi, thanks before you see it.\nI got an error when i run tensorflow model of cnn.\n\nTypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.\n\n This error tell me that I cant feed tensor,but i dont know how to modify my code .Any one can tell me how can i modify my code ? \n\nHere is my code.\nhttps://github.com/xuhuapeng/cifar/blob/master/cnn_1.py\n\n  https://github.com/xuhuapeng/cifar\n\nThanks very much.\n", "comments": ["Once you have launched a sess, you can use `your_tensor.eval(session=sess)` or `sess.run(your_tensor)` to get you feed tensor into the format of `numpy.array` and then feed it to your placeholder.\n", "@zakizhou \n I have change the code to :\n`sess.run(train_step,feed_dict={x: images, y_: labels, keep_prob: 0.5})`\n\nBut it give the same error as I pointed out before.\n\nAlso I had tried to  change the code to\n `sess.run(train_step,feed_dict={x: images.eval(), y_: labels.eval(),keep_prob:0.5})`.\nBut this will lead the program to execute forever. In my point the `images.eval()` step can't done forever.\n\nCan you see my code to give me some another advice ?? Thank you so much.\n", "@xuhuapeng \nThe `cnn_1.py` in your git repo is modified from the original file in the official tutorial of  TF right?  If you have a close look at its original code, you will find no `placeholder`s in it which means the input of the model is the second way(`readings from files` not `feeding`) according to  [this](https://www.tensorflow.org/versions/r0.11/how_tos/reading_data/index.html), as a result, you can't feed any data to this model.\nSince cifar10 is not a small dataset like mnist, `placeholder` is not suitable for this kind of large datasets, personally I think  reading inputs from files is the best way to train it. If you still want to use `placeholder`  you'd better write a `next_batch` method in `mnist` for cifar10 so as to feed the `placeholder`\n", "yeah.I will try you suggestion.Thank you very much.\nOne more question,please be patient with me. Why  I modified my code to  `sess.run(train_step,feed_dict={x: images.eval(), y_: labels.eval(),keep_prob:0.5})`. The program won't be stop? Doing the `.eval()` operation forever?\n", "see [this](https://www.tensorflow.org/versions/r0.11/how_tos/reading_data/index.html) Creating threads to prefetch using QueueRunner objects section.\n\nYou delete the  `tf.train.start_queue_runners` ,`coord` and `theads`  from the training code which will start the input queue that the `reader`  need to read from, so you `reader` will hang there until the queue starts.\n", "Thanks very much.\n I had saw the link you  gave me, but there are lots thing I can't understand due to my poor English,. Maybe I should see it again.  \ud83d\udc4d @zakizhou \n", "You are welcome,byt,\u54b1\u4eec\u4e2d\u56fd\u4eba\u8fd8\u662f\u7528\u4e2d\u6587\u4ea4\u6d41\u6bd4\u8f83\u597d> < @xuhuapeng \n", "Thanks @zakizhou for helping to resolve this problem for @xuhuapeng. If you have questions in the future, we recommend [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) for community support. We try to keep this issue tracker focused on bugs and feature requests.\n", "@zakizhou \u4f60\u597d\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u76f8\u4f3c\u7684\u95ee\u9898\uff0c\u7cfb\u7edf\u521a\u5f00\u59cb\u548c\u6211\u8bf4\uff0c\u8f93\u5165\u5fc5\u987b\u662f\u4e00\u4e2atensor\uff0c\u53e6\u4e00\u65b9\u9762\u7cfb\u7edf\u53c8\u548c\u6211\u8bf4\uff0cfeed\u4e0d\u80fd\u662ftensor\uff0c\u80fd\u4e0d\u80fd\u9ebb\u70e6\u5927\u795e\u5e2e\u6211\u770b\u4e00\u4e0b\uff0c\u4ee3\u7801\u5e76\u4e0d\u590d\u6742\u3002\u611f\u8c22\r\nhttps://github.com/RayAnteku/tensorflow", "@zakizhou \u4f60\u597d\uff0c\u6839\u636e\u4f60\u4e0a\u8fb9\u7684\u56de\u7b54\u6211\u5bf9\u6211\u7684\u7a0b\u5e8f\u505a\u4e86\u4fee\u6539\uff0c\u4f46\u7a0b\u5e8f\u8fd8\u662f\u4e00\u76f4\u963b\u585e\uff0c\u80fd\u529e\u5fd9\u770b\u4e00\u4e0b\u4ee3\u7801\u5417\uff0c\u4e0d\u80dc\u611f\u6fc0\uff0c\u4f60github\u4e0a\u7684\u90ae\u7bb1\u53d1\u4e0d\u8fc7\u53bb\u90ae\u4ef6\uff0c\u6211\u7684\u90ae\u7bb11107404430@qq.com\u3002[https://github.com/Tony-Hou/Img_classification.git](url)", "@RayAnteku , Do you solve this problem? I have the same error with you . If you did,please telll me how."]}, {"number": 4841, "title": "Problem on building target with GPU support", "body": "Result of `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`:\n\n```\nERROR: /home/darth/.cache/bazel/_bazel_darth/08554d152596e5a7df399506682a63f3/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\n    File \"/home/darth/.cache/bazel/_bazel_darth/08554d152596e5a7df399506682a63f3/external/local_config_cuda/crosstool/BUILD\", line 4\n        error_gpu_disabled()\n    File \"/home/darth/.cache/bazel/_bazel_darth/08554d152596e5a7df399506682a63f3/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\n        fail(\"ERROR: Building with --config=c...\")\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/darth/.cache/bazel/_bazel_darth/08554d152596e5a7df399506682a63f3/external/local_config_cuda/crosstool/BUILD.\nINFO: Elapsed time: 0.097s\n```\n\nAnd yes, I have GPU enabled when I did `sudo ./configure`\n", "comments": ["@tatatodd Hello?\n", "@AFAgarap This looks similar to #4105 \n\nBased on that issue, you might try the following:\n\n```\n$ bazel clean\n$ ./configure # make sure to choose gpu support\n$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n```\n\nIf that doesn't work, please cut-and-paste the result of the above commands, including the exact values you entered for the `./configure` call.  Also include the below information:\n\n---\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n", "@tatatodd I met the same issue. And I do configure with CUDA enabled. Do you have any solutions for this issue?\n\n$git rev-parse HEAD\n8e48ec6ea0492e2cb9fd19c0a2ccf41afc7b4dc6\n\n$bazel version\nINFO: $TEST_TMPDIR defined: output root default is '/gruntdata/houge/tmp'.\n.\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n\nThanks\n", "@AFAgarap @tatatodd I found a work around method to fixed this issue in my machine. \nIn ./third_party/gpus/cuda_configure.bzl file, there is a function to check whether cuda is enabled, \n`def _enable_cuda(repository_ctx):\n  if \"TF_NEED_CUDA\" in repository_ctx.os.environ:\n    enable_cuda = repository_ctx.os.environ[\"TF_NEED_CUDA\"].strip()\n    print (enable_cuda)\n    return enable_cuda == \"1\"\n  return False\n`\nIn my case, even I run the configure with CUDA enabled. The environment variable \"TF_NEED_CUDA\" was still no in the list of repository_ctx.os.environ. So It would say CUDA was not enabled when compiled from source. Then I export \"TF_NEED_CUDA=1\" in my ~/.bashrc. And it compiled successfully. \n\nSo I am not sure whether it works for your case? @AFAgarap\n", "I was suspecting that there was some problem with the code or something, but wasn't sure where or which module would it be. Thanks for this, @jinhou  I'll try it later.\n", "I have tensorflow installed using binary, with CUDA 8.0, and cuDNN 5.0.\nDoes the binary-installed tensorflow has anything to do with this failure to build from source? @tatatodd @jinhou\n\n```\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rwxrwxrwx 1 root root    558720 Oct  8 23:18 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Oct  8 23:17 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root        19 Oct  8 23:18 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxrwxrwx 1 root root    415432 Oct  8 23:17 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rwxrwxrwx 1 root root    775162 Oct  8 23:18 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root        13 Oct  8 23:22 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root        17 Oct  8 23:22 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxrwxrwx 1 root users 79337624 Jul 27 13:53 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rwxrwxrwx 1 root users 69756172 Jul 27 13:53 /usr/local/cuda/lib64/libcudnn_static.a\n\n```\n\nBinary pip package: \n\n```\n$ python3 -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0\n```\n\n## \n\nThe repo clone I have:\n\n```\n$ git rev-parse HEAD\n$ 36ebbf1ddc3ed820b7a5572ff4ed8e9bc707b8e5\n```\n\n## \n\nBazel installed in my system:\n\n```\n$ bazel version\nKilled non-responsive server process (pid=12228)\n.\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n```\n\n```\n$ /usr/bin/bazel version\nKilled non-responsive server process (pid=25627)\n.\nBuild label: 0.3.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\nBuild timestamp: 1475861110\nBuild timestamp as int: 1475861110\n```\n\nI have two `bazel` installed because I've read somewhere that `bazel-0.3.1` is the one that works for TF. @tatatodd \n", "Hello @AFAgarap, I think you had intended to tag @jinhou but tagged me by mistake :)\n", "@tatatodd \nI have met the same issue.\n$ git rev-parse HEAD\n73b01567d68d4639d2329deb335ddfcd9c04f87c\n\n$ bazel version\n.\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n", "@jihunchoi Sorry, my bad. :grinning:\n\n@jinhou Nope, it didn't solve my problem. :disappointed:  When it is building, it gets stuck at some point.\n", "@AFAgarap See related issue #4910\n\nWe don't support CUDA 8.0 yet. It will be supported soon. Right now we only officially support 7.0 - 7.5. Please see #2559 which is tracking this. There's also #4895 which encountered this issue on the same version of Ubuntu.\n\nI'm closing this out, but feel free to comment on this issue or file a new issue if you have a different problem.\n", "@tatatodd You do not support CUDA 8 yet for building from sources? Because the one I installed using binary pip is working out fine.\n", "@AFAgarap We plan on CUDA 8 support to come officially in TensorFlow version 0.11rc1.\n\nIn general there is no difference in features between our binary and source releases at a particular version.  I.e. our binaries are built out of our sources at a particular version.\n\nIn the meantime if you're building from sources, and want to use CUDA 8, you'll need to ensure you have a fresh enough version of the sources, that hasn't introduced some other silly bug.  Once 0.11rc1 has been released you can just use that as a stable point in the codebase.\n", "@tatatodd Thank you. Though with the binary installation TensorFlow, I've been able to do `inception`. Is that okay? I mean, is it required to build TensorFlow from sources to use `inception`? I mean, perhaps there are just some \"underground\" bugs happening to my install that I'm not aware.\n", "@AFAgarap If the binary TensorFlow that you're using seems to work for Inception, I wouldn't worry about it too much in the short-term.  But I would recommend you upgrade to version 0.11rc1 when it is available.\n", "@tatatodd In the short-term? Why? Will it have a problem? And yes, I'll upgrade to `version 0.11rc` as soon as you deploy it. \n", "I performed a ./configure with GPU enabled, the build did not work.\nGPU support will be enabled for TensorFlow\nbazel build  -c opt --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package\nINFO: $TEST_TMPDIR defined: output root default is '/scratch/local/hpcapps/bazel'.\n..............\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nERROR: /scratch/local/hpcapps/bazel/_bazel_hpcapps/9854aab478a0076ff75539c378bcd3e3/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\n        File \"/scratch/local/hpcapps/bazel/_bazel_hpcapps/9854aab478a0076ff75539c378bcd3e3/external/local_config_cuda/crosstool/BUILD\", line 4\n                error_gpu_disabled()\n        File \"/scratch/local/hpcapps/bazel/_bazel_hpcapps/9854aab478a0076ff75539c378bcd3e3/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\n                fail(\"ERROR: Building with --config=c...\")\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /scratch/local/hpcapps/bazel/_bazel_hpcapps/9854aab478a0076ff75539c378bcd3e3/external/local_config_cuda/crosstool/BUILD.\nINFO: Elapsed time: 2.299s\n\nI did a bazel clean and a new configure, and:\nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer   (see above)\nI now got:\nINFO: $TEST_TMPDIR defined: output root default is '/scratch/local/hpcapps/bazel'.\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nINFO: Found 1 target...\nERROR: /scratch/local/hpcapps/tensorflow/tensorflow/core/kernels/BUILD:271:1: null failed: protoc failed: error executing command bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-opt/genfiles/external/protobuf/src ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version`CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 517.714s, Critical Path: 507.68s\n\nPS: My OS is centos6\nLinux kp298 2.6.32-642.6.2.el6.x86_64\n\nThanks,\n\nWim\n", "@jinhou you are the man! Exporting the environment variable worked for me!\r\n\r\n```\r\nexport TF_NEED_CUDA=\"1\"\r\n\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --copt=-msse4.1 --copt=-msse3 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\r\n\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n```\r\n\r\nBy-the-way, I compile TF in a ramdisk. If you're impatient, you can really boost the compilation time. I went from 35 minutes on my RAID-10 SSDs to ~14 minutes in my ram disk. Jfyi, you'll need about 8GB of free ram to do this.", "Thanks @jinhou, exporting TF_NEED_CUDA = \"1\" did the trick for me. Just curious, how did you find this out?", "export TF_NEED_CUDA=\"1\" solved the issue for me also, thanks @jinhou \r\nMy system: Ubuntu 16.10, Cuda 8.0.61, Cudnn8.0, NVIDIA linux 378.13 (.run).\r\n", "I'll also confirm that **export TF_NEED_CUDA=\"1\"** works when building from source. I assume this error somehow made it back into the master branch.", "This still seems to be an issue. I have Ubuntu 14.04 and **export TF_NEED_CUDA=\"1\"** solved the issue.", "Had to also export `CUDNN_INSTALL_PATH` for Bazel to recognize CuDNN.", "I am having same issue on Gentoo system with CUDA 9 and CudNN 7 which discussed elsewhere might work, I am giving it try now.\r\n\r\n@goldsborough what is the value of the variable? I suggest it is simply /usr/lib64 (I am on gentoo system):\r\n```\r\nandromeda /var/lib/layman/archenroot/sci-libs/tensorflow # equery f nvidia-cuda-cudnn\r\n * Searching for nvidia-cuda-cudnn ...\r\n * Contents of dev-libs/nvidia-cuda-cudnn-7.0:\r\n/usr\r\n/usr/include\r\n/usr/include/cudnn.h\r\n/usr/lib64\r\n/usr/lib64/libcudnn.so -> libcudnn.so.7\r\n/usr/lib64/libcudnn.so.7 -> libcudnn.so.7.0.4\r\n/usr/lib64/libcudnn.so.7.0.4\r\n/usr/lib64/libcudnn_static.a\r\n\r\n```\r\n\r\nWhile I exported both variables it is failing now at:\r\n```\r\nInvalid path to cuDNN 6 toolkit. None of the following files can be found:\r\n/usr/lib64/lib64/libcudnn.so.6\r\n/usr/lib64/libcudnn.so.6\r\n/usr/lib64/libcudnn.so.6\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \r\n```", "Ok, small update, I had to export some other variables\r\n```\r\nexport CUDNN_INSTALL_PATH=\"/usr/lib64\"\r\n\texport TF_NEED_CUDA=\"1\"\r\n\texport TF_CUDA_VERSION=\"9.0\"\r\n\texport TF_CUDNN_VERSION=\"7\"\r\n```\r\n\r\n, here is whole content from Ebuild, important is phase configure where I export related variables:\r\n```\r\n# Copyright 2017 Gentoo Foundation\r\n# Distributed under the terms of the GNU General Public License v2\r\n\r\nEAPI=5\r\nPYTHON_COMPAT=( python{2_7,3_4} pypy )\r\n\r\ninherit eutils multiprocessing distutils-r1 git-r3\r\n\r\nDESCRIPTION=\"Library for Machine Intelligence\"\r\n\r\nHOMEPAGE=\"https://www.tensorflow.org/\"\r\nSRC_URI=\"\"\r\nEGIT_REPO_URI=\"https://github.com/tensorflow/tensorflow\"\r\nEGIT_COMMIT=\"c9568f1ee51a265db4c5f017baf722b9ea5ecfbb\"\r\n\r\nLICENSE=\"Apache-2.0\"\r\nSLOT=\"0\"\r\nKEYWORDS=\"~amd64 ~arm ~hppa ~ppc ~ppc64 ~sparc ~x86 ~x86-fbsd ~amd64-linux ~x86-linux ~x86-macos\"\r\nIUSE=\"-cuda -opencl\"\r\nRESTRICT=\"primaryuri\"\r\n\r\nRDEPEND=\"\r\n\t>=dev-python/numpy-1.11.2-r1\r\n\t>=dev-python/six-1.10.0\r\n\tcuda? (\r\n          >=dev-libs/nvidia-cuda-cudnn-7.0\r\n\t  >=dev-util/nvidia-cuda-toolkit-8.0.61\r\n          >=x11-drivers/nvidia-drivers-3.78.13\r\n        )\r\n\"\r\n\r\nDEPEND=\"\r\n\tdev-python/setuptools\r\n\t>=dev-util/bazel-0.7.0[tools]\r\n\t>=dev-java/oracle-jdk-bin-1.8.0.152-r1\r\n\t>=dev-python/markdown-2.6.9\r\n\t>=dev-python/werkzeug-0.12.2\r\n\t>=dev-python/bleach-1.5.0\r\n\t>=dev-python/protobuf-python-3.4.1\r\n\t>=dev-python/pip-9.0.1-r1\r\n\t>=dev-python/wheel-0.29.0\r\n\t>=dev-lang/swig-3.0.12\r\n\t${RDEPEND}\r\n\"\r\n\r\n#src_prepare() {\r\n\t#sed -i -e 's/protobuf == 3.0.0a3/protobuf >= 2.6.0/g' \\\r\n\t#tensorflow/tools/pip_package/setup.py\r\n#}\r\n\r\nsrc_configure() {\r\n\t\r\n\texport CUDNN_INSTALL_PATH=\"/usr/lib64\"\r\n\texport TF_NEED_CUDA=\"1\"\r\n\texport TF_CUDA_VERSION=\"9.0\"\r\n\texport TF_CUDNN_VERSION=\"7\"\r\n\tyes \"\" | ./configure\r\n\r\n\tcat > CROSSTOOL << EOF\r\ntool_path {\r\n\tname: \"gcc\"\r\n\tpath: \"${CC}\"\r\n}\r\ntool_path {\r\n\tname: \"g++\"\r\n\tpath: \"${CXX}\"\r\nEOF\r\n\r\n\techo \"Will build with $(makeopts_jobs) jobs\"\r\n\r\n}\r\n\r\nsrc_compile() {\r\n\taddwrite /proc/self\r\n\t# Added from bazel ebuild.. I am blind here as I don't understand deeply bazel itself :-)\r\n\taddpredict /proc\r\n\telog \"Compile Phase - Starting\"\r\n\r\n\tlocal JAVA_HOME_DECL=\"$(java-config --print oracle-jdk-bin-1.8 | grep JAVA_HOME)\"\r\n\teval \"export $JAVA_HOME_DECL\"\r\n\r\n\t# Add /proc/self to avoid a sandbox breakage\r\n\tlocal -x SANDBOX_WRITE=\"${SANDBOX_WRITE}\"\r\n\techo \"SANDBOX_WRITE=$SANDBOX_WRITE\"\r\n\r\n\telog \"Compile Phase - SANDBOX_WRITE\"\r\n\r\n\tcat > bazelrc << EOF\r\nstartup --batch\r\nbuild --spawn_strategy=standalone --genrule_strategy=standalone\r\nbuild --jobs $(makeopts_jobs)\r\nEOF\r\n\texport BAZELRC=\"$PWD/bazelrc\"\r\n\telog \"Compile Phase - Bazel configured\"\r\n\tbazel build \\\r\n\t --spawn_strategy=standalone --genrule_strategy=standalone \\\r\n\t --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\t elog \"Compile Phase - Bazel build finished\"\r\n}\r\n\r\nsrc_install() {\r\n\telog \"Install Phase - Starting\"\r\n\tbazel-bin/tensorflow/tools/pip_package/build_pip_package \"$PWD/tensorflow_pkg\"\r\n\telog \"Install Phase - PIP package finished\"\r\n\tlocal ALFA=\"$(find /tmp/empty* -type f -exec sh -c 'echo $(basename {})' \\;)\"\r\n\tlocal TENSORFLOW_WHEEL_FILE=\"$(find $PWD/tensorflow_pkg/tensorflow* -type f -exec sh -c 'echo $(basename {})' \\;)\"\r\n\tpip install --root \"${ED}\" \"$PWD/tensorflow_pkg/$TENSORFLOW_WHEEL_FILE\"\r\n\telog \"Install Phase - PIP install finished\"\r\n\trm -rf \"${ED}\"/usr/lib*/python*/site-packages/google/protobuf\r\n\telog \"Install Phase - removal of some files\"\r\n}\r\n```\r\n\r\nAnd this works, or in minimum I was able to finish compilation and installation process with CUDA 9 and CUDNN 7, now I will do some hello world test.... "]}, {"number": 4840, "title": "retrain.py input PNG picture", "body": "Hi all, \n\nI try to change the retrain.py from jpeg to png so that I can input the png image. ( replace \"jpeg\" in the code to \"png\")\n\nbut I got the error **'Requested return_element %r not found in graph_def.' % name)\nValueError: Requested return_element 'DecodePng/contents:0' not found in graph_def.**\n\nHow to fix it ? \nI try **input_map={'DecodePng:0': decoded_png}** in **tf.import_graph_def** but **decoded_png** locate under the **create_inception_graph()** so I don't know where is the **decoded_png** to add with **\"DecodePng:0\"** \n\nthank you and regards,\nKhoa\n", "comments": ["Hi, I fixed it and it run\n\nI import Image in Python\nthen I convert PNG to JPG. You can search function **convert_png_to_jpeg**\n[retrain.txt](https://github.com/tensorflow/tensorflow/files/518028/retrain.txt)\n\nwould you mind checking it\n\nthank you and regard,\nKhoa\n", "This [StackOverflow answer](http://stackoverflow.com/a/34497833) should provide some help.\n\nBasically, you don't need to use PIL. There's an op for decoding PNG files. https://www.tensorflow.org/versions/r0.11/api_docs/python/image.html\n\nAnother thing you can do is use ImageMagick on the command line to `convert foo.png foo.jpg`.\n", "Hi!\n\n@shaolinkhoa Thanks for your code, it helped me as well.\n\nStill, @jart I would like to understand how to fix it according to the Stackoverflow answer using the tf.image.decode_png\n\nI changed the code on lines 615, 616 of add_input_distortions definition, so as to apply decode_png\nThen according to Stackoverfow I have to edit the import_graph_definition to apply the input_map\n\nThe code to change should be the following in create_inception_graph (line 249):\n\nbottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n          tf.import_graph_def(graph_def, name='', return_elements=[\n              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n              RESIZED_INPUT_TENSOR_NAME]))\n\nSo, in that case I cannot put the input map inside this definition because it will give an error that tensor is used before assignment. \n\nI guess my question might seem stupid, but as I am totally new, I would appreciate some help on how to make it work that second way.\n\nThanks in advance.. !\n", "@Dagalaki We hope you've been enjoying TensorFlow so far! I wish I could answer your question, but we try to keep this issue tracker limited to bugs and feature requests. We rely on the [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) community to provide support on using TensorFlow. I recommend redirecting your question there.\n", "Thanks @jart ! I will ask StackOverflow community\n", "hallo @Dagalaki , have you fixed the problem mit using using the tf.image.decode_png, i have the same problem as yours, if you have the answer, could you please help me, thanks"]}, {"number": 4839, "title": "R0.11", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@milanka22, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @asimshankar to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 4838, "title": "AttributeError during pip install when building from source", "body": "I was trying to build TensorFlow from source, and all went well until I was in the last step \n`sudo pip install /tmp/tensorflow-pkg/tensorflow-0.11.0rc0-py2-none-any.whl\n`\nit crashes with this error message: \n\n> Exception:\n> Traceback (most recent call last):\n>   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 209, in main\n>     status = self.run(options, args)\n>   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 317, in run\n>     requirement_set.prepare_files(finder)\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 360, in prepare_files\n>     ignore_dependencies=self.ignore_dependencies))\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 448, in _prepare_file\n>     req_to_install, finder)\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 387, in _check_skip_installed\n>     req_to_install.check_if_exists()\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_install.py\", line 1011, in check_if_exists\n>     self.req.project_name\n> AttributeError: 'Requirement' object has no attribute 'project_name'\n\nI did some search online and found that this may be due to an upstream bug and it's been happening in other projects too. Is there anyway to work around this issue? I currently can't use a pre-compiled whl because I'm using gtx1080 and CUDA8, i think the precompiled whl only supports 7.5\n\nI'm using Ubuntu 16.04, python 2.7, pip 8.1.1\n", "comments": ["It turns out all I had to do was to update pip to latest outside virtualenv. \n"]}, {"number": 4837, "title": "updates to einsum", "body": "Resolving https://github.com/tensorflow/tensorflow/issues/4722:\n-- Fix bug where output indices are expected to be in alphabetical order\n-- Add to docstring\n", "comments": ["@nikhilmishra000, thanks for your PR! By analyzing the history of the files in this pull request, we identified @lukaszkaiser to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "Einsum is not a trivial abstraction. Numpy has 900 lines of test code for einsum ([test_einsum.py](https://github.com/numpy/numpy/blob/master/numpy/core/tests/test_einsum.py)) and 100 lines of Pydoc tests ([einsumfunc.py](https://github.com/numpy/numpy/blob/master/numpy/core/einsumfunc.py)). Ideally we would just use their test cases to show that the behavior is identical. Especially if we document the function as being \"like numpy.einsum.\"\n\nThank you for the work you put into bringing einsum to TensorFlow @nikhilmishra000 and for being responsive in addressing the concerns in #4722. I just can't help but wonder if this function is more appropriate for the contrib package, since it isn't on par with numpy in terms of functionality and test comprehensiveness. What do you think @martinwicke?\n\nSee also: #4886\n", "I think it is fine in core. There's no experimentation with the interface needed, which is usually the concern. If its functionality is not a complete mirror of numpy's we have to document the differences clearly. \n\nIn this case, it should be noted that transpose doesn't work, are there other differences that are not documented yet?\n", "The docstring has been updated, and I have added some more tests.\n\nFollowing this PR, I think the outstanding differences from numpy will be that:\n- Ellipses will not be recognized. This shouldn't be too hard to implement, but I don't know that I have the bandwidth to get it done in the near future.\n- Subscripts where an axis appears more than once (example: `ii->i` computes the trace of a matrix). Adding support for this seems a little bit more involved.\n\nExceptions are raised for both of these cases.\n", "Jenkins, test this please.\n", "The previous failure in python3 was my fault (I didn't realize that passing a comparator to `sorted()` had been disallowed). Not too sure what happened on linux gpu, but it seems unrelated?\n", "Jenkins, test this please!\n"]}, {"number": 4836, "title": "ZeroMQ Operator", "body": "Currently (it seems like) the encouraged way to read data is either through the provided reader/producer ops which are not quite flexible, or through python feed_dict which is slower.\r\n\r\nIs there a plan to support something like a ZeroMQReaderOp, which keeps reading and deserializing tensors from a zmq socket and produce them? This way we can use any comfortable way to process data perhaps in an independent process, and send them through zmq for training.\r\n\r\n// UPDATE: wrote my own at https://github.com/tensorpack/zmq_ops\r\n  ", "comments": ["@ppwwyyxx Are you referring to http://zeromq.org/ or something else?\n\nCan you provide more details on the deficiencies of the reader/producer ops?  Thanks!\n", "Yes, it is one of the most widely used messaging library.\r\nI think the existing reader ops basically all assume that data eventually comes from file system - please correct me if I'm wrong about this. \r\nIf data is actually generated on the fly in training, we cannot use reader ops and have to use feed_dict. \r\n\r\nIn other words, it seems to me that the only possible ways to send data from outside into a graph, is either through file system or through feed_dict. Supporting a message interface such as zmq would be of great help.\r\n\r\nThis would be helpful for: reinforcement learning, synthetic data training, heavy data augmentation on the fly.\r\n", "@ppwwyyxx I see.\n\nIt is true that most of the provided subclasses of [tf.ReaderBase](https://www.tensorflow.org/versions/r0.11/api_docs/python/io_ops.html#ReaderBase) deal with reading data from the filesystem.  However note that the trivial [tf.IdentityReader](https://www.tensorflow.org/versions/r0.11/api_docs/python/io_ops.html#IdentityReader) is an example of a non-filesystem implementation.\n\nA natural way to add support for other data sources is to implement a subclass of `tf.ReaderBase` for that data source.  This is a simple way extend TensorFlow to support arbitrary messaging / pubsub / raw socket layers.\n\nWe welcome contributions!\n", "@mrry Is this done?", "We decided not to add the 0MQ dependency in the discussion thread on #8728. @vrv made the great suggestion that extensions like this should be developed as `tf.load_op_library()` dynamic dependencies first, in which case there's no need to add it to the mainline repository.", "FYI:\r\nhttps://github.com/PatWie/tf_zmq"]}, {"number": 4835, "title": "Branch 135521241", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @dsmilkov and @josh11b to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n", "Jenkins, test this please\n"]}, {"number": 4834, "title": "Error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list             argument types are: ({...})", "body": "Hi, when I try to build tensowflow from source on a aarch64 16.04 ubuntu, I meet this error. I have been struggling with this for several days already, but still no luck.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\n[#2143](https://github.com/tensorflow/tensorflow/issues/2143)\n[#1066](https://github.com/tensorflow/tensorflow/issues/1066#issuecomment-200580370)\n[#3786](https://github.com/tensorflow/tensorflow/issues/3786)\n[#4430](https://github.com/tensorflow/tensorflow/issues/4430)\n[#3985](https://github.com/tensorflow/tensorflow/issues/3985)\n[Errors when building tensorflow on linux](http://stackoverflow.com/questions/38585357/errors-when-building-tensorflow-on-linux)\n[](https://github.com/xman/tensorflow/commit/0cdb90d6024ead10e9dc87baf4730dc0962fde3c)\n### Environment info\n\nOperating System:\nubuntu 16.04\nLinux tegra-ubuntu 3.10.96-tegra #1 SMP PREEMPT Wed Sep 28 17:51:08 PDT 2016 aarch64 aarch64 aarch64 GNU/Linux\n\nGraphic: NVIDIA Tegra X1 (nvgpu)/integrated\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nCUDA version: 8.0\ncuDNN version; 5.1.5\ngcc version: 5.3 (also have tried 4.8, but no luck)\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n\nv0.11.0.rc0\n1. The output of `bazel version`\n\n```\nubuntu@tegra-ubuntu:~/ws/tensorflow/tensorflow$ bazel version\nBuild label: 0.3.2-2016-10-04 (@5604163)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue Oct 4 23:34:52 2016 (1475624092)\nBuild timestamp: 1475624092\nBuild timestamp as int: 1475624092\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n```\nbazel clean --expunge\n\n./configure (enable GPU support)\n\n bazel build -c opt --local_resources 1024,4.0,1.0 --verbose_failures --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n### What other attempted solutions have you tried?\n\nI have tried gcc5.3 and gcc4.8, but not work.  I also tried to add these to third_party/gpus/crosstool/CROSSTOOL:\n\n```\ncxx_flag: \"-D_MWAITXINTRIN_H_INCLUDED\"\ncxx_flag: \"-D_FORCE_INLINES\"\ncxx_flag: \"-D__STRICT_ANSI__\"\n```\n\nAnd I insert this to CROSSTOOL too:\n\n```\ncxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"\n```\n\nbut the errors are still there.\n### Logs or other output that would be helpful\n\n```\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=Eigen::half]\" \n(74): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=float]\" \n(75): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=double]\" \n(76): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=tensorflow::int32]\" \n(77): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=tensorflow::int64]\" \n(78): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=tensorflow::functor::complex64]\" \n(79): here\n\ntensorflow/core/kernels/cwise_op_gpu_select.cu.cc(46): error: no instance of constructor \"Eigen::array<T, n>::array [with T=int, n=2UL]\" matches the argument list\n            argument types are: ({...})\n          detected during instantiation of \"void tensorflow::functor::BatchSelectFunctor<tensorflow::functor::GPUDevice, T>::operator()(const tensorflow::functor::GPUDevice &, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::Matrix, tensorflow::TTypes<tensorflow::functor::base<__nv_bool, Eigen::internal::scalar_boolean_not_op<__nv_bool>, __nv_bool>::out_type, 1, Eigen::DenseIndex>::ConstVec, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix, tensorflow::TTypes<T, 1, Eigen::DenseIndex>::ConstMatrix) [with T=tensorflow::functor::complex128]\" \n(80): here\n\n7 errors detected in the compilation of \"/tmp/tmpxft_00002cb1_00000000-7_cwise_op_gpu_select.cu.cpp1.ii\".\nERROR: /home/ubuntu/ws/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:1170:1: output 'tensorflow/core/kernels/_objs/cwise_op_gpu/tensorflow/core/kernels/cwise_op_gpu_select.cu.pic.o' was not created.\nERROR: /home/ubuntu/ws/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:1170:1: not all outputs were created.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nERROR: /home/ubuntu/ws/tensorflow/tensorflow/tensorflow/tools/pip_package/BUILD:23:1 not all outputs were created.\n\n```\n", "comments": ["@gwljf What is the git commit hash?  You can retrieve it by running `git rev-parse HEAD` within the directory with your sources.\n\nAdding @rmlarsen in case he's seen similar errors from Eigen before.\n", "@tatatodd @benoitsteiner \nI have solved this. Thank you. \n\nFor any one who face this problem, please this [#851](https://github.com/tensorflow/tensorflow/issues/851)\n", "@gwljf glad to hear it!  Closing this out, but feel free to comment or file a new issue if you run into other problems.\n", "@gwljf \r\nThe referred thread is very long and there are many different issues handled. \r\nWhich solution was the solution, that helped in your case?", "Any one here could solve this error?\r\n\r\nI think there is a connection between this error and \"Eigen\" library (https://bitbucket.org/eigen/eigen)"]}, {"number": 4833, "title": "Slow IDCT used in JPEG decode", "body": "This issue is related to #4807, yet a bit distinct. Regardless of whether libjpeg or libjpeg-turbo is used, I was wondering if there was a reason to choose the slow but more accurate variant of IDCT in libjpeg ([code link](https://github.com/tensorflow/tensorflow/blob/6b1d4fd8090d44d20fdadabf06f1a9b178c3d80c/tensorflow/core/lib/jpeg/jpeg_mem.cc#L143)). For human image viewing pleasure, accuracy may matter, but I was wondering if for model training, the decision was made to use the slower IDCT because that improved model convergence? In case the training is immune to using the faster but less accurate IDCT, it may be worth changing the default. Has anyone done any studies as to the trained model impact of the faster IDCT? From a performance point of view, I'm getting a significant performance gain (2x GTX 1080, 6-core high-clock Core i7, 500 MB/s SSD), around 20% for AlexNet against precomputed ImageNet AlexNet may be more CPU bound for decode since the network passes themselves are relatively cheap, so maybe the gains for Inception v3 or ResNet would be less, but they would still likely be significant.\n", "comments": ["@mkolod Thanks for another interesting point.  These are good areas to investigate wrt runtime performance!\n\nI don't know of any studies of setting JDCT_IFAST, either wrt runtime performance or model accuracy.\n\nAs before, @prb12 and @poxvoculi might be interested.\n", "Interesting ... when training models for real (i.e. where time-to-accuracy is often more important than step-time), people often deliberately introduce noise and random distortions after decoding the image, so I can't imagine this would hurt!\n", "Choosing for JPEG is already a choice for lossy compression, so flipping the toggle makes sense.\n", "I made the fast IDCT the default in febdc1d13576a28382122e718bc8ab22ba9e6a45"]}, {"number": 4832, "title": "Android Demo build error", "body": "The error I saw is as follows, don't quit know how this permission error occurs\n\n```\nERROR: /home/toxido/.cache/bazel/_bazel_root/e7444205eb7a78f2fb0f6da55e24d78b/external/androidsdk/BUILD:5:1: Executing genrule @androidsdk//:aapt_runner failed: linux-sandbox failed: error executing command /home/toxido/.cache/bazel/_bazel_root/e7444205eb7a78f2fb0f6da55e24d78b/execroot/tensorflow/_bin/linux-sandbox ... (remaining 5 argument(s) skipped).\nsrc/main/tools/linux-sandbox-pid1.cc:233: \"mount(/, /home/toxido/.cache/bazel/_bazel_root/e7444205eb7a78f2fb0f6da55e24d78b/bazel-sandbox/28d014be-3643-4295-b588-2ed7789511a4-1/tmp, NULL, MS_BIND | MS_REC, NULL)\": Permission denied\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n```\n", "comments": ["@ToxidoLiu Please fill out the following information, which was the default template when you clicked on the green \"New issue\" button.  Also include the exact command-line that you ran, that causes the error.\n\n---\n\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n### What other attempted solutions have you tried?\n\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "@tatatodd\nOS & Environment : Ubuntu 16.04 LTS , Android Studio v2.2\ntensorflow version : 0.8.0\nbazel version: 0.3.2\nAndroid SDK version: 24.0.3\nNDK version: 13.0.3315539\n\nThe above error occured when I tried to do\n`$ bazel build //tensorflow/examples/android:tensorflow_demo`\nas instructed here:\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\nand I did `$ sudo bazel build //tensorflow/examples/android:tensorflow_demo` as well\n\nThanks!\n", "@ToxidoLiu Please try the latest version of TensorFlow 0.11, since 0.8 is quite old at this point:\nhttps://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#download-and-setup\n", "@toxidoliu Have you checked that relevant binaries all have the execute bit set? If you're still having issues after you upgrade TF can you paste the error log running with --verbose_failures?\n", "Closing automatically due to lack of recent activity. Please reopen when further information becomes available. Thank you.\n"]}, {"number": 4831, "title": "Branch 135436451", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @dsmilkov and @josh11b to be potential reviewers.\n"]}, {"number": 4830, "title": "tensorboard produces a lot of IOError", "body": "Hi, I'm using the tensorboard comes with 0.11rc.0 and it outputs a lot of warning on IOError for not being able to find file or directory, e.g. /path/to/tensorflow/tensorboard/paper-item/all-imports.html. I checked the directory and there are indeed no such files. The board still runs but wonder if we can get rid of the warnings. My python env is anaconda 2.7.\n", "comments": ["@flyfj is this causing an actual problem, or is it just a matter of cleanliness?\n\n@danmane might have some thoughts on this.\n", "the board itself seems to work (not sure if it's showing the correct thing), but looking at all the warning is just weird. Do other people encounter this issue?\n", "@flyfj Can you copy+paste in the exact IOErrors you're getting?\n", "WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js\n127.0.0.1 - - [12/Oct/2016 16:05:01] \"GET /lodash/lodash.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/all-imports.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/all-imports.html\n127.0.0.1 - - [12/Oct/2016 16:05:01] \"GET /paper-item/all-imports.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/iron-list/iron-list.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/iron-list/iron-list.html\n127.0.0.1 - - [12/Oct/2016 16:05:01] \"GET /iron-list/iron-list.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-icon-item.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-icon-item.html\n127.0.0.1 - - [12/Oct/2016 16:05:01] \"GET /paper-item/paper-icon-item.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-item-body.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-item-body.html\n127.0.0.1 - - [12/Oct/2016 16:05:01] \"GET /paper-item/paper-item-body.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /graphlib/dist/graphlib.core.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-group/paper-radio-group.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-group/paper-radio-group.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-radio-group/paper-radio-group.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tooltip/paper-tooltip.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tooltip/paper-tooltip.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-tooltip/paper-tooltip.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/iron-list/iron-list.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/iron-list/iron-list.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /iron-list/iron-list.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/all-imports.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/all-imports.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-item/all-imports.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-button/paper-radio-button.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-button/paper-radio-button.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-radio-button/paper-radio-button.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-item-body.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-item-body.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-item/paper-item-body.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-icon-item.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-item/paper-icon-item.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-item/paper-icon-item.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tooltip/paper-tooltip.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tooltip/paper-tooltip.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-tooltip/paper-tooltip.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-group/paper-radio-group.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-group/paper-radio-group.html\n127.0.0.1 - - [12/Oct/2016 16:05:02] \"GET /paper-radio-group/paper-radio-group.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-button/paper-radio-button.html' on path /home/jiefeng/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/paper-radio-button/paper-radio-button.html\n\nHere is part of the outputs @danmane \nthe tensorboard page initially shows nothing, after a while if i reload, it starts to show the data.\n", "How are you running TensorBoard?\n", "Same here. I built TF r0.11 from source to make wheel file, and installed by (user level) PIP. (so, `$ whereis tensorboard` returns `/home/leebc/.local/bin/tensorboard`)\nWhen I run tensorboard by `$ tensorboard --logdir=/tmp/tensorboard`, I get these logs:\n\n```\n127.0.0.1 - - [13/Oct/2016 09:17:07] \"GET / HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/webcomponentsjs/webcomponents-lite.min.js' on path /home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/webcomponentsjs/webcomponents-lite.min.js\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/dist/bazel-html-imports.html' on path /home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/dist/bazel-html-imports.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/external/dist/bazel-html-imports.html' on path /home/leebc/.local/lib/python3.5/site-packages/external/dist/bazel-html-imports.html\n127.0.0.1 - - [13/Oct/2016 09:17:07] code 404, message Not Found\n127.0.0.1 - - [13/Oct/2016 09:17:07] \"GET /webcomponentsjs/webcomponents-lite.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [13/Oct/2016 09:17:07] \"GET /dist/tf-tensorboard.html HTTP/1.1\" 200 -\n127.0.0.1 - - [13/Oct/2016 09:17:07] \"GET /lib/css/global.css HTTP/1.1\" 200 -\n127.0.0.1 - - [13/Oct/2016 09:17:07] \"GET /dist/bazel-html-imports.html HTTP/1.1\" 404 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-checkbox/paper-checkbox.html' on path /home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-checkbox/paper-checkbox.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-tabs/paper-tabs.html' on path /home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-tabs/paper-tabs.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-dialog/paper-dialog.html' on path /home/leebc/.local/lib/python3.5/site-packages/tensorflow/tensorboard/paper-dialog/paper-dialog.html\n```\n", "@jart just like what @bc-lee did: tensorboard --logdir=/path/to/log\n", "Same here. A lot of IOErrors and tinsted of graph I see a black rectangle in the browser. \nA lot of html and js files are missing in the tensorboard folder.\nUbuntu 14.04.5 LTS, python 2.7.11\nTensorflow v. 0.11.0rc0 installed from pip.\n\n```\n127.0.0.1 - - [13/Oct/2016 15:35:10] \"GET / HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/webcomponentsjs/webcomponents-lite.min.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/webcomponentsjs/webcomponents-lite.min.js\n127.0.0.1 - - [13/Oct/2016 15:35:10] \"GET /webcomponentsjs/webcomponents-lite.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [13/Oct/2016 15:35:10] \"GET /lib/css/global.css HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/dist/bazel-html-imports.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/dist/bazel-html-imports.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/external/dist/bazel-html-imports.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/external/dist/bazel-html-imports.html\n127.0.0.1 - - [13/Oct/2016 15:35:10] code 404, message Not Found\n127.0.0.1 - - [13/Oct/2016 15:35:10] \"GET /dist/bazel-html-imports.html HTTP/1.1\" 404 -\n127.0.0.1 - - [13/Oct/2016 15:35:10] \"GET /dist/tf-tensorboard.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/polymer/polymer.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/polymer/polymer.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-icons/iron-icons.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-icons/iron-icons.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tabs/paper-tabs.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-tabs/paper-tabs.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-dialog/paper-dialog.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-dialog/paper-dialog.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-checkbox/paper-checkbox.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-checkbox/paper-checkbox.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-toolbar/paper-toolbar.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/paper-toolbar/paper-toolbar.html\n```\n\n```\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /neon-animation/web-animations.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/neon-animation/animations/opaque-animation.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/neon-animation/animations/opaque-animation.html\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-fit-behavior/iron-fit-behavior.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-fit-behavior/iron-fit-behavior.html\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /neon-animation/animations/opaque-animation.html HTTP/1.1\" 200 -\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /iron-fit-behavior/iron-fit-behavior.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-overlay-behavior/iron-overlay-manager.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-overlay-behavior/iron-overlay-manager.html\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /iron-overlay-behavior/iron-overlay-manager.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-dropdown/iron-dropdown-scroll-manager.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-dropdown/iron-dropdown-scroll-manager.html\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /iron-dropdown/iron-dropdown-scroll-manager.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-overlay-behavior/iron-overlay-backdrop.html' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/iron-overlay-behavior/iron-overlay-backdrop.html\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /iron-overlay-behavior/iron-overlay-backdrop.html HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/web-animations-js/web-animations-next-lite.min.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/web-animations-js/web-animations-next-lite.min.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /web-animations-js/web-animations-next-lite.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /lodash/lodash.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/d3/d3.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/d3/d3.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /d3/d3.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/plottable/plottable.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/plottable/plottable.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /plottable/plottable.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /lodash/lodash.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js\n127.0.0.1 - - [13/Oct/2016 15:35:11] \"GET /graphlib/dist/graphlib.core.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/dagre/dist/dagre.core.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/dagre/dist/dagre.core.js\n127.0.0.1 - - [13/Oct/2016 15:35:12] \"GET /dagre/dist/dagre.core.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/lodash/lodash.min.js\n127.0.0.1 - - [13/Oct/2016 15:35:12] \"GET /lodash/lodash.min.js HTTP/1.1\" 200 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js' on path /export/home/asanakoy/.venvs/tf/local/lib/python2.7/site-packages/tensorflow/tensorboard/graphlib/dist/graphlib.core.js\n\n```\n", "Hi,\n\nWe just resolved this internally. Should see the fix at master within 1-2 days.\n\nThanks for letting us know!\n", "@dsmilkov awesome, thanks! will the official binary be updated?\n", "Not the current binary, but 0.11 RC1 will have the patch!\n", "@dsmilkov I just installed 0.11 RC1 but the error is still there. When I try to load an 'events.out.tfevents' file, nothing appears on localhost:6006. Tried on Chrome and Firefox, both don't work.\n", "My experience is if you reload the page multiple times, the data will show up regardless of all the warning/error it produces in the command line. Hopefully it can be fixed in the next patch.\n", "@flyfj refreshing the page does not work for me.\n", "@jkschin Try to use Chromium browser. Didn't work for me in firefox, but works in Chromium.\n", "@jkschin Do you get the same IOErrors just like the other users (logs pasted above)? What browser are you using?\n\nIf the issue you are seeing looks unrelated to the issue of TensorBoard producing a lot of IOErrors, feel free to file another issue regarding your problem.\n\nThanks!\n", "It's not an IOError. Filed new issue here #5341\n"]}, {"number": 4829, "title": "TensorBoard logdir assignment issue", "body": "Dear all,\nAs instructed I type\n`$tensorboard --logdir=/tmp/tensorflowlogs --debug`\nbut the debug message showing that the tensorboard logdir is still in my working dir.\n`INFO:tensorflow:TensorBoard path_to_run is: {'/home/USER_NAME/Documents/workspace/python_dir/tensor_test/=': None}\n`\nHowever after I deleted the \"=\" sign and replace it with a space\n`$tensorboard --logdir /tmp/tensorflowlogs --debug`\n\nthe debug message show the right direcory\n`INFO:tensorflow:TensorBoard path_to_run is: {'/tmp/tensorflowlogs': None}\n`\nI don't know its a typo or something in the instruction.\n\nSo just FYI\n", "comments": ["@ToxidoLiu When you say \"As instructed I type $tensorboard...\", what are you referring to?  Can you provide a link to the documentation that you're following?\n\nThat'll help us identify if there is a problem, and fix it up if so.  Thanks!\n", "@tatatodd\nI check the instruction in the following link, first section\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#my-tensorboard-isnt-showing-any-data-whats-wrong\n\nThanks!\n", "@ToxidoLiu I cannot reproduce your problem.  Can you provide the following information, which is also the default template when you click on the green \"New issue\" button:\n\n---\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n", "@ToxidoLiu based on #4832 I'm assuming you're running TensorFlow version 0.8.  Please try the latest version of TensorFlow 0.11, since 0.8 is quite old at this point:\nhttps://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#download-and-setup\n", "Closing due to inactivity.\n"]}, {"number": 4828, "title": "PIP install OS X, requirement to install", "body": "Today I tried to install TensorFlow on my MacBook pro following the guidelines on [tensorflow.org](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#installing-from-sources).\n\nOperating System: OS X 10.11.6\nPip: 8.1.2 (python 3.5)\nMy MBP doesn't have an actual GPU so I tried using the CPU only version: [link](https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc0-py3-none-any.whl)\n\nWhen trying to run `sudo -H pip3.5 install --upgrade $TG_BINARY_URL`\nPip logged `You must give at least one requirement to install (see \"pip help install\")`\n\nI'm pretty new to pip, is there something obvious that I'm missing ?\n", "comments": ["@Hnri that error indicates that the TF_BINARY_URL bash variable is empty.  The pip-install instructions are here:\nhttps://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#pip-installation\n\nSpecifically, you're supposed to run these two lines:\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc0-py3-none-any.whl\n\nsudo pip3 install --upgrade $TF_BINARY_URL\n```\n\nThe first line exports the TF_BINARY_URL variable, while the second line does the pip install.\n\nClosing this out, since I believe that should fix your problem.  If not just comment on this issue.  Thanks!\n", "That worked like magic, thank you!\n", "tanx\r\n"]}, {"number": 4827, "title": "Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: :/usr/local/cuda-7.5/lib64", "body": "I have a system where I installed CUDA 7.5 for TensorFlow 0.10.0. The specs of my system is written in #4825 . However, I have a small problem when importing `tensorflow` in my Python 3.5.2\n\nScreenshot of the problem.\n\n![screenshot from 2016-10-08 01-11-11](https://cloud.githubusercontent.com/assets/11130276/19199007/8a0a861c-8cf4-11e6-8155-6a71ff932947.png)\n\nAny help would be great!\n", "comments": ["@AFAgarap For future note, please cut-and-paste text into your issues, rather than attaching screenshots.\n\nPlease answer the following question:\n\n---\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n---\n\nAlso note that the following two errors seem to indicate a mix-up between cuda 7.5 and 8.0:\n\n`/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link`\n`Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: :/usr/local/cuda-7.5/lib64`\n", "@tatatodd Yes, I do have cuda 8.0 installed. I installed 7.5 when I couldn't get 8.0 to work cor TensorFlow. \n", "Output of `ls -l /usr/local/cuda-7.5/lib/libcud*`:\n\n```\n-rw-r--r-- 1 root root 189170 Oct  8 00:30 /usr/local/cuda-7.5/lib/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Oct  8 00:30 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Oct  8 00:30 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 311596 Oct  8 00:30 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 558020 Oct  8 00:30 /usr/local/cuda-7.5/lib/libcudart_static.a\n```\n", "I already removed CUDA 8.0 by `sudo -r /usr/local/cuda-8.0` but the same error persists.\n", "Am good with this already. I reinstalled CUDA 7.5 and cuDNN. I have a new problem though #4841 \n", "I've a similar problem for CUDA 8.0(latest version) also. The following is my error output when I doing a simple test on my newly installed environment:\r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\n", "@clockzhong Did you try reinstalling CUDA? What's the version of your TensorFlow? Did you upgrade to the latest version?", "@AFAgarap I'm very sorry, it seems my mistake. I mixed the CUDA library with CUDNN library. I need install both of them. Thanks for your reply, I'll correct this mistake soon.\r\n\r\n@AFAgarap, Yes, I confirmed it's my mistake. After I installed cudnn-8.0-linux-x64-v5.1.tgz in my environment. It's fixed. Thanks for your help. The following is my test log:\r\n\r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n>>> \r\n", "Oh, good. Glad to help. :) ", "@clockzhong  Hi, I met the same problem. How did you solve that problem? Just reinstall the CUDA and CUDnn?  Thanks a lot", "@terminator9487 \r\nYes, I've not installed CUDnn library. So what I did is just installing both CUDA and CUDnn. They are different libraries, and you also need pay special attention on their versions also. \r\nIt's really a pity that they haven't provided a complete package to setup the tensorflow working environment. \r\nI think the tensorflow, CUDA, and CUDnn fast development pacing is the reason that they couldn't provide one complete package. These 3 packages developers just keep updating to their latest version in their own developing environment. But any version mismatch or package missing will cause us facing problems. The situation will be better when these 3 packages become stable.\r\n", "I just had this exact same problem. I had to use the above advice and found my libcuda directory with this lost shared object, and in my case I ran:\r\n\r\n```bash\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64/\r\n```\r\n\r\n...and then everything worked for me when I ran my Tensorflow script in `python3.6` . This was with  `cuda-8.0` however -- I was pointing to a symlink for my environment variable.", "@abomm \r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64/\r\nIt works for me. With CUDA Toolkit 11.2, Tensorflow 2.4.1, cuDNN 11.1 and Python 3.8."]}, {"number": 4826, "title": "Better support for initializing without explicit initializer(issue#4419)", "body": "When using `tf.get_variable(name='foo', shape=(42,), dtype=tf.int32)` without explicit initializer, it causes the error:\r\n\r\n```\r\nTypeError: Expected int32, got -1.7320508075688772 of type 'float' instead.\r\n```\r\n\r\nThe reason is as follows:\r\nIf no initializer provided, it would use the default initializer `uniform_unit_scaling_initializer` which just fit with `float`(notice that sqrt(3)==1.7320...). While, it always conflict with the required integer dtype.\r\n\r\nThe current solution is initialize the integer by `init_ops.zeros_initializer` when no initializer provided.\r\n\r\nreference the [issus#4419](https://github.com/tensorflow/tensorflow/issues/4419)\r\n", "comments": ["Can one of the admins verify this patch?\n", "@DjangoPeng, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo, @theweiho and @keveman to be potential reviewers.\n", "Perhaps we should just throw a cleaner error?  Initializer should be explicit imo\n", "Nevermind. That's not backwards compatible.\n", "@ebrevdo But I think Tensorflow should provide the default initializer for integer, such as float. And in many platform and language, they have the build-in mechanism to handle the case \n", "@rohan100jain I have updated and it can support for all dtypes including partitioned variables. When I define the function `_get_default_initializer()`, I found it's hard to cover `qint and bfloat` dtype. So I want to open a new PR to handle that, cause I think the fixed size dtype is a little different from the other dtypes. \n\n## Change log\uff1a\n\n### variable_scope.py\n- Add a function called `_get_default_initializer()` handling variables when no initializer provided.\n- It both works for single variable and partitioned variables, so you can find there are two calls, one in `_get_single_variable()`, another in `_get_partitioned_variable()`\n\n### variable_scope_test.py\n- Add two class for testing single variable and partitioned variables.\n- According to dtype, I divided initializer into `strings_initializer` and `zeros_initializer`.\n\n### array_ops.py\n- Add `strings()` for `tf.string` to set all elements to ''(empty string) of a tensor\n\n### init_ops.py\n- Add `strings_initializer()` for `tf.string` calling to `array_ops.strings()`. The definitions are similar to  the `init_ops.zeros_initializer()` and `array_ops.zeros()`.\n\n### dtypes.py\n- Add `is_bool()` and `is_string()` function for condition judgement in `_get_default_initializer`\n- Adjust the definitions by alphabetical order \n\n### Supported dtype list\n- tf.float16\n- tf.float32\n- tf.float64\n- tf.int8\n- tf.uint8\n- tf.int16\n- tf.uint16\n- tf.int32\n- tf.int64\n- tf.bool\n- tf.complex64\n- tf.complex128\n- tf.string \n", "@lukaszkaiser @rohan100jain @ebrevdo, @theweiho @keveman  Can one of you review the PR?\n", "Please send a separate PR for tf.string, I think I'm not the best person to\nreview that (maybe andrew selle)\n\nOn Sun, Oct 16, 2016 at 7:50 PM, Jingtian Peng notifications@github.com\nwrote:\n\n> ## _@DjangoPeng_ commented on this pull request.\n> \n> In tensorflow/python/ops/variable_scope.py\n> https://github.com/tensorflow/tensorflow/pull/4826:\n> \n> > -  def _get_default_initializer(self, shape=None, dtype=dtypes.float32):\n> > -    \"\"\"Use this function to provide a default and corresponding initializer of dtype\n> >   +\n> > -    Args:\n> > -      dtype: Type of the new or existing variable.(defaults to `DT_FLOAT`).\n> >   +\n> > -    Returns:\n> > -      initializer and initializing_from_value. See documentation of get_variable above.\n> >   +\n> > -    Raises:\n> > -      TypeError: When giving unsupported dtype.\n> > -    \"\"\"\n> > -    if dtype.is_floating:\n> > -      initializer = init_ops.uniform_unit_scaling_initializer()\n> > -      initializing_from_value = False\n> > -    elif dtype.is_string:\n> \n> I think tf.string is the same issue regarding initialization, so put them\n> in one PR. If you insist that they are different, I can split them to\n> reopen a PR for tf.string\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4826, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim7-wfbJPfieTsVgHcWnFT8H8svPGks5q0uKGgaJpZM4KRMaa\n> .\n", "@ebrevdo Please review..\n", "Jenkins, test this please.\n", "@drpngx @ebrevdo It seems like everything goes well. \u2299\u25bd\u2299\n", "Did you address all changes?\n", "yep\uff0cincluding necessary comments\n", "More comments.\n", "@ebrevdo Could you review and merge this PR, please?\n", "A mistake of closing the PR.\n", "Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "@ebrevdo Can you  test the change and review?\n", "@ebrevdo @drpngx  I revert all commits before and add more informative comments. Then I re-pushed the branch. Now, it would be better to review and merge. \n\n## Change log:\n\n### dtypes.py\n\nAdd `is_bool()`  function for `if` judgement in `_get_default_initializer`. And `DT_BOOL` can use `zeros_initializer` to initialize with `FALSE`, so I combine it with `DT_INT` and `DT_UINT` to avoid duplicating code block.\n\n### variable_scope.py\n\nAdd `_get_default_initializer()` private function to provide a default initializer and a corresponding value when no explicit initializer provided. Now, it can handle `DT_FLOAT/DT_INT/DT_UINT/DT_BOOL`. In other dtype case, it would raise a `ValueError` with info `\"An initializer for variable %s is required\" % name`.\n\n### variable_scope_test.py\n\nAdd `testInitFromNonInitializer()` for single_variable and partitioned_variable.\n", "@vrv Please review.\n", "Running a test but going to let @ebrevdo and @rohan100jain give the final approval.\n\n@tensorflow-jenkins test this please\n", "@vrv It seems like there are some internal errors? \n", "@tensorflow-jenkins test this please\n", "@rohan100jain @ebrevdo does this look good?  I ca merge if so.\n", "@ebrevdo @rohan100jain @vrv @drpngx Can one of you verify the patch? \n", "@DjangoPeng What's the status here - should I poke rohan/ebrevdo to re-review?\r\nAlso, it now has conflicts, so you will need to rebase.", "@danmane I think it's ready to merge, and I will rebase it after work today. I hope them can accept the PR, which is helpful from my perspective.", "once you merge we can run a test.", "@danmane @ebrevdo I have solved the conflict and update `tf.global_variables_initializer()` API. Please check and test.", "Jenkins, test this please.", "@ebrevdo @drpngx @danmane It looks everything goes well, would you mind merging it?"]}, {"number": 4825, "title": "Failure to install from source", "body": "So, I have installed TensorFlow 0.10.0 using `pip3`. I have Python 3.5.2 GCC 5.4.0. And am running it on Ubuntu 16.04 LTS (x64) with the following specifications:\n\n<ul>\n<li>CPU: Intel Core i5-6300HQ 2.3GHz-3.2GHz</li>\n<li>RAM: 8GB DDR3 1600MHz</li>\n<li>GPU: NVidia GeForce GTX 960M DDR5 4GB</li>\n<li>1 TB Hybrid HD + 8GB Cache</li>\n</ul>\n\n\nWhen I'm trying to install `tensorflow` from source, i.e. `git clone https://github.com/tensorflow/tensorflow`, `cd tensorflow`, and `bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`. It gives me the following error:\n\n![screenshot from 2016-10-07 23-56-18](https://cloud.githubusercontent.com/assets/11130276/19196833/af667cdc-8ce9-11e6-82a2-eda8c620651e.png)\n\nEven if I use `sudo`, the same error arises. I want to use `tensorflow` with GPU enabled in my system. Any help would be much appreciated. Thanks!\n", "comments": ["I am using `bazel 0.3.1` btw.\n"]}, {"number": 4824, "title": "Branch 135477243", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @dsmilkov and @josh11b to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 4823, "title": "Tensorflow not using GPU (according to TensorBoard)", "body": "GTX 1070, ubuntu 16.04.\n\nI am retraining [inception](https://github.com/tensorflow/models/tree/master/inception) model on my own data. Everything is fine until the final command :\n\n```\nbazel-bin/inception/flowers_train \\\n  --config=cuda \\\n  --train_dir=\"${TRAIN_DIR}\" \\\n  --data_dir=\"${OUTPUT_DIRECTORY}\" \\\n  --pretrained_model_checkpoint_path=\"${MODEL_PATH}\" \\\n  --fine_tune=True \\\n  --initial_learning_rate=0.001 \\\n  --input_queue_memory_factor=1\n```\n\nAccording to the logs, **Tensorflow seems to be using the GPU** :\n\n```\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7715\npciBusID 0000:03:00.0\nTotal memory: 7.92GiB\nFree memory: 7.77GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:03:00.0)\n```\n\nBut when I am checking the learning in TensorBoard, **the net is using mainly the CPU** (blue /device:CPU:0, green /device:GPU:0):\n\nTensorBoard graph:\n\n![graph](https://cloud.githubusercontent.com/assets/4989990/19196523/33a2e6c2-8cb6-11e6-85b1-1f35950657e3.png)\n\nI have tried this two TensorFlow setups :\n1. Install from the source (3b75eb34ea2c4982fb80843be089f02d430faade) with nvidia-367 drivers, CUDA8 8.0, cuDNN\n   v5,    source from the master (16/10/06 - r11?). compiled for GPU\n   use:\n   \n   ```\n   bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n   bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu    \n   bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n   ```\n2. docker GPU image of Tensorflow on a PC with a GTX\n   1070 8Go\n   \n   ```\n   nvidia-docker run -it -p 8888:8888 -p 6006:6006 gcr.io/tensorflow/tensorflow:latest-gpu /bin/bash\n   ```\n\nAccording to the doc Cuda >=7.0 can be used when installed from sources. \n\n> The GPU version works best with Cuda Toolkit 7.5 and cuDNN v5. Other versions are supported (Cuda toolkit >= 7.0 and cuDNN >= v3) only when installing from sources\n\nAnd the dockerfile begins with `FROM nvidia/cuda:7.5-cudnn5-devel`. So it is not using cuda and cudnn of the host system\n", "comments": ["@seeb0h is there a specific problem that you're running into as a result?  Or are you just wondering why the picture seems to show more blue (cpu) than green (gpu)?\n\nI'm not an expert on tensorboard visualization, or the inception model.  But isn't the inception 'tower' where the bulk of the work is being performed?  So even though it's only a small portion of the total picture, it might account for the majority of the actual work.\n\n@dsmilkov probably knows more about this.\n", "Yes, exactly. I was wondering why the picture seems to show more blue (cpu) than green (gpu).\n\nI haven't study that much the inception model and didn't know 'tower' was the main deal. So everything could be perfectly fine. \nIf it is, sorry for your wasted time...\n", "Ok. Still something weird. \nRunning `watch nvidia-smi` gives :\n\n```\nMon Oct 10 10:31:04 2016\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1070    Off  | 0000:03:00.0      On |                  N/A |\n| 29%   57C    P2    41W / 230W |   7806MiB /  8113MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1082    G   /usr/lib/xorg/Xorg                              69MiB |\n|    0      3082    C   /usr/bin/python                               7729MiB |\n+-----------------------------------------------------------------------------+\n\n```\n\nWhile top gives : \n\n```\n  PID UTIL.     PR  NI    VIRT    RES    SHR S  %CPU %MEM    TEMPS+ COM.\n 3082 root      20   0 26,739g 3,469g 1,657g S 101,3 59,7   7254:50 python\n```\n\nGPU seems to be ignored...\n", "@seeb0h tower_0 is the namespace that holds the GPU ops. If you expand it, you will probably see that tower_0 contains conv_0,1,2... nodes as well which correspond to the actual convolution operations, whereas the external conv_0,1,2... nodes correspond to variables holding the weights of that convolution and variables are always allocated to the CPU.\n\nI will close this bug for now, but feel free to reopen if you have any other concerns.\n\nThanks!\n", "Ok. And I was running tensorflow from a docker image. It seems `watch nvidia-smi` is not reliable in this case.\n\nSo everything works flawlessly \n"]}]