[{"number": 45307, "title": "Extract a function for parsing operator FILL", "body": "Extract the parsing out of a switch statement case to create a\r\nstandalone function which can be called by the micro op resolver.\r\n\r\nThis PR is part of the work to port operator FILL from lite to micro,\r\nas tracked in #45306.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45307) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "Note that this PR was automatically rolled back with 2b0d8f5bdcf28639e75c07d0cb0494754cb760c8. We're working on fixing the issue but might take a day or so to get sorted out.\r\n\r\nPlease work off a commit before 2b0d8f5bdcf28639e75c07d0cb0494754cb760c8 in the interim.", "The modifications from this PR are restored with https://github.com/tensorflow/tensorflow/commit/005cab3999626252e3a2af5a10c977a5227f0d02"]}, {"number": 45306, "title": "micro: port op FILL from lite", "body": "@tensorflow/micro\r\n\r\nThis issue tracks my work porting operator FILL from lite to micro.\r\n\r\nThe port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:\r\n\r\n- PR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver\r\n- PR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences\r\n- PR 3: Copy operator from lite to micro without making any changes or including in the build\r\n- PR 4: Delete extra code from the micro copy of the operator\r\n- PR 5: Port micro copy of operator as necessary and add a corresponding test\r\n\r\n", "comments": ["Finished by PR #45647 in 3eacc397.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45306\">No</a>\n"]}, {"number": 45305, "title": "Tensorflow 2.3 Conversion to .tflite fails if last layer is Reshape (tf.keras.functional API)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 or Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: 3.6 or 3.7\r\n\r\n**Describe the current behavior**\r\nI made an easily reproducible example in this notebook\r\nhttps://colab.research.google.com/drive/12Wj60KVP-cMxteiZXdZRmSxJaPX37D4c?usp=sharing\r\n\r\nI'm currently porting my framework for ML on the edge, aXeleRate to tf.keras. You can find the code for converters here\r\nhttps://github.com/AIWintermuteAI/aXeleRate/blob/8e66a39dadb469998a62c365c37c39984b30de4d/axelerate/networks/common_utils/convert.py#L180\r\n\r\nCurrently the issue is that when converting Keras model to .tflite, if last layer of the model is Reshape, the conversion fails silently. It doesn't output any errors, but the resulting model is not usable by Coral Edge TPU converter and also is deipalyed as wrong file type in Ubuntu, see the screenshot:\r\n![Screenshot from 2020-12-02 01-27-06](https://user-images.githubusercontent.com/32562299/100774882-8ab99680-343d-11eb-972a-99188a0247d8.png)\r\nThis conversion works fine with Tensorflow 1.15. I think I can make it work by using old converter, but I'd like to report the issue regardless, in case it affects other users.\r\n\r\n**Describe the expected behavior**\r\nKeras model converting properly to .tflite format regardless of last layer used in the model.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/12Wj60KVP-cMxteiZXdZRmSxJaPX37D4c?usp=sharing\r\n\r\nFor converter code, refer to \r\nhttps://github.com/AIWintermuteAI/aXeleRate/blob/8e66a39dadb469998a62c365c37c39984b30de4d/axelerate/networks/common_utils/convert.py#L180\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nPossibly has relation to\r\nhttps://stackoverflow.com/questions/62783988/reshape-cc55-stretch-dim-1-node-number-x-reshape-failed-to-prepare", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/158b722b71285b42608f3fc1eb89a598/45305.ipynb).\r\n\r\n\r\nRunning with [TF v1.15](https://colab.research.google.com/gist/amahendrakar/4686c65d5f46c60cac2e98dd6ce9b801/45305-1-15.ipynb#scrollTo=awR7r4ILzrmb) throws an error stating `AttributeError: type object 'TFLiteConverter' has no attribute 'from_keras_model'`.\r\n\r\nWhereas, running with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/3c110d7a4935dcaf96cecef1aeec2326/45305-tf-nightly.ipynb#scrollTo=y07yAbYbjV2s) throws the error `AttributeError: module 'tensorflow' has no attribute 'python'`. Please check the linked gist for reference. Thanks!", "Hi! You've encountered issues different from the one I described:\r\nin tf 1.15 there is no from_keras_model method of TFLiteConverter - instead from_keras_model _file should be used with Keras model file as argument. Then conversion should work with Keras 2.3 and Tensorflow 1.15.\r\nI have not yet tried tf-nightly, but module 'tensorflow' has no attribute 'python' likely points to \r\nimport tensorflow.python.keras.backend as k\r\nhere\r\nhttps://github.com/AIWintermuteAI/aXeleRate/blob/8e66a39dadb469998a62c365c37c39984b30de4d/axelerate/networks/common_utils/convert.py#L2", "Re-open the issue if it's still not fixed. It looks like the model gets generated without a Reshape in the last layer using TF 2.4.0. Could you verify if this is the case for you?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45305\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45305\">No</a>\n"]}, {"number": 45304, "title": "[Intel-MKL] Supporting quantized pooling op for signed 8 bit", "body": "Maxpool and average pool supports unsigned 8 bit quantization. But, for some models using Intel MKL quantization, we need to use signed 8 bit. Here, we are supporting signed 8 bit quantization. ", "comments": ["Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 45303, "title": "KeyError: \"The name 'import/final_result' refers to an Operation not in the graph.\"", "body": "Traceback (most recent call last):\r\n  File \"D:/xcr/human-action-classification-master/human-action-classification-master/run_webcam.py\", line 65, in <module>\r\n    pose_class = label_img.classify(image)\r\n  File \"D:\\xcr\\human-action-classification-master\\human-action-classification-master\\scripts\\label_image.py\", line 99, in classify\r\n    output_operation = graph.get_operation_by_name(output_name)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3606, in get_operation_by_name\r\n    return self.as_graph_element(name, allow_tensor=False, allow_operation=True)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3478, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3538, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'import/final_result' refers to an Operation not in the graph.\"", "comments": ["@shaowujie,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Hi there,\r\n\r\nI have generated the same error:\r\n\r\n2022-01-15 13:02:21.671933: W tensorflow/core/framework/op_def_util.cc:355] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\nTraceback (most recent call last):\r\n  File \"run_image.py\", line 51, in <module>\r\n    scene_class = label_img_scene.classify(args.image)\r\n  File \"C:\\Users\\libby\\Documents\\Python\\new-human-action-classification-g\\human-action-classification-g\\scripts\\label_image_scene.py\", line 87, in classify\r\n    output_operation = graph.get_operation_by_name(output_name);\r\n  File \"C:\\Users\\libby\\Anaconda3\\envs\\action-classification\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3606, in get_operation_by_name\r\n    return self.as_graph_element(name, allow_tensor=False, allow_operation=True)\r\n  File \"C:\\Users\\libby\\Anaconda3\\envs\\action-classification\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3478, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"C:\\Users\\libby\\Anaconda3\\envs\\action-classification\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3538, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'import/final_result' refers to an Operation not in the graph.\"\r\n\r\nI'm on Tensorflow 1.13.1\r\n\r\n"]}, {"number": 45302, "title": "error in converting ssdlite_mobilenet_v2_coco_2018_05_09 tflite_graph.pb to tflite", "body": "Windows10 , tensorflow 1.15.0\r\nI want to trained a tflite model base on `ssdlite_mobilenet_v2_coco_2018_05_09` pretrained model, and this is the resulted [tflite_graph.pb](https://drive.google.com/file/d/10ejimZpsIOrtL_FR-DnsbVaa_cxDTwxj/view?usp=sharing), then i used below script to convert it to tflite format :\r\n```\r\nimport os\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nRepresentative_Dataset_Dir = r\"D:\\MachineLearning\\DataSet\\iGuardDataset\\IMAGE\\Rider-384-484-images\\\"\r\nImage_Names = os.listdir(Representative_Dataset_Dir)\r\n\r\ndef representative_dataset_gen():\r\n    n = 0\r\n    NORM_H = 300\r\n    NORM_W = 300\r\n    ncalib = 100\r\n    assert ncalib <= len(Image_Names), \"ncalib should smaller than the number of dataset\"\r\n    for i in range(ncalib):\r\n        n += 1\r\n        img0 = cv2.imread(Representative_Dataset_Dir + Image_Names[i])\r\n        img = cv2.resize(img0, (NORM_H, NORM_W))\r\n        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x300x300\r\n        img = np.ascontiguousarray(img)\r\n        input = np.transpose(img, [1, 2, 0])\r\n        input = np.expand_dims(input, axis=0).astype(np.float32)\r\n        input /= 255.0\r\n        yield [input]\r\n\r\ngraph_def_file = r\"E:\\iGuard\\TrainedModel\\tflite\\2020121ssdlite_mobilenet_v2_coco_2018_05_09\\tflite_graph.pb\"\r\ninput_arrays=[\"normalized_input_image_tensor\"]\r\noutput_arrays=['TFLite_Detection_PostProcess', 'TFLite_Detection_PostProcess:1', 'TFLite_Detection_PostProcess:2', 'TFLite_Detection_PostProcess:3']\r\ninput_shape={\"normalized_input_image_tensor\": [1, 300, 300, 3]}\r\n\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8  # or tf.int8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_uint8_model = converter.convert()\r\nopen(\"uint8_model_converted_from_\"+os.path.basename(os.path.dirname(graph_def_file))+\".tflite\", \"wb\").write(tflite_uint8_model)\r\n```\r\nThe output log is \uff1a\r\n```\r\nC:\\Users\\wadew\\.conda\\envs\\tf1.15\\python.exe C:/MachineLearning/CV/TFLiteConverter_uint8-new.py\r\n2020-12-01 23:37:07.472348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n1.15.0\r\n2020-12-01 23:37:10.963739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-12-01 23:37:11.014012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:01:00.0\r\n2020-12-01 23:37:11.014441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2020-12-01 23:37:11.026263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2020-12-01 23:37:11.040675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\r\n2020-12-01 23:37:11.046711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\r\n2020-12-01 23:37:11.064293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\r\n2020-12-01 23:37:11.074437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\r\n2020-12-01 23:37:11.120022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-01 23:37:11.120884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-12-01 23:37:11.121677: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2020-12-01 23:37:11.126202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\r\npciBusID: 0000:01:00.0\r\n2020-12-01 23:37:11.126612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2020-12-01 23:37:11.127010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2020-12-01 23:37:11.127368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\r\n2020-12-01 23:37:11.127708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\r\n2020-12-01 23:37:11.128043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\r\n2020-12-01 23:37:11.128405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\r\n2020-12-01 23:37:11.128748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-01 23:37:11.129582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-12-01 23:37:11.981571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-01 23:37:11.981937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-12-01 23:37:11.982171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-12-01 23:37:11.985844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4629 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nTraceback (most recent call last):\r\n  File \"C:/MachineLearning/CV/TFLiteConverter_uint8-new.py\", line 67, in <module>\r\n    tflite_uint8_model = converter.convert()\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 989, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 412, in toco_convert_graph_def\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-12-01 23:37:12.759297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2020-12-01 23:37:16.367452: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2020-12-01 23:37:16.742053: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 2800 arrays (0 quantized)\r\n2020-12-01 23:37:16.960765: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1895 operators, 2800 arrays (0 quantized)\r\n2020-12-01 23:37:17.515990: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 213 operators, 407 arrays (0 quantized)\r\n2020-12-01 23:37:17.530260: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 213 operators, 407 arrays (0 quantized)\r\n2020-12-01 23:37:17.540882: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 213 operators, 407 arrays (0 quantized)\r\n2020-12-01 23:37:17.561096: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 20160000 bytes, theoretical optimal value: 17280000 bytes.\r\n2020-12-01 23:37:17.563117: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 837311268 ops, equivalently 418655634 MACs\r\n2020-12-01 23:37:17.563500: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 1733299\r\n2020-12-01 23:37:17.566015: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/Conv/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.566827: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.567687: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.568541: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.569396: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.570257: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.571181: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.572052: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.572922: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.573788: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.574672: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.575528: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.576390: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.577248: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.578103: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.578969: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.579826: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.580705: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.581562: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.582425: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.583286: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.584175: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.585030: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.585890: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.586746: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.587606: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.588559: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.589429: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.590323: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.591182: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.592045: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.592902: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.593785: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.594642: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.595600: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.596492: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.597399: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.598271: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.599142: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.600004: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.600865: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.601753: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.602624: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.603517: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.604386: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.605258: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.606125: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.607018: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.607885: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.608741: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.609605: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.610465: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.611330: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.612197: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.613080: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.613943: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.614803: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.615736: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.616639: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.617509: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.618375: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.619234: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/Conv_1/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.620055: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.620928: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_384_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.621822: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_384/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.622696: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.623562: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_192_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.624546: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.625449: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.626324: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_192_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.627230: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.628108: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_48/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.628974: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_96_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.629868: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.630741: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.631601: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.632431: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.633275: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.634102: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.634945: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.635774: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.636614: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.637442: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.638287: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.639115: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.639956: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.640781: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.641604: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.642405: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.643225: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.644033: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.644852: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.645656: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.646475: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.647284: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.648102: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.648905: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.649725: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.\r\n2020-12-01 23:37:17.651419: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, FAKE_QUANT, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\Scripts\\toco_from_protos-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"C:\\Users\\wadew\\.conda\\envs\\tf1.15\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, FAKE_QUANT, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n\r\nProcess finished with exit code 1\r\n```\r\n", "comments": ["@wwdok,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.3 and check if you are facing the same issue. Thanks!", "But TF2.x doesn't support `.from_frozen_graph()` ", "@wwdok,\r\nOn running the code, I am facing an error stating `FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\MachineLearning\\\\DataSet\\\\iGuardDataset\\\\IMAGE\\\\Rider-384-484-images'`. \r\n\r\nCould you please share all the files required to run the code, so that we can reproduce the issue on our end.\r\n\r\n\r\n\r\n> But TF2.x doesn't support `.from_frozen_graph()`\r\n\r\nAlso, please take a look at the [tf.compat.v1.TFLiteConverter.from_frozen_graph](https://www.tensorflow.org/api_docs/python/tf/compat/v1/lite/TFLiteConverter) api and check if you are facing the same error. Thanks!", "Hi, @amahendrakar ,the Rider-384-484-images download link is [here](https://drive.google.com/file/d/1JPbJgG5KFBolhCaDgBjCgdxOSbim7xJ1/view?usp=sharing). I tried on another computer whose TF version is 2.3.0rc0, it seems produce differennt logs from TF1.15 as below screenshot shows , but still can not generate tflite file.\r\n```\r\n  %513 = \"tfl.dequantize\"(%512) : (tensor<1x10x10x120x!quant.uniform<u8:f32, 0.044040001139921299:129>>) -> tensor<1x10x10x120xf32>\r\n  %514 = \"tfl.dequantize\"(%512) : (tensor<1x10x10x120x!quant.uniform<u8:f32, 0.044040001139921299:129>>) -> tensor<1x10x10x120xf32>\r\n  %515 = \"tfl.add\"(%514, %496) {fused_activation_function = \"NONE\"} : (tensor<1x10x10x120xf32>, tensor<1x10x10x120xf32>) -> tensor<1x10x10x120xf32>\r\n  %516 = \"tfl.quantize\"(%515) {qtype = tensor<1x10x10x120x!quant.uniform<u8:f32, 0.085307319491517306:129>>} : (tensor<1x10x10x120xf32>) -> tensor<1x10x10x120x!quant.uniform<u8:f32, 0.085307319491517306:129>>\r\n  %517 = \"tfl.dequantize\"(%516) : (tensor<1x10x10x120x!quant.uniform<u8:f32, 0.085307319491517306:129>>) -> tensor<1x10x10x120xf32>\r\n  %518 = \"tfl.dequantize\"(%516) : (tensor<1x10x10x120x!quant.uniform<u8:f32, 0.085307319491517306:129>>) -> tensor<1x10x10x120xf32>\r\n  %519 = \"tfl.quantize\"(%cst_201) {qtype = tensor<720x1x1x120x!quant.uniform<u8<1:255>:f32, 0.0011782469594572474:132>>} : (tensor<720x1x1x120xf32>) -> tensor<720x1x1x120x!quant.uniform<u8<1:255>:f32, 0.0011782469594572474:132>>\r\n  %520 = \"tfl.dequantize\"(%519) : (tensor<720x1x1x120x!quant.uniform<u8<1:255>:f32, 0.0011782469594572474:132>>) -> tensor<720x1x1x120xf32>\r\n  %521 = \"tfl.conv_2d\"(%518, %520, %cst_82) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x120xf32>, tensor<720x1x1x120xf32>, tensor<720xf32>) -> tensor<1x10x10x720xf32>\r\n  %522 = \"tfl.quantize\"(%521) {qtype = tensor<1x10x10x720x!quant.uniform<u8:f32, 0.049845175649605548:126>>} : (tensor<1x10x10x720xf32>) -> tensor<1x10x10x720x!quant.uniform<u8:f32, 0.049845175649605548:126>>\r\n  %523 = \"tfl.dequantize\"(%522) : (tensor<1x10x10x720x!quant.uniform<u8:f32, 0.049845175649605548:126>>) -> tensor<1x10x10x720xf32>\r\n  %524 = \"tfl.dequantize\"(%522) : (tensor<1x10x10x720x!quant.uniform<u8:f32, 0.049845175649605548:126>>) -> tensor<1x10x10x720xf32>\r\n  %525 = \"tfl.quantize\"(%cst_202) {qtype = tensor<1x3x3x720x!quant.uniform<u8<1:255>:f32, 0.013717100845547173:126>>} : (tensor<1x3x3x720xf32>) -> tensor<1x3x3x720x!quant.uniform<u8<1:255>:f32, 0.013717100845547173:126>>\r\n  %526 = \"tfl.dequantize\"(%525) : (tensor<1x3x3x720x!quant.uniform<u8<1:255>:f32, 0.013717100845547173:126>>) -> tensor<1x3x3x720xf32>\r\n  %527 = \"tfl.depthwise_conv_2d\"(%524, %526, %cst_80) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x720xf32>, tensor<1x3x3x720xf32>, tensor<720xf32>) -> tensor<1x10x10x720xf32>\r\n  %528 = \"tfl.quantize\"(%527) {qtype = tensor<1x10x10x720x!quant.uniform<u8:f32, 0.058845002043480969:125>>} : (tensor<1x10x10x720xf32>) -> tensor<1x10x10x720x!quant.uniform<u8:f32, 0.058845002043480969:125>>\r\n  %529 = \"tfl.dequantize\"(%528) : (tensor<1x10x10x720x!quant.uniform<u8:f32, 0.058845002043480969:125>>) -> tensor<1x10x10x720xf32>\r\n  %530 = \"tfl.dequantize\"(%528) : (tensor<1x10x10x720x!quant.uniform<u8:f32, 0.058845002043480969:125>>) -> tensor<1x10x10x720xf32>\r\n  %531 = \"tfl.quantize\"(%cst_203) {qtype = tensor<240x1x1x720x!quant.uniform<u8<1:255>:f32, 0.0013646536807375631:127>>} : (tensor<240x1x1x720xf32>) -> tensor<240x1x1x720x!quant.uniform<u8<1:255>:f32, 0.0013646536807375631:127>>\r\n  %532 = \"tfl.dequantize\"(%531) : (tensor<240x1x1x720x!quant.uniform<u8<1:255>:f32, 0.0013646536807375631:127>>) -> tensor<240x1x1x720xf32>\r\n  %533 = \"tfl.conv_2d\"(%530, %532, %cst_255) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x720xf32>, tensor<240x1x1x720xf32>, tensor<240xf32>) -> tensor<1x10x10x240xf32>\r\n  %534 = \"tfl.quantize\"(%533) {qtype = tensor<1x10x10x240x!quant.uniform<u8:f32, 0.046724407345640893:128>>} : (tensor<1x10x10x240xf32>) -> tensor<1x10x10x240x!quant.uniform<u8:f32, 0.046724407345640893:128>>\r\n  %535 = \"tfl.dequantize\"(%534) : (tensor<1x10x10x240x!quant.uniform<u8:f32, 0.046724407345640893:128>>) -> tensor<1x10x10x240xf32>\r\n  %536 = \"tfl.dequantize\"(%534) : (tensor<1x10x10x240x!quant.uniform<u8:f32, 0.046724407345640893:128>>) -> tensor<1x10x10x240xf32>\r\n  %537 = \"tfl.quantize\"(%cst_204) {qtype = tensor<960x1x1x240x!quant.uniform<u8<1:255>:f32, 0.0014220292525967276:126>>} : (tensor<960x1x1x240xf32>) -> tensor<960x1x1x240x!quant.uniform<u8<1:255>:f32, 0.0014220292525967276:126>>\r\n  %538 = \"tfl.dequantize\"(%537) : (tensor<960x1x1x240x!quant.uniform<u8<1:255>:f32, 0.0014220292525967276:126>>) -> tensor<960x1x1x240xf32>\r\n  %539 = \"tfl.conv_2d\"(%536, %538, %cst_40) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x240xf32>, tensor<960x1x1x240xf32>, tensor<960xf32>) -> tensor<1x10x10x960xf32>\r\n  %540 = \"tfl.quantize\"(%539) {qtype = tensor<1x10x10x960x!quant.uniform<u8:f32, 0.05025379330504174:128>>} : (tensor<1x10x10x960xf32>) -> tensor<1x10x10x960x!quant.uniform<u8:f32, 0.05025379330504174:128>>\r\n  %541 = \"tfl.dequantize\"(%540) : (tensor<1x10x10x960x!quant.uniform<u8:f32, 0.05025379330504174:128>>) -> tensor<1x10x10x960xf32>\r\n  %542 = \"tfl.quantize\"(%cst_205) {qtype = tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.0099428314862288827:120>>} : (tensor<1x3x3x960xf32>) -> tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.0099428314862288827:120>>\r\n  %543 = \"tfl.dequantize\"(%542) : (tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.0099428314862288827:120>>) -> tensor<1x3x3x960xf32>\r\n  %544 = \"tfl.depthwise_conv_2d\"(%541, %543, %cst_9) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x960xf32>, tensor<1x3x3x960xf32>, tensor<960xf32>) -> tensor<1x10x10x960xf32>\r\n  %545 = \"tfl.quantize\"(%544) {qtype = tensor<1x10x10x960x!quant.uniform<u8:f32, 0.051817071204091986:126>>} : (tensor<1x10x10x960xf32>) -> tensor<1x10x10x960x!quant.uniform<u8:f32, 0.051817071204091986:126>>\r\n  %546 = \"tfl.dequantize\"(%545) : (tensor<1x10x10x960x!quant.uniform<u8:f32, 0.051817071204091986:126>>) -> tensor<1x10x10x960xf32>\r\n  %547 = \"tfl.dequantize\"(%545) : (tensor<1x10x10x960x!quant.uniform<u8:f32, 0.051817071204091986:126>>) -> tensor<1x10x10x960xf32>\r\n  %548 = \"tfl.quantize\"(%cst_206) {qtype = tensor<12x1x1x960x!quant.uniform<u8<1:255>:f32, 9.5579761454439539E-4:106>>} : (tensor<12x1x1x960xf32>) -> tensor<12x1x1x960x!quant.uniform<u8<1:255>:f32, 9.5579761454439539E-4:106>>\r\n  %549 = \"tfl.dequantize\"(%548) : (tensor<12x1x1x960x!quant.uniform<u8<1:255>:f32, 9.5579761454439539E-4:106>>) -> tensor<12x1x1x960xf32>\r\n  %550 = \"tfl.conv_2d\"(%547, %549, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x960xf32>, tensor<12x1x1x960xf32>, tensor<12xf32>) -> tensor<1x10x10x12xf32>\r\n  %551 = \"tfl.reshape\"(%550, %cst) : (tensor<1x10x10x12xf32>, tensor<4xi32>) -> tensor<1x300x1x4xf32>\r\n  %552 = \"tfl.quantize\"(%551) {qtype = tensor<1x300x1x4x!quant.uniform<u8:f32, 0.033533786324893726:142>>} : (tensor<1x300x1x4xf32>) -> tensor<1x300x1x4x!quant.uniform<u8:f32, 0.033533786324893726:142>>\r\n  %553 = \"tfl.dequantize\"(%552) : (tensor<1x300x1x4x!quant.uniform<u8:f32, 0.033533786324893726:142>>) -> tensor<1x300x1x4xf32>\r\n  %554 = \"tfl.dequantize\"(%552) : (tensor<1x300x1x4x!quant.uniform<u8:f32, 0.033533786324893726:142>>) -> tensor<1x300x1x4xf32>\r\n  %555 = \"tfl.quantize\"(%cst_207) {qtype = tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.009561476745004729:108>>} : (tensor<1x3x3x960xf32>) -> tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.009561476745004729:108>>\r\n  %556 = \"tfl.dequantize\"(%555) : (tensor<1x3x3x960x!quant.uniform<u8<1:255>:f32, 0.009561476745004729:108>>) -> tensor<1x3x3x960xf32>\r\n  %557 = \"tfl.depthwise_conv_2d\"(%541, %556, %cst_12) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x960xf32>, tensor<1x3x3x960xf32>, tensor<960xf32>) -> tensor<1x10x10x960xf32>\r\n  %558 = \"tfl.quantize\"(%557) {qtype = tensor<1x10x10x960x!quant.uniform<u8:f32, 0.059627830280977137:123>>} : (tensor<1x10x10x960xf32>) -> tensor<1x10x10x960x!quant.uniform<u8:f32, 0.059627830280977137:123>>\r\n  %559 = \"tfl.dequantize\"(%558) : (tensor<1x10x10x960x!quant.uniform<u8:f32, 0.059627830280977137:123>>) -> tensor<1x10x10x960xf32>\r\n  %560 = \"tfl.dequantize\"(%558) : (tensor<1x10x10x960x!quant.uniform<u8:f32, 0.059627830280977137:123>>) -> tensor<1x10x10x960xf32>\r\n  %561 = \"tfl.quantize\"(%cst_208) {qtype = tensor<9x1x1x960x!quant.uniform<u8<1:255>:f32, 0.001210898395598404:127>>} : (tensor<9x1x1x960xf32>) -> tensor<9x1x1x960x!quant.uniform<u8<1:255>:f32, 0.001210898395598404:127>>\r\n  %562 = \"tfl.dequantize\"(%561) : (tensor<9x1x1x960x!quant.uniform<u8<1:255>:f32, 0.001210898395598404:127>>) -> tensor<9x1x1x960xf32>\r\n  %563 = \"tfl.conv_2d\"(%560, %562, %cst_257) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x960xf32>, tensor<9x1x1x960xf32>, tensor<9xf32>) -> tensor<1x10x10x9xf32>\r\n  %564 = \"tfl.reshape\"(%563, %cst_0) : (tensor<1x10x10x9xf32>, tensor<3xi32>) -> tensor<1x300x3xf32>\r\n  %565 = \"tfl.quantize\"(%564) {qtype = tensor<1x300x3x!quant.uniform<u8:f32, 0.058483150893566656:194>>} : (tensor<1x300x3xf32>) -> tensor<1x300x3x!quant.uniform<u8:f32, 0.058483150893566656:194>>\r\n  %566 = \"tfl.dequantize\"(%565) : (tensor<1x300x3x!quant.uniform<u8:f32, 0.058483150893566656:194>>) -> tensor<1x300x3xf32>\r\n  %567 = \"tfl.dequantize\"(%565) : (tensor<1x300x3x!quant.uniform<u8:f32, 0.058483150893566656:194>>) -> tensor<1x300x3xf32>\r\n  %568 = \"tfl.quantize\"(%cst_209) {qtype = tensor<192x1x1x960x!quant.uniform<u8<1:255>:f32, 0.0011508345134614959:125>>} : (tensor<192x1x1x960xf32>) -> tensor<192x1x1x960x!quant.uniform<u8<1:255>:f32, 0.0011508345134614959:125>>\r\n  %569 = \"tfl.dequantize\"(%568) : (tensor<192x1x1x960x!quant.uniform<u8<1:255>:f32, 0.0011508345134614959:125>>) -> tensor<192x1x1x960xf32>\r\n  %570 = \"tfl.conv_2d\"(%541, %569, %cst_125) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x960xf32>, tensor<192x1x1x960xf32>, tensor<192xf32>) -> tensor<1x10x10x192xf32>\r\n  %571 = \"tfl.quantize\"(%570) {qtype = tensor<1x10x10x192x!quant.uniform<u8:f32, 0.047376830905091531:126>>} : (tensor<1x10x10x192xf32>) -> tensor<1x10x10x192x!quant.uniform<u8:f32, 0.047376830905091531:126>>\r\n  %572 = \"tfl.dequantize\"(%571) : (tensor<1x10x10x192x!quant.uniform<u8:f32, 0.047376830905091531:126>>) -> tensor<1x10x10x192xf32>\r\n  %573 = \"tfl.dequantize\"(%571) : (tensor<1x10x10x192x!quant.uniform<u8:f32, 0.047376830905091531:126>>) -> tensor<1x10x10x192xf32>\r\n  %574 = \"tfl.quantize\"(%cst_210) {qtype = tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.0099807972983112485:131>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.0099807972983112485:131>>\r\n  %575 = \"tfl.dequantize\"(%574) : (tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.0099807972983112485:131>>) -> tensor<1x3x3x192xf32>\r\n  %576 = \"tfl.depthwise_conv_2d\"(%573, %575, %cst_135) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x10x10x192xf32>, tensor<1x3x3x192xf32>, tensor<192xf32>) -> tensor<1x5x5x192xf32>\r\n  %577 = \"tfl.quantize\"(%576) {qtype = tensor<1x5x5x192x!quant.uniform<u8:f32, 0.043643508237950941:125>>} : (tensor<1x5x5x192xf32>) -> tensor<1x5x5x192x!quant.uniform<u8:f32, 0.043643508237950941:125>>\r\n  %578 = \"tfl.dequantize\"(%577) : (tensor<1x5x5x192x!quant.uniform<u8:f32, 0.043643508237950941:125>>) -> tensor<1x5x5x192xf32>\r\n  %579 = \"tfl.dequantize\"(%577) : (tensor<1x5x5x192x!quant.uniform<u8:f32, 0.043643508237950941:125>>) -> tensor<1x5x5x192xf32>\r\n  %580 = \"tfl.quantize\"(%cst_211) {qtype = tensor<384x1x1x192x!quant.uniform<u8<1:255>:f32, 0.00378718115682677:128>>} : (tensor<384x1x1x192xf32>) -> tensor<384x1x1x192x!quant.uniform<u8<1:255>:f32, 0.00378718115682677:128>>\r\n  %581 = \"tfl.dequantize\"(%580) : (tensor<384x1x1x192x!quant.uniform<u8<1:255>:f32, 0.00378718115682677:128>>) -> tensor<384x1x1x192xf32>\r\n  %582 = \"tfl.conv_2d\"(%579, %581, %cst_133) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x192xf32>, tensor<384x1x1x192xf32>, tensor<384xf32>) -> tensor<1x5x5x384xf32>\r\n  %583 = \"tfl.quantize\"(%582) {qtype = tensor<1x5x5x384x!quant.uniform<u8:f32, 0.039862963732551125:124>>} : (tensor<1x5x5x384xf32>) -> tensor<1x5x5x384x!quant.uniform<u8:f32, 0.039862963732551125:124>>\r\n  %584 = \"tfl.dequantize\"(%583) : (tensor<1x5x5x384x!quant.uniform<u8:f32, 0.039862963732551125:124>>) -> tensor<1x5x5x384xf32>\r\n  %585 = \"tfl.quantize\"(%cst_212) {qtype = tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010509150704060952:108>>} : (tensor<1x3x3x384xf32>) -> tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010509150704060952:108>>\r\n  %586 = \"tfl.dequantize\"(%585) : (tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010509150704060952:108>>) -> tensor<1x3x3x384xf32>\r\n  %587 = \"tfl.depthwise_conv_2d\"(%584, %586, %cst_15) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x384xf32>, tensor<1x3x3x384xf32>, tensor<384xf32>) -> tensor<1x5x5x384xf32>\r\n  %588 = \"tfl.quantize\"(%587) {qtype = tensor<1x5x5x384x!quant.uniform<u8:f32, 0.041075497047573913:115>>} : (tensor<1x5x5x384xf32>) -> tensor<1x5x5x384x!quant.uniform<u8:f32, 0.041075497047573913:115>>\r\n  %589 = \"tfl.dequantize\"(%588) : (tensor<1x5x5x384x!quant.uniform<u8:f32, 0.041075497047573913:115>>) -> tensor<1x5x5x384xf32>\r\n  %590 = \"tfl.dequantize\"(%588) : (tensor<1x5x5x384x!quant.uniform<u8:f32, 0.041075497047573913:115>>) -> tensor<1x5x5x384xf32>\r\n  %591 = \"tfl.quantize\"(%cst_213) {qtype = tensor<12x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0010448484204885527:120>>} : (tensor<12x1x1x384xf32>) -> tensor<12x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0010448484204885527:120>>\r\n  %592 = \"tfl.dequantize\"(%591) : (tensor<12x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0010448484204885527:120>>) -> tensor<12x1x1x384xf32>\r\n  %593 = \"tfl.conv_2d\"(%590, %592, %cst_258) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x384xf32>, tensor<12x1x1x384xf32>, tensor<12xf32>) -> tensor<1x5x5x12xf32>\r\n  %594 = \"tfl.reshape\"(%593, %cst) : (tensor<1x5x5x12xf32>, tensor<4xi32>) -> tensor<1x75x1x4xf32>\r\n  %595 = \"tfl.quantize\"(%594) {qtype = tensor<1x75x1x4x!quant.uniform<u8:f32, 0.024388512443093691:131>>} : (tensor<1x75x1x4xf32>) -> tensor<1x75x1x4x!quant.uniform<u8:f32, 0.024388512443093691:131>>\r\n  %596 = \"tfl.dequantize\"(%595) : (tensor<1x75x1x4x!quant.uniform<u8:f32, 0.024388512443093691:131>>) -> tensor<1x75x1x4xf32>\r\n  %597 = \"tfl.dequantize\"(%595) : (tensor<1x75x1x4x!quant.uniform<u8:f32, 0.024388512443093691:131>>) -> tensor<1x75x1x4xf32>\r\n  %598 = \"tfl.quantize\"(%cst_214) {qtype = tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010357493960012601:111>>} : (tensor<1x3x3x384xf32>) -> tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010357493960012601:111>>\r\n  %599 = \"tfl.dequantize\"(%598) : (tensor<1x3x3x384x!quant.uniform<u8<1:255>:f32, 0.010357493960012601:111>>) -> tensor<1x3x3x384xf32>\r\n  %600 = \"tfl.depthwise_conv_2d\"(%584, %599, %cst_18) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x384xf32>, tensor<1x3x3x384xf32>, tensor<384xf32>) -> tensor<1x5x5x384xf32>\r\n  %601 = \"tfl.quantize\"(%600) {qtype = tensor<1x5x5x384x!quant.uniform<u8:f32, 0.046257351894004671:119>>} : (tensor<1x5x5x384xf32>) -> tensor<1x5x5x384x!quant.uniform<u8:f32, 0.046257351894004671:119>>\r\n  %602 = \"tfl.dequantize\"(%601) : (tensor<1x5x5x384x!quant.uniform<u8:f32, 0.046257351894004671:119>>) -> tensor<1x5x5x384xf32>\r\n  %603 = \"tfl.dequantize\"(%601) : (tensor<1x5x5x384x!quant.uniform<u8:f32, 0.046257351894004671:119>>) -> tensor<1x5x5x384xf32>\r\n  %604 = \"tfl.quantize\"(%cst_215) {qtype = tensor<9x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0015118802626301923:118>>} : (tensor<9x1x1x384xf32>) -> tensor<9x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0015118802626301923:118>>\r\n  %605 = \"tfl.dequantize\"(%604) : (tensor<9x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0015118802626301923:118>>) -> tensor<9x1x1x384xf32>\r\n  %606 = \"tfl.conv_2d\"(%603, %605, %cst_259) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x384xf32>, tensor<9x1x1x384xf32>, tensor<9xf32>) -> tensor<1x5x5x9xf32>\r\n  %607 = \"tfl.reshape\"(%606, %cst_0) : (tensor<1x5x5x9xf32>, tensor<3xi32>) -> tensor<1x75x3xf32>\r\n  %608 = \"tfl.quantize\"(%607) {qtype = tensor<1x75x3x!quant.uniform<u8:f32, 0.038203794815961055:189>>} : (tensor<1x75x3xf32>) -> tensor<1x75x3x!quant.uniform<u8:f32, 0.038203794815961055:189>>\r\n  %609 = \"tfl.dequantize\"(%608) : (tensor<1x75x3x!quant.uniform<u8:f32, 0.038203794815961055:189>>) -> tensor<1x75x3xf32>\r\n  %610 = \"tfl.dequantize\"(%608) : (tensor<1x75x3x!quant.uniform<u8:f32, 0.038203794815961055:189>>) -> tensor<1x75x3xf32>\r\n  %611 = \"tfl.quantize\"(%cst_216) {qtype = tensor<96x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0017099232654871903:124>>} : (tensor<96x1x1x384xf32>) -> tensor<96x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0017099232654871903:124>>\r\n  %612 = \"tfl.dequantize\"(%611) : (tensor<96x1x1x384x!quant.uniform<u8<1:255>:f32, 0.0017099232654871903:124>>) -> tensor<96x1x1x384xf32>\r\n  %613 = \"tfl.conv_2d\"(%584, %612, %cst_127) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x384xf32>, tensor<96x1x1x384xf32>, tensor<96xf32>) -> tensor<1x5x5x96xf32>\r\n  %614 = \"tfl.quantize\"(%613) {qtype = tensor<1x5x5x96x!quant.uniform<u8:f32, 0.038239514593984565:128>>} : (tensor<1x5x5x96xf32>) -> tensor<1x5x5x96x!quant.uniform<u8:f32, 0.038239514593984565:128>>\r\n  %615 = \"tfl.dequantize\"(%614) : (tensor<1x5x5x96x!quant.uniform<u8:f32, 0.038239514593984565:128>>) -> tensor<1x5x5x96xf32>\r\n  %616 = \"tfl.dequantize\"(%614) : (tensor<1x5x5x96x!quant.uniform<u8:f32, 0.038239514593984565:128>>) -> tensor<1x5x5x96xf32>\r\n  %617 = \"tfl.quantize\"(%cst_217) {qtype = tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0093031779048949707:129>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0093031779048949707:129>>\r\n  %618 = \"tfl.dequantize\"(%617) : (tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0093031779048949707:129>>) -> tensor<1x3x3x96xf32>\r\n  %619 = \"tfl.depthwise_conv_2d\"(%616, %618, %cst_139) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x5x5x96xf32>, tensor<1x3x3x96xf32>, tensor<96xf32>) -> tensor<1x3x3x96xf32>\r\n  %620 = \"tfl.quantize\"(%619) {qtype = tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033284727732340494:132>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033284727732340494:132>>\r\n  %621 = \"tfl.dequantize\"(%620) : (tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033284727732340494:132>>) -> tensor<1x3x3x96xf32>\r\n  %622 = \"tfl.dequantize\"(%620) : (tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033284727732340494:132>>) -> tensor<1x3x3x96xf32>\r\n  %623 = \"tfl.quantize\"(%cst_218) {qtype = tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0057532308608528194:122>>} : (tensor<192x1x1x96xf32>) -> tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0057532308608528194:122>>\r\n  %624 = \"tfl.dequantize\"(%623) : (tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0057532308608528194:122>>) -> tensor<192x1x1x96xf32>\r\n  %625 = \"tfl.conv_2d\"(%622, %624, %cst_137) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x96xf32>, tensor<192x1x1x96xf32>, tensor<192xf32>) -> tensor<1x3x3x192xf32>\r\n  %626 = \"tfl.quantize\"(%625) {qtype = tensor<1x3x3x192x!quant.uniform<u8:f32, 0.031968343024160351:121>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8:f32, 0.031968343024160351:121>>\r\n  %627 = \"tfl.dequantize\"(%626) : (tensor<1x3x3x192x!quant.uniform<u8:f32, 0.031968343024160351:121>>) -> tensor<1x3x3x192xf32>\r\n  %628 = \"tfl.quantize\"(%cst_219) {qtype = tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.012865518491099201:101>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.012865518491099201:101>>\r\n  %629 = \"tfl.dequantize\"(%628) : (tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.012865518491099201:101>>) -> tensor<1x3x3x192xf32>\r\n  %630 = \"tfl.depthwise_conv_2d\"(%627, %629, %cst_21) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x192xf32>, tensor<1x3x3x192xf32>, tensor<192xf32>) -> tensor<1x3x3x192xf32>\r\n  %631 = \"tfl.quantize\"(%630) {qtype = tensor<1x3x3x192x!quant.uniform<u8:f32, 0.033022232616648953:107>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8:f32, 0.033022232616648953:107>>\r\n  %632 = \"tfl.dequantize\"(%631) : (tensor<1x3x3x192x!quant.uniform<u8:f32, 0.033022232616648953:107>>) -> tensor<1x3x3x192xf32>\r\n  %633 = \"tfl.dequantize\"(%631) : (tensor<1x3x3x192x!quant.uniform<u8:f32, 0.033022232616648953:107>>) -> tensor<1x3x3x192xf32>\r\n  %634 = \"tfl.quantize\"(%cst_220) {qtype = tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 0.001163998868052415:138>>} : (tensor<12x1x1x192xf32>) -> tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 0.001163998868052415:138>>\r\n  %635 = \"tfl.dequantize\"(%634) : (tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 0.001163998868052415:138>>) -> tensor<12x1x1x192xf32>\r\n  %636 = \"tfl.conv_2d\"(%633, %635, %cst_260) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x192xf32>, tensor<12x1x1x192xf32>, tensor<12xf32>) -> tensor<1x3x3x12xf32>\r\n  %637 = \"tfl.reshape\"(%636, %cst) : (tensor<1x3x3x12xf32>, tensor<4xi32>) -> tensor<1x27x1x4xf32>\r\n  %638 = \"tfl.quantize\"(%637) {qtype = tensor<1x27x1x4x!quant.uniform<u8:f32, 0.023541544932945101:142>>} : (tensor<1x27x1x4xf32>) -> tensor<1x27x1x4x!quant.uniform<u8:f32, 0.023541544932945101:142>>\r\n  %639 = \"tfl.dequantize\"(%638) : (tensor<1x27x1x4x!quant.uniform<u8:f32, 0.023541544932945101:142>>) -> tensor<1x27x1x4xf32>\r\n  %640 = \"tfl.dequantize\"(%638) : (tensor<1x27x1x4x!quant.uniform<u8:f32, 0.023541544932945101:142>>) -> tensor<1x27x1x4xf32>\r\n  %641 = \"tfl.quantize\"(%cst_221) {qtype = tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011183834920717976:90>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011183834920717976:90>>\r\n  %642 = \"tfl.dequantize\"(%641) : (tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011183834920717976:90>>) -> tensor<1x3x3x192xf32>\r\n  %643 = \"tfl.depthwise_conv_2d\"(%627, %642, %cst_24) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x192xf32>, tensor<1x3x3x192xf32>, tensor<192xf32>) -> tensor<1x3x3x192xf32>\r\n  %644 = \"tfl.quantize\"(%643) {qtype = tensor<1x3x3x192x!quant.uniform<u8:f32, 0.037984894771201941:109>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8:f32, 0.037984894771201941:109>>\r\n  %645 = \"tfl.dequantize\"(%644) : (tensor<1x3x3x192x!quant.uniform<u8:f32, 0.037984894771201941:109>>) -> tensor<1x3x3x192xf32>\r\n  %646 = \"tfl.dequantize\"(%644) : (tensor<1x3x3x192x!quant.uniform<u8:f32, 0.037984894771201941:109>>) -> tensor<1x3x3x192xf32>\r\n  %647 = \"tfl.quantize\"(%cst_222) {qtype = tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0012243818931692229:121>>} : (tensor<9x1x1x192xf32>) -> tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0012243818931692229:121>>\r\n  %648 = \"tfl.dequantize\"(%647) : (tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0012243818931692229:121>>) -> tensor<9x1x1x192xf32>\r\n  %649 = \"tfl.conv_2d\"(%646, %648, %cst_261) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x192xf32>, tensor<9x1x1x192xf32>, tensor<9xf32>) -> tensor<1x3x3x9xf32>\r\n  %650 = \"tfl.reshape\"(%649, %cst_0) : (tensor<1x3x3x9xf32>, tensor<3xi32>) -> tensor<1x27x3xf32>\r\n  %651 = \"tfl.quantize\"(%650) {qtype = tensor<1x27x3x!quant.uniform<u8:f32, 0.029586039804944807:191>>} : (tensor<1x27x3xf32>) -> tensor<1x27x3x!quant.uniform<u8:f32, 0.029586039804944807:191>>\r\n  %652 = \"tfl.dequantize\"(%651) : (tensor<1x27x3x!quant.uniform<u8:f32, 0.029586039804944807:191>>) -> tensor<1x27x3xf32>\r\n  %653 = \"tfl.dequantize\"(%651) : (tensor<1x27x3x!quant.uniform<u8:f32, 0.029586039804944807:191>>) -> tensor<1x27x3xf32>\r\n  %654 = \"tfl.quantize\"(%cst_223) {qtype = tensor<96x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0027923111136504046:131>>} : (tensor<96x1x1x192xf32>) -> tensor<96x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0027923111136504046:131>>\r\n  %655 = \"tfl.dequantize\"(%654) : (tensor<96x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0027923111136504046:131>>) -> tensor<96x1x1x192xf32>\r\n  %656 = \"tfl.conv_2d\"(%627, %655, %cst_129) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x3x3x192xf32>, tensor<96x1x1x192xf32>, tensor<96xf32>) -> tensor<1x3x3x96xf32>\r\n  %657 = \"tfl.quantize\"(%656) {qtype = tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033001357433842679:125>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033001357433842679:125>>\r\n  %658 = \"tfl.dequantize\"(%657) : (tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033001357433842679:125>>) -> tensor<1x3x3x96xf32>\r\n  %659 = \"tfl.dequantize\"(%657) : (tensor<1x3x3x96x!quant.uniform<u8:f32, 0.033001357433842679:125>>) -> tensor<1x3x3x96xf32>\r\n  %660 = \"tfl.quantize\"(%cst_224) {qtype = tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0109707300118574:114>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0109707300118574:114>>\r\n  %661 = \"tfl.dequantize\"(%660) : (tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.0109707300118574:114>>) -> tensor<1x3x3x96xf32>\r\n  %662 = \"tfl.depthwise_conv_2d\"(%659, %661, %cst_143) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x3x3x96xf32>, tensor<1x3x3x96xf32>, tensor<96xf32>) -> tensor<1x2x2x96xf32>\r\n  %663 = \"tfl.quantize\"(%662) {qtype = tensor<1x2x2x96x!quant.uniform<u8:f32, 0.024654746523090437:126>>} : (tensor<1x2x2x96xf32>) -> tensor<1x2x2x96x!quant.uniform<u8:f32, 0.024654746523090437:126>>\r\n  %664 = \"tfl.dequantize\"(%663) : (tensor<1x2x2x96x!quant.uniform<u8:f32, 0.024654746523090437:126>>) -> tensor<1x2x2x96xf32>\r\n  %665 = \"tfl.dequantize\"(%663) : (tensor<1x2x2x96x!quant.uniform<u8:f32, 0.024654746523090437:126>>) -> tensor<1x2x2x96xf32>\r\n  %666 = \"tfl.quantize\"(%cst_225) {qtype = tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0062577724456787109:124>>} : (tensor<192x1x1x96xf32>) -> tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0062577724456787109:124>>\r\n  %667 = \"tfl.dequantize\"(%666) : (tensor<192x1x1x96x!quant.uniform<u8<1:255>:f32, 0.0062577724456787109:124>>) -> tensor<192x1x1x96xf32>\r\n  %668 = \"tfl.conv_2d\"(%665, %667, %cst_141) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x96xf32>, tensor<192x1x1x96xf32>, tensor<192xf32>) -> tensor<1x2x2x192xf32>\r\n  %669 = \"tfl.quantize\"(%668) {qtype = tensor<1x2x2x192x!quant.uniform<u8:f32, 0.026478831908282111:123>>} : (tensor<1x2x2x192xf32>) -> tensor<1x2x2x192x!quant.uniform<u8:f32, 0.026478831908282111:123>>\r\n  %670 = \"tfl.dequantize\"(%669) : (tensor<1x2x2x192x!quant.uniform<u8:f32, 0.026478831908282111:123>>) -> tensor<1x2x2x192xf32>\r\n  %671 = \"tfl.quantize\"(%cst_226) {qtype = tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.010845297903526487:119>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.010845297903526487:119>>\r\n  %672 = \"tfl.dequantize\"(%671) : (tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.010845297903526487:119>>) -> tensor<1x3x3x192xf32>\r\n  %673 = \"tfl.depthwise_conv_2d\"(%670, %672, %cst_27) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x192xf32>, tensor<1x3x3x192xf32>, tensor<192xf32>) -> tensor<1x2x2x192xf32>\r\n  %674 = \"tfl.quantize\"(%673) {qtype = tensor<1x2x2x192x!quant.uniform<u8:f32, 0.024867111093857711:112>>} : (tensor<1x2x2x192xf32>) -> tensor<1x2x2x192x!quant.uniform<u8:f32, 0.024867111093857711:112>>\r\n  %675 = \"tfl.dequantize\"(%674) : (tensor<1x2x2x192x!quant.uniform<u8:f32, 0.024867111093857711:112>>) -> tensor<1x2x2x192xf32>\r\n  %676 = \"tfl.dequantize\"(%674) : (tensor<1x2x2x192x!quant.uniform<u8:f32, 0.024867111093857711:112>>) -> tensor<1x2x2x192xf32>\r\n  %677 = \"tfl.quantize\"(%cst_227) {qtype = tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 8.1347621332003377E-4:137>>} : (tensor<12x1x1x192xf32>) -> tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 8.1347621332003377E-4:137>>\r\n  %678 = \"tfl.dequantize\"(%677) : (tensor<12x1x1x192x!quant.uniform<u8<1:255>:f32, 8.1347621332003377E-4:137>>) -> tensor<12x1x1x192xf32>\r\n  %679 = \"tfl.conv_2d\"(%676, %678, %cst_262) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x192xf32>, tensor<12x1x1x192xf32>, tensor<12xf32>) -> tensor<1x2x2x12xf32>\r\n  %680 = \"tfl.reshape\"(%679, %cst) : (tensor<1x2x2x12xf32>, tensor<4xi32>) -> tensor<1x12x1x4xf32>\r\n  %681 = \"tfl.quantize\"(%680) {qtype = tensor<1x12x1x4x!quant.uniform<u8:f32, 0.017574823603910557:134>>} : (tensor<1x12x1x4xf32>) -> tensor<1x12x1x4x!quant.uniform<u8:f32, 0.017574823603910557:134>>\r\n  %682 = \"tfl.dequantize\"(%681) : (tensor<1x12x1x4x!quant.uniform<u8:f32, 0.017574823603910557:134>>) -> tensor<1x12x1x4xf32>\r\n  %683 = \"tfl.dequantize\"(%681) : (tensor<1x12x1x4x!quant.uniform<u8:f32, 0.017574823603910557:134>>) -> tensor<1x12x1x4xf32>\r\n  %684 = \"tfl.quantize\"(%cst_228) {qtype = tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011709987647890106:100>>} : (tensor<1x3x3x192xf32>) -> tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011709987647890106:100>>\r\n  %685 = \"tfl.dequantize\"(%684) : (tensor<1x3x3x192x!quant.uniform<u8<1:255>:f32, 0.011709987647890106:100>>) -> tensor<1x3x3x192xf32>\r\n  %686 = \"tfl.depthwise_conv_2d\"(%670, %685, %cst_30) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x192xf32>, tensor<1x3x3x192xf32>, tensor<192xf32>) -> tensor<1x2x2x192xf32>\r\n  %687 = \"tfl.quantize\"(%686) {qtype = tensor<1x2x2x192x!quant.uniform<u8:f32, 0.029412503335990159:117>>} : (tensor<1x2x2x192xf32>) -> tensor<1x2x2x192x!quant.uniform<u8:f32, 0.029412503335990159:117>>\r\n  %688 = \"tfl.dequantize\"(%687) : (tensor<1x2x2x192x!quant.uniform<u8:f32, 0.029412503335990159:117>>) -> tensor<1x2x2x192xf32>\r\n  %689 = \"tfl.dequantize\"(%687) : (tensor<1x2x2x192x!quant.uniform<u8:f32, 0.029412503335990159:117>>) -> tensor<1x2x2x192xf32>\r\n  %690 = \"tfl.quantize\"(%cst_229) {qtype = tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0011278207259853995:129>>} : (tensor<9x1x1x192xf32>) -> tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0011278207259853995:129>>\r\n  %691 = \"tfl.dequantize\"(%690) : (tensor<9x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0011278207259853995:129>>) -> tensor<9x1x1x192xf32>\r\n  %692 = \"tfl.conv_2d\"(%689, %691, %cst_263) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x192xf32>, tensor<9x1x1x192xf32>, tensor<9xf32>) -> tensor<1x2x2x9xf32>\r\n  %693 = \"tfl.reshape\"(%692, %cst_0) : (tensor<1x2x2x9xf32>, tensor<3xi32>) -> tensor<1x12x3xf32>\r\n  %694 = \"tfl.quantize\"(%693) {qtype = tensor<1x12x3x!quant.uniform<u8:f32, 0.02018145439671535:202>>} : (tensor<1x12x3xf32>) -> tensor<1x12x3x!quant.uniform<u8:f32, 0.02018145439671535:202>>\r\n  %695 = \"tfl.dequantize\"(%694) : (tensor<1x12x3x!quant.uniform<u8:f32, 0.02018145439671535:202>>) -> tensor<1x12x3xf32>\r\n  %696 = \"tfl.dequantize\"(%694) : (tensor<1x12x3x!quant.uniform<u8:f32, 0.02018145439671535:202>>) -> tensor<1x12x3xf32>\r\n  %697 = \"tfl.quantize\"(%cst_230) {qtype = tensor<48x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0031271315231097964:128>>} : (tensor<48x1x1x192xf32>) -> tensor<48x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0031271315231097964:128>>\r\n  %698 = \"tfl.dequantize\"(%697) : (tensor<48x1x1x192x!quant.uniform<u8<1:255>:f32, 0.0031271315231097964:128>>) -> tensor<48x1x1x192xf32>\r\n  %699 = \"tfl.conv_2d\"(%670, %698, %cst_131) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x2x2x192xf32>, tensor<48x1x1x192xf32>, tensor<48xf32>) -> tensor<1x2x2x48xf32>\r\n  %700 = \"tfl.quantize\"(%699) {qtype = tensor<1x2x2x48x!quant.uniform<u8:f32, 0.026402967116411994:123>>} : (tensor<1x2x2x48xf32>) -> tensor<1x2x2x48x!quant.uniform<u8:f32, 0.026402967116411994:123>>\r\n  %701 = \"tfl.dequantize\"(%700) : (tensor<1x2x2x48x!quant.uniform<u8:f32, 0.026402967116411994:123>>) -> tensor<1x2x2x48xf32>\r\n  %702 = \"tfl.dequantize\"(%700) : (tensor<1x2x2x48x!quant.uniform<u8:f32, 0.026402967116411994:123>>) -> tensor<1x2x2x48xf32>\r\n  %703 = \"tfl.quantize\"(%cst_231) {qtype = tensor<1x3x3x48x!quant.uniform<u8<1:255>:f32, 0.011937171924771287:117>>} : (tensor<1x3x3x48xf32>) -> tensor<1x3x3x48x!quant.uniform<u8<1:255>:f32, 0.011937171924771287:117>>\r\n  %704 = \"tfl.dequantize\"(%703) : (tensor<1x3x3x48x!quant.uniform<u8<1:255>:f32, 0.011937171924771287:117>>) -> tensor<1x3x3x48xf32>\r\n  %705 = \"tfl.depthwise_conv_2d\"(%702, %704, %cst_147) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x2x2x48xf32>, tensor<1x3x3x48xf32>, tensor<48xf32>) -> tensor<1x1x1x48xf32>\r\n  %706 = \"tfl.quantize\"(%705) {qtype = tensor<1x1x1x48x!quant.uniform<u8:f32, 0.01531987657733992:128>>} : (tensor<1x1x1x48xf32>) -> tensor<1x1x1x48x!quant.uniform<u8:f32, 0.01531987657733992:128>>\r\n  %707 = \"tfl.dequantize\"(%706) : (tensor<1x1x1x48x!quant.uniform<u8:f32, 0.01531987657733992:128>>) -> tensor<1x1x1x48xf32>\r\n  %708 = \"tfl.dequantize\"(%706) : (tensor<1x1x1x48x!quant.uniform<u8:f32, 0.01531987657733992:128>>) -> tensor<1x1x1x48xf32>\r\n  %709 = \"tfl.quantize\"(%cst_232) {qtype = tensor<96x1x1x48x!quant.uniform<u8<1:255>:f32, 0.0063841525963910925:130>>} : (tensor<96x1x1x48xf32>) -> tensor<96x1x1x48x!quant.uniform<u8<1:255>:f32, 0.0063841525963910925:130>>\r\n  %710 = \"tfl.dequantize\"(%709) : (tensor<96x1x1x48x!quant.uniform<u8<1:255>:f32, 0.0063841525963910925:130>>) -> tensor<96x1x1x48xf32>\r\n  %711 = \"tfl.conv_2d\"(%708, %710, %cst_145) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x1x1x48xf32>, tensor<96x1x1x48xf32>, tensor<96xf32>) -> tensor<1x1x1x96xf32>\r\n  %712 = \"tfl.quantize\"(%711) {qtype = tensor<1x1x1x96x!quant.uniform<u8:f32, 0.017484465767355527:128>>} : (tensor<1x1x1x96xf32>) -> tensor<1x1x1x96x!quant.uniform<u8:f32, 0.017484465767355527:128>>\r\n  %713 = \"tfl.dequantize\"(%712) : (tensor<1x1x1x96x!quant.uniform<u8:f32, 0.017484465767355527:128>>) -> tensor<1x1x1x96xf32>\r\n  %714 = \"tfl.quantize\"(%cst_233) {qtype = tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012543449720998448:128>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012543449720998448:128>>\r\n  %715 = \"tfl.dequantize\"(%714) : (tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012543449720998448:128>>) -> tensor<1x3x3x96xf32>\r\n  %716 = \"tfl.depthwise_conv_2d\"(%713, %715, %cst_33) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x1x1x96xf32>, tensor<1x3x3x96xf32>, tensor<96xf32>) -> tensor<1x1x1x96xf32>\r\n  %717 = \"tfl.quantize\"(%716) {qtype = tensor<1x1x1x96x!quant.uniform<u8:f32, 0.015001340473399443:112>>} : (tensor<1x1x1x96xf32>) -> tensor<1x1x1x96x!quant.uniform<u8:f32, 0.015001340473399443:112>>\r\n  %718 = \"tfl.dequantize\"(%717) : (tensor<1x1x1x96x!quant.uniform<u8:f32, 0.015001340473399443:112>>) -> tensor<1x1x1x96xf32>\r\n  %719 = \"tfl.dequantize\"(%717) : (tensor<1x1x1x96x!quant.uniform<u8:f32, 0.015001340473399443:112>>) -> tensor<1x1x1x96xf32>\r\n  %720 = \"tfl.quantize\"(%cst_234) {qtype = tensor<12x1x1x96x!quant.uniform<u8<1:255>:f32, 6.2906231701843386E-4:169>>} : (tensor<12x1x1x96xf32>) -> tensor<12x1x1x96x!quant.uniform<u8<1:255>:f32, 6.2906231701843386E-4:169>>\r\n  %721 = \"tfl.dequantize\"(%720) : (tensor<12x1x1x96x!quant.uniform<u8<1:255>:f32, 6.2906231701843386E-4:169>>) -> tensor<12x1x1x96xf32>\r\n  %722 = \"tfl.conv_2d\"(%719, %721, %cst_264) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x1x1x96xf32>, tensor<12x1x1x96xf32>, tensor<12xf32>) -> tensor<1x1x1x12xf32>\r\n  %723 = \"tfl.reshape\"(%722, %cst) : (tensor<1x1x1x12xf32>, tensor<4xi32>) -> tensor<1x3x1x4xf32>\r\n  %724 = \"tfl.quantize\"(%723) {qtype = tensor<1x3x1x4x!quant.uniform<u8:f32, 0.0049011422138588098:199>>} : (tensor<1x3x1x4xf32>) -> tensor<1x3x1x4x!quant.uniform<u8:f32, 0.0049011422138588098:199>>\r\n  %725 = \"tfl.dequantize\"(%724) : (tensor<1x3x1x4x!quant.uniform<u8:f32, 0.0049011422138588098:199>>) -> tensor<1x3x1x4xf32>\r\n  %726 = \"tfl.dequantize\"(%724) : (tensor<1x3x1x4x!quant.uniform<u8:f32, 0.0049011422138588098:199>>) -> tensor<1x3x1x4xf32>\r\n  %727 = \"tfl.concatenation\"(%451, %554, %597, %640, %683, %726) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x1083x1x4xf32>, tensor<1x300x1x4xf32>, tensor<1x75x1x4xf32>, tensor<1x27x1x4xf32>, tensor<1x12x1x4xf32>, tensor<1x3x1x4xf32>) -> tensor<1x1500x1x4xf32>\r\n  %728 = \"tfl.reshape\"(%727, %cst_265) : (tensor<1x1500x1x4xf32>, tensor<3xi32>) -> tensor<1x1500x4xf32>\r\n  %729 = \"tfl.quantize\"(%cst_235) {qtype = tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012152169633099414:129>>} : (tensor<1x3x3x96xf32>) -> tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012152169633099414:129>>\r\n  %730 = \"tfl.dequantize\"(%729) : (tensor<1x3x3x96x!quant.uniform<u8<1:255>:f32, 0.012152169633099414:129>>) -> tensor<1x3x3x96xf32>\r\n  %731 = \"tfl.depthwise_conv_2d\"(%713, %730, %cst_36) {depth_multiplier = 1 : i32, dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x1x1x96xf32>, tensor<1x3x3x96xf32>, tensor<96xf32>) -> tensor<1x1x1x96xf32>\r\n  %732 = \"tfl.quantize\"(%731) {qtype = tensor<1x1x1x96x!quant.uniform<u8:f32, 0.019713215734444414:127>>} : (tensor<1x1x1x96xf32>) -> tensor<1x1x1x96x!quant.uniform<u8:f32, 0.019713215734444414:127>>\r\n  %733 = \"tfl.dequantize\"(%732) : (tensor<1x1x1x96x!quant.uniform<u8:f32, 0.019713215734444414:127>>) -> tensor<1x1x1x96xf32>\r\n  %734 = \"tfl.dequantize\"(%732) : (tensor<1x1x1x96x!quant.uniform<u8:f32, 0.019713215734444414:127>>) -> tensor<1x1x1x96xf32>\r\n  %735 = \"tfl.quantize\"(%cst_236) {qtype = tensor<9x1x1x96x!quant.uniform<u8<1:255>:f32, 7.7706600326722067E-4:175>>} : (tensor<9x1x1x96xf32>) -> tensor<9x1x1x96x!quant.uniform<u8<1:255>:f32, 7.7706600326722067E-4:175>>\r\n  %736 = \"tfl.dequantize\"(%735) : (tensor<9x1x1x96x!quant.uniform<u8<1:255>:f32, 7.7706600326722067E-4:175>>) -> tensor<9x1x1x96xf32>\r\n  %737 = \"tfl.conv_2d\"(%734, %736, %cst_266) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x1x1x96xf32>, tensor<9x1x1x96xf32>, tensor<9xf32>) -> tensor<1x1x1x9xf32>\r\n  %738 = \"tfl.reshape\"(%737, %cst_0) : (tensor<1x1x1x9xf32>, tensor<3xi32>) -> tensor<1x3x3xf32>\r\n  %739 = \"tfl.quantize\"(%738) {qtype = tensor<1x3x3x!quant.uniform<u8:f32, 0.010160081526812394:255>>} : (tensor<1x3x3xf32>) -> tensor<1x3x3x!quant.uniform<u8:f32, 0.010160081526812394:255>>\r\n  %740 = \"tfl.dequantize\"(%739) : (tensor<1x3x3x!quant.uniform<u8:f32, 0.010160081526812394:255>>) -> tensor<1x3x3xf32>\r\n  %741 = \"tfl.dequantize\"(%739) : (tensor<1x3x3x!quant.uniform<u8:f32, 0.010160081526812394:255>>) -> tensor<1x3x3xf32>\r\n  %742 = \"tfl.concatenation\"(%464, %567, %610, %653, %696, %741) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x1083x3xf32>, tensor<1x300x3xf32>, tensor<1x75x3xf32>, tensor<1x27x3xf32>, tensor<1x12x3xf32>, tensor<1x3x3xf32>) -> tensor<1x1500x3xf32>\r\n  %743 = \"tfl.logistic\"(%742) : (tensor<1x1500x3xf32>) -> tensor<1x1500x3xf32>\r\n  %744:4 = \"tf.TFLite_Detection_PostProcess\"(%728, %743, %cst_1) {_output_quantized = true, _output_types = [f32, f32, f32, f32], _support_output_type_float_in_quantized_op = true, detections_per_class = 100 : i64, device = \"\", h_scale = 5.000000e+00 : f32, max_classes_per_detection = 1 : i64, max_detections = 10 : i64, nms_iou_threshold = 5.000000e-01 : f32, nms_score_threshold = 9.99999993E-9 : f32, num_classes = 2 : i64, use_regular_nms = false, w_scale = 5.000000e+00 : f32, x_scale = 1.000000e+01 : f32, y_scale = 1.000000e+01 : f32} : (tensor<1x1500x4xf32>, tensor<1x1500x3xf32>, tensor<1500x4xf32>) -> (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)\r\n  \"std.return\"(%744#0, %744#1, %744#2, %744#3) : (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"normalized_input_image_tensor\", outputs = \"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\"}, type = (tensor<1x300x300x3xf32>) -> (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)} : () -> ()\r\n```\r\n", "> the Rider-384-484-images download link is [here](url)\r\n\r\n@wwdok,\r\nThe `url` you've given redirects to `https://github.com/tensorflow/tensorflow/issues/url`.\r\n\r\nCould you please provide the link to the dataset along with the latest code you are running, so that we can reproduce the issue on our end?\r\n\r\nAlso, please paste the error log instead of the screenshot. It would be easier for us to read and debug. Thanks!", "@amahendrakar Hi, sorry for the mistake, i have update above comment, the error log isvery long, here i only paste the last part of it, thanks !", "On running the code with TF v2.3, Colab session crashes. \r\n\r\nHowever, with TF v2.4 and TF-nightly, I'm facing an error stating `'tf.TFLite_Detection_PostProcess' op is neither a custom op nor a flex op`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5c5848cddcbb959122cfe22d86e54aa2/45302-tf-nightly.ipynb). Thanks!", "You need to add `TFLITE_BUILTINS` here:\r\n\r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\r\n```\r\n\r\nThe post-processing (NMS) in SSD models cannot be quantized, so you need to mention that as well during quantization :-)", "@wwdok \r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45302\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45302\">No</a>\n"]}, {"number": 45301, "title": "I am trying to convert yolov3 to a full uint8 tflite model after, i got this error : Quantized not yet supported for op : 'EXP'", "body": "**System information**\r\n- I used Google Colab.\r\n- TensorFlow installed from google colab :\r\n- TensorFlow version 2.3.0, after I tried 2.3.1 and 2.4.0-rc2 (it gives the same error):\r\n\r\n**I'm using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook\r\nhttps://colab.research.google.com/drive/1i1gXJyVpiu9qngAiQEhMZoU1Q6LFKf0j#scrollTo=3CPc8AYBxa1U\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"yolov3-416\")\r\ndef representative_dataset_gen():\r\n    for _ in range(250):\r\n        yield [tf.random.uniform(shape=[1, 416, 416, 3], minval=0.0, maxval=1.0, dtype=tf.dtypes.float32)]\r\n\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]    \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.allow_custom_ops = True\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.inference_input_type = tf.int8  # or tf.uint8\r\nconverter.inference_output_type = tf.int8  # or tf.uint8\r\ntflite_quant_model_uint8_io = converter.convert()\r\n# Save the model.\r\nwith open('tflite_quant_model_uint8_io.tflite', 'wb') as f:\r\n  f.write(tflite_quant_model_uint8_io)\r\n\r\n**The output from the converter invocation**\r\nTraceback (most recent call last):\r\n  File \"convertToTflite_uint8_io.py\", line 15, in <module>\r\n    tflite_quant_model_uint8_io = converter.convert()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\", line 742, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\", line 461, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py\", line 104, in calibrate_and_quantize\r\n    np.dtype(activations_type.as_numpy_dtype()).num)\r\nRuntimeError: Quantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'.\r\nQuantization not yet supported for op: 'EXP'\r\n", "comments": ["@Tieckby \r\n\r\nPlease, grant me the access for the colab link you have provided. Thanks!", "https://colab.research.google.com/drive/10BCL6_F5RQz_mMsB7VIKU8dABFJswlBB\n\nShare link\n\nOn Tue, Dec 1, 2020, 16:46 ravikyram <notifications@github.com> wrote:\n\n> @Tieckby <https://github.com/Tieckby>\n>\n> Please, grant me the access for the colab link you have provided. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45301#issuecomment-736674136>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AMBZXSBRVI7AQGTVIENWVF3SSUMUXANCNFSM4UJEDNZQ>\n> .\n>\n", "Have you solved the problem? I met the same problem while transform the pb file into tflite file.", "Not yet\n\nOn Thu, Dec 3, 2020, 3:32 AM Alxendx <notifications@github.com> wrote:\n\n> Have you solved the problem? I met the same problem while transform the pb\n> file into tflite file.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45301#issuecomment-737643056>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AMBZXSFAG6PN7P6DPTI4QDTSS4BD3ANCNFSM4UJEDNZQ>\n> .\n>\n", "@Tieckby It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.6 and let us know if the issue still persists? Please have a look at the similar [issue ](https://stackoverflow.com/questions/67176489/convert-from-saved-model-to-quant-tflite-quantization-not-yet-supported-for-o)and let us know if it helps ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45301\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45301\">No</a>\n"]}, {"number": 45300, "title": "TF 2.4.0-rc3: Mismatched protobuf version in setup.py and workspace.bzl", "body": "Protobuf version in `tensorflow/workspace.bzl` and `tensorflow/tools/pip_package/setup.py` aren't same in TF 2.4.0-rc3.\r\nsetup.py has protobuf 3.13 and workspace.bzl still fetches 3.9.2 during the build. Same is the case with master branch.\r\nIs this intentional or to be done item?\r\n\r\n", "comments": ["The one in workspace is used when compiling whereas the one in `setup.py` is needed at `pip install` time.\r\n\r\nThis is something that we should fix, but is there a bug that results from this? So we know how to prioritize?", "According to: https://abi-laboratory.pro/?view=timeline&l=protobuf\r\nprotobuf 3.9 and 3.13 are not compatible (even the soname has changed). I'd think you'd want to ensure matching internal and external function, no?", "Hmm, you are right. Yes, this is something we need to fix. Thank you", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45300\">No</a>\n"]}, {"number": 45299, "title": "Tensorflow GPU stuck at epoch 1 on rtx3070 gpu", "body": "tensorflow is not running corectly on rtx3070 gpu same code is running well on gtx1050 ti and on cpu but when i run it on gpu it take 5 min than print last 2 line saying Epoch 1/1 and it stucks there please help\r\n\r\n\r\n2020-12-01 18:08:04.785338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nUsing TensorFlow backend.\r\n2020-12-01 18:08:06.705948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-12-01 18:08:06.732000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-12-01 18:08:06.732171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-01 18:08:06.735229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-01 18:08:06.738060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-01 18:08:06.739052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-12-01 18:08:06.742158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-01 18:08:06.743937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2.1.0\r\n2020-12-01 18:08:06.751015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-01 18:08:06.751155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-12-01 18:08:06.795732: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2020-12-01 18:08:06.798286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-12-01 18:08:06.798450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-12-01 18:08:06.798533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-12-01 18:08:06.798613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-12-01 18:08:06.798693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-12-01 18:08:06.798774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-12-01 18:08:06.798858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-12-01 18:08:06.798941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-01 18:08:06.799044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-12-01 18:10:40.051239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-12-01 18:10:40.051340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-12-01 18:10:40.051396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-12-01 18:10:40.052361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6254 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2940 2940 1260 1260\r\nEpoch 1/1\r\n2020-12-01 18:10:41.127488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): conda install tensorflow-gpu==2.1.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:cuda 10.1 , cudnn 7.6\r\n- GPU model and memory: rtx 3070 8 gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n2020-12-01 18:15:14.820555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nunknown 2.1.0\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Im having the same issue with rtx 3080. im using a conda tf-gpu env and every time i try to train a trivial model it sometime freezes on \r\n`2020-12-01 23:03:19.344280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-12-01 23:03:19.344355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0`\r\n\r\nand other times when it magicaly decides to work it freezes exactly the same spot yours does.\r\n `Train for 2276 steps, validate for 23 steps\r\nEpoch 1/2\r\n2020-12-01 23:06:50.959111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll`\r\n\r\nalso when i checked the gpu memory usage\r\n\r\n![Capture](https://user-images.githubusercontent.com/37509362/100785595-4ec90600-342a-11eb-8b02-c17c0e03c424.PNG)\r\n\r\nIve been searching for a fix haven't gotten anywhere.", "Solved it by uninstall cuda 10, and tensorflow-gpu reinstalling cuda 11.1 with cudnn 8, then after changing environment variable i installed tensorflow nightly using \"pip install tf-nightly-gpu\" after this i got error not found .dll files. then i uninstalled python which i installed from windows app store\nAnd re installed python 3.8 from official website. It solved problem for me.", "@game-sys,\r\nThank you for the update. Marking this issues as close, as it is resolved. Please feel free to re-open if necessary. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45299\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45299\">No</a>\n", "@AhmedRAlmansoori,\r\nPlease take a look at @game-sys's comment and check if it helps.\r\n\r\nIf the issue still persists, submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track it there. Thanks!", "Ive done the same as @game-sys and it worked. Thanks for the help", "> Solved it by uninstall cuda 10, and tensorflow-gpu reinstalling cuda 11.1 with cudnn 8, then after changing environment variable i installed tensorflow nightly using \"pip install tf-nightly-gpu\" after this i got error not found .dll files. then i uninstalled python which i installed from windows app store\r\n> And re installed python 3.8 from official website. It solved problem for me.\r\n\r\nI just want to say a big thank you to you and hope you have a great day! I have been searching for solutions and bingo!", "Solved the issue using the configuration mentioned at the following link:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/45285#issuecomment-822640988", "@game-sys Sorry to bother you. I use this method. But it still stuck on first epoch.\r\nBelow is my issue.\r\n#49826 ", "@er778899789 did you install python from Windows store or official website?"]}, {"number": 45298, "title": "Fix can't get a replica variable bug when use recompute_grad", "body": "Fix can't get a replica variable bug when use recompute_grad in the graph mode which is reported in https://github.com/google/automl/issues/886.", "comments": ["This is a TF1 only bug-fix? Since we have no more TF1 releases, how does this help?\r\ncc @w-xinyi to help review as well from dist strat side.", "@fsx950223  Can you please resolve conflicts? Thanks!\r\n", "Done", "@w-xinyi-zz  Can you please review this PR ? Thanks!", "@w-xinyi-zz  Can you please review this PR ? Thanks!", "@w-xinyi-zz Can you please review this PR ? Thanks!", "Hi @fsx950223,\r\n\r\nOne thing that came up as Rohan and I were discussing: we're trying to keep tf.distribute layered cleanly on top of \"core\" tensorflow as much as possible. The change itself looked fine, but would you mind structuring the tests as (a) a unit test with a stand-in custom tf.Variable subclass (whatever's easy, just to trigger the .op issue) but not tf.distribute, and (b) an integration test using custom_gradient/recompute_grad (rather than the get_dependent_variables helper, i.e. public symbols) + tf.distribute which lives in tensorflow/python/distribute.\r\n\r\n(b) is optional, but it's probably useful to have an integration test anyway.", "> Hi @fsx950223,\r\n> \r\n> One thing that came up as Rohan and I were discussing: we're trying to keep tf.distribute layered cleanly on top of \"core\" tensorflow as much as possible. The change itself looked fine, but would you mind structuring the tests as (a) a unit test with a stand-in custom tf.Variable subclass (whatever's easy, just to trigger the .op issue) but not tf.distribute, and (b) an integration test using custom_gradient/recompute_grad (rather than the get_dependent_variables helper, i.e. public symbols) + tf.distribute which lives in tensorflow/python/distribute.\r\n> \r\n> (b) is optional, but it's probably useful to have an integration test anyway.\r\n\r\nDo you know how to create such a custom variable?", "> Hi @fsx950223,\r\n> \r\n> One thing that came up as Rohan and I were discussing: we're trying to keep tf.distribute layered cleanly on top of \"core\" tensorflow as much as possible. The change itself looked fine, but would you mind structuring the tests as (a) a unit test with a stand-in custom tf.Variable subclass (whatever's easy, just to trigger the .op issue) but not tf.distribute, and (b) an integration test using custom_gradient/recompute_grad (rather than the get_dependent_variables helper, i.e. public symbols) + tf.distribute which lives in tensorflow/python/distribute.\r\n> \r\n> (b) is optional, but it's probably useful to have an integration test anyway.\r\n\r\nI have finished task a. I'm going to add an integration test, where should I put it?", "I'd put the integration test in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/mirrored_variable_test.py\r\n\r\nAnd you can subclass ResourceVariable to e.g. override the `op` property to throw an error: https://github.com/tensorflow/tensorflow/blob/17f694077ee5228eb20a8e228e88cd3987e6b854/tensorflow/python/ops/resource_variable_ops.py#L1461", "Looks like the newly added test is failing,\r\n\r\n```\r\nERROR: testGetVariableByName (__main__.GetDependentVariablesTest)\r\nGetDependentVariablesTest.testGetVariableByName\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"[...]tensorflow/python/ops/gradients_test.py\", line 1033, in testGetVariableByName\r\n    var2 = custom_gradient.get_variable_by_name(\"a\")\r\n  File \"[...]tensorflow/python/ops/custom_gradient.py\", line 330, in get_variable_by_name\r\n    raise ValueError(\"Unsuccessful at finding variable {}.\".format(var_name))\r\nValueError: Unsuccessful at finding variable a.\r\n```\r\n\r\nIt's [tagged not to run in the outside-Google presubmits](https://github.com/tensorflow/tensorflow/blob/371d215a7b40bc083f593e353f775ae71d73f2c4/tensorflow/python/BUILD#L2699) because it was flaky on GPU a few years ago... you may want to run it manually for now, or try removing the tag.", "> Looks like the newly added test is failing,\r\n> \r\n> ```\r\n> ERROR: testGetVariableByName (__main__.GetDependentVariablesTest)\r\n> GetDependentVariablesTest.testGetVariableByName\r\n> ----------------------------------------------------------------------\r\n> Traceback (most recent call last):\r\n>   File \"[...]tensorflow/python/ops/gradients_test.py\", line 1033, in testGetVariableByName\r\n>     var2 = custom_gradient.get_variable_by_name(\"a\")\r\n>   File \"[...]tensorflow/python/ops/custom_gradient.py\", line 330, in get_variable_by_name\r\n>     raise ValueError(\"Unsuccessful at finding variable {}.\".format(var_name))\r\n> ValueError: Unsuccessful at finding variable a.\r\n> ```\r\n> \r\n> It's [tagged not to run in the outside-Google presubmits](https://github.com/tensorflow/tensorflow/blob/371d215a7b40bc083f593e353f775ae71d73f2c4/tensorflow/python/BUILD#L2699) because it was flaky on GPU a few years ago... you may want to run it manually for now, or try removing the tag.\r\n\r\nIt passes the test again and it passes my local tests too.", "Maybe decorate it with `@test_util.run_v2_only`. It was probably failing in 1.x mode with reference variables.", "> Maybe decorate it with `@test_util.run_v2_only`. It was probably failing in 1.x mode with reference variables.\r\n\r\nDone"]}, {"number": 45297, "title": "randomly discontinuation when model training with tf.keras in tf-gpu-2.1", "body": "When I use model.fit to train my model, I get the below errors randomly at the beginning of the steps, or the code and gpus suddenly shut down without any error. Even sometimes self-reset occurs. \r\n\r\nPython Version: 3.7\r\nTesorflow Version: 2.1\r\nOS: Windows 10\r\nGPU Card: RTX 2080Ti * 4\r\nCUDA: 10.1\r\nCUDNN: 7.6.5.32\r\n\r\nerrors as follows\r\n E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\n F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1", "comments": ["@jianku122 \r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "**code like this**\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Activation, Masking, TimeDistributed, LSTM, Bidirectional\r\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\nfrom tensorflow.keras import backend as K\r\n\r\nDUMMY_VALUE = -1.0\r\n\r\nmodel = Sequential()\r\nmodel.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 100)))\r\nmodel.add(Bidirectional(LSTM(100, return_sequences=True, implementation=1)))\r\nmodel.add(TimeDistributed(Dense(1, activation='sigmoid')))\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy', K_precision, K_recall],\r\n              sample_weight_mode='temporal')\r\nmodel.summary()\r\n\r\nmodelName = 'test'\r\ncheckpoint = ModelCheckpoint(filepath='./model_checkpoints/{epoch:02d}-{val_loss:.4f}_' + modelName + '.h5', verbose=1, save_best_only=True, mode='min')\r\nes = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\r\n\r\nhistories = []\r\nhistories.append( model.fit(padding_x, padding_y, epochs=30, batch_size=2, validation_split=0.1, callbacks=[es, checkpoint], sample_weight=w) )\r\nmodel.save(modelName + '.h5')\r\n\r\n**error occurs like this**\r\n......\r\n  49/2000 [..............................] - ETA: 2:29:49 - loss: 0.0072 - accuracy: 0.8820\r\n  50/2000 [..............................] - ETA: 2:27:52 - loss: 0.0071 - accuracy: 0.8822\r\n  51/2000 [..............................] - ETA: 2:25:58 - loss: 0.0070 - accuracy: 0.8835\r\n  52/2000 [..............................] - ETA: 2:24:08 - loss: 0.0069 - accuracy: 0.8853\r\n2020-12-01 19:55:35.557321: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\n2020-12-01 19:55:35.557718: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\n", "@jianku122 \r\n\r\nPlease, share colab link or complete code snippet with supporting files to reproduce the issue in our environment.I am seeing the error messages (`NameError: name 'K_precision' is not defined`).Request you to share reproducible code and helps using localizing the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45296, "title": "[tflite] map leaky relu to prelu to use NNAPI", "body": "Leaky ReLU is one of the widely used activation functions. However it's not supported by NNAPI, so it's unlikely to\r\naccelerate a model with many Leaky ReLU ops. Fortunately, NNAPI 1.2 supports PReLU, which is a general case of Leaky\r\nReLU. So we can map Leaky ReLU to PReLU. With that, we can fully delegate models, such as the [TFLite super\r\nresolution example,](https://github.com/tensorflow/examples/tree/master/lite/examples/super_resolution/android) to NNAPI.", "comments": ["@miaowang14 could you take a look at this PR?\r\n", "@miaowang14 Thanks. I'll add a simple test.", "I stole test cases from [kernel activation tests](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/activations_test.cc). Tested on both a Pixel 4 and a MTK Dimensity 1000+ device.\r\n```\r\n$ LD_LIBRARY_PATH=nnapi_libs ./nnapi_delegate_test --gtest_filter=NNAPIDelegate.LeakyRelu*\r\nNote: Google Test filter = NNAPIDelegate.LeakyRelu*\r\n[==========] Running 2 tests from 1 test suite.\r\n[----------] Global test environment set-up.\r\n[----------] 2 tests from NNAPIDelegate\r\n[ RUN      ] NNAPIDelegate.LeakyReluFloat\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nINFO: Initialized TensorFlow Lite runtime.\r\nHaving a manually-set TfLite delegate, and bypassing KernelTestDelegateProviders\r\n[       OK ] NNAPIDelegate.LeakyReluFloat (143 ms)\r\n[ RUN      ] NNAPIDelegate.LeakyReluQuantized\r\nHaving a manually-set TfLite delegate, and bypassing KernelTestDelegateProviders\r\n[       OK ] NNAPIDelegate.LeakyReluQuantized (5 ms)\r\n[----------] 2 tests from NNAPIDelegate (148 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 2 tests from 1 test suite ran. (148 ms total)\r\n[  PASSED  ] 2 tests.\r\n\r\n```"]}, {"number": 45295, "title": "module 'gast' has no attribute 'Ellipsis'", "body": "``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom tqdm.autonotebook import tqdm\r\n%matplotlib inline\r\nfrom IPython import display\r\nimport pandas as pd\r\nimport tensorflow_probability as tfp\r\nds = tfp.distribution\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/46621519/100713763-c0379300-33ef-11eb-81ea-3938e2204309.png)\r\n\r\n\r\n\r\n", "comments": ["@bruceh191,\r\nI was able to import the modules without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e18e9ecad4fb482867f70ce49ed513c3/45295.ipynb#scrollTo=ZzZGjfOAeN5s).\r\n\r\nPlease provide the following information, so that we can look into this \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nThanks!", "Also, what version of `gast` are you using.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45295\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45295\">No</a>\n"]}, {"number": 45294, "title": "Resource Excuted error while training object detection model in google colab", "body": "i try to train model  Google  Colab using gpu . while training at one time i got error like rosirce exvuted error  OMM like this. i don't understand why i got this error. Please help me to sort it out this error.", "comments": ["@RD191295 \r\nMemory error indicates that the process has consumed all of the ram memory. You may want to reduce the batch size/image size and try again. [please refer to #38414] ", "I am using batch size : 16 and image size is 420x420. Train.record file size is 2 mb.. ", "Even it not start 1 epoch also and  before that only memory was consumed... ", "@RD191295 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "\r\n\r\nError while using model_main_tf2.py file for training object detection model i got such error:\r\n\r\n2020-12-02 03:59:43.514873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-12-02 03:59:46.353952: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-12-02 03:59:46.363592: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-12-02 03:59:46.363634: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f6a8f84517f0): /proc/driver/nvidia/version does not exist\r\n2020-12-02 03:59:46.363975: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-02 03:59:46.378641: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000160000 Hz\r\n2020-12-02 03:59:46.378943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1df1100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-02 03:59:46.378979: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\r\nW1202 03:59:46.381007 139968975648640 cross_device_ops.py:1202] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nI1202 03:59:46.381281 139968975648640 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nINFO:tensorflow:Maybe overwriting train_steps: None\r\nI1202 03:59:46.746428 139968975648640 config_util.py:552] Maybe overwriting train_steps: None\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI1202 03:59:46.746670 139968975648640 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Reading unweighted datasets: ['annotations/train.record']\r\nI1202 03:59:46.797454 139968975648640 dataset_builder.py:148] Reading unweighted datasets: ['annotations/train.record']\r\nINFO:tensorflow:Reading record datasets for input file: ['annotations/train.record']\r\nI1202 03:59:46.798697 139968975648640 dataset_builder.py:77] Reading record datasets for input file: ['annotations/train.record']\r\nINFO:tensorflow:Number of filenames to read: 1\r\nI1202 03:59:46.798857 139968975648640 dataset_builder.py:78] Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW1202 03:59:46.798953 139968975648640 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\r\nW1202 03:59:46.809036 139968975648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW1202 03:59:46.855802 139968975648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nW1202 03:59:53.997627 139968975648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW1202 03:59:56.998954 139968975648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW1202 03:59:58.767645 139968975648640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/inputs.py:281: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/model_lib_v2.py:349: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\r\nInstructions for updating:\r\nSimply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\nW1202 04:00:05.767568 139967178823424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/model_lib_v2.py:349: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\r\nInstructions for updating:\r\nSimply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\r\nW1202 04:01:09.248560 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._groundtruth_lists\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\r\nW1202 04:01:09.248836 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\r\nW1202 04:01:09.248930 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\r\nW1202 04:01:09.249010 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\r\nW1202 04:01:09.249088 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\r\nW1202 04:01:09.249185 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\r\nW1202 04:01:09.249259 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\r\nW1202 04:01:09.249329 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\r\nW1202 04:01:09.249399 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\r\nW1202 04:01:09.249469 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\r\nW1202 04:01:09.249538 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\r\nW1202 04:01:09.249608 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\r\nW1202 04:01:09.249683 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\r\nW1202 04:01:09.249752 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\r\nW1202 04:01:09.249820 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.3\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\r\nW1202 04:01:09.249889 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._additional_projection_layers.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\r\nW1202 04:01:09.249957 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\r\nW1202 04:01:09.250025 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\r\nW1202 04:01:09.250095 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\r\nW1202 04:01:09.250177 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\r\nW1202 04:01:09.250265 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\r\nW1202 04:01:09.250335 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\r\nW1202 04:01:09.250405 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\r\nW1202 04:01:09.250473 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\r\nW1202 04:01:09.250540 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\r\nW1202 04:01:09.250608 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\r\nW1202 04:01:09.250680 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\r\nW1202 04:01:09.250749 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\r\nW1202 04:01:09.250827 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\r\nW1202 04:01:09.250896 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\r\nW1202 04:01:09.250964 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\r\nW1202 04:01:09.251032 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\r\nW1202 04:01:09.251099 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\r\nW1202 04:01:09.251187 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\r\nW1202 04:01:09.251255 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.3\r\nW1202 04:01:09.251323 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.3\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\r\nW1202 04:01:09.251391 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\r\nW1202 04:01:09.251462 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\r\nW1202 04:01:09.251529 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3\r\nW1202 04:01:09.251596 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.kernel\r\nW1202 04:01:09.251727 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\r\nW1202 04:01:09.251800 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._box_prediction_head._box_encoder_layers.0.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\r\nW1202 04:01:09.251870 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\r\nW1202 04:01:09.251940 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\r\nW1202 04:01:09.252009 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\r\nW1202 04:01:09.252078 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\r\nW1202 04:01:09.252158 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\r\nW1202 04:01:09.252232 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\r\nW1202 04:01:09.252305 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10\r\nW1202 04:01:09.252373 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.11\r\nW1202 04:01:09.252442 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\r\nW1202 04:01:09.252510 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\r\nW1202 04:01:09.252578 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\r\nW1202 04:01:09.252645 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\r\nW1202 04:01:09.252848 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\r\nW1202 04:01:09.252990 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\r\nW1202 04:01:09.253071 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10\r\nW1202 04:01:09.253171 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.11\r\nW1202 04:01:09.253247 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\r\nW1202 04:01:09.253319 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\r\nW1202 04:01:09.253390 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\r\nW1202 04:01:09.253459 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\r\nW1202 04:01:09.253533 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\r\nW1202 04:01:09.253602 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\r\nW1202 04:01:09.285281 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10\r\nW1202 04:01:09.285442 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.11\r\nW1202 04:01:09.285610 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\r\nW1202 04:01:09.285717 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\r\nW1202 04:01:09.285815 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\r\nW1202 04:01:09.285911 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\r\nW1202 04:01:09.286005 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\r\nW1202 04:01:09.286098 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\r\nW1202 04:01:09.286211 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10\r\nW1202 04:01:09.286303 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.11\r\nW1202 04:01:09.286394 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\r\nW1202 04:01:09.286501 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\r\nW1202 04:01:09.286594 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\r\nW1202 04:01:09.286685 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\r\nW1202 04:01:09.286776 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\r\nW1202 04:01:09.286867 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\r\nW1202 04:01:09.286958 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10\r\nW1202 04:01:09.287050 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.11\r\nW1202 04:01:09.287165 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\r\nW1202 04:01:09.287259 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\r\nW1202 04:01:09.287367 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\r\nW1202 04:01:09.287471 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\r\nW1202 04:01:09.287569 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\r\nW1202 04:01:09.287662 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\r\nW1202 04:01:09.287754 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10\r\nW1202 04:01:09.287846 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.11\r\nW1202 04:01:09.287938 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\r\nW1202 04:01:09.288027 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\r\nW1202 04:01:09.288133 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\r\nW1202 04:01:09.288230 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\r\nW1202 04:01:09.288321 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\r\nW1202 04:01:09.288414 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\r\nW1202 04:01:09.288517 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10\r\nW1202 04:01:09.288609 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.11\r\nW1202 04:01:09.288700 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\r\nW1202 04:01:09.288791 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\r\nW1202 04:01:09.288893 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\r\nW1202 04:01:09.288988 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\r\nW1202 04:01:09.289080 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\r\nW1202 04:01:09.289196 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\r\nW1202 04:01:09.289291 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10\r\nW1202 04:01:09.289384 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.11\r\nW1202 04:01:09.289486 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\r\nW1202 04:01:09.289583 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\r\nW1202 04:01:09.289687 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\r\nW1202 04:01:09.289780 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\r\nW1202 04:01:09.289871 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\r\nW1202 04:01:09.289962 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\r\nW1202 04:01:09.290054 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10\r\nW1202 04:01:09.290166 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.11\r\nW1202 04:01:09.290261 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\r\nW1202 04:01:09.290352 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\r\nW1202 04:01:09.290443 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\r\nW1202 04:01:09.290563 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\r\nW1202 04:01:09.290657 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.5\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\r\nW1202 04:01:09.290749 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\r\nW1202 04:01:09.290840 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.8\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10\r\nW1202 04:01:09.290930 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.11\r\nW1202 04:01:09.291022 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.11\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.kernel\r\nW1202 04:01:09.291135 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.kernel\r\nW1202 04:01:09.291225 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.1.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.kernel\r\nW1202 04:01:09.291299 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.2.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.3.kernel\r\nW1202 04:01:09.291373 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.BoxPredictionTower.3.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.kernel\r\nW1202 04:01:09.291445 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.kernel\r\nW1202 04:01:09.291541 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.1.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.kernel\r\nW1202 04:01:09.291625 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.2.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3.kernel\r\nW1202 04:01:09.291713 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._head_scope_conv_layers.ClassPredictionTower.3.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.kernel\r\nW1202 04:01:09.291809 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\r\nW1202 04:01:09.291902 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background._class_predictor_layers.0.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\r\nW1202 04:01:09.291993 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\r\nW1202 04:01:09.292086 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\r\nW1202 04:01:09.292200 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\r\nW1202 04:01:09.292292 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\r\nW1202 04:01:09.292385 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\r\nW1202 04:01:09.292486 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\r\nW1202 04:01:09.292579 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\r\nW1202 04:01:09.292668 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\r\nW1202 04:01:09.292760 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\r\nW1202 04:01:09.292850 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\r\nW1202 04:01:09.292940 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\r\nW1202 04:01:09.293032 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\r\nW1202 04:01:09.293139 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\r\nW1202 04:01:09.293234 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\r\nW1202 04:01:09.293324 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.axis\r\nW1202 04:01:09.293414 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.gamma\r\nW1202 04:01:09.293516 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.beta\r\nW1202 04:01:09.293607 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_mean\r\nW1202 04:01:09.293696 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_variance\r\nW1202 04:01:09.293787 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.0.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\r\nW1202 04:01:09.293876 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\r\nW1202 04:01:09.293964 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\r\nW1202 04:01:09.294054 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\r\nW1202 04:01:09.294163 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\r\nW1202 04:01:09.294256 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\r\nW1202 04:01:09.294346 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\r\nW1202 04:01:09.294436 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\r\nW1202 04:01:09.294542 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\r\nW1202 04:01:09.294632 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\r\nW1202 04:01:09.294722 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\r\nW1202 04:01:09.294812 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\r\nW1202 04:01:09.294901 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\r\nW1202 04:01:09.294990 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\r\nW1202 04:01:09.295081 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\r\nW1202 04:01:09.295197 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.axis\r\nW1202 04:01:09.295289 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.gamma\r\nW1202 04:01:09.295379 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.beta\r\nW1202 04:01:09.295476 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_mean\r\nW1202 04:01:09.295570 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_variance\r\nW1202 04:01:09.295660 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.1.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\r\nW1202 04:01:09.295750 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\r\nW1202 04:01:09.295839 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\r\nW1202 04:01:09.295930 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\r\nW1202 04:01:09.296020 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\r\nW1202 04:01:09.296135 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\r\nW1202 04:01:09.296241 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\r\nW1202 04:01:09.296343 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\r\nW1202 04:01:09.296441 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\r\nW1202 04:01:09.296549 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\r\nW1202 04:01:09.296645 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\r\nW1202 04:01:09.296737 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\r\nW1202 04:01:09.296827 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\r\nW1202 04:01:09.296920 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\r\nW1202 04:01:09.297011 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\r\nW1202 04:01:09.297102 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.axis\r\nW1202 04:01:09.297217 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.gamma\r\nW1202 04:01:09.297323 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.beta\r\nW1202 04:01:09.297431 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_mean\r\nW1202 04:01:09.297546 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_variance\r\nW1202 04:01:09.297646 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.2.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\r\nW1202 04:01:09.297748 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\r\nW1202 04:01:09.297846 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\r\nW1202 04:01:09.297944 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\r\nW1202 04:01:09.298043 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\r\nW1202 04:01:09.298164 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\r\nW1202 04:01:09.298264 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\r\nW1202 04:01:09.298358 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\r\nW1202 04:01:09.298451 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\r\nW1202 04:01:09.298556 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\r\nW1202 04:01:09.298647 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\r\nW1202 04:01:09.298739 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\r\nW1202 04:01:09.298830 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\r\nW1202 04:01:09.298920 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\r\nW1202 04:01:09.299080 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\r\nW1202 04:01:09.299198 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.axis\r\nW1202 04:01:09.299287 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.gamma\r\nW1202 04:01:09.299375 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.beta\r\nW1202 04:01:09.299474 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_mean\r\nW1202 04:01:09.299570 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_variance\r\nW1202 04:01:09.299663 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.3.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\r\nW1202 04:01:09.299754 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\r\nW1202 04:01:09.299844 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\r\nW1202 04:01:09.299934 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\r\nW1202 04:01:09.300027 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\r\nW1202 04:01:09.300138 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\r\nW1202 04:01:09.300239 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\r\nW1202 04:01:09.300330 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\r\nW1202 04:01:09.300421 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\r\nW1202 04:01:09.300543 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\r\nW1202 04:01:09.300635 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\r\nW1202 04:01:09.300725 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\r\nW1202 04:01:09.300814 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\r\nW1202 04:01:09.300901 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\r\nW1202 04:01:09.300991 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\r\nW1202 04:01:09.301081 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.axis\r\nW1202 04:01:09.301195 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.gamma\r\nW1202 04:01:09.301287 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.beta\r\nW1202 04:01:09.301376 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_mean\r\nW1202 04:01:09.301474 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_variance\r\nW1202 04:01:09.301568 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.box_encodings.4.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\r\nW1202 04:01:09.301657 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\r\nW1202 04:01:09.301751 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\r\nW1202 04:01:09.301854 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\r\nW1202 04:01:09.301948 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\r\nW1202 04:01:09.302040 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\r\nW1202 04:01:09.302148 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\r\nW1202 04:01:09.302243 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\r\nW1202 04:01:09.302335 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\r\nW1202 04:01:09.302425 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\r\nW1202 04:01:09.302532 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\r\nW1202 04:01:09.302625 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\r\nW1202 04:01:09.302716 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\r\nW1202 04:01:09.302806 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\r\nW1202 04:01:09.302897 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\r\nW1202 04:01:09.302988 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.axis\r\nW1202 04:01:09.303080 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.gamma\r\nW1202 04:01:09.303195 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.beta\r\nW1202 04:01:09.303288 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.moving_mean\r\nW1202 04:01:09.303380 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.moving_variance\r\nW1202 04:01:09.303481 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.0.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\r\nW1202 04:01:09.303578 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\r\nW1202 04:01:09.303669 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\r\nW1202 04:01:09.303761 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\r\nW1202 04:01:09.303853 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\r\nW1202 04:01:09.303945 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\r\nW1202 04:01:09.304039 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\r\nW1202 04:01:09.304150 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\r\nW1202 04:01:09.304247 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\r\nW1202 04:01:09.304339 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\r\nW1202 04:01:09.304429 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\r\nW1202 04:01:09.304537 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\r\nW1202 04:01:09.304629 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\r\nW1202 04:01:09.304721 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\r\nW1202 04:01:09.304825 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\r\nW1202 04:01:09.304926 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.axis\r\nW1202 04:01:09.305020 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.gamma\r\nW1202 04:01:09.305129 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.beta\r\nW1202 04:01:09.305229 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.moving_mean\r\nW1202 04:01:09.305321 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.moving_variance\r\nW1202 04:01:09.305412 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.1.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\r\nW1202 04:01:09.305523 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\r\nW1202 04:01:09.305616 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\r\nW1202 04:01:09.305707 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\r\nW1202 04:01:09.305800 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\r\nW1202 04:01:09.305892 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\r\nW1202 04:01:09.305984 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\r\nW1202 04:01:09.306077 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\r\nW1202 04:01:09.306190 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\r\nW1202 04:01:09.306279 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\r\nW1202 04:01:09.306370 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\r\nW1202 04:01:09.306471 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\r\nW1202 04:01:09.306568 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\r\nW1202 04:01:09.306660 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\r\nW1202 04:01:09.306752 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\r\nW1202 04:01:09.306843 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.axis\r\nW1202 04:01:09.306934 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.gamma\r\nW1202 04:01:09.307026 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.beta\r\nW1202 04:01:09.307137 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.moving_mean\r\nW1202 04:01:09.307235 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.moving_variance\r\nW1202 04:01:09.307340 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.2.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\r\nW1202 04:01:09.307433 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\r\nW1202 04:01:09.307536 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\r\nW1202 04:01:09.307627 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\r\nW1202 04:01:09.307717 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\r\nW1202 04:01:09.307809 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\r\nW1202 04:01:09.307898 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\r\nW1202 04:01:09.307989 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\r\nW1202 04:01:09.308081 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\r\nW1202 04:01:09.308195 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\r\nW1202 04:01:09.308287 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\r\nW1202 04:01:09.308378 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\r\nW1202 04:01:09.308478 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\r\nW1202 04:01:09.308572 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\r\nW1202 04:01:09.308662 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\r\nW1202 04:01:09.308753 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.axis\r\nW1202 04:01:09.308842 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.gamma\r\nW1202 04:01:09.308932 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.beta\r\nW1202 04:01:09.309022 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.moving_mean\r\nW1202 04:01:09.309128 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.moving_variance\r\nW1202 04:01:09.309227 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.3.10.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\r\nW1202 04:01:09.309318 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\r\nW1202 04:01:09.309406 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\r\nW1202 04:01:09.309510 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\r\nW1202 04:01:09.309603 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\r\nW1202 04:01:09.309691 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\r\nW1202 04:01:09.309781 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\r\nW1202 04:01:09.309865 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\r\nW1202 04:01:09.309954 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\r\nW1202 04:01:09.310052 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\r\nW1202 04:01:09.310163 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.4.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\r\nW1202 04:01:09.310254 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\r\nW1202 04:01:09.310358 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\r\nW1202 04:01:09.310447 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\r\nW1202 04:01:09.310563 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\r\nW1202 04:01:09.310655 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.axis\r\nW1202 04:01:09.310749 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.gamma\r\nW1202 04:01:09.310841 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.beta\r\nW1202 04:01:09.310931 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_mean\r\nW1202 04:01:09.311020 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_variance\r\nW1202 04:01:09.311125 139968975648640 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_variance\r\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\r\nW1202 04:01:09.311225 139968975648640 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse fn_output_signature instead\r\nW1202 04:01:25.383937 139967170430720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse fn_output_signature instead\r\n^C", "@RD191295 \r\nAs requested earlier please share simple stand alone code such that we can replicate the issue reported or if possible share a colab gist with the error.", "I try login from other gmail account it's working fine but if I do on that mail id I got that error!! Don't understand what is wrong with that account!! But account switch help me to solve problem", "@RD191295 \r\nPlease move the issue to closed status if resolved.", "Thank you for help!!", "Thank you for helping to solve issue"]}, {"number": 45293, "title": "Tensorflow Runtime error", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"model_main_tf2.py\", line 31, in <module>\r\n    import tensorflow.compat.v2 as tf\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\raj\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "When i Import tensorflow in python enviorment it is working fine but when i use model_main_tf2.py file for training it is giving this error.", "@RD191295 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download [the latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167\r\n\r\nThanks!", "i am using intel i3 processor and windows 10. visual c++ is already installed. system is 64 bit.", "seems like tensorflow is not installed properly with my system. can you please give some guide that help me to install correctly? i am using anaconda distribution.", "@RD191295 \r\n\r\nPlease, follow this [guide](https://www.tensorflow.org/install/pip) for installing Tensorflow.Also, please let me know your model number of cpu. Thanks!", "it 's intel (R)  Pentium(R)  3850U @ 1.90GHZ", "@RD191295 \r\n\r\n\r\nAs per Intel's [product specification](https://ark.intel.com/content/www/us/en/ark/products/84813/intel-pentium-processor-3805u-2m-cache-1-90-ghz.html), your CPU doesn't support AVX. For more information, please take a look at the [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements) to install TensorFlow with pip.\r\n\r\nAs an alternative in this case, you can [build TensorFlow from source](https://www.tensorflow.org/install/source_windows) or use [Google Colab](https://colab.research.google.com/). Thanks!", "i try to use Google co lab but it's encounter resource exhausted error while doing training.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45293\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45293\">No</a>\n"]}, {"number": 45292, "title": "[mbed] ERROR: Unable to write build ignore file ", "body": "hi,guys, when I compile the example project \"image_recognition_experimental\", a mbed error occurs.\r\n```\r\nsalt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$ sudo mbed compile -m auto -t GCC_ARM --profile release\r\n[sudo] password for salt: \r\n[mbed] Working path \"/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed\" (program)\r\n[mbed] Detected \"DISCO_F746NG\" connected to \"/media/salt/DIS_F746NG\" and using com port \"/dev/ttyACM0\"\r\n[mbed] ERROR: Unable to write build ignore file in \"/usr/local/project/tensorflow/BUILD/.mbedignore\"\r\n---\r\nBut the \"BUILD\" is not a folder, and does have write permission, just as follows,\r\n\r\nroot@ubuntu:/usr/local/project/tensorflow# ll\r\ntotal 580\r\ndrwxr-xr-x  8 root root   4096 Nov 30 17:08 ./\r\ndrwxr-xr-x  3 root root   4096 Nov 30 17:02 ../\r\n-rw-r--r--  1 root root   2219 Nov 30 17:02 ACKNOWLEDGMENTS\r\n-rw-r--r--  1 root root   1174 Nov 30 17:02 arm_compiler.BUILD\r\n-rw-r--r--  1 root root    349 Nov 30 17:02 AUTHORS\r\n-rw-r--r--  1 root root  32964 Nov 30 17:02 .bazelrc\r\n-rw-r--r--  1 root root      6 Nov 30 17:02 .bazelversion\r\n-rw-rw-rw-  1 root root    122 Nov 30 17:02 BUILD\r\n-rw-r--r--  1 root root   5360 Nov 30 17:02 CODE_OF_CONDUCT.md\r\n-rw-r--r--  1 root root    573 Nov 30 17:02 CODEOWNERS\r\n-rwxr-xr-x  1 root root    285 Nov 30 17:02 configure*\r\n-rw-r--r--  1 root root    782 Nov 30 17:02 configure.cmd\r\n-rw-r--r--  1 root root  53321 Nov 30 17:02 configure.py\r\n-rw-r--r--  1 root root   9906 Nov 30 17:02 CONTRIBUTING.md\r\ndrwxrwxrwx  8 root root   4096 Nov 30 17:08 .git/\r\ndrwxr-xr-x  4 root root   4096 Nov 30 17:02 .github/\r\n-rw-r--r--  1 root root    896 Nov 30 17:02 .gitignore\r\n-rw-r--r--  1 root root    606 Nov 30 17:02 ISSUES.md\r\n-rw-r--r--  1 root root   2232 Nov 30 17:02 ISSUE_TEMPLATE.md\r\n-rw-r--r--  1 root root  11419 Nov 30 17:02 LICENSE\r\n-rw-r--r--  1 root root      7 Nov 30 17:10 .mbed\r\ndrwxr-xr-x 19 root root   4096 Nov 30 17:07 mbed-os/\r\n-rw-r--r--  1 root root     77 Nov 30 17:07 mbed-os.lib\r\n-rw-r--r--  1 root root   1339 Nov 30 17:08 mbed_settings.py\r\n-rw-r--r--  1 root root    328 Nov 30 17:02 models.BUILD\r\n-rw-r--r--  1 root root     34 Nov 30 17:02 .pylintrc\r\n-rw-r--r--  1 root root  21169 Nov 30 17:02 README.md\r\n-rw-r--r--  1 root root 319193 Nov 30 17:02 RELEASE.md\r\n-rw-r--r--  1 root root  13158 Nov 30 17:02 SECURITY.md\r\ndrwxr-xr-x 16 root root   4096 Nov 30 17:02 tensorflow/\r\ndrwxr-xr-x 46 root root   4096 Nov 30 17:02 third_party/\r\ndrwxr-xr-x  2 root root   4096 Nov 30 17:02 tools/\r\n-rw-r--r--  1 root root   4246 Nov 30 17:02 WORKSPACE\r\nroot@ubuntu:/usr/local/project/tensorflow# cd BUILD \r\nbash: cd: BUILD: Not a directory\r\n\r\nThe content of BUILD is \r\n\r\nexports_files(\r\n    [\r\n        \"LICENSE\",\r\n        \"ACKNOWLEDGEMENTS\",\r\n        \"configure\",\r\n        \"configure.py\",\r\n    ],\r\n)\r\n```\r\nSo I really don't know why this error occurs, and how to solve it. I hope someone of you have a good idea about this, \r\n                                                                                                                                                                               Thanks a lot!", "comments": ["Did you install the [prerequisites](https://stackoverflow.com/a/63312051/11127923) as mentioned in the tutorial?", "hi ymodak,\r\nThank you very much for your answering,\r\n I installed just as that, I can show you what I have installed.\r\n```\r\nsalt@ubuntu:/usr$ python --version\r\nPython 2.7.17 (Python 3.8.0) I tryed both;\r\nsalt@ubuntu:/usr/local3$ pip --version\r\npip 9.0.1 from /usr/lib/python2.7/dist-packages (python 2.7)\r\nsalt@ubuntu:/usr/local$ mbed-cli --version\r\n1.10.5\r\n\r\n**mbed-os  and tensorflow  are same root addr.**\r\n\r\nsalt@ubuntu:/usr/local/project/tensorflow$ ls\r\nACKNOWLEDGMENTS     CODEOWNERS       ISSUE_TEMPLATE.md   __pycache__   tools\r\narm_compiler.BUILD  configure        LICENSE            README.md    WORKSPACE\r\nAUTHORS             configure.cmd    **mbed-os**            RELEASE.md\r\nBUILD               configure.py     mbed-os.lib        SECURITY.md       CONTRIBUTING.md  mbed_settings.py   **tensorflow**\r\nCODE_OF_CONDUCT.md  ISSUES.md        models.BUILD       third_party\r\n\r\nsalt@ubuntu:/usr/local$ ls\r\nbin  games    icetea_lib  lib  **project**  share\r\netc  **gcc-arm-none-eabi-9-2020-q2-update**  include     man  sbin     src\r\n\r\nsalt@ubuntu:/usr/local/project/tensorflow$ mbed config --list\r\n[mbed] Global config:\r\nGCC_ARM_PATH=/usr/local/gcc-arm-none-eabi-9-2020-q2-update/bin\r\n\r\n[mbed] Local config (/usr/local/project/tensorflow):\r\nNo local configuration is set\r\n\r\nBuilding and Compiling\r\n\r\nsalt@ubuntu:/usr/local/project/tensorflow$ _sudo make -f tensorflow/lite/micro/tools/make/Makefile TAGS=disco_f746ng generate_image_recognition_mbed_project_\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/Makefile:476: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/Makefile:476: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\nsalt@ubuntu:/usr/local/project/tensorflow$ _cd tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed/_\r\nsalt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$  _mbed config root ._\r\n[mbed] WARNING: Unable to write config file /usr/local/project/tensorflow/.mbed\r\n---\r\nsalt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$ _sudo  mbed config root ._\r\n[mbed] . now set as default root in program \"tensorflow\"\r\nsalt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$ _sudo mbed deploy_\r\n[mbed] Working path \"/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed\" (program)\r\n[mbed] Updating library \"\" to rev #4e0d07d50fdf\r\n[mbed] Updating library \"BSP_DISCO_F746NG\" to rev #df2ea349c37a\r\n[mbed] Updating library \"mbed-os\" to rev #4e0d07d50fdf\r\n[mbed] Updating library \"LCD_DISCO_F746NG\" to rev #d44525b1de98 (tag: tip)\r\nsalt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$ _sudo mbed compile -m auto -t GCC_ARM --profile release_\r\n[mbed] Working path \"/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed\" (program)\r\n[mbed] Detected \"DISCO_F746NG\" connected to \"/media/salt/DIS_F746NG\" and using com port \"/dev/ttyACM0\"\r\n[mbed] ERROR: Unable to write build ignore file in \"/usr/local/project/tensorflow/BUILD/.mbedignore\"\r\n```\r\n", "What TF version are you using? Can you try `tf-nightly` version and compile with `DISCO_F746NG` flag? \r\n`mbed compile -m DISCO_F746NG -t GCC_ARM --profile release`", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45292\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45292\">No</a>\n"]}, {"number": 45291, "title": "Unbalanced workload distribution on parameter server replicas in distributed tensorflow (parameter-server strategy)", "body": "\r\nHello everyone, i have been running various experiments using the parameter-server strategy for distributed tensorflow. My shows uneven distribution on workload for parameter servers replicas (some replicas get more work than others).  For example, i ran distributed job having (1master, 2parameter-servers, 1worker) using resnet50 model and observed the network traffic on the parameter servers. From the graph.pbtxt file i can see near balanced task assignments on both parameter-servers (3823 for `ps/task:0` & 3993 for `ps/task:1`) but from monitoring network activity, it seems like only 1 of the 2 parameter servers is actively participating in the training process. (see the network logs below in MBytes).\r\n\r\nUpon some preliminary searching i found that this problem stems from the fact that tensors are of different sizes and since tensorflow uses round-robin assignment, this could lead to unbalanced parameter assignments (https://github.com/tensorflow/tensorflow/issues/24953). However, this would have made sense if 1 parameter-server was facing 2x or 3x the traffic in comparison but my results show no activity at all for the second parameter-server which makes me wonder if its simply sitting idle?\r\n\r\n  \r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow version (v2.3):\r\n- Python version: v3.6\r\n- GPU model and memory: N/A (running on CPU cores)\r\n\r\n**Describe the current behavior**\r\nOnly one of the 2 parameter servers is showing network activity.\r\n\r\n**Describe the expected behavior**\r\nBoth parameter servers show be having near balanced network activity.\r\n\r\n\r\n`ps0`\r\n```\r\n-timeStamp -incomingTraffic -outgoingTraffic -totalTraffic\r\n1606778918 0 0 0\r\n1606778918 0 0 0\r\n1606778919 0 0 0\r\n1606778919 0 0 0\r\n1606778920 0 0 0\r\n1606778920 0 0 0\r\n1606778921 0 0 0\r\n1606778921 0 0 0\r\n1606778922 0 0 0\r\n1606778922 0 0 0\r\n1606778923 0 0 0\r\n1606778923 0 0 0\r\n1606778924 0 0 0\r\n1606778924 0 0 0\r\n1606778925 0 0 0\r\n1606778925 0 0 0\r\n1606778926 0 0 0\r\n1606778926 0 0 0\r\n1606778927 0 0 0\r\n1606778927 0 0 0\r\n1606778928 0 0 0\r\n1606778928 0 0 0\r\n1606778929 0 0 0\r\n1606778929 0 0 0\r\n1606778930 0 0 0\r\n1606778930 0 0 0\r\n1606778931 0 0 0\r\n1606778931 0 0 0\r\n1606778932 0 0 0\r\n1606778932 0 0 0\r\n1606778933 0 0 0\r\n1606778933 0 0 0\r\n1606778934 0 0 0\r\n1606778934 0 0 0\r\n1606778935 0 0 0\r\n1606778935 0 0 0\r\n1606778936 0 0 0\r\n1606778936 0 0 0\r\n1606778937 0 0 0\r\n1606778937 0 0 0\r\n1606778938 0 0 0\r\n1606778938 0 0 0\r\n1606778939 0 0 0\r\n1606778939 0 0 0\r\n1606778940 0 0 0\r\n1606778940 0 0 0\r\n1606778941 0 0 0\r\n1606778941 0 0 0\r\n1606778942 0 0 0\r\n1606778942 0 0 0\r\n1606778943 0 0 0\r\n1606778943 0 0 0\r\n1606778944 0 0 0\r\n1606778944 0 0 0\r\n1606778945 0 0 0\r\n1606778945 0 0 0\r\n1606778946 0 0 0\r\n1606778946 0 0 0\r\n1606778947 0 0 0\r\n1606778947 0 0 0\r\n1606778948 0 0 0\r\n1606778948 0 0 0\r\n1606778949 0 0 0\r\n1606778949 0 0 0\r\n1606778950 0 0 0\r\n1606778950 0 0 0\r\n1606778951 0 0 0\r\n1606778951 0 0 0\r\n1606778952 0 0 0\r\n1606778952 0 0 0\r\n1606778953 0 0 0\r\n1606778953 0 0 0\r\n1606778954 0 0 0\r\n1606778954 0 0 0\r\n1606778955 0 0 1\r\n1606778955 1 0 1\r\n1606778956 0 0 0\r\n1606778956 0 0 1\r\n1606778957 0 0 0\r\n1606778957 0 0 0\r\n1606778958 0 0 0\r\n1606778958 0 0 0\r\n1606778959 0 0 0\r\n1606778959 0 0 0\r\n1606778960 0 0 1\r\n1606778960 0 0 0\r\n1606778961 1 0 2\r\n1606778961 0 0 0\r\n1606778962 0 0 0\r\n1606778962 0 0 0\r\n1606778963 0 0 1\r\n1606778963 0 0 0\r\n1606778964 0 0 0\r\n1606778964 0 0 0\r\n1606778965 0 0 0\r\n1606778965 0 0 0\r\n1606778966 0 0 0\r\n1606778966 1 0 1\r\n1606778967 0 0 0\r\n1606778967 1 0 1\r\n1606778968 2 0 2\r\n1606778968 0 0 0\r\n1606778969 0 0 0\r\n1606778969 0 0 0\r\n1606778970 0 0 0\r\n1606778970 1 0 1\r\n1606778971 0 0 0\r\n1606778971 0 0 0\r\n1606778972 0 0 0\r\n1606778972 1 0 1\r\n1606778973 0 0 0\r\n1606778973 0 0 0\r\n1606778974 1 0 1\r\n1606778974 0 0 0\r\n1606778975 0 0 0\r\n1606778975 0 0 0\r\n1606778976 0 0 0\r\n1606778976 2 1 3\r\n1606778977 0 0 0\r\n1606778977 0 0 0\r\n1606778978 0 0 0\r\n1606778978 1 0 1\r\n1606778979 0 0 0\r\n1606778979 0 0 0\r\n1606778980 1 0 1\r\n1606778980 1 0 1\r\n1606778981 0 0 0\r\n1606778981 0 0 0\r\n1606778982 0 0 0\r\n1606778982 0 0 0\r\n1606778983 0 0 0\r\n1606778983 1 0 1\r\n1606778984 0 0 0\r\n1606778984 0 0 0\r\n1606778985 0 0 0\r\n1606778985 0 0 0\r\n1606778986 1 0 1\r\n1606778986 0 0 0\r\n1606778987 0 0 0\r\n1606778987 1 0 1\r\n1606778988 1 0 1\r\n1606778988 0 0 0\r\n1606778989 0 1 1\r\n1606778989 0 0 0\r\n1606778990 0 0 0\r\n1606778990 0 0 0\r\n1606778991 0 0 0\r\n1606778991 0 0 0\r\n1606778992 1 0 1\r\n1606778992 0 0 0\r\n1606778993 1 0 1\r\n1606778993 0 0 0\r\n1606778994 0 0 0\r\n1606778994 0 0 0\r\n1606778995 1 0 1\r\n1606778995 0 0 0\r\n1606778996 1 0 1\r\n1606778996 0 0 0\r\n1606778997 0 0 0\r\n1606778997 1 0 1\r\n1606778998 1 1 2\r\n1606778998 0 0 0\r\n1606778999 1 1 2\r\n1606778999 0 0 0\r\n1606779000 0 0 0\r\n1606779000 0 0 0\r\n1606779001 1 0 1\r\n1606779001 0 0 0\r\n1606779002 0 0 0\r\n1606779002 1 0 1\r\n1606779003 0 0 0\r\n1606779003 0 0 0\r\n1606779004 0 0 0\r\n1606779004 0 0 0\r\n1606779005 0 0 0\r\n1606779005 1 0 2\r\n1606779006 0 0 0\r\n1606779006 0 0 0\r\n1606779007 0 0 0\r\n1606779007 0 0 0\r\n1606779008 0 0 0\r\n1606779008 1 0 1\r\n1606779009 0 1 1\r\n1606779009 1 0 1\r\n1606779010 0 1 1\r\n1606779010 0 0 0\r\n1606779011 1 0 1\r\n1606779011 0 0 0\r\n1606779012 0 0 0\r\n1606779012 0 0 0\r\n1606779013 0 0 0\r\n1606779013 0 0 0\r\n1606779014 0 0 0\r\n1606779014 0 0 0\r\n1606779015 0 0 0\r\n1606779015 0 0 0\r\n1606779016 1 0 1\r\n1606779016 0 0 0\r\n1606779017 1 0 1\r\n1606779017 0 0 1\r\n1606779018 1 0 1\r\n1606779018 0 0 0\r\n1606779019 0 0 0\r\n1606779019 0 0 0\r\n1606779020 0 0 0\r\n1606779020 0 0 0\r\n1606779021 0 0 0\r\n1606779021 0 0 0\r\n1606779022 0 0 0\r\n1606779022 0 0 0\r\n1606779023 0 0 0\r\n1606779023 0 1 1\r\n1606779024 0 0 0\r\n1606779024 0 0 0\r\n1606779025 0 0 0\r\n1606779025 0 0 0\r\n1606779026 0 0 0\r\n1606779026 0 0 0\r\n1606779027 0 0 0\r\n1606779027 0 0 0\r\n1606779028 0 0 0\r\n1606779028 0 0 0\r\n1606779029 0 0 0\r\n1606779029 0 0 0\r\n1606779030 0 0 0\r\n1606779030 0 0 0\r\n1606779031 0 0 0\r\n1606779031 0 0 0\r\n1606779032 1 0 1\r\n1606779032 0 0 0\r\n1606779033 0 0 0\r\n1606779033 0 0 0\r\n1606779034 0 0 0\r\n1606779034 0 0 0\r\n1606779035 0 0 0\r\n1606779035 0 0 0\r\n1606779036 0 0 0\r\n1606779036 0 0 0\r\n1606779037 0 0 0\r\n1606779037 0 0 0\r\n1606779038 0 0 0\r\n1606779038 0 1 1\r\n1606779039 0 0 1\r\n1606779039 0 0 0\r\n1606779040 0 0 0\r\n1606779040 0 0 0\r\n1606779041 0 0 0\r\n1606779041 0 0 0\r\n1606779042 0 0 0\r\n1606779042 0 0 0\r\n1606779043 0 0 0\r\n1606779043 0 0 0\r\n1606779044 0 0 0\r\n1606779044 0 0 0\r\n1606779045 0 0 0\r\n1606779045 0 0 0\r\n1606779046 0 0 0\r\n1606779046 0 0 0\r\n1606779047 0 0 0\r\n1606779047 0 1 1\r\n1606779048 0 0 0\r\n1606779048 0 0 0\r\n1606779049 0 0 0\r\n1606779049 0 0 1\r\n1606779050 0 0 0\r\n1606779050 0 0 0\r\n1606779051 0 0 0\r\n1606779051 0 0 0\r\n1606779052 0 0 0\r\n1606779052 0 0 0\r\n1606779053 0 1 1\r\n1606779053 0 0 0\r\n1606779054 0 0 1\r\n1606779054 0 0 0\r\n1606779055 0 0 0\r\n1606779055 0 0 0\r\n1606779056 0 0 0\r\n1606779056 0 0 0\r\n1606779057 0 0 1\r\n1606779057 0 0 0\r\n1606779058 0 0 0\r\n1606779058 0 0 0\r\n1606779059 0 0 0\r\n1606779059 0 0 0\r\n1606779060 0 0 0\r\n1606779060 0 0 0\r\n1606779061 0 0 0\r\n1606779061 0 0 0\r\n1606779062 0 0 0\r\n1606779062 0 0 0\r\n1606779063 0 0 0\r\n1606779063 0 0 1\r\n1606779064 0 0 1\r\n1606779064 0 0 0\r\n1606779065 0 0 0\r\n1606779065 0 0 0\r\n1606779066 0 0 0\r\n1606779066 0 0 0\r\n1606779067 0 0 0\r\n1606779067 0 0 0\r\n1606779068 0 0 0\r\n1606779068 0 0 0\r\n1606779069 0 0 0\r\n1606779069 0 0 0\r\n1606779070 0 0 0\r\n1606779070 0 0 0\r\n1606779071 0 0 0\r\n1606779071 0 0 1\r\n1606779072 0 0 0\r\n1606779072 0 0 0\r\n1606779073 0 0 0\r\n1606779073 0 0 0\r\n1606779074 0 0 0\r\n1606779074 0 0 0\r\n1606779075 0 0 0\r\n1606779075 0 0 0\r\n1606779076 0 0 0\r\n1606779076 0 0 0\r\n1606779077 0 0 0\r\n1606779077 0 0 0\r\n1606779078 0 0 0\r\n1606779078 0 0 0\r\n1606779079 0 0 0\r\n1606779079 0 0 0\r\n1606779080 0 0 0\r\n1606779080 0 0 0\r\n1606779081 0 0 0\r\n1606779081 0 0 0\r\n1606779082 0 0 0\r\n1606779082 0 0 0\r\n1606779083 0 0 0\r\n1606779083 0 0 0\r\n1606779084 0 0 0\r\n1606779084 0 0 0\r\n1606779085 0 1 1\r\n1606779085 0 0 0\r\n1606779086 0 0 0\r\n1606779086 0 0 0\r\n1606779087 0 0 0\r\n1606779087 0 0 0\r\n1606779088 0 0 0\r\n1606779088 0 0 1\r\n1606779089 0 0 1\r\n1606779089 0 0 0\r\n1606779090 0 0 0\r\n1606779090 0 0 0\r\n1606779091 0 0 0\r\n1606779091 0 0 0\r\n1606779092 0 0 0\r\n1606779092 0 0 0\r\n1606779093 0 0 0\r\n1606779093 0 1 1\r\n1606779094 0 0 0\r\n1606779094 0 0 0\r\n1606779095 0 0 0\r\n1606779095 0 0 0\r\n1606779096 0 0 0\r\n1606779096 0 0 0\r\n1606779097 0 0 0\r\n1606779097 0 0 0\r\n1606779098 0 0 0\r\n1606779098 0 1 1\r\n1606779099 0 0 0\r\n1606779099 0 0 0\r\n1606779100 0 0 0\r\n1606779100 0 0 0\r\n1606779101 0 0 0\r\n1606779101 0 0 0\r\n1606779102 0 0 1\r\n1606779102 0 0 0\r\n1606779103 0 0 0\r\n1606779103 0 0 0\r\n1606779104 0 0 0\r\n1606779104 0 0 0\r\n1606779105 0 0 0\r\n1606779105 0 0 0\r\n1606779106 0 0 0\r\n1606779106 0 0 0\r\n1606779107 0 0 0\r\n1606779107 0 0 0\r\n1606779108 0 0 0\r\n1606779108 0 0 0\r\n1606779109 0 1 1\r\n1606779109 0 1 1\r\n1606779110 0 0 0\r\n1606779110 0 0 0\r\n1606779111 0 0 0\r\n1606779111 0 0 0\r\n1606779112 0 0 0\r\n1606779112 0 0 0\r\n1606779113 0 0 0\r\n1606779113 0 0 0\r\n1606779114 0 0 0\r\n1606779114 0 0 0\r\n1606779115 0 0 0\r\n1606779115 0 0 0\r\n1606779116 0 0 0\r\n1606779116 0 0 0\r\n1606779117 0 0 0\r\n1606779117 0 0 0\r\n1606779118 0 0 0\r\n1606779118 0 0 0\r\n1606779119 0 0 0\r\n1606779119 0 0 0\r\n1606779120 0 0 0\r\n1606779120 0 0 1\r\n1606779121 0 0 1\r\n1606779121 0 0 0\r\n1606779122 0 0 0\r\n1606779122 0 0 0\r\n1606779123 0 0 0\r\n1606779123 0 0 0\r\n1606779124 0 0 0\r\n1606779124 0 0 0\r\n1606779125 0 0 0\r\n1606779125 0 0 1\r\n1606779126 0 0 1\r\n1606779126 0 0 0\r\n1606779127 0 0 0\r\n1606779127 0 0 0\r\n1606779128 0 0 0\r\n1606779128 0 0 0\r\n1606779129 1 0 1\r\n1606779129 0 0 0\r\n1606779130 0 0 0\r\n1606779130 0 0 0\r\n1606779131 0 0 0\r\n1606779131 0 0 0\r\n1606779132 0 0 0\r\n1606779132 0 0 0\r\n1606779133 0 0 0\r\n1606779133 0 0 0\r\n1606779134 0 0 0\r\n1606779134 0 1 1\r\n1606779135 0 0 0\r\n1606779135 0 0 0\r\n1606779136 0 0 0\r\n1606779136 0 0 0\r\n1606779137 0 0 1\r\n1606779137 0 0 0\r\n1606779138 0 0 0\r\n1606779138 0 0 0\r\n1606779139 0 0 0\r\n1606779139 0 0 0\r\n1606779140 0 0 0\r\n1606779140 0 1 1\r\n1606779141 0 0 0\r\n1606779141 0 0 0\r\n1606779142 0 0 0\r\n1606779142 0 0 0\r\n1606779143 0 0 0\r\n1606779143 0 0 0\r\n1606779144 0 0 0\r\n1606779144 0 0 0\r\n1606779145 0 0 0\r\n1606779145 0 0 0\r\n1606779146 0 0 0\r\n1606779146 0 0 0\r\n1606779147 0 0 0\r\n1606779147 0 0 0\r\n1606779148 0 0 0\r\n1606779148 0 0 1\r\n1606779149 0 0 0\r\n1606779149 0 0 1\r\n1606779150 0 0 0\r\n1606779150 0 0 0\r\n1606779151 0 0 0\r\n1606779151 0 0 0\r\n1606779152 0 0 0\r\n1606779152 0 0 0\r\n1606779153 0 0 0\r\n1606779153 0 0 1\r\n```\r\n`ps1`\r\n```\r\n-timeStamp -incomingTraffic -outgoingTraffic -totalTraffic\r\n1606778918 0 0 0\r\n1606778919 0 0 0\r\n1606778919 0 0 0\r\n1606778920 0 0 0\r\n1606778920 0 0 0\r\n1606778921 0 0 0\r\n1606778921 0 0 0\r\n1606778922 0 0 0\r\n1606778922 0 0 0\r\n1606778923 0 0 0\r\n1606778923 0 0 0\r\n1606778924 0 0 0\r\n1606778924 0 0 0\r\n1606778925 0 0 0\r\n1606778925 0 0 0\r\n1606778926 0 0 0\r\n1606778926 0 0 0\r\n1606778927 0 0 0\r\n1606778927 0 0 0\r\n1606778928 0 0 0\r\n1606778928 0 0 0\r\n1606778929 0 0 0\r\n1606778929 0 0 0\r\n1606778930 0 0 0\r\n1606778930 0 0 0\r\n1606778931 0 0 0\r\n1606778931 0 0 0\r\n1606778932 0 0 0\r\n1606778932 0 0 0\r\n1606778933 0 0 0\r\n1606778933 0 0 0\r\n1606778934 0 0 0\r\n1606778934 0 0 0\r\n1606778935 0 0 0\r\n1606778935 0 0 0\r\n1606778936 0 0 0\r\n1606778936 0 0 0\r\n1606778937 0 0 0\r\n1606778937 0 0 0\r\n1606778938 0 0 0\r\n1606778938 0 0 0\r\n1606778939 0 0 0\r\n1606778939 0 0 0\r\n1606778940 0 0 0\r\n1606778940 0 0 0\r\n1606778941 0 0 0\r\n1606778941 0 0 0\r\n1606778942 0 0 0\r\n1606778942 0 0 0\r\n1606778943 0 0 0\r\n1606778943 0 0 0\r\n1606778944 0 0 0\r\n1606778944 0 0 0\r\n1606778945 0 0 0\r\n1606778945 0 0 0\r\n1606778946 0 0 0\r\n1606778946 0 0 0\r\n1606778947 0 0 0\r\n1606778947 0 0 0\r\n1606778948 0 0 0\r\n1606778948 0 0 0\r\n1606778949 0 0 0\r\n1606778949 0 0 0\r\n1606778950 0 0 0\r\n1606778950 0 0 0\r\n1606778951 0 0 0\r\n1606778951 0 0 0\r\n1606778952 0 0 0\r\n1606778952 0 0 0\r\n1606778953 0 0 0\r\n1606778953 0 0 0\r\n1606778954 0 0 0\r\n1606778954 0 0 0\r\n1606778955 1 0 1\r\n1606778955 1 0 1\r\n1606778956 0 0 1\r\n1606778956 0 0 0\r\n1606778957 0 0 0\r\n1606778957 0 183 183\r\n1606778958 42 6 49\r\n1606778958 137 0 137\r\n1606778959 8 0 8\r\n1606778959 0 0 0\r\n1606778960 0 0 1\r\n1606778960 0 0 0\r\n1606778961 1 109 111\r\n1606778961 0 78 79\r\n1606778962 148 0 149\r\n1606778962 38 0 38\r\n1606778963 2 27 30\r\n1606778963 0 319 320\r\n1606778964 15 30 46\r\n1606778964 165 0 166\r\n1606778965 141 0 141\r\n1606778965 45 0 45\r\n1606778966 9 0 9\r\n1606778966 2 0 2\r\n1606778967 0 186 187\r\n1606778967 46 1 48\r\n1606778968 133 0 134\r\n1606778968 10 210 221\r\n1606778969 1 96 97\r\n1606778969 9 215 224\r\n1606778970 91 43 134\r\n1606778970 88 18 107\r\n1606778971 153 28 182\r\n1606778971 104 55 160\r\n1606778972 59 86 146\r\n1606778972 31 0 32\r\n1606778973 27 19 46\r\n1606778973 8 150 158\r\n1606778974 12 20 32\r\n1606778974 70 17 88\r\n1606778975 98 170 269\r\n1606778975 86 2 88\r\n1606778976 56 0 56\r\n1606778976 47 135 183\r\n1606778977 71 136 208\r\n1606778977 59 105 165\r\n1606778978 31 0 31\r\n1606778978 34 0 34\r\n1606778979 44 150 195\r\n1606778979 85 39 124\r\n1606778980 82 0 83\r\n1606778980 95 24 120\r\n1606778981 52 278 331\r\n1606778981 89 74 163\r\n1606778982 57 0 57\r\n1606778982 20 0 20\r\n1606778983 29 8 37\r\n1606778983 31 139 171\r\n1606778984 71 92 163\r\n1606778984 75 23 98\r\n1606778985 104 51 155\r\n1606778985 58 77 136\r\n1606778986 95 129 225\r\n1606778986 50 44 95\r\n1606778987 52 0 52\r\n1606778987 55 11 66\r\n1606778988 47 177 224\r\n1606778988 33 0 33\r\n1606778989 57 61 118\r\n1606778989 62 287 349\r\n1606778990 73 28 101\r\n1606778990 49 6 55\r\n1606778991 38 163 201\r\n1606778991 43 19 63\r\n1606778992 55 3 58\r\n1606778992 119 29 149\r\n1606778993 90 27 118\r\n1606778993 95 34 130\r\n1606778994 62 93 156\r\n1606778994 84 75 160\r\n1606778995 80 112 193\r\n1606778995 70 0 70\r\n1606778996 28 0 28\r\n1606778996 31 0 31\r\n1606778997 20 0 20\r\n1606778997 32 0 32\r\n1606778998 24 95 119\r\n1606778998 53 199 252\r\n1606778999 76 156 233\r\n1606778999 58 277 335\r\n1606779000 58 123 182\r\n1606779000 41 111 153\r\n1606779001 23 150 173\r\n1606779001 41 105 147\r\n1606779002 24 31 56\r\n1606779002 74 45 120\r\n1606779003 97 31 128\r\n1606779003 135 0 136\r\n1606779004 102 0 103\r\n1606779004 109 0 109\r\n1606779005 101 0 101\r\n1606779005 99 93 193\r\n1606779006 122 94 216\r\n1606779006 59 2 61\r\n1606779007 91 0 92\r\n1606779007 53 0 53\r\n1606779008 43 0 43\r\n1606779008 74 0 74\r\n1606779009 22 98 121\r\n1606779009 39 127 167\r\n1606779010 35 177 213\r\n1606779010 48 315 364\r\n1606779011 37 41 79\r\n1606779011 20 105 125\r\n1606779012 42 112 155\r\n1606779012 14 114 129\r\n1606779013 18 46 64\r\n1606779013 62 182 245\r\n1606779014 70 0 70\r\n1606779014 71 0 71\r\n1606779015 91 0 91\r\n1606779015 95 0 95\r\n1606779016 128 0 129\r\n1606779016 124 36 161\r\n1606779017 152 94 246\r\n1606779017 152 199 351\r\n1606779018 130 114 245\r\n1606779018 68 132 200\r\n1606779019 51 144 196\r\n1606779019 44 38 82\r\n1606779020 22 0 22\r\n1606779020 28 0 29\r\n1606779021 36 22 58\r\n1606779021 19 113 132\r\n1606779022 8 52 61\r\n1606779022 34 6 40\r\n1606779023 15 117 132\r\n1606779023 65 221 286\r\n1606779024 89 219 309\r\n1606779024 93 0 93\r\n1606779025 83 67 151\r\n1606779025 108 187 295\r\n1606779026 84 122 207\r\n1606779026 92 0 92\r\n1606779027 80 0 80\r\n1606779027 77 0 78\r\n1606779028 86 0 86\r\n1606779028 91 0 91\r\n1606779029 95 0 95\r\n1606779029 156 0 157\r\n1606779030 120 0 120\r\n1606779030 80 0 80\r\n1606779031 104 0 104\r\n1606779031 86 13 100\r\n1606779032 65 130 195\r\n1606779032 59 121 181\r\n1606779033 41 163 205\r\n1606779033 31 144 175\r\n1606779034 23 161 184\r\n1606779034 25 47 73\r\n1606779035 9 77 86\r\n1606779035 5 85 91\r\n1606779036 6 0 6\r\n1606779036 3 21 24\r\n1606779037 29 258 287\r\n1606779037 46 152 198\r\n1606779038 45 97 142\r\n1606779038 149 191 341\r\n1606779039 109 159 268\r\n1606779039 98 156 255\r\n1606779040 90 85 175\r\n1606779040 107 9 117\r\n1606779041 94 0 94\r\n1606779041 104 0 105\r\n1606779042 122 0 122\r\n1606779042 108 0 108\r\n1606779043 107 0 107\r\n1606779043 111 0 112\r\n1606779044 123 0 123\r\n1606779044 132 137 269\r\n1606779045 115 51 166\r\n1606779045 80 0 80\r\n1606779046 84 0 84\r\n1606779046 30 0 30\r\n1606779047 37 0 37\r\n1606779047 41 61 102\r\n1606779048 47 201 248\r\n1606779048 28 115 144\r\n1606779049 12 60 72\r\n1606779049 41 152 194\r\n1606779050 26 202 228\r\n1606779050 40 150 191\r\n1606779051 42 144 186\r\n1606779051 13 207 221\r\n1606779052 17 25 43\r\n1606779052 12 0 12\r\n1606779053 71 134 205\r\n1606779053 81 148 230\r\n1606779054 128 138 267\r\n1606779054 152 64 217\r\n1606779055 100 80 180\r\n1606779055 93 0 94\r\n1606779056 148 0 149\r\n1606779056 100 0 101\r\n1606779057 113 78 191\r\n1606779057 122 76 198\r\n1606779058 87 36 123\r\n1606779058 53 0 54\r\n1606779059 79 0 79\r\n1606779059 63 0 63\r\n1606779060 74 0 74\r\n1606779060 72 117 189\r\n1606779061 68 70 139\r\n1606779061 43 0 43\r\n1606779062 57 30 87\r\n1606779062 61 102 163\r\n1606779063 81 160 241\r\n1606779063 42 145 187\r\n1606779064 63 207 270\r\n1606779064 41 185 227\r\n1606779065 43 102 146\r\n1606779065 68 12 81\r\n1606779066 45 0 45\r\n1606779066 90 24 114\r\n1606779067 45 110 156\r\n1606779067 65 152 218\r\n1606779068 68 89 157\r\n1606779068 73 0 74\r\n1606779069 68 11 79\r\n1606779069 93 149 242\r\n1606779070 123 28 151\r\n1606779070 72 123 195\r\n1606779071 91 68 160\r\n1606779071 71 10 82\r\n1606779072 95 116 211\r\n1606779072 105 45 150\r\n1606779073 78 108 187\r\n1606779073 64 97 161\r\n1606779074 81 2 83\r\n1606779074 43 81 125\r\n1606779075 45 107 152\r\n1606779075 62 34 97\r\n1606779076 81 153 234\r\n1606779076 57 0 58\r\n1606779077 88 0 88\r\n1606779077 93 1 95\r\n1606779078 44 141 185\r\n1606779078 85 45 131\r\n1606779079 65 53 118\r\n1606779079 86 113 199\r\n1606779080 87 70 157\r\n1606779080 104 111 215\r\n1606779081 66 138 205\r\n1606779081 86 80 167\r\n1606779082 65 0 65\r\n1606779082 50 53 104\r\n1606779083 23 127 151\r\n1606779083 61 8 70\r\n1606779084 30 0 30\r\n1606779084 84 29 114\r\n1606779085 59 220 280\r\n1606779085 62 267 329\r\n1606779086 71 49 121\r\n1606779086 98 80 179\r\n1606779087 96 86 182\r\n1606779087 77 24 101\r\n1606779088 69 0 69\r\n1606779088 61 26 88\r\n1606779089 94 199 294\r\n1606779089 95 150 245\r\n1606779090 114 0 114\r\n1606779090 80 0 80\r\n1606779091 113 0 113\r\n1606779091 85 0 85\r\n1606779092 68 0 68\r\n1606779092 82 0 82\r\n1606779093 65 0 65\r\n1606779093 97 47 144\r\n1606779094 54 292 346\r\n1606779094 47 207 255\r\n1606779095 46 21 67\r\n1606779095 70 0 70\r\n1606779096 39 61 101\r\n1606779096 39 56 95\r\n1606779097 38 87 125\r\n1606779097 49 256 306\r\n1606779098 35 104 140\r\n1606779098 29 63 92\r\n1606779099 65 178 244\r\n1606779099 71 136 207\r\n1606779100 74 0 74\r\n1606779100 83 0 84\r\n1606779101 91 0 91\r\n1606779101 135 14 150\r\n1606779102 136 338 474\r\n1606779102 130 26 156\r\n1606779103 140 0 140\r\n1606779103 88 0 88\r\n1606779104 102 0 102\r\n1606779104 80 0 81\r\n1606779105 71 27 99\r\n1606779105 59 102 162\r\n1606779106 63 59 122\r\n1606779106 48 0 48\r\n1606779107 25 0 25\r\n1606779107 37 0 37\r\n1606779108 61 47 109\r\n1606779108 59 91 150\r\n1606779109 71 159 231\r\n1606779109 42 261 303\r\n1606779110 53 239 292\r\n1606779110 59 188 247\r\n1606779111 49 188 238\r\n1606779111 39 127 166\r\n1606779112 36 16 52\r\n1606779112 40 0 40\r\n1606779113 80 0 80\r\n1606779113 74 0 74\r\n1606779114 129 0 130\r\n1606779114 116 1 118\r\n1606779115 152 27 179\r\n1606779115 169 135 304\r\n1606779116 124 188 313\r\n1606779116 110 25 136\r\n1606779117 70 0 70\r\n1606779117 99 18 117\r\n1606779118 98 141 239\r\n1606779118 45 29 75\r\n1606779119 36 0 36\r\n1606779119 39 0 39\r\n1606779120 28 0 28\r\n1606779120 28 5 34\r\n1606779121 44 142 186\r\n1606779121 54 262 317\r\n1606779122 45 155 201\r\n1606779122 47 106 154\r\n1606779123 27 125 153\r\n1606779123 38 90 128\r\n1606779124 60 55 116\r\n1606779124 29 0 29\r\n1606779125 67 0 67\r\n1606779125 49 116 166\r\n1606779126 109 154 263\r\n1606779126 121 73 194\r\n1606779127 129 32 162\r\n1606779127 164 33 197\r\n1606779128 115 105 220\r\n1606779128 109 50 160\r\n1606779129 106 4 110\r\n1606779129 107 143 250\r\n1606779130 52 41 94\r\n1606779130 66 0 66\r\n1606779131 55 0 55\r\n1606779131 80 0 80\r\n1606779132 55 101 156\r\n1606779132 35 103 139\r\n1606779133 63 170 234\r\n1606779133 30 1 31\r\n1606779134 24 61 86\r\n1606779134 69 169 238\r\n1606779135 65 260 325\r\n1606779135 66 163 230\r\n1606779136 36 98 134\r\n1606779136 29 0 29\r\n1606779137 36 17 53\r\n1606779137 39 79 118\r\n1606779138 62 91 153\r\n1606779138 119 0 119\r\n1606779139 108 0 109\r\n1606779139 133 0 133\r\n1606779140 148 66 214\r\n1606779140 160 212 372\r\n1606779141 122 186 308\r\n1606779141 98 101 200\r\n1606779142 66 0 66\r\n1606779142 52 0 52\r\n1606779143 48 0 49\r\n1606779143 49 0 49\r\n1606779144 48 0 48\r\n1606779144 50 7 57\r\n1606779145 27 164 192\r\n1606779145 36 17 54\r\n1606779146 82 110 192\r\n1606779146 72 156 228\r\n1606779147 70 204 275\r\n1606779147 75 81 156\r\n1606779148 41 13 55\r\n1606779148 81 116 198\r\n1606779149 63 199 263\r\n1606779149 53 202 255\r\n1606779150 66 46 113\r\n1606779150 103 0 103\r\n1606779151 126 0 126\r\n1606779151 113 0 113\r\n1606779152 98 0 98\r\n1606779152 71 0 71\r\n1606779153 80 44 125\r\n1606779153 85 175 260\r\n```\r\n", "comments": ["@ali-raza-tariq \r\nPlease share simple stand alone code to replicate the issue faced.", "@Saduf2019 ty for the quick response! i am using keras model with keras to estimator model conversion(see the code below) and no specific customization. I should mention that i am running it inside pods on kubernetes and as i have already mentioned, this problem is not specific to any model (tested with multiple models) or configuration (1 master, 2 ps, 1 worker) . When i ran (1 master, 3 ps 1 worker), again only parameter-server was facing network traffic but when i ran (1master, 4ps, 1 worker), 2 of the 4 parameter-servers were participating equally while the other 2 saw close to no activity. For (1master, 4ps, 1 worker) configuration, i double checked the task assignments in graph.pbtxt file and they were near equally distributed on all 4 parameter-servers. Please let me know if there is any confusion!\r\n`code`\r\n```\r\n# from __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nfrom absl import flags, app\r\nimport sys, logging\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow_federated as tff\r\n# tfds.disable_progress_bar()\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_string(name='model_dir', default='./keras_est_model', help='Directory to store model checkpoints')\r\n\r\n### Dataset specs ###\r\n#flags.DEFINE_string(name='', default='', help='')\r\nflags.DEFINE_string(name='data_dir', default='./dataDir/', help='Directory to store data sets.')\r\nflags.DEFINE_string(name='dataset', default='cifar10', help='Dataset name for training and evaluation.')\r\nflags.DEFINE_integer(name='img_size', default=128, help='Set the size of the image (img_size, img_size, 3).')\r\nflags.DEFINE_integer(name='num_class', default=10, help='Set the number of classes in the dataset.')\r\n\r\n### Training specs ###\r\n#flags.DEFINE_integer(name='', default='', help='')\r\nflags.DEFINE_integer(name='num_epochs', default=500, help='Number of epochs for training.')\r\nflags.DEFINE_integer(name='max_steps', default=None, help='Number of steps for training, need to work with num_epoches.')\r\nflags.DEFINE_integer(name='summ_steps', default=100, help='Number of steps to save summary.')\r\nflags.DEFINE_integer(name='checkpoint_steps', default=500, help='Number of steps to save checkpoint which also controls evaluation frequency.')\r\n# flags.DEFINE_integer(name='checkpoint_time', default=None, help='Number of seconds to save checkpoint.')\r\nflags.DEFINE_integer(name='log_steps', default=100, help='Number of steps to print log message.')\r\nflags.DEFINE_integer(name='eval_sec', default=10, help='Throttle evaluation for at least this many seconds.')\r\nflags.DEFINE_bool(name='train_distribute', default=False, help='Whether to the train with ParameterServer strategy.')\r\n\r\n### Model specs ###\r\nK_MODELS = {\r\n    'resnet50':keras.applications.resnet.ResNet50,\r\n    'resnet101':keras.applications.resnet.ResNet101,\r\n    'resnet152':keras.applications.resnet.ResNet152,\r\n    'resnet50v2':keras.applications.resnet_v2.ResNet50V2,\r\n    'resnet101v2':keras.applications.resnet_v2.ResNet101V2,\r\n    'resnet152v2':keras.applications.resnet_v2.ResNet152V2,\r\n    'mobilenet':keras.applications.MobileNet,\r\n    'mobilenetv2':keras.applications.MobileNetV2,\r\n    'densenet121':keras.applications.densenet.DenseNet121,\r\n    'densenet169':keras.applications.densenet.DenseNet169,\r\n    'densenet201':keras.applications.densenet.DenseNet201,\r\n    'nasnetlarge':keras.applications.nasnet.NASNetLarge,\r\n    'nasnetmobile':keras.applications.nasnet.NASNetMobile,\r\n    'xception':keras.applications.xception.Xception,\r\n    'inceptionv3':keras.applications.inception_v3.InceptionV3,\r\n    'inceptionresnetv2':keras.applications.inception_resnet_v2.InceptionResNetV2,\r\n    'vgg16':keras.applications.vgg16.VGG16,\r\n    'vgg19':keras.applications.vgg19.VGG19,\r\n}\r\nOUT_LAYERS_2 = ['resnet50', 'resnet101', 'resnet152', 'resnet50v2', 'resnet101v2', 'resnet152v2',\r\n                'mobilenet', 'mobilenetv2', 'densenet121', 'densenet169', 'densenet201',\r\n                'nasnetlarge', 'nasnetmobile', 'xception', 'inceptionv3', 'inceptionresnetv2']\r\nOUT_LAYERS_4 = ['vgg16', 'vgg19']\r\n\r\nOPTIMIZERS = {\r\n    'adadelta': keras.optimizers.Adadelta,\r\n    'adagrad': keras.optimizers.Adagrad,\r\n    'adam': keras.optimizers.Adam,\r\n    'adamax': keras.optimizers.Adamax,\r\n    'ftrl': keras.optimizers.Ftrl,\r\n    'nadam': keras.optimizers.Nadam,\r\n    'rmsprop': keras.optimizers.RMSprop,\r\n    'sgd': keras.optimizers.SGD,\r\n}\r\n\r\nLOSS = ['binary_crossentropy', 'categorical_crossentropy', 'sparse_categorical_crossentropy',\r\n    'cosine_similarity', 'huber_loss', 'logcosh' , 'poisson']\r\n\r\nflags.DEFINE_enum(name='model', default='resnet50',\r\n      enum_values=K_MODELS.keys(),\r\n      help='Set the name of the neural network model.')\r\nflags.DEFINE_bool(name='pretrain', default=True, help='Whether to use weights pre-trained on ImageNet.')\r\n\r\n### Tuning parameters ###\r\nflags.DEFINE_integer(name='batch_size', default=64, help='Set batch size.')\r\nflags.DEFINE_integer(name='buffer_size', default=1000, help='Set buffer size for image preprocess.')\r\nflags.DEFINE_enum(name='optimizer', default='adam', enum_values=OPTIMIZERS.keys(), help='Optimizer for training.')\r\nflags.DEFINE_float(name='learning_rate', default=0.001, help='Learning rate for optimizer.')\r\nflags.DEFINE_float(name='momentum', default=0.0, help='Learning rate for optimizer.')\r\nflags.DEFINE_enum(name='loss', default='sparse_categorical_crossentropy', enum_values=LOSS, help='Loss for training.')\r\n\r\n\r\ndef data_fn(ds_name, mode, data_dir, repeat_cnt=1):\r\n\r\n    if mode not in ['train', 'test']:\r\n        raise Exception(f'Dataset can only be splitted with \"train\" and \"test\", {mode} is not supported.')\r\n\r\n    if ds_name == 'mnist_numpy':\r\n        ### Load image data using Keras API in numpy matrix\r\n        (train_img, train_label), (test_img, test_label) = keras.datasets.mnist.load_data()\r\n        if mode == 'train':\r\n            print('MNIST training image dataset:', train_img.shape)\r\n            ### Create TF dataset objects from numpy matrix including features AND labels\r\n            dataset = tf.data.Dataset.from_tensor_slices((train_img, train_label))\r\n        else:\r\n            print('MNIST testing image dataset:', train_img.shape)\r\n            ### Create TF dataset objects from numpy matrix including features AND labels\r\n            dataset = tf.data.Dataset.from_tensor_slices((test_img, test_label))\r\n    elif ds_name in ['cifar10', 'mnist']:\r\n        dataset, metadata = tfds.load(ds_name, split=mode, as_supervised=True, with_info=True, data_dir=data_dir)\r\n    else:\r\n        raise Exception(f'Dataset {ds_name} is not supported')\r\n\r\n    assert isinstance(dataset, tf.data.Dataset)\r\n    print(metadata)\r\n\r\n    ### Show an example of the imported image dataset\r\n    # if tf.executing_eagerly():\r\n    #   get_label_name = metadata.features['label'].int2str\r\n    #   for image, label in train_ds.take(2):\r\n    #     plt.figure()\r\n    #     plt.imshow(image)\r\n    #     plt.title(get_label_name(label))\r\n\r\n    def preprocess(image, label):\r\n        image = tf.cast(image, tf.float32)  # Cast to float for the following feature scaling (0,1)\r\n        image = image / 255.0               # Scale feature values\r\n        image = tf.image.resize(image, (FLAGS.img_size, FLAGS.img_size))  # Resize images\r\n        return image, label\r\n\r\n    ### Shuffle images using 5000 buffer and then batch them to 32\r\n    dataset = dataset.map(preprocess).repeat(repeat_cnt).shuffle(FLAGS.buffer_size).batch(FLAGS.batch_size)\r\n    print(f'Input data (batch size {FLAGS.batch_size}): {dataset}')\r\n\r\n    return dataset\r\n\r\n\r\ndef train_input_fn():\r\n    return data_fn(FLAGS.dataset, 'train', FLAGS.data_dir, FLAGS.num_epochs)\r\n\r\n\r\ndef eval_input_fn():\r\n    return data_fn(FLAGS.dataset, 'test', FLAGS.data_dir)\r\n\r\n\r\ndef build_keras_model(model_name, pretrain, num_class, img_size, image_batch=None):\r\n\r\n    print('+++++ Building Keras model +++++')\r\n    w = 'imagenet' if pretrain and model_name not in ['nasnetmobile', 'nasnetlarge'] else None\r\n    keras_app = K_MODELS[model_name](input_shape=(img_size, img_size, 3), include_top=False, weights=w)\r\n#    if not pretrain:\r\n    keras_app.trainable = True\r\n\r\n    ### Build new output layers ###\r\n    # global_average_layer = keras.layers.GlobalAveragePooling2D()\r\n    # prediction_layer = keras.layers.Dense(num_class, activation='softmax')\r\n\r\n    ### Build new output layers ###\r\n    if model_name in OUT_LAYERS_2:\r\n        new_output = keras.Sequential([\r\n                keras.layers.GlobalAveragePooling2D(),\r\n                keras.layers.Dense(num_class, activation='softmax')\r\n            ])\r\n    elif model_name in OUT_LAYERS_4:\r\n        new_output = keras.Sequential([\r\n                keras.layers.Flatten(),\r\n                keras.layers.Dense(4096, activation='relu'),\r\n                keras.layers.Dense(4096, activation='relu'),\r\n                # keras.layers.Dropout(0.5),\r\n                keras.layers.Dense(num_class, activation='softmax')\r\n            ])\r\n    else:\r\n        raise Exception(f'{model_name} is not supported yet.')\r\n\r\n    ### image_batch is an optional image sample for testing ###\r\n    if image_batch is not None:\r\n        output_batch = keras_app(image_batch)\r\n        print(f'Output of feature extraction (original model):', output_batch.shape)\r\n\r\n        for i, layer in enumerate(new_output.layers):\r\n            output_batch = layer(output_batch)\r\n            print(f'Output of {i}th classification layer ({layer}): {output_batch.shape}')\r\n\r\n\r\n    keras_model = keras.Sequential([\r\n        keras_app,\r\n        new_output,\r\n    ])\r\n\r\n    ### Compile the model ###\r\n    keras_model.compile(\r\n        optimizer=OPTIMIZERS[FLAGS.optimizer](learning_rate=FLAGS.learning_rate),\r\n        loss=FLAGS.loss,\r\n        metrics=['accuracy'])\r\n\r\n    keras_model.summary()\r\n    new_output.summary()\r\n\r\n    return keras_model\r\n\r\n\r\ndef main(_):\r\n    if FLAGS.model not in K_MODELS:\r\n        raise Exception(f'{FLAGS.model} is not supported yet.')\r\n\r\n    train_ds = data_fn(FLAGS.dataset, 'train', FLAGS.data_dir)\r\n    for image_batch, label_batch in train_ds.take(1):\r\n        pass\r\n\r\n    ### Create and compile a Keras model ###\r\n    model_keras = build_keras_model(FLAGS.model, FLAGS.pretrain,\r\n            FLAGS.num_class, FLAGS.img_size, image_batch)\r\n\r\n    ### Create RunConfig with distribution strategy ###\r\n    run_config = tf.estimator.RunConfig(\r\n        train_distribute=None,\r\n        log_step_count_steps=FLAGS.log_steps,\r\n        save_summary_steps=FLAGS.summ_steps,\r\n        save_checkpoints_steps=FLAGS.checkpoint_steps,\r\n    )\r\n    if FLAGS.train_distribute:\r\n        strategy = tf.distribute.experimental.ParameterServerStrategy()\r\n        # strategy = tf.distribute.MirroredStrategy()\r\n        run_config.replace(train_distribute=strategy)\r\n\r\n    ### Convert the Keras model to Estimator model\r\n    model_est = keras.estimator.model_to_estimator(keras_model=model_keras, model_dir=FLAGS.model_dir, config=run_config)\r\n\r\n    ### Train and evaluate the Estimator model\r\n    print('+++++ Train and evaluate the Estimator model +++++')\r\n    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=FLAGS.max_steps) #STEPS_PER_EPOCH * NUM_EPOCHS)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, throttle_secs=FLAGS.eval_sec)\r\n    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)\r\n    print('+++++ Done with train_and_evaluate +++++')\r\n\r\n    ### estimator.train() => ValueError: Only `STANDALONE_CLIENT` mode is supported when you call `estimator.train`\r\n#    print('+++++ Training estimator model')\r\n#    model_est.train(input_fn=lambda: train_input_fn(), steps=5000)\r\n#    print('+++++ Estimating estimator model')\r\n#    model_est.evaluate(input_fn=lambda: train_input_fn(32), steps=10)\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n    tf_logger = logging.getLogger('tensorflow')\r\n    formatter = logging.Formatter('%(levelname)s:%(created)s:%(name)s:%(message)s')\r\n    tf_logger.handlers[0].setFormatter(formatter)\r\n    app.run(main)\r\n\r\n\r\n```", "Hi @ali-raza-tariq, [TF 2.4](https://github.com/tensorflow/tensorflow/releases) includes support for training Keras models with Parameter Server Strategy. The existing `tf.distribute.experimental.ParameterServerStrategy` symbol is replaced with a new class that is for parameter server training in TF2. Usage of the old symbol (ie for the Estimator API) should be replaced with `tf.compat.v1.distribute.experimental.ParameterServerStrategy`. \r\n\r\nGiven these changes, and that the new API is the recommended way to do parameter server training with Keras, I would highly recommend you try out the new API. You can find [a tutorial for PSS and Keras here](https://www.tensorflow.org/tutorials/distribute/parameter_server_training). 2.4 is currently in pre-release, but will be the stable version very soon. Unfortunately, I don't think performance issues in the old API will be prioritized at this point.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45290, "title": "tflite 2.4 build benchmark_model error on ubuntu 16.04 (cmake)", "body": "when i build tflite2.4 on Ubuntu, i encount the problem:\r\ni can success build libtensorflow-lite.a with CMakeLists.txt use CMake, but when i buildbenchmark-model i got these errors:\r\nmy build command is : make benchmark-model\r\nerrors:\r\n\r\n[ 98%] Linking CXX executable benchmark_model\r\n_deps/xnnpack-build/libXNNPACK.a(4x16c8-minmax-avx512skx.c.o): In function `xnn_qs8_gemm_minmax_ukernel_4x16c8__avx512skx':\r\n4x16c8-minmax-avx512skx.c:(.text+0x720): undefined reference to `_kshiftli_mask64'\r\n4x16c8-minmax-avx512skx.c:(.text+0x753): undefined reference to `_kshiftli_mask64'\r\n4x16c8-minmax-avx512skx.c:(.text+0x785): undefined reference to `_kshiftli_mask64'\r\n_deps/xnnpack-build/libXNNPACK.a(4x16c8-minmax-avx512skx.c.o): In function `xnn_qs8_igemm_minmax_ukernel_4x16c8__avx512skx':\r\n4x16c8-minmax-avx512skx.c:(.text+0x7a2): undefined reference to `_kshiftri_mask64'\r\n4x16c8-minmax-avx512skx.c:(.text+0x7d4): undefined reference to `_kshiftri_mask64'\r\n4x16c8-minmax-avx512skx.c:(.text+0x80d): undefined reference to `_kshiftri_mask64'\r\ncollect2: error: ld returned 1 exit status\r\nCMakeFiles/benchmark_model.dir/build.make:382: recipe for target 'benchmark_model' failed\r\nmake[3]: *** [benchmark_model] Error 1\r\nCMakeFiles/Makefile2:2012: recipe for target 'CMakeFiles/benchmark_model.dir/all' failed\r\nmake[2]: *** [CMakeFiles/benchmark_model.dir/all] Error 2\r\nCMakeFiles/Makefile2:2019: recipe for target 'CMakeFiles/benchmark_model.dir/rule' failed\r\nmake[1]: *** [CMakeFiles/benchmark_model.dir/rule] Error 2\r\nMakefile:199: recipe for target 'benchmark_model' failed\r\nmake: *** [benchmark_model] Error 2\r\n\r\nthis puzzled me for a long time , appreciate your reply!\r\n\r\nthe CMakeLists.txt help me much ,but also has some errors i think , for example the xnnpack delegate switch to control build with xnnpack delegate. i found use TFLITE_ENABLE_XNNPACK  to control xnnpack delegate will get errors when i build shared library in windows x64. so i change the source code.\r\n\r\n\r\nemail:   lxiao217@163.com", "comments": ["It works well for me with r2.4 branch.\r\nCould you check if you're using up-to-date r2.4 branch?\r\n\r\nBTW, here is the official guide on CMake build\r\nhttps://www.tensorflow.org/lite/guide/build_cmake", "> It works well for me with r2.4 branch.\r\n> Could you check if you're using up-to-date r2.4 branch?\r\n> \r\n> BTW, here is the official guide on CMake build\r\n> https://www.tensorflow.org/lite/guide/build_cmake\r\n\r\n\r\nthanks for your reply, the reason for this problem is my gcc/g++ version too low, avx512 is supported after 6.x, but mine is 5.x, so i upgrade it to 9.0 and this problem solved.\r\n\r\nbut this build also has problem when i build dynamic libraries in ubuntu/windows et.\r\ntest_delegate_providers.cpp in line 29 and 40 throw errors with unrecognized reference of Merge and Parse.", "@lxiao217 could you share the command you used to build dynamic libraries?", "> @lxiao217 could you share the command you used to build dynamic libraries?\r\n\r\ni added \"shared\" in CMakeLists.txt like this:\r\n# TFLite library\r\nadd_library(tensorflow-lite SHARED \r\n  ${TFLITE_CORE_API_SRCS}\r\n\r\nand then\" cmake ./ -B ./build  \", then errors up thrown. i annotated those code at last, i dont know if this action will have other bad influence. though this code in test file.", "Could you try if the patch https://github.com/tensorflow/tensorflow/commit/94550574cdc0b0c61181d10d1df87eed60f4d7fa helps?", "> Could you try if the patch [9455057](https://github.com/tensorflow/tensorflow/commit/94550574cdc0b0c61181d10d1df87eed60f4d7fa) helps?\r\n\r\nthanks very much! i  will try later.\r\n when i build so in ubuntu16.04, i get the dynamic library libtensorflow-lite.so, but when i use it  in my demo , errors were thrown  like this:\r\n\r\n/tmp/cifar10-d10aa3.o: In function `cv::String::operator=(cv::String const&)':\r\n/usr/include/opencv2/core/cvstd.hpp:656: undefined reference to `cv::String::deallocate()'\r\n/home/xiaoling/tf_build/tflite_test/libs/x86_64/libtensorflow-lite.so: undefined reference to `TfLiteXNNPackDelegateOptionsDefault'\r\n/home/xiaoling/tf_build/tflite_test/libs/x86_64/libtensorflow-lite.so: undefined reference to `TfLiteXNNPackDelegateCreate'\r\n/home/xiaoling/tf_build/tflite_test/libs/x86_64/libtensorflow-lite.so: undefined reference to `TfLiteXNNPackDelegateDelete'\r\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n\r\nwhen i build so, i close the switch to build with xnnpack:\r\n\r\noption(TFLITE_ENABLE_XNNPACK \"Enable XNNPACK backend\" OFF)\r\n\r\nthis option is set ON default.\r\n\r\notherwise, seek for some helps:\r\nwhen i build tflite, many thirdparty  will be pull but the network speed  is limited here, so i want to copy those 3rdparty to new folder where i want to save my building files. but the build script will delete files in these folder like eigen, and pull it from remote server in gitlab. this will waste me much time. \r\nwhere i can set use local 3rdparty files, please give me some advise, i search in the build scripts will need much time. thanks for your help!\r\n\r\n\r\n", "> when i build so in ubuntu16.04, i get the dynamic library libtensorflow-lite.so, but when i use it in my demo\r\n\r\nHi, we had the same problem (undefined reference to TfLiteXNNPackDelegateCreate, `TfLiteXNNPackDelegateDelete, also Parse and Merge problem).\r\n\r\nThe patch [9455057](https://github.com/tensorflow/tensorflow/commit/94550574cdc0b0c61181d10d1df87eed60f4d7fa) seems to solve our issue, but it's not present in the r2.4 branch and we had to pull directly from the master\r\n", "@lxiao217,\r\n\r\nCan you update to the latest stable version i.e `2.6.0` and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45290\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45290\">No</a>\n"]}, {"number": 45289, "title": "resnet50 inference is slower when use tensorflow with onednn", "body": "> @zhangqiang-hf\r\n> \r\n> I think your issue is new one for Resnet50 model.\r\n> This issue topic is LSTM.\r\n> \r\n> Is it possible to create a new github issue for your model?\r\n> You could @me in the new issue, so I can continue following it.\r\n> \r\n> Thank you!\r\n\r\nok\uff01I will assign a new bug for you\uff01when one pic, why it is slower when use onednn, this  still a issue? am I right?\r\nalso, I have checked when bs=100, it is quicker when onednn. but this 100 pictures is the same, when the100 pictures are different, how about?\r\n\r\n_Originally posted by @zhangqiang-hf in https://github.com/tensorflow/tensorflow/issues/33138#issuecomment-736168560_", "comments": ["@zhangqiang-hf \r\n1. Could you copy the detailed info about your case from the #33138 ?\r\nSo, the reader could know whole problem and answer of your case.\r\n\r\n2. Answer about your question\r\na. BS=1 case, we are checking. I will feedback later.\r\nb. Performance is better with more big BS.\r\nI use Intel Xeon CPU, there is AVX512 to accelerate the Tensorflow by vector.\r\nIf you are using Intel Core CPU, AVX2/AVX512 in it will speed up the Tensorflow in same way.\r\n\r\nAVX512 support 512 bits vector to execute the operation, like add, mul, addmul.\r\none 512 bits vector could load 16 FP32 float numbers in one time. \r\n\r\nV512 + V512 = (FP32+FP32), (FP32+FP32),..., (FP32+FP32)  (total 16 groups).\r\n\r\nSo, it's more quick than FP32 operation when add more float number.\r\n\r\nBut, there is additional cost: load the data to vector.\r\nIf the vector load 16 FP32 floats, the performance benefit is max.\r\nIf the vector only load 1 FP32 floats, the performance is bad: load to vector waste time. \r\n\r\nSo, when BS is big, the vector could be full and get better performance.\r\n\r\nc. For your case: Tensorflow with MKL get same performance when BS=100.\r\nDo you use Intel Core CPU?\r\nIf yes, could refer to the optimization setting, like:\r\n\r\n```\r\nexport TF_ENABLE_MKL_NATIVE_FORMAT=1  \r\nexport TF_NUM_INTEROP_THREADS=1\r\nexport TF_NUM_INTRAOP_THREADS=24\r\nexport OMP_NUM_THREADS=24\r\nexport KMP_BLOCKTIME=1\r\nexport KMP_AFFINITY=granularity=fine,compact,1,0\r\n```\r\n\r\n`TF_ENABLE_MKL_NATIVE_FORMAT` is key optimization, friendly to Keras model inference.\r\n`TF_NUM_INTRAOP_THREADS` & `OMP_NUM_THREADS` are set as the number of cores in the CPU. You could change it for better performance.\r\n`KMP_BLOCKTIME` are set 0, 1 or other number.  Depend on test result.\r\n\r\n\r\n", "@zhangqiang-hf @Zantares\r\nAs answer from Zantares: \"Bad performance is expected if you only run session once because TF with oneDNN will take more time in warmup (1st iteration). You will get similar performance with different pics as long as you don't change pic shape. In same word, TF with oneDNN doesn't care about data, it only cares shape.\"\r\n\r\nI just test to run 100 times for BS=1.\r\nThe performance of TF with MKL is better than stack TF.\r\n```\r\n    times = 100\r\n    a = time.time()    \r\n    for i in range(times):    \r\n        preds = model.predict(x)\r\n    b = time.time()\r\n    seconds = (b - a)/times\r\n    print(\"predict() cost time:\",seconds)\r\n```", "Dear sir\uff0c\r\nthe format of resnet50 is keras HD5\u3002ok\uff0c I will share my test code for this issue\u3002\r\nTensorflow-2.4.0\r\noneDNN-1.5.0\r\nCPU\uff1amips64\r\nOS\uff1aloongnix\uff08fedora21\uff09\r\npython\uff1a3.7.9\r\nthe test code is as bellow\uff1a\r\n[\r\n[resnet50.zip](https://github.com/tensorflow/tensorflow/files/5621083/resnet50.zip)\r\n\r\n](url)\r\n\r\nthe attach file include: \r\n1)resnet50-onepic.py(only one pic inference)\r\n2) resnet50-100.py(100 pictures for inference,the dataset download from: http://www.robots.ox.ac.uk/~vgg/data/pets/        ),you can download the Dataset from this website.\r\n\r\nTensorflow build command\uff1a\r\nuse mkl\r\nbazel build --verbose_failures --config=noaws --config=mkl --config=opt --host_copt=-march=loongson3a --action_env=BAZEL_LINKLIBS=-l%:libstdc++.a --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\nnot use mkl\uff1a\r\nbazel build --verbose_failures --config=noaws --config=opt --host_copt=-march=loongson3a --action_env=BAZEL_LINKLIBS=-l%:libstdc++.a --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**then I test \uff1apython-3.7.9 resnet50-onepic.py  or resnet-100.py**\r\nthe result is:\r\nresnet50 inference\uff1atensorflow-2.4.0 that use mkl is slower than tensorflow-2.4.0 which not use mkl\uff01\r\n\r\n**than, I do the same test on x86 platform(delete  --host_copt=-march=loongson3a when build on x86), it is the same result. it is still slower when use mkl on x86 platform**", "@zhangqiang-hf,\r\nCould you please go through [this similar issue](https://github.com/tensorflow/tensorflow/issues/33146) and let us know if it helps. Thanks!", "@zhangqiang-hf \r\n\r\nIn your code, the function predict_result() including the code to load the dataset.\r\nSo, when you load more images, the time used by predict_result() will be more.\r\nThat's why the time is more when you load 100 different images.\r\n\r\nTo estimate the performance of TF inference, it's better to record the pure inference time.\r\nOther codes should be excluded as possible.\r\n\r\nI check your case, after I change the estimate code (I only record the inference time).", "> @zhangqiang-hf\r\n> \r\n> In your code, the function predict_result() including the code to load the dataset.\r\n> So, when you load more images, the time used by predict_result() will be more.\r\n> That's why the time is more when you load 100 different images.\r\n> \r\n> To estimate the performance of TF inference, it's better to record the pure inference time.\r\n> Other codes should be excluded as possible.\r\n> \r\n> I check your case, after I change the estimate code (I only record the inference time).\r\n\r\nDear sir\uff0c\r\n  I test the same py file in two mode\uff08tensorflow with onednn or no onednn\uff09\uff0cso it is the same test situation", "@zhangqiang-hf \r\nIf you wan to to speed up loading the dataset, it maybe another topic.\r\nNot in the scope of Tensorflow with MKL.", "> @zhangqiang-hf\r\n> If you wan to to speed up loading the dataset, it maybe another topic.\r\n> Not in the scope of Tensorflow with MKL.\r\nfrom now on\uff0c I find it is stll slower to test one pic 100 times when use onednn\r\nOK\uff0c I will modify the test time only do the predict\u3002\r\nbut\uff0c when one pic  why it is slower then not use mkl\uff1f", "> @zhangqiang-hf\r\n> If you wan to to speed up loading the dataset, it maybe another topic.\r\n> Not in the scope of Tensorflow with MKL.\r\n\r\nDear sir,\r\n   I have modified my test py file. just as your opinion\uff0conly compute the cost time of predict, loading the data not included now.\r\n**first\uff0c I use Intel Core CPU\uff08i7-4790 cpu @ 3.6GHz\uff0chas 8 cores\uff09**\r\nthe optimization setting, like:\r\nexport TF_ENABLE_MKL_NATIVE_FORMAT=1  \r\nexport TF_NUM_INTEROP_THREADS=1\r\nexport TF_NUM_INTRAOP_THREADS=8\r\nexport OMP_NUM_THREADS=8\r\nexport KMP_BLOCKTIME=1\r\nexport KMP_AFFINITY=granularity=fine,compact,1,0\r\n\r\n**Then , I do the test as bellow:**\r\ncase1\uff1abs=100: one pic reproduce 100 times and call predict once, \r\ncase2\uff1aone pic do 100 predict\r\ncase3\uff1a100 different pics\uff0cone pic do once predict\uff0cso do 100 predicts in all\r\n**Now\uff0ccase1/2/3\uff0c resnet50 inference the result is the same\uff1a**\r\n1\uff09use tensorflow with onednn\uff0cdo the optimize setting above is quicker than not do the optimize setting\r\n2\uff09but\uff0cuse tensorflow with onednn do the optimize setting above is still slower than tensorflow not use onednn \uff01 \r\n3\uff09the tensorflow not use onednn\uff0c resnet50 inference is the quickest in the  case1/2/3", "@zhangqiang-hf \r\n1.\r\nI checked this i7-4790 , it includes 4 cores, 8 threads.\r\nPlease set with 4 in above setting.\r\n\r\n2.\r\nCould you share the build cmd for the TF with MKL on i7?\r\nor the cmd to install it.\r\n", "> @zhangqiang-hf\r\n> 1.\r\n> I checked this i7-4790 , it includes 4 cores, 8 threads.\r\n> Please set with 4 in above setting.\r\n> \r\n> \r\n> Could you share the build cmd for the TF with MKL on i7?\r\n> or the cmd to install it.\r\n\r\ncat /proc/cpuinfo\uff0c it displays 8 processor\uff0cbut cpu cores =4\uff0c ok\uff0c I will set \r\nexport TF_NUM_INTRAOP_THREADS=4\r\nexport OMP_NUM_THREADS=4\r\n\r\n\r\n**2. build cmd\uff08with onednn\uff09\uff1a**\r\nbazel build --verbose_failures --config=noaws --config=mkl --config=opt  --action_env=BAZEL_LINKLIBS=-l%:libstdc++.a --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**if no use onednn\uff0c omitted \u201c--config=mkl\u201d\u3002**\r\n\r\n**then generate whl\uff1a**bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg\r\n**and last install cmd\uff1a**/opt/python/python-3.7.9/bin/pip3.7 install  ~/tensorflow_pkg/tensorflow-xxx.whl\r\n\r\n> @zhangqiang-hf\r\n> 1.\r\n> I checked this i7-4790 , it includes 4 cores, 8 threads.\r\n> Please set with 4 in above setting.\r\n> \r\n> \r\n> Could you share the build cmd for the TF with MKL on i7?\r\n> or the cmd to install it.\r\n\r\ncat /proc/cpuinfo\uff0c it displays 8 processor\uff0cbut cpu cores =4\uff0c ok\uff0c I will set \r\nexport TF_NUM_INTRAOP_THREADS=4\r\nexport OMP_NUM_THREADS=4\r\n\r\n**2. build cmd\uff08with onednn\uff09\uff1a**\r\nbazel build --verbose_failures --config=noaws --config=mkl --config=opt  --action_env=BAZEL_LINKLIBS=-l%:libstdc++.a --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**if no use onednn\uff0c omitted \u201c--config=mkl\u201d\u3002**\r\n\r\n**then generate whl\uff1a**bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg\r\n**and last install cmd\uff1a**/opt/python/python-3.7.9/bin/pip3.7 install  ~/tensorflow_pkg/tensorflow-xxx.whl", "@zhangqiang-hf \r\nHave you modified the scripts in resnet50.zip which detect the performance?\r\nIf yes, could you share your latest scripts?\r\n\r\nI will reproduce your issue local.", "> @zhangqiang-hf\r\n> Have you modified the scripts in resnet50.zip which detect the performance?\r\n> If yes, could you share your latest scripts?\r\n> \r\n> I will reproduce your issue local.\r\n\r\nYes, I have modified the test file.  please see the attach file. \r\nwhen test, I have set\r\nexport TF_ENABLE_MKL_NATIVE_FORMAT=1\r\nexport TF_NUM_INTEROP_THREADS=1\r\nexport TF_NUM_INTRAOP_THREADS=4\r\nexport OMP_NUM_THREADS=4\r\nexport KMP_BLOCKTIME=1\r\nexport KMP_AFFINITY=granularity=fine,compact,1,0\r\n\r\nand the test result is that:\r\ncase1:   resnet50-onepic.py,  do the predict for one picture\r\ncase2\uff1aresnet50-bs100.py,  one pic reproduce 100 times and call predict once,\r\ncase3\uff1aresnet50-one100.py,  one pic do 100 predict\r\ncase4\uff1aresnet50-100pic.py,  100 different pics\uff0cone pic do once predict\uff0cso do 100 predicts in all\r\nNow\uff0ccase2/3/4\uff0c resnet50 inference the result is the same\uff1a\r\n1\uff09use tensorflow with onednn\uff0cdo the optimize setting above is quicker than not do the optimize setting for case2/3/4\r\n2\uff09but\uff0cuse tensorflow with onednn do the optimize setting above is still a bit slower or nearby the tensorflow not use onednn\uff0c it is not better than not use mkl \uff01\r\n3\uff09case1\uff0c that is no effect when do the optimize setting when tensorflow use mkl. it is still slower!\r\n[\r\n[resnet50.zip](https://github.com/tensorflow/tensorflow/files/5656742/resnet50.zip)\r\n](url)", "@zhangqiang-hf \r\ncase1: resnet50-onepic.py\r\nThe problem you mentioned is present.\r\nBut, I repeat the predict() 100 times and got the average time, it's a little better than stack TF.\r\n\r\n```\r\ntimes = 100\r\n    a = time.time()\r\n    for i in range(times):\r\n        preds = model.predict(x)\r\n    b = time.time()\r\n    seconds = (b - a)/times\r\n```\r\n\r\nThe reason was explained in preview comment:\r\n\"\r\n@zhangqiang-hf @Zantares\r\nAs answer from Zantares: \"Bad performance is expected if you only run session once because TF with oneDNN will take more time in warmup (1st iteration). You will get similar performance with different pics as long as you don't change pic shape. In same word, TF with oneDNN doesn't care about data, it only cares shape.\"\r\n\r\nI just test to run 100 times for BS=1.\r\nThe performance of TF with MKL is better than stack TF.\r\n\"\r\n\r\ncase2\uff1aresnet50-bs100.py\r\nbetter \r\n\r\nCase 3: resnet50-one100.py, one pic do 100 predict\r\nbetter\r\n\r\ncase4\uff1aresnet50-100pic.py\r\nI have not such dataset, so not run it.\r\nBut the code is not good to test the performance as I said: \r\nThe running time includes the image load process. That would be impacted by both IO and CPU.\r\nSo, this case can't be recommended to test the CPU performance load.\r\n\r\nCould you run following cmd and paste the output?\r\n```\r\nlscpu\r\n```\r\nIn my case, I use Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz which including 24 cores.\r\nI use numactrl to limit only 4 cores to be used:\r\n```\r\nnumactl -C 1-4 -m 0 python resnet50-bs100.py\r\n\r\n```", "> @zhangqiang-hf\r\n> case1: resnet50-onepic.py\r\n> The problem you mentioned is present.\r\n> But, I repeat the predict() 100 times and got the average time, it's a little better than stack TF.\r\n> \r\n> ```\r\n> times = 100\r\n>     a = time.time()\r\n>     for i in range(times):\r\n>         preds = model.predict(x)\r\n>     b = time.time()\r\n>     seconds = (b - a)/times\r\n> ```\r\n> \r\n> The reason was explained in preview comment:\r\n> \"\r\n> @zhangqiang-hf @Zantares\r\n> As answer from Zantares: \"Bad performance is expected if you only run session once because TF with oneDNN will take more time in warmup (1st iteration). You will get similar performance with different pics as long as you don't change pic shape. In same word, TF with oneDNN doesn't care about data, it only cares shape.\"\r\n> \r\n> I just test to run 100 times for BS=1.\r\n> The performance of TF with MKL is better than stack TF.\r\n> \"\r\n> \r\n> case2\uff1aresnet50-bs100.py\r\n> better\r\n> \r\n> Case 3: resnet50-one100.py, one pic do 100 predict\r\n> better\r\n> \r\n> case4\uff1aresnet50-100pic.py\r\n> I have not such dataset, so not run it.\r\n> But the code is not good to test the performance as I said:\r\n> The running time includes the image load process. That would be impacted by both IO and CPU.\r\n> So, this case can't be recommended to test the CPU performance load.\r\n> \r\n> Could you run following cmd and paste the output?\r\n> \r\n> ```\r\n> lscpu\r\n> ```\r\n> \r\n> In my case, I use Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz which including 24 cores.\r\n> I use numactrl to limit only 4 cores to be used:\r\n> \r\n> ```\r\n> numactl -C 1-4 -m 0 python resnet50-bs100.py\r\n> ```\r\n\r\nDear sir,\r\nmy test result with cost time as bellow:\r\n  case1:  onepic,  slower then not use onednn, you known.   (with onednn:1.3s,    not with onednn :0.6s)\r\n  case2:  bs100,  nearby   (with onednn:4.7s,  not with onednn:4.5s)\r\n  case3:  one100,  slower  (with onednn: 9.5s,   not with onednn:6.8s)\r\n  case4: 100pic, a bit quicker (with onednn:24s,  not with onednn:27s)\r\nfor this four cases, I test the same test script with the two situation\uff08tensorflow  with onednn or not with onednn\uff09\uff0cthe optimize setting as said above\u3002\r\n\r\nlscpu infor as bellow:\r\n\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    2\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 60\r\nModel name:            Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\r\nStepping:              3\r\nCPU MHz:               900.140\r\nCPU max MHz:           4000.0000\r\nCPU min MHz:           800.0000\r\nBogoMIPS:              7184.05\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              8192K\r\nNUMA node0 CPU(s):     0-7\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm xsaveopt dtherm ida arat pln pts\r\n", "@zhangqiang-hf \r\nI use following cmd to build the TF with MKL:\r\n```\r\nbazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=mkl  --copt=-march=native //tensorflow/tools/pip_package:build_pip_package \r\n```\r\n\r\nYou can try it and test.", "> @zhangqiang-hf\r\n> I use following cmd to build the TF with MKL:\r\n> \r\n> ```\r\n> bazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=mkl  --copt=-march=native //tensorflow/tools/pip_package:build_pip_package \r\n> ```\r\n> \r\n> You can try it and test.\r\n\r\nok\uff0c later \uff0c I will try to build as you said. These build items will give good performance?", "@zhangqiang-hf \r\nIt's working for me.\r\nI'm not sure for your case. \r\n\r\nLet's check the result.\r\n\r\nIf it's not working for you, there is no more method.\r\nYour CPU is a little old, so that I can't reproduce it in same HW.\r\n\r\nMy test approve that TF with MKL is better in Intel Xeon CPU.\r\n\r\nI have shared you all of common optimization methods on Intel CPU.\r\nIf you use non-Intel CPU, you could choose the TF version which is better in your platform.\r\nI guess your target is to get the best performance on your CPU platform by TF with MKL.\r\nEven if the method is working in i7, it's not sure for you CPU platform.\r\n", "@zhangqiang-hf \r\nCould you send me an email for your target?", "> @zhangqiang-hf\r\n> It's working for me.\r\n> I'm not sure for your case.\r\n> \r\n> Let's check the result.\r\n> \r\n> If it's not working for you, there is no more method.\r\n> Your CPU is a little old, so that I can't reproduce it in same HW.\r\n> \r\n> My test approve that TF with MKL is better in Intel Xeon CPU.\r\n> \r\n> I have shared you all of common optimization methods on Intel CPU.\r\n> If you use non-Intel CPU, you could choose the TF version which is better in your platform.\r\n> I guess your target is to get the best performance on your CPU platform by TF with MKL.\r\n> Even if the method is working in i7, it's not sure for you CPU platform.\r\n\r\nYes\uff0c  My target is to get the best performance on my CPU platform(mips64 cpu) by TF-2.4.0 with oneDNN\r\nI do the same test on X86 intel cpu. the result is above that I said.", "> @zhangqiang-hf\r\n> Could you send me an email for your target?\r\n\r\nDear sir, you are chinese? Do you have weixin? share we make a friend? can I add your weixin?", "@zhangqiang-hf Yes, could you send me an email, instead of comment here.", "> @zhangqiang-hf Yes, could you send me an email, instead of comment here.\r\n\r\n\r\n\r\n> @zhangqiang-hf Yes, could you send me an email, instead of comment here.\r\n\r\nI have sent a email to you, please check it, thank you!"]}, {"number": 45288, "title": "load_model in tf>=2.3.0 raises TypeError when loading a model saved in tf 2.2.0", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Google Colab\r\n- TensorFlow version: 2.2.0 vs 2.3.1 or tf-nightly (2.5.0.dev20201130)\r\n- Python version: 3.6.9\r\n- GPU model and memory: None (Colab CPU)\r\n\r\n**Describe the current behavior**\r\nWhen I saved a model using `tf.keras.models.Model(...).save` in tf 2.2.0, I am unable to load the model back using `tf.keras.models.load_model` in tf 2.3.1 or the latest tf-nightly. See abbreviated error message below:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-8326baccad65> in <module>()\r\n      1 # Restart the runtime, then run\r\n      2 import tensorflow as tf\r\n----> 3 model = tf.keras.models.load_model('hidden_net')\r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in reconstruct_from_config(config, custom_objects, created_layers)\r\n   1234     layer = created_layers[layer_name]\r\n   1235     node_index = get_node_index(layer, node_index)\r\n-> 1236     layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\r\n   1237     output_tensors.append(nest.flatten(layer_output_tensors)[tensor_index])\r\n   1238 \r\n\r\nTypeError: list indices must be integers or slices, not NoneType\r\n```\r\n\r\n**Describe the expected behavior**\r\nShould be able to load the model back\r\n\r\n**Standalone code to reproduce the issue**\r\nSee [gist](https://colab.research.google.com/gist/shengpu1126/5d4674a9475590ef2fe46565f0641b12/untitled2.ipynb)\r\n\r\n**Other info / logs**\r\n- Maybe related to #42890. I could not find a newer issue related to this so I created a new one; please close it if it's a duplicate. \r\n- This may have to do with the way I defined my model, where I used a combination of Keras sequential and functional API. Could it be related to the recent Keras functional refactoring in 2.4.0? ", "comments": ["@shengpu1126 \r\nI ran the gist and see a different response, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/919d03ee55b3f8cd2ad3e66dfbb40b79/untitled476.ipynb).", "@Saduf2019 You would need to restart the runtime after installing the 2.3.1 version and reimport it. I've updated the [gist](https://colab.research.google.com/gist/shengpu1126/5d4674a9475590ef2fe46565f0641b12/untitled2.ipynb) to print out the version number after reimporting, could you please try again? ", "I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/c4d7b6ef2ccb6b2416bc8580e017ed7f/untitled483.ipynb).", "@shengpu1126 There are some changes (\"keras_metadata.pb\" as mentioned in the warning) in model saving and loading before and after `TF2.4`. The code throws the following warnings which clearly explains what is missing.\r\n\r\n\r\n```\r\n2.5.0-dev20201217\r\nWARNING:tensorflow:SavedModel saved prior to TF 2.4 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-2b2d876fd0e5> in <module>()\r\n      5 print(tf.__version__)\r\n      6 \r\n----> 7 loaded_model = tf.keras.models.load_model('hidden_net')\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in reconstruct_from_config(config, custom_objects, created_layers)\r\n   1308     layer = created_layers[layer_name]\r\n   1309     node_index = get_node_index(layer, node_index)\r\n-> 1310     layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\r\n   1311     output_tensors.append(nest.flatten(layer_output_tensors)[tensor_index])\r\n   1312 \r\n\r\nTypeError: list indices must be integers or slices, not NoneType\r\n```\r\n\r\nHowever, Looks like this is a bug or atleast need to update the following warning. Even when the model was created and saved in `TF2.4`, and later loaded in `tf-nightly`, it throws the warning as follows. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/fcb9ff5279139417b0a5174a640700dd/untitled483.ipynb). we will look into it.\r\n\r\n```\r\n2.5.0-dev20201217\r\nWARNING:tensorflow:SavedModel saved prior to TF 2.4 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\r\nWARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\r\n```", "I am closing this issue as the original issue is resolved. I will open another issue to track the progress on removing the warning when the model (tf format only) saved using `TF2.4` but later reloaded using `tf-nightly` throws a warning as mentioned in my earlier response. \r\n\r\nI noticed that there is no warning if the model was saved in `h5` format. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45288\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45288\">No</a>\n", "Hello, \r\n\r\nThanks for creating the other issue for the incorrect warning message. \r\n\r\nUnfortunately I don't believe the original issue has been resolved. I have created a new [gist](https://colab.research.google.com/gist/shengpu1126/eec804b543ae8bd69bbab7bd3699cd61/untitled2.ipynb) that demonstrates the issue with the latest nightly version. \r\n\r\n> **IMPORTANT NOTE**: the code first saves a model in TF 2.2.0, and then you need to **restart the runtime** and reimport TF-nightly to load the saved model. \r\n\r\nThis is crucial because I have models saved in TF 2.2.0 and I have updated my TF to the latest version, now I can no longer load those models. ", "@shengpu1126 Looks like there is some issue with your model. I tried running another [simple model](https://colab.research.google.com/gist/jvishnuvardhan/c79db173a23d9a941ed203d8b8f836f0/untitled74.ipynb), saved using `tf-nightly`, restarted runtime, and loaded it without any issue. But, when i tried your model, it throws an error as shown by you.\r\n\r\nI will reopen the issue for deeper look. Thanks!", "@jvishnuvardhan Thank you! \r\n\r\nYes when I tried with simpler models it works fine. I suspect it has to do with using `keras.Sequential` as a layer inside the keras functional interface `keras.Model(inputs, outputs)`. \r\n\r\nI'm quoting the network definition below for easier reference:\r\n\r\n```python\r\ndef init_networks():\r\n    # Inputs\r\n    state_input = tf.keras.Input(shape=(d), name='state_input')\r\n    action_input = tf.keras.Input(shape=(), dtype=tf.int32, name='action_input')\r\n    \r\n    # Layers\r\n    hidden_layers = tf.keras.Sequential([\r\n        tf.keras.layers.Dense(1000, activation=\"relu\"),\r\n        tf.keras.layers.Dense(nA),\r\n    ], name='hidden_layers')\r\n    \r\n    # Outputs\r\n    hidden_output = hidden_layers(state_input)\r\n\r\n    # Models\r\n    hidden_net = tf.keras.Model(inputs=[state_input], outputs=[hidden_output], name='hidden_net')\r\n    \r\n    return hidden_net\r\n\r\nhidden_net = init_networks()\r\n```", "@shengpu1126 I updated one line in your code as follows (added `input_shape` to first layer of `Sequential`)\r\n\r\n`tf.keras.layers.Dense(1000, activation=\"relu\", input_shape=(d,)),`\r\n\r\nAfter the above update, I cannot reproduce the error. [Here](https://colab.research.google.com/gist/jvishnuvardhan/ad305a6648a729e50cea08006e7d0a1d/untitled2.ipynb) is a gist for your reference. \r\n\r\nCan you please verify once and close the issue if this was resolved for you. Thanks!", "Yes that solved it. Thank you! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45288\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45288\">No</a>\n"]}, {"number": 45287, "title": "Import Error DLL failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64bit)\r\n- TensorFlow installed from (source or binary): install using conda in command window as admin\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: installed using conda then created virtual env\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: RTX 2060 16GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have installed tensorflow on my windows desktop with anaconda. As a result I followed the steps from a youtube video by Jeff Heaton. Now I would like to run Tensorflow in  VS code and it will not work. I get an import error that says the following ImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nThe only code I have is an import line \"import tensorflow as tf\" when I run the script by using ctl+F5, I get the error. When I type \"python test.py\" in the no errors are thrown. (test.py is the name of my file)\r\n\r\n\r\n**Creating and install packages and tensorflow for environment steps**\r\n1. Run CMD as admin\r\n2. conda create -n tensorflow-cpu python=3.8\r\n3. conda activate tensorflow-cpu \r\n4. conda install jupyter matplotlib numpy pandas scipy\r\n5. pip install tensorflow \r\n     got lots of messages that the requirement was already met.\r\n6. python \r\n7. import tensorflow as tf\r\n8. tf.__version__\r\n9. 2.3.1\r\n10. quit()\r\n11. code (opens VS code)\r\n12. create new file\r\n13. import tensorflow as tf (autofill in works)\r\n14. run\r\n15. no error\r\n16. add other packages (import matplotlib, pandas etc...)\r\n17. autofill no longer works\r\n18. create new file\r\n19. import tensorflow as tf (autofill doesn't work)\r\n20. run (error outputted in terminal)\r\n21. run python test.py in terminal (no error)\r\n\r\n**Any other info / logs**\r\nJeff heaton video link: https://www.youtube.com/watch?v=RgO8BBNGB8w&t=474s\r\n\r\n\r\n", "comments": ["When I go back to cmd and run \"code\" again and open a new VS code window, autofill works again but error persists.", "@ObeyedSky622 \r\n\r\nLooks like this is not issue with Tensorflow installation as you are able to import without any issues. \r\nThis seems to be issue with VS code. Thanks!", "@ravikyram Then why when I run the code by pressing F5 I get the error and run I run in terminal I don't get anything? I also ran the script in IDLE and got the same error.", "@ObeyedSky622 \r\n\r\nCould you please create a new virtual environment and try running the code and see if the issue still persists.If you facing the issue request you to share the error log. Thanks!", "Yes. I have created 2 new environments already. Here is the full error:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"d:\\VS_code_files\\ml_files\\functionLib.py\", line 8, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\bre13\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "@ObeyedSky622 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167\r\n\r\nThanks!", "Yes, I figured the issue out. When I clicked download for python it auto-downloaded the 32-bit version and not the 64-bit. I uninstalled python and installed the correct version.", "@ObeyedSky622 \r\n\r\nTF supports 64 bit only.\r\n\r\nPlease, close this thread if your issue was resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45287\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45287\">No</a>\n"]}, {"number": 45286, "title": "Push and pop gcc diagnostic pragma's in the flexbuffer patching script. ", "body": "The change from PR #45040 made null-dereference an error for any code that was compiled after flexbuffers.h was included. This resulted in build errors that were hard to debug.\r\n\r\nSee [this comment](https://github.com/tensorflow/tensorflow/issues/44971#issuecomment-736130061) for additional context.\r\n\r\nThe patched lines in flexbuffers.h after this change are:\r\n```cc\r\n#if 1\r\n#pragma GCC diagnostic push\r\n#pragma GCC diagnostic ignored \"-Wnull-dereference\"\r\n          // TODO(b/173239141): Patched via micro/tools/make/flexbuffers_download.sh\r\n          // Introduce a segfault for an unsupported code path for TFLM.\r\n          return *(static_cast<double*>(nullptr));\r\n#pragma GCC diagnostic pop\r\n#else\r\n          // This is the original code\r\n          double d;\r\n          flatbuffers::StringToNumber(AsString().c_str(), &d);\r\n          return d;\r\n#endif\r\n\r\n```", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45284, "title": "how  optimize a noise image with tensorflow?", "body": "\r\nhow to apply sgd to an image with tensorflow?\r\n\r\nI have these elements:\r\n* image noise\r\n* target image\r\n* optimizer\r\n* loss function\r\nIs there a way to optimize a noise image so that it looks more like a target image?\r\nfirst it starts with noise then we calculate the difference or error between image noise and target image, then we calculate the gradient and apply it to the noise image.", "comments": ["@molo32 \r\nPlease use [Denoising AutoEncoder](https://www.pyimagesearch.com/2020/02/24/denoising-autoencoders-with-keras-tensorflow-and-deep-learning/), and move this ticket to closed status as it is not a bug or feature request, you may open a ticket on stackoverflow for any further help on this.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45283, "title": "Improve recurrent layers Call API mask documentation", "body": "The documentation for the \"mask\" parameter in the recurrent layers Call API should be augmented to explain what is the effect of including a \"True\" or \"False\" parameter for each timestep.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45283) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 45282, "title": "Update array_ops.py", "body": "Fixes Github #45239", "comments": []}, {"number": 45281, "title": "I am trying to convert yolov3 to a full uint8 tflite model after, i got this error : Quantized not yet supported for op : 'EXP'", "body": "Quantized not yet supported for op : 'EXP'\r\nQuantized not yet supported for op : 'EXP'\r\nQuantized not yet supported for op : 'EXP'", "comments": ["@Tieckby \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "@Tieckby \r\n\r\nLooks like duplicate #45301.Please, close this issue and we can track the issue in #45301.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45281\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45281\">No</a>\n", "No, it doesn't.\n\nOn Mon, Dec 7, 2020, 5:52 AM tensorflow-butler[bot] <\nnotifications@github.com> wrote:\n\n> Are you satisfied with the resolution of your issue?\n> Yes\n> <https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45281>\n> No\n> <https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45281>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45281#issuecomment-739683441>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AMBZXSGRCCRD2NJEC7IVXMTSTRUQBANCNFSM4UICHXGQ>\n> .\n>\n", "@Tieckby Let's continue discussions at the #45301.", "Ok, Can you solve it ?\n\nOn Mon, Dec 7, 2020, 6:27 AM Jae sung Chung <notifications@github.com>\nwrote:\n\n> @Tieckby <https://github.com/Tieckby> Let's continue discussions at the\n> #45301 <https://github.com/tensorflow/tensorflow/issues/45301>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/45281#issuecomment-739698578>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AMBZXSDVMKUPUUQQLQHSIW3STRYUBANCNFSM4UICHXGQ>\n> .\n>\n"]}, {"number": 45280, "title": "Fix unique shape inference", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/44788. Seems that python side hasn't used V2 ops yet.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/unique_op.cc#L131\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L2007-L2011", "comments": ["Sorry for the delay, slipped of my radar last week. Will try to get to it shortly.", "CL mostly looks good. The reason why this isn't being used in python right now is that ideally we'd like multiple axis support and for that I think we need to implement an UniqueOpV3 that supports it. "]}, {"number": 45279, "title": "Error building graph with `@tf.function` decorator for recursive function with strided slices", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux version 5.9.8-arch1-1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow --user \r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1\r\n- Python version: python 3.8.6-1\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\n\r\nI coded my own 3 dimensional FFT with TensorFlow, translated from the algorithm `In[4]` of [https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/](https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/).\r\n\r\nI know there is already an FFT coded in TensorFlow, but it does not have a gradient implemented, which I need.\r\n\r\nThe code works without the decorators `@tf.function` and gives results coherent with `numpy`. However it crashes while building the graph if they are present, invoking an error on dimensions (ill computed in the case of graph computation). I have not been able to trace the problem to its core. \r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the code to work with decorators, however I must admit that the use of strided slices in a recursive function might be not be compatible with automatic graph building (lines 30 and 31).\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndtype = 'float32'\r\ncdtype = 'complex64'\r\nc_pi = tf.constant(np.pi, cdtype)\r\n\r\n# Leaves of the FFT algorithm : DFT of 32\r\n# Just building a 32 x 32 complex matrix\r\ntf_Nmin = 32\r\ntf_rg = tf.range(tf_Nmin)\r\ntf_k = tf.broadcast_to(tf_rg, (tf_Nmin, tf_Nmin))\r\ntf_n = tf.transpose(tf_k)\r\ntf_M = tf.exp(-2j * c_pi * tf.cast(tf_k * tf_n / tf_Nmin, cdtype))\r\n\r\n\r\n# Matrix product between M and x with shape = [32, 128, 128] \r\n# Works without the decorator\r\n# Fails with the decorator, invoking that the shapes are [32,32] and [128,16384]. \r\n@tf.function\r\ndef _tf_FFT0_leaf(x):\r\n    return (tf.tensordot(tf_M, x, axes=[[1], [0]]))\r\n\r\n\r\n# Nodes of the FFT algorithm\r\n@tf.function\r\ndef _tf_FFT0_node(x, N):\r\n    N2 = N // 2\r\n    XE = tf_FFT0(x[::2, :, :], N2)\r\n    XO = tf_FFT0(x[1::2, :, :], N2)\r\n    fac = tf.exp(-2j * c_pi * tf.cast(tf.range(N2) / N, cdtype))\r\n    fac = tf.transpose(tf.broadcast_to(fac, [tf_N, tf_N, N2]), perm=(2, 0, 1))\r\n    fXO = fac * XO\r\n    return (tf.concat([XE + fXO, XE - fXO], axis=0))\r\n\r\n\r\n# Recursive function of the FFT algorithm\r\n@tf.function\r\ndef tf_FFT0(x, N):\r\n    return (tf.cond(N <= tf_Nmin, lambda: _tf_FFT0_leaf(x),\r\n                    lambda: _tf_FFT0_node(x, N)))\r\n\r\n\r\n# Run the code\r\nnx = 128\r\nx = np.random.random((nx, nx, nx))\r\ntf_x = tf.cast(x, cdtype)\r\ntf_N = tf.constant(x.shape[0], 'int32')\r\n\r\ny = tf_FFT0(tf_x, tf_N)\r\nz = np.fft.fft(x, axis=0)\r\nprint()\r\nprint('DIFF WITH NUMPY', np.mean(np.abs(y - z) / np.abs(z)))\r\n```\r\n**Other info / logs** \r\n\r\nOutput **without** decorator:\r\n```\r\n2020-11-30 19:51:41.195663: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-11-30 19:51:41.195690: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-11-30 19:51:42.046458: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-11-30 19:51:42.046475: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-11-30 19:51:42.046485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lyonovae21.in2p3.fr): /proc/driver/nvidia/version does not exist\r\n2020-11-30 19:51:42.046697: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-30 19:51:42.066848: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1900610000 Hz\r\n2020-11-30 19:51:42.067237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5590a7465cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-30 19:51:42.067308: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n\r\nDIFF WITH NUMPY 4.81155889723075e-06\r\n```\r\n\r\nOutput **with** decorator:\r\n```\r\n2020-11-30 20:13:22.743043: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-11-30 20:13:22.743073: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-11-30 20:13:23.540001: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-11-30 20:13:23.540022: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-11-30 20:13:23.540035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lyonovae21.in2p3.fr): /proc/driver/nvidia/version does not exist\r\n2020-11-30 20:13:23.540281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-30 20:13:23.560290: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1900610000 Hz\r\n2020-11-30 20:13:23.560760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602b27b1590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-30 20:13:23.560786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"crash_tf.py\", line 54, in <module>\r\n    y = tf_FFT0(tf_x, tf_N)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 696, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3065, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 973, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    crash_tf.py:43 tf_FFT0  *\r\n        return (tf.cond(N <= tf_Nmin, lambda: _tf_FFT0_leaf(x),\r\n    crash_tf.py:21 _tf_FFT0_leaf  *\r\n        return (tf.tensordot(tf_M, x, axes=[[1], [0]]))\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\r\n        return target(*args, **kwargs)\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:4518 tensordot\r\n        ab_matmul = matmul(a_reshape, b_reshape)\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\r\n        return target(*args, **kwargs)\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:3253 matmul\r\n        return gen_math_ops.mat_mul(\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:5640 mat_mul\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper\r\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal\r\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal\r\n        ret = Operation(\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__\r\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\r\n    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\r\n        raise ValueError(str(e))\r\n\r\n    ValueError: Dimensions must be equal, but are 32 and 128 for '{{node Tensordot/MatMul}} = MatMul[T=DT_COMPLEX64, transpose_a=false, transpose_b=false](Tensordot/a, Tensordot/Reshape)' with input shapes: [32,32], [128,16384].\r\n```", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/004c7c6d9d15ef277811c589beadf53f/45279.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/cfd457b9fd70a2e94bbe964a0bf3265a/45279-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Unfortunately, you're right, `tf.function` doesn't support recursion at the moment. It is possible to implement in theory, and it's a feature that's being asked now and then.\r\n\r\nThe error message on the other hand is a confusing side effect of tracing combined with static shape verification: when tracing `tf_FFT0`, it is traced with the most specific shape of its input, which happens to be `(128, 128, 128)`. Then the tf.cond traces both its branches, including `_tf_FFT0_leaf`. But when tracing that, we get a `matmul` which checks the current shape of x (`(128, 128, 128)`) and `tf_M` and complains that they're mismatched. The tracer has no idea that `_tf_FFT0_leaf` will never be called with this shape. That issue is resolved by telling `tf.function` to assume that the shape is dynamic so it should skip this static verification. We can do that like so:\r\n\r\n```\r\n@tf.function(\r\n    input_signature=[\r\n                     tf.TensorSpec(shape=[None, nx, nx], dtype=cdtype),\r\n                     tf.TensorSpec(shape=[], dtype=tf.int32)])\r\ndef tf_FFT0(x, N):\r\n  ...\r\n```\r\n\r\n(this is something worth doing to avoid excessive retraces as well)\r\n\r\nAlas, this only explains the strange error message, and doesn't resolve the main problem which is that tf.function doesn't support recursion.\r\n\r\nIt's always possible to rewrite a recursive algorithm in a non-recursive fashion, using a few while loops and `tf.TensorArray` as a stack, see the example below.\r\nBut first I should ask whether the ops in [tf.signal](https://www.tensorflow.org/api_docs/python/tf/signal) have the FFT implementations that you need?\r\n\r\nAnyway here's the non-recursive example. It's a bit long because working with `TensorArray` is very verbose. But we can use autograph to write the control flow as normal Python:\r\n\r\n```\r\n@tf.function(\r\n    input_signature=[\r\n                     tf.TensorSpec(shape=[None, nx, nx], dtype=cdtype),\r\n                     tf.TensorSpec(shape=[], dtype=tf.int32)])\r\ndef tf_FFT0(x, N):\r\n    s_x = tf.TensorArray(cdtype, size=0, dynamic_size=True, element_shape=[None, nx, nx])  # Set up a stack for x.\r\n    s_N = tf.TensorArray(tf.int32, size=0, dynamic_size=True)  # Set up a stack for N.\r\n    s_ret = tf.TensorArray(cdtype, size=0, dynamic_size=True, infer_shape=False)  # Set up a stack for the results.\r\n\r\n    # Set up a stack for the state needed to simulate the recursion.\r\n    # Node states:\r\n    #  0 - entry, need to calculate tf_FFT0(x[::2, :, :], N2)\r\n    #  1 - need to calculate tf_FFT0(x[1::2, :, :], N2)\r\n    #  2 - both operands done, compute the final result\r\n    s_node = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\r\n\r\n    # TensorArray doesn't support deletion, so keep a stack pointer separately.\r\n    level = 0\r\n    s_x = s_x.write(level, x)\r\n    s_N = s_N.write(level, N)\r\n    s_node = s_node.write(level, 0)\r\n\r\n    level = tf.constant(0)  # For autograph - we need a TF while_loop.\r\n    while level >= 0:\r\n      N = s_N.read(level)\r\n      x = s_x.read(level)\r\n      if N <= tf_Nmin:\r\n        # leaf\r\n        # No recursion. Put results on stack and go back.\r\n        s_ret = s_ret.write(level, tf.tensordot(tf_M, x, axes=[[1], [0]]))\r\n        level -= 1\r\n      else:\r\n        # node\r\n        # Simulate recursion.\r\n        state = s_node.read(level)\r\n        N2 = N // 2\r\n        if state == 0:\r\n          # Nothing calculated yet.\r\n          s_node = s_node.write(level, 1)\r\n\r\n          # \"Call\" for first operand.\r\n          level += 1\r\n          s_x = s_x.write(level, x[::2, :, :])\r\n          s_N = s_N.write(level, N2)\r\n          s_node = s_node.write(level, 0)\r\n\r\n        elif state == 1:\r\n          # First operand done.\r\n          s_node = s_node.write(level, 2)\r\n\r\n          # Copy result for first operand to current level.\r\n          s_ret = s_ret.write(level, s_ret.read(level + 1))\r\n\r\n          # \"Call\" for second operand.\r\n          level += 1\r\n          s_x = s_x.write(level, x[1::2, :, :])\r\n          s_N = s_N.write(level, N2)\r\n          s_node = s_node.write(level, 0)\r\n\r\n        else:\r\n          # Both operands done. Current level has first operand, next level has the second.\r\n          XE = s_ret.read(level)\r\n          XO = s_ret.read(level + 1)\r\n          fac = tf.exp(-2j * c_pi * tf.cast(tf.range(N2) / N, cdtype))\r\n          fac = tf.transpose(tf.broadcast_to(fac, [tf_N, tf_N, N2]), perm=(2, 0, 1))\r\n          fXO = fac * XO\r\n\r\n          # All done. Put final result on stack and go back.\r\n          s_ret = s_ret.write(level, tf.concat([XE + fXO, XE - fXO], axis=0))\r\n          level -= 1\r\n\r\n    # Final results should be at the bottom of the stack.\r\n    return s_ret.read(0)\r\n```", "Thanks a lot for your very detailed answer! \r\n\r\nI am surprised that it is possible for the algorithm to draw a graph from a python function containing a `while` statement! Does it impact the performances? Is `tensorflow` going to be able to compute the gradient of that function ?\r\n\r\nI am using the HMC method implemented in `tensorflow_probabilities` but in order to compute my likelihood, I need to perform a 3D-FT on the parameters and interpolate the resulting field on a few dozen of thousands of points... However, letting the interpolation part aside, the `tf.signal.irfft3d` does not have a gradient implemented, which led to a error while trying to run the HMC. I do not have a example code to hand right now, but the error simply read in substance as `tf.signal.irfft3d does not have a gradient method implemented`. I then decided to compute my own, using as `tf.function` to efficiently build the graph. ", "The graph is drawn by autograph which uses source code transformation. Simply put, it turns the `while` statement into a `tf.while_loop` call; the transformation can be done mechanically. And the result is differentiable so gradients should work, too.\r\n\r\nPerformance-wise, it's identical to writing `tf.cond` and `tf.while_loop` by hand (but less annoying). A word of caution that `tf.cond` and `tf.while_loop` are not terribly fast themselves. They do become much faster by setting the `experimental_compile=True` arg of `tf.function`, although that has some limitations, and I think it ran into a bug that we'll need to fix before we can use it. Hopefully we should be able to try it in a few weeks.", "Thank you again for your answer. \r\nDo you thus confirm there is no simpler work-around to get the gradient of the (inverse) Fourrier Transform in `tensorflow` ?\r\nShould I then close the issue? ", "Yes, I think the example I gave is about as simple as it can get, at the moment. We're considering supporting recursion in `tf.function`, but there are no concrete plans for it yet.\r\nTechnically one could also define a gradient kernel for `tf.signal.irfft3d`, but that is not trivial either and involves writing C++ code.\r\nSo I believe it's ok to close this issue, and I hope the alternate solution I gave is useful!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45279\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45279\">No</a>\n", "@ValadeAurelien,\r\nCan you please confirm if your issue has been resolved so that we can close it. Thanks!"]}, {"number": 45278, "title": "Keras SavedModel: Ignore custom metrics failure when compile=False", "body": "Keras currently doesn't support serialising and loading custom metrics in the saved model format.\r\n\r\nHowever, when loading models with `compile=False` these metrics are not needed but still prevent the model from being loaded correctly.\r\nThis PR will ignore such errors when used with `tf.keras.models.load_model(path, compile=False)` allowing to reload models without code even if they have been saved with custom metrics. This is important since [\"SavedModels are [supposed to be] able to save custom objects like subclassed models and custom layers without requiring the original code\"](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects).\r\n\r\nThis PR fixes #43478 which was introduced in TensorFlow 2.2. It is a workaround until [proper support for serialising and deserialising custom metrics](https://github.com/tensorflow/tensorflow/blob/107b96da1ca5f0db752a11c4fae85ef1272ee175/tensorflow/python/keras/saving/saved_model/metric_serialization.py#L43-L46) is implemented. /cc @k-w-w, @yhliang2018, @qlzh727\r\n\r\n@mihaimaruseac Would you still accept a cherry-pick of this PR onto the 2.4 release branch, since it fixes a bug that prevents loading of saved models with custom metrics that have been saved with TensorFlow 2.2 or newer? To me it looks like the risk of this PR breaking any current users is pretty low, but I might be missing something here.", "comments": ["Apologies for the delay. Unfortunately this is too late for a cherry-pick as it will need another RC and then push the final release in the next year :(", "> Unfortunately this is too late for a cherry-pick as it will need another RC and then push the final release in the next year :(\r\n\r\nThat makes sense, I only pinged you because #43478 was labeled as a `regression issue` for 2.3 so I thought it might still have a chance to make it :)", "In any case, after merging, let's make a cherrypick on the 2.4 branch. In case there is a patch release we can get it fixed in 2.4.1."]}, {"number": 45277, "title": "Fixed wrong cast which caused problems with build for ARC targets.", "body": "This PR fixes the build problem. It does it using const_cast which is necessary measure at the moment, since we have no choice with the current state of ARC backend interface. But it will be replaced in future update of our backend (with update to MLI 2.0) and our team already has plans how to deal with this mismatch.\r\n\r\nFixes #45106", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}]