[{"number": 50849, "title": "[CherryPick2.6]Ensure non-empty compressed input in tf.raw_ops.UncompressElement", "body": "PiperOrigin-RevId: 383955815\nChange-Id: I072a84fd02738dd2f51b3f42836ed80067dba4a8", "comments": []}, {"number": 50848, "title": "[CherryPick2.6]Validate num_elements input in tf.raw_ops.TensorListReserve", "body": "PiperOrigin-RevId: 383954564\nChange-Id: I454bd78eff85bc4f16ddb7e608596971cca47f8f", "comments": []}, {"number": 50847, "title": "[CherryPick2.6]Fix null ptr deref in tf.raw_ops.RaggedTensorToTensor", "body": "PiperOrigin-RevId: 384257511\nChange-Id: I0484ad285039d132d6c41b284a7fcdd2b774a38e", "comments": []}, {"number": 50846, "title": "[CherryPick2.6]Disallow division by zero FPE in tf.raw_ops.SparseDenseCwiseDiv", "body": "PiperOrigin-RevId: 383959809\nChange-Id: Ibe88458bdf66a686c93e354b8255dec94285c560", "comments": []}, {"number": 50845, "title": "InvalidArgumentError:  indices[0,2] = 2188 is not in [0, 2027)", "body": "Hi when I run the evaluation I get this error message, which I can't identify what is the issue.\r\n\r\n***** train\r\nWARNING:tensorflow:Model was constructed with shape (None, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 10).\r\nsrc=[d\u00e9placezvous sil vous pla\u00eet], target=[please move], predicted=[im relax]\r\nsrc=[attrapezle], target=[grab him], predicted=[im me]\r\nsrc=[tu peux y arriver], target=[you can do it], predicted=[in objected]\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-15-840ecd362078> in <module>()\r\n     83 # test on some training sequences\r\n     84 print('***** train')\r\n---> 85 evaluate_model(model, eng_tokenizer, trainX, train)\r\n     86 \r\n     87 # test on some test sequences\r\n\r\n8 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nInvalidArgumentError:  indices[0,2] = 2188 is not in [0, 2027)\r\n\t [[node sequential/embedding/embedding_lookup (defined at <ipython-input-15-840ecd362078>:32) ]] [Op:__inference_predict_function_24327]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node sequential/embedding/embedding_lookup:\r\n sequential/embedding/embedding_lookup/23436 (defined at /usr/lib/python3.7/contextlib.py:112)\r\n\r\nFunction call stack:\r\npredict_function\r\nSEARCH STACK OVERFLOW", "comments": ["@tianopino Could you please fill the issue template.Also Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "@tianopino \r\nYou may refer to [this link ](https://stackoverflow.com/questions/51223936/tensorflow-invalidargumenterror-indices-while-training-with-keras)and let us know", "Moving this to closed status due to lack of activity."]}, {"number": 50844, "title": "fix cropping layer return empty list if crop is higher than data shap\u2026", "body": "initialy the PR was in #50612 but the Tensorflow/Keras policy changed. Now is #14958\r\n\r\nI do a first try to solve this issue. I think we can do a prototype with `Cropping1D` and after when everything is perfect, copy the same pattern to `Cropping2D`, `Cropping3D`, etc.\r\n\r\nPls, give me your thoughts. @ymodak", "comments": ["This PR must be close because is from Keras Team, not from Tensorflow.  \r\n\r\nHere is the issue in Keras: https://github.com/keras-team/keras/issues/14958"]}, {"number": 50842, "title": "tensorflow does not recognize gpu", "body": "**System information**\r\n- OS Platform and Distribution : Linux Ubuntu 20.04.2 LTS\r\n- TensorFlow version: tensorflow-gpu 2.5.0\r\n- Python version: Python 3.8\r\n- Installed using virtualenv? pip? conda?:  pycharm venv\r\n- GPU model and memory: Nvidia TU102[TITANRTX]\r\n- CUDA/cuDNN version: CUDA 10.1 / 11.1\r\n![](https://i.imgur.com/KQOzYES.png)\r\n![](https://i.imgur.com/DamemJ7.png)\r\n\r\n**Describe the problem**\r\nI ran my deep reinforcement learning code(tensorflow model) on CPU and the code worked.The output is below:\r\n```\r\n2021-07-18 15:40:19.039476: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-18 15:40:20.551477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-07-18 15:40:20.584382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2021-07-18 15:40:20.584422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-18 15:40:20.587696: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2021-07-18 15:40:20.587764: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2021-07-18 15:40:20.588983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2021-07-18 15:40:20.589327: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2021-07-18 15:40:20.589548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\r\n2021-07-18 15:40:20.590170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2021-07-18 15:40:20.590293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2021-07-18 15:40:20.590310: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2021-07-18 15:40:20.590571: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-07-18 15:40:20.591825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-07-18 15:40:20.591846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \r\n/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\r\n  warnings.warn(\r\n \r\n```\r\nBut it required so much memory(nearly 100%).According to my cudnn and cuda version. I installed ```tensorflow-gpu 2.5.0```. \r\nI checked and ensured I had the lastest tensorflow gpu release installed.The command and output is below:\r\n- command\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n```\r\n- output\r\n```\r\n2021-07-18 15:46:34.898115: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-18 15:46:35.945751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-07-18 15:46:35.975290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: TITAN RTX computeCapability: 7.5\r\ncoreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\r\n2021-07-18 15:46:35.975330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-07-18 15:46:35.978463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2021-07-18 15:46:35.978520: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2021-07-18 15:46:35.979857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2021-07-18 15:46:35.980175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2021-07-18 15:46:35.980391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\r\n2021-07-18 15:46:35.981033: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2021-07-18 15:46:35.981142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2021-07-18 15:46:35.981158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\nNum GPUs Available:  0\r\n\r\n```\r\nI tried to install other tensorflow gpu version (2.4.0,2.3.0.....).The error is below:\r\n```\r\n(venv) wayne:~/PycharmProjects/stock_point_$ python train.py ^GSPC 10 1000\r\n2021-07-18 15:50:49.752192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 1, in <module>\r\n    from agent.agent import Agent\r\n  File \"/home/wayne/PycharmProjects/stock_point_/agent/agent.py\", line 1, in <module>\r\n    import keras\r\n  File \"/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/__init__.py\", line 25, in <module>\r\n    from keras import models\r\n  File \"/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/models.py\", line 19, in <module>\r\n    from keras import backend\r\n  File \"/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/backend.py\", line 37, in <module>\r\n    from tensorflow.python.eager.context import get_config\r\nImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/tensorflow/python/eager/context.py)\r\n\r\n```\r\n\r\nCould you help me solve this problem.Thanks in advance.\r\n", "comments": ["@WayneHsiao0225 ,\r\n\r\nCan you please try installing TensorFlow v2.5 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Also please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu).\r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow-2.5.0 | 3.6-3.9 | GCC 7.3.1 | Bazel 3.7.2 | 8.1 | 11.2\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 7.6 | 10.1\r\n\r\n\r\n\r\nThanks!", "@WayneHsiao0225 \r\ninstead of importing keras as \r\n`import keras`\r\nplease try and import it like \r\n`from tensorflow import keras`\r\nalso in your code if you have imported any package from keras try and import it from tensorflow.keras instead", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50842\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50842\">No</a>\n"]}, {"number": 50841, "title": "tensorflow-serving-apt signature key expired", "body": "### System information\r\n- OS Platform and Distribution: Ubuntu 1804, Windows - Dockerfile, Google Cloud Build (Dockerfile)\r\n- TensorFlow installed from (source or binary): apt\r\n\r\n### Problem\r\ntensorflow serving apt key is expired\r\n[https://www.tensorflow.org/tfx/serving/setup#installation_2](https://www.tensorflow.org/tfx/serving/setup#installation_2)\r\n\r\n**Command to run**\r\n```bash\r\necho \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\r\ncurl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\r\n```\r\n\r\n**Error**\r\nGPG error: http://storage.googleapis.com/tensorflow-serving-apt stable InRelease: The following signatures were invalid: KEYEXPIRED...\r\n", "comments": ["This is a duplicate of https://github.com/tensorflow/serving/issues/1896 and should be resolved now. Please let us know if it still doesn't work.", "Hi, sorry I might have missed that issue while searching, causing a duplicate. Thank you it works fine now. Closing this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50841\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50841\">No</a>\n"]}, {"number": 50840, "title": "tensorflow.python.data.ops.dataset_ops.BatchDataset to HDF5", "body": "Hello,\r\nI need to load large image datasets (JPEG and other types) with tensorflow and then transform them to HDF5, I have loaded the dataset with the following code, but I don't know how to transform it to HDF5.**\r\n\r\n\r\nimg = tf.keras.preprocessing.image_dataset_from_directory(\r\n    '/home/tiny-imagenet-200/train/',\r\n    labels=\"inferred\",\r\n    label_mode=\"int\",\r\n    class_names=None,\r\n    color_mode=\"rgb\",\r\n    batch_size=32,\r\n    image_size=(256, 256),\r\n    shuffle=True,\r\n    seed=None,\r\n    validation_split=None,\r\n    subset=None,\r\n    interpolation=\"bilinear\",\r\n    follow_links=False,\r\n)\r\n\r\nI tried to do it like it did in python, but it doesn't work:\r\n\r\nfor i in range(len(img)):\r\n    Imagen = cv2.imread(img)\r\n    Imagen = cv2.resize(Imagen, (224, 224), interpolation=cv2.INTER_CUBIC)\r\n    Imagen = cv2.cvtColor(Imagen, cv2.COLOR_BGR2RGB)\r\n*****************\r\nThe error:\r\n\r\n\r\ntypeError                                 Traceback (most recent call last)\r\n<ipython-input-18-94fcf3e072ce> in <module>\r\n \r\n---> 10     Imagen = cv2.imread(img)\r\n     11     Imagen = cv2.resize(Imagen, (224, 224), interpolation=cv2.INTER_CUBIC)\r\n     12     Imagen = cv2.cvtColor(Imagen, cv2.COLOR_BGR2RGB)\r\n\r\nTypeError: Can't convert object of type 'tensorflow.python.framework.ops.EagerTensor' to 'str' for 'filename'\r\n\r\nI guess it is because of the type of object it generates that it is: tensorflow.python.data.ops.dataset_ops.BatchDataset\r\n\r\nPlease I would appreciate if someone can help me to know how to transform this to HDF5. Thank you.\r\n\r\n", "comments": ["Will [`this`](https://stackoverflow.com/questions/55606909/how-to-use-tensorflow-dataset-with-opencv-preprocessing) work?", "@bethven \r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Afeature&template=30-feature-request.md) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced].\r\n\r\nalso please refer this [comment](https://stackoverflow.com/questions/62211655/python-data-ops-dataset-ops-batchdataset-how-to-use-it-to-create-training-and).    Thanks\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50839, "title": "Add default value in `Attention` layer docs", "body": "In https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention, default values of `causal` and `dropout` are not specified and a user have to look up in the source code.\r\n\r\nI added default values to this document in this pull request.", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thankyou.\r\n@fchollet, @qlzh727", "Thank you for your guidance."]}, {"number": 50838, "title": "TFLite convertion bug: NumDimensions(input) != 4 (3 != 4)Node number 0 (RESIZE_BILINEAR) failed to prepare.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.2\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\nI am trying to quantize the `tf.image.resize()` function to TFLite but the following error is raised:\r\n```\r\nRuntimeError: tensorflow/lite/kernels/resize_bilinear.cc:73 NumDimensions(input) != 4 (3 != 4)Node number 0 (RESIZE_BILINEAR) failed to prepare.\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nThe code below leads to the error:\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.version.VERSION)\r\ninputs = tf.keras.Input(shape=(720, 1280, 3), batch_size=1)\r\noutputs = tf.image.resize(inputs, (360, 640))\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\nmodel.summary()\r\n\r\n\r\ndef representative_dataset_generator():\r\n    for _ in range(20):\r\n        image = tf.random.uniform(shape=(1, 720, 1280, 3), dtype=tf.float32)\r\n        yield image\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.representative_dataset = representative_dataset_generator\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.target_spec.supported_types = [tf.int8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_model = converter.convert()\r\n```\r\nWith TF 2.5.0, the error changes and becomes: \r\n```\r\nValueError: The inference_input_type and inference_output_type must be tf.float32.\r\n```\r\nas shown in [this google colab](https://colab.research.google.com/drive/14rgat_c4d4TWaF7Vmp7MnPczYbmDhv6R?usp=sharing). This is also a problem because I want to do full-integer quantization.\r\n\r\nSince this operation has its [TFLite equivalent](https://tensorflow.google.cn/mlir/tfl_ops#tflresize_bilinear_tflresizebilinearop), I expect to be able to quantize it without a problem. \r\nLooking forward to hearing from you.\r\n", "comments": ["the dataset generator should return `[image]` it is a mistake from my side.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50838\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50838\">No</a>\n"]}, {"number": 50837, "title": "'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Geforce 3090\r\n\r\n**Describe the current behavior**\r\n when loading pipeline.config, it cause error. \r\nconfig = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\r\neven I installed tensorflow nightly version. but it is same. \r\n\r\nerror is\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte\r\n\r\n\r\nfull log error is\r\nUnicodeDecodeError                        Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp/ipykernel_16452/1215164193.py in <module>\r\n      1 print(\"s\")\r\n----> 2 config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\r\n\r\nc:\\users\\pedro\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\object_detection\\utils\\config_util.py in get_configs_from_pipeline_file(pipeline_config_path, config_override)\r\n    138 \r\n    139     print(\"protto\")\r\n--> 140     proto_str = f.read()\r\n    141     print(proto_str)\r\n    142     print(\"proto\")\r\n\r\nc:\\users\\pedro\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in read(self, n)\r\n    117       string if in string (regular) mode.\r\n    118     \"\"\"\r\n--> 119     self._preread_check()\r\n    120     if n == -1:\r\n    121       length = self.size() - self.tell()\r\n\r\nc:\\users\\pedro\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in _preread_check(self)\r\n     80       print(self.__name)\r\n     81       self._read_buf = _pywrap_file_io.BufferedInputStream(\r\n---> 82           compat.path_to_str(self.__name), 1024 * 512)\r\n     83 \r\n     84   def _prewrite_check(self):\r\n\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte\r\n\r\n", "comments": ["@kotran88 \r\nCould you please refer to [this link](https://stackoverflow.com/questions/22216076/unicodedecodeerror-utf8-codec-cant-decode-byte-0xa5-in-position-0-invalid-s) and let us know. [[link1](https://www.edureka.co/community/51644/python-unicodedecodeerror-codec-decode-position-invalid)],[[link2](https://github.com/llSourcell/tensorflow_chatbot/issues/17#issuecomment-866719858)]", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Moving this to closed status due to lack of activity.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50837\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50837\">No</a>\n"]}, {"number": 50836, "title": "Move code shared between lite and micro to elementwise_portable.h", "body": "This PR refactors the elementwise kernel and moves code shared between Lite and Micro to elementwise_portable.h, as suggested by @advaitjain [here](https://github.com/tensorflow/tflite-micro/pull/204#pullrequestreview-692482804)", "comments": ["Hi Patrick,\r\n\r\nI think micro related issues should be raised in https://github.com/tensorflow/tflite-micro\r\n\r\nThanks,\r\nTiezhen", "> Hi Patrick,\r\n> \r\n> I think micro related issues should be raised in https://github.com/tensorflow/tflite-micro\r\n> \r\n> Thanks,\r\n> Tiezhen\r\n\r\nThis is a pull request that refactors the code in tflite to allow for more sharing when it is exported to tflite-micro. As such, the tensorflow repository is the correct location for this change.", "@advaitjain  Can you please review this PR ? Thanks!", "@advaitjain ready for review. I must have mistakenly pushed a commit last week. I apologize for any inconvenience caused.  953111e is the commit relevant for review.", "@advaitjain I needed to move `IsSqrtSupportedType` to back into elementwise.cc to get the micro kernel to compile. Since micro only has float32 support for RSQRT it uses `IsNumericSupportedType` and the compilation fails due to `IsRsqrtSupportedType` being defined but unused.", "@advaitjain Can you please assist on above comments from @patriklaurell. Thanks!", "Ready for review @advaitjain ", "@advaitjain @liufengdb ready for review", "Apologies, I sent you down the wrong path with https://github.com/tensorflow/tflite-micro/pull/204#pullrequestreview-692482804. \r\n\r\nWhile the code looks like it can be shared, there are small differences which make it incompatible with TFLM.\r\n\r\nThis discrepancy is made more explicit by the recently added AllocateTempInputTensor API:\r\nhttps://github.com/tensorflow/tflite-micro/blob/8a710d8ff01fd5d8797caaf349608b89ac2119ec/tensorflow/lite/micro/micro_context.h#L62-L67\r\n\r\nI'm going to close this PR."]}, {"number": 50835, "title": "There should be No expansion ReLU on MobileNet v2 bottleneck", "body": "I argue that this line should be removed:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/a4d25192f0340b7786760d57e6b5859e561d9b49/tensorflow/python/keras/applications/mobilenet_v2.py#L450\r\n\r\nThe code seems wrong vs. the [MobileNet v2 paper](https://arxiv.org/pdf/1801.04381.pdf), **which this code is supposed to faithfully implement**, for the following reasons:\r\n\r\nThe paper uses all of Figure 1 (read the caption), part D of Figure 2 (also read the caption), and part B of Figure 3 (also read the caption and check the parts that are annotated ReLU vs. those that aren't), as well as well as the last two paragraphs of Section 3.2 \"Linear Bottlenecks\" to argue _against_ having ReLU on the bottlenecks. One can specifically see that the _expansion_ layer in part D of Figure 2 is shown without ReLU, and the same setup is shown with part B of Figure 3, all of which matches perfectly with the description given in the last two paragraphs of the section.\r\n\r\nCurrently, it is like the entire point of a central section of the paper was missed or ignored.", "comments": ["@ChrisChiasson \r\n\r\n\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on [Tensorflow/Models](https://github.com/tensorflow/models/issues?q=is%3Aopen+is%3Aissue) repo from here. Thanks!\r\n", "@UsharaniPagadala can you direct me to the location of this file within that repository?", "@UsharaniPagadala Just to clarify, I don't think this file exists in that repository. I did look.", "Looking at the original paper, the Table 1 (Bottleneck residual block) shows that the (1x1 conv2d , ReLU6) is the operation used for the block, which I think is matching with the current implementation in Keras. I have also check the pytorch implementation in https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/mobilenet.py#L45, which also use Relu6 as activation. \r\n\r\nAlso adding @marksandler2 and @andrewghoward who are the original author of the paper to confirm the correctness here.", "With respect to above comment and update on pr, moving this to close status."]}, {"number": 50834, "title": "Implementation of a Buffer Packing Pass.", "body": "The first iteration of a `Buffer Packing` pass that reduces the memory consumption for `Buffer Reuse` by packing small buffers into bigger buffers, considering a time component represented by the userange of the buffers.\r\nThe implemenation is a greedy bin packing approach based on the `Userange Analysis` to compute a new memory distribution over the userange of packed buffers. Note that all buffers are aligned to 64 bytes, for GPU kernels.\r\n\r\nAs a work in progress PR, we want get early feedback.\r\n\r\nNote: We try to replace the buffer allocations with an offset and the associated `memref` view operation. But there are some legalization issues we still need to solve.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50834) for more info**.\n\n<!-- need_author_cla -->", "This fails with \r\n\r\n```\r\ntensorflow/compiler/mlir/hlo/lib/Transforms/buffer_packing.cc:16:10: fatal error: mlir-hlo/Analysis/userange_analysis.h: No such file or directory\r\n #include \"mlir-hlo/Analysis/userange_analysis.h\"\r\n ```\r\n\r\nso there likely is some dependency missing in the BUILD file.", "@dfki-thsc Can you please resolve conflicts? Thanks!", "```\r\n[19,100 / 19,587] Compiling tensorflow/compiler/mlir/tensorflow/utils/compile_mlir_util.cc; 46s remote ... (199 actions, 187 running)\r\ntensorflow/compiler/mlir/hlo/lib/Transforms/buffer_packing.cc:21:10: fatal error: mlir/Conversion/LLVMCommon/ConversionTarget.h: No such file or directory\r\n #include \"mlir/Conversion/LLVMCommon/ConversionTarget.h\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/compiler/mlir/hlo/BUILD:1885:11: Compiling tensorflow/compiler/mlir/hlo/lib/Transforms/buffer_packing.cc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /tmpfs/bazel_output/_bazel_kbuilder/f2d52ca1f092ccbe254cc98c3dc90790/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    TF2_BEHAVIOR=1 \\\r\n```\r\n\r\nThe BUILD file is still missing a dependency. Can you please fix?", "Still fails on windows with\r\n\r\n```\r\ntensorflow/compiler/mlir/hlo/lib/Transforms/buffer_packing.cc(369): error C2398: Element '1': conversion from 'size_t' to 'T' requires a narrowing conversion\r\n        with\r\n        [\r\n            T=int64_t\r\n        ]\r\ntensorflow/compiler/mlir/hlo/lib/Transforms/buffer_packing.cc(439): note: see reference to function template instantiation 'mlir::`anonymous-namespace'::BufferPacking::BufferPacking<mlir::`anonymous-namespace'::SortedPackingStrategy<mlir::`anonymous-namespace'::AllocInfoMemSizeCompare>>(mlir::Operation *,StrategyT)' being compiled\r\n        with\r\n        [\r\n            StrategyT=mlir::`anonymous-namespace'::SortedPackingStrategy<mlir::`anonymous-namespace'::AllocInfoMemSizeCompare>\r\n        ]\r\n```", "Next one up is a BUILD file issue. The entries likely are not sorted.\r\n\r\n```\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\ntensorflow/compiler/mlir/hlo/BUILD:\r\n1771a1772\r\n>         \":buffer_packing\",\r\n1797d1797\r\n<         \":buffer_packing\",\r\n1884a1885\r\n>\r\n1896d1896\r\n<         \"@llvm-project//mlir:IR\",\r\n1897a1898\r\n>         \"@llvm-project//mlir:IR\",\r\n1899d1899\r\n<         \"@llvm-project//mlir:StandardOps\",\r\n1900a1901\r\n>         \"@llvm-project//mlir:StandardOps\",\r\nexit status 1\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```"]}, {"number": 50833, "title": "tensorflow estimator how to export sub-graph", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04\r\n- TensorFlow version (use command below): 1.14.1\r\n- Python version: 3.7\r\n\r\n```\r\n        self.features = self._build_input_placeholder_for_serving(features)\r\n        imei_embedding, user_inputs, item_inputs_a, item_inputs_b = self._build_input(self.features)\r\n        self.labels = self.get_labels(labels)\r\n        meta_embedding, meta_embedding_variables = self.build_meta_embedding_generator(imei_embedding, user_inputs)\r\n        self.logits_a = self.build_graph([meta_embedding, user_inputs, item_inputs_a])\r\n        self.cold_loss_a = self.cross_entropy_loss(self.labels['label_a'], self.logits_a)\r\n        self.predictions = self.get_prediction(self.logits_a)\r\n        cold_embedding_grads = tf.gradients(self.cold_loss_a, meta_embedding)[0]\r\n        new_meta_embedding = meta_embedding - self.learning_rate_cold * cold_embedding_grads\r\n        self.logits_b = self.build_graph([new_meta_embedding, user_inputs, item_inputs_b])\r\n        self.cold_loss_b = self.cross_entropy_loss(self.labels['label_b'], self.logits_b)\r\n        self.loss = self.cold_loss_a * self.alpha + self.cold_loss_b * (1 - self.alpha)\r\n```\r\nwhen i want to export the model, the error occurs:\r\n```\r\n  File \"/usr/local/lib/python3.6/dist-packages/apts/run_loop/run.py\", line 56, in run\r\n    self.run_loop.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py\", line 594, in run\r\n    self.run_loop()\r\n  File \"/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py\", line 245, in run_loop\r\n    self._export_and_upload_saved_model()\r\n  File \"/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py\", line 502, in _export_and_upload_saved_model\r\n    export_path=os.path.join(self.model_dir, 'saved_model'))\r\n  File \"/root/workspace/meta_embedding/utils/run_loop.py\", line 140, in export_and_upload_saved_model\r\n    checkpoint_path=checkpoint_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 732, in export_saved_model\r\n    strip_default_attrs=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 856, in _export_all_saved_models\r\n    strip_default_attrs=strip_default_attrs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 929, in _add_meta_graph_for_mode\r\n    config=self.config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/root/workspace/meta_embedding/model/meta_embedding_meta_generator.py\", line 51, in model_fn\r\n    self.labels = self.get_labels(labels)\r\n  File \"/root/workspace/meta_embedding/model/meta_embedding_meta_generator.py\", line 340, in get_labels\r\n    _labels['label_a'] = labels[list(self.feature_config['label_name'])[0]]\r\nTypeError: 'NoneType' object is not subscriptable\r\n\r\n```\r\nI guess it's because I compute the gradient with **loss_a** and then update **meta_embedding**. I only want to export the graph of **loss_a**. Are there any feasible solutions?", "comments": ["@Lihengwannafly ,\r\n\r\nWe see that you are using tf version 1.14, 1.x is not actively supported, please update to 2.x and let us know if you are using same issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50833\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50833\">No</a>\n"]}, {"number": 50832, "title": "tf.function runs correctly in eager mode, but breaks in graph mode", "body": "\r\n### System information\r\n\r\n= check python ===================================================\r\npython version: 3.8.10\r\npython branch: \r\npython build version: ('default', 'Jun  2 2021 10:49:15')\r\npython compiler version: GCC 9.4.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                         1.19.5\r\nprotobuf                      3.17.3\r\ntensorflow                    2.5.0+nv\r\ntensorflow-addons             0.13.1\r\ntensorflow-datasets           3.2.1\r\ntensorflow-dot-based-interact 0.0.1\r\ntensorflow-estimator          2.5.0\r\ntensorflow-metadata           1.1.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.5.0\r\ntf.version.GIT_VERSION = unknown\r\ntf.version.COMPILER_VERSION = 9.3.0\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/compat/lib.real:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-11.4/targets/x86_64-linux/lib/libcudart.so.11.4.43\r\n/usr/local/cuda-11.4/targets/x86_64-linux/lib/libcudart_static.a\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.5.0+nv\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.8/dist-packages\r\nRequired-by: tensorflow-dot-based-interact, nvtx-plugins\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 8, 10, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\nBuild label: 3.7.2\r\nBuild time: Thu Dec 17 16:57:23 2020 (1608224243)\r\nBuild timestamp: 1608224243\r\nBuild timestamp as int: 1608224243\r\n\r\n\r\n### Describe the problem\r\n\r\nWhen doing perf analysis of Tensorflow2 models, we want to breakdown the training flow into separate phases: forward, loss, backward, weight_update etc. The main idea to do the time breakdown is to run the flow in overall eager mode, but each phase is wrapped in tf.function API, so to run the phase in graph mode. We have an issue that a tf.function can run correctly under eager mode, but breaks in graph mode. \r\n\r\nI created a minimum tests to reproduce the issue pasted below.\r\n\r\nin the direct test, we want to run optimizer.minimize in graph mode by wrapping with tf.function, when running the tf.function in eager mode throught setting tf.config.experimental_run_functions_eagerly(True), it works. \r\n\r\nBut fails with if running the graph mode with below error: \r\n\r\nTraceback (most recent call last):\r\n  File \"direct_test.py\", line 119, in <module>\r\n    dummy_model.fit(dummy_data_generator,steps_per_epoch = 100)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"direct_test.py\", line 59, in train_function\r\n    return step_function(self, iterator)\r\n  File \"direct_test.py\", line 49, in step_function\r\n    outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1285, in run\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2833, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3608, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 597, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"direct_test.py\", line 41, in run_step\r\n    outputs = model.train_step(data)\r\n  File \"direct_test.py\", line 88, in train_step\r\n    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize  *\r\n        return self.apply_gradients(grads_and_vars, name=name)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients  **\r\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py:75 filter_empty_gradients\r\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n\r\n    ValueError: No gradients provided for any variable: ['training_model/dense/kernel:0', 'training_model/dense/bias:0'].\r\n\r\n2021-07-15 03:29:43.999375: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n         [[{{node PyFunc}}]]\r\n\r\n### Source code / logs\r\n\r\n[direct_test.txt](https://github.com/tensorflow/tensorflow/files/6838642/direct_test.txt)\r\n\r\n", "comments": ["Can you check the code again please.\r\nThe code provided throws an error in line 49 `outputs = model.distribute_strategy.run(run_step, args=(data,))`\r\n\r\nValueError: No gradients provided for any variable: ['training_model/dense/kernel:0', 'training_model/dense/bias:0'].", "@old-school-kid This issue is as expected, and it is why we filing the issue in this thread. \r\n\r\nif un-comment the code in line 20 to run the tf.function with eager mode:  \r\ntf.config.experimental_run_functions_eagerly(True)\r\n\r\nthe test will pass without reporting the issue. ", "@shawnwang18 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50832\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50832\">No</a>\n"]}, {"number": 50831, "title": "Updated docstring for mha layer call", "body": "switched bool values for return_attention_scores", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead.  Thanks!"]}, {"number": 50830, "title": "Update stale.yml", "body": "Simplified the Message to the User", "comments": []}, {"number": 50829, "title": "Error while building tensorflow from source.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), wuie only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Mac Os Big sur\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):Source\r\n- TensorFlow version: r2.4 \r\n- Python version:3.9\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):3.1.0\r\n- GCC/Compiler version (if compiling from source):4.2.1\r\n- CUDA/cuDNN version:NA\r\n- GPU model and memory:NA\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\ni am following the steps from this link : https://www.tensorflow.org/install/source#macos_1, i am getting an error in the last step, where we install tensorflow wheel file generated through pip.\r\n\r\n**Any other info / logs**\r\n\r\nBuilding wheels for collected packages: grpcio, wrapt, termcolor, h5py\r\n  Building wheel for grpcio (setup.py) ... /^[[error\r\n  ERROR: Command errored out with exit status 1:\r\n   command: /usr/local/opt/python@3.9/bin/python3.9 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-wheel-x721u2p1\r\n       cwd: /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/\r\n  Complete output (1640 lines):\r\n  Found cython-generated files...\r\n  running bdist_wheel\r\n  running build\r\n  running build_py\r\n  running build_project_metadata\r\n  creating python_build\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_compression.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_common.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_simple_stubs.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_plugin_wrapping.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_interceptor.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_grpcio_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_runtime_protos.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  copying src/python/grpcio/grpc/_auth.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/_server_adaptations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/interfaces.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/implementations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  copying src/python/grpcio/grpc/beta/_client_adaptations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental\r\n  copying src/python/grpcio/grpc/experimental/gevent.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental\r\n  copying src/python/grpcio/grpc/experimental/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental\r\n  copying src/python/grpcio/grpc/experimental/session_cache.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework\r\n  copying src/python/grpcio/grpc/framework/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_base_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_typing.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_call.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_base_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_interceptor.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_base_call.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  copying src/python/grpcio/grpc/aio/_utils.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython\r\n  copying src/python/grpcio/grpc/_cython/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental/aio\r\n  copying src/python/grpcio/grpc/experimental/aio/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental/aio\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/callable_util.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/abandonment.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/stream.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/stream_util.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/future.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  copying src/python/grpcio/grpc/framework/foundation/logging_pool.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common\r\n  copying src/python/grpcio/grpc/framework/common/style.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common\r\n  copying src/python/grpcio/grpc/framework/common/cardinality.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common\r\n  copying src/python/grpcio/grpc/framework/common/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces\r\n  copying src/python/grpcio/grpc/framework/interfaces/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face\r\n  copying src/python/grpcio/grpc/framework/interfaces/face/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face\r\n  copying src/python/grpcio/grpc/framework/interfaces/face/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face\r\n  copying src/python/grpcio/grpc/framework/interfaces/face/face.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base\r\n  copying src/python/grpcio/grpc/framework/interfaces/base/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base\r\n  copying src/python/grpcio/grpc/framework/interfaces/base/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base\r\n  copying src/python/grpcio/grpc/framework/interfaces/base/base.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_cygrpc\r\n  copying src/python/grpcio/grpc/_cython/_cygrpc/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_cygrpc\r\n  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_credentials\r\n  copying src/python/grpcio/grpc/_cython/_credentials/roots.pem -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_credentials\r\n  running build_ext\r\n  Found cython-generated files...\r\n  building 'grpc._cython.cygrpc' extension\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/census\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/health\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/grpclb\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/pick_first\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/priority\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/round_robin\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/weighted_target\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/xds\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns/c_ares\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns/native\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/fake\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/sockaddr\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/xds\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_idle\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/deadline\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/client\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/message_compress\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/server\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/max_age\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/message_size\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/workarounds\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/alpn\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client/insecure\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client/secure\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server/insecure\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server/secure\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/transport\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/inproc\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/annotations\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/accesslog\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/accesslog/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/cluster\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/cluster/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/core\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/core/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/endpoint\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/endpoint/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/listener\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/listener/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/rbac\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/rbac/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/route\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/route/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/trace\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/trace/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network/http_connection_manager\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network/http_connection_manager/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets/tls\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets/tls/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/cluster\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/cluster/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/discovery\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/discovery/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/endpoint\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/endpoint/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/listener\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/listener/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/load_stats\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/load_stats/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/route\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/route/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/matcher\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/matcher/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/metadata\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/metadata/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/tracing\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/tracing/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/gogoproto\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api/expr\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api/expr/v1alpha1\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/protobuf\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/rpc\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/gcp\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/health\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/health/v1\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/lb\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/lb/v1\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/annotations\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data/orca\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data/orca/v1\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/validate\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/xds\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/avl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/backoff\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/channel\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/compression\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/debug\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/gpr\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/gprpp\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/http\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr/executor\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr/poller\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/json\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/profiling\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/authorization\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/context\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/alts\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/composite\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/fake\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/google_default\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/iam\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/jwt\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/local\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/oauth2\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/plugin\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/ssl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/tls\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/alts\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/fake\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/local\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/ssl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/tls\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/transport\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/util\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/slice\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/surface\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/transport\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/uri\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/plugin_registry\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/crypt\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/frame_protector\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/handshaker\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/zero_copy_frame_protector\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/ssl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/ssl/session_cache\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio/grpc\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio/grpc/_cython\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/base\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/base/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/container\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/container/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/debugging\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/debugging/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/hash\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/hash/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/numeric\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/status\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings/internal/str_format\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/synchronization\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/synchronization/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal/cctz\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal/cctz/src\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/types\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/address_sorting\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/chacha\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/cipher_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/fipsmodule\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/test\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/asn1\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/base64\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bio\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bn_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/buf\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bytestring\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/chacha\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/cipher_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/cmac\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/conf\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/curve25519\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/dh\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/digest_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/dsa\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ec_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ecdh_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ecdsa_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/engine\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/err\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/evp\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/fipsmodule\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hkdf\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hpke\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hrss\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/lhash\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/obj\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pem\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pkcs7\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pkcs8\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/poly1305\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pool\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rand_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rc4\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rsa_extra\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/siphash\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/stack\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/trust_token\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/x509\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/x509v3\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/ssl\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/cares\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/cares/cares\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2/re2\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2/util\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/upb\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/upb/upb\r\n  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/zlib\r\n  clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/Tk.framework/Versions/8.5/Headers -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern \"C\" __attribute__((visibility (\"default\"))) PyObject* -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_darwin -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/local/include -I/usr/local/opt/openssl@1.1/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c src/core/ext/filters/census/grpc_context.cc -o python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/census/grpc_context.o -std=c++11 -stdlib=libc++ -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread\r\n \r\n    Traceback (most recent call last):\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py\", line 117, in _compile\r\n        self.spawn(compiler_so + cc_args + [src, '-o', obj] +\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_spawn_patch.py\", line 54, in _commandfile_spawn\r\n        _classic_spawn(self, command)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/ccompiler.py\", line 910, in spawn\r\n        spawn(cmd, dry_run=self.dry_run)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/spawn.py\", line 87, in spawn\r\n        raise DistutilsExecError(\r\n    distutils.errors.DistutilsExecError: command '/usr/bin/clang' failed with exit code 1\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py\", line 264, in build_extensions\r\n        build_ext.build_ext.build_extensions(self)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 449, in build_extensions\r\n        self._build_extensions_serial()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\r\n        self.build_extension(ext)\r\n      File \"/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 196, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 529, in build_extension\r\n        objects = self.compiler.compile(sources,\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py\", line 58, in _parallel_compile\r\n        multiprocessing.pool.ThreadPool(BUILD_EXT_COMPILER_JOBS).map(\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 364, in map\r\n        return self._map_async(func, iterable, mapstar, chunksize).get()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 771, in get\r\n        raise self._value\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\r\n        result = (True, func(*args, **kwds))\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\r\n        return list(map(*args))\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py\", line 54, in _compile_single_file\r\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py\", line 247, in new_compile\r\n        return old_compile(obj, src, ext, cc_args, extra_postargs,\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py\", line 120, in _compile\r\n        raise CompileError(msg)\r\n    distutils.errors.CompileError: command '/usr/bin/clang' failed with exit code 1\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py\", line 448, in <module>\r\n        setuptools.setup(\r\n      File \"/usr/local/lib/python3.9/site-packages/setuptools/__init__.py\", line 153, in setup\r\n        return distutils.core.setup(**attrs)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/core.py\", line 148, in setup\r\n        dist.run_commands()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py\", line 966, in run_commands\r\n        self.run_command(cmd)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.9/site-packages/setuptools/command/install.py\", line 61, in run\r\n        return orig.install.run(self)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/install.py\", line 546, in run\r\n        self.run_command('build')\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build.py\", line 135, in run\r\n        self.run_command(cmd_name)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/cmd.py\", line 313, in run_command\r\n        self.distribution.run_command(command)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py\", line 985, in run_command\r\n        cmd_obj.run()\r\n      File \"/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 79, in run\r\n        _build_ext.run(self)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 340, in run\r\n        self.build_extensions()\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py\", line 268, in build_extensions\r\n        raise CommandError(\r\n    commands.CommandError: Failed `build_ext` step:\r\n    Traceback (most recent call last):\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py\", line 117, in _compile\r\n        self.spawn(compiler_so + cc_args + [src, '-o', obj] +\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_spawn_patch.py\", line 54, in _commandfile_spawn\r\n        _classic_spawn(self, command)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/ccompiler.py\", line 910, in spawn\r\n        spawn(cmd, dry_run=self.dry_run)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/spawn.py\", line 87, in spawn\r\n        raise DistutilsExecError(\r\n    distutils.errors.DistutilsExecError: command '/usr/bin/clang' failed with exit code 1\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py\", line 264, in build_extensions\r\n        build_ext.build_ext.build_extensions(self)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 449, in build_extensions\r\n        self._build_extensions_serial()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\r\n        self.build_extension(ext)\r\n      File \"/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 196, in build_extension\r\n        _build_ext.build_extension(self, ext)\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py\", line 529, in build_extension\r\n        objects = self.compiler.compile(sources,\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py\", line 58, in _parallel_compile\r\n        multiprocessing.pool.ThreadPool(BUILD_EXT_COMPILER_JOBS).map(\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 364, in map\r\n        return self._map_async(func, iterable, mapstar, chunksize).get()\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 771, in get\r\n        raise self._value\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\r\n        result = (True, func(*args, **kwds))\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\r\n        return list(map(*args))\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py\", line 54, in _compile_single_file\r\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\r\n      File \"/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py\", line 247, in new_compile\r\n        return old_compile(obj, src, ext, cc_args, extra_postargs,\r\n      File \"/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py\", line 120, in _compile\r\n        raise CompileError(msg)\r\n    distutils.errors.CompileError: command '/usr/bin/clang' failed with exit code 1\r\n    \r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: /usr/local/opt/python@3.9/bin/python3.9 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-record-j6oeuxp5/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.9/grpcio Check the logs for full command output.\r\n\r\n\r\nPlease refer to the following file for the detailed logs \r\n[tf_build_from_source_logs.txt](https://github.com/tensorflow/tensorflow/files/6838193/tf_build_from_source_logs.txt)\r\n\r\n\r\n\r\n", "comments": ["I think that you can try to build it without clang .", "Hi vulkomilev,\r\nThanks for the reply.\r\n\r\nCan you please tell how i can build it without clang? I pressed N when it asked the following option in configuration.\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n", "Hmm that is strange let me check", "Sorry but I can't help you . I am on Ubuntu 20.04 and there is no way to investigate this one further ", "@Koushik667 \r\nIs this still an issue, Please refer to [this issue](https://stackoverflow.com/questions/62527882/dockerfile-build-distutils-errors-distutilsexecerror-command-gcc-failed-with) and let us know.", "I switched to a linux machine and it worked there, Thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50829\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50829\">No</a>\n"]}, {"number": 50828, "title": "binary_crossentropy() usage example is misleading", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.5/api_docs/python/tf/keras/losses/binary_crossentropy\r\n\r\nThe same problem occurs across many versions and aliases of this function.\r\n\r\n## Description of issue (what needs changing):\r\nThe \"standalone usage\" example appears to be misleading, because it implies that rows and/or columns of the `y_pred` parameter should sum to 1.0. \r\n\r\nAs I am new to TensorFlow, I am a little apprehensive about pointing out a potential problem in the documentation and I will be very grateful if an experienced practitioner can confirm whether my suggestion is correct or alternatively if I have misunderstood something. Thank you!\r\n\r\n### Usage example\r\n\r\nIn the usage example given here, the `y_pred` parameter is `[[0.6, 0.4], [0.4, 0.6]]`. Any reader with a background in probability and statistics will immediately assume that these numbers represent normalized probabilities, because the rows and the columns sum to 1.0. Furthermore, because the name of the method is *binary* cross entropy, a reader is likely to assume that the rows or columns of y_pred represent the two possible binary outcomes. In fact, none of these assumptions is correct. The parameter `y_pred` can be any shape (subject to a certain restriction mentioned below). Each entry in `y_pred` has a value that does not depend on the other values in the tensor. Example code demonstrating this is attached.\r\n\r\nMy feeling is that a better usage example would use numbers that do not sum to 1.0, so that readers will not make the mistaken assumption that they represent normalized probabilities. In addition, the usage example could be further improved by breaking the symmetry of the 2x2 example, and avoiding using two rows or two columns so that it is clear the \"binary\" nature of the cross entropy has nothing to do with the number of rows and columns here. The smallest example conveying all of these ideas would probably be 4x3, as in the attached code.\r\n\r\nTechnical note: There is a possibility of confusion when we say that the parameter does not represent normalized probabilities. This is certainly true when the parameter `from_logits` is `True`. However, when `from_logits` is `False`, each element in `y_pred` does in fact represent a probability, and as with any other true probability it is a normalized probability. However, it is not normalized with respect to any other elements of the tensor. For example, the value 0.8 represents a prediction that the an instance has an 80% chance of being a positive instance.  This means there is a 20% chance of that same instance being negative, but the value 0.2 does not appear anywhere in the `y_pred` tensor; the 0.2 is implicit in the 0.8.\r\n\r\nDetails about the shape for `y_pred`: it must have either the same shape as `y_true`, or a shape that is compatible with the shape of `y_true` after broadcasting has been applied to `y_true`.\r\n\r\n### Submit a pull request?\r\n\r\nI will be happy to prepare and submit a pull request if an experienced contributor can confirm to me that my description of the problem is correct.\r\n\r\nAgain, I will be grateful if someone can let me know if my suggestions are correct and I do apologize in advance if I misunderstood something.\r\n\r\n~~~~\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef my_sigmoid(x: np.ndarray):\r\n    return 1 / (1 + np.exp(-x))\r\n\r\n\r\ndef safe_log(x: np.ndarray):\r\n    eps = 1e-11\r\n    return np.log(np.maximum(x, eps))\r\n\r\n\r\ndef my_cross_entropy(y: np.ndarray, z: np.ndarray, from_logits=True):\r\n    if from_logits:\r\n        z = my_sigmoid(z)\r\n    return -(y * safe_log(z) + (1 - y) * safe_log((1 - z)))\r\n\r\n\r\ndef tf_cross_entropy(y: np.ndarray, z: np.ndarray, from_logits=True):\r\n    y = tf.constant(y, dtype=tf.float32)\r\n    z = tf.constant(z, dtype=tf.float32)\r\n    return tf.keras.losses.binary_crossentropy(y_true=y, y_pred=z,\r\n                                               from_logits=from_logits)\r\n\r\n\r\ndef compare_cross_entropy(y, z, from_logits=True):\r\n    my_val = my_cross_entropy(y, z, from_logits)\r\n    tf_val = tf_cross_entropy(y, z, from_logits)\r\n    print(f\"y {y}\\nz {z}\\n\")\r\n    print(f\"my_val {my_val}\\ntf_val {tf_val}\\n\")\r\n    print(f\"my_val shape {my_val.shape}\\ntf_val shape {tf_val.shape}\\n\")\r\n\r\n\r\n##########\r\n# main ###\r\n##########\r\ny_val = np.array([[1, 1, 1],\r\n                  [1, 1, 1],\r\n                  [0, 0, 0],\r\n                  [0, 1, 0], ], dtype=np.float32)\r\n\r\nz_val = np.array([[0.4, 0.45, 0.46],\r\n                  [0.9, 0.95, 0.96],\r\n                  [0.0, 0.0, 0.0],\r\n                  [0.7, 0.7, 0.7],\r\n                  ], dtype=np.float32)\r\n\r\nprint(f'y shape {y_val.shape}, z shape {z_val.shape}')\r\ncompare_cross_entropy(y_val, z_val, from_logits=False)\r\n~~~~\r\n", "comments": ["@johnmaccormick ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "Thanks, this has been reposted as requested:\r\n\r\nhttps://github.com/keras-team/keras/issues/14955", "@johnmaccormick ,\r\n\r\nPlease feel free to move this issue to closed status since it is already being tracked in Keras repo.Thanks!"]}, {"number": 50827, "title": "\"ModuleNotFoundError\", Some times the import of \"tensorflow_addons\" doesn't take place", "body": "Some time the import works, some time it doesn't.\r\n    `!pip install --user tensorflow-addons`\r\n    `import tensorflow_addons as tfa`\r\n\r\nOutput:\r\nCollecting tensorflow-addons\r\n  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 686kB 4.3MB/s \r\nRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\r\nInstalling collected packages: tensorflow-addons\r\nSuccessfully installed tensorflow-addons-0.13.0\r\n\r\n---------------------------------------------------------------------------\r\n\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n\r\n<ipython-input-29-4c254e4a3ee7> in <module>()\r\n      1 get_ipython().system('pip install --user tensorflow-addons')\r\n----> 2 import tensorflow_addons as tfa\r\n\r\nModuleNotFoundError: No module named 'tensorflow_addons'\r\n-------------------------------------------------------------------------------------------------------------------------------\r\nWhat to do?\r\n", "comments": ["@RanaBan  Please follow this [link](https://pypi.org/project/tensorflow-addons/) to  install tensorflow-addons package. \r\n\r\nI tried to import tensorflow addons on [colab](https://colab.research.google.com/gist/saikumarchalla/19580a43954bc479e5362d6cb8727f13/untitled113.ipynb) and it is working fine but not sure why it is not working some times.  Could you please try in virtual environment and let us know  if you are facing the issue still. Thanks!", "Due to scarcity of resources, I use colab. \r\n\r\nThe module imported this time and working fine. \r\n\r\nThanks for your response!!\r\n"]}, {"number": 50826, "title": "Cross-compilation error by Bazel in pip_package of TensorFlow Lite in r2.6 or v2.6.0-rc1 (armhf/aarch64)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 (HostPC), Ubuntu 16.04 (Docker)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.6, v2.6.0-rc1\r\n- Python version: 3.7 (Docker)\r\n- Bazel version (if compiling from source): 3.7.2 (Docker)\r\n\r\n**Describe the problem**\r\nAbort by building the pip_package of TensorFlow Lite with Bazel using the same procedure as for the r2.5 or v2.5.0 branch. The same problem occurs in both r2.6 and the latest release v2.6.0-rc1 as of today. If I check out r2.5 or v2.5.0, the same command will successfully build it.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI referred to the procedure using Bazel below.\r\nhttps://github.com/tensorflow/tensorflow/tree/v2.6.0-rc1/tensorflow/lite/tools/pip_package#cross-build-with-flex-for-armhf-python-37\r\n```bash\r\n$ git clone -b r2.6 https://github.com/tensorflow/tensorflow.git\r\n$ cd tensorflow\r\n```\r\n- aarch64\r\n```bash\r\n$ sudo CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3.7 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7\" \\\r\n  tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \\\r\n  tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh aarch64\r\n\r\n :\r\n :\r\nSUBCOMMAND: # //tensorflow/lite/schema:schema_fbs_srcs [action 'Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs', configuration: d6b574c9b84611aa340a96e749e5599cae8f6d55e0af10df15724f62bdc6068b, execution platform: @local_execution_config_platform//:platform]\r\n(cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/aarch64-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/aarch64-opt/bin/tensorflow/lite/schema $f; done')\r\nERROR: /workspace/tensorflow/lite/schema/BUILD:96:22: Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs failed (Exit 126): bash failed: error executing command \r\n  (cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/aarch64-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/aarch64-opt/bin/tensorflow/lite/schema $f; done')\r\nExecution platform: @local_execution_config_platform//:platform\r\n/bin/bash: bazel-out/aarch64-opt/bin/external/flatbuffers/flatc: cannot execute binary file: Exec format error\r\nTarget //tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper failed to build\r\nINFO: Elapsed time: 57.367s, Critical Path: 8.89s\r\nINFO: 410 processes: 178 internal, 232 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```\r\n- armhf\r\n```bash\r\n$ sudo CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3.7 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7\" \\\r\n  tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \\\r\n  tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf\r\n\r\nSUBCOMMAND: # //tensorflow/lite/schema:schema_fbs_srcs [action 'Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs', configuration: d2c4f92953c17c21701ba73a2ad97645e41ff9f8c325ec409c23649eb0856f42, execution platform: @local_execution_config_platform//:platform]\r\n(cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/armhf-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/armhf-opt/bin/tensorflow/lite/schema $f; done')\r\nERROR: /workspace/tensorflow/lite/schema/BUILD:96:22: Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs failed (Exit 126): bash failed: error executing command \r\n  (cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/armhf-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/armhf-opt/bin/tensorflow/lite/schema $f; done')\r\nExecution platform: @local_execution_config_platform//:platform\r\n/bin/bash: bazel-out/armhf-opt/bin/external/flatbuffers/flatc: cannot execute binary file: Exec format error\r\nTarget //tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper failed to build\r\nINFO: Elapsed time: 15.584s, Critical Path: 9.85s\r\nINFO: 410 processes: 178 internal, 232 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nIn addition, I have confirmed that the build using the make command succeeds as shown below. Only the build workflow using Bazel does not seem to work as expected.\r\n```\r\n$ cd tensorflow/tensorflow/lite/tools/pip_package\r\n$ sudo make BASE_IMAGE=debian:buster PYTHON=python3 TENSORFLOW_TARGET=aarch64 BUILD_DEB=y docker-build\r\n```\r\n![Screenshot 2021-07-19 23:11:09](https://user-images.githubusercontent.com/33194443/126174312-af38725a-c37c-4bbb-bffa-e2cfcdf3b6ac.png)\r\n", "comments": ["https://github.com/tensorflow/tensorflow/pull/50893 will fix this. ", "@terryheo Thank you! I will try to apply the suggested fixes and close it if there are no problems.", "- tensorflow/tensorflow/.bazelrc\r\n```bazel\r\n# TFLite build configs for generic embedded Linux\r\nbuild:elinux --crosstool_top=@local_config_embedded_arm//:toolchain\r\nbuild:elinux --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nbuild:elinux_aarch64 --config=elinux\r\nbuild:elinux_aarch64 --cpu=aarch64\r\nbuild:elinux_aarch64 --distinct_host_configuration=true\r\nbuild:elinux_armhf --config=elinux\r\nbuild:elinux_armhf --cpu=armhf\r\nbuild:elinux_armhf --distinct_host_configuration=true\r\n```\r\nThe build was successful.\r\n![Screenshot 2021-07-22 16:44:01](https://user-images.githubusercontent.com/33194443/126605204-16cd71a8-2ca8-4174-8ac8-4e23e5aac7bf.png)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50826\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50826\">No</a>\n", "@PINTO0309 How you solve it? I have the same .bazelrc with you but still failed.", "@SefaZeng \r\nIf your goal is to cross-compile the TensorFlow Lite runtime, everything is committed in my repository. This is a closed issue, so if you want to continue the discussion, please submit an issue in my repository.\r\n\r\n- Procedure\r\nhttps://github.com/PINTO0309/TensorflowLite-bin#2-tensorflow-v230-version-or-later\r\n\r\n- Installer\r\nhttps://github.com/PINTO0309/TensorflowLite-bin"]}, {"number": 50825, "title": "dataset support prefetch_to_device", "body": "If model in the device(GPU) and dataset in the host(CPU), the data output by dataset must be memcpyH2D, All compute graph spend long time to wait memcpyH2D done.\r\nI think we need a queue to cache output of dataset. so I find  https://github.com/tensorflow/tensorflow/issues/43905, this issues tell me we can use ```prefetch_to_device ``` by ```map().batch()``` or ```experimental::map_and_batch```. But in fact ```map(parallel_num).batch()``` is too slow, we need ```batch().map()``` and ```prefetch_to_device```\r\n\r\nbatch().map() nsys profiling:\r\n![image](https://user-images.githubusercontent.com/33950866/126093526-c21f6edc-1bf2-4f7c-a6d2-2d6812f1bd4f.png)\r\n\r\nI re-copy output of ParallelMapDataset::Iterator to device by set_gpu_compatible(true), and I got a more obvious speedup.\r\nso I would like to add a dataset named copy_to_device, usage like:\r\n\r\n```\r\nds = tf.data.TFRecordDataset(files).batch(batch_size).map(map_func,4).copy_to_device().prefetch(2).\r\nit = ds.make_one_shot_iterator()\r\ngn = it.get_next()\r\n...\r\n```", "comments": ["There is already `copy_to_device` transformation ([documentation](https://www.tensorflow.org/api_docs/python/tf/data/experimental/copy_to_device)) and `prefetch_to_device` is implemented as you suggest ([source](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/prefetching_ops.py#L62-L63)). Could you explain how is what's available different from what you would like? Thanks.", "> There is already `copy_to_device` transformation ([documentation](https://www.tensorflow.org/api_docs/python/tf/data/experimental/copy_to_device)) and `prefetch_to_device` is implemented as you suggest ([source](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/prefetching_ops.py#L62-L63)). Could you explain how is what's available different from what you would like? Thanks.\r\n\r\nthx, and  I will close this question ~"]}, {"number": 50824, "title": "Unknown: input/output error", "body": "When running my training script, I encounter this error inconsistently for different tfrecords (in the run below it was 11, but this number changes). I don't think it's an issue with the particular file mentioned below as I've been able to read every tfrecord I'm using with a separate script.\r\n\r\nUnknown: dataset-train.tfrecord-00011-of00032; Input/output error\r\n[[{{node MultiDeviceIteratorGetNextShard}}]][[RemoteCall]][[while/boy/_1/IteratorGetNext_1]][[while/body/_1/replica_1/mod/y/_39]]\r\n\r\nDoes anyone have thoughts on what is triggered this inconsistency?\r\n\r\n", "comments": ["@slala2121 Could you please fill the issue template.Also Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 50823, "title": "Dark mode not working for `metric_names` attributes of `tf.keras.Model`", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#attributes_1\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe `metrics_names` attribute section of `tf.keras.Model` doesn't work properly while turning on dark mode.\r\n\r\n<img width=\"629\" alt=\"Screenshot 2021-07-18 at 7 32 01 PM\" src=\"https://user-images.githubusercontent.com/46242526/126070193-287588da-0504-4807-a63a-727b15426fb7.png\">\r\n\r\n### Correct links\r\n\r\nDoc for `Model` : https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/engine/training.py#L135-L207\r\n\r\nDoc for attribute `metric_names` : https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/engine/training.py#L684-L717\r\n\r\n### Parameters defined\r\n\r\nThe `layers` attribute of the `tf.keras.Model` is not defined\r\n<img width=\"858\" alt=\"Screenshot 2021-07-18 at 8 27 48 PM\" src=\"https://user-images.githubusercontent.com/46242526/126071975-ac217cea-2e23-439b-ac78-35c588c275da.png\">\r\n\r\n\r\n### Submit a pull request?\r\n\r\nYes", "comments": ["@01-vyom \r\n\r\nIt looks like your Issue relates to the Keras component. Please submit it to the [github.com/keras-team/keras](https://github.com/keras-team/keras/issues) repository instead. As previously [announced](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) all future development of Keras is expected to happen in the keras-team/keras repository. If your issue lies with the TF-Core area please comment back with your explanation and we can look into it further. Thanks!\r\n \r\n", "@UsharaniPagadala \r\n\r\nThank you for the info. In Keras, the code-copy and code-theme functionality has not been implemented yet so will hold out on the issue. Will raise an issue in Keras later. \r\n\r\nThis issue can be closed."]}, {"number": 50822, "title": "Setting of Number of Threads for TFLite Interpreter API", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI am using TFLite  label image example - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/label_image/label_image.cc \r\n\r\nIn this example, We are setting number of threads at line number 238.\r\n```\r\nif (settings->number_of_threads != -1) {\r\n    interpreter->SetNumThreads(settings->number_of_threads);\r\n  }\r\n```\r\n\r\n\r\nCould you confirm whether the number of threads setting is needed or not ?\r\n\r\n\r\nDo the user need to specify the number of threads compulsory ?\r\n\r\n\r\n**If not specified will it take max number of threads available ?** \r\n\r\n\r\n\r\n**Will this change the current api?** \r\n\r\nNo need of setting the number of threads in the workflow.\r\n\r\n\r\n\r\n**Who will benefit with this feature?**\r\n\r\nUsers need not to manually set the number of threads if its set to max threads available.\r\n\r\n", "comments": ["If the number of threads are not specified then they will be implementation-defined and platform-dependent. \r\nSee https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/Interpreter.Options#public-interpreter.options-setnumthreads-int-numthreads", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 50821, "title": "TF 2.5 | preprocessing.CategoryCrossing behavior different than feature_column.crossed_column", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow version (use command below): 2.5( All 2+ )\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nWhen using the new `experimental.preprocessing.CategoryCrossing` layer, it returns values like `[[b'1_X_2_X_3'], [b'4_X_5_X_6']]` as stated in the documentation. Now when the dimension space becomes very large, it is impossible to convert these values to embeddings using the layer `tf.keras.layers.Embedding` as it expects values to be encoded between 0 to N and the layer doesn't return any integerlookup for these new categories generated from `CategoryCrossing`.\r\n\r\nOne of the alternates that I was trying was as below:\r\n```\r\ncross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])\r\nhash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)\r\nembed_cross_day_hour = tf.keras.layers.Embedding(193, 4)(hash_cross_day_hour)\r\n```\r\n\r\nHowever it is not reliable to use the above method as the Hashing layer will have possible collisions( even when num_bins = max number of values ) in each training loop of minibatch. The hashing layer doesn't remember values from previous loops, leading to same hash for different values in each iteration. This will lead to same value passing in the `Embedding` layer for same hash generated for two different values being passed to `Hashing` layer in separate training batches( loops ).\r\n\r\nIt was *possible earlier* using the `tf.feature_column.crossed_column` to convert it to embeddings by passing the output directly to `tf.feature_column.embedding_column` as `crossed_column` automatically used to return hashes but no more in case of the new layer. ***Please fix this.***\r\n\r\n**Describe the expected behavior**:\r\nEither of possible solutions:\r\n1. The new layer `preprocessing.CategoryCrossing` should ideally be directly pluggable with the `layers.Embedding` layer to generate embeddings for very large categorical space. It should generate values = 0 to N\r\n2. Or `preprocessing.CategoryCrossing` should return some other output as well which depicts what all possible unique values are there that can be passed to StringLookup layer to further generate Integer mapping per cross.\r\n3. Or `preprocessing.Hashing` should be capable of remembering values from previous loops until re-instantiated in order to avoid generating same hashes for different values even though num_bins = total unique values\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\ncross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])\r\nhash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)\r\nembed_cross_day_hour = tf.keras.layers.Embedding(193, 4)(hash_cross_day_hour)\r\n```\r\n\r\nAlso see how the ***Hashing*** layer generates same hash for different values even though num_bins is set to total number of unique values, which makes it impossible to use the above solution:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\n\r\nlayer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=10)\r\ninp = [['A'], ['B'], ['C'], ['D'], ['E']]\r\nprint(layer(inp))\r\n\r\ninp = [['F'], ['G'], ['H'], ['I'], ['J']]\r\nprint(layer(inp))\r\n```\r\n\r\nOutput:\r\n```\r\ntf.Tensor(\r\n[[4]\r\n [8]\r\n [7]\r\n [5]\r\n [2]], shape=(5, 1), dtype=int64)\r\ntf.Tensor(\r\n[[6]\r\n [1]\r\n [8]\r\n [0]\r\n [4]], shape=(5, 1), dtype=int64)\r\n\r\n```\r\n\r\nCC: @rsesha @AutoViML @rafiqhasan - This directly affects the libraries: https://github.com/AutoViML/deep_autoviml and https://github.com/rafiqhasan/auto-tensorflow/", "comments": ["Thank you. I will try my best to bring it to some people\u2019s attention.\nRam\n\nOn Sun, Jul 18, 2021 at 7:37 AM Hasan Rafiq ***@***.***>\nwrote:\n\n>\n>    - Have I written custom code (as opposed to using a stock example\n>    script provided in TensorFlow): Yes\n>    - OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\n>    - TensorFlow version (use command below): 2.5( All 2+ )\n>    - Python version: 3.7\n>\n> *Describe the current behavior*\n> When using the new experimental.preprocessing.CategoryCrossing layer, it\n> returns values like [[b'1_X_2_X_3'], [b'4_X_5_X_6']] as stated in the\n> documentation. Now when the dimension space becomes very large, it is\n> impossible to convert these values to embeddings using the layer\n> tf.keras.layers.Embedding as it expects values to be encoded between 0 to\n> N and the layer doesn't return any integerlookup for these new categories\n> generated from CategoryCrossing.\n>\n> One of the alternates that I was trying was as below:\n>\n> cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])\n> hash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)\n> cat_cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryEncoding(max_tokens = 24 * 8)(hash_cross_day_hour)\n> embed_cross_pick_lon_lat = tf.keras.layers.Embedding(((len(bins_lat) + 1) ** 2), 4)(hash_cross_pick_lon_lat)\n>\n> However it is not reliable to use the above method as the Hashing layer\n> will have possible collisions in each training loop of minibatch. The\n> hashing layer doesn't remember values from previous loops, leading to same\n> hash for different values in each iteration. This will lead to same value\n> passing in the CategoryEncoding layer for two different values passed to\n> Hashing layer in separate training batches( loops ), as it can return\n> same hash in different loops even though the number of bins are = number of\n> categories from previous layers.\n>\n> It was *possible earlier* using the tf.feature_column.crossed_column to\n> convert it to embeddings by passing the output directly to\n> tf.feature_column.embedding_column as crossed_column automatically used\n> to return hashes but no more in case of the new layer. *Please fix this.*\n>\n> *Describe the expected behavior*:\n> The new layer preprocessing.CategoryCrossing should ideally be directly\n> pluggable with the layers.Embedding layer to generate embeddings for very\n> large categorical space. Or it should return some other output as well\n> which depicts what all possible unique values are there that can be passed\n> to CategoryEncoding layers to further generate Integer mapping per cross.\n>\n> *Standalone code to reproduce the issue*\n> Provide a reproducible test case that is the bare minimum necessary to\n> generate\n> the problem. If possible, please share a link to Colab/Jupyter/any\n> notebook.\n>\n> cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])\n> hash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)\n> cat_cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryEncoding(max_tokens = 24 * 8)(hash_cross_day_hour)\n> embed_cross_pick_lon_lat = tf.keras.layers.Embedding(((len(bins_lat) + 1) ** 2), 4)(hash_cross_pick_lon_lat)\n>\n> Also see how the *Hashing* layer generates same hash for different values\n> even though num_bins is set to total number of unique values, which makes\n> it impossible to use the above solution:\n>\n> import tensorflow as tf\n> import tensorflow.keras as keras\n>\n> layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=10)\n> inp = [['A'], ['B'], ['C'], ['D'], ['E']]\n> print(layer(inp))\n>\n> layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=10)\n> inp = [['F'], ['G'], ['H'], ['I'], ['J']]\n> print(layer(inp))\n>\n> Output:\n>\n> tf.Tensor(\n> [[4]\n>  [8]\n>  [7]\n>  [5]\n>  [2]], shape=(5, 1), dtype=int64)\n> tf.Tensor(\n> [[6]\n>  [1]\n>  [8]\n>  [0]\n>  [4]], shape=(5, 1), dtype=int64)\n>\n>\n> CC: @rsesha <https://github.com/rsesha> @AutoViML\n> <https://github.com/AutoViML> @rafiqhasan <https://github.com/rafiqhasan>\n> - This directly affects the libraries:\n> https://github.com/AutoViML/Auto_ViML and\n> https://github.com/rafiqhasan/auto-tensorflow/\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/50821>, or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AGEUZ7CIVOK54YI5QQH2KT3TYK4GNANCNFSM5ASBJ3BA>\n> .\n>\n", "@rafiqhasan  It looks like your Issue relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. As ([previously announced](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999/)), all future development of Keras is expected to happen in the [github.com/keras-team/keras](github.com/keras-team/keras) repository. If your issue lies with the TF-Core area please comment back with your explanation and we can look into it further. Thanks!", "Thanks @saikumarchalla I'll link this bug there\r\n\r\nHowever I still don't understand this point, we have been told on various bugs specifically that tf.feature_column has been deprecated by tf.preprocessing layer. \r\n\r\nSo are we saying that this option from TF core has been completely deprecated and replaced with a Keras library option which is now officially maintained outside TF core ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50821\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50821\">No</a>\n"]}, {"number": 50820, "title": "Unclear how to adapt multiple Keras preprocessing layers", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/keras/preprocessing_layers\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nCurrently all examples of calling `adapt()` on a preprocessing layer with a `Dataset` argument assumes a single input feature (and thus a single `Input`). In a model with multiple `Input`s and `PreprocessingLayer`s it's unclear how to use `adapt()` together with a `Dataset`.\r\n\r\n### Usage example\r\n\r\n(Cross-posted to https://stackoverflow.com/questions/68426974/how-do-you-use-keras-preprocessing-normalization-layers-with-multi-input-models):\r\n\r\n```\r\nx_norm = preprocessing.Normalization()\r\ny_norm = preprocessing.Normalization()\r\n\r\nx = layers.Input(shape=(1,))\r\nx = x_norm(x)\r\ny = layers.Input(shape=(1,))\r\ny = y_norm(y)\r\nconcated = layers.Concatenate()([x, y])\r\noutput = layers.Dense(1)(concated)\r\nmodel = keras.Model(inputs=[x, y], outputs=output)\r\n```\r\n\r\nThis does *not* work but should:\r\n\r\n```\r\nx_norm.adapt(dataset)\r\ny_norm.adapt(dataset)\r\n```\r\n\r\nWorkaround that involve manual iteration over the `Dataset` result in inefficient execution as `adapt()` manages its own `tf.function` internally. This results in warning for the manual approach:\r\n\r\n```\r\nnormalization_layers = {\r\n    'x': preprocessing.Normalization(),\r\n    'y': preprocessing.Normalization(),\r\n    }\r\nfor batch in dataset:\r\n  for name, layer in normalization_layers.items():\r\n    layer.adapt(batch[0][name])\r\n```", "comments": ["More generally, it seems like `adapt()` is in the wrong place. It seems like it should be part of the model, just like `fit()`, so all preprocessing layers can be automatically discovered and adapted together: `model.adapt(dataset)`. Currently you need to keep track of your various preprocessing layers outside the model so you can call `adapt()` individually on them. This is especially annoying when several preprocessing layers need to be stacked.", "https://www.tensorflow.org/recommenders/examples/featurization seems to be the best example of how to work with several inputs. Perhaps https://www.tensorflow.org/guide/keras/preprocessing_layers clarifying the approach (e.g. use `Dataset.map` repeatedly). Seems rather inefficient though as you need one pass over the data per feature instead of adapting them all in a single pass.", "This class offers a similar interface to what you describe:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/79e9e45fa08931aaa6bc72124cfbe776e40e2cc0/tensorflow/python/keras/layers/preprocessing/preprocessing_stage.py#L98-L133", "@tibbe \r\nPlease update as per above comment", "Works well. Could perhaps a somewhat more elaborate example where the inputs/outputs of the stage is connected to a model. I'd imagine it'd look something like:\r\n\r\n```py\r\npreproc_layer = preprocessing_stage.FunctionalPreprocessingStage(\r\n    inputs, normalization_layers)\r\npreproc_layer.adapt(train_dataset)\r\n\r\nx = tf.keras.layers.Concatenate()(preproc_layer.outputs)\r\nx = ...\r\noutput = layers.Dense(1)(x)\r\nmodel = keras.Model(inputs=preproc_layer.inputs, outputs=output)\r\n```\r\n\r\nFeel free to close.", "@tibbe \r\nThank you for your update moving this to closed status as resolved.", "I spoke too soon. While the `FunctionalPreprocessingState.adapt()` method runs without errors it doesn't seem to work. If I individually adapt layers like so:\r\n\r\n```py\r\ninputs = {}\r\nnormalization_layers = {}\r\n\r\nfor name in NUMERIC_FEATURES:\r\n  inputs[name] = layers.Input(shape=(1,))\r\n  normalization_layers[name] = preprocessing.Normalization()\r\n\r\nfor name, layer in normalization_layers.items():\r\n  layer.adapt(train_dataset.map(lambda x, y: x[name]))\r\n\r\ninput_layers = []\r\nfor name, input in inputs.items():\r\n  input_layers.append(normalization_layers.get(name)(input))\r\nx = tf.keras.layers.Concatenate()(input_layers)\r\nx = layers.Dense(32)(x)\r\nx = layers.Dense(16)(x)\r\noutput = layers.Dense(1)(x)\r\nmodel = keras.Model(inputs=inputs, outputs=output)\r\nmodel.compile(optimizer='adam', loss='mse',\r\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\r\n```\r\n\r\nthe model trains (the loss is decreasing). If I instead use the `FunctionalPreprocessingState` helper class like so:\r\n\r\n```py\r\ninputs = []\r\nnormalization_layers = []\r\n\r\nfor name in NUMERIC_FEATURES:\r\n  input = layers.Input(shape=(1,))\r\n  inputs.append(input)\r\n  normalization_layers.append(preprocessing.Normalization()(input))\r\n\r\npreproc_layer = preprocessing_stage.FunctionalPreprocessingStage(\r\n    inputs, normalization_layers)\r\npreproc_layer.adapt(train_dataset)\r\n\r\nx = tf.keras.layers.Concatenate()(preproc_layer.outputs)\r\nx = layers.Dense(32, activation=\"relu\")(x)\r\nx = layers.Dense(16, activation=\"relu\")(x)\r\noutput = layers.Dense(1)(x)\r\nmodel = keras.Model(inputs=preproc_layer.inputs, outputs=output)\r\nmodel.compile(optimizer='adam', loss='mse',\r\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\r\n```\r\n\r\nIt doesn't train (the loss isn't decreasing). I suspect that the layers didn't get adapted properly and are doing random transformations to the input features during training.", "I think this issue needs to be re-opened.", "@tibbe \r\n\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "https://github.com/keras-team/keras/issues/15219", "So the Keras people says (see previous comment for link to the Keras bug) that `FunctionalPreprocessingStage` isn't an exposed symbol of Keras (but I believe it is of TF as of 2.6) so it's now unclear to me who feels responsible for that function working. :)"]}, {"number": 50819, "title": "Which version of CUDA and cuDNN should i use with tensorflow2.5.0 ?", "body": "https://tensorflow.google.cn/install/source_windows#gpu\r\nIn this page, I can't figure out what version of CUDA and cuDNN should I use with tf2.5.0.\r\nWhen I use my tensorflow, it can't recognize my GPU.\r\nit shows:\r\n2021-07-18 14:45:58.223694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\r\n2021-07-18 14:45:58.223904: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\n**System information**\r\n- Windows 10\r\n- TensorFlow installed from (source or binary): https://pypi.python.org/simple\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 11.2 cuDNN 8.2\r\n- GPU model and memory: Nvidia 1660 Ti\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen I use my tensorflow, it can't recognize my GPU.\r\nI think it is a version problem, but in this page[https://tensorflow.google.cn/install/source_windows#gpu] I can't find which version to use.\r\n\r\nSo, please update the installation info page and let us know which version of CUDA and cuDNN to use. Thanks!\r\n\r\n", "comments": ["you need cuda 11.2 and cuDNN 8.1.0\r\nalso,, you should copy cuDNN to cuda's path.\r\ntype nvcc --version in your cmd/shell window and you should get the version of your cuda. if you don't get that, it means you havent properly installed cuda and/or you havent added it to path", "Thanks\uff01", "https://www.tensorflow.org/install/source_windows#gpu\r\n<img width=\"888\" alt=\"Screen Shot 2021-07-18 at 1 02 52 AM\" src=\"https://user-images.githubusercontent.com/42785357/126060238-55cd6bed-aaa4-48f9-b1c5-62ccca133b62.png\">\r\n", "I have a similiar issue where my CUDA V11.2 as well as my CUDNN V 8.1.0 does not get recognized by tensorflow 2.5. I managed to fix this by adding the mentioned libraries in System32. As described in this Issue https://github.com/tensorflow/tensorflow/issues/50589. \r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50819\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50819\">No</a>\n"]}]