[{"number": 55278, "title": "tf.function condition with tensor", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nColab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\ncolab\r\n- TensorFlow version (use command below):\r\ndefault colab\r\n- Python version:\r\ndefault colab\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```python \r\n@tf.function\r\ndef test():\r\n  b = tf.math.maximum(0,1)\r\n  if 0 < b <= 2:\r\n   b = b+1\r\n  return b\r\ntest().numpy()\r\n```\r\n```python\r\nOperatorNotAllowedInGraphError: in user code:\r\n\r\n    File \"<ipython-input-80-cfa5312e70c9>\", line 4, in test  *\r\n        if 0 < b <= 2:\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\nI suppose that it will give `2` as with this little modified version:\r\n\r\n```python\r\n@tf.function\r\ndef test():\r\n  b = tf.math.maximum(0,1)\r\n  if 0 < b and b <= 2:\r\n   b = b+1\r\n  return b\r\ntest().numpy()\r\n```\r\n```python\r\n2\r\n```\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\nWith some hints\r\n- Briefly describe your candidate solution(if contributing):\r\nI need some pointer\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Just to share more debugging info for the failing and working case:\r\n\r\n```python\r\nINFO:tensorflow:Source code of <function test at 0x7f06040d5160>:\r\n\r\n@tf.function\r\ndef test():\r\n  b = tf.math.maximum(0,1)\r\n  if 0 < b and b <= 2:\r\n   b = b+1\r\n  return b\r\n\r\n\r\nINFO:tensorflow:Transformed <function test at 0x7f06040d5160>:\r\n\r\n# coding=utf-8\r\ndef tf__test():\r\n    with ag__.FunctionScope('test', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n        do_return = False\r\n        retval_ = ag__.UndefinedReturnValue()\r\n        b = ag__.converted_call(ag__.ld(tf).math.maximum, (0, 1), None, fscope)\r\n\r\n        def get_state():\r\n            return (b,)\r\n\r\n        def set_state(vars_):\r\n            nonlocal b\r\n            (b,) = vars_\r\n\r\n        def if_body():\r\n            nonlocal b\r\n            b = ag__.ld(b) + 1\r\n\r\n        def else_body():\r\n            nonlocal b\r\n            pass\r\n        ag__.if_stmt(ag__.and_(lambda : 0 < ag__.ld(b), lambda : ag__.ld(b) <= 2), if_body, else_body, get_state, set_state, ('b',), 1)\r\n        try:\r\n            do_return = True\r\n            retval_ = ag__.ld(b)\r\n        except:\r\n            do_return = False\r\n            raise\r\n        return fscope.ret(retval_, do_return)\r\n```\r\n```python\r\nINFO:tensorflow:Source code of <function test at 0x7ff34af56160>:\r\n\r\n@tf.function\r\ndef test():\r\n  b = tf.math.maximum(0,1)\r\n  if 0 < b <= 2:\r\n   b = b+1\r\n  return b\r\n\r\n\r\nINFO:tensorflow:Transformed <function test at 0x7ff34af56160>:\r\n\r\n# coding=utf-8\r\ndef tf__test():\r\n    with ag__.FunctionScope('test', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n        do_return = False\r\n        retval_ = ag__.UndefinedReturnValue()\r\n        b = ag__.converted_call(ag__.ld(tf).math.maximum, (0, 1), None, fscope)\r\n\r\n        def get_state():\r\n            return (b,)\r\n\r\n        def set_state(vars_):\r\n            nonlocal b\r\n            (b,) = vars_\r\n\r\n        def if_body():\r\n            nonlocal b\r\n            b = ag__.ld(b) + 1\r\n\r\n        def else_body():\r\n            nonlocal b\r\n            pass\r\n        ag__.if_stmt(0 < ag__.ld(b) <= 2, if_body, else_body, get_state, set_state, ('b',), 1)\r\n        try:\r\n            do_return = True\r\n            retval_ = ag__.ld(b)\r\n        except:\r\n            do_return = False\r\n            raise\r\n        return fscope.ret(retval_, do_return)\r\n```", "The 2nd autograph is valid so I think that there is a false positive:\r\n```python\r\nfrom tensorflow.python.autograph.impl import api\r\nag__ = api._TRANSPILER.get_extra_locals()['ag__']  # pylint:disable=protected-access\r\ndef tf__test():\r\n    with ag__.FunctionScope('test', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n        do_return = False\r\n        retval_ = ag__.UndefinedReturnValue()\r\n        b = ag__.converted_call(ag__.ld(tf).math.maximum, (0, 1), None, fscope)\r\n\r\n        def get_state():\r\n            return (b,)\r\n\r\n        def set_state(vars_):\r\n            nonlocal b\r\n            (b,) = vars_\r\n\r\n        def if_body():\r\n            nonlocal b\r\n            b = ag__.ld(b) + 1\r\n\r\n        def else_body():\r\n            nonlocal b\r\n            pass\r\n        ag__.if_stmt(0 < ag__.ld(b) <= 2, if_body, else_body, get_state, set_state, ('b',), 1)\r\n        try:\r\n            do_return = True\r\n            retval_ = ag__.ld(b)\r\n        except:\r\n            do_return = False\r\n            raise\r\n        return fscope.ret(retval_, do_return)\r\n\r\nprint(tf__test().numpy())\r\n```\r\n```python\r\n2\r\n```", "The second form seems to pass with:\r\n`@tf.function(experimental_autograph_options=tf.autograph.experimental.Feature.EQUALITY_OPERATORS)`\r\n\r\nAs it is converted in the same form as the first impl:\r\nhttps://github.com/tensorflow/tensorflow/blob/87462bfac761435a46641ff2f10ad0b6e5414a4b/tensorflow/python/autograph/converters/logical_expressions.py#L89-L90\r\n\r\n```python\r\nag__.if_stmt(ag__.and_(lambda : 0 < ag__.ld(b), lambda : ag__.ld(b) < 2), if_body, else_body, get_state, set_state, ('b',), 1)\r\n```\r\n/cc @mdanatg ", "https://github.com/tensorflow/tensorflow/blob/87462bfac761435a46641ff2f10ad0b6e5414a4b/tensorflow/python/autograph/converters/logical_expressions.py#L89-L90", "Odd, I thought we had enabled that feature by default. But I think if was left off as Tensor implemented its own `__eq__` , `__lt__`, etc. This use case indicates that we should turn it on anyway.", "> Odd, I thought we had enabled that feature by default. But I think if was left off as Tensor implemented its own `__eq__` , `__lt__`, etc. This use case indicates that we should turn it on anyway.\n\nIs https://github.com/tensorflow/tensorflow/issues/55278#issuecomment-1073058951 running fine cause we are in eager mode?", "Yes. When evaluating `a < b < c` Python calls something in the lines of `(a < b).__bool__()`, which only works in eager mode.", "> Yes. When evaluating `a < b < c` Python calls something in the lines of `(a < b).__bool__()`, which only works in eager mode.\r\n\r\nYes honestly it is so hard to explain this kind of underline machinery to our users/developers. I needed to point another user to the `Cpython` source for a [\"similar\" case](https://discuss.tensorflow.org/t/you-cannot-build-your-model-by-calling-build-if-your-layers-do-not-support-float-type-inputs/8356/6)", "Yep, Python has uses a bit of magic in this case. I find is easiest to explain by crafting a class with overloaded operators and running it:\r\n\r\n```\r\nclass C():\r\n\r\n  def __init__(self, name):\r\n    self.name = name\r\n\r\n  def __lt__(self, other):\r\n    print('__lt__: ', self.name, '<', other.name)\r\n    return C('result of ' + self.name + ' < ' + other.name)\r\n  \r\n  def __bool__(self):\r\n    print('__bool__: ', self.name)\r\n    return True\r\n\r\n  def __repr__(self):\r\n    return self.name\r\n\r\na = C('a')\r\nb = C('b')\r\nc = C('c')\r\n\r\nprint(a < b < c)\r\n```\r\n\r\nBTW, the `max` case could be a feature requerst for autograph to replace `tf.maximum` - we do that for a few builtins like `len`, and it's a fairly straightforward change: https://github.com/tensorflow/tensorflow/blob/b75de1cb47551a5a43f0c8d095252d0a125c4a8a/tensorflow/python/autograph/operators/py_builtins.py#L630", "> Yep, Python has uses a bit of magic in this case. I find is easiest to explain by crafting a class with overloaded operators and running it:\r\n\r\nIt is still hard for an avg developer to understand that we probably want to collect this case as a new `Autograph` ticket. \r\nDo you think that we could improve the string:\r\n`OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.`\r\n", "P.s. I would like to make a PR for both the cases but I will go for sure to abuse the CI with a blackbox impl as I've described in https://github.com/tensorflow/tensorflow/pull/55192#issue-1165231429.\r\nAnd in this case it will require for sure  more CI cycles so this will go to slowdown the PR too much without locally executing tests.\r\n\r\n\r\n\r\n", "Oops, edited.\r\n\r\nYes, improving the error message makes sense too; one challenge is that it comes from outside of autograph, and can be triggered from other places as well.", "@mdanatg Let me know how I could help you. If required I could spent/invest again many computing hours to rebuild TF with a fresh commit. I still think it will be faster for you with your build infra but if you don't have free slots give me some pointers I would try to rebuild \"again\" TF. \r\n\r\nI see 3 activities here:\r\n- Default enable `tf.autograph.experimental.Feature.EQUALITY_OPERATORS`\r\n- Extend buitlin ops for `min` and `max` + tests.\r\n- Improve `OperatorNotAllowedInGraphError: using a tf.Tensoras a Pythonbool is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.`", "It's definitely easier for me to test, though I'm not sure when I'll have the bandwidth. For very simple changes, I think it'd be ok to rely on the CI instead of building locally. BTW, I think basic building is a bit more practical on linux nowadays - especially if you use the [docker container](https://www.tensorflow.org/install/source#cpu-only); you don't need to build the whole pip package, just `bazel test` the unit test straight after `./configure`.\r\n\r\nFor now, how about we keep this issue for the first bullet, and file separate ones for the other two bullets?", "> For now, how about we keep this issue for the first bullet, and file separate ones for the other two bullets?\r\n\r\nOk\r\n\r\n> especially if you use the [docker container](https://www.tensorflow.org/install/source#cpu-only); you don't need to build the whole pip package, just bazel test the unit test straight after ./configure.\r\n\r\nThis will not speedup my contribution, I've built TF multiple times in the last years investing many hours of (waiting) compile time between a PR and the next one. \r\nAre you aware of:\r\nhttps://discuss.tensorflow.org/t/llvm-updates-and-bazel-cache/2060\r\nhttps://github.com/tensorflow/build/pull/48\r\nhttps://github.com/tensorflow/build/issues/72\r\n\r\n\r\n", "As we are not going to care/solve these build topics quite soon I need to invest many hours to rebuild again TF.\r\n\r\n For the fist point do you have a specific pointer for the tests I need to run/pass? Is `bazel test tensorflow/python/autograph/operator` enough?\r\n\r\nAs just `bazel test tensorflow/python/autograph/operator` already requires  more then 27k targets if the bazel estimation is correct:\r\n\r\n`INFO: Analyzed target //tensorflow/python/autograph/operators:operators (372 packages loaded, 27441 targets configured).`", "> As we are not going to care/solve these build topics quite soon I need to invest many hours to rebuild again TF.\r\n\r\nI admit it's frustrating :( Most PRs rely on the internal build system, making it hard to get traction to improve the external one.\r\n\r\n> For the fist point do you have a specific pointer for the tests I need to run/pass? Is bazel test tensorflow/python/autograph/operator enough?\r\n\r\nI'd say, just `tensorflow/python/autograph/operators:py_builtins_test` and `tensorflow/python/autograph/converterd:logical_expressions_test` (especially if you add a test in there). The main idea is to test that the code builds and runs, and let the CI catch any other corner cases.\r\n\r\n> As just bazel test tensorflow/python/autograph/operator already requires more then 27k targets if the bazel estimation is correct:\r\n\r\nLooks about right, though IIRC it can grow up to 50k. It practically builds the whole TF, it's just that you'll run far fewer tests.", "> I admit it's frustrating :( Most PRs rely on the internal build system, making it hard to get traction to improve the external one.\r\n\r\nIt is one of the \"chicken or the egg\" problems we have for the community growing.\r\n\r\nI will ping you when the compilation is done.\r\n", "Done.. for the the record:\r\n`bazel test tensorflow/python/autograph/operator` \r\n`INFO: Elapsed time: 15290.045s, Critical Path: 298.10s` - Quad core with  6K bogomips (just to give a reference.)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55278\">No</a>\n"]}, {"number": 55277, "title": "Tensorflow Model Compiler Metrics Error: NaN Outputs", "body": "I am having a problem using Tensorflow when trying to use two custom metric functions which calculate the mean and maximum fractional errors. My code for these functions are the following:\r\n\r\n```\r\nmeanFE = np.sum(np.abs(f_emulator - f_test))\r\nmaxFE = np.max(np.abs(f_emulator - f_test))\r\n```\r\n\r\nWhen I try to use these metrics, all of the loss outputs go to NaN. If I use my meanFE and maxFE outside of Tensorflow, I don't encounter this issue. The only way I have been able to use these functions in Tensorflow is to remove the denominator term in the fractional errors, but this defeats the purpose of using a fractional error in the first place. I suspect this has something to do with the fact that my arrays get turned into Tensor objects by default when the system trains. My inputs are astronomical spectra (i.e., each spectrum is an array of shape (500 x 100), or there are 500 spectral arrays with 100 wavelength bins per array.\r\n\r\nI have tried using other built in functions for my metrics, namely the MAPE function (mean absolute percentage error), but this generates bad spectra (output spectra do not look like input spectra), so I am trying to implement my own shown above. Has anyone encountered NaN outputs as your loss and metric output when using functions such as these? I am using Tensorflow 1.14.0 on macOS.", "comments": ["Hi @abojanich ! 1.x versions are not supported anymore. I think there might be NaN values in Dataset itself as you are already using np.abs to convert the negative fraction values to positive ones.  Please let us know after replacing the above metrics with the below one.  If it is a zero division error in your loss function , you can resolve it by adding [k.epsilon](https://stackoverflow.com/a/69679222) in Denominator.  Please post on [TF forum ](https://discuss.tensorflow.org/)for further assistance. Thank you!\r\n```\r\nmeanFE = np.abs(np.sum(np.abs(np.nan_to_num(f_emulator - f_test)))) // I think np.mean instead of np.sum for getting the mean \r\nmaxFE = np.abs(np.max(np.abs(np.nan_to_num(f_emulator - f_test))))\r\n```\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55277\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55277\">No</a>\n"]}, {"number": 55276, "title": "Event file summary metric type changed, breaking the example in summary_iterator.py", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\n[Please provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/summary/summary_iterator.py#L45)\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n```\r\n  for e in tf.compat.v1.train.summary_iterator(path to events file):\r\n      for v in e.summary.value:\r\n          if v.tag == 'loss':\r\n              print(v.simple_value)\r\n```\r\nSome version between TF 2.3 and TF 2.8, it seems the behavior of logging metrics in TB event files changed. Before, values were logged as `simple_value` in the proto. Now, it is logged as a tensor that requires additional parsing with `tf.make_ndarray()` for example. As a result, this example in the documentation here no longer works. I'm not sure if the change to metrics writing was intentional (wasn't able to find release notes on that) but we should update the documentation here to a working one.\r\n\r\nTF 2.3 gist: https://colab.research.google.com/gist/timatim/067edda865dc9c0899bda0befd97930c/beginner.ipynb\r\n```\r\nv.simple_value\r\n```\r\nTF 2.8 gist: https://colab.research.google.com/gist/timatim/2828cf9aa67e77d20baa22fc9935a684/beginner.ipynb\r\n```\r\ntf.make_ndarray(v.tensor)\r\n```", "comments": ["@timatim,\r\n\r\nThanks for reporting. Created CL to fix above issue.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 55275, "title": "Converter for LogicalOr and LogicalAnd operations", "body": "Implement  converters for LogicalOr and LogicalAnd operations.", "comments": ["@bixia1 please review", "This PR has been replaced by [PR#55548](https://github.com/tensorflow/tensorflow/pull/55548) "]}, {"number": 55274, "title": "Add necessary check in fft ops to fix crash", "body": "This PR tries to address the issue raised in #55263 where\r\ntf.single.rfft2d will crash when length contains negative value.\r\n\r\nThis PR fixes #55263\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 55272, "title": "Enabling Bazelisk to be used when Bazel is not present during install build from source", "body": "Update Configure.py @55218, Last commit failed at CICD for seemly unrelated issue. This patch is just to re run the same CICD and validate", "comments": ["Please use a better PR title. See https://cbea.ms/git-commit/", "> Please use a better PR title. See https://cbea.ms/git-commit/\r\n\r\nDo I need to make a fresh PR ? Could you please review this ?", "You can update the title of this PR", "> You can update the title of this PR\r\n\r\nDone, hope it looks good. Thanks for your feedback, @mihaimaruseac ", "@mihaimaruseac , any thought on the internal CI fail Internal ", "Currently blocked on \"import/copybara Pending \u2014 Waiting for internal safe review approval\". Needs another eye on review there.\r\n\r\nWindows builds were broken last week due to LLVM updates, but now they should be ok."]}, {"number": 55270, "title": "model.fit error, I need to adjust my code for a 5 categories instead of two.", "body": "\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\r\n\r\n\r\n\r\nX = pickle.load(open(\"X.pickle\",\"rb\"))\r\ny = pickle.load(open(\"y.pickle\",\"rb\"))\r\n\r\nX = X/255.0\r\n\r\n\r\nmodel = Sequential()\r\n\r\nmodel.add(  Conv2D(64,  (3,3), input_shape = X.shape[1:]  ))\r\nmodel.add(Activation(\"relu\"))\r\nmodel.add(MaxPooling2D(pool_size=(2,2)))\r\n\r\nmodel.add(Conv2D(64,  (3,3)))\r\nmodel.add(Activation(\"relu\"))\r\nmodel.add(MaxPooling2D(pool_size=(2,2)))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64))\r\nmodel.add(Activation(\"relu\"))\r\n\r\nmodel.add(Dense(1))\r\nmodel.add(Activation('sigmoid'))\r\n\r\nmodel.compile(loss=\"categorical_crossentropy\",\r\n              optimizer=\"adam\",\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(X, [y], batch_size=32, epochs=30, validation_split=0.1)", "comments": ["ValueError                                Traceback (most recent call last)\r\n[<ipython-input-138-bed1b8040615>](https://localhost:8080/#) in <module>()\r\n     32               metrics=['accuracy'])\r\n     33 \r\n---> 34 model.fit(X, [y], batch_size=32, epochs=30, validation_split=0.1)\r\n     35 \r\n\r\n1 frames\r\n[/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py](https://localhost:8080/#) in train_validation_split(arrays, validation_split)\r\n   1478     raise ValueError(\r\n   1479         \"`validation_split` is only supported for Tensors or NumPy \"\r\n-> 1480         \"arrays, found following types in the input: {}\".format(unsplitable))\r\n   1481 \r\n   1482   if all(t is None for t in flat_arrays):\r\n\r\nValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class 'int'>, <class...\r\n", "Change y to a numpy array\r\ny=np.array(y)", "@youssefelnaggar,\r\n\r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose). Also share all supporting files (i.e pickle) to replicate your issue reported here.\r\n\r\nIn meanwhile, here your issue will be resolved either by changing your input to tensor or numpy array.  Can you please refer [this issue](https://github.com/tensorflow/tensorflow/issues/38613).\r\n\r\nSince you are trying for multi class classification please change last code backlog of your model with below the code snippet\r\n```\r\nmodel.add(Dense(5))\r\nmodel.add(Activation('softmax'))\r\n```\r\nThanks!", "thank you so much\\\n\n\nOn Thu, Mar 17, 2022 at 10:31 AM chunduriv ***@***.***> wrote:\n\n> @youssefelnaggar <https://github.com/youssefelnaggar>,\n>\n> Can you please fill the issue template\n> <https://github.com/tensorflow/tensorflow/issues/new/choose>. Also share\n> all supporting files (i.e pickle) to replicate your issue reported here.\n>\n> In meanwhile, here your issue will be resolved either by changing your\n> input to tensor or numpy array. Can you please refer this issue\n> <https://github.com/tensorflow/tensorflow/issues/38613>.\n>\n> Since you are trying for multi class classification please change last\n> code backlog of your model with below the code snippet\n>\n> model.add(Dense(5))\n> model.add(Activation('softmax'))\n>\n> Thanks!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/55270#issuecomment-1071054440>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AYIPGR4KEDXYQ4KPYZ534I3VANM4VANCNFSM5Q7EEKOQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n", "@youssefelnaggar,\r\n\r\nCould you please confirm if this issue is resolved for you? Thanks!", "Yes. Thank you !\n\nOn Mon, Mar 21, 2022 at 4:42 AM chunduriv ***@***.***> wrote:\n\n> @youssefelnaggar <https://github.com/youssefelnaggar>,\n>\n> Could you please confirm if this issue is resolved for you? Thanks!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/55270#issuecomment-1073741437>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AYIPGR7KVVQOJVDWJV3LU6DVBBHA5ANCNFSM5Q7EEKOQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n", "@youssefelnaggar,\r\n\r\nPlease feel free to close the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55270\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55270\">No</a>\n"]}, {"number": 55269, "title": "Hexagon delegate doesn`t work on Android devices, cannot be loaded library UnsatisfiedLinkError (CMake)", "body": "**System information**\r\n- OS Platform and Distribution: build with ubuntu:18.04(docker image)\r\n-  Samsung S7 tab (SM-T875, Android12, Snapdragon 865), Samsung S21 (SM-G9910, Snapdragon 888, Android 12), Vivotek FT9392-EHTV-0 (Smart Camera, Qualcomm SOC, Custom Android OS API 27 - Azena OS)\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.6\r\n- Installed using bazel build\r\n- Bazel version: bazel-3.7.2\r\n- Compiler version: clang(ndk;18.1.5063045)\r\n- CUDA/cuDNN version: not used\r\n- GPU model and memory:  not used\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nTF build with this command:\r\n```\r\n    bazel --output_base=. build -c opt --config=android_arm64 //tensorflow/lite:libtensorflowlite.so && \\\r\n    bazel --output_base=. build -c opt --config=android_arm64 tensorflow/lite/delegates/hexagon:hexagon_delegate && \\\r\n    bazel --output_base=. build -c opt --config=android_arm64  tensorflow/lite/delegates/hexagon/hexagon_nn:libhexagon_interface.so\r\n```\r\nLinkage: \r\nCMake:\r\n```\r\ntarget_link_libraries(TFLite INTERFACE \"/opt/tflite/lib/libtensorflowlite.so\" \"/opt/tflite/lib/libhexagon_delegate.so\" \"/opt/tflite/lib/libhexagon_interface.so\" log)\r\n```\r\nCppCode (based on https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/evaluation/utils.cc#L132):\r\n```\r\ntflite::Interpreter::TfLiteDelegatePtr CreateHexagonDelegate(\r\n const TfLiteHexagonDelegateOptions* options,\r\n const std::string& library_directory_path) {\r\n\tif (library_directory_path.empty()) {\r\n\t\tTfLiteHexagonInit();\r\n\t} else {\r\n\t\tTfLiteHexagonInitWithPath(library_directory_path.c_str());\r\n\t}\r\n\r\n\tTfLiteDelegate* delegate = TfLiteHexagonDelegateCreate(options);\r\n\tif (!delegate) {\r\n\t\tTfLiteHexagonTearDown();\r\n\t\treturn CreateNullDelegate();\r\n\t}\r\n\treturn tflite::Interpreter::TfLiteDelegatePtr(delegate, [](TfLiteDelegate* delegate) {\r\n\t\tTfLiteHexagonDelegateDelete(delegate);\r\n\t\tTfLiteHexagonTearDown();\r\n\t});\r\n}\r\n\r\ntflite::Interpreter::TfLiteDelegatePtr CreateDelegate() {\r\n        // path from tablet\r\n\tstd::string library_directory_path = \"/system/vendor/lib/rfsa/adsp\";\r\n\tTfLiteHexagonDelegateOptions options = {0};\r\n\tbool profiling = true;\r\n\toptions.print_graph_profile = profiling;\r\n\treturn CreateHexagonDelegate(&options, library_directory_path);\r\n}\r\n```\r\n\r\nAar contains: libhexagon_interface.so; libhexagon_delegate.so; libtensorflowlite.so; libhexagon_nn_skel(_v66/_v65/).so\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nFailed to load library\r\n    java.lang.UnsatisfiedLinkError: dlopen failed: library \"libadsprpc.so\" not found: needed by /data/app/~~61iiTanIn8XaBlzk1Msb3g==/com.brainbuilder-fKAm_DWPORj_MBhTzkwZqQ==/base.apk!/lib/arm64-v8a/libhexagon_interface.so in namespace classloader-namespace\r\n```", "comments": ["I am wondering if this is related to open sourcing the hexagon interface code, where some refactoring caused an issue here.\r\n\r\nFew suggestions / questions:\r\n\r\n1) Do you get the same issue when you run evaluation tool, benchmark tool using adb ?\r\n2) Do you face same issue when running on older versions ?\r\n3) Do you face same issue when using the precompiled aar ?\r\n\r\nThanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55269\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55269\">No</a>\n"]}, {"number": 55266, "title": "Exact Same outputs with 2 different datasets", "body": "I was trying to reimplement the paper https://arxiv.org/pdf/1901.11196.pdf and created 2 models which have same structure one takes in the augmented data and one doesn't to see which one performs better but for some weird reason both of them have exact same loss and other metrics and it doesn't even change after every epoch\r\nThis is the link for my implementation - https://colab.research.google.com/drive/192mGhABi1n51cg8SFLvuUCwvsYIMNvx1?usp=sharing\r\nThe model training is at the very end\r\nI tried to check and the inputs, encoders etc. are all different to both models but still this issue persists. Any ideas what could be going wrong?", "comments": []}, {"number": 55265, "title": "[ROCm] Correcting the output size for the RFFT call in `//tensorflow/compiler/xla/service/gpu/tests:mlir_fft_test`", "body": "The `//tensorflow/compiler/xla/service/gpu/tests:mlir_fft_test` was added via this commit https://github.com/tensorflow/tensorflow/commit/58740928fff82a6193a6cc89f09b732e061764c7\r\n\r\nThe test\r\n* calls RFFT transform on an input buffer of type `4 x f32` with values `[1,0,1,0]`\r\n* expects the resulting output buffer to be of type `4 x complex<f32>` ... this is incorrect\r\n\r\nThe correct size for the output buffer should be `3 x complex<f32>`.  This can be verfied via numpy doc and example\r\n\r\nFrom https://numpy.org/doc/stable/reference/generated/numpy.fft.rfft.html\r\n\r\n```\r\n...\r\nReturns\r\n\r\n    out : complex ndarray\r\n\r\n        The truncated or zero-padded input, transformed along the axis indicated by axis,\r\n\tor the last one if axis is not specified.\r\n\r\n\tIf n is even, the length of the transformed axis is (n/2)+1.\r\n\tIf n is odd, the length is (n+1)/2.\r\n...\r\n```\r\n\r\nIn the testcase n is 4, and hence output size should be 4/2 + 1 = 3\r\n\r\nnp version on testcase\r\n\r\n```\r\n# python3 -c \"import numpy as np; print (np.fft.rfft([1,0,1,0]))\"\r\n[2.+0.j 0.+0.j 2.+0.j]\r\n```\r\n\r\nThe incorrect output size was causing this test to fail on ROCm (elems 7 & 8 had junk data and hence mismatching)\r\n\r\nThis commit updates to testcase to have the correct return size, and now the test passes on the ROCm platform\r\n\r\n-----------------------\r\n\r\n\r\n/cc @cheshire @chsigg ", "comments": ["@gbaned I have rebased the PR to resolve the merge conflict, please re-approve and re-merge...thanks"]}, {"number": 55263, "title": "`tf.compat.v1.signal.rfft2d` and `rfft3d` lacks input validation leading to crashes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version:3.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2 (based on a colab notebook)\r\n- GPU model and memory: Tesla T4, 15109MiB (based on a colab notebook)\r\n\r\n**Describe the current behavior**\r\n\r\nThe following code snippets lead to crashes when executed:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = np.empty([6, 0])\r\nb = np.array([1, -1])\r\ntry:\r\n  tf.compat.v1.signal.rfft2d(input_tensor=a,fft_length=b)\r\n  # on a different machine: Check failed: size >= 0 (-9223372036854775808 vs. 0)\r\n  # Aborted (core dumped)\r\nexcept:\r\n  pass\r\n\r\nprint('execution does not reach this line')\r\n```\r\n\r\nand\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = np.empty([6, 1, 1])\r\nb = np.array([1, 2, 0])\r\n\r\ntry:\r\n  tf.compat.v1.signal.irfft3d(input_tensor=a,fft_length=b)\r\n  # on a different machine: failed to initialize batched cufft plan with customized allocator: Failed to make cuFFT batched plan.\r\n  # Aborted (core dumped)\r\nexcept:\r\n  pass\r\nprint('execution does not reach this line')\r\n```\r\n\r\nIn either case, the inputs do not quite make sense, and tensorflow should throw.\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorflow should throw exceptions instead of crashing.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere is a colab notebook:\r\nhttps://colab.research.google.com/drive/168jYG6MqnW4jpJdIXFMUBkyiaweA43aP?usp=sharing\r\nEdit: the notebook has to be run with GPU \r\n\r\nThe code snippets above should also reproduce the issue.\r\n\r\n", "comments": ["Added PR #55274 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55263\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55263\">No</a>\n"]}, {"number": 55262, "title": "tf.gradient returns None ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.3.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.6.1-9-gc2363d6d025 2.6.2\r\n- Python version: Python 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIn training an LSTM model I would like to compute the gradients of the cell state at step t on the initial cell state: dc_t/dc_0. However calling ```tf.gradients(ct, c0)``` returns None type output.\r\n\r\n**Describe the expected behavior**\r\nMy c_t c_0 are both of shape (100, 200). I am expecting the gradient to be a real-valued Tensor of the same shape. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n### 1. Define model\r\nbatch_size = 100\r\ninput_length_m= 1403\r\noutput_dim= 100\r\n\r\nxtr_pad = tf.random.uniform((batch_size, input_length_m), maxval = 500, dtype=tf.int32)\r\nytr = tf.random.normal((batch_size, input_length_m, 200))\r\ninp= Input(batch_shape= (batch_size, input_length_m), name= 'input') \r\nemb_out= Embedding(500, output_dim, input_length= input_length_m, trainable= False, name= 'embedding')(inp)\r\n\r\nclass LSTMCellwithStates(LSTMCell):\r\n    def call(self, inputs, states, training=None):\r\n        real_inputs = inputs[:,:self.units] # decouple [h, c]\r\n        outputs, [h,c] = super().call(real_inputs, states, training=training)\r\n        return tf.concat([h, c], axis=1), [h,c]\r\n    \r\nrnn = RNN(LSTMCellwithStates(200), return_sequences= True, return_state= False, name= 'LSTM') \r\nh0 = tf.Variable(tf.random.uniform((batch_size, 200)))\r\nc0 = tf.Variable(tf.random.uniform((batch_size, 200)))\r\nrnn_allstates= rnn(emb_out, initial_state=[h0, c0])  \r\nmodel_lstm_mod = Model(inputs=inp, outputs= rnn_allstates, name= 'model_LSTMCell')\r\nmodel_lstm_mod.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n\r\n### 2. Compute gradients:\r\nds = tf.data.Dataset.from_tensor_slices((xtr_pad, ytr)).batch(100)\r\n\r\n@tf.function\r\ndef compute_dct_dc0(ct, c0):\r\n    return tf.gradients(ct, c0)\r\n\r\nn_b = int(xtr_pad.shape[0]/ 100)\r\nn_steps = 20   # look up only the first and last 20 steps\r\n\r\ndctdc0_all= tf.zeros([n_b, n_steps])\r\nfor b, (x_batch_train, y_batch_train) in enumerate(ds):  \r\n    grad_batch= []   \r\n    cell_states= model_lstm_mod(x_batch_train)[:, :, 200:]\r\n    for t in range(n_steps):  \r\n        ct= cell_states[:, t, :]\r\n        print(ct)\r\n        # steps 0,...,19\r\n        dctdc0_b_t = compute_dct_dc0(ct, c0)  # (batch_size, n_units)\r\n        print(dctdc0_b_t)\r\n        grad_t = tf.reduce_mean(abs(dctdc0_b_t[0]), [0,1]) # Scalar dctdc0 at the current batch and step\r\n        print('step', t+1, 'of batch' ,b+1, 'done')\r\n        grad_batch.append(grad_t)\r\n    \r\n    dctdc0_all= tf.concat([dctdc0_all, [grad_batch]], axis = 0)   \r\n```\r\nThe error occurs specifically here:\r\n```\r\n### 3. \r\n@tf.function\r\ndef compute_dct_dc0(ct, c0):\r\n    print(ct)\r\n    print(c0)\r\n    return tf.gradients(ct, c0)\r\ncompute_dct_dc0(ct, c0)\r\n\r\n>> Tensor(\"ct:0\", shape=(100, 200), dtype=float32)\r\n<tf.Variable 'Variable:0' shape=(100, 200) dtype=float32>\r\n[None]\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nSurprisingly when the function is defined in a slightly different manner the gradients are computed without issue:\r\n```\r\n@tf.function\r\n# Compute gradients\r\ndef compute_dct_dc0(t, x, c0):\r\n    return tf.gradients(model_lstm_mod(x)[:,t,:], c0)\r\n\r\nn_b = int(xtr_pad.shape[0]/ 100) \r\nn_steps = 20   # look up only the first and last 20 steps\r\n\r\ndctdc0_all= tf.zeros([n_b, n_steps])\r\nfor b, (x_batch_train, y_batch_train) in enumerate(ds):  # batches 0,1\r\n    grad_batch= []   # a list of 1403 scalar gradients on the current batch\r\n    for t in range(n_steps):  \r\n        # steps 0,...,19\r\n        dctdc0_b_t = compute_dct_dc0(t, x_batch_train, c0)  # (batch_size, n_units)\r\n        grad_t = tf.reduce_mean(abs(dctdc0_b_t[0]), [0,1]) # Scalar dctdc0 at the current batch and step\r\n        print('step', t+1, 'of batch' ,b+1, 'done')\r\n        grad_batch.append(grad_t)\r\n    \r\n    dctdc0_all= tf.concat([dctdc0_all, [grad_batch]], axis = 0)   \r\n\r\n## Outputs:\r\n>> step 1 of batch 1 done\r\nstep 2 of batch 1 done\r\nstep 3 of batch 1 done\r\n```\r\nHowever this way is a lot more expensive because it will be fitted the entire batch for each step t. \r\n```cell_states= model_lstm_mod(x_batch_train)[:, :, 200:]``` fits the batch only once and extracts c_t for each t to compute gradients. \r\n", "comments": ["Another related question is that, is ```tf.gradients(ht h0)``` watching h0 over the computations? \r\nGradient Tape is capable of watching the input but only the input. Using Gradient Tape while specifying ```tape.watch(h0)``` also returns None in gradients ", "@DagonArises ,\r\nI was facing different error while executing the give code.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/0cbffeb86c0f88560a633e847430044c/untitled250.ipynb) and share required dependencies or share the colab gist.Thanks!", "@tilakrayal Sorry I forgot to specify the imports. Here is the [notebook](https://colab.research.google.com/drive/1CQyLVcz3VX6eEi1d5UqwU68HevkmHKg6#scrollTo=z8tmyVsRCwhb) \r\n\r\nPlease note that ```tf.gradients``` is an expensive computation. Is it possible to carry out my computations in Gradient Tape? \r\nI had this None gradient issue before when I tried to watch c0.", "@DagonArises ,\r\nI do not have access to the link you have provided. Could you please provide the required permissions to view the files.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55261, "title": "How can I use tf.data.experimental.make_csv_dataset to make a dataset with no batches", "body": "Currently I'm doing this - \r\n\r\n```\r\ncolumn_names = ['Label','Sentence']\r\nbatchsize = 32\r\nlabel = column_names[0]\r\ntrain_dataset = tf.data.experimental.make_csv_dataset(\r\n    'datasettrain.csv',\r\n    batchsize,\r\n    column_names = column_names,\r\n    label_name = label,\r\n    num_epochs=1\r\n)\r\n```\r\n\r\nDue to this the batches being ordered dicts don't allow me to do certain things which a dataset directly loaded from tfds.load would allow. For instance in this tutorial - https://www.tensorflow.org/text/tutorials/text_classification_rnn\r\n\r\nThe author is able to run - \r\n\r\n```\r\nfor example, label in train_dataset.take(1):\r\n  print('text: ', example.numpy())\r\n  print('label: ', label.numpy())\r\n```\r\n\r\nand I wish to do the same however in my case the type for example comes out to be `<class 'collections.OrderedDict'>` while in the tutorials it is `<class 'tensorflow.python.framework.ops.EagerTensor'>`.\r\n\r\nIs there some way I can do the same with `tf.data.experimental.make_csv_dataset`?\r\n\r\nUsing -\r\n\r\n```\r\nls = []\r\nfor example, label in train_dataset:\r\n  ls.append([example['Sentence'][0],label[0]])\r\n```\r\n\r\nI was able to get the required form internally however the entire array is no longer a `<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>` is there any way to do that from this `ls`?", "comments": ["Hi @aflah02 ! Can you please share the code with above error stack trace a Colab gist?  Did you try connecting those two mentioned methods?Thanks!", "Hey\nThe code which is causing the error is the \none mentioned in the issue already\nWhich 2 methods are you referring to?", "Incase some one faces a similar issue I eventually got a workaround by making 2 numpy arrays converting them into tensors and then feeding that into tf.data.Dataset.from_tensors but I guess there would be a better way than this the problem seems to be that Tensorflow does not recognize a np array of EagerTensors as a valid argument for making a dataset", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55261\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55261\">No</a>\n", "Ok @aflah02 ! Glad it resolved. Could you please share the resolved code for the community ?", "Sure @mohantym Thanks for pointing it out\r\n\r\nFor perspective my dataset is of the following form - \r\n\r\n- A CSV\r\n- 2 Columns\r\n- First Column Which I Need to Predict Named Label\r\n- Second Column Which I Use to Predict the Label which is a Sentence\r\n\r\nSo I first loaded it in using - \r\n\r\n```\r\ncolumn_names = ['Label','Sentence']\r\nbatchsize = 1\r\nlabel = column_names[0]\r\ntrain_dataset = tf.data.experimental.make_csv_dataset(\r\n    'datasettrain.csv',\r\n    batchsize,\r\n    column_names = column_names,\r\n    label_name = label,\r\n    num_epochs=1\r\n)\r\n```\r\n\r\nThis returns a `tensorflow.python.data.ops.dataset_ops.PrefetchDataset`\r\n\r\nAfter that I used the following code to do the work mentioned in [Comment](https://github.com/tensorflow/tensorflow/issues/55261#issuecomment-1070543375) above\r\n\r\n```\r\nls_train = []\r\nfor example, label in train_dataset:\r\n  ls_train.append([example['Sentence'][0],label[0]])\r\n\r\nnparrtrainsentences = np.array([])\r\nnparrtrainlabels = np.array([])\r\nfor i in range(len(ls_train)):\r\n  nparrtrainsentences = np.append(nparrtrainsentences, [ls_train[i][0].numpy()])\r\n  nparrtrainlabels = np.append(nparrtrainlabels, [ls_train[i][1].numpy()])\r\n\r\ntrain_sentences = tf.convert_to_tensor(nparrtrainsentences)\r\ntrain_labels = tf.convert_to_tensor(nparrtrainlabels)\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensors((train_sentences,train_labels))\r\n```\r\n\r\nIn hindsight certain aspects do feel redundant now but since it works for now I won't be trying to fix those things"]}, {"number": 55259, "title": "Facing Issues with tf.io.TFRecordWriter while trying to write string", "body": "I'm trying to write a dataset to a tfrecords file however the string portion keeps raising an error\r\n```\r\ninfile='dataset.csv'\r\noutfile='data.tfrecords'\r\n\r\ncsv = pd.read_csv(infile, header=None).values\r\n\r\nitr = 1\r\nwith tf.io.TFRecordWriter(outfile) as file_writer:\r\n    for row in csv:\r\n        if (itr==1):\r\n          itr+=1\r\n          continue\r\n        record_bytes = tf.train.Example(features=tf.train.Features(feature={\r\n          \"sentence\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[row[3]])),\r\n          \"split\": tf.train.Feature(float_list=tf.train.FloatList(value=[row[2]])),\r\n          \"Label\": tf.train.Feature(float_list=tf.train.FloatList(value=[row[1]])),\r\n        })).SerializeToString()\r\n        file_writer.write(record_bytes)\r\n```\r\n\r\nError - \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n[<ipython-input-91-a13b07fac787>](https://localhost:8080/#) in <module>()\r\n     11           continue\r\n     12         record_bytes = tf.train.Example(features=tf.train.Features(feature={\r\n---> 13           \"sentence\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[row[3]])),\r\n     14           \"split\": tf.train.Feature(float_list=tf.train.FloatList(value=[row[2]])),\r\n     15           \"Label\": tf.train.Feature(float_list=tf.train.FloatList(value=[row[1]])),\r\n\r\nTypeError: 'a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror f has type str, but expected one of: bytes\r\n```\r\n\r\nI looked at several doc pages but it seems BytesList is the wat to go with string but for some reason it isn't working here.\r\nAm I missing something?", "comments": ["@aflah02 ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code and the TensorFlow version you are using.\r\n", "I was using the default version which comes with colab currently not sure which one it is and this is the part which was causing the issue\n\nI've now removed it and used a workaround but I'm still interested to see what was going wrong\n\nI also tried reordering and saw all 3 have issues be it float or bytes", "@aflah02 ,\r\nWithout the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, could you please provide complete code and the TensorFlow version you are using.", "Hey \nI no longer have that code and i used a different process from scratch. I guess it's best to close the issue as your point is correct but I don't have the code as i overwrote it"]}, {"number": 55258, "title": "Update Compute Library to version 22.02", "body": "This PR updates the Compute Library verion from 21.11 to 22.02 and updates the build to supports Arm-v8 in addition to Arm-v8.2a and above.", "comments": ["Hi @penpornk,\r\n\r\nCompute Library 22.02 was released recently, this patch updates the Bazel build to pick up the new version.\r\nI intend to update the oneDNN version as soon as the next release, or RC, is available.", "@nSircombe ,\r\nCan you please sign CLA. Thanks!", "Hi @tilakrayal,\r\nI should be covered under the Arm's CLA, and it looks like the cla/google test on this PR has passed now. Is there anything I still need to do?"]}, {"number": 55257, "title": "C-API Binaries for 32-bit for x86 instruction set", "body": "**System information**\r\n- TensorFlow version (you are using): 2.7.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nTensorflow provides Windows binaries for the C-API for 64-bit processprs for instruction set x86 (= x64), see:\r\nhttps://www.tensorflow.org/install/lang_c#supported_platforms\r\n\r\nIt would be great to support this for 32-bit also.\r\n\r\n**Who will benefit with this feature?**\r\nProjects requiring to build in 32-bit and 64-bit OS.\r\n", "comments": ["@CometManAtGitHub,\r\n\r\nWe no longer build 32bit TF. The code assumes 64 bits in several places, so building from source might still lead into errors. It is recommended to use 64-bit architecture to build Tensorflow. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54687)\r\n[No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54687)"]}, {"number": 55256, "title": "[INTEL oneDNN] Resubmitting scratch pad optimization for matmul primitive : PR number :54381", "body": "This PR has changes from PR [54381 ](https://github.com/tensorflow/tensorflow/pull/54381)(reverted back) + fix for Windows build failure.\r\nChanges to add user scratch pad for matmul primitive to fix OOM issue in Transformer LT.\r\n\r\nThis reduces memory footprint of the primitive. It fixes an out of memory issue when running Transformer LT with multiple instances and total thread count is large. Managing scratch pad for the primitive from the framework, fixes the out of memory issue, reduces memory footprint and does not affect performance. The changes :\r\nCreates a new struct that hold the Tensor for scratch pad arg.\r\nAllocates memory based on scratch pad size queried from primitive description.\r\nSets user scratch pad in post ops for the primitive.", "comments": ["@penpornk . There are 3 code style failures(Code Check). The first failure is often seen with clang-format style fix. It switches the location of the header from first to last or vice versa. The changes in second the third failures are copied from clang-format style=Google file. Please advice what to do for these failures. Wondering if I am using a different version than the one run by Internal CI.\r\nThanks\r\n", "@jojivk73 Don't worry about that. We have already imported the PR. I'm just running Windows tests at a different snapshot to make sure there is no more failures. (The code at HEAD already failed the Windows tests because some unrelated LLVM errors so we can't tell.)"]}, {"number": 55255, "title": "Remove calls to `rules_cc_toolchains`", "body": "There was a previous plan was to move Bazel toolchain configuration to\r\n`@rules_cc`, but that plan isn't progressing and `@rules_cc` is\r\ncurrently just an outdated copy of the toolchain configuration\r\nmechanism. Amongst other issues, the outdated copy does not support\r\n`layering_check`. The Bazel team recommended removing this override.\r\nSee https://github.com/bazelbuild/bazel/issues/15004", "comments": ["@izuk maybe you could take a look or direct to the right person?"]}, {"number": 55254, "title": "Updates Error log in  `subprocess.cc`", "body": "Updated Error log as per Author's suggestion in  #48089", "comments": ["Please use a better title, not \"fix issue <number>\"", "See https://cbea.ms/git-commit/"]}, {"number": 55253, "title": "Allow some tolerance in equality test by using EXPECT_FLOAT_EQ", "body": "Float values on AARCH64 fail the plain EXPECT_EQ check with a difference of 1.42109e-14 which is negligible so use the more tolerant EXPECT_FLOAT_EQ form instead.", "comments": ["Fixes https://github.com/tensorflow/tensorflow/issues/55251", "Tagging @penpornk \r\n"]}, {"number": 55251, "title": "Test //tensorflow/core/framework:model_test fails on AARCH64", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): git HEAD\r\n- Python version: 3.8.12\r\n- Bazel version (if compiling from source): 5.0.0\r\n- GCC/Compiler version (if compiling from source): 10.2.1\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nTest fails with\r\n\r\n[ RUN      ] Test/AsyncUnknownRatioTest.Model/0\r\ntensorflow/core/framework/model_test.cc:462: Failure\r\nExpected equality of these values:\r\n  async_unknown_many->TotalProcessingTime( nullptr)\r\n    Which is: 109.333\r\n  ratio * (50 + 50) + 128 / 3.0\r\n    Which is: 109.333\r\n[  FAILED  ] Test/AsyncUnknownRatioTest.Model/0, where GetParam() = (1, 0) (1 ms)\r\n\r\n**Describe the expected behavior**\r\n\r\nTest passes\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\nAdd some tolerance to test for equality. Debugging the test shows that there is a difference of 1.42109e-14 in the two values on AARCH64.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 --build_tests_only -- //tensorflow/core/framework:model_test\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nIntroduced with https://github.com/tensorflow/tensorflow/commit/8d46773e6aa6b2eb44b62e422b3c7ccc4adb79b6\r\n", "comments": ["@cfRod @nSircombe ", "@elfringham Could you please let us know if we can close this issue as the PR is merged?\r\nThanks!", "Yes, all good, can close.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55251\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55251\">No</a>\n"]}, {"number": 55250, "title": "multi worker training in tensorflow gives error - \"terminate called without an active exception aborted\"", "body": "I am running a tensorflow distributed training model on multiple workers using vertex AI/local and multiworkermirroredstrategy\r\n\r\nAfter completion of all epochs it gives the error of \"terminate called without an active exception aborted\"\r\n\r\npython=3.8\r\ntensorflow=2.7\r\n\r\nCan anyone explain why is this happening.", "comments": ["@ranvirdesai ,\r\nCan you please take a look at this [SO link](https://stackoverflow.com/questions/7381757/c-terminate-called-without-an-active-exception) and [issue](https://github.com/tensorflow/tensorflow/issues/51768) with the similar error.It helps.Thanks!", "@tilakrayal \r\nI face issue at the end of training, after completion of epochs and I am not using tensorboard profiling.\r\n\r\nMirroredstrategy and TPUStrategy works fine.\r\n\r\nJust the Multiworkermirroredstrategy fails giving error - \"terminate called without an active exception aborted\"", "@ranvirdesai ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n \r\n", "@tilakrayal \r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nprint(\"tf version\", tf.__version__)\r\n\r\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ndef normalize_img(image, label):\r\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n  return tf.cast(image, tf.float32) / 255., label\r\n\r\nds_train = ds_train.map(\r\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(128)\r\nds_train = ds_train.prefetch(tf.data.AUTOTUNE)\r\n\r\n\r\nds_test = ds_test.map(\r\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\r\nds_test = ds_test.batch(128)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.AUTOTUNE)\r\n\r\ndef build_cnn_model():\r\n    return tf.keras.Sequential([\r\n      tf.keras.Input(shape=(28, 28)),\r\n      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dense(10)\r\n    ])\r\n\r\nwith strategy.scope():\r\n    model = build_cnn_model()\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(0.001),\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\r\n    )\r\n\r\nmodel.fit(\r\n    ds_train,\r\n    epochs=2,\r\n    validation_data=ds_test,\r\n)\r\n```\r\n\r\nIt is simple mnist model which gives error.\r\nAlso model training on multtiple CPU machines works fine but when we attach GPUs to it gives the error - \r\n\r\n**terminate called without an active exception aborted**\r\n\r\nThanks", "@ranvirdesai ,\r\nCan you please confirm whether this issue is duplicate of #55178?.Thanks!", "The model isn't duplicated or rescripted in any form but could be a test modification plugin. Are you having any complications with running it?", "Are you trying to mass script or group the code plugin for a infinite loop or machine learning module?", "I was using a small dataset and it was giving problems, but when I used bigger dataset it worked.\r\nAlso changed python 3.8 to 3.7", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55250\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55250\">No</a>\n", "so the component you were first  using wasn't administering enough data to your device at first until you rendered and migrated to a more sufficient unit ?"]}, {"number": 55248, "title": "[conv3d_transpose] Fix dim check for bias", "body": "Per discussion with @thaink in https://github.com/tensorflow/tensorflow/commit/38a77f4bc1c897c75560a0beb53426f20b883f6e#r68775543 , the previous way to do the dim check for bias is not correct. So, we need this change.", "comments": ["I think you need to change MismatchBiasSizeTest in the test as well.", "@thaink Done.", "@thaink Is there any difficulty in landing this PR?", "I am not sure why the recent update was not reflected in our internal PR. Let me try again."]}, {"number": 55247, "title": "[TF-TRT] Einsum debug message moved to VLOG(2)", "body": "@bixia1 \r\n\r\nCleanup logging", "comments": []}, {"number": 55245, "title": "Refactoring of the Converter for Binary Operations", "body": "Refactor converters and tests for binary operations to prepare for the implementation of the converter for `LogicalOr` and `LogicalAnd` operations.", "comments": ["@drivanov  I edited the PR description, would you please check?", "> @drivanov I edited the PR description, would you please check?\r\n\r\nTo make it simpler, my intention was to was to submit two separate  PRs: \r\n- first: for refactoring of converter for Binary operations\r\n- second: for `LogicalAnd` and `LogicalOr`\r\n\r\nI will remove the code related `LogicalAnd` and `LogicalOr` from `ops/binary_ops.cc` and I will change PR description."]}, {"number": 55244, "title": "Updating config.py fixes #55218", "body": "Updating config.py fixes #55218", "comments": ["@mihaimaruseac  , The CICD build failed, on this patch seems to be from some other issue. Because this patch is just to fix the code alignment and spacing. Nothing functionally different.    ", "Please use a better PR title. See https://cbea.ms/git-commit/", "@Gelesh Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "another pull request submitted", "You could have just edited the title :)"]}, {"number": 55242, "title": "Regression: TFLiteConverter changes output order again since 2.7", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n  No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n   Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n   N/A\r\n- TensorFlow installed from (source or binary):\r\n   Binary\r\n- TensorFlow version (use command below):\r\n   2.7.1\r\n- Python version:\r\n   3.8.10\r\n- Bazel version (if compiling from source):\r\n   N/A\r\n- GCC/Compiler version (if compiling from source):\r\n   N/A\r\n- CUDA/cuDNN version:\r\n   11.2\r\n- GPU model and memory:\r\n   1080TI, 11G\r\n\r\n**Describe the current behavior**\r\n   tf.lite.TFLiteConverter.from_keras_model changes output order.\r\n\r\n**Describe the expected behavior**\r\n   Should keep the same order as the keras model.\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n  No\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nThis is a regression bug. Please find an example here: https://github.com/tensorflow/tensorflow/issues/33303\r\n", "comments": ["Hi @chunduriv ! Could you please look at this issue ? It is replicating in  [2.7 ](https://colab.sandbox.google.com/gist/mohantym/497e7ad863352c438687735dd0b4ea08/github_33303.ipynb#scrollTo=lV0UZ3IMXJie), [2.8 ](https://colab.sandbox.google.com/gist/mohantym/11f85642afdccf2e17053f71eb9dda41/github_33303.ipynb#scrollTo=9rUgGQnje2Dn)and [nightly](https://colab.sandbox.google.com/gist/mohantym/11f85642afdccf2e17053f71eb9dda41/github_33303.ipynb#scrollTo=9rUgGQnje2Dn) ( 2.9.0dev) .Thanks!", "Hi @chao-camect \r\n\r\nThe issue is that TFLite converter uses saved model underneath, saved model doesn't guarantee order/names of tensors when loading the model, and that causes the issue.\r\nActually if you searched github you will even find other issues on older TF releases.\r\n\r\nHow to fix it ?\r\nBecause of this ordering / naming issue, TFLite now supports signature concept so you don't need to care about the tensors order or the tensor name.\r\nInstead you deal with the defined signature on the model and the input / output names.\r\nThe mapping between the readable names and the actual tensors is done by TFLite and you don't need to care about them changing if the implementation underneath caused any order changes.\r\n\r\nAn example of using signatures\r\n\r\n```\r\n# Load the TFLite model in TFLite Interpreter\r\ninterpreter = tf.lite.Interpreter('/tmp/my_mode.tflite')\r\n\r\n# If the model has only  1 signature defined\r\n# then it will return it by default.\r\n# If there are multiple signatures then we can pass the name as an argument.\r\nmy_signature = interpreter.get_signature_runner()\r\n\r\n# my_signature is callable with input as arguments.\r\noutput = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\r\n# 'output' is dictionary with all outputs from the inference.\r\n# Assuming we named it in the original model as 'result' we can then pass it here.\r\nprint(output['result'])\r\n```\r\n\r\nSee more details [here](https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python) and API for other models.\r\nPlease let us know if you are having any issues.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55242\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55242\">No</a>\n"]}, {"number": 55241, "title": "`tf.keras.callbacks.BackupAndRestore` showing wrong number of steps after restoring the model!", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): colab\r\n- TensorFlow version (use command below): v2.8.0-0-g3f878cff5b6 2.8.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2 \r\n- GPU model and memory: Tesla V100-SXM2-16GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nBy using the BackupAndRestore, I can save and reload the model from the last saved checkpoint and the training will continue from the last epoch before the interruption. The problem I'm facing is that after the training of the epoch is complete, the number of steps for that epoch is wrong (it takes the number of steps of the epoch and multiplies it with the number of epochs completed). The time of the epoch is correct but because the number of steps is wrong, the time per step is also wrong (as It divides the time taken for this epoch and divides it with the wrong number of steps). This issue causes the next epochs to show wrong progress bar and wrong number of steps as well.\r\n\r\nYou can see an example here:\r\nMy model trains for 1481 steps per epoch and it usually takes 7 to 8 seconds per step therefore I expect the total time of the epoch to be around 1481 * 8 = 10000 to 12000 seconds. I get the following log for training the model after restoring the 16th epoch by using the last saved checkpoint.\r\n\r\nEpoch 16/40\r\n23696/23696 [==============================] - 11513s 484ms/step - loss: 32.1565 - lr: 0.0010\r\nEpoch 17/40\r\n   74/23696 [..............................] - ETA: 40:37:26 - loss: 31.8166\r\n\r\n\r\nAs you can see, the number of steps should be 1481 but it's instead 16*1481=23696 for 16th epoch. The time per step should be 11513 / 1481 which is around 7s but what it shows is 11513 / 23696 = 484ms.\r\n\r\nAlso, the next epoch has a wrong total number of steps and ETA as well because of the wrong number of steps of the previous epoch. it stays like this until I restore from another epoch which produces the same issue\r\n\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is to see the total time of the epoch (and not all the trained epochs) and to see the correct time per step\r\n\r\nFor example, I expect to see this in my case:\r\nEpoch 16/40\r\n1481/1481 [==============================] - 11513s 7s/step - loss: 32.1565 - lr: 0.0010\r\nEpoch 17/40\r\n   74/1481 [..............................] - ETA: 3:19:00 - loss: 31.8166\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nThis is the training method of my model.\r\n```\r\ndef train(self, loss_function:Callable, data_generator:Callable=None, learning_rate_scheduler:tf.keras.callbacks=None, learning_rate:float = 1e-3, epochs:int=40, batch_size:int=8, shuffle_data:bool=True, seed:int=0)->History:\r\n    '''This method will generate the train_dataset and trains and backup the model after each epoch.\r\n       it finally saves the model and removes the checkpoints\r\n    '''\r\n    def store_spectrograms():\r\n        music_names = os.listdir(self._train_dir_path)\r\n        music_names.remove(\"spectrograms\")\r\n        train_spectrograms_temp_dir_path = os.path.join(self._train_dir_path, \"spectrograms\")\r\n        for music_name in music_names:\r\n            #print(f\"storing spectrograms for {music_name}\")\r\n            music_dir_path = os.path.join(train_spectrograms_temp_dir_path, music_name)\r\n            \r\n            for file_name in [\"mixture.wav\", \"vocals.wav\", \"accompaniment.wav\"]:\r\n                destination_dir = os.path.join(music_dir_path, file_name[:-4])\r\n                if os.path.exists(destination_dir):\r\n                    # print(f\"{destination_dir} already exists\")\r\n                    continue\r\n                Config_Handler.make_dir(destination_dir)\r\n                wav_file_handler = Wav_File_Handler(wav_file_path = os.path.join(music_dir_path, file_name))\r\n                _, spectrograms = wav_file_handler.generate_segments_and_spectrograms(segment_length_in_seconds=self._segment_length_in_seconds, clip_stft_to_even_frequency_bins=self._clip_stft_to_even_frequency_bins)\r\n                for i, spectrogram in enumerate(spectrograms):\r\n                    spectrogram_id = f\"id_{i}\"\r\n                    destination_path = os.path.join(destination_dir, f\"{spectrogram_id}-spectrogram.npy\")\r\n                    np.save(destination_path, spectrogram)\r\n            #print(f\"storing spectrograms for {music_name} completed!\\n\")\r\n\r\n    store_spectrograms()\r\n\r\n    if os.path.exists(self._model_path):\r\n      train_more = str.lower(input(f\"Model is already trained, are you sure you want to train it for {epochs} more epochs? \\n (y for yes and n for no:)\"))\r\n      while train_more not in [\"y\", \"n\"]:\r\n        print(\"invalid answer!\")\r\n        train_more = input(f\"Model is already trained, are you sure you want to train it for {epochs} more epochs? \\n (y for yes and n for no:)\")\r\n      if train_more == \"n\":\r\n        print(\"cancelling training!\")\r\n        return\r\n      else:\r\n        print(f\"model will be trained for {epochs} more epochs\")\r\n\r\n    input_file_name = \"mixture.wav\"\r\n    output_vocal_file_name = \"vocals.wav\"\r\n    output_ac_file_name = \"accompaniment.wav\"\r\n    music_dict = dict()\r\n    \r\n    train_dataset = tf.data.Dataset.from_generator(lambda: self.generate_data(self._train_dir_path),\r\n                                             output_signature=(tf.TensorSpec(shape=(None, self._input_shape[0], self._input_shape[1], self._input_shape[2]), dtype=tf.float32),\r\n                                                               tf.TensorSpec(shape=(None, self._input_shape[0], self._input_shape[1], 2, self._input_shape[2]), dtype=tf.float32)))\r\n    # test_dataset = tf.data.Dataset.from_generator(lambda: self.generate_data(self._test_dir_path, shuffle_data=shuffle_data, seed=seed),\r\n    #                                          output_signature=(tf.TensorSpec(shape=(None, 1024, 256, 1), dtype=tf.float32),\r\n    #                                                            tf.TensorSpec(shape=(None, 1024, 256, 2, 1), dtype=tf.float32)))\r\n    optimizer = AdamW(weight_decay=1e-6, learning_rate=1e-3)\r\n\r\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(\r\n    log_dir=self._tensorboard_logs_dir, histogram_freq=0, write_graph=True,\r\n    write_images=False, write_steps_per_second=False, update_freq='epoch',\r\n    profile_batch=0, embeddings_freq=0, embeddings_metadata=None,)\r\n    #tf.debugging.experimental.enable_dump_debug_info(self._tensorboard_logs_dir, tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\r\n    #tf.debugging.experimental.disable_dump_debug_info()\r\n\r\n    backup_and_restore_callback = tf.keras.callbacks.BackupAndRestore( \r\n    backup_dir=self._checkpoint_path)\r\n    callbacks = [tensorboard_callback, backup_and_restore_callback] + [tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)] if learning_rate_scheduler != None else []\r\n    self._model.compile(loss=loss_function, optimizer=optimizer)\r\n    print(\"starting training!\")\r\n    history = self._model.fit(train_dataset, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1)\r\n\r\n    self.save_model()\r\n    self._finalise_training()\r\n\r\n    return history\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@mohammadreza490 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "Will do thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55241\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55241\">No</a>\n"]}, {"number": 55240, "title": "Windows Build From Source, executing ./config responded 404 is a different issue.", "body": "Had applied a potential fix for #55218, however, I think this 404 is a different issue.\r\n_Originally posted by @Gelesh in https://github.com/tensorflow/tensorflow/issues/55218#issuecomment-1066932121_\r\n\r\nbelow is the console message, I think this 404 is a different issue.\r\n\r\nINFO: Found applicable config definition build:monolithic in file c:\\users\\gomath776\\christwork\\tensorflow_renamed\\.bazelrc: --define framework_shared_object=false\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/e83168170a0d0bdf856a109187936bc44853c1b8.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found\r\n\r\n_Originally posted by @Gelesh in https://github.com/tensorflow/tensorflow/issues/55218#issuecomment-1066932121_", "comments": ["@Gelesh ,\r\nLooks like this is duplicate of issue #55218.Can you please close this issue, since it is already being tracked there? Thanks!", "this is not duplicate of #55218, this issue is about  error 404, file not found. Where as 55218 is about , bazelisk is not attempted to build when bazel is not installed.  Some are even attempting to set the path of bazel == path of bazelisk as a work arround ", "@Gelesh ,\r\nLooks like error is coming from MSVC. Make sure you have installed\r\n1. [Visual C++ Build Tools 2019](https://www.tensorflow.org/install/source_windows#install_visual_c_build_tools_2019).\r\nThanks!", "This issue is from the URL , noting is being fetched from URL, even when we hit the url from browser. I am sorry, I dont understand how is it even related to Visual Studio C++. However, I do have that in my pc", "This 404 is just a warning which can be ignored. We have multiple mirrors from which build deps are downloaded, this just says that one of them does not have the sought for target.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55240\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55240\">No</a>\n"]}, {"number": 55239, "title": "Updating config.py for #55218", "body": "#55218 Updating config.py for #55218,\r\nAccommodating PyLint #1555", "comments": ["Please use a better PR title. See https://cbea.ms/git-commit/", "@Gelesh Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "another pull request submitted"]}]