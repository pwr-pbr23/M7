[{"number": 38231, "title": "Libs can not download from China when compile from source", "body": "```\r\nERROR: An error occurred during the fetch of repository 'org_sqlite':\r\n   java.io.IOException: Error downloading [http://mirror.tensorflow.org/www.sqlite.org/2019/sqlite-amalgamation-3280000.zip, https://www.sqlite.org/2019/sqlite-amalgamation-3280000.zip] to /home/jintian/.cache/bazel/_bazel_jintian/879bdee779be1c04fff5ab7e8f48b925/external/org_sqlite/sqlite-amalgamation-3280000.zip: All mirrors are down: [connect timed out]\r\n\r\n```\r\n\r\nthis url is blocked inside china,\r\n\r\nwhy using this download when compile? why not just make it --recursive when clone?", "comments": ["@jinfagang Could you please provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38231\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38231\">No</a>\n"]}, {"number": 38230, "title": "TensorFlow hangs: 0% GPU, 1 CPU core @ 100% in cuModuleUnload", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or\r\nbinary): Both. Bug first appeared in TF2 python package, then was reproduced using TF2 compiled from source.\r\n- TensorFlow version (use command below): Both 2.1 (from PyPI) and 2.0 (source) appear affected\r\n- Python version: 3.6.6 x64\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from\r\nsource): Visual Studio Professional 2017\r\n- CUDA/cuDNN version: 10.0 & 10.1\r\n- GPU model and memory: 1080 & 1080 TI\r\n\r\n**Describe the current behavior**\r\n\r\nAt a random time during training, TensorFlow just stops progressing. I've seen this happen both after 200 iterations = roughly 1 minute and after 3000 iterations. \r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow either continues training, or it crashes with an error message.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nThis happens in a rather large and complex project with partially proprietary source code. That said, I do have a full dump of Python & TensorFlow in that state, which is 30 GB. \r\n\r\n**Other info / logs** \r\n\r\nAttached is a dump of the stack traces of all threads, created with VS2017 `Debug.ListCallStack /ShowLineOffset /AllThreads `\r\n\r\n[tensorflow callstacks.txt](https://github.com/tensorflow/tensorflow/files/4432702/tensorflow.callstacks.txt)\r\n\r\n**My Analysis** \r\n\r\nThe Python main thread is stuck in tensorflow::KernelAndDeviceFunc::Run > nsync::nsync_cv_wait, which seems reasonable. The other threads are idle in openblas or Eigen::ThreadPoolTempl::WaitForWork, except for one suspicious thread.\r\n\r\nThe suspicious thread (ID 7020 in the attached dump) is looping around with 100% CPU usage inside cuModuleUnload, which was called by stream_executor::gpu::GpuDriver::UnloadModule from within stream_executor::KernelBase::~KernelBase inside tensorflow::CheckRedzones and apparently attempting to execute a tensorflow::Conv2DOp\r\n\r\n```\r\nCallstack for Thread 74 (Thread Id: 7020 (0x1b6c)):\r\n Index  Function\r\n--------------------------------------------------------------------------------\r\n 1      [External Code]  =  cuModuleUnload\r\n*2      _pywrap_tensorflow_internal.pyd!stream_executor::gpu::GpuDriver::UnloadModule(stream_executor::gpu::GpuContext * context, CUmod_st * module) Line 762\r\n 3      _pywrap_tensorflow_internal.pyd!stream_executor::gpu::GpuExecutor::UnloadGpuBinary(const void * gpu_binary) Line 339\r\n 4      _pywrap_tensorflow_internal.pyd!stream_executor::gpu::GpuExecutor::UnloadKernel(const stream_executor::KernelBase * kernel) Line 357\r\n 5      _pywrap_tensorflow_internal.pyd!stream_executor::KernelBase::~KernelBase() Line 79\r\n 6      _pywrap_tensorflow_internal.pyd!stream_executor::cuda::RedzoneAllocator::CheckRedzones() Line 340\r\n 7      _pywrap_tensorflow_internal.pyd!tensorflow::CheckRedzones(const stream_executor::cuda::RedzoneAllocator & rz_allocator, tensorflow::AutotuneResult * autotune_result) Line 618\r\n 8      _pywrap_tensorflow_internal.pyd!tensorflow::LaunchConv2DOp<Eigen::GpuDevice,float>::operator()(tensorflow::OpKernelContext * ctx, bool use_cudnn, bool cudnn_use_autotune, const tensorflow::Tensor & input_param, const tensorflow::Tensor & filter, int row_dilation, int col_dilation, int row_stride, int col_stride, const tensorflow::Padding & padding, const std::vector<__int64,std::allocator<__int64> > & explicit_paddings, tensorflow::Tensor * output, tensorflow::TensorFormat data_format) Line 1062\r\n 9      _pywrap_tensorflow_internal.pyd!tensorflow::Conv2DOp<Eigen::GpuDevice,float>::Compute(tensorflow::OpKernelContext * context) Line 546\r\n 10     _pywrap_tensorflow_internal.pyd!tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel * op_kernel, tensorflow::OpKernelContext * context) Line 582\r\n 11     _pywrap_tensorflow_internal.pyd!tensorflow::`anonymous namespace'::ExecutorState::Process(tensorflow::`anonymous-namespace'::ExecutorState::TaggedNode tagged_node, __int64 scheduled_nsec) Line 1844\r\n 12     [External Code]\r\n 13     _pywrap_tensorflow_internal.pyd!Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int thread_id) Line 326\r\n 14     [External Code]\r\n```\r\n\r\n\r\nSo there is a reasonable chance that this is a CUDA 10.1 bug, because both the PyPI TF 2.1 and my self-compiled TF 2.0 use CUDA 10.1 to avoid triggering https://github.com/tensorflow/tensorflow/issues/31166\r\n\r\nThis might be related to https://github.com/tensorflow/tensorflow/issues/37450 where others also report a CPU-spike upon training freezing with TF2.0 and TF2.1. That would imply the bug to be present in CUDA 10.0 and 10.1.\r\n\r\n", "comments": ["@fxtentacle,\r\nIn order to expedite the trouble-shooting process, is it possible to provide a minimal code sample to reproduce the issue reported here. Thanks!", "Maybe related https://github.com/tensorflow/tensorflow/issues/36072", "> @fxtentacle,\r\n> In order to expedite the trouble-shooting process, is it possible to provide a minimal code sample to reproduce the issue reported here. Thanks!\r\n\r\nAny updates regarding this issue? Thanks!\r\n", "http://colab.research.google.com/gist/fxtentacle/0c19dc1ce013f4f98ff57b1261d4b644/tf_hang.ipynb\r\n\r\nExpected result: It prints \"................................done\".\r\n\r\nActual result: It freezes. Repeatedly clicking the Stop button produces \"The executing code is not responding to interrupts.\"\r\n\r\nFYI, the tf.py_function is necessary because tf.image.extract_patches cannot handle Tensor inputs for sizes. See `gen_array_ops.py:2350 extract_image_patches`. \r\n\r\n", "Actually, I believe I might be seeing two different bugs being triggered randomly, because while this example surely freezes the runtime, my stack trace caught it freezing inside a Conv2D Op, while the Python example here does not include any Conv2D ops.", "The above example freezes on:\r\n- TF 2.0 recompiled with CUDA 10.1 on my machine\r\n- '2.1.0' PyPI package on my machine\r\n- '2.2.0-rc2' on Colab\r\n- '2.2.0-dev20200415' on Colab", "Was able to reproduce the issue with TF v2.2.0rc3 and TF-nightly. Code runs indefinitely and freezes on interrupting. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/261286c6844c713a4ab93f32b706bc22/38230.ipynb). Thanks!", "@amahendrakar I was not able to reproduce this on tf-nightly.  Are you still able to reproduce this?", "> @amahendrakar I was not able to reproduce this on tf-nightly. Are you still able to reproduce this?\r\n\r\n@sanjoy,\r\nYes, I am able to reproduce the issue with the stable version of TF v2.2 and TF-nightly. \r\nCode runs forever and never reaches the print statement. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/225d6850361258566ff3cb325325e839/38230.ipynb). Thanks!", "George, can you PTAL?  It looks like something is weird about how the red zone allocator loads and unloads CUDA modules.", "I'll take a look a bit later, but it uses exactly the same codepath XLA does.\r\nFor now, does setting the environment variable `TF_DISABLE_RZ_CHECK` to 1 help?", "Hi @fxtentacle! \r\nHi ! we are  checking to see if you are still looking for assistance in this issue.\r\nCould you please try on latest stable version TF 2.6  and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38230\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38230\">No</a>\n"]}, {"number": 38229, "title": "No examples showing how to generate Arduino files from source for Arduino IDE", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nNo examples of generating Arduino IDE specific files from source (.cc) files\r\n\r\n### Clear description\r\nThere is documentation and code (generate_microlite_projects() function,transform_arduino_source.py, etc.) suggesting that the Make build system allows for easily creating files and a directory from source files to be used in the Arduino IDE but there are no Arduino examples that show how this is or should be done. \r\n\r\nIt would be useful to show how the hello_world project example was built for the Arduino IDE from the repo's source using Make.\r\n\r\n### Usage example\r\nIs there a usage example?\r\nNot for Arduino.", "comments": []}, {"number": 38227, "title": "train_speech_model.ipynb TUTORIAL with colab not working", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\n I am trying to use this to train a set, the base tutorial will not compile the train.py section. I am copying and pasting the commands to colab to test and get a MODULE NOT FOUND ERROR.\r\nI have used this in the past about a month or so ago and it worked fine. Something must have been changed recently to cause this issue.\r\n\r\nHere is the output I get when trying to run the \"Begin Training\" section:\r\n\r\n2020-04-04 20:08:28.890032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"tensorflow/tensorflow/examples/speech_commands/train.py\", line 81, in <module>\r\n    import input_data\r\n  File \"/content/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 35, in <module>\r\n    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nModuleNotFoundError: No module named 'tensorflow.contrib'\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["I found that line 35 in /content/tensorflow/tensorflow/examples/speech_commands/input_data.py is no the same using the git in the instructions of the tutorial. I changed it manually to match what is currently in the git hub and it compiles further but is still having issues finding \"contrib_audio\"", "On my side I get another error about the dependencies not found\r\n\r\nERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729 (from versions: 2.2.0.dev20200210, 2.2.0.dev20200211, 2.2.0.dev20200212, 2.2.0.dev20200215, 2.2.0.dev20200216, 2.2.0.dev20200217, 2.2.0.dev20200218, 2.2.0.dev20200226, 2.2.0.dev20200227, 2.2.0.dev20200228, 2.2.0.dev20200229, 2.2.0.dev20200301, 2.2.0.dev20200302, 2.2.0.dev20200303, 2.2.0.dev20200304, 2.2.0.dev20200305, 2.2.0.dev20200306, 2.2.0.dev20200307, 2.2.0.dev20200308, 2.2.0.dev20200309, 2.2.0.dev20200310, 2.2.0.dev20200311, 2.2.0.dev20200312, 2.2.0.dev20200313, 2.2.0.dev20200314, 2.2.0.dev20200315, 2.2.0.dev20200316, 2.2.0.dev20200317, 2.2.0.dev20200318, 2.2.0.dev20200319, 2.2.0.dev20200323, 2.2.0.dev20200324, 2.2.0.dev20200325, 2.2.0.dev20200327, 2.2.0.dev20200328, 2.2.0.dev20200329, 2.2.0.dev20200330, 2.2.0.dev20200331, 2.2.0.dev20200401, 2.2.0.dev20200402, 2.2.0.dev20200403, 2.2.0.dev20200404, 2.2.0.dev20200405)\r\nERROR: No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729\r\n\r\ncan someone provide any help on this issue ?", "@llllGEM  Currently, Tf-nightly-gpu version is 2.2.0.dev20200405, For additional information please refer this [link](https://pypi.org/project/tf-nightly-gpu/).\r\nTo install tf 1.15, try pip install tensorflow==1.15. Thanks!", "@nahsam  Could you please provide the TF version as it helps us to reproduce the issue.Thanks!", "Using version 2.x gives those results\n\nOn Mon, Apr 6, 2020, 8:04 AM saikumarchalla <notifications@github.com>\nwrote:\n\n> @nahsam <https://github.com/nahsam> Could you please provide the TF\n> version as it helps us to reproduce the issue.Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38227#issuecomment-609781000>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIY75AGWBUPKGM7SQMDQWALRLHHOZANCNFSM4L7CEFOA>\n> .\n>\n", "Was able to reproduce the issue. Please find the Gist [here](https://colab.research.google.com/gist/saikumarchalla/37b418d191f58e32aea10803d45b206e/train-simple-audio-recognition-model.ipynb). Thanks!", "TF nightly installs TF 2.x version and `contrib` module is no longer part of TF from 2.X. \r\nAlso we don't save pipy packages of older tf nightly versions such as `1.15.0.dev20190729`\r\nYou can try using stable TF 1.x versions for using `contrib` module.\r\nThanks!", "I have be able to get version 1.x to complete but the tensor board doesn't\nwork anymore. It makes it difficult to gauge progress. Can you try and run\nit on version 1 and see if tensor board works for you?\n\nOn Wed, Apr 8, 2020, 7:54 PM Yasir Modak <notifications@github.com> wrote:\n\n> TF nightly installs TF 2.x version and contrib module is no longer part\n> of TF from 2.X.\n> Also we don't save pipy packages of older tf nightly versions.\n> You can try using stable TF 1.x versions for using contrib module.\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38227#issuecomment-611268643>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIY75AFDW2S67SPSQUMCVZDRLUMF5ANCNFSM4L7CEFOA>\n> .\n>\n", "If you can open a new issue and explain the tensorboard problem perhaps we can take a look and assist you. Reason being, we want to keep one issue thread specific to one topic so that it helps for users referring it in future. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38227\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38227\">No</a>\n"]}, {"number": 38226, "title": "from .pyrfc import *", "body": "i already install \r\nC:\\Python37>pip3 install pyrfc\r\nCollecting pyrfc\r\n  Downloading pyrfc-0.1.2.tar.gz (3.5 kB)\r\nInstalling collected packages: pyrfc\r\n    Running setup.py install for pyrfc ... done\r\nSuccessfully installed pyrfc-0.1.2\r\n\r\nbut when import i see this issue \r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#2>\", line 1, in <module>\r\n    from .pyrfc import *\r\nModuleNotFoundError: No module named '__main__.pyrfc'; '__main__' is not a package", "comments": ["@saberabdelhady,\r\nCould you please confirm if the issue is related to TensorFlow?\r\n\r\nIf is it, please provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "Not a TF issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38226\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38226\">No</a>\n"]}, {"number": 38225, "title": "Creating a dynamic weight matrix that can be optimised", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- I have written the following code myself\r\n- I am running it on google colab\r\n- \r\n-pip installed tensorflow==1.15\r\n\r\n- python 3.6\r\n\r\n-Cuda 10.0 Cudnn 7:\r\n- K80 GPU\r\n\r\n\r\n### Describe the problem\r\nThis is a bug i am receiving. i would like to create a dynamic weight matrix that is isomorphic with the input vector. to that end i split all the individual integer digits from their numbers and use them as indices in tf.gather() in order to reorder the weight matrix. i encounter the problem that when the result of tf.gather() is set as the trainable weights i get the error \"ValueError: Tensor conversion requested dtype float64_ref for Tensor with dtype float64: <tf.Tensor 'training_18/Nadam/my_layer2_88/Variable_1/m/Initializer/zeros:0' shape=(400, 400) dtype=float64>\"\r\n\r\nI beleived that what this meant is that it needed the trainable weights to be a tensor. So i converted it to a tensor but then i got the error that tensor object doesnt support the operation in_graph_mode.\r\n\r\nIn the larger picture is what i am trying to do , have a different weight matrix permutation for each new input possible. if it is , what is the best way to go about it and is it amenable to batch training or can it only apply to batch sizes of one. \r\n\r\n### Source code / logs\r\nthis is my call function in my custom layer:\r\n\r\ndef call(self, y):\r\n                 \r\n            paddings = [[0,0],[0, 10-tf.shape(y)[0]]]\r\n            out = tf.pad(y, paddings, 'CONSTANT', constant_values=2)\r\n            x =tf.map_fn(lambda xi: tf.strings.format('{}', xi), out, dtype=tf.string)\r\n            b= tf.compat.v1.string_split(x)\r\n            b=tf.sparse.to_dense(b)\r\n            b= tf.compat.v1.strings.to_number(b,tf.int32)\r\n            print(b)\r\n               \r\n            S =  tf.Variable(lambda :tf.reshape((tf.gather((tf.reshape(self.kernels, [-1])),(b))), (400, \r\n                                             400)),trainable=True)\r\n            #S=tf.convert_to_tensor(S)\r\n            self._trainable_weights = [S]\r\n            y= tf.cast(y, tf.float64)\r\n                               \r\n                     \r\n             return K.dot(y,S)", "comments": ["@MoyoT, Can you provide complete standalone code to replicate the reported issue. Thanks", "https://colab.research.google.com/drive/1Szs8AikhKI6olIDjdZSLuhQ1GUZRe8kh\r\n\r\n@gadagashwini  That is the google colab link.\r\nEven once we have debugged this issue, i expect there will be more before it is fully functional. For instance , the number of indices parsed to tf.gather() probably arent the same numebr as the shape of the weight matrix implies. so we wont be able to reshape it to the same size afterward.\r\n\r\non top of that a smaller problem is that we are duplicating weighted connections, or sharing them between neurons for example when string_split spilts the digits there will be some digits repeated.\r\n\r\nideally i wanted a situation where every input neuron \"i\" has the same amount of connections emanating out of it, and there are ten neurons in the next layer for the numbers 0 to 9, and there is a j for every possible decimal slot in the input to the neuron. The ith jth connection will then connect to the neuron representing the digit in the j decimal spot.\r\n\r\nSo if j stands for the 1/10th decimal slot, and the input to the ith neuron is 0,427...then, since 4 is the number in the 1/10th position, the weighted connection representing the 1/10th slot of the input to the ith neuron will connect to the neuron standing for the numebr 4 in the next layer among the 10 neurons there.", "@gadagashwini are you looking into it, please?", "@MoyoT, I am unable to access your driver. \r\nIssue looks like, `plot_generated_images()` requires model as argument.\r\nPass the saved model to `plot_generated_images()` and check. Thanks!", "@gadagashwini     Sorry for the confusion, the cell containing plot_generated is not the cell that produces the error I reported. The error comes when you run the largest cell in the notebook. The driver I used was chrome driver, the commands for installing it are in the first few cells for your convenience", "@gadagashwini accessing my google drive is not necessary in order to run the script and reproduce the error", "@gadagashwini Thankyou for your assistance so far, you continued assistance is appreciated", "@gabriel-vanzandycke @amahendrakar  are you able to assist", "Was able to reproduce the issue with TF v1.15.2. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/bdcc6a2a1451ca352ec636f7af1d2cf2/38225.ipynb). Thanks!", "@MoyoT,\r\nPlease check out [this](https://stackoverflow.com/a/58523478) StackOverflow comment and let us know if it works? Thanks!", "Thankyou for the response. the stack overflow comment does not directly address my issue. I set trainable weights to be the variable S. If i convert S to a tensor , before setting it the error says that tensor object has no attribute \"in_graph_mode\". If i dont it gives the following error \"ValueError: Tensor conversion requested dtype float64_ref for Tensor with dtype float64: <tf.Tensor 'training_1/Nadam/my_layer2_4/Variable_1/m/Initializer/zeros:0' shape=(400, 400) dtype=float64>\"\r\n\r\n@gowthamkpr the issue seems to be between using a tensor and a variable as the weight matrix as that is what distinguishes the two datatypes in the above error. Basically when i make it a tensor it complains that it needs it to be a variable, and when i make it a variable it complains that it needs to be a tensor.\r\nif i change the optimizer to SGD i get the error that \"not implemented updating tensor\" when i convert S (the weight matrix) to a tensor, and refVariable has no attribute handle, when it is a variable.\r\n\r\nIf i use tf2.0 i get the error \"ValueError: tf.function-decorated function tried to create variables on non-first call.\" when S is a variable and \"NotImplementedError: ('Trying to update a Tensor ', <tf.Tensor 'model_1/my_layer2_3/ReadVariableOp:0' shape=(400, 400) dtype=float64>)\" when S is a tensor.\r\n\r\nplease take the time to understand the call method in my custom layer to see what is going on.\r\n\r\n`def call(self, y):\r\n\r\n        paddings = [[0,0],[0, 10-tf.shape(y)[0]]]\r\n        out = tf.pad(y, paddings, 'CONSTANT', constant_values=2)\r\n        x =tf.map_fn(lambda xi: tf.strings.format('{}', xi), out, dtype=tf.string)\r\n        b= tf.compat.v1.string_split(x)\r\n        b=tf.sparse.to_dense(b)\r\n        b= tf.compat.v1.strings.to_number(b,tf.int32)\r\n        print(b)\r\n           \r\n        S =  tf.Variable(lambda :tf.reshape((tf.gather((tf.reshape(self.kernels, [-1])),(b))), (400, \r\n                                         400)),trainable=True)\r\n        #S=tf.convert_to_tensor(S)\r\n        self._trainable_weights = [S]\r\n        y= tf.cast(y, tf.float64)\r\n                           \r\n                 \r\n         return K.dot(y,S)`\r\nAlso , i would like to find a way to train with a batchsize of greater than one, with this method. Thankyou", "I have 3 instances of my custom layer and i placed a print statement in it. The statement prints 3 times showing that data is going from one layer to the next. only when doing BP the problem arises.", "I added my on compute output shape method, now the error has to do with string_split not separating digits, as i would like it to do. i will update.", "I managed to get somewhere, now the error is AssertionError: Could not compute output Tensor(\"conv2d_34/Identity:0\", shape=(2, 640, 360, 3), dtype=float32)\r\n\r\nFor some reason the batch size is showing two while im fitting one training example at a time. Please assist, it may have to do with the same problem. https://colab.research.google.com/gist/amahendrakar/bdcc6a2a1451ca352ec636f7af1d2cf2/38225.ipynb", "@tanzhenyu  do you have any idea where things are going wrong?", "Ok, if i set dynamic = True , we get two tensors as outputs to my custom layer. So i indexed the correct one and parsed it on and that seems to reslove the batchsize mismatch. but i am still geting the error Could not compute output Tensor(\"conv2d_34/Identity:0\", shape=(1, 640, 360, 3), dtype=float32)\r\n\r\nThis is what i did in short. i took the weight matrix and rearrange the indices at each training example. The pattern is to use the input (which consists of integers) as the index to tf.gather and the weight matrix as the input to it.\r\n\r\nDoing this makes for the preceding error.", "I tried using run_eagerly = True instead of dynamic = True in the models compile method, and it ran properly but with the following error, WARNING:tensorflow:Gradients do not exist for variables ['my_layer2_31/kernel:0'] when minimizing the loss. please reffer to the code\r\n ,https://colab.research.google.com/drive/1JVdbTmJPaiTipIn4xxoX0SmjepF8ocfO", "https://colab.research.google.com/drive/1XMmeyIMgwPSizFaKyGYb58IOrFLTEQW9\r\n\r\nI managed to fix the above problem. i was making new variables that werent being trained on with tf.variable. Now i only have the following bug: ValueError: The inner -398 dimensions of output.shape=[?,?] must match the inner 1 dimensions of updates.shape=[?,400]: Shapes must be equal rank, but are 0 and 1 for 'my_layer2_20/ScatterNd' (op: 'ScatterNd') with input shapes: [1,400], [?,400], [2].\r\n\r\nPlease please could you assist", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38225\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38225\">No</a>\n"]}, {"number": 38224, "title": "Ensemble of custom sequential models", "body": "I am trying to split the sequential models and combine them back in reference to the documentation on [CNN](https://www.tensorflow.org/tutorials/images/cnn)\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers, models\r\ntf.keras.backend.set_floatx('float64')\r\n```\r\n### Data\r\n```\r\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\n# Normalize pixel values to be between 0 and 1\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\n```\r\n### Model 1:\r\n\r\n```\r\nclass Model1(tf.keras.Model):\r\n\r\n  def __init__(self):\r\n    super(Model1,self).__init__(name = 'Model1')\r\n    self.model = models.Sequential()\r\n\r\n  def call(self,inputs):\r\n    # self.model.add(layers.Input(shape=(32, 32, 3)))\r\n    self.model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(32,32,3)))\r\n    self.model.add(layers.MaxPooling2D((2, 2)))\r\n    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n    self.model.add(layers.MaxPooling2D((2, 2)))\r\n    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n    \r\n    return self.model\r\n```\r\n### Model 2:\r\n```\r\nclass Model2(tf.keras.Model):\r\n  def __init__(self):\r\n    super(Model2,self).__init__(name = 'Model2')\r\n    self.model = models.Sequential()\r\n  def call(self,inputs):\r\n    self.model.add(layers.Reshape((32,32,1),input_shape=(32,32,1))\r\n    self.model.add(layers.Flatten())\r\n    self.model.add(layers.Dense(64, activation='relu')) \r\n    self.model.add(layers.Dense(10))\r\n    return self.model\r\n```\r\n### Ensemble of above two models:\r\n\r\n```\r\nclass Ensemble(tf.keras.Model):\r\n  def __init__(self,model1, model2):\r\n    super(Ensemble,self).__init__(name = 'Ensemble')\r\n    self.model = models.Sequential()\r\n    self.model.add(model1)\r\n    self.model.add(model2)\r\n\r\n  def call(self,inputs):\r\n    output = self.model(inputs)\r\n    return output\r\n\r\n# class Ensemble(tf.keras.Model):\r\n\r\n#   def __init__(self,model1, model2):\r\n#     super(Ensemble,self).__init__(name = 'Ensemble')\r\n#     self.model1 = model1\r\n#     self.model2 = model2\r\n#   def call(self,inputs):\r\n#     output = self.model1(inputs)\r\n#     output = self.model2(output)\r\n#     return output\r\n```\r\nInitialize and build the model\r\n\r\n```\r\nmodel1 = Model1()\r\nmodel2 = Model2()\r\nmodel = Ensemble(model1,model2)\r\nmodel.build((32,32,3))\r\nmodel.summary()\r\n```\r\n```Model: \"Ensemble\"```\r\n`_________________________________________________________________`\r\n`Layer (type)                 Output Shape              Param #`   \r\n`=================================================================`\r\n`Model1 (Model1)              multiple                  56320`     \r\n`_________________________________________________________________`\r\n`Model2 (Model2)              multiple                  66250`     \r\n`=================================================================`\r\n`Total params: 122,570`\r\n`Trainable params: 122,570`\r\n`Non-trainable params: 0`\r\n\r\n### Compile and fit the model\r\n```\r\n# Compile model\r\nmodel.compile(optimizer='adam',\r\n                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                metrics=['accuracy'])\r\n\r\n# Train the model\r\nhistory = model.fit(train_images, train_labels, epochs=10, batch_size=64,\r\n                      validation_data=(test_images, test_labels))\r\n```\r\n### Returns:\r\n`ValueError: The name \"conv2d\" is used 2 times in the model. All layer names should be unique.`\r\n\r\n### Error trace below: \r\n```\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-12-e612d6023946> in <module>()\r\n      5 # Train the model\r\n      6 history = model.fit(train_images, train_labels, epochs=10, batch_size=64,\r\n----> 7                       validation_data=(test_images, test_labels))\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    783                 batch_size=batch_size):\r\n    784               callbacks.on_train_batch_begin(step)\r\n--> 785               tmp_logs = train_function(iterator)\r\n    786               # Catch OutOfRangeError for Datasets of unknown size.\r\n    787               # This blocks until the batch has finished executing.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    625       # This is the first call of __call__, so we have to initialize.\r\n    626       initializers = []\r\n--> 627       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    628     finally:\r\n    629       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    504     self._concrete_stateful_fn = (\r\n    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 506             *args, **kwds))\r\n    507 \r\n    508     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2444       args, kwargs = None, None\r\n   2445     with self._lock:\r\n-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2447     return graph_function\r\n   2448 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2775 \r\n   2776       self._function_cache.missed.add(call_context_key)\r\n-> 2777       graph_function = self._create_graph_function(args, kwargs)\r\n   2778       self._function_cache.primary[cache_key] = graph_function\r\n   2779       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2665             arg_names=arg_names,\r\n   2666             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2667             capture_by_value=self._capture_by_value),\r\n   2668         self._function_attributes,\r\n   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    440         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    442     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    443 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    <ipython-input-5-a5fe0db529f5>:38 call  *\r\n        output = self.model(inputs)\r\n    <ipython-input-3-e360f03e53e3>:9 call  *\r\n        self.model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(32,32,3)))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:456 _method_wrapper  **\r\n        result = method(self, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:224 add\r\n        self._init_graph_network(self.inputs, self.outputs, name=self.name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:456 _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:302 _init_graph_network\r\n        self.inputs, self.outputs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1798 _map_graph_network\r\n        str(all_names.count(name)) + ' times in the model. '\r\n\r\n    ValueError: The name \"conv2d\" is used 2 times in the model. All layer names should be unique.\r\n```\r\n### Bit of troubleshooting:\r\n\r\n```\r\nfor i, la in enumerate(model.layers):\r\n  print(la.name)\r\n  for j, laye in enumerate(la.layers):\r\n    print(laye.name)\r\n    for k, lay in enumerate(laye.layers):\r\n      print(lay.name) \r\n```\r\nReturns:\r\n\r\n```model1\r\nsequential\r\nconv2d\r\nmax_pooling2d\r\nconv2d_1\r\nmax_pooling2d_1\r\nconv2d_2\r\nmodel2\r\nsequential_1\r\nreshape\r\nflatten\r\ndense\r\ndense_1\r\n```\r\n\r\n#### The name scope 'conv2d' is invoked only once? Is there any documentation/ feature to combine two sequential models?\r\n \r\n**System information** \r\nTensorflow '2.2.0-rc2' : Colab \r\n (https://colab.research.google.com/drive/1mlZJBh2BAsOGKziXZ9V60Web53c7vRI0)\r\n\r\n\r\n", "comments": ["@Saran-nns \r\nplease let us know which tensorflow version are you facing the issue in", "@Saran-nns\r\nplease update on the above comment", "@Saduf2019  I am using Tensorflow '2.2.0-rc2' : Colab; \r\n\r\nApparently, the error disappeared when i compile the model directly without building it. \r\nHowever, i received new error while fitting the model. \r\n\r\nError trace:\r\n```Epoch 1/10\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-7-e612d6023946> in <module>()\r\n      5 # Train the model\r\n      6 history = model.fit(train_images, train_labels, epochs=10, batch_size=64,\r\n----> 7                       validation_data=(test_images, test_labels))\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    783                 batch_size=batch_size):\r\n    784               callbacks.on_train_batch_begin(step)\r\n--> 785               tmp_logs = train_function(iterator)\r\n    786               # Catch OutOfRangeError for Datasets of unknown size.\r\n    787               # This blocks until the batch has finished executing.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    625       # This is the first call of __call__, so we have to initialize.\r\n    626       initializers = []\r\n--> 627       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    628     finally:\r\n    629       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    504     self._concrete_stateful_fn = (\r\n    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 506             *args, **kwds))\r\n    507 \r\n    508     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2444       args, kwargs = None, None\r\n   2445     with self._lock:\r\n-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2447     return graph_function\r\n   2448 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2775 \r\n   2776       self._function_cache.missed.add(call_context_key)\r\n-> 2777       graph_function = self._create_graph_function(args, kwargs)\r\n   2778       self._function_cache.primary[cache_key] = graph_function\r\n   2779       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2665             arg_names=arg_names,\r\n   2666             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2667             capture_by_value=self._capture_by_value),\r\n   2668         self._function_attributes,\r\n   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    440         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    442     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    443 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nTypeError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:467 train_step  **\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\r\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__\r\n        losses = self.call(y_true, y_pred)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call\r\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1555 sparse_categorical_crossentropy\r\n        y_pred = ops.convert_to_tensor_v2(y_pred)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1283 convert_to_tensor_v2\r\n        as_ref=False)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function\r\n        return constant(v, dtype=dtype, name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant\r\n        allow_broadcast=True)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto\r\n        \"supported type.\" % (type(values), values))\r\n\r\n    TypeError: Failed to convert object of type <class 'tensorflow.python.keras.engine.sequential.Sequential'> to Tensor. Contents: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7c24e8fe48>. Consider casting elements to a supported type.```", "i am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/d5a4ec5a134db77080734fb355ce50f0/38224.ipynb)", "@Saduf2019 @gowthamkpr Any update on this issue, please.", "You should create all layers during build, not call. It's likely that call got invoked twice (because we need to trace the graph)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38224\">No</a>\n"]}, {"number": 38223, "title": "TF2.0 frozen ckpt model or h5 model to pb model appear wrong", "body": "> freeze the graph reference from the below code\r\n> \r\n> ```python\r\n> from keras import backend as K\r\n> import tensorflow as tf\r\n> \r\n> def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\r\n>     \"\"\"\r\n>     Freezes the state of a session into a pruned computation graph.\r\n> \r\n>     Creates a new computation graph where variable nodes are replaced by\r\n>     constants taking their current value in the session. The new graph will be\r\n>     pruned so subgraphs that are not necessary to compute the requested\r\n>     outputs are removed.\r\n>     @param session The TensorFlow session to be frozen.\r\n>     @param keep_var_names A list of variable names that should not be frozen,\r\n>                           or None to freeze all the variables in the graph.\r\n>     @param output_names Names of the relevant graph outputs.\r\n>     @param clear_devices Remove the device directives from the graph for better portability.\r\n>     @return The frozen graph definition.\r\n>     \"\"\"\r\n>     from tensorflow.python.framework.graph_util import convert_variables_to_constants\r\n>     graph = session.graph\r\n>     with graph.as_default():\r\n>         freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\r\n>         output_names = output_names or []\r\n>         output_names += [v.op.name for v in tf.global_variables()]\r\n>         # Graph -> GraphDef ProtoBuf\r\n>         input_graph_def = graph.as_graph_def()\r\n>         if clear_devices:\r\n>             for node in input_graph_def.node:\r\n>                 node.device = \"\"\r\n>         frozen_graph = convert_variables_to_constants(session, input_graph_def,\r\n>                                                       output_names, freeze_var_names)\r\n>         return frozen_graph\r\n> \r\n> \r\n> frozen_graph = freeze_session(K.get_session(),\r\n>                               output_names=[out.op.name for out in model.outputs]\r\n> \r\n> tf.train.write_graph(frozen_graph, \"model\", \"tf_model.pb\", as_text=False)\r\n> ```\r\n\r\nhi\uff0ci use your demo complete frozen the ckpt model(checkpoint = tf.train.Checkpoint(myAwesomeModel=me), checkpoint.restore(tf.train.latest_checkpoint('examples'    ))) or h5 model (model.load_weights('model_enc.h5'))to pb model\u3002after i run ckpt model and pb model\uff0ci find their result is different\u3002and the result of ckpt model  is right\u3002i check the pb model parmas\uff0c and find some op variable parmas is initial value\uff0clike \u201cbias\u201d is vector contain zero\uff0c\u201clayer normal beta\u201d  is vector contain zero eg.  i think it is  wrong to restore model, hope your give me some advice,thx", "comments": ["@hahadashi, I tried reproducing the issue with Tf 2.0 but received different error. \r\nPlease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/9b25d752b3d77347cc8d727c54e96d1a/untitled488.ipynb) and provide the more information to analyze the issue. Thanks  ", "> @hahadashi, I tried reproducing the issue with Tf 2.0 but received different error.\r\n> Please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/9b25d752b3d77347cc8d727c54e96d1a/untitled488.ipynb) and provide the more information to analyze the issue. Thanks\r\n\r\nthx your response\u3002 i use this way\uff0chave sovled problem\uff0cmay be it is because of when i rebuild the model and i made  a minor mistake", "> @hahadashi, I tried reproducing the issue with Tf 2.0 but received different error.\r\n> Please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/9b25d752b3d77347cc8d727c54e96d1a/untitled488.ipynb) and provide the more information to analyze the issue. Thanks\r\n\r\nbut i meet  a new problem\u3002if i use pb model by c++ env\uff0ci try to inference by batch\u3002 i set the same inputs\uff0cbut these outputs are difference\u3002have you try inference by bctch\uff1fif i set batch is one\uff0cthe result is right", "@hahadashi, Can you raise the new issue with all the information asked in Template. Thanks", "> @hahadashi, Can you raise the new issue with all the information asked in Template. Thanks\r\n\r\nOK\uff0cthx your response!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38223\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38223\">No</a>\n"]}, {"number": 38222, "title": "MutableGraphView::MutableGraphView error: node has self cycle fanin - But graph is not cyclic", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n\r\n - Python 3.6.6 on Fedora\r\n - `python3 -c 'import tensorflow as tf; print(tf.__version__)'` -> 2.1.0\r\n - `tf.version.GIT_VERSION` -> v2.1.0-rc2-17-ge5bf8de\r\n - TensorFlow installed using `pip3 install --upgrade tensorflow`\r\n - Running on AMD CPU, no GPU acceleration\r\n\r\n**Describe the current behavior**\r\n\r\nFor graphs that are not cyclic, I sometimes receive messages like this:\r\n\r\n```\r\n2020-04-04 11:20:02.351817: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:02.355486: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.357350: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.371116: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.372145: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:02.373345: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.374334: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.377600: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect that TensorFlow should not print these messages (and presumably, be able to topologically order the non-cyclic graph).\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport random\r\n\r\nrandom.seed(1)\r\nnp.random.seed(1)\r\n\r\ninput_data = np.random.random(20000).reshape(10000, 2)\r\noutput_data = np.sin(input_data)\r\n\r\njson = '''{\"class_name\": \"Model\", \"config\": {\"name\": \"model_4\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 2], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_5\"}, \"name\": \"input_5\", \"inbound_nodes\": []}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_2\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [1, 2]}, \"name\": \"reshape_2\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_1\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [1, 2]}, \"name\": \"reshape_1\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [2, 1]}, \"name\": \"reshape\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}]]]}, {\"class_name\": \"UpSampling1D\", \"config\": {\"name\": \"up_sampling1d_2\", \"trainable\": true, \"dtype\": \"float32\", \"size\": 3}, \"name\": \"up_sampling1d_2\", \"inbound_nodes\": [[[\"reshape_2\", 0, 0, {}]]]}, {\"class_name\": \"UpSampling1D\", \"config\": {\"name\": \"up_sampling1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"size\": 3}, \"name\": \"up_sampling1d_1\", \"inbound_nodes\": [[[\"reshape_1\", 0, 0, {}]]]}, {\"class_name\": \"UpSampling1D\", \"config\": {\"name\": \"up_sampling1d\", \"trainable\": true, \"dtype\": \"float32\", \"size\": 2}, \"name\": \"up_sampling1d\", \"inbound_nodes\": [[[\"reshape\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_5\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [2, 1]}, \"name\": \"reshape_5\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}]]]}, {\"class_name\": \"ZeroPadding1D\", \"config\": {\"name\": \"zero_padding1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"padding\": [0, 1]}, \"name\": \"zero_padding1d_1\", \"inbound_nodes\": [[[\"up_sampling1d_2\", 0, 0, {}]]]}, {\"class_name\": \"ZeroPadding1D\", \"config\": {\"name\": \"zero_padding1d\", \"trainable\": true, \"dtype\": \"float32\", \"padding\": [0, 1]}, \"name\": \"zero_padding1d\", \"inbound_nodes\": [[[\"up_sampling1d_1\", 0, 0, {}]]]}, {\"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 2, \"kernel_size\": [1], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"conv1d\", \"inbound_nodes\": [[[\"up_sampling1d\", 0, 0, {}]]]}, {\"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d\", \"trainable\": true, \"dtype\": \"float32\", \"strides\": [2], \"pool_size\": [2], \"padding\": \"valid\", \"data_format\": \"channels_last\"}, \"name\": \"max_pooling1d\", \"inbound_nodes\": [[[\"reshape_5\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_3\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [2, 1]}, \"name\": \"reshape_3\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}]]]}, {\"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 4, \"kernel_size\": [1], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"conv1d_1\", \"inbound_nodes\": [[[\"zero_padding1d_1\", 0, 0, {}]]]}, {\"class_name\": \"Dot\", \"config\": {\"name\": \"dot\", \"trainable\": true, \"dtype\": \"float32\", \"axes\": -1, \"normalize\": false}, \"name\": \"dot\", \"inbound_nodes\": [[[\"zero_padding1d\", 0, 0, {}], [\"conv1d\", 0, 0, {}]]]}, {\"class_name\": \"SpatialDropout1D\", \"config\": {\"name\": \"spatial_dropout1d\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}, \"name\": \"spatial_dropout1d\", \"inbound_nodes\": [[[\"max_pooling1d\", 0, 0, {}]]]}, {\"class_name\": \"GlobalAveragePooling1D\", \"config\": {\"name\": \"global_average_pooling1d\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"name\": \"global_average_pooling1d\", \"inbound_nodes\": [[[\"reshape_3\", 0, 0, {}]]]}, {\"class_name\": \"Dot\", \"config\": {\"name\": \"dot_1\", \"trainable\": true, \"dtype\": \"float32\", \"axes\": -1, \"normalize\": false}, \"name\": \"dot_1\", \"inbound_nodes\": [[[\"conv1d_1\", 0, 0, {}], [\"dot\", 0, 0, {}]]]}, {\"class_name\": \"AlphaDropout\", \"config\": {\"name\": \"alpha_dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.24308844217362846}, \"name\": \"alpha_dropout\", \"inbound_nodes\": [[[\"spatial_dropout1d\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_4\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [1, 1]}, \"name\": \"reshape_4\", \"inbound_nodes\": [[[\"global_average_pooling1d\", 0, 0, {}]]]}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}, \"name\": \"dropout\", \"inbound_nodes\": [[[\"dot_1\", 0, 0, {}]]]}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"name\": \"flatten\", \"inbound_nodes\": [[[\"alpha_dropout\", 0, 0, {}]]]}, {\"class_name\": \"GlobalAveragePooling1D\", \"config\": {\"name\": \"global_average_pooling1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"name\": \"global_average_pooling1d_1\", \"inbound_nodes\": [[[\"reshape_4\", 0, 0, {}]]]}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_1\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"name\": \"flatten_1\", \"inbound_nodes\": [[[\"dropout\", 0, 0, {}]]]}, {\"class_name\": \"Concatenate\", \"config\": {\"name\": \"concatenate\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": -1}, \"name\": \"concatenate\", \"inbound_nodes\": [[[\"input_5\", 0, 0, {}], [\"flatten\", 0, 0, {}], [\"global_average_pooling1d_1\", 0, 0, {}], [\"flatten_1\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_4\", \"inbound_nodes\": [[[\"concatenate\", 0, 0, {}]]]}], \"input_layers\": [[\"input_5\", 0, 0]], \"output_layers\": [[\"dense_4\", 0, 0]]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'''\r\n\r\nmodel = tf.keras.models.model_from_json(json)\r\nmodel.compile(loss = 'mse', optimizer = 'adam')\r\n\r\nmodel.summary()\r\n\r\nmodel.fit(x = input_data.reshape(-1, 2), y = output_data.reshape(-1, 2), epochs = 3, validation_split = 0.2)\r\n```\r\n\r\nThis runs and produces the following output:\r\n\r\n```\r\n2020-04-04 11:19:57.409765: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-04 11:19:57.409910: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-04-04 11:19:57.409938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-04-04 11:20:00.326542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-04 11:20:00.326615: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-04 11:20:00.326705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sapling6): /proc/driver/nvidia/version does not exist\r\n2020-04-04 11:20:00.357649: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2195855000 Hz\r\n2020-04-04 11:20:00.358616: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2db3a0250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-04 11:20:00.358698: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nModel: \"model_4\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_5 (InputLayer)            [(None, 2)]          0                                            \r\n__________________________________________________________________________________________________\r\nreshape_2 (Reshape)             (None, 1, 2)         0           input_5[0][0]                    \r\n__________________________________________________________________________________________________\r\nreshape_1 (Reshape)             (None, 1, 2)         0           input_5[0][0]                    \r\n__________________________________________________________________________________________________\r\nreshape (Reshape)               (None, 2, 1)         0           input_5[0][0]                    \r\n__________________________________________________________________________________________________\r\nup_sampling1d_2 (UpSampling1D)  (None, 3, 2)         0           reshape_2[0][0]                  \r\n__________________________________________________________________________________________________\r\nup_sampling1d_1 (UpSampling1D)  (None, 3, 2)         0           reshape_1[0][0]                  \r\n__________________________________________________________________________________________________\r\nup_sampling1d (UpSampling1D)    (None, 4, 1)         0           reshape[0][0]                    \r\n__________________________________________________________________________________________________\r\nreshape_5 (Reshape)             (None, 2, 1)         0           input_5[0][0]                    \r\n__________________________________________________________________________________________________\r\nzero_padding1d_1 (ZeroPadding1D (None, 4, 2)         0           up_sampling1d_2[0][0]            \r\n__________________________________________________________________________________________________\r\nzero_padding1d (ZeroPadding1D)  (None, 4, 2)         0           up_sampling1d_1[0][0]            \r\n__________________________________________________________________________________________________\r\nconv1d (Conv1D)                 (None, 4, 2)         4           up_sampling1d[0][0]              \r\n__________________________________________________________________________________________________\r\nmax_pooling1d (MaxPooling1D)    (None, 1, 1)         0           reshape_5[0][0]                  \r\n__________________________________________________________________________________________________\r\nreshape_3 (Reshape)             (None, 2, 1)         0           input_5[0][0]                    \r\n__________________________________________________________________________________________________\r\nconv1d_1 (Conv1D)               (None, 4, 4)         12          zero_padding1d_1[0][0]           \r\n__________________________________________________________________________________________________\r\ndot (Dot)                       (None, 4, 4)         0           zero_padding1d[0][0]             \r\n                                                                 conv1d[0][0]                     \r\n__________________________________________________________________________________________________\r\nspatial_dropout1d (SpatialDropo (None, 1, 1)         0           max_pooling1d[0][0]              \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling1d (Globa (None, 1)            0           reshape_3[0][0]                  \r\n__________________________________________________________________________________________________\r\ndot_1 (Dot)                     (None, 4, 4)         0           conv1d_1[0][0]                   \r\n                                                                 dot[0][0]                        \r\n__________________________________________________________________________________________________\r\nalpha_dropout (AlphaDropout)    (None, 1, 1)         0           spatial_dropout1d[0][0]          \r\n__________________________________________________________________________________________________\r\nreshape_4 (Reshape)             (None, 1, 1)         0           global_average_pooling1d[0][0]   \r\n__________________________________________________________________________________________________\r\ndropout (Dropout)               (None, 4, 4)         0           dot_1[0][0]                      \r\n__________________________________________________________________________________________________\r\nflatten (Flatten)               (None, 1)            0           alpha_dropout[0][0]              \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling1d_1 (Glo (None, 1)            0           reshape_4[0][0]                  \r\n__________________________________________________________________________________________________\r\nflatten_1 (Flatten)             (None, 16)           0           dropout[0][0]                    \r\n__________________________________________________________________________________________________\r\nconcatenate (Concatenate)       (None, 20)           0           input_5[0][0]                    \r\n                                                                 flatten[0][0]                    \r\n                                                                 global_average_pooling1d_1[0][0] \r\n                                                                 flatten_1[0][0]                  \r\n__________________________________________________________________________________________________\r\ndense_4 (Dense)                 (None, 2)            42          concatenate[0][0]                \r\n==================================================================================================\r\nTotal params: 58\r\nTrainable params: 58\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nTrain on 8000 samples, validate on 2000 samples\r\nEpoch 1/3\r\n2020-04-04 11:20:02.351817: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:02.355486: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.357350: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.371116: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.372145: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:02.373345: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.374334: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:02.377600: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.\r\n7904/8000 [============================>.] - ETA: 0s - loss: 0.16842020-04-04 11:20:04.124781: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:04.126366: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:04.127223: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:04.132842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:04.133249: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-04 11:20:04.133728: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:04.134178: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-04 11:20:04.135585: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.\r\n8000/8000 [==============================] - 3s 429us/sample - loss: 0.1671 - val_loss: 0.0197\r\nEpoch 2/3\r\n8000/8000 [==============================] - 2s 204us/sample - loss: 0.0260 - val_loss: 0.0089\r\nEpoch 3/3\r\n8000/8000 [==============================] - 2s 204us/sample - loss: 0.0112 - val_loss: 0.0054\r\n```\r\n", "comments": ["@hfinkel,\r\nI tried reproducing the issue, but was able to run the code without any warning or error logs. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/20b6214077c4d93d5f268ab0f1c009a9/38222-2-1.ipynb).\r\n\r\nCould you please try changing the log level using the following code and let us know if it works?\r\n```\r\nimport os\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\r\nimport tensorflow as tf\r\n```\r\nThanks!", "> Could you please try changing the log level using the following code and let us know if it works?\r\n\r\nNo, that does not have an effect on those messages. Setting the log level to 2 does remove the informational messages at the beginning of the execution:\r\n\r\n```\r\n2020-04-08 14:00:29.272792: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2195855000 Hz\r\n2020-04-08 14:00:29.274725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596233c6980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-08 14:00:29.274803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n```\r\n\r\nSo those are gone, but these:\r\n\r\n```2020-04-08 14:01:03.347880: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-08 14:01:03.351566: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-08 14:01:03.353443: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-08 14:01:03.368067: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.\r\n2020-04-08 14:01:03.369385: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'model_4/up_sampling1d_2/concat' has self cycle fanin 'model_4/up_sampling1d_2/concat'.\r\n2020-04-08 14:01:03.370744: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n2020-04-08 14:01:03.371978: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n```\r\n\r\nand so on still remain.\r\n", "@hfinkel,\r\nSeems like the issue is fixed in the latest TF-nightly build. Please find the [attached gist](https://colab.research.google.com/gist/amahendrakar/e9ec3ba4a35e93cb6a6682e27fbbb5a9/38222-tf-nightly.ipynb#scrollTo=f1uK4LjIVjNI&line=1&uniqifier=1). \r\n\r\nCould you please verify it on your end? Thanks!", "Any updates regarding this issue? Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38222\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38222\">No</a>\n"]}, {"number": 38221, "title": "Distributed tensorflow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Closing as no information was provided"]}, {"number": 38220, "title": "Request to have ConvLSTM2D for TFLite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Android 6.0\r\n- TensorFlow installed from (source or binary): Anaconda, \r\n- TensorFlow version (or github SHA if from source): 1.15\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nMODEL_PATH = f'final_{name}.hdf5'\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(MODEL_PATH)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\nopen(\"test.tflite\", \"wb\").write(tflite_model)\r\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nWARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nINFO:tensorflow:Froze 9 variables.\r\nINFO:tensorflow:Converted 9 variables to const ops.\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-8-a668afd61005>\", line 7, in <module>\r\n    tflite_model = converter.convert()\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n\r\nConverterError: See console for info.\r\nThe system cannot find the path specified.\r\n2020-04-04 18:18:56.937955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2020-04-04 18:19:02.693081: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.693268: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.693408: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.693578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.693922: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.694124: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.694364: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-04-04 18:19:02.694576: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-04-04 18:19:02.694796: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-04-04 18:19:02.695011: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-04-04 18:19:02.695242: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.695478: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.695663: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-04-04 18:19:02.695871: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.696067: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.696287: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-04-04 18:19:02.696509: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-04-04 18:19:02.696735: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.696926: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.697133: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-04-04 18:19:02.697378: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-04-04 18:19:02.697585: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-04-04 18:19:02.697834: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-04-04 18:19:02.698063: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-04-04 18:19:02.698388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-04-04 18:19:02.698730: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-04-04 18:19:02.698982: F tensorflow/lite/toco/tooling_util.cc:1474] Should not get here: 5\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00004d20 (most recent call first):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52 in execute\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\absl\\app.py\", line 299 in run\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40 in run\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89 in main\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tfgpu\\Scripts\\toco_from_protos-script.py\", line 10 in <module>\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nfrom keras.layers.wrappers import TimeDistributed\r\nfrom keras.layers import Dense,Flatten,Input,concatenate,Dot, Conv2D,Reshape, MaxPooling2D, UpSampling2D,Conv3DTranspose, ZeroPadding2D,Conv3D,Conv2DTranspose, BatchNormalization, Dropout\r\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Input, LSTM, Dropout, Dense, Concatenate, TimeDistributed, Permute\r\nfrom keras.models import Model,Sequential\r\nfrom keras.layers.convolutional_recurrent import ConvLSTM2D\r\nfrom keras.callbacks import TensorBoard\r\nimport keras.losses as losses\r\nimport numpy as np\r\n\r\n\r\n\r\n\r\n# create our model here\r\nkernel_size = 3\r\nnfilters_lstm = 16\r\n\r\nNbatch=1\r\nNtime=10\r\nNx=32\r\nNy=32\r\nNchannel=1\r\n\r\n\r\n# define an input layer (Ntime, Nbatch, Nx, Ny, Nchannel)\r\ninputs = Input(name='x_input', dtype='float32',batch_shape=(Nbatch, Ntime, Nx, Ny, Nchannel)) \r\n\r\n'''define model'''\r\n# convLSTM 1\r\nConvLSTM_1= ConvLSTM2D(filters=nfilters_lstm , kernel_size=(kernel_size, kernel_size)\r\n                   , data_format='channels_last'\r\n                   , recurrent_activation='hard_sigmoid'\r\n                   , activation='tanh'\r\n                   , padding='same', return_sequences=False)(inputs)\r\n\r\nBatchNorm_1 = BatchNormalization()(ConvLSTM_1)\r\n\r\n# conv2D \r\nConv_1 = Conv2D(1, kernel_size, strides=(1, 1), padding='same', data_format='channels_last',  activation='relu')(BatchNorm_1)\r\n    \r\n# define the output\r\nmodel = Model(inputs=inputs, outputs=Conv_1, name='Model ')\r\n\r\nmodel.compile(loss=losses.categorical_crossentropy,\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\n\r\nmodel.save('test.hdf5')\r\n\r\n\r\nimport tensorflow as tf\r\nMODEL_PATH = 'test.hdf5'\r\nmodel = tf.keras.models.load_model(MODEL_PATH)\r\nmodel.summary()\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(MODEL_PATH)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\nopen(\"3x9.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**GRAPH:**\r\n```\r\nModel: \"Model \"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nx_input (InputLayer)         [(1, 10, 32, 32, 1)]      0         \r\n_________________________________________________________________\r\nconv_lst_m2d_1 (ConvLSTM2D)  (1, 32, 32, 16)           9856      \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (1, 32, 32, 16)           64        \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (1, 32, 32, 1)            145       \r\n=================================================================\r\nTotal params: 10,065\r\nTrainable params: 10,033\r\nNon-trainable params: 32\r\n_________________________________________________________________\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n\r\nThe TFLite converter fails to convert the convLSTM2D layer since it has 5 dimensions. Is there any way to make it work? Any hacky workaround? Would be great to see that in the next TF versions somehow! ", "comments": ["i have replicated this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/2a4a8291cd03e38ae55800018699ab06/untitled127.ipynb#scrollTo=L4o6kJXp_ptT)", "Thanks for offering help. \r\nIn the meantime, I tried to solve the issue by creating a customized convLSTM using plain Tensorflow. I had medium success..\r\n\r\nBut I was wondering about the following line in particular: \r\n\r\n```\r\nConverterError: See console for info.\r\nThe system cannot find the path specified.\r\n```\r\n\r\nI'm using a fresh tensorflow-gpu installation on a windows 10 machine. It doesn't appear in the google colab! ", "Hi, Can you upgrade to 2.2 and try again?\r\n\r\nThanks a lot!", "Hey, thanks for the feedback. I have checked with the above mentioned gist and replaced the pip install command with ```pip install tf-nightly``` which should give me the latest TF 2.2.0 version as I'm assuming you meant, right? \r\nI've changed the code:\r\n\r\n```\r\nfrom keras.layers.wrappers import TimeDistributed\r\nfrom keras.layers import Dense,Flatten,Input,concatenate,Dot, Conv2D,Reshape, MaxPooling2D, UpSampling2D,Conv3DTranspose, ZeroPadding2D,Conv3D,Conv2DTranspose, BatchNormalization, Dropout\r\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Input, LSTM, Dropout, Dense, Concatenate, TimeDistributed, Permute\r\nfrom keras.models import Model,Sequential\r\nfrom keras.layers.convolutional_recurrent import ConvLSTM2D\r\nfrom keras.callbacks import TensorBoard\r\nimport keras.losses as losses\r\nimport numpy as np\r\n\r\n\r\n\r\n\r\n# create our model here\r\nkernel_size = 3\r\nnfilters_lstm = 16\r\n\r\nNbatch=1\r\nNtime=10\r\nNx=32\r\nNy=32\r\nNchannel=1\r\n\r\n\r\n# define an input layer (Ntime, Nbatch, Nx, Ny, Nchannel)\r\ninputs = Input(name='x_input', dtype='float32',batch_shape=(Nbatch, Ntime, Nx, Ny, Nchannel)) \r\n\r\n'''define model'''\r\n# convLSTM 1\r\nConvLSTM_1= ConvLSTM2D(filters=nfilters_lstm , kernel_size=(kernel_size, kernel_size)\r\n                   , data_format='channels_last'\r\n                   , recurrent_activation='hard_sigmoid'\r\n                   , activation='tanh'\r\n                   , padding='same', return_sequences=False)(inputs)\r\n\r\nBatchNorm_1 = BatchNormalization()(ConvLSTM_1)\r\n\r\n# conv2D \r\nConv_1 = Conv2D(1, kernel_size, strides=(1, 1), padding='same', data_format='channels_last',  activation='relu')(BatchNorm_1)\r\n    \r\n# define the output\r\nmodel = Model(inputs=inputs, outputs=Conv_1, name='Model ')\r\n\r\nmodel.compile(loss=losses.categorical_crossentropy,\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\nopen(\"3x9.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nand it gives the following error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-8c00ee04e722> in <module>()\r\n     45               metrics=['accuracy'])\r\n     46 \r\n---> 47 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n     48 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n     49                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\n1 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py in model_input_signature(model, keep_original_batch_size)\r\n     75     TensorSpecs. This list does not contain the `training` argument.\r\n     76   \"\"\"\r\n---> 77   input_specs = model._get_save_spec(dynamic_batch=not keep_original_batch_size)  # pylint: disable=protected-access\r\n     78   if input_specs is None:\r\n     79     return None\r\n\r\nAttributeError: 'Model' object has no attribute '_get_save_spec'\r\n```\r\n\r\nThis has probably nothing to do with the first error. Any idea?\r\nThanks! ", "Hi Scott, can you take a look? thanks!", "I think the code failed since it is trying to use keras rather than tf.keras. The implementation detail for tf.keras and keras has been very different, and can't be interchanged between each other.\r\n\r\nI have tried the code with nightly tf.keras and it worked.", "@qlzh727 thanks for looking into it. I'm able to convert the code now using a MacBook Pro running on TF 2.2.0. Windows still fails. Google colab works too (perhaps GPU problem)...Anyway. \r\n\r\nThe next problem I'm facing based on the ```ConvLSTM2D``` layer is the following: \r\n\r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: de.nanoimaging.stormimager, PID: 20945\r\n    java.lang.RuntimeException: Unable to start activity ComponentInfo{de.nanoimaging.stormimager/de.nanoimaging.stormimager.acquisition.AcquireActivity}: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\n    Node number 2 (FlexConv2D) failed to prepare.\r\n    \r\n    Node number 5 (WHILE) failed to prepare.\r\n    \r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2793)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2864)\r\n        at android.app.ActivityThread.-wrap12(ActivityThread.java)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1567)\r\n        at android.os.Handler.dispatchMessage(Handler.java:105)\r\n        at android.os.Looper.loop(Looper.java:156)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6523)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:942)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:832)\r\n     Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\n    Node number 2 (FlexConv2D) failed to prepare.\r\n    \r\n    Node number 5 (WHILE) failed to prepare.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:83)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:192)\r\n        at de.xx.xx.tflite.TFLitePredict.loadModel(TFLitePredict.java:102)\r\n        at de.xx.xx.tflite.TFLitePredict.<init>(TFLitePredict.java:41)\r\n        at de.xx.xx.acquisition.AcquireActivity.onCreate(AcquireActivity.java:499)\r\n        at android.app.Activity.performCreate(Activity.java:6915)\r\n        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1123)\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2746)\r\n        \t... 9 more\r\n```\r\n\r\nWhen converting the model, a while-loop is introduced. Is there anyway to use it on a TFLite (Android)? Are there additional settings I have set when calling the converter like so: \r\n\r\n```\r\n#%% export tflite\r\nmodel = tf.keras.models.load_model('test.hdf5')\r\nmodel.summary()\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n#converter.experimental_new_converter=False\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]\r\ntflite_model = converter.convert()\r\nopen('converted_model'+str(Nx)+'_'+str(Ntime)+'_keras.tflite', 'wb').write(tflite_model)\r\n```\r\n\r\nIn Android I import tensorflow inside the ```build.gradle``` like so:\r\n\r\n```implementation  'org.tensorflow:tensorflow-lite:0.0.0-nightly'// ''```\r\n\r\n\r\nThanks\r\n", "you will also need to link the flex delegate, please see the instructions here:\r\nhttps://www.tensorflow.org/lite/guide/ops_select", "Thanks! Adding the \r\n\r\n```\r\nmplementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'\r\n```\r\nto the ```build.gradle``` solved it. \r\n\r\nBUT: The next problem is just coming. It says something about dimension mismatch - now in Android:\r\n\r\n```\r\n2020-06-11 15:09:58.477 28133-28381/de.xx.xx I/TFLitePredictor: Predicting using the TFLite model\r\n2020-06-11 15:09:58.477 28133-28381/de.xx.xx I/TFLitePredictor: Do Inference using the TFLite model\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/slice.cc Slice op only supports 1D-4D input arrays.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 44 (SLICE) failed to prepare.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 5 (WHILE) failed to invoke.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: tensorflow/lite/kernels/slice.cc Slice op only supports 1D-4D input arrays.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 44 (SLICE) failed to prepare.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 5 (WHILE) failed to invoke.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: tensorflow/lite/kernels/slice.cc Slice op only supports 1D-4D input arrays.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 44 (SLICE) failed to prepare.\r\n2020-06-11 15:09:58.622 28133-28381/de.xx.xx I/System.out: Node number 5 (W ....\r\n```\r\n\r\nI'm using tf-lite nightlies. Any idea how to solve this @renjie-liu ? \r\n\r\nThanks! ", "Seems slice does not support 5d.\r\n\r\nHi Thai, can you take a look", "Our current kernel only support 4D. \r\nThere was an effort to remove this limitation https://github.com/tensorflow/tensorflow/pull/27113\r\nBut that PR is closed now. So I will handle that.", "@beniroquai could you convert your model to tflite again with the nightly TFLite version? Your model needs to use flex version of slice op and the newer version of converter is able to handle the flex op fallback.", "Dear @abattery thanks for your quick reply; I've tested it on the nightly and get an error you can also find on [Stackoverflow](https://stackoverflow.com/questions/61362953/keras-convlstm2d-valueerror-when-saving-model): \r\n\r\n```\r\nModel: \"learn2sofi\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nx_input (InputLayer)         [(None, 491520)]          0         \r\n_________________________________________________________________\r\nreshape_6 (Reshape)          (None, 30, 128, 128, 1)   0         \r\n_________________________________________________________________\r\nconv_lst_m2d_4 (ConvLSTM2D)  (None, 128, 128, 4)       736       \r\n_________________________________________________________________\r\nbatch_normalization_4 (Batch (None, 128, 128, 4)       16        \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 128, 128, 1)       37        \r\n_________________________________________________________________\r\nup_sampling2d_4 (UpSampling2 (None, 256, 256, 1)       0         \r\n_________________________________________________________________\r\nreshape_7 (Reshape)          (None, 65536)             0         \r\n=================================================================\r\nTotal params: 789\r\nTrainable params: 781\r\nNon-trainable params: 8\r\n_________________________________________________________________\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-eb7f22429ecb> in <module>\r\n      7 #converter.experimental_new_converter=False\r\n      8 converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]\r\n----> 9 tflite_model = converter.convert()\r\n     10 open('converted_model'+str(Nx)+'_'+str(Ntime)+'_keras.tflite', 'wb').write(tflite_model)\r\n\r\n18 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/serialized_attributes.py in set_and_validate_objects(self, object_dict)\r\n    210           raise ValueError(\r\n    211               'Object dictionary contained a non-trackable object: {} (for key'\r\n--> 212               ' {})'.format(object_dict[key], key))\r\n    213         self._object_dict[key] = object_dict[key]\r\n    214         setattr(self._keras_trackable, key, object_dict[key])\r\n\r\nValueError: Object dictionary contained a non-trackable object: (None, None) (for key states)\r\n```\r\n\r\nI'm working on google colab and execute this code: \r\n\r\n\r\n```\r\n#%% export tflite\r\nNx = 256\r\nNtime = 30\r\nmodel = tf.keras.models.load_model('test.hdf5')\r\nmodel.summary()\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]\r\ntflite_model = converter.convert()\r\nopen('converted_model'+str(Nx)+'_'+str(Ntime)+'_keras.tflite', 'wb').write(tflite_model)\r\n```\r\n\r\nAny idea? Thanks! ", "I suspect that the some keras layers do not have a name. Could you make sure that every keras layer has a name to be serialized?", "Just to clarify the term \"name\". You mean the name for a given layer, right? I double checked it and checked the output of model.print:\r\n\r\n```\r\nModel: \"learn2sofi\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nx_input (InputLayer)         [(None, 491520)]          0         \r\n_________________________________________________________________\r\nreshape_1d_2d (Reshape)      (None, 30, 128, 128, 1)   0         \r\n_________________________________________________________________\r\nconvlstm2d_1 (ConvLSTM2D)    (None, 128, 128, 4)       736       \r\n_________________________________________________________________\r\nbatchnorm_1 (BatchNormalizat (None, 128, 128, 4)       16        \r\n_________________________________________________________________\r\nconv_1 (Conv2D)              (None, 128, 128, 1)       37        \r\n_________________________________________________________________\r\nupsampling_1 (UpSampling2D)  (None, 256, 256, 1)       0         \r\n_________________________________________________________________\r\nreshape_2d_1d (Reshape)      (None, 65536)             0         \r\n=================================================================\r\nTotal params: 789\r\nTrainable params: 781\r\nNon-trainable params: 8\r\n_________________________________________________________________\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-11-eb7f22429ecb> in <module>\r\n      7 #converter.experimental_new_converter=False\r\n      8 converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]\r\n----> 9 tflite_model = converter.convert()\r\n     10 open('converted_model'+str(Nx)+'_'+str(Ntime)+'_keras.tflite', 'wb').write(tflite_model)\r\n\r\n18 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/serialized_attributes.py in set_and_validate_objects(self, object_dict)\r\n    210           raise ValueError(\r\n    211               'Object dictionary contained a non-trackable object: {} (for key'\r\n--> 212               ' {})'.format(object_dict[key], key))\r\n    213         self._object_dict[key] = object_dict[key]\r\n    214         setattr(self._keras_trackable, key, object_dict[key])\r\n\r\nValueError: Object dictionary contained a non-trackable object: (None, None) (for key states)\r\n```\r\n\r\nEach layer should have a name, but the error stays the same. The training ran on TF2.2.0, converting in colab on TF-nightly. Could this be an issue?", "I tested training, saving and exporting on TF-nightly, but it gave the same error. ", "@k-w-w could you help us to avoid the above error?", "@beniroquai could you share very simple steps from scratch, that can reproduce the error?", "Certainly. I've added a [Google Colab](https://colab.research.google.com/drive/1_GJKcha7S_J_s0JitunMWd4I2dMx4KC4?usp=sharing) which does everything I need but without the training/testing. \r\nDoes this work?", "@beniroquai May be this is not a tflite issue. I tried saving the model in 'tf' format which throws the same error as you mentioned. For some reason, when you save the model in 'h5' format, it is not throwing error but throws the same error during execution of `convert.convert`.\r\n\r\nI replaced this line `model.save('test.hdf5')` with `model.save('test',save_format='tf')`.\r\n\r\nError trace is as follows\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-204f3c69e426> in <module>()\r\n----> 1 model.save('test',save_format='tf')\r\n\r\n17 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/serialized_attributes.py in set_and_validate_objects(self, object_dict)\r\n    210           raise ValueError(\r\n    211               'Object dictionary contained a non-trackable object: {} (for key'\r\n--> 212               ' {})'.format(object_dict[key], key))\r\n    213         self._object_dict[key] = object_dict[key]\r\n    214         setattr(self._keras_trackable, key, object_dict[key])\r\n\r\nValueError: Object dictionary contained a non-trackable object: (None, None) (for key states)\r\n```", "@jvishnuvardhan Maybe I don't quiet understand what you mean, but I also tried to forgo the step of saving and loading the keras model so that the model is getting converted using the tflite converter directly, but the error stays the same. \r\nI've updated the [Colab](https://colab.research.google.com/drive/1_GJKcha7S_J_s0JitunMWd4I2dMx4KC4?usp=sharing) and followed [this advice](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/python_api.md). \r\n\r\nUnfortunately I cannot say if it's a tflite or keras problem. ", "Can you try the conversion with tf-nightly? We actually land some changes for increasing robustness on storing saved model and converting keras model.", "Note that the new fixes will be included in nightly tomorrow.", "Hey, tomorrow means \"now\"? I've tested it and the Android APP gives a different error:\r\n\r\n```\r\n2020-06-19 11:54:29.708 13744-14514/de.xx.xxI/STORMimager_AcquireActivity: All frames have been accumulated\r\n2020-06-19 11:54:29.708 13744-14514/de.xx.xxI/TFLitePredictor: Predicting using the TFLite model\r\n2020-06-19 11:54:29.708 13744-14514/de.xx.xxI/TFLitePredictor: Do Inference using the TFLite model\r\n2020-06-19 11:54:29.708 13744-14514/de.xx.xxI/System.out: java.lang.NullPointerException: Attempt to invoke virtual method 'void org.tensorflow.lite.Interpreter.run(java.lang.Object, java.lang.Object)' on a null object reference\r\n2020-06-19 11:54:29.708 13744-14514/de.dd.dd I/System.out: ProcessingThread Stopped.\r\n```\r\n\r\nbut the good thing is: The model gets exported! ", "One comment; It happens when I call the tflite.run() routine:\r\n\r\n![image](https://user-images.githubusercontent.com/4345528/85138623-60836c00-b243-11ea-9fbd-7aebcff66dfd.png)\r\n\r\nand the error in the catch blox is not called explicitly. Any idea what this means? ", "I think the issue is related to this posted on [Stack Overflow](https://stackoverflow.com/questions/60767578/tensorflow-lite-on-android-how-can-i-define-the-input-and-output-of-runformult). \r\nI have an input and output tensor of 1xN and 1xM. What should be the float array look-like in Java then? In a pure tensorflow tflite model the code above works fine, in Keras not. I suppose it has something to do with the batch dimensions? I need to convert the 3d image stack to a 1d array in order to handle it with tflite, maybe keras works different here? \r\n\r\nThis is the input:\r\n![image](https://user-images.githubusercontent.com/4345528/85952111-6f66ce80-b967-11ea-9324-b95f231ab6f6.png)\r\n\r\nThis is the output:\r\n![image](https://user-images.githubusercontent.com/4345528/85952129-83123500-b967-11ea-9c50-71eab3bb049c.png)\r\n", "Sorry, my fault, I loaded an old model. It works now.", "I cannot convert a model composed by a single ConvLSTM2D layer into tflite. The issue persists in tensorflow 2.3.0. I have also tried with tf-nightly 2.4.0-dev20200910 and the error is the same:\r\n\r\n`ValueError: Input 0 of node sequential/conv_lst_m2d/AssignVariableOp was passed float from sequential/conv_lst_m2d/convolution_4/ReadVariableOp/resource:0 incompatible with expected resource.`\r\n\r\nSee this [colab gist](https://gist.github.com/edumotya/47e15c700bc008d5f5a8460319022aeb).", "@edumotya could you try saved model converter instead of keras converter with tf-nightly? From tf-nightly, TF v2 saved model converter only can solve some issues regarding resource type issues.", "Yes, thank you @abattery, I haved tried it. It raises a different error:\r\n\r\n`ConverterError: <unknown>:0: error: loc(\"conv_lst_m2d/Variable\"): is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable\r\n<unknown>:0: note: loc(\"conv_lst_m2d/Variable\"): see current operation: \"tf_saved_model.global_tensor\"() {is_mutable, sym_name = \"conv_lst_m2d/Variable\", type = tensor<1x10x10x32xf32>, value = dense<0.000000e+00> : tensor<1x10x10x32xf32>} : () -> ()`\r\n\r\nSee this [colab gist](https://colab.research.google.com/gist/edumotya/4034961546de66327a6ae29023c16c41/convlstm2d-savedmodel-tflite.ipynb).", "@edumotya I can reproduce your error in my side. Will take a look.", "Any updates on this @abattery? Do you mind to re-open it? ", "I too have the same issue. Any insights would be helpful.", "Any updates on this? Why is this issue closed? ", "any updates?? I wanna run my convLSTM on coral TPU that requires a TFlite extension model ..", "Well, I think it is resolved, or? Did you try Anything above TF2.3? I got it to work in Tensorflow Lite on Android. You can have a look [here](https://github.com/beniroquai/dSTORM-on-the-chea-i-p-Learn2Fluct). I don't know if the documentation works out for you. Let me know if there is something missing. \r\n", "oh, I just see your repo that you use .hdf5 instead of .h5, after I retrain my model and save it to hdf5 then it can convert to tflite, thanks a lot!!!", "> Well, I think it is resolved, or? Did you try Anything above TF2.3? I got it to work in Tensorflow Lite on Android. You can have a look [here](https://github.com/beniroquai/dSTORM-on-the-chea-i-p-Learn2Fluct). I don't know if the documentation works out for you. Let me know if there is something missing.\r\n\r\nWell, you still need a flex delegate to wrap the tensorflow (not tf-lite) options, so I wouldn't consider this solved.", "Please file a new issue for further requests in order to keep each issue focused.", "> \r\n> \r\n> Well, I think it is resolved, or? Did you try Anything above TF2.3? I got it to work in Tensorflow Lite on Android. You can have a look [here](https://github.com/beniroquai/dSTORM-on-the-chea-i-p-Learn2Fluct). I don't know if the documentation works out for you. Let me know if there is something missing.\r\n\r\n@beniroquai Is `convlstm` is supported on GPU as well?\r\nIt's working on CPU but when trying to use GPU delegate it's throwing the following error:\r\n`java.lang.IllegalArgumentException:` Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`", "Hey, not sure if I remember correctly, but I guess it worked at least on\nLinux.\n\n>\n", "> \r\n> Hey, not sure if I remember correctly, but I guess it worked at least on Linux.\r\n> [\u2026](#)\r\n\r\n@beniroquai ya on PCs it's working but on Android like delegating to SD845, 855 or any processor's GPU it's failing"]}, {"number": 38219, "title": "Tensorflow version downgrade ", "body": "ModuleNotFoundError: No module named 'tensorflow.contrib' \r\nThis is the error i keep getting when i try to load my video file for YOLO object detection using darkflow. I tried using pip to downgrade the tensorflow version but its not changing the output.\r\n", "comments": ["Hey, @Mahati04  would you please provide your code so that we'll try to replicate the error in our machine?\r\n", "@Mahati04 \r\nplease share tensorflow version and simple stand alone code for us to replicate the issue faced.\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nAs per error faced check these existing issues.\r\n##37720 #36419 #30794 #36269  #36878 #32147 #35197 #31350 #34083 #27084 #32621\r\n", "You have to do `pip list`; identify all packages in the tensorfow ecosystem (estimator, tensorboard, tensorflow), `pip uninstall` each one of them and then install again those you need at 1.15.\r\n\r\n`contrib` does not exist in 2.0 and later.", "@Mahati04\r\nplease update on above comments", "> You have to do `pip list`; identify all packages in the tensorfow ecosystem (estimator, tensorboard, tensorflow), `pip uninstall` each one of them and then install again those you need at 1.15.\r\n> \r\n> `contrib` does not exist in 2.0 and later.\r\n\r\nI uninstalled everything that you say. i try to install tensorflow 1.15.0 but i got error. \"couldnt find a version that satisfies the requirement tensorflow==1.15.0\" \r\n\r\nbefore that i tried to run object detection model_builder_test.py file but i got error also \"ModuleNotFoundError: No module named 'tensorflow.contrib'\"\r\n\r\nwhat should i do ?", "@nihalb7 \r\nplease share your system information", "[info.txt](https://github.com/tensorflow/tensorflow/files/4476885/info.txt)\r\n I have tf 1.14 im not try to downgrade, i try to upgrade to 1.15", "Please open a new issue since this is about a downgrade.\r\n\r\nPlease fill in **all questions** in the issue template", "@Mahati04\r\nplease update if this is still an issue", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38219\">No</a>\n"]}, {"number": 38218, "title": "Smart compose using tensorflow", "body": "Hey I am trying to create a API which can smart compose. Anyone that can help me out ?\r\n", "comments": ["@swaroop23,\r\n\r\nCould you please elaborate the issue you are facing? Thanks!", "This is not the place for this question. Please try StackOverflow.\r\n\r\nHere we only accept issues strictly related to code of TF."]}, {"number": 38217, "title": "load_model cause memory leak.", "body": "model = load_model('.\\Models\\LSTM-RAdam-batchsize50-Data5040\\Algorithm-LSTM-RAdam-batchsize50-Data5040-0.h5')\r\nif i use tensorflow2.0 will got this bug,and tensorflow2.1.0 no this bug.\r\n\r\n\r\nsave.py 146  2020-04-04 20:14:39.885989\r\nhdf5_format.py 153  2020-04-04 20:14:39.886990\r\nhdf5_format.py 159  2020-04-04 20:14:39.886990\r\nmodel_config.py 54  2020-04-04 20:14:39.890988\r\nhdf5_format.py 169  2020-04-04 20:14:45.900547\r\nhdf5_format.py 172  2020-04-04 20:14:46.118488\r\noptimizer_v2.py 253  2020-04-04 20:14:46.118488\r\nhdf5_format.py 185  2020-04-04 20:14:48.779033\r\nhdf5_format.py 193  2020-04-04 20:14:48.779033\r\ntraing.py 2094  2020-04-04 20:14:48.779033\r\ntraing.py 2112  2020-04-04 20:14:48.822994\r\ntraing.py 2116  2020-04-04 20:14:48.823996\r\noptimizer_v2.py 501  2020-04-04 20:14:48.823996\r\noptimizer_v2.py 390 2020-04-04 20:14:48.823996\r\noptimizer_v2.py 393  2020-04-04 20:14:48.824993\r\ngradients_impl.py 154  2020-04-04 20:14:48.824993\r\ngradients_impl.py 156  2020-04-04 20:14:48.824993\r\ngradients_util.py 504  2020-04-04 20:14:48.824993 513.27 MB   0\r\ngradients_util.py 680  <function _AddGrad at 0x0000024A9360BD90>\r\n_MaybeCompile 340  513.27 MB  \r\n_MaybeCompile 350  513.27 MB  \r\n_MaybeCompile 358  <function _GradientsHelper.<locals>.<lambda> at 0x0000024AA779C730> 513.27 MB  \r\ngradients_util.py 682 \r\ngradients_util.py 711 \r\n...\r\n...\r\ngradients_util.py 711 \r\ngradients_util.py 680  <function _IfGrad at 0x0000024A9609A488>\r\n_MaybeCompile 340  544.09 MB  \r\n_MaybeCompile 350  544.09 MB  \r\n_MaybeCompile 358  <function _GradientsHelper.<locals>.<lambda> at 0x0000024AAC1750D0> **544.09** MB  \r\ngradients_util.py 504  2020-04-04 20:14:52.229995 **571.5** MB   1\r\ngradients_util.py 680  <function _IdGrad at 0x0000024A935BCE18>\r\n_MaybeCompile 340  571.5 MB  \r\n...\r\n...\r\ngradients_util.py 680  <function _IfGrad at 0x0000024A9609A488>\r\n_MaybeCompile 340  2058.01 MB  \r\n_MaybeCompile 350  2058.01 MB  \r\n_MaybeCompile 358  <function _GradientsHelper.<locals>.<lambda> at 0x0000024B0A7B08C8> **2058.01** MB  \r\ngradients_util.py 504  2020-04-04 20:15:10.104159 **2101.93** MB   84\r\n\r\n\r\ngradients()-->_GradientsHelper()-->_MaybeCompile()-->grad_fn()(_GradientsHelper)\r\n\r\n", "comments": ["@jackyesf, Tensorflow 2.1 is latest stable release, which has new features and many fixes compared to Tf2.0. It would be good to use Tf 2.1. Thanks", "I try to use Tf2.1 and got another bug.\r\nthe Tf got 5 batch data then start train,I don't know when why?the same soure code run in another computer with cpu don't have this problem.\r\n\r\nhistory = model.fit(train_generator,\r\n                    steps_per_epoch=5,#582,\r\n                    epochs=2,\r\n                    workers=0,\r\n                    shuffle=False,\r\n                    callbacks=callbacks_log,\r\n                    max_queue_size=1,\r\n                    use_multiprocessing=False)\r\n2017-02-13 is open day\r\ntotal_count: 50   Time:  0 : 0 : 24   ReadTime:  0.4885924999999993\r\ndate:   2020-04-06 20:08:05.283358\r\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\r\n 0. 0.]\r\nTrain for 5 steps\r\nEpoch 1/2\r\n\r\n2017-02-14 is open day\r\ntotal_count: 100   Time:  0 : 1 : 22   ReadTime:  0.146348500000002\r\ndate:   2020-04-06 20:09:03.293034\r\n[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0.]\r\n\r\n2017-02-15 is open day\r\ntotal_count: 150   Time:  0 : 2 : 10   ReadTime:  0.17794280000001095\r\ndate:   2020-04-06 20:09:51.197738\r\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0.]\r\n\r\n2017-02-16 is open day\r\ntotal_count: 200   Time:  0 : 2 : 23   ReadTime:  0.1687238000000093\r\ndate:   2020-04-06 20:10:04.233256\r\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\r\n 1. 0.]\r\n\r\n2017-02-17 is open day\r\ntotal_count: 250   Time:  0 : 2 : 36   ReadTime:  0.14867739999999685\r\ndate:   2020-04-06 20:10:16.904404\r\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\r\n 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\r\n 0. 0.]\r\n1/5 [=====>........................] - ETA: 9:13 - loss:  0.0420", "@jackyesf, Could you share the complete standalone code to analyze the issue. Thanks ", "It's too big to upload the code and data .", "I tracing in traing the LSTM layers is tensorflow.python.keras.layers.recurrent_v2.LSTM\r\n\r\nnetwork.py,888  _run_internal_graph False <tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x000001B05E6BC518>\r\n\r\nbut after save the model and reload it ,I found the LSTM layers changed to ensorflow.python.keras.layers.recurrent.LSTM \r\n\r\nmodel = tf.keras.models.load_model('.\\\\Models\\\\LSTM-RAdam-batchsize50\\\\AlgorithmLSTM-RAdam-batchsize.h5',\r\n                                                                   custom_objects={'binary_focal_loss': binary_focal_loss,\r\n                                                                   'binary_focal_loss_fixed':binary_focal_loss_fixed})\r\nhistory = model.fit(train_generator,\r\n                            steps_per_epoch=1,#582,\r\n                            epochs=2,\r\n                            workers=0)\r\nnetwork.py,888  _run_internal_graph False <tensorflow.python.keras.layers.recurrent.LSTM object at 0x000001CB28747F98>", "https://www.tensorflow.org/guide/keras/save_and_serialize?hl=zh_cn#saving_subclassed_models\r\nPart II: Saving and Loading of Subclassed Models\r\nmodel.save('path_to_my_model',save_format='tf')\r\neven i follow the instructon on the guide ,still got the same problem", "I found this bug fixed on tensorflow2.2.0rc3", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38217\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38217\">No</a>\n"]}, {"number": 38216, "title": "[saved_model_cli] cannot import name 'saved_model_aot_compile' from 'tensorflow.python.tools'  [2.2.0-rc2]", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): yes\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below):  v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2\r\n- Python version: 3.7.6\r\n- Bazelversion (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: - GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n`saved_model_cl`i\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/tarrade/anaconda-release/conda-env/env_test/bin/saved_model_cli\", line 5, in <module>\r\n    from tensorflow.python.tools.saved_model_cli import main\r\n  File \"/Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 51, in <module>\r\n    from tensorflow.python.tools import saved_model_aot_compile\r\nImportError: cannot import name 'saved_model_aot_compile' from 'tensorflow.python.tools' (/Users/tarrade/anaconda-release/conda-env/env_test/lib/python3.7/site-packages/tensorflow/python/tools/__init__.py)\r\n```\r\n\r\n**Describe the expected behavior**\r\nwith TF 2.1:\r\n`saved_model_cli`\r\n```\r\nusage: saved_model_cli [-h] [-v] {show,run,scan,convert} ...\r\nsaved_model_cli: error: too few arguments\r\n```\r\nand if we pass all needed argument then it is working as expected\r\n\r\n**Standalone code to reproduce the issue** \r\njust use the command line:\r\n`saved_model_cli`\r\n", "comments": ["@tarrade \r\nThis has been noted and it will be taken care in next release, please refer to [this comment](https://github.com/tensorflow/tensorflow/issues/38042#issuecomment-608036111)\r\n\r\nplease confirm if we may move this to closed status as its already noted to be taken care.", "@Saduf2019 sorry, I tried to look at existing tickets and I missed the already existing one since it was already closed. It is a duplicate so you can close it. Thanks", "moving this to closed status with confirmation", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38216\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38216\">No</a>\n", "I have saved model using serving with TF version 1.14.0. \r\nI want to run: saved_model_cli.py and I have the same error. \r\nAny update ?\r\n"]}, {"number": 38215, "title": "iterating over `tf.Tensor` is not allowed when using autograph", "body": "I am using tf2.1.0, but when I use `tf.range` within a funtion decorated by `tf.function` it throw an error. My code is blow\r\n```\r\nfor batch in tf.range(batch_size):\r\n    pass\r\n```\r\nand here is the error message\r\n```\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function\r\n```\r\nIt works for tf2.0.0\r\n\r\nSo, I wonder how to use `tf.range` when using **Autograph**.", "comments": ["@xqiangx1991 Please be more specific and provide a minimal reproducible code snippet. The description you provided is not very clear to reproduce.", "@xqiangx1991  Any updates regarding this issue? Thanks!", "@xqiangx1991,\r\nCould you please check [this comment](https://github.com/tensorflow/tensorflow/issues/33308#issuecomment-542565633) from a similar issue and let us know if it works? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38214, "title": "Updated categorical_hinge loss docs in losses.py", "body": "Fixes : #38199 ", "comments": ["@ManishAradwad  Can you please check @fchollet's comments and keep us posted ? Thanks!", "@ManishAradwad  Any update on this PR? Please. Thanks!", "Hello @gbaned,\r\nSorry for not being in touch. At this moment, I won't be able to work on this one for a while. Please, feel free to assign it to someone else.\r\nThanks!"]}, {"number": 38213, "title": "[XLA:GPU] Memory Leak in r1.15 due to defer host callbacks", "body": "**System information** \r\n- Have I written custom code: \r\nyes\r\n- OS Platform and Distribution: \r\ncentos\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n`pip install tensorflow-gpu==1.15.0`\r\n- Python version:\r\npython3.6\r\n- CUDA/cuDNN version: - GPU model and memory:\r\ncuda 10.0\r\n\r\n**Describe the current behavior**\r\nThere is memory leak observed in `ThenRunAfterNextBlockHostUntilDone` when XLA is turned on. The reason for the memory leak is that in tensorflow `BlockHostUntilDone()` is not called and large amount of defered callback was accumulated.\r\n\r\n**Describe the expected behavior**\r\nNo memory leaking in the function mentioned above.\r\n\r\n**Standalone code to reproduce the issue** \r\nProbably any code that use XLA in r1.15.\r\n\r\n**Other info / logs** \r\nThe memory leaking problem was solved in master branch in commit 80851c0ad. I wonder if I can help to cherry-pick it to r1.15? Because it would be inconvenient to upgrade tf in our environment.\r\n", "comments": ["@zhuzilin,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code sample to reproduce the issue reported here. Thanks!", "@zhuzilin,\r\nAny updates regarding the reproducible code? Thanks!", "@amahendrakar I've submitted the pr for this bug in #38292. Please feel free to close this issue.", "Thank you for the update @zhuzilin. Marking this issue as closed."]}, {"number": 38212, "title": "tf.py_function could return a dictionary of tensors", "body": "Usually, a transformers tokenizer encodes an input as a dictionary.\r\n```python\r\n{\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}\r\n```\r\nAnd to archive better performance handling with a large dataset, is a good practice implement a pipeline which includes using [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply a tokenizer function to each element of an input dataset. Exactly the same as done in the Tensorflow tutorial: [Load text](https://www.tensorflow.org/tutorials/load_data/text#encode_examples). \r\n\r\nHowever, the [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) (used to wrap the map python function) doesn't support returning a dictionary of tensors as shown above.\r\n\r\nFor instance, if the tokenizer (encoder) in the [Load text](https://www.tensorflow.org/tutorials/load_data/text#encode_examples) returns the following dictionary:\r\n\r\n```python\r\n{\r\n    \"input_ids\": [ 101, 13366,  2131,  1035,  6819,  2094,  1035,  102 ],\r\n    \"attention_mask\": [ 1, 1, 1, 1, 1, 1, 1, 1 ]\r\n}\r\n```\r\nhow can someone set the `Tout` parameter of the [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) to get the desired dictionary of tensors:\r\n\r\n```python\r\n{\r\n    'input_ids': <tf.Tensor: shape=(16,), dtype=int32, numpy = array(\r\n    [ 101, 13366,  2131,  1035,  6819,  2094,  1035,  102 ], dtype=int32)>\r\n\r\n    'attention_mask': <tf.Tensor: shape=(16,), dtype=int32, numpy=array(\r\n     [ 1, 1, 1, 1, 1, 1, 1, 1 ], dtype=int32)>\r\n}\r\n```\r\n?\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["I think this would be a nice feature but I think you can work around this limitation by constructing your py_function appropriately as tf.data supports dictionaries\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef tokenizer(x):\r\n  return { \"input_ids\": [ 101, 13366,  2131,  1035,  6819,  2094,  1035,  102 ], \"attention_mask\": [ 1, 1, 1, 1, 1, 1, 1, 1 ]}\r\n\r\ndef py_func(x):\r\n  d = tokenizer(x)\r\n  return list(d.values())\r\n\r\ndef ds_map_fn(x):\r\n  flattened_output = tf.py_function(py_func, [x], [tf.int32, tf.int32])\r\n  return {\"input_ids\": flattened_output[0], \"attention_mask\": flattened_output[1]}\r\n\r\nds = tf.data.Dataset.range(2)\r\nds = ds.map(ds_map_fn)\r\n\r\nfor value in ds:\r\n  print(value)\r\n```", "See also the related issue #27679, concerned with `py_function` accepting dictionaries of tensors. I would really like to see both features implemented in TensorFlow. In real-world problems, data with heterogeneous features is quite common, and managing such features is made unnecessarily complicated by poor support for feature dictionaries.", "@rohan100jain,\r\nAlthough the limitation of  ` tf.py_function` I could use it to encode my dataset. Thank you.", "@novog, it would be great.", "Absolutely. It is very useful."]}, {"number": 38211, "title": "Missing Trainable Variables and Variables", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 19.04\r\n- TensorFlow installed from (source or\r\nbinary): TF 2.1 installed from pip\r\n- Python version: Python 3.7.5\r\n\r\n\r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\r\nimport tensorflow as tf\r\n\r\nclass FooLayer(tf.keras.layers.Layer):\r\n    def __init__(self, siz):\r\n        super(FooLayer, self).__init__()\r\n        self.siz = siz\r\n        self.buildFoo(siz)\r\n\r\n    def call(self, in_data):\r\n        Foo0 = tf.multiply(in_data,self.FooTns0)\r\n        FooList = []\r\n        FooList.append(Foo0)\r\n        for it in range(1,self.siz+1):\r\n            tmp = tf.multiply(FooList[it-1],self.FooTns[it-1])\r\n            FooList.append(tmp)\r\n        return FooList[self.siz]\r\n\r\n    def buildFoo(self,siz):\r\n        self.FooTns0 = tf.Variable(1, name=\"TNS0\")\r\n        self.FooTns = []\r\n        for it in range(0,self.siz):\r\n            self.FooTns.append(tf.Variable(it, name=\"TNS\"+str(it+1)))\r\n\r\nclass FooModel(tf.keras.Model):\r\n    def __init__(self, siz):\r\n        super(FooModel, self).__init__()\r\n        self.flayer = FooLayer(siz)\r\n\r\n    def call(self, in_data):\r\n        return self.flayer(in_data)\r\n\r\nmodel = FooModel(5)\r\n\r\nfor v in model.trainable_variables:\r\n    print(v.name)\r\n\r\nfor v in model.variables:\r\n    print(v.name)\r\n```\r\n\r\n\r\nThe output currently is only:\r\n```\r\nTNS0:0\r\nTNS0:0\r\n```\r\n\r\nWhile the expected output is listing all 6 tensors, ''self.FooTns0'' and ''self.FooTns''.", "comments": ["i am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/38d3adcbe02fb9e977f93f2e7b7f05fc/38211.ipynb)", "Thank you @Saduf2019 .\r\n@jvishnuvardhan , could you please let me know whether this is a bug in tensorflow 2? Is there an easy way to work around this python array? In my complicated code, the variables are of different sizes and I cannot simply concatenate them as a bigger tensor.", "@YingzhouLi, As you haven't called for the call function, thatswhy it isn't being concatenated and is not showing all 6 vectors. Probably certain changes might help in showing all 6 vectors and finally call function will concatenate all of the vectors-\r\nPlease find the changes here-[colab_link](https://colab.research.google.com/gist/gulshanrana10/ea4520455f4591ed0364ea58aab229d6/38211.ipynb#scrollTo=E5fQvwtPByRJ)", "@gulshanrana10 Thank you very much for the fix. It works. However, I am very much confused by the mechanism behind this. I am relatively new to python but familiar with C++ class. Why tensorflow cannot catch self.FooTns directly, which is also a member of the class as self.array in __init__?", "Thanks for reporting the issue, it seems to be a bug in layer weight tracking logic. There are a few walkaround at the moment when we fix the issue:\r\n\r\n1. Change the base class to tf.keras.Model, which currently track the weights correclty.\r\n2. Use layer.add_weights() and append the result into your list, which also will do the correct thing.", "Thank you. It is good to know that the issue is not caused by some unknown nature of python. The workaround works for me and look forward to the update.", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210525, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/c8deb719cbc70f6cd7be79497706dee9/untitled7.ipynb). Thanks!", "Was able to reproduce your issue in `TFv2.7` and `Tf Nightly(2.8.0-dev20211125)`, please find the [gist here](https://colab.research.google.com/gist/chunduriv/bff1e6d60d9afaa378010747d3a7f31e/38211.ipynb#scrollTo=QZZw5cVktLNJ). Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38211\">No</a>\n"]}, {"number": 38210, "title": "optimize keyword argument for tf.einsum", "body": "I am trying to use the ```optimize``` keyword argument for the einsum operation, but I receive the following error:\r\n\r\n```\r\n    ....\r\n    my_path/file.py:27 basis_transform_conv2d  *\r\n        out = tf.einsum('bhwcfg,fgcu->bhwfgu', x_col, basis, optimize='optimal')\r\n    Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\special_math_ops.py:252 einsum\r\n        [format(key) for key in sorted(list(kwargs.keys()))]))\r\n\r\n    TypeError: invalid keyword arguments for this function: optimize\r\n```\r\n\r\nI am currently using tensorflow-gpu==2.0.0 with up-to-date CUDA, cudnn (everything else works fine).\r\nIt is to my understanding that tensorflow is calling the legacy einsum operation, einsum_v1 : https://github.com/tensorflow/tensorflow/blob/44d3065391ea2188979ff2e747f4e7b789edd2e6/tensorflow/python/ops/special_math_ops.py#L407\r\n\r\nHow do I ensure my code calls einsum_v2, which supports the ```optimize``` keyword argument?", "comments": ["@roymiles, Can you provide the minimal code snippet to replicate the reported issue. Thanks!", "```\r\nimport tensorflow as tf\r\n\r\na = tf.zeros(shape=(100, 100))\r\nb = tf.zeros(shape=(100, 300))\r\n\r\nc = tf.einsum('ij,jk->ik', a, b, optimize=True)\r\n```\r\n\r\nThis is enough to reproduce the error. In the documentation, **kwargs should allow an `optimize` keyword argument, similar to np.einsum.\r\n\r\nIn case anyone is having the same problem, https://optimized-einsum.readthedocs.io/en/stable/ is a good solution that supports tensorflow GPU backend.", "I could reproduce the issue with Tf 2.0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5468d5657551c0061b482b500c99bc1a/untitled493.ipynb). Thanks!", "@roymiles,\r\nThis issue is fixed in Tf 2.2.rc1\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/8da934854e3a5f83e9311f9ef740788e/untitled494.ipynb). Thanks!", "@roymiles \r\nThis issue was resolved in  TF version 2.2.rc1 .Please verify once and close the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38210\">No</a>\n"]}, {"number": 38209, "title": "Support negative axis for tf.signal.fftshift", "body": "\r\nThis PR tries to address the issue raised in #38172 where\r\nnegative axis is not supported for tf.signal.fftshift\r\n\r\nThis PR use tf.where to adjust the axis when it is less than zero.\r\n\r\nThis PR fixes #38172.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @alextp for the review. The PR has been updated."]}, {"number": 38208, "title": "Fix TPU `saved_model.save` with SyncOnReadVariable.", "body": "PiperOrigin-RevId: 304032507\nChange-Id: I93abd43d43351b50eff544fbf4e2d5ef3a26fe17", "comments": []}, {"number": 38207, "title": "Idk", "body": "\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Current revision enterprise:\r\n- **TensorFlow installed from (source or binary)**: Using Pip \r\n- **TensorFlow version (use command below)**:2.1(Tensorflow wont even let me check\r\n- **Python version**:3.7.7\r\n- **CUDA/cuDNN version**:10.1.243; 7.6.5.32;\r\n- **GPU model and memory**:gtx 1060 6gb\r\n- **TensorRT**: 6.0.1.5\r\n- **Exact command to reproduce**:Legit any tf command I\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI'm unsure what the error in my config is I believe I have everything installed properly everything is in the path directories as they should be but I still get this error.\r\n\r\n### Source code / logs\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\H4MST3R\\Desktop\\Rock-Paper-Scissors-Image-Classifier-Using-Deep-Learning\\gather_images.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\H4MST3R\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "you didn't check for duplicates.\r\n\r\nClosing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204"]}, {"number": 38205, "title": "[XLA] bazel tests broken", "body": "When running XLA C++ tests with bazel, many of them fails with an error like:\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/compiler/xla/client/lib:arithmetic_test_gpu\r\n-----------------------------------------------------------------------------\r\n[==========] Running 4 tests from 1 test suite.\r\n[----------] Global test environment set-up.\r\n[----------] 4 tests from ArithmeticTest\r\n[ RUN      ] ArithmeticTest.ArgMinR2Axis0\r\n2020-04-03 16:57:48.451927: I tensorflow/compiler/xla/service/platform_util.cc:72] platform CUDA present but no XLA compiler available: could not find registered compiler for platform CUDA -- check target linkage (hint: try linking in tensorflow/compiler/jit:xla_gpu_jit)\r\n2020-04-03 16:57:48.451981: F tensorflow/compiler/xla/tests/client_library_test_base.cc:48] Non-OK-status: result.status() status: Not found: no platforms found could not create local client for testing\r\nexternal/bazel_tools/tools/test/test-setup.sh: line 310: 14802 Aborted                 (core dumped) \"${TEST_PATH}\" \"$@\" 2>&1\r\n```\r\n\r\nHow to reproduce:\r\n\r\n```\r\ndocker run --gpus all -it --rm tensorflow/tensorflow:devel-gpu /bin/bash\r\ncd /tensorflow_src\r\n./configure\r\ngit show\r\n```\r\n```\r\ncommit 09910a17749e7836462b843b537ffeccd302d260 (HEAD -> master, origin/master,\r\norigin/HEAD)\r\nAuthor: A. Unique TensorFlower <gardener@tensorflow.org>\r\nDate:   Tue Mar 31 04:44:27 2020 -0700\r\n\r\n    Fixed accumulator precision for generic DepthWise implementation.\r\n    Removed inlined constants for kernel sizes.\r\n\r\n    PiperOrigin-RevId: 303938922\r\n    Change-Id: I4f1359341b8aa4a9c70b4c9f786657e5cbfdf645\r\n```\r\n```\r\nbazel test -j 24 --config=opt -s  --config=noaws --config=nogcp --config=nohdfs --verbose_failures --config=cuda --cache_test_results=no --runs_per_test=1 --flaky_test_attempts=1 --test_tag_filters=gpu //tensorflow/compiler/xla/client/lib:arithmetic_test\r\ncat /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/client/lib/arithmetic_test_gpu/test.log\r\n```\r\n\r\nSee error above:\r\n\r\nNow try with the current HEAD:\r\n\r\n```\r\ngit pull\r\ngit show\r\n```\r\n```\r\ncommit f0571998d0195b5b243cf409a64d5fa17bd44d43 (HEAD -> master, origin/master, origin/HEAD)\r\nMerge: 2921d2ed93 2082d706a5\r\nAuthor: TensorFlower Gardener <gardener@tensorflow.org>\r\nDate:   Fri Apr 3 09:29:53 2020 -0700\r\n\r\n    Merge pull request #34218 from Flamefire:fix_missing_linker_path\r\n\r\n    PiperOrigin-RevId: 304630859\r\n    Change-Id: I3e412ed958acd0d60c8ddbdb22fd59ddf9caf05b\r\n```\r\n```\r\nbazel test -j 24 --config=opt -s  --config=noaws --config=nogcp --config=nohdfs --verbose_failures --config=cuda --cache_test_results=no --runs_per_test=1 --flaky_test_attempts=1 --test_tag_filters=gpu //tensorflow/compiler/xla/client/lib:arithmetic_test\r\ncat /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/client/lib/arithmetic_test_gpu/test.log\r\n```\r\n\r\nSame error.\r\n\r\n\r\nI have this on 2 different computers.", "comments": ["@nouiz \r\nas there is a PR to monitor this, please let us know if we may move this to closed status", "Which PR fix this? #38136 development is blocked by this issue.", "Would it work with the flag --noincompatible_do_not_split_linking_cmdline? We have seen this in some other tests as well that they only work when passing this flag to bazel.", "I tried with that flag with this command : `bazel test --config=nonccl --noincompatible_do_not_split_linking_cmdline --config=opt --config=cuda --cache_test_results=no //tensorflow/compiler/xla/client/lib:arithmetic_test`\r\nAnd an extra flag with this command: `bazel test --config=nonccl --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --noincompatible_do_not_split_linking_cmdline --config=opt --config=cuda --cache_test_results=no //tensorflow/compiler/xla/client/lib:arithmetic_test`\r\n\r\nAnd in both cases, got this new error:\r\n```\r\n[ RUN      ] ArithmeticTest.ArgMinR2Axis0\r\n2020-04-07 19:44:10.787375: I tensorflow/compiler/xla/service/platform_util.cc:72] platform Host present but no XLA compiler available: could not find registered compiler for platform Host -- check target linkage (hint: try linking in tensorflow/compiler/jit:xla_cpu_jit)\r\n2020-04-07 19:44:10.787551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-07 19:44:10.787585: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (-1)\r\n2020-04-07 19:44:10.787609: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: a15e93e2e5b6\r\n2020-04-07 19:44:10.787613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: a15e93e2e5b6\r\n2020-04-07 19:44:10.787706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n2020-04-07 19:44:10.787740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.87.1\r\n2020-04-07 19:44:10.787761: F tensorflow/compiler/xla/tests/client_library_test_base.cc:48] Non-OK-status: result.status() status: Not found: no CUDA devices found could not create local client for testing\r\nexternal/bazel_tools/tools/test/test-setup.sh: line 310: 46321 Aborted                 (core dumped) \"${TEST_PATH}\" \"$@\" 2>&1\r\n```\r\n", "I can reproduce the issue.", "Adding `linkstatic=1` to the `nvptx_compiler` target seems to fix the issue, but I'm trying to figure out what would be the unintended consequences.", "Hi all,\r\n\r\nI've submitted a toolchain refactoring that makes the fix quite simple in\u00a0https://github.com/tensorflow/tensorflow/commit/e0b19f6ef223af40e2e6d1d21b8464c1b2ebee8f.\u00a0I could repro the failure mentioned above and I believe I understand how to best fix it (in short, moving `-no-as-needed` before libraries to link, and re-adding -lrt into nccl). I'll upload the fix next week.", "Great news! Thanks for continuing to work on this.", "For those following this issues, you will probably need to remote the `--noincompatible_do_not_split_linking_cmdline` parameter to bazel with this commit. This commit is already merged upstream. With it and the parameter, there is now a compilation error.", "I just tried it again with an updated devel-gpu container. \r\nWith this command line:\r\n`bazel test --config=opt -s  --config=noaws --config=nogcp --config=nohdfs --verbose_failures --config=cuda --cache_test_results=no --runs_per_test=1 --flaky_test_attempts=1 --test_tag_filters=gpu //tensorflow/compiler/xla/client/lib:arithmetic_test`\r\n\r\nI have this error: \r\n```\r\nExecuting tests from //tensorflow/compiler/xla/client/lib:arithmetic_test_gpu\r\n-----------------------------------------------------------------------------\r\n[==========] Running 4 tests from 1 test suite.\r\n[----------] Global test environment set-up.\r\n[----------] 4 tests from ArithmeticTest\r\n[ RUN      ] ArithmeticTest.ArgMinR2Axis0\r\n2020-05-23 04:26:21.892802: I tensorflow/compiler/xla/service/platform_util.cc:72] platform CUDA present but no XLA compiler available: could not find registered compiler for platform CUDA -- check target linkage (hint: try linking in tensorflow/compile\r\nr/jit:xla_gpu_jit)\r\n2020-05-23 04:26:21.892842: F tensorflow/compiler/xla/tests/client_library_test_base.cc:48] Non-OK-status: result.status() status: Not found: no platforms found could not create local client for testing\r\nexternal/bazel_tools/tools/test/test-setup.sh: line 310: 42559 Aborted                 (core dumped) \"${TEST_PATH}\" \"$@\" 2>&1\r\n```\r\n\r\nIf I try with the `--noincompatible_do_not_split_linking_cmdline` parameter, bazel crash before running the test. The flag `--cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0` doesn't help more.\r\n\r\nAs said in a previous comment, your change remove the need for strange bazel flag at many places. This is pretty good. But there is still something missing to run the tests in a normal ubuntu container.", "Could you please verify that https://github.com/tensorflow/tensorflow/pull/39849 fixed the issue for you?", "I just tried and still have this error:\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/compiler/xla/client/lib:arithmetic_test_gpu\r\n-----------------------------------------------------------------------------\r\n2020-05-27 20:45:32.874308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n[==========] Running 4 tests from 1 test suite.\r\n[----------] Global test environment set-up.\r\n[----------] 4 tests from ArithmeticTest\r\n[ RUN      ] ArithmeticTest.ArgMinR2Axis0\r\n2020-05-27 20:45:32.874883: I tensorflow/compiler/xla/service/platform_util.cc:72] platform Host present but no XLA compiler available: could not find registered compiler for platform Host -- check target linkage (hint: try linking in tensorflow/compiler/jit:xla_cpu_jit)\r\n2020-05-27 20:45:32.875025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-05-27 20:45:32.875039: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (-1)\r\n2020-05-27 20:45:32.875063: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: a33883a7b4cb\r\n2020-05-27 20:45:32.875068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: a33883a7b4cb\r\n2020-05-27 20:45:32.875226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n2020-05-27 20:45:32.875258: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.24.0\r\n2020-05-27 20:45:32.875294: F tensorflow/compiler/xla/tests/client_library_test_base.cc:48] Non-OK-status: result.status() status: Not found: no CUDA devices found could not create local client for testing\r\nexternal/bazel_tools/tools/test/test-setup.sh: line 310:  7224 Aborted                 (core dumped) \"${TEST_PATH}\" \"$@\" 2>&1\r\n```", "I managed to repro and the \"fix\" is to remove stubs from `LD_LIBRARY_PATH`. I used \r\n```\r\ncd /tensorflow_src\r\ngit pull\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nbazel test -j 24 --config=noaws --config=nogcp --config=nohdfs --verbose_failures --config=cuda --cache_test_results=no --runs_per_test=1 --flaky_test_attempts=1 --test_tag_filters=gpu //tensorflow/compiler/xla/client/lib:arithmetic_test\r\n```\r\n\r\nand got a green run. Stubs were introduced in https://github.com/tensorflow/tensorflow/pull/30911. It seems that the PR expects that the stubs are overwritten but maybe they're not? @gunan do you have more context there?\r\n\r\n", "Unfortunately, I do not have much context on that change.\r\n@angerson may know. @yifeif in case she has ideas.", "I'm not sure of how the stubs work, either. There's more context in #36974, where there are more suggestions for improvements.", "tl;dr: We did need stubs in the LD_LIBRARY_PATH back before we dlopened libcuda.\r\n\r\nlibcuda comes with the driver; if you don't have a GPU, you don't have a driver, and so you don't have libcuda. If you want to execute code that links against libcuda, you can make it point to the stub (which is basically \"for linking when cross-compiling\"). Executing code from stubs/libcuda will always return an error, but should otherwise be benign.\r\n\r\nGiven we now always dlopen libcuda on demand, we should not need the stub any more.", "(as an aside - if we need it for linking somewhere, the stubs LD_LIBRARY_PATH entry should always be after the \"real\" driver libcuda directory)", "> (as an aside - if we need it for linking somewhere, the stubs LD_LIBRARY_PATH entry should always be after the \"real\" driver libcuda directory)\r\n\r\nThis looks like a good solution.\r\n\r\n@hlopko I tried with your suggested fix and I still had 4 tests failing. So it fix most of the problem, but not all of them. Here are the tests failing:\r\n```\r\n//tensorflow/compiler/xla/tests:local_client_execute_test_gpu            FAILED in 1 out of 30 in 34.9s\r\n  Stats over 30 runs: max = 34.9s, min = 11.6s, avg = 16.0s, dev = 4.4s\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/local_client_execute_test_gpu/shard_28_of_30/test.log\r\n\r\n//tensorflow/compiler/xla/tests:exhaustive_binary_16_bit_test_gpu        FAILED in 4 out of 48 in 45.3s\r\n  Stats over 48 runs: max = 45.3s, min = 33.0s, avg = 36.3s, dev = 2.3s\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_16_bit_test_gpu/shard_1_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_16_bit_test_gpu/shard_31_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_16_bit_test_gpu/shard_17_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_16_bit_test_gpu/shard_15_of_48/test.log\r\n//tensorflow/compiler/xla/tests:exhaustive_binary_test_f32_f64_gpu       FAILED in 4 out of 48 in 46.3s\r\n  Stats over 48 runs: max = 46.3s, min = 32.1s, avg = 36.5s, dev = 3.1s\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_test_f32_f64_gpu/shard_26_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_test_f32_f64_gpu/shard_23_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_test_f32_f64_gpu/shard_15_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_binary_test_f32_f64_gpu/shard_12_of_48/test.log\r\n//tensorflow/compiler/xla/tests:exhaustive_unary_test_complex_gpu        FAILED in 26 out of 48 in 82.7s\r\n  Stats over 48 runs: max = 82.7s, min = 41.4s, avg = 62.7s, dev = 9.6s\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_unary_test_complex_gpu/shard_46_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_unary_test_complex_gpu/shard_1_of_48/test.log\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/compiler/xla/tests/exhaustive_unary_test_complex_gpu/shard_45_of_48/test.log\r\n  ...\r\n```\r\n\r\nI checked 1 failure for each of them and they are related to nan not being present while they are expected. Example:\r\n```\r\n2020-06-01 14:39:05.700041: E tensorflow/compiler/xla/tests/exhaustive_op_test_utils.cc:314] Mismatch on (-nan (0xfdcb), -0 (0x8000)). Expected -nan (0xfe00), but got 1 (0x3c00).\r\n```\r\n\r\nAny guess on what could make it fail here but not for you? I ran this on a DGX1 with V100. On which hardware did you ran this container?", "The exhaustive_* tests are known to not be working in OSS, therefore they have a \"no_oss\" tag. They also don't work in the open source CI, only internally. I don't really know why, but maybe because they have shard_count > 1 and that causes problems in the open source environment? It seems local_client_execute_test also has shard_count > 1, but there are quite a few tests which do and which seem to work.", "I always forget about that tag. I guess it can be related to clang vs gcc, not about remote execution with the error. Maybe one of the compiler optimize the code differently and so do not handle nan exactly the same.\r\n\r\nSadly, if I'm right, it can mean that nan aren't well handle if not compiled with clang...", "The fix was included and a new container was made. Now it works.\r\nThanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38205\">No</a>\n"]}, {"number": 38204, "title": "Fix TPU `saved_model.save` with SyncOnReadVariable.", "body": "", "comments": []}, {"number": 38203, "title": "Close (and reopen new) summary files at regular intervals", "body": "This helps prevent the summary file from growing too large, allowing easier management of summaries users are interested in. When uploading summaries to S3, it allows the user to clear up local disk space by uploading the files. S3 File system only uploads the file when the file closes, since it doesn't support append. \r\n\r\nFrom Tensorboard's point of view, it doesn't make a difference if it's a single file or multiple files. I'm open to feedback especially on the default values/behavior. ", "comments": ["Hi @rahul003 - thanks for the contribution and sorry for the long delay in response.  I understand the utility of being able to rotate event files used by the summary writer, and in fact we're looking into how we can add that into the base summary writing functionality.  Until we have that design fleshed out further I'd like to hold off on merging this, since I would want to make sure that any parameters exposed here aren't contradicting the lower-level API (e.g. we may not expose the ability to control the rotation period at first, or we might want it to be based on size rather than time, for example).\r\n\r\nThanks for your patience.\r\n\r\n", "@nfelt  Any update on this PR? Please. Thanks!", "No updates. I understand the use case, but the previous comment still applies - it would be better if we integrate functionality like this into the base summary writer so it's consistent everywhere, rather than specific to Estimator / SummarySaverHook, and we haven't really had a chance to explore that design sufficiently.  ", "@rahul003 Can you please check @nfelt's comments and keep us posted ? Thanks!", "Doesn't look like there's anything expected from me here. \n\nIn any case, since I'm not working with TF much these days, it doesn't personally affect me. I am closing the PR."]}, {"number": 38202, "title": "tensorflow.keras.constraints.RadialConstraint causes exception when training", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10  Enterprise 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or\r\nbinary): pip\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: Could not determine\r\n- GPU model and memory: Intel UHD Graphics 630 8gb / NVIDIA Quadro P1000 12gb\r\n\r\n**Describe the current behavior**\r\nAttempting to train a simple CNN with the RadialConstraint as the kernel constraint for the Conv2D layers throws an exception with the first batch:\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-4-2e0f3adf9bdb> in <module>\r\n     26 \r\n     27 #train the model\r\n---> 28 model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    340                 mode=ModeKeys.TRAIN,\r\n    341                 training_context=training_context,\r\n--> 342                 total_epochs=epochs)\r\n    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    344 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    126         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    127       try:\r\n--> 128         batch_outs = execution_function(iterator)\r\n    129       except (StopIteration, errors.OutOfRangeError):\r\n    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     96     # `numpy` translates Tensors to values in Eager mode.\r\n     97     return nest.map_structure(_non_none_constant_value,\r\n---> 98                               distributed_function(input_fn))\r\n     99 \r\n    100   return execution_function\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    630         # Lifting succeeded, so variables are initialized and we can run the\r\n    631         # stateless function.\r\n--> 632         return self._stateless_fn(*args, **kwds)\r\n    633     else:\r\n    634       canon_args, canon_kwds = \\\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   2360     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   2361     with self._lock:\r\n-> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2364 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   2701 \r\n   2702       self._function_cache.missed.add(call_context_key)\r\n-> 2703       graph_function = self._create_graph_function(args, kwargs)\r\n   2704       self._function_cache.primary[cache_key] = graph_function\r\n   2705       return graph_function, args, kwargs\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2591             arg_names=arg_names,\r\n   2592             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2593             capture_by_value=self._capture_by_value),\r\n   2594         self._function_attributes,\r\n   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    438         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    440     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    441 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in distributed_function(input_iterator)\r\n     83     args = _prepare_feed_values(model, input_iterator, mode, strategy)\r\n     84     outputs = strategy.experimental_run_v2(\r\n---> 85         per_replica_function, args=args)\r\n     86     # Out of PerReplica outputs reduce or pick values to return.\r\n     87     all_outputs = dist_utils.unwrap_output_dict(\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)\r\n    761       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\r\n    762                                 convert_by_default=False)\r\n--> 763       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    764 \r\n    765   def reduce(self, reduce_op, value, axis):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)\r\n   1817       kwargs = {}\r\n   1818     with self._container_strategy().scope():\r\n-> 1819       return self._call_for_each_replica(fn, args, kwargs)\r\n   1820 \r\n   1821   def _call_for_each_replica(self, fn, args, kwargs):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)\r\n   2162         self._container_strategy(),\r\n   2163         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\r\n-> 2164       return fn(*args, **kwargs)\r\n   2165 \r\n   2166   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py in wrapper(*args, **kwargs)\r\n    290   def wrapper(*args, **kwargs):\r\n    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n--> 292       return func(*args, **kwargs)\r\n    293 \r\n    294   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\r\n    431       y,\r\n    432       sample_weights=sample_weights,\r\n--> 433       output_loss_metrics=model._output_loss_metrics)\r\n    434 \r\n    435   if reset_metrics:\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)\r\n    310           sample_weights=sample_weights,\r\n    311           training=True,\r\n--> 312           output_loss_metrics=output_loss_metrics))\r\n    313   if not isinstance(outs, list):\r\n    314     outs = [outs]\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)\r\n    271                         loss_scale_optimizer.LossScaleOptimizer):\r\n    272             grads = model.optimizer.get_unscaled_gradients(grads)\r\n--> 273           model.optimizer.apply_gradients(zip(grads, trainable_weights))\r\n    274       else:\r\n    275         logging.warning('The list of trainable weights is empty. Make sure that'\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py in apply_gradients(self, grads_and_vars, name)\r\n    442           functools.partial(self._distributed_apply, apply_state=apply_state),\r\n    443           args=(grads_and_vars,),\r\n--> 444           kwargs={\"name\": name})\r\n    445 \r\n    446   def _distributed_apply(self, distribution, grads_and_vars, name, apply_state):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in merge_call(self, merge_fn, args, kwargs)\r\n   1947     if kwargs is None:\r\n   1948       kwargs = {}\r\n-> 1949     return self._merge_call(merge_fn, args, kwargs)\r\n   1950 \r\n   1951   def _merge_call(self, merge_fn, args, kwargs):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in _merge_call(self, merge_fn, args, kwargs)\r\n   1954         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\r\n   1955     try:\r\n-> 1956       return merge_fn(self._strategy, *args, **kwargs)\r\n   1957     finally:\r\n   1958       _pop_per_thread_mode()\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py in _distributed_apply(self, distribution, grads_and_vars, name, apply_state)\r\n    486           update_ops.extend(\r\n    487               distribution.extended.update(\r\n--> 488                   var, apply_grad_to_update_var, args=(grad,), group=False))\r\n    489 \r\n    490       any_symbolic = any(isinstance(i, ops.Operation) or\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in update(self, var, fn, args, kwargs, group)\r\n   1541       kwargs = {}\r\n   1542     with self._container_strategy().scope():\r\n-> 1543       return self._update(var, fn, args, kwargs, group)\r\n   1544 \r\n   1545   def _update(self, var, fn, args, kwargs, group):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in _update(self, var, fn, args, kwargs, group)\r\n   2172     # The implementations of _update() and _update_non_slot() are identical\r\n   2173     # except _update() passes `var` as the first argument to `fn()`.\r\n-> 2174     return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\r\n   2175 \r\n   2176   def _update_non_slot(self, colocate_with, fn, args, kwargs, should_group):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in _update_non_slot(self, colocate_with, fn, args, kwargs, should_group)\r\n   2178     # once that value is used for something.\r\n   2179     with UpdateContext(colocate_with):\r\n-> 2180       result = fn(*args, **kwargs)\r\n   2181       if should_group:\r\n   2182         return result\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py in apply_grad_to_update_var(var, grad)\r\n    471       if var.constraint is not None:\r\n    472         with ops.control_dependencies([update_op]):\r\n--> 473           return var.assign(var.constraint(var))\r\n    474       else:\r\n    475         return update_op\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\constraints.py in __call__(self, w)\r\n    213     w = K.map_fn(\r\n    214         self._kernel_constraint,\r\n--> 215         K.stack(array_ops.unstack(w, axis=-1), axis=0))\r\n    216     return K.reshape(K.stack(array_ops.unstack(w, axis=0), axis=-1),\r\n    217                      (height, width, channels, kernels))\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py in map_fn(fn, elems, name, dtype)\r\n   5830       Tensor with dtype `dtype`.\r\n   5831   \"\"\"\r\n-> 5832   return map_fn_lib.map_fn(fn, elems, name=name, dtype=dtype)\r\n   5833 \r\n   5834 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\r\n    266         back_prop=back_prop,\r\n    267         swap_memory=swap_memory,\r\n--> 268         maximum_iterations=n)\r\n    269     results_flat = [r.stack() for r in r_a]\r\n    270 \r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\r\n   2673         name=name,\r\n   2674         return_same_structure=return_same_structure,\r\n-> 2675         back_prop=back_prop)\r\n   2676 \r\n   2677   with ops.name_scope(name, \"while\", loop_vars):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\r\n    192         func_graph=util.WhileBodyFuncGraph(\r\n    193             body_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\r\n--> 194         add_control_dependencies=add_control_dependencies)\r\n    195     # Add external captures of body to the list of loop vars.\r\n    196     # Note that external tensors will be treated as loop invariants, i.e.,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\while_v2.py in wrapped_body(loop_counter, maximum_iterations_arg, *args)\r\n    170       # `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\r\n    171       # and packs it into the structure of `orig_loop_vars`.\r\n--> 172       outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n    173       if not nest.is_sequence_or_composite(outputs):\r\n    174         outputs = [outputs]\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\map_fn.py in compute(i, tas)\r\n    255       \"\"\"\r\n    256       packed_values = input_pack([elem_ta.read(i) for elem_ta in elems_ta])\r\n--> 257       packed_fn_values = fn(packed_values)\r\n    258       nest.assert_same_structure(dtype or elems, packed_fn_values)\r\n    259       flat_fn_values = output_flatten(packed_fn_values)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\constraints.py in _kernel_constraint(self, kernel)\r\n    227         K.cast(math_ops.floormod(kernel_shape, 2), 'bool'),\r\n    228         lambda: kernel[start - 1:start, start - 1:start],\r\n--> 229         lambda: kernel[start - 1:start, start - 1:start] + K.zeros(  # pylint: disable=g-long-lambda\r\n    230             (2, 2), dtype=kernel.dtype))\r\n    231     index = K.switch(\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py in switch(condition, then_expression, else_expression)\r\n   4234     else:\r\n   4235       else_expression_fn = else_expression\r\n-> 4236     x = control_flow_ops.cond(condition, then_expression_fn, else_expression_fn)\r\n   4237   else:\r\n   4238     # tf.where needs its condition tensor\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_ops.py in cond(pred, true_fn, false_fn, strict, name, fn1, fn2)\r\n   1172   if (util.EnableControlFlowV2(ops.get_default_graph()) and\r\n   1173       not context.executing_eagerly()):\r\n-> 1174     return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n   1175 \r\n   1176   # We needed to make true_fn/false_fn keyword arguments for\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py in cond_v2(pred, true_fn, false_fn, name)\r\n     88             false_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\r\n     89         add_control_dependencies=add_control_dependencies,\r\n---> 90         op_return_value=pred)\r\n     91 \r\n     92     verify_captures(_COND, [true_graph, false_graph])\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\constraints.py in <lambda>()\r\n    228         lambda: kernel[start - 1:start, start - 1:start],\r\n    229         lambda: kernel[start - 1:start, start - 1:start] + K.zeros(  # pylint: disable=g-long-lambda\r\n--> 230             (2, 2), dtype=kernel.dtype))\r\n    231     index = K.switch(\r\n    232         K.cast(math_ops.floormod(kernel_shape, 2), 'bool'),\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py in zeros(shape, dtype, name)\r\n   1300     v = array_ops.zeros(shape=shape, dtype=tf_dtype, name=name)\r\n   1301     if py_all(v.shape.as_list()):\r\n-> 1302       return variable(v, dtype=dtype, name=name)\r\n   1303     track_variable(v)\r\n   1304     return v\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py in variable(value, dtype, name, constraint)\r\n    812       dtype=dtypes_module.as_dtype(dtype),\r\n    813       name=name,\r\n--> 814       constraint=constraint)\r\n    815   if isinstance(value, np.ndarray):\r\n    816     v._keras_shape = value.shape\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in __call__(cls, *args, **kwargs)\r\n    258       return cls._variable_v1_call(*args, **kwargs)\r\n    259     elif cls is Variable:\r\n--> 260       return cls._variable_v2_call(*args, **kwargs)\r\n    261     else:\r\n    262       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    252         synchronization=synchronization,\r\n    253         aggregation=aggregation,\r\n--> 254         shape=shape)\r\n    255 \r\n    256   def __call__(cls, *args, **kwargs):\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2078     def creator(next_creator, *args, **kwargs):\r\n   2079       _require_strategy_scope_strategy(strategy)\r\n-> 2080       return next_creator(*args, **kwargs)\r\n   2081 \r\n   2082     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2078     def creator(next_creator, *args, **kwargs):\r\n   2079       _require_strategy_scope_strategy(strategy)\r\n-> 2080       return next_creator(*args, **kwargs)\r\n   2081 \r\n   2082     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2078     def creator(next_creator, *args, **kwargs):\r\n   2079       _require_strategy_scope_strategy(strategy)\r\n-> 2080       return next_creator(*args, **kwargs)\r\n   2081 \r\n   2082     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py in creator(next_creator, *args, **kwargs)\r\n   2078     def creator(next_creator, *args, **kwargs):\r\n   2079       _require_strategy_scope_strategy(strategy)\r\n-> 2080       return next_creator(*args, **kwargs)\r\n   2081 \r\n   2082     self._var_creator_scope = variable_scope.variable_creator_scope(creator)\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in getter(**kwargs)\r\n     63 \r\n     64   def getter(**kwargs):\r\n---> 65     return captured_getter(captured_previous, **kwargs)\r\n     66 \r\n     67   return getter\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in invalid_creator_scope(*unused_args, **unused_kwds)\r\n    500       \"\"\"Disables variable creation.\"\"\"\r\n    501       raise ValueError(\r\n--> 502           \"tf.function-decorated function tried to create \"\r\n    503           \"variables on non-first call.\")\r\n    504 \r\n\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe model should train without an exception being thrown.\r\n\r\n**Standalone code to reproduce the issue** \r\nCopied and altered example from https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\r\n```\r\nfrom tensorflow.keras.datasets import mnist\r\n#download mnist data and split into train and test sets\r\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n\r\n#reshape data to fit model\r\nX_train = X_train.reshape(60000,28,28,1)\r\nX_test = X_test.reshape(10000,28,28,1)\r\n\r\nfrom tensorflow.keras.utils import to_categorical\r\n#one-hot encode target column\r\ny_train = to_categorical(y_train)\r\ny_test = to_categorical(y_test)\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten\r\n#create model\r\nmodel = Sequential()\r\n#add model layers\r\nmodel.add(Conv2D(64, kernel_constraint='radial_constraint', kernel_size=3, activation='relu', input_shape=(28,28,1)))\r\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(10, activation='softmax'))\r\n\r\n#compile model using accuracy to measure model performance\r\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\n#train the model\r\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\r\n```\r\n\r\n**Other info / logs**\r\nNone", "comments": ["I could replicate the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/ffa7a4134bbf80c98e26875192fbbb56/untitled487.ipynb). Thanks!", "I had the same issue and found a bug in `RadialConstraint` that has a potentially easy fix.\r\n\r\nI used [this tensorflow CNN tutorial](https://www.tensorflow.org/tutorials/images/cnn) and added `kernel_constraint=tf.keras.constraints.radial_constraint()` to the first conv layer, which then causes the error (when running in Google Colab and on my local machine).\r\n\r\nThe error was caused by `K.zeros((2, 2), dtype=kernel.dtype))` in [this line](https://github.com/tensorflow/tensorflow/blob/b459be827a7c1d1b2a958b90cfd49eb37d62275a/tensorflow/python/keras/constraints.py#L248) in `tensorflow/tensorflow/python/keras/constraints.py`.\r\n\r\nI replaced it with `K.constant([[0, 0], [0, 0]], dtype=kernel.dtype)` and it works now, see [my gist here](https://gist.github.com/LaurinHerbsthofer/95499af563f67e022d63f56639efcfcc).\r\n\r\nI tested it for kernel sizes 3, 4 and 5 and it works in all cases.\r\n\r\nHowever, when running it in Google Colab, training becomes slow (from 5s/epoch to 60s/epoch). Running it on my local machine (Ubuntu 20.04, RTX2070, TF 2.4) does not show any significant increase in training time and works just fine.", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210525, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/558e440fcc0d63813edb11b6145153cc/untitled7.ipynb).", "@Oney18, Sorry for late response. \r\n\r\nWhen i tried using `CustomRadialConstraint` function [as suggested](https://github.com/tensorflow/tensorflow/issues/38202#issuecomment-762697661) by @LaurinHerbsthofer. I am able to run the code in TF2.7. Please find the [gist here](https://colab.research.google.com/gist/chunduriv/282869e019389525e962cf8e0adae82e/38202.ipynb).Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38202\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38202\">No</a>\n"]}, {"number": 38201, "title": "[DOCS] Updated documentation for the versioning of the TensorFlow Lite operators.", "body": "I was going through the document for the TensorFlow Lite operators versioning\r\nhttps://www.tensorflow.org/lite/guide/ops_version\r\nand noticed that some mentioned files/functions are out-of-dated.\r\nI have corrected them in this PR.", "comments": []}, {"number": 38200, "title": "[INTEL MKL] upgrade curl version to 7.69.1 to fix CVE-2019-15601", "body": "upgrade curl version to 7.69.1 to fix CVE-2019-15601", "comments": ["@chuanqi129 Nice.", "Will also cherrypick on 1.15, 2.0, 2.1 and 2.2 branches", "The builds are failing with errors such as\r\n\r\n```\r\n7353FD4B/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Ubatch_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: undefined reference to `Curl_rename'\r\n```\r\n\r\nI'm going to try a manual import, but if that fails too, we'll have to do more here.", "Thanks @mihaimaruseac , I will also look into this issue further.", "It was needing one additional file in the BUILD file, see bfb0e49"]}]