[{"number": 46668, "title": "Extract a function for parsing operator BATCH_MATMUL", "body": "Extract the parsing out of a switch statement case to create a\r\nstandalone function which can be called by the micro op resolver.\r\n\r\nPR step 1 for issue #46504", "comments": [":frowning_face: Sorry, but only Googlers may change the label `cla: yes`."]}, {"number": 46667, "title": "Updates to the TFLM Makfile that are not backwards compatible", "body": "**System information**\r\n\r\n-   OS Platform and Distribution: Linux Ubuntu 20.10 \r\n-   TensorFlow version: 2.4.1\r\n-   Python version: 3.8\r\n-   CPU Intel Core i7\r\n-   GPU: NVIDIA GeForce GTX\r\n-   STM32CubeIDE-Lnx: 1.3.0\r\n-   STM32 Nucleo-64 development board\r\n\r\n**Describe the problem**\r\n\r\nI would like to run the Makefile in the Tensorflow Lite for Microcontrollers directory in order to run inference on ST microcontroller above. My problem is that I cannot use the \r\nTAGS =\u201dportable_optimized\u201d command line option /cc @advaitjain\r\n\r\n**Source code / logs**\r\n\r\ntensorflow/lite/micro/tools/make/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..\r\n\r\nThanks in advance.", "comments": ["The portable_optimized kernels have been removed for some time now. You can remove `TAGS=portable_optimized` from your command line and things should work as before.", "Also, since you're using an stm32f4 board, you might also want to try `OPTIMIZED_KERNEL_DIR=cmsis_nn` to get optimized implementations for some of the kernels.", "> **System information**\r\n> \r\n> * OS Platform and Distribution: Linux Ubuntu 20.10\r\n> * TensorFlow version: 2.4.1\r\n> * Python version: 3.8\r\n> * CPU Intel Core i7\r\n> * GPU: NVIDIA GeForce GTX\r\n> * STM32CubeIDE-Lnx: 1.3.0\r\n> * STM32 Nucleo-64 development board\r\n> \r\n> **Describe the problem**\r\n> \r\n> I would like to run the Makefile in the Tensorflow Lite for Microcontrollers directory in order to run inference on ST microcontroller above. My problem is that I cannot use the TAGS =\u201dportable_optimized\u201d command line option /cc @advaitjain\r\n> \r\n> **Source code / logs**\r\n> \r\n> tensorflow/lite/micro/tools/make/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..\r\n> \r\n> Thanks in advance.\r\n\r\nDid you generate sample project to test with the stm32, if so what was the make command you used\r\n\r\n> **System information**\r\n> \r\n> * OS Platform and Distribution: Linux Ubuntu 20.10\r\n> * TensorFlow version: 2.4.1\r\n> * Python version: 3.8\r\n> * CPU Intel Core i7\r\n> * GPU: NVIDIA GeForce GTX\r\n> * STM32CubeIDE-Lnx: 1.3.0\r\n> * STM32 Nucleo-64 development board\r\n> \r\n> **Describe the problem**\r\n> \r\n> I would like to run the Makefile in the Tensorflow Lite for Microcontrollers directory in order to run inference on ST microcontroller above. My problem is that I cannot use the TAGS =\u201dportable_optimized\u201d command line option /cc @advaitjain\r\n> \r\n> **Source code / logs**\r\n> \r\n> tensorflow/lite/micro/tools/make/Makefile:61: *** The TAGS command line option is no longer supported in the TFLM Makefile..\r\n> \r\n> Thanks in advance.\r\n\r\nDid you generate sample projects for the stm32 board, what was the make command used\r\n", "Hi, I used this command: `make -f tensorflow/lite/micro/tools/make/Makefile` (from https://www.digikey.com/en/maker/projects/tinyml-getting-started-with-tensorflow-lite-for-microcontrollers/c0cdd850f5004b098d263400aa294023)"]}, {"number": 46666, "title": "Old Lookup Bug still active?", "body": "I am using Tensorflow 1.x \r\nOS: Mac OS or Linux can be testet e.g in Cola\r\n\r\nThe following demo code works with GPU but not with CPU. It looks like this from 2018 - I think it should work on both:\r\n```\r\n`\r\nvocab = [{'this':1},\r\n         {'is':2},\r\n         {'just':3},\r\n         {'the':4},\r\n         {'a':5},\r\n         {'demo':6},\r\n         {'code':7},\r\n         {'tensorflow':8},\r\n         {'test':9}]\r\n\r\nfeatures = [[1, 2, 3, 4, 5], [5, 6, 7, 8, 9]]\r\n\r\nEMBEDDING_SIZE = 1\r\nwith tf.Session() as sess:\r\n    features_embedded = tf.contrib.layers.embed_sequence(\r\n        ids=features,\r\n        vocab_size=len(vocab),\r\n        embed_dim=EMBEDDING_SIZE,\r\n        scope='words',\r\n        reuse=tf.AUTO_REUSE\r\n        )\r\n    word_list = tf.unstack(features_embedded, axis=1)\r\n    sess.run(tf.global_variables_initializer())`\r\n```\r\n\r\nLeads to InvalidArgumentError: indices[1,4] = 9 is not in [0, 9)\r\n\t [[{{node words/embedding_lookup}}]]\r\n\r\nOr GPU:\r\n[[[-0.03936231]\r\n  [-0.62959105]\r\n  [ 0.05874097]\r\n  [-0.39156422]\r\n  [-0.50708985]]\r\n\r\n [[-0.50708985]\r\n  [-0.2946922 ]\r\n  [-0.32304823]\r\n  [ 0.514025  ]\r\n  [ 0.        ]]]\r\n\r\n\r\nIt is something like this bug: https://github.com/tensorflow/tensorflow/issues/17417\r\n", "comments": ["Think I got it, len(vocab) is 9 should be 10 or more. But why does it work with GPU???", "We no longer fix TF 1.x. Can you try with the latest version?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@mihaimaruseac Thanks. What does latest Version mean? TF 2.x or latest TF 1.x?\r\n\r\n", "@DHOFM \r\nAs informed \"We no longer fix TF 1.x. \" please use 2.x i.e 2.4 and let us know if you face any issues.", "OK, but as yo can see, this is tf.contrib.layers.embed_sequence - so there is no more tf.contrib.layers.embed_sequence in TF 2.x, right?\r\n\r\n", "You should convert to use the replacements APIs for `tf.contrib`.", "> OK, but as yo can see, this is tf.contrib.layers.embed_sequence - so there is no more tf.contrib.layers.embed_sequence in TF 2.x, right?\r\n\r\nThat's correct. Also check out [`TF Addons`](https://github.com/tensorflow/addons) repository where a subset of `tf.contrib` functions are revived.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46666\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46666\">No</a>\n"]}, {"number": 46665, "title": "neuro-symbolic", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 46664, "title": "Tensorflow 2.4 Compile", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  with command  pip install tensorflow-gpu==2.4.0\r\n- TensorFlow version: 2.4.0\r\n- Python version: Python 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: cuda :11.0,  cuDNN :  8.0.2\r\n- Driver Version: 450.102.04\r\n- GPU model and memory: Gigabyte Nvidia GForce 1660 6GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI execute the basic command \r\nimport tensorflow as tf\r\nprint(tf.test.gpu_device_name())\r\n\r\nto see if tensorflow 2.4 is execute in my ubuntu i have all installed than we need for this version like cuda version, cuddn version and driver version. What maybe is the problem ? \r\nWith tensorflow 2.3 compile successfully but he cannnot load the cuddn library and cuda.\r\n\r\n**Any other info / logs**\r\nFrom compiler i get this message : \r\n2021-01-25 16:27:37.386741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 435, in <module>\r\n    _ll.load_library(_main_dir)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/load_library.py\", line 153, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/antreas/.local/lib/python3.6/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\r\n\r\n", "comments": ["@aloizo03,\r\nCould you please try installing TensorFlow in a new virtual environment and check if it works?\r\n\r\nAlso, try installing TensorFlow v2.4.1 using the below command and let us know if you are facing the same error. \r\n\r\n`pip install tensorflow==2.4.1`\r\n\r\nThanks!", "@amahendrakar  \r\nI install the 2.4.1 and i get this\r\n2021-01-25 18:50:21.072974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-01-25 18:50:21.821691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-25 18:50:21.822075: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 18:50:22.001576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-01-25 18:50:23.284599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:23.285193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:2d:00.0 name: GeForce GTX 1660 computeCapability: 7.5\r\ncoreClock: 1.86GHz coreCount: 22 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 178.86GiB/s\r\n2021-01-25 18:50:23.285219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-01-25 18:50:23.972534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-01-25 18:50:23.972624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-01-25 18:50:24.478819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-01-25 18:50:24.722951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-01-25 18:50:25.546900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-01-25 18:50:25.561327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-01-25 18:50:25.566373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-01-25 18:50:25.566510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:25.567143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:25.567663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-25 18:50:25.567697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-01-25 18:50:25.978800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-25 18:50:25.978832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2021-01-25 18:50:25.978837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2021-01-25 18:50:25.978997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:25.979305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:25.979582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 18:50:25.979852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 4937 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660, pci bus id: 0000:2d:00.0, compute capability: 7.5)\r\n/device:GPU:0\r\n\r\nIt's ok now ?\r\nAnd thanks for the help and the quick response i appreciate very much!!", "Those seems to be all information messages (`I`). Seems ok to me.", "> It's ok now ?\r\n> And thanks for the help and the quick response i appreciate very much!!\r\n\r\n@aloizo03,\r\nHappy to help :)\r\n\r\nThe logs are just to confirm that TensorFlow has successfully detected the GPU on your machine. You can safely ignore those information logs. \r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46664\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46664\">No</a>\n"]}, {"number": 46663, "title": "Breaking change of TFLite model definition in TensorFlow 2.4.0: OperatorCode.BuiltinCode", "body": "(source issue: https://github.com/jackwish/tflite/issues/9)\r\n\r\n**This change breaks software stacks that depend on the built TFLite model parser, e.g. [tvm](https://github.com/apache/tvm), [tflite2onnx](https://github.com/jackwish/tflite2onnx), and etc.**\r\n\r\nStarting from [TensorFlow 2.4.0](https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/lite/schema/schema.fbs#L220), the `BuiltinOperator` switches to `int32` from `byte`. As a result, the `OperatorCode.builtin_code` is now an `int32` too, and code like `op_code.BuiltinCode()` is broken. \r\n\r\n```\r\n// An OperatorCode can be an enum value (BuiltinOperator) if the operator is a\r\n// builtin, or a string if the operator is custom.\r\ntable OperatorCode {\r\n  // This field is for backward compatibility. This field will be used when\r\n  // the value of the extended builtin_code field has less than\r\n  // BulitinOperator_PLACEHOLDER_FOR_GREATER_OP_CODES.\r\n  deprecated_builtin_code:byte;\r\n  custom_code:string;\r\n\r\n  // The version of the operator. The version need to be bumped whenever new\r\n  // parameters are introduced into an op.\r\n  version:int = 1;\r\n\r\n  // This field is introduced for resolving op builtin code shortage problem\r\n  // (the original BuiltinOperator enum field was represented as a byte).\r\n  // This field will be used when the value of the extended builtin_code field\r\n  // has greater than BulitinOperator_PLACEHOLDER_FOR_GREATER_OP_CODES.\r\n  builtin_code:BuiltinOperator;\r\n}\r\n``` \r\n\r\nFor any code that uses `op_code.BuiltinCode()`, a workaround like the below (or [this PR](https://github.com/jackwish/tflite/pull/10/files)) is needed.\r\n\r\n```py\r\n\r\nif op_code.BuiltinCode() < BuiltinOperator.PLACEHOLDER_FOR_GREATER_OP_CODES:\r\n    opc = op_code.DeprecatedBuiltinCode()\r\nelse:\r\n    opc = op_code.BuiltinCode()\r\n```", "comments": ["Sorry for encountering this issue in your side. Since TFLite builtin operator set is getting bigger, we need to roll this change unluckily. We provide the following helpers to adopt this change:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_conversion_utils.cc\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_utils.cc\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/schema_util.py\r\n\r\nPlease take a look at them and I hope them help resolving your issue.\r\n\r\nHere is a link to describe some backgrounds of the behavior change: https://github.com/tensorflow/community/pull/285", "@abattery Thank you for the details! I understand that is something that can hardly avoid when the system involves... So by design, for any systems that rely on a TFLite model (or the model representation), they should wrap up the calling to `BuiltinCode` like [this](https://github.com/tensorflow/tensorflow/blob/747ca958fa6c51ffd81616867e7f043216cbe4ad/tensorflow/lite/python/util.py#L651) with the example handlers you listed? If that's the case, maybe we can do something (maybe [this](https://github.com/jackwish/tflite/pull/10)) in [`tflite`](https://github.com/jackwish/tflite) (a python parser package) to avoid such change in the software system stack.", "@jackwish we would do that but we are depending the flatbuffer library to generate the interfaces which are done by the codegen approach so it is very tricky to do that.\r\n\r\nMaybe we can wrap again with the result of the codegen by introducing a new layer. However, it will require a tons of refactoring and it may not reflect the actual model structure as well.\r\n\r\nThanks for the suggestion!", "@abattery Thanks for your reply. Refactoring for such a case seems can be avoided. I can work around it in [the python parsing package](https://github.com/jackwish/tflite) (done in `v2.4.0`).\r\n\r\nNow closing as I have got the answer. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46663\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46663\">No</a>\n"]}, {"number": 46662, "title": "Reshape after conversion has two dynamic shapes, fails inference", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2\r\n- TensorFlow installed from (source or binary): With pip install tensorflow\r\n- TensorFlow version (or github SHA if from source): 2.4.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n    model_concrete_function = model.inference_encode.get_concrete_function()\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions(\r\n        [model_concrete_function]\r\n    )\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\r\n\r\n    if args.quantized:\r\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n        output_file_name = os.path.join(args.outdir, 'model_quant.tflite')\r\n    else:\r\n        output_file_name = os.path.join(args.outdir, 'model.tflite')\r\n\r\n    tflite_model = converter.convert()\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2021-01-25 12:34:22.930736: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-01-25 12:34:22.930757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2021-01-25 12:34:25.599105: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 12:34:25.599281: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-01-25 12:34:25.599294: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-01-25 12:34:25.599313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev-dsk-dmmatwic-1b-a5a0da5a.eu-west-1.amazon.com): /proc/driver/nvidia/version does not exist\r\n2021-01-25 12:34:25.599516: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-25 12:34:25.600785: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 12:34:28.607374: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-01-25 12:34:28.607500: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-01-25 12:34:28.607690: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 12:34:28.627718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz\r\n2021-01-25 12:34:28.634934: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\r\n2021-01-25 12:34:29,117 (lite:619) INFO: Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\r\n2021-01-25 12:34:29.139440: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\r\n2021-01-25 12:34:29.139470: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\r\n2021-01-25 12:34:29.183040: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 12:34:29,771 (convert:102) INFO: Model of size 6.231964 MBs saved to model_tflite/model.tflite\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\nI can't include a model since it's company's internal model.\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n\r\nReshape nodes have shapes of [-1, -1, 128] instead of [1, -1, 128] and inference therefore fails\r\n**Here's a screenshot of this part from Netron, the selected node is the Reshape node** \r\n![Untitled 2](https://user-images.githubusercontent.com/32575801/105708210-61385b00-5f14-11eb-8e8d-4be25947043c.png)\r\n\r\nThese nodes are part of tf.keras.layers.Conv1D, which is created with\r\n**tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding=\"same\")**\r\n\r\nInference log\r\n**ERROR: tensorflow/lite/kernels/reshape.cc:58 stretch_dim != -1 (0 != -1)\r\nERROR: Node number 69 (RESHAPE) failed to prepare.**\r\n\r\n", "comments": ["Please try the conversion code with tf-nightly. We have implemented a better reshape op handling in the newer version.", "Hi, thanks, that helped with this problem and the model works fine now. Unfortunately I get different error in different model now, namely I get \r\n**ERROR: tensorflow/lite/kernels/kernel_util.cc:404 d1 == d2 || d1 == 1 || d2 == 1 was not true.\r\nERROR: Node number 3 (ADD) failed to prepare.**\r\nwhen running \r\n**TfLiteInterpreterAllocateTensors(interpreter)** in TFLite C++ API.\r\nThe conversion to tflite model runs fine.\r\n\r\n> 2021-01-26 09:30:17.656931: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-01-26 09:30:17.656958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n/home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210125). \r\nTensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \r\nIf you encounter a bug, do not file an issue on GitHub.\r\n  warnings.warn(\r\n2021-01-26 09:30:20.220470: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-01-26 09:30:20.220498: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-01-26 09:30:20.220517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev-dsk-dmmatwic-1b-a5a0da5a.eu-west-1.amazon.com): /proc/driver/nvidia/version does not exist\r\n2021-01-26 09:30:20.220718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nWARNING:tensorflow:From /home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5039: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\r\n2021-01-26 09:30:22,167 (deprecation:528) WARNING: From /home/dmmatwic/anaconda3/envs/tflite_x86/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5039: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\r\n2021-01-26 09:30:22.977251: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-01-26 09:30:22.977359: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-01-26 09:30:22.995718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz\r\n2021-01-26 09:30:23.040599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:935] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: Graph size after: 900 nodes (122), 1564 edges (136), time = 10.878ms.\r\n  function_optimizer: Graph size after: 900 nodes (0), 1564 edges (0), time = 9.301ms.\r\nOptimization results for grappler item: while_body_3883\r\n  function_optimizer: function_optimizer did nothing. time = 0.006ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\nOptimization results for grappler item: while_body_4324\r\n  function_optimizer: function_optimizer did nothing. time = 0.004ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\nOptimization results for grappler item: while_cond_3882\r\n  function_optimizer: function_optimizer did nothing. time = 0.004ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\nOptimization results for grappler item: while_cond_4323\r\n  function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2021-01-26 09:30:24,125 (lite:659) INFO: Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\r\n2021-01-26 09:30:24.216881: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:332] Ignored output_format.\r\n2021-01-26 09:30:24.216915: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:335] Ignored drop_control_dependency.\r\n2021-01-26 09:30:24.305204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2021-01-26 09:30:25.025058: I tensorflow/lite/tools/optimize/quantize_weights.cc:233] Skipping quantization of tensor arg5 because it has no allocated buffer.\r\n2021-01-26 09:30:25.026738: I tensorflow/lite/tools/optimize/quantize_weights.cc:233] Skipping quantization of tensor arg5 because it has no allocated buffer.\r\n2021-01-26 09:30:25,077 (convert_model:102) INFO: Model of size 10.273849 MBs saved to model_tflite/model_quant.tflite\r\n\r\nThe part of model that it concerns looks like that\r\n![add_node](https://user-images.githubusercontent.com/32575801/105826429-03ae1800-5fc1-11eb-87c6-6a535fde494d.png)\r\n\r\nI'm not sure what exactly does this error mean. As far as I can see these conditions are met, with [1, 128] and [1, 128, 128] d1 is in fact equal to d2, while d1 and d2 also being 1? Unless I misunderstood how it works. This happens during tensors allocation, so I understand that this has nothing to do with input data shapes? Thanks :)", "@Jkeezuz thank you for reporting an issue to us! To make this closed and keep the history simple, could you file another issue for the new one?", "When you upload the new issue, it would be helpful to provide the reproducible steps to us. Thanks!"]}, {"number": 46661, "title": "Memory Leak in VGG16 based model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.0 / 8.0.5\r\n- GPU model and memory: Nvidia Quadro M2200 (4 Gb)\r\n\r\n\r\n**Describe the current behavior**\r\nRunning predictions (and also training) with a **VGG16** (from Keras Model Zoo) based model leads to a steadily increasing memory usage until either the all predictions are completed or the system memory is exhausted and the process dies.\r\nSee the script below to reproduce the issue. It plots the memory consumption for each iteration of predicting with the defined model.\r\nThe memory consumption for TensorFlow 2.4 looks like this:\r\n![Memory_Leak_Plot_TF_2_4](https://user-images.githubusercontent.com/7513153/105699507-c174d000-5f07-11eb-8d8e-feff12628172.png)\r\nThe memory consumption of TensorFlow 2.3 behaves as expected:\r\n![Memory_Leak_Plot_TF_2_3](https://user-images.githubusercontent.com/7513153/105699551-d5b8cd00-5f07-11eb-973c-20bbb91e370a.png)\r\n**Note:** Running the same script TensorFlow 2.4 consumes >8 Gb of RAM while TensorFlow 2.3 only consumes ~1.3 Gb.\r\n**Note 2:** The critical part of this model is the VGG16 model from tf.keras.applications. Using a ResNet50 model instead the memory leak does not occur.\r\n\r\n**Describe the expected behavior**\r\nThe memory consumption in TensorFlow 2.4 is similar to TensorFlow 2.3 such that running an increased number of iterations does not lead to a potentially infinite main memory consumption.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe required packages to run the script below are: tqdm, psutil, matplotlib, numpy, tensorflow=2.4\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer('block5_pool').output\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)\r\n        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)\r\n        decoder = tf.keras.layers.Concatenate()([model.input, decoder])\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)\r\n        super().__init__(model.input, decoder)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_predictions(5000)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\n\r\n**Other info / logs**\r\nI found another bug that also deals with a memory leak in TensorFlow 2.4 (#46475). However, the OS there is Ubuntu Linux 20.04 while the bug described above was only reproducible on Windows 10 and not in a Linux based colab. Furthermore, the issue described in the other bug seems to be related to ReLU activation. As I was able to reproduce the issue with VGG16 but not ResNet50 (Both contain ReLU activations)  I assume that this is a different issue.\r\n", "comments": ["@soyers,\r\nI did not observe much difference in the memory consumption with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/58f61be61ef25c96fb494a880490833d/46661-2-3.ipynb) and [TF v2.4](https://colab.research.google.com/gist/amahendrakar/648d981f9be7a62bd73d1f8f12584b0c/46661.ipynb). Please check the linked gist for reference. \r\n\r\nCould you please restart your machine, try running the code in a new virtual environment and check if you are facing the same issue. Thanks!", "Hi @amahendrakar,\r\n\r\nthanks for your effort and reply! I suppose that your colab notebooks ran on the default colab Linux VM. I wasn't able to reproduce this bug on the Linux VMs and therefore suspect that this issue only appears on **Windows 10**. In the meantime I was able to also reproduce the memory leak on a different Windows 10 machine (2x Xeon E5-2623 v3, 128Gb RAM, Nvidia Quadro M4000 (8Gb)).\r\n\r\nSo, I am quite confident that this issue is reproducible on any Windows 10 machine, but not on Linux (at least not on the distribution that runs on colab). If I can assist with any other information please let me know!", "I have new insights that might help narrow down the issue. It seems like the issue only appears when using CUDA/cuDNN. Running the script on the CPU (`set CUDA_VISIBLE_DECIVES=-1`) the memory consumption plot looks reasonable:\r\n![Memory_Leak_Plot_TF_2_4_CPU](https://user-images.githubusercontent.com/7513153/105847590-1420bb80-5fde-11eb-827c-d3f65f5a7e17.png)\r\n\r\nThis implies that the issue seems to be CUDA/cuDNN related.\r\n\r\nI investigated the default colab environment and noticed that although TensorFlow 2.4 is installed there, the CUDA version is still 10.1.243 and cuDNN is 7.6.5 (while TensorFlow 2.4 officially requires CUDA 11 and cuDNN 8). This explains why the memory leak is not reproducible on colab.\r\nTo determine the CUDA/cuDNN version on colab please see the following notebook: https://gist.github.com/soyers/493af91dd4bc9f385bef60b8373926b8\r\n\r\nI therefore suspect that this is not a Windows/Linux problem after all, but rather a CUDA/cuDNN related issue in cuda version 11 or cuDNN version 8.\r\n\r\nAny suggestions how to deal with this?\r\n", "Thanks for the report, we'll investigate. As a work around you might want to use `model(inputs)` instead of `model.predict(inputs)` (and possibly wrap that in a `tf.function` for performance).", "Hi @soyers, as this may be a windows+cuda issue and a quick check on colab doesn't repro the leak for us, could you help us narrow it down as follows?\r\n\r\n1. Do you experience a memory leak when calling the model directly? What about when you call the model inside of a tf.function? (predict is ill-suited for single-item predictions and is intended for batch prediction, so you may want to do that anyway depending on our use case. Or pass the entire input to predict instead of one batch at a time).\r\n\r\n2. Can you do an ablation check to identify which part of the model does it? (Change the layer you're grabbing via `get_layer`).\r\n\r\n3. Do you have access to a linux vm with cuda 11 installed? That way we can see if it's a windows 10 issue or a cuda issue.\r\n\r\nWe'll also loop in the gpu team in case this is related more to the cuda integration than to keras.", "Hi @fchollet and @tomerk! Thanks for looking into this and sorry for the delay from my side.\r\n\r\nI am aware that using the predict method is meant to be called on the entire dataset which I am also doing in our production code. However, I am working on a long-running inference service that is supposed to run many prediction jobs potentially without being restarted for a long time. If TensorFlow has a memory leak there this service will break after some time, which is currently the reason for sticking with TensorFlow 2.2. So, this VGG16 based script just runs the .predict method in a loop to illustrate what will probably happen in long-running inference services.\r\n\r\nI investigated the circumstances that lead to the memory leak a bit further and made the following findings:\r\n1. Calling the model directly does not cause a memory leak. I changed the run_prediction method of the script as follows:\r\n```python\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model(inputs)   # This is the changed line: Call the model directly\r\n    return memory_used\r\n```\r\nThe memory consumption pattern is very different from that of the `.predict` method and seems to allocate the entire needed memory at once at the beginning of the execution. Please see the following plot of the memory consumption:\r\n![Memory_Plot_Direct_Call_TF_2_4](https://user-images.githubusercontent.com/7513153/106439088-93e3d580-6477-11eb-90c9-82a733a4f2fc.png)\r\n\r\nMaybe it's also interesting to note that the memory leak also happens during training with the `model.fit` function. The following script illustrates this:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass MemoryCallback(tf.keras.callbacks.Callback):\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.memory_used = []\r\n\r\n    def on_epoch_end(self, epoch, log={}):\r\n        process = psutil.Process(os.getpid())\r\n        self.memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer('block5_pool').output\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)\r\n        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)\r\n        decoder = tf.keras.layers.Concatenate()([model.input, decoder])\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)\r\n        super().__init__(model.input, decoder)\r\n\r\n\r\ndef run_training(iterations, epochs):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\")\r\n\r\n    inputs = np.random.rand(*input_shape)\r\n    labels = np.random.rand(*input_shape)\r\n    dataset = tf.data.Dataset.from_tensor_slices((inputs, labels)).repeat().batch(2)\r\n\r\n    callback = MemoryCallback()\r\n\r\n    model.fit(dataset, steps_per_epoch=iterations, epochs=epochs, callbacks=[callback])\r\n    return callback.memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_training(iterations=20, epochs=100)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\nThe corresponding memory footprint looks like this:\r\n![Memory_Leak_Training_Plot_TF_2_4](https://user-images.githubusercontent.com/7513153/106443079-5df52000-647c-11eb-9bd8-fcdd12f1fc85.png)\r\n\r\n2. I tried to narrow down the set of layers inside the VGG16 model that causes the issue. Whatever causes the issue seems to be there in very early layers of VGG16. I removed the upsampling layers so that the TestModel only wraps the VGG16 model: \r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape, output_layer_name):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer(output_layer_name).output\r\n        super().__init__(model.input, output_encoder)\r\n\r\ndef run_predictions(iterations, output_layer_name):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape, output_layer_name)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_predictions(5000, 'block1_pool')\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\n Using the output of `block1_conv2` already causes the memory leak:\r\n![Memory_Leak_block1_conv2_TF_2_4](https://user-images.githubusercontent.com/7513153/106446211-415ae700-6480-11eb-90f3-7ce15fd57f2f.png)\r\nwhereas it is not there when using `block1_conv1`:\r\n![Memory_Leak_block1_conv1_TF_2_4](https://user-images.githubusercontent.com/7513153/106446284-5b94c500-6480-11eb-8ec3-cb24a93c1437.png)\r\n\r\nI therefore tried to create a simpler example to reproduce this issue as the example above basically uses only two conv2D layers and came up with this example with a simple 2-layer model:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer_1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')\r\n        self.layer_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')\r\n\t\t\r\n    def call(self, inputs):\r\n        return self.layer_2(self.layer_1(inputs))\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel()\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_predictions(5000)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\nIt produces the following memory footprint:\r\n![Memory_Leak_2_layer_model_TF_2_4](https://user-images.githubusercontent.com/7513153/106448737-774d9a80-6483-11eb-9aed-64f722bae270.png)\r\n\r\n**Note:** removing the ReLU layers causes the memory leak to disappear. Although (#46475) looked different to me on first glimpse, I now suspect that it could actually be related. I am still puzzled why the ResNet50 implementation does not have this memory leak although it should also contain Conv2D layers with ReLU activation.\r\n\r\nThe model without the ReLU activations looks like this:\r\n```python\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer_1 = tf.keras.layers.Conv2D(64, (3, 3), activation=None, padding='same', name='block1_conv1')   # Note activations here\r\n        self.layer_2 = tf.keras.layers.Conv2D(64, (3, 3), activation=None, padding='same', name='block1_conv2')   # Note activations here\r\n\t\t\r\n    def call(self, inputs):\r\n        return self.layer_2(self.layer_1(inputs))\r\n``` \r\nIt produces the following memory footprint:\r\n![Memory_Leak_2_layer_model_no_relu_TF_2_4](https://user-images.githubusercontent.com/7513153/106449986-e081dd80-6484-11eb-8a3e-279a0c7c1c5d.png)\r\n\r\n3. I will try to get my hands on a proper linux machine and see If I can reproduce the results. However, this might take some time. I tried the script in a colab notebook but wasnt able to reproduce it since it doesn't use cudatoolkit 11 and cudnn 8. Therefore, I suspect that the issue has something to do with the latest cudatoolkit/cudnn combined with the relu activations in conv2d layers. Sorry for not being less handwavy here :sweat_smile:\r\n\r\nI hope to have answered some of your questions here. If you require any more information please let me know!", "This is extremely helpful, thank you!\r\n\r\nOne follow-up question to the above:\r\nDid you try calling the model directly in a tf.function too? Or just calling the model separately w/o putting it in a tf.function? Do they both have the same memory semantics?\r\n(You should try both w/ passing a numpy value to the tf.function, and passing a tensor value to the tf.function).\r\n\r\nThat'll help us isolate whether something with the dataset reading or something with tf.function execution and the lower-level runtime is more likely to be the case. (In past memory leaks we've seen problems with input reading, but some of the characteristics you've observed make that seem unlikely, e.g. how removing relu layers is able to get rid of the memory issue).", "Hi @tomerk!\r\n\r\nThat's a reallly good point! Investigating the effect of wrapping the model into a `tf.function` is quite interesting! I adjusted the script such that the model is wrapped into a function that can be decorated with`@tf.function`.\r\n\r\n**TL;DR:** The memory leak happens in models wrapped into `@tf.function` and does not happen if `@tf.function` is not used. Feeding Tensors instead of numpy arrays to the model does not have any effekt.\r\n\r\nRunning the model without `tf.function` does, as expected, not cause a memory leak:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.layer_1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')\r\n        self.layer_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')\r\n\t\t\r\n    def call(self, inputs):\r\n        return self.layer_2(self.layer_1(inputs))\r\n\r\n\r\nmodel = TestModel()\r\n\r\n\r\ndef run_model(inputs):\r\n    return model(inputs)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        run_model(inputs)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_predictions(5000)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\nIt produces the following result: \r\n![Memory_Leak_no_tffunction_TF_2_4](https://user-images.githubusercontent.com/7513153/106585941-2a7fc780-6548-11eb-8a80-ed68f66efe3a.png)\r\n\r\nWrapping the  `run_model` function into a `tf.function`:\r\n```python\r\n@tf.function\r\ndef run_model(inputs):\r\n    return model(inputs)\r\n```\r\ncauses the memory leak as can be observed in the corresponding plot bleow:\r\n![Memory_Leak_tffunction_TF_2_4](https://user-images.githubusercontent.com/7513153/106586348-a11cc500-6548-11eb-980e-1b83ce3b12c4.png)\r\n\r\nI also tested if it makes a difference when providing the input as as a Tensor instead of a numpy array by replacing the line\r\n```python\r\ninputs = np.random.rand(*input_shape)\r\n```\r\nin the script above by\r\n```python\r\ninputs = tf.convert_to_tensor(np.random.rand(*input_shape))\r\n```\r\nand I couldn't find any significant differences in the memory footprint. I would therefore conclude that the issue is not related to the conversion from numpy arrays to Tensors.", "Okay, I've gone ahead and internally forwarded this to the folks focusing on tf.function! I can't speak to what their backlog looks like currently, but your info should definitely be helpful for them.", "Great, thank's a lot! I'm looking forward to a fix. If there's anything I can do to help, just let me know!", "Hi @soyers, sorry for the late response. I have been trying to reproduce the bug in environments similar to what you specified, but with no success. Here are the tests I did.\r\n\r\n### Test Code\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer('block5_pool').output\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)\r\n        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)\r\n        decoder = tf.keras.layers.Concatenate()([model.input, decoder])\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)\r\n        super().__init__(model.input, decoder)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    memory_used = run_predictions(5000)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\n\r\n### Test 1\r\n**System information**\r\n- OS Platform and Distribution: Windows Server 2019 Datacenter\r\n- GPU: 4 NVIDIA Tesla P100\r\n- CUDA: 11.0\r\n- cuDNN: 8.0.2\r\n- Python: 3.8.5\r\n- TensorFlow: 2.4.0\r\n\r\n![image (2)](https://user-images.githubusercontent.com/12569322/111006033-dc2cc800-8340-11eb-9f36-eb4b213d13f0.png)\r\n\r\n### Test 2\r\n**System information**\r\n- OS Platform and Distribution: Windows Server 2019 Datacenter\r\n- GPU: No GPU\r\n- Python: 3.8.5\r\n- TensorFlow: 2.4.0\r\n\r\n![image (3)](https://user-images.githubusercontent.com/12569322/111006129-0ed6c080-8341-11eb-9361-ee2e7edb2ecf.png)\r\n\r\n### Test 3\r\n**System information**\r\n- OS Platform and Distribution: Windows Server 2019 Datacenter\r\n- GPU: 4 NVIDIA Tesla P100\r\n- CUDA: 10.1\r\n- cuDNN: 7.6.5\r\n- Python: 3.8.5\r\n- TensorFlow: 2.3.0\r\n\r\n![image (4)](https://user-images.githubusercontent.com/12569322/111006200-37f75100-8341-11eb-938e-3f8a6c5fec6d.png)\r\n\r\n### Test 4\r\n**System information**\r\n- OS Platform and Distribution: Windows Server 2019 Datacenter\r\n- GPU: No GPU\r\n- Python: 3.8.5\r\n- TensorFlow: 2.3.0\r\n\r\n![image (6)](https://user-images.githubusercontent.com/12569322/111006253-53625c00-8341-11eb-826f-85da251874b7.png)\r\n\r\nThough the pattern of memory usage looks different w/o GPU, they are similar with TensorFlow 2.3/2.4 and no significant memory leak was noticed in all 4 cases.  \r\nThe main discrepancy in our test environments and your test environment is GPU and windows version. At this moment, we are not able to identify if they are the cause of memory leak. If you could provide us more information (with different GPUs or Windows versions), it will definitely help us keep narrow down the issue.\r\n\r\nThe other advice we have is to replace the keras in your example with raw ops and see if the memory leak persists. If you need help with that, please let us know. \r\n\r\n@sanjoy and @mdanatg if you have more suggestions, please feel free to add them here.\r\n\r\n\r\n", "@soyers if you would like to help us debug further, since the issue only appears on your side, it would be useful to narrow down the possible source. I've modified the model code to use low-level TF ops instead of the Keras model. If the leak still reproduces with it, then we can try to narrow things down further. If it doesn't, then we can have a closer look at the interaction between Keras and tf.function.\r\n\r\nThe code below is roughly similar to the Keras model, with a simplified variables initializer. If you could give it a try, it would be helpful:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass SimpleModel:\r\n    def __init__(self):\r\n        self.built = False\r\n        self.k1 = None\r\n        self.b1 = None\r\n        self.k2 = None\r\n        self.b2 = None\r\n\t\t\r\n    def __call__(self, inputs):\r\n        if not self.built:\r\n          self.k1 = tf.Variable(tf.random.truncated_normal((3, 3, 3, 64), 0.0, 0.1, tf.float64))\r\n          self.k2 = tf.Variable(tf.random.truncated_normal((3, 3, 64, 64), 0.0, 0.1, tf.float64))\r\n          self.b1 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.b2 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.built = True\r\n        y = inputs\r\n        y = tf.nn.relu(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k1, strides=(1, 1), padding='SAME'), self.b1))\r\n        y = tf.nn.relu(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k2, strides=(1, 1), padding='SAME'), self.b2))\r\n        return y\r\n\r\n\r\nmodel = SimpleModel()\r\n\r\n\r\n@tf.function\r\ndef run_model(inputs):\r\n    return model(inputs)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        run_model(inputs)\r\n    return memory_used\r\n\r\nmemory_used = run_predictions(50)\r\nplt.plot(memory_used)\r\nplt.xlabel(\"Iteration\")\r\nplt.ylabel(\"Memroy Usage (MB)\")\r\nplt.show()\r\n```", "@mdanatg looks like you are on the right track, at least on my setup.\r\n\r\nI tried the Keras code from here (had to lower the number of iterations to 1000 to get results):\r\nhttps://github.com/tensorflow/tensorflow/issues/46661#issuecomment-797801964\r\n![Keras](https://user-images.githubusercontent.com/35486837/112306805-7e816f80-8ca0-11eb-991e-7439a6db91c0.png)\r\n\r\nYour example gave this result (I increased the number of iterations to 1000 to be sure):\r\n![Tensorflow](https://user-images.githubusercontent.com/35486837/112306975-b1c3fe80-8ca0-11eb-9a17-f7c674ccf952.png)\r\n\r\nOS: Windows 10\r\nTensorflow version: 2.4.1 (pip install)\r\nCUDA: 10.2\r\ncuDNN: 8.0.3\r\nGPU: GeForce RTX 2060\r\n\r\nREMARK: I had CUDA 11 with the corresponding cuDNN installed previously. I though this might be the cause for the memory issue, that's why I downgraded (including TF). The issue was still present and it seemed to work fine otherwise (even after updating TF), that's why I just kept it.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "This issue is a huge show stopper for me and it seems for others as well. Is there anything else that needs to be provided to make progress on the issue?", "cc @tomerk \r\n\r\nThe main problem is that we can't reproduce the issue on our machines. So the remaining alternative is to keep narrowing the faulty case down to as few TF ops as possible (ideally, just a handful of raw ops). That's easiest with the help of a Keras expert, so things are blocked a bit on our side.\r\n\r\nThere is another solution we could pursue: running the code with a memory profiler. If that could capture the type of objects which are exploding, it would give us additional hints. Since we don't know whether the leak is in C++ or Python, profiling each side would be needed. @DeepBlender would you be interested / have the time to try that out?", "Hi everyone! Sorry for not answering for such a long time. It's a shame that this issue is so hard to reproduce but I am glad that I am not the only one having to stick with TF 2.2 with cuda 7 due to this bug. Maybe we can figure something out by joining forces.\r\n\r\nI don't have much experience with memory profiling, so I quickly ran the script with tracemalloc hoping to find any obvious memory leak on the python side. Unfortunately, I can't find any indications of a memory leak there. This is the code I ran:\r\n\r\n```python\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer('block5_pool').output\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)\r\n        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)\r\n        decoder = tf.keras.layers.Concatenate()([model.input, decoder])\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)\r\n        super().__init__(model.input, decoder)\r\n\t\t\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    tracemalloc.start()\r\n    memory_used = run_predictions(1000)\r\n    snapshot = tracemalloc.take_snapshot()\r\n    top_stats = snapshot.statistics('lineno')\r\n    for stat in top_stats[:10]:\r\n        print(stat)\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\n\r\nand this is the output:\r\n```\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98: size=2337 KiB, count=201, average=11.6 KiB\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\abc.py:102: size=973 KiB, count=8902, average=112 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1509: size=866 KiB, count=15242, average=58 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1473: size=328 KiB, count=2002, average=168 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\google\\protobuf\\internal\\decoder.py:572: size=283 KiB, count=4696, average=62 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\linecache.py:137: size=260 KiB, count=2460, average=108 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:82: size=228 KiB, count=3001, average=78 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:525: size=222 KiB, count=4732, average=48 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1346: size=221 KiB, count=1349, average=168 B\r\nC:\\Users\\m1ssoyer\\AppData\\Local\\Continuum\\miniconda3\\envs\\venv_tf24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:384: size=199 KiB, count=1158, average=176 B\r\n```\r\n\r\nAs shown in the plots above, after running the 1000 predictions the application actually consumes more than 1gb of memory more than before. I can't find anything in the tracemalloc output that would indicate such a huge memory consumption.\r\n\r\nI would therefore conclude that the issue lies on the c++ side of TensorFlow or I am using the tracemalloc tool wrong. I would appreciate any advice! Thanks!\r\n\r\nI am still a bit puzzled that the issue is not reproducible with a Tesla P100 (Pascal series) card which @DeepBlender was able to reproduce it with an RTX 2060 (Turing series). This means that this is not an issue with old cards but can also happen with newer architectures.", "@sanjoy for more advice", "@soyers thank you for running the check, this is useful.\r\n\r\nIt might be useful to try out TensorFlow's memory profiler next: https://www.tensorflow.org/guide/profiler#memory_profile_tool\r\n\r\nHopefully, the leak is somewhere in the TF stack and the tool can catch it / we can fix it easily, and not some strange interaction with the GPU drivers or some other part of the OS.\r\n", "Hi @soyers .  Another tool you can try is [objgraph](https://mg.pov.lt/objgraph/). If it's originated from a Python object leak, this tool is very easy and helpful.  It can't catch C++ side leak so if that's the case, we'll need another tool.  But since this is easy to try, I suggest to give a shot first.\r\n\r\nExample usage:\r\n```import tensorflow as tf\r\nimport objgraph\r\nimport gc\r\n\r\nleaking_global_list = []\r\n\r\nfor i in range(5):\r\n  for _ in range(100):\r\n    leaking_global_list.append(tf.constant(1.))\r\n\r\n  print(\"Iteration\", i)\r\n  gc.collect()\r\n  objgraph.get_new_ids(limit=30)\r\n```\r\n\r\nExample Output\r\n```\r\nIteration 0\r\n================================================================================\r\nType                              Old_ids  Current_ids      New_ids Count_Deltas\r\n================================================================================\r\ntuple                               51492        52410         +932         +918\r\ndict                                54481        55294         +870         +813\r\nfunction                            80092        80570         +484         +478\r\nweakref                             16403        16748         +345         +345\r\nMessageDescriptor                    1573         1807         +234         +234\r\nGeneratedProtocolMessageType         1573         1807         +234         +234\r\nlist                                29005        29171         +203         +166\r\nset                                 10562        10689         +127         +127\r\nEnumTypeWrapper                       614          741         +127         +127\r\nEnumDescriptor                        614          741         +127         +127\r\nmodule                               4177         4268          +91          +91\r\nModuleSpec                           4161         4252          +91          +91\r\ntype                                 7512         7583          +71          +71\r\nMimeTypes                               1           70          +69          +69\r\nSourceFileLoader                     3326         3390          +64          +64\r\ngetset_descriptor                    7418         7476          +58          +58\r\nFileFinder                            691          727          +36          +36\r\ncell                                15952        15984          +40          +32\r\nproperty                             5836         5865          +29          +29\r\nWeakSet                              2236         2263          +27          +27\r\nSourcelessFileLoader                  232          255          +23          +23\r\nFileDescriptor                        233          256          +23          +23\r\nmethod_descriptor                    4346         4363          +17          +17\r\nitemgetter                           1808         1821          +13          +13\r\nstaticmethod                         1424         1436          +12          +12\r\nclassmethod                          1392         1402          +10          +10\r\nABCMeta                               689          698           +9           +9\r\nmethod                               1324         1331          +13           +7\r\nbuiltin_function_or_method           8426         8433           +9           +7\r\nclassmethod_descriptor                 69           74           +5           +5\r\n================================================================================\r\nIteration 1\r\n==============================================================================\r\nType                            Old_ids  Current_ids      New_ids Count_Deltas\r\n==============================================================================\r\nEagerTensor                         100          200         +100         +100\r\nset                               10689        10732          +43          +43\r\ndict                              55294        55324          +30          +30\r\nlist                              29171        29183          +12          +12\r\nframe                                78           88          +10          +10\r\nbuiltin_function_or_method         8433         8438           +5           +5\r\ntuple_iterator                        1            2           +1           +1\r\nmethod                             1331         1332           +1           +1\r\nlist_iterator                         3            4           +1           +1\r\ngenerator                            16           17           +1           +1\r\nStringIO                              2            3           +1           +1\r\nStackTraceResponseBody                0            1           +1           +1\r\nStackTraceResponse                    0            1           +1           +1\r\nNetCommand                            2            3           +1           +1\r\nInternalGetThreadStack                1            2           +1           +1\r\nFramesList                            1            2           +1           +1\r\nzipf_gen                              1            1           +0           +0\r\nyulesimon_gen                         1            1           +0           +0\r\nwrapper_descriptor                 3864         3864           +0           +0\r\nwrapcauchy_gen                        1            1           +0           +0\r\nwishart_gen                           1            1           +0           +0\r\nweibull_min_gen                       1            1           +0           +0\r\nweibull_max_gen                       1            1           +0           +0\r\nweekday                              14           14           +0           +0\r\nweakref                           16748        16748           +0           +0\r\nwald_gen                              1            1           +0           +0\r\nvonmises_gen                          2            2           +0           +0\r\nvectorize                           458          458           +0           +0\r\nunitary_group_gen                     1            1           +0           +0\r\nuniform_gen                           1            1           +0           +0\r\n==============================================================================\r\nIteration 2\r\n===========================================================================\r\nType                         Old_ids  Current_ids      New_ids Count_Deltas\r\n===========================================================================\r\nEagerTensor                      200          300         +100         +100\r\nset                            10732        10737           +6           +5\r\nzipf_gen                           1            1           +0           +0\r\nyulesimon_gen                      1            1           +0           +0\r\nwrapper_descriptor              3864         3864           +0           +0\r\nwrapcauchy_gen                     1            1           +0           +0\r\nwishart_gen                        1            1           +0           +0\r\nweibull_min_gen                    1            1           +0           +0\r\nweibull_max_gen                    1            1           +0           +0\r\nweekday                           14           14           +0           +0\r\nweakref                        16748        16748           +0           +0\r\nwald_gen                           1            1           +0           +0\r\nvonmises_gen                       2            2           +0           +0\r\nvectorize                        458          458           +0           +0\r\nunitary_group_gen                  1            1           +0           +0\r\nuniform_gen                        1            1           +0           +0\r\nuname_result                       1            1           +0           +0\r\ntzutc                              1            1           +0           +0\r\ntzUTC                              1            1           +0           +0\r\ntype                            7583         7583           +0           +0\r\ntuple                          52410        52410           +1           +0\r\ntukeylambda_gen                    1            1           +0           +0\r\ntruncnorm_gen                      1            1           +0           +0\r\ntruncexpon_gen                     1            1           +0           +0\r\ntriang_gen                         1            1           +0           +0\r\ntrapz_gen                          1            1           +0           +0\r\nt_gen                              1            1           +0           +0\r\nsymbol                             1            1           +0           +0\r\nstaticmethod                    1436         1436           +0           +0\r\nspecial_ortho_group_gen            1            1           +0           +0\r\n===========================================================================\r\nIteration 3\r\n==============================================================================\r\nType                            Old_ids  Current_ids      New_ids Count_Deltas\r\n==============================================================================\r\nEagerTensor                         300          400         +100         +100\r\nbuiltin_function_or_method         8434         8436           +7           +2\r\nmethod                             1330         1331           +2           +1\r\ncell                              15984        15985           +1           +1\r\nThreadsRequest                        0            1           +1           +1\r\nzipf_gen                              1            1           +0           +0\r\nyulesimon_gen                         1            1           +0           +0\r\nwrapper_descriptor                 3864         3864           +0           +0\r\nwrapcauchy_gen                        1            1           +0           +0\r\nwishart_gen                           1            1           +0           +0\r\nweibull_min_gen                       1            1           +0           +0\r\nweibull_max_gen                       1            1           +0           +0\r\nweekday                              14           14           +0           +0\r\nweakref                           16748        16748           +0           +0\r\nwald_gen                              1            1           +0           +0\r\nvonmises_gen                          2            2           +0           +0\r\nvectorize                           458          458           +0           +0\r\nunitary_group_gen                     1            1           +0           +0\r\nuniform_gen                           1            1           +0           +0\r\nuname_result                          1            1           +0           +0\r\ntzutc                                 1            1           +0           +0\r\ntzUTC                                 1            1           +0           +0\r\ntype                               7583         7583           +0           +0\r\ntukeylambda_gen                       1            1           +0           +0\r\ntruncnorm_gen                         1            1           +0           +0\r\ntruncexpon_gen                        1            1           +0           +0\r\ntriang_gen                            1            1           +0           +0\r\ntrapz_gen                             1            1           +0           +0\r\nt_gen                                 1            1           +0           +0\r\nsymbol                                1            1           +0           +0\r\n==============================================================================\r\nIteration 4\r\n===========================================================================\r\nType                         Old_ids  Current_ids      New_ids Count_Deltas\r\n===========================================================================\r\nEagerTensor                      400          500         +100         +100\r\ntuple                          52409        52412           +3           +3\r\nframe                             73           74           +6           +1\r\nzipf_gen                           1            1           +0           +0\r\nyulesimon_gen                      1            1           +0           +0\r\nwrapper_descriptor              3864         3864           +0           +0\r\nwrapcauchy_gen                     1            1           +0           +0\r\nwishart_gen                        1            1           +0           +0\r\nweibull_min_gen                    1            1           +0           +0\r\nweibull_max_gen                    1            1           +0           +0\r\nweekday                           14           14           +0           +0\r\nweakref                        16748        16748           +0           +0\r\nwald_gen                           1            1           +0           +0\r\nvonmises_gen                       2            2           +0           +0\r\nvectorize                        458          458           +0           +0\r\nunitary_group_gen                  1            1           +0           +0\r\nuniform_gen                        1            1           +0           +0\r\nuname_result                       1            1           +0           +0\r\ntzutc                              1            1           +0           +0\r\ntzUTC                              1            1           +0           +0\r\ntype                            7583         7583           +0           +0\r\ntukeylambda_gen                    1            1           +0           +0\r\ntruncnorm_gen                      1            1           +0           +0\r\ntruncexpon_gen                     1            1           +0           +0\r\ntriang_gen                         1            1           +0           +0\r\ntrapz_gen                          1            1           +0           +0\r\nt_gen                              1            1           +0           +0\r\nsymbol                             1            1           +0           +0\r\nstaticmethod                    1436         1436           +0           +0\r\nspecial_ortho_group_gen            1            1           +0           +0\r\n===========================================================================\r\n```", "Thanks for the quick replies and your helpful suggestions! At first I started a TensorFlow memory profiling run with the following code:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass TestModel(tf.keras.models.Model):\r\n    def __init__(self, input_shape):\r\n        model = tf.keras.applications.VGG16(input_shape=input_shape[1:], include_top=False)\r\n        output_encoder = model.get_layer('block5_pool').output\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(output_encoder)\r\n        decoder = tf.keras.layers.UpSampling2D(size=(32,32))(decoder)\r\n        decoder = tf.keras.layers.Concatenate()([model.input, decoder])\r\n        decoder = tf.keras.layers.Conv2D(3, 3, padding='SAME')(decoder)\r\n        super().__init__(model.input, decoder)\r\n\t\t\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    model = TestModel(input_shape)\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        model.predict(inputs, batch_size=1)\r\n    return memory_used\r\n\r\nif __name__ == \"__main__\":\r\n    options = tf.profiler.experimental.ProfilerOptions(host_tracer_level = 3, python_tracer_level = 1, device_tracer_level = 1)\r\n    tf.profiler.experimental.start('logdir', options = options)\r\n    memory_used = run_predictions(250)\r\n    tf.profiler.experimental.stop()\r\n    plt.plot(memory_used)\r\n    plt.xlabel(\"Iteration\")\r\n    plt.ylabel(\"Memroy Usage (MB)\")\r\n    plt.show()\r\n```\r\n\r\nIf I understand the dashboard correctly, the logs clearly high heap allocation (> 2GB) in the ReLU activation of block 5. It also strikes me that the profiler does not seem to be able to determine shape, data type and region type for that operation (it just shows INVALID, see the screenshot below).\r\n![Memory_Per_Op](https://user-images.githubusercontent.com/7513153/113993471-cb467800-9854-11eb-8800-6c61c7d53b23.PNG)\r\n\r\nIn the other screenshot below you can see that profiler on the one hand claims that memory is deallocated correctly (according to the timeline graph on the right) while in the summary on the left it claims to still have allocated the peak heap usage of (2.29 GB). I am not sure how to interpret these graphs, so I may be making false assumptions here.\r\n![Memory_Graph](https://user-images.githubusercontent.com/7513153/113993488-cf729580-9854-11eb-98ba-cfa1a4d87740.PNG)\r\n\r\nThe fact that the ReLU operation seems to be leaking memory here, there must be at least a connection to the issue described in #46475.\r\n\r\n@kkimdev Thank's for the suggestion! I also ran the code with the objgraph library as you described and redirected the output to [this file](https://github.com/tensorflow/tensorflow/files/6277484/objgraph_out.txt).\r\nIt seems to me that there are no leftover python objects after the prediction.\r\n\r\n", "Great finds again @soyers. It does indeed that the likely culprit is ReLU+Conv2D. It is suspicious that the leak only happens when you call the Keras layer, not when calling the vanilla Conv2D + BiasAdd + Relu. Nevertheless, it should be easy to confirm it's Conv2D+Relu by (1) running with a different activation and (2) using a different layer that still has a relu activation (say, a dense one).\r\n\r\nThere's another thing looking suspicious. Could you try your code with the following settings (call the function early in your program, be sure to restart the runtime for each run):\r\n\r\nOnce with `tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})`\r\n\r\nThen again with `tf.config.optimizer.set_experimental_options({'remapping': False})`\r\n\r\ncc @ezhulenev \r\n", "Hi @soyers,\r\n\r\nCould also you try the model of low-level ops shared by mdanatg@ earlier, but trying both `tf.keras.layers.ReLU` and `tf.keras.activations.relu` instead of tf.nn.relu? That way we can check if the Keras relu usage is causing more or different ops to be created than the standard tf.nn.relu call\r\n\r\nactivations.relu:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass SimpleModel:\r\n    def __init__(self):\r\n        self.built = False\r\n        self.k1 = None\r\n        self.b1 = None\r\n        self.k2 = None\r\n        self.b2 = None\r\n\t\t\r\n    def __call__(self, inputs):\r\n        if not self.built:\r\n          self.k1 = tf.Variable(tf.random.truncated_normal((3, 3, 3, 64), 0.0, 0.1, tf.float64))\r\n          self.k2 = tf.Variable(tf.random.truncated_normal((3, 3, 64, 64), 0.0, 0.1, tf.float64))\r\n          self.b1 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.b2 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.built = True\r\n        y = inputs\r\n        y = tf.keras.activations.relu(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k1, strides=(1, 1), padding='SAME'), self.b1))\r\n        y = tf.keras.activations.relu(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k2, strides=(1, 1), padding='SAME'), self.b2))\r\n        return y\r\n\r\n\r\nmodel = SimpleModel()\r\n\r\n\r\n@tf.function\r\ndef run_model(inputs):\r\n    return model(inputs)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        run_model(inputs)\r\n    return memory_used\r\n\r\nmemory_used = run_predictions(50)\r\nplt.plot(memory_used)\r\nplt.xlabel(\"Iteration\")\r\nplt.ylabel(\"Memroy Usage (MB)\")\r\nplt.show()\r\n```\r\n\r\nLayers.relu:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tqdm\r\nimport os\r\nimport psutil\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\nclass SimpleModel:\r\n    def __init__(self):\r\n        self.built = False\r\n        self.k1 = None\r\n        self.b1 = None\r\n        self.k2 = None\r\n        self.b2 = None\r\n\t\t\r\n    def __call__(self, inputs):\r\n        if not self.built:\r\n          self.k1 = tf.Variable(tf.random.truncated_normal((3, 3, 3, 64), 0.0, 0.1, tf.float64))\r\n          self.k2 = tf.Variable(tf.random.truncated_normal((3, 3, 64, 64), 0.0, 0.1, tf.float64))\r\n          self.b1 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.b2 = tf.Variable(tf.zeros((64,), tf.float64))\r\n          self.built = True\r\n        y = inputs\r\n        y = tf.keras.layers.ReLU()(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k1, strides=(1, 1), padding='SAME'), self.b1))\r\n        y = tf.keras.layers.ReLU()(tf.nn.bias_add(\r\n            tf.nn.conv2d(y, self.k2, strides=(1, 1), padding='SAME'), self.b2))\r\n        return y\r\n\r\n\r\nmodel = SimpleModel()\r\n\r\n\r\n@tf.function\r\ndef run_model(inputs):\r\n    return model(inputs)\r\n\r\ndef run_predictions(iterations):\r\n    input_shape = 1, 256, 256, 3\r\n    inputs = np.random.rand(*input_shape)\r\n    memory_used = []\r\n    for _ in tqdm.tqdm(range(iterations)):\r\n        process = psutil.Process(os.getpid())\r\n        memory_used += [process.memory_info().rss / 1024.0 / 1024.0]\r\n        run_model(inputs)\r\n    return memory_used\r\n\r\nmemory_used = run_predictions(50)\r\nplt.plot(memory_used)\r\nplt.xlabel(\"Iteration\")\r\nplt.ylabel(\"Memroy Usage (MB)\")\r\nplt.show()\r\n```\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "I'm having the same issue (during predict only, with both `model.predict(inputs)` and `model(inputs)`) when using the following pre-trained keras models: VGG16, VGG19, MobileNet (I suppose it's the same with other models)\r\n\r\n- Linux Mint 19.2 (based on Ubuntu 18.04)\r\n- CUDA 11.3\r\n- CuDnn 8.2\r\n- Tensorflow 2.5.0\r\n- Python 3.7.5\r\n- Nvidia Quadro RTX 4000\r\n- Nvidia driver 465.19.01\r\n\r\nI know these CUDA and CuDnn versions are not officially supported by tf but maybe the bug persists after 11.2 and 8.1", "Hi @andreasntr,\r\n\r\nthis is interesting. I actually stopped debugging this since I couldn't reproduce the issue with my minimal example posted above in TensorFlow 2.5.0. I was, therefore assuming that the issue was fixed in TF 2.5. Sorry for not reporting back on this!\r\n\r\nAre you using the same code as I posted above or are you using a different setup? Could you provide example code reproducing the issue in that case?", "> Are you using the same code as I posted above or are you using a different setup? Could you provide example code reproducing the issue in that case?\r\n\r\nNot exactly the same but I was doing something similar, i.e. I was slicing my dataset (since each observation is composed by N images) and feeding the model with one slice at a time in a for loop to extract features to be fed to another classifier. I was using the slicing to avoid fulling the whole VRAM.\r\nEven if I read that predict in for loop is discouraged, I wasn't expecting this behaviour with huge slices of data (more than 10k images per iteration, small batch size).\r\nI solved the issue by reshaping the dataset from `(n_obs, n_img, h, w, c)` to `(n_obs*n_imgs, h, w, c)` and then reshaping the result from `(n_obs*n_imgs, n_feats)` to `(n_obs, n_imgs, n_feats)`.\r\n\r\nThe model was using 8GB of VRAM with tf.float32 data no matter the batch size, while now it's only using 5GB with MobileNet which is still a lot but I think it's because of the size of the dataset\r\n\r\nEDIT: I ran it with VGG16 and the problem was still there\r\n\r\n```\r\nBATCH_SIZE = 32\r\nEMBEDDING_SIZE = 512 #size of the extracted features\r\nimgs = ... #numpy array of shape (N, 6, 128, 128, 3)\r\nfeat_extractor = ... #VGG16 cut at block4_pool with GlobalAveragePooling2D at the end\r\n\r\ndef predict(x):\r\n    preds = feat_extractor.predict(x, batch_size=BATCH_SIZE, verbose=1).astype(DTYPE)\r\n    tf.keras.backend.clear_session()\r\n    gc.collect()\r\n    return preds\r\n\r\npredict(imgs.reshape((np.prod(imgs.shape[:2]), *imgs.shape[2:]))).reshape((*imgs.shape[:2], EMBEDDING_SIZE))\r\n```"]}, {"number": 46660, "title": "Third-party Tensorflow 2.4.0", "body": "Hello TensorFlow team,\r\nI'm looking for version 2.4.0 of Tensorflow for all used third-party with the version status. Is there a document that refers to all third-party versions and versions?\r\nBest regards,\r\nFabian", "comments": ["@fsinn1995 \r\nPlease refer to this [link]( https://github.com/tensorflow/tensorflow#community-supported-builds) and let us know if i helps.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46659, "title": "Loading a model with a Lambda layer causes a 'str' object is not callable exception", "body": "I'm running tf 2.3.1 on Python 3.7.6 (via Kaggle). Running this code...\r\n\r\nimport tensorflow as tf\r\n\r\n```\r\nmodel1 = tf.keras.Sequential([\r\n    tf.keras.layers.Input(shape = (81,), dtype = 'uint8'), \r\n    tf.keras.layers.Lambda(tf.keras.backend.one_hot, arguments={'num_classes': 10}, output_shape=(81, 10)),\r\n])\r\n\r\ntf.keras.models.save_model(model1, './model')\r\nmodel2 = tf.keras.models.load_model('./model', custom_objects={'one_hot' : tf.keras.backend.one_hot})\r\nmodel2.summary()\r\n```\r\n\r\ncauses a rather long exception, quoted in full below. It seems to be the Lambda layer that causes issues; save-loading works fine without it. I've tried adding `custom_objects={'one_hot' : tf.keras.backend.one_hot}` and suchlike to the load call, but it doesn't fix it. \r\n\r\n\r\n```---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n\r\nTypeError: 'str' object is not callable\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-22-9347e5c173dd> in <module>\r\n      7 \r\n      8 tf.keras.models.save_model(model1, './model')\r\n----> 9 model2 = tf.keras.models.load_model('./model', custom_objects={'one_hot' : tf.keras.backend.one_hot})\r\n     10 model2.summary()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\r\n    185     if isinstance(filepath, six.string_types):\r\n    186       loader_impl.parse_saved_model(filepath)\r\n--> 187       return saved_model_load.load(filepath, compile, options)\r\n    188 \r\n    189   raise IOError(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)\r\n    119 \r\n    120   model = tf_load.load_internal(\r\n--> 121       path, options=options, loader_cls=KerasObjectLoader)\r\n    122 \r\n    123   # pylint: disable=protected-access\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls)\r\n    631       try:\r\n    632         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\r\n--> 633                             ckpt_options)\r\n    634       except errors.NotFoundError as err:\r\n    635         raise FileNotFoundError(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in __init__(self, *args, **kwargs)\r\n    192     self._models_to_reconstruct = []\r\n    193 \r\n--> 194     super(KerasObjectLoader, self).__init__(*args, **kwargs)\r\n    195 \r\n    196     # Now that the node object has been fully loaded, and the checkpoint has\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options)\r\n    128       self._concrete_functions[name] = _WrapperFunction(concrete_function)\r\n    129 \r\n--> 130     self._load_all()\r\n    131     self._restore_checkpoint()\r\n    132 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_all(self)\r\n    219 \r\n    220     # Finish setting up layers and models. See function docstring for more info.\r\n--> 221     self._finalize_objects()\r\n    222 \r\n    223   @property\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _finalize_objects(self)\r\n    528 \r\n    529     # Initialize graph networks, now that layer dependencies have been resolved.\r\n--> 530     self._reconstruct_all_models()\r\n    531 \r\n    532   def _unblock_model_reconstruction(self, layer_id, layer):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_all_models(self)\r\n    546       all_initialized_models.add(model_id)\r\n    547       model, layers = self.model_layer_dependencies[model_id]\r\n--> 548       self._reconstruct_model(model_id, model, layers)\r\n    549       self._add_object_graph_edges(self._proto.nodes[model_id], model_id)\r\n    550       _finalize_config_layers([model])\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _reconstruct_model(self, model_id, model, layers)\r\n    576               dtype=layers[0].dtype,\r\n    577               name=layers[0].name + '_input'))\r\n--> 578       model.__init__(layers, name=config['name'])\r\n    579       if not model.inputs:\r\n    580         first_layer = self._get_child_layer_node_ids(model_id, model.name)[0]\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\r\n    140         layers = [layers]\r\n    141       for layer in layers:\r\n--> 142         self.add(layer)\r\n    143 \r\n    144   @property\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n    219       # If the model is being built continuously on top of an input layer:\r\n    220       # refresh its output.\r\n--> 221       output_tensor = layer(self.outputs[0])\r\n    222       if len(nest.flatten(output_tensor)) != 1:\r\n    223         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    924     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n    925       return self._functional_construction_call(inputs, args, kwargs,\r\n--> 926                                                 input_list)\r\n    927 \r\n    928     # Maintains info about the `Layer.call` stack.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n   1115           try:\r\n   1116             with ops.enable_auto_cast_variables(self._compute_dtype_object):\r\n-> 1117               outputs = call_fn(cast_inputs, *args, **kwargs)\r\n   1118 \r\n   1119           except errors.OperatorNotAllowedInGraphError as e:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py in call(self, inputs, mask, training)\r\n    901     with backprop.GradientTape(watch_accessed_variables=True) as tape,\\\r\n    902         variable_scope.variable_creator_scope(_variable_creator):\r\n--> 903       result = self.function(inputs, **kwargs)\r\n    904     self._check_variables(created_variables, tape.watched_variables())\r\n    905     return result\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    204       # TypeError, when given unexpected types.  So we need to catch both.\r\n--> 205       result = dispatch(wrapper, args, kwargs)\r\n    206       if result is not OpDispatcher.NOT_SUPPORTED:\r\n    207         return result\r\n\r\nTypeError: 'module' object is not callable```", "comments": ["I have tried in colab with TF version 2.3.1, 2.4 ,Nightly version(`2.5.0-dev20210126`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/ee45b59ce4a636a5c852d2757cd6c509/untitled628.ipynb).Thanks!", "Looks like a bug. \r\n\r\n> I've tried adding custom_objects={'one_hot' : tf.keras.backend.one_hot} and suchlike to the load call, but it doesn't fix it.\r\n\r\nSomething like this should have been fixing it.\r\n\r\nHere's what should happen upon deserialization:\r\n\r\n- If the function is not recognized, then there should be an error related to that specific issue (\"cannot deserialize object \"one_hot\"\")\r\n- If it is passed as a custom object, we should be able to use that.\r\n\r\nRight now it's looking like the serialized \"one_hot\" is just passed through without deserialization.", "@mg262 Seems the issue is fixed in latest TF Nightly. 2.6 version.When executed the code I am not facing any error. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/50b2a38a537b0932e957fc3181c8306e/untitled92.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46659\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46659\">No</a>\n", "> @mg262 Seems the issue is fixed in latest TF Nightly. 2.6 version.When executed the code I am not facing any error. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/50b2a38a537b0932e957fc3181c8306e/untitled92.ipynb).\r\nhave you tried to load model? `model2 = tf.keras.models.load_model('./model', custom_objects={'one_hot' : tf.keras.backend.one_hot})`\r\n", "I still have the same error, it is not being fixed."]}, {"number": 46658, "title": "Error in prediction:Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU for TensorFlow C++ API Reference", "body": "<em>Please make sure that this is a bug. As per our\r\n\r\n**System information**\r\n- OS Platform \uff1aUbuntu 16.04\r\n- TensorFlow installed from source :\r\n- TensorFlow version (use command below): TensorFlow Core v2.4.1  TensorFlow C++ API Reference\r\n- Python version: 3.5\r\n- Bazel version : release: release 1.2.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\r\n\r\n\r\nLOG OUTPUT\r\n\r\n2021-01-25 10:39:38.260369: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:661] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[{{node v_}}]]\r\n2021-01-25 10:39:38.261762: E external/org_tensorflow/tensorflow/core/common_runtime/executor.cc:661] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[{{node v_}}]]\r\nError in prediction:Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[{{node v_}}]]\r\n", "comments": ["PLEASE WE NEED NCHW dataformat for c++ API", "@clemente0420,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "![image](https://user-images.githubusercontent.com/32806348/105708612-aaf26700-5f4f-11eb-8e72-7d961245c71a.png)\r\n\r\nif not support on cpu , why you guys write the doc for that?\r\n\r\nWith the default format \"NHWC\", the data is stored in the order of: [batch, in_height, in_width, in_channels]. Alternatively, the format could be \"NCHW\", the data storage order of: [batch, in_channels, in_height, in_width].", "@clemente0420,\r\nThank you for sharing the documentation for reference. Can you please share your code so that we can reproduce the error and see what's going on? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46658\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46658\">No</a>\n"]}, {"number": 46657, "title": "Guide for porting reference ops to TFLite micro", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md\r\n\r\n## Description of issue (what needs changing):\r\n\r\n> TODO(b/165627437): Create and link to a guide to porting reference ops.\r\n\r\nThis TODO is still open. It feels like TFLite micro is getting more and more attention and recently many ops are in the process to be ported. I'm also working on two ops (#45693) and I would highly appreciate such a guide since I'm struggling to port the tests from TFLite to micro.\r\nHow are the TODOs handled in tensorflow? Is someone working on that or is it just open until somebody picks it up?\r\n", "comments": ["@stephanboner,\r\n\r\nCan you take a look at this [guide](https://github.com/tensorflow/tflite-micro/blob/080db2db55e82863d1a9adcf5c045d48e3e73941/tensorflow/lite/micro/docs/porting_reference_ops.md) and let me know if that is what you're looking for? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46657\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46657\">No</a>\n"]}, {"number": 46656, "title": "Issue with tflite converter in tf-nightly:  'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.5\r\n- Python version: 3.7.4\r\n- TensorFlow version: tf-nightly-2.5.0.dev20210124\r\n\r\nHello, I have a new issue with the tflite converter which is happening only when using nightly (it isn't happening when using tensorflow main branch). I tried as much as I can to create the minimal code to reproduce: \r\n\r\n    !pip install tf-nightly\r\n    import tensorflow as tf\r\n    import os\r\n    import numpy as np\r\n    \r\n    class EXAMPLE(tf.Module):\r\n    \r\n        @tf.function(input_signature=[tf.TensorSpec(shape=[100], dtype=tf.float32)])\r\n        def calculate(self, x):\r\n        \r\n          maxima_ind = tf.where(x > 0.8)\r\n          maxima_ind = tf.gather(maxima_ind,0,axis=1)\r\n    \r\n          maxima_ind = tf.cast(maxima_ind, dtype=tf.float32)\r\n    \r\n          if len(maxima_ind) > 10:\r\n              maxima_ind = tf.cast(maxima_ind, dtype=tf.float32)\r\n    \r\n          return maxima_ind\r\n          \r\n    to_export = EXAMPLE()\r\n    np.random.seed(54)\r\n    buffer_size = 100\r\n    x1  = tf.convert_to_tensor(np.random.rand(buffer_size).astype('float32'))\r\n    \r\n    \r\n    solution = to_export.calculate(x1)\r\n    print(solution)\r\n    models_dir = '/content/model_example/'\r\n    tf.saved_model.save(to_export, models_dir)\r\n    imported = tf.saved_model.load(models_dir)\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(models_dir) # path to the SavedModel directory\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                            tf.lite.OpsSet.SELECT_TF_OPS]\r\n    \r\n    tflite_model = converter.convert()\r\n    with open(models_dir + 'model_example.tflite', 'wb') as f:\r\n      f.write(tflite_model)\r\n\r\nWhen running it, I'm getting this error: \r\n\r\n    Exception                                 Traceback (most recent call last)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n        216                                                  debug_info_str,\r\n    --> 217                                                  enable_mlir_converter)\r\n        218       return model_str\r\n    \r\n    4 frames\r\n    Exception: <unknown>:0: error: loc(\"cond@__inference_calculate_3155\"): 'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0\r\n    \r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n        ConverterError                            Traceback (most recent call last)\r\n        /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n            218       return model_str\r\n            219     except Exception as e:\r\n        --> 220       raise ConverterError(str(e))\r\n            221 \r\n            222   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n        \r\n        ConverterError: <unknown>:0: error: loc(\"cond@__inference_calculate_3155\"): 'tf.If' op 'then_branch' input type tensor<?xf32> is incompatible with input type tensor<?xi64> at index 0\r\n\r\nYou can also use this gist (which include the above code): https://colab.research.google.com/gist/AiaHaruv/6cac62614ef85f76db8bcfcfa0b8baae/conversion_bug.ipynb\r\nI understand there is a thing with the types but I'm using casting before the if statement and inside of it I'm actually doing nothing, and it isn't happening in the main branch..  \r\nAny help will be appreciated. Thank you \r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46656\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46656\">No</a>\n", "@abattery - thank you, where can I see the fix? (running the gist with installing the latest tf-nightly still throws the same error)"]}, {"number": 46655, "title": "google.protobuf.text_format.ParseError: 161:14 : Message type \"object_detection.protos.Optimizer\" has no field named \"i\".", "body": "sparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aarju/anaconda3/envs/demo_model/lib:/usr/lib/x86_64-linux-gnu:/home/aarju/anaconda3/envs/caffe/lib:/usr/lib/x86_64-linux-gnu\r\n2021-01-25 14:30:04.810886: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aarju/anaconda3/envs/demo_model/lib:/usr/lib/x86_64-linux-gnu:/home/aarju/anaconda3/envs/caffe/lib:/usr/lib/x86_64-linux-gnu\r\n2021-01-25 14:30:04.810902: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2021-01-25 14:30:04.811643: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-25 14:30:04.814596: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-25 14:30:04.814714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-25 14:30:04.814742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]\r\nWARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\r\nW0125 14:30:04.820366 140452454930176 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nI0125 14:30:04.821369 140452454930176 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nTraceback (most recent call last):\r\n  File \"model_main_tf2.py\", line 113, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main_tf2.py\", line 104, in main\r\n    model_lib_v2.train_loop(\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/object_detection/model_lib_v2.py\", line 466, in train_loop\r\n    configs = get_configs_from_pipeline_file(\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/object_detection/utils/config_util.py\", line 139, in get_configs_from_pipeline_file\r\n    text_format.Merge(proto_str, pipeline_config)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 728, in Merge\r\n    return MergeLines(\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 802, in MergeLines\r\n    return parser.MergeLines(lines, message)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 827, in MergeLines\r\n    self._ParseOrMerge(lines, message)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 849, in _ParseOrMerge\r\n    self._MergeField(tokenizer, message)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 974, in _MergeField\r\n    merger(tokenizer, message, field)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 1048, in _MergeMessageField\r\n    self._MergeField(tokenizer, sub_message)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 974, in _MergeField\r\n    merger(tokenizer, message, field)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 1048, in _MergeMessageField\r\n    self._MergeField(tokenizer, sub_message)\r\n  File \"/home/aarju/anaconda3/envs/demo_model/lib/python3.8/site-packages/google/protobuf/text_format.py\", line 939, in _MergeField\r\n    raise tokenizer.ParseErrorPreviousToken(\r\ngoogle.protobuf.text_format.ParseError: 161:14 : Message type \"object_detection.protos.Optimizer\" has no field named \"i\".\r\n\r\n\r\n### System information\r\n\r\n\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:: 2.4\r\n-   **Python version**: : 3.7\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**: 10.2\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\n\r\n", "comments": ["@aarju123,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "this is protos error getting to run program, using tensorlow 2.4.1", "@aarju123,\r\nCould you please share the script you are running, so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46655\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46655\">No</a>\n"]}, {"number": 46654, "title": "micro: minor fix: Alphabetical order in build file", "body": "Change the ordering such that the alphabetical order is correct again", "comments": []}, {"number": 46653, "title": "Ignoring visible gpu device (device: 0, name: GeForce GTX 780M compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): From source\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): bazel 3.1.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version:  10.1/8\r\n- GPU model and memory: dual GeForce GTX 780M with 2 GB each\r\n\r\n\r\n**Describe the problem**\r\n \r\n I built tensorflow (version 2.4.1) from source becuase my old gpu compute capability is 3.0.\r\n I followed the instructions from https://www.tensorflow.org/install/source\r\n and from https://medium.com/@mccann.matt/compiling-tensorflow-with-cuda-3-0-support-42d8fe0bf3b5\r\n \r\n I did the build process 5 times, every time I change some parameters in ./configure\r\n I also manualy edited .tf_configure.bazelrc (suggested parameters from https://github.com/tensorflow/tensorflow/issues/24126#issuecomment-443847200) to turn XLA off by\r\n removing --config=XLA\r\n and \r\n adding the line build --define with_xla_support=false\r\n \r\n and every time I run python to check if tensorflow is using my gpu, I got False as shown below.\r\n \r\n `>>> tf.test.is_gpu_available(True,3.0)\r\n2021-01-25 09:21:44.146701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.148484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 780M computeCapability: 3.0\r\ncoreClock: 0.797GHz coreCount: 8 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 149.01GiB/s\r\n2021-01-25 09:21:44.148617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.150416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:07:00.0 name: GeForce GTX 780M computeCapability: 3.0\r\ncoreClock: 0.797GHz coreCount: 8 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 149.01GiB/s\r\n2021-01-25 09:21:44.150466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-01-25 09:21:44.150508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-01-25 09:21:44.150535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-01-25 09:21:44.150559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-01-25 09:21:44.150585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-01-25 09:21:44.150611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-01-25 09:21:44.150638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-01-25 09:21:44.150664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-01-25 09:21:44.150773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.152515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.154623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.156318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1816] Ignoring visible gpu device (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\r\n2021-01-25 09:21:44.156445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-25 09:21:44.158101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1816] Ignoring visible gpu device (device: 1, name: GeForce GTX 780M, pci bus id: 0000:07:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\r\n2021-01-25 09:21:44.158151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-25 09:21:44.158161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \r\n2021-01-25 09:21:44.158167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \r\n2021-01-25 09:21:44.158173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \r\nFalse\r\n`\r\nSo I did not know what do now.", "comments": ["@eagle-hub \r\nPlease share simple indented stand alone code to replicate the issue or if possible share a colab git with the error reported.", "@Saduf2019 \r\n`\r\nimport tensorflow as tf\r\n\r\ntf.test.is_gpu_available()\r\n\r\ntf.config.list_physical_devices('GPU')\r\n\r\ntf.test.is_gpu_available(True,3.0)\r\n\r\ntf.test.is_gpu_available()\r\n`\r\nI used jupyter to run code and also from terminal. I will attach 2 files for both running.\r\nPlease note that I'm running the code on my machine as I mentioned in the first comment.\r\n\r\n![py_tf](https://user-images.githubusercontent.com/13749446/105773252-4a255780-5f6c-11eb-9fdb-4dfefd805114.png)\r\n![py_tf_2](https://user-images.githubusercontent.com/13749446/105773288-56111980-5f6c-11eb-95b0-ca26649842ce.png)\r\n", "@tensorflowbutler @Saduf2019 \r\nAny advice on how to build from source and support GeForce GTX 780M compute capability: 3.0", "Unfortunately we don't have an exhaustive guide for TF build with cuda compute 3.0\r\nI think reaching out to community (SO) can be your best bet here.\r\nI found one [article](https://medium.com/@mccann.matt/compiling-tensorflow-with-cuda-3-0-support-42d8fe0bf3b5) that may help in your case.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46653\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46653\">No</a>\n", "I have the same problem but I tried with version 2.3.2 since it supports cuda 10.1 that works with compute capability 3.0.\r\n\r\nIn my case I followed [https://github.com/tensorflow/tensorflow/issues/27840] to turn off XLA and edited `.tf_configure.bazelrc`, after running `./configure` script, and appended ` --define with_xla_support=false` to `build:xla` line.\r\n\r\nAfter a successful compilation I run the example:\r\n\r\n```\r\npython3 -c \"import tensorflow as tf; print(\\\"Num GPUs Available: \\\", len(tf.config.list_physical_devices('GPU')))\"\r\n```\r\nand the output:\r\n\r\n```\r\n...\r\n... I tensorflow/core/common_runtime/gpu/gpu_device.cc:1812] Ignoring visible gpu device (device: 0, name: Quadro K600, pci bus id: 0\r\n000:04:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5. \r\nNum GPUs Available:  0\r\n```\r\n\r\nI gave it a second try but this time I removed `build:xla` line and added\r\n\r\n```\r\nbuild --define with_xla_support=false\r\nbuild --action_env=TF_ENABLE_XLA=0\r\n```\r\n\r\nunfortunately with the same result.\r\n\r\nIs there a proper way to disable XLA in v2.x? \r\nis `build --define=with_xla_support=false` the same as `build --define with_xla_support=false`?\r\n\r\nAlso notice that `./configure` script explicitly says that compute capability 3.0 is not supported\r\n\r\n```\r\nPlease note that each additional compute capability significantly increases your build time and binary size,\r\nand that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.0]: 3.0\r\n\r\n\r\nWARNING: XLA does not support CUDA compute capabilities lower than 3.5. Disable XLA when running on older GPUs.\r\n```\r\n\r\ndoes this mean that v2.x can never run on a gpu with compute capability 3.0?\r\n\r\n@ymodak answer does not help because the article is for v1.x and v1.x is known to work with cc 3.0", "I solved the problem in my case using tensorflow 2.1.3 + cuda 10.1 + cudnn 7.6.5 + bazel 0.27.2:\r\n\r\n```\r\n...\r\n2021-04-26 19:28:16.651806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but the\r\nre must be at least one NUMA node, so returning NUMA node zero \r\n2021-04-26 19:28:16.652966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0 \r\nNum GPUs Available: \u00a01\r\n```\r\nlooking at the code in `tensorflow/core/common_runtime/gpu/gpu_device.cc` it should also work with v2.2 and for greater versions it might work defining TF_EXTRA_CUDA_CAPABILITIES in bazel command line \r\n\r\n```\r\n--copt=-DTF_EXTRA_CUDA_CAPABILITIES=3.0\r\n```", "This is to confirm that the following recipe solved this problem in my case with tensorflow 2.3.2 + cuda 10.1 + cudnn 7.6.5 + bazel 3.10:\r\n\r\n1) disable XLA (not supported with compute capability 3.0) by removing the line `build:xla` in `.tf_configure.bazelrc` and adding:\r\n\r\n```\r\nbuild --define=with_xla_support=false \r\nbuild --action_env TF_ENABLE_XLA=0\r\n```\r\n\r\n2) for tensorflow > 2.2 the code changed and it is necessary to define `TF_EXTRA_CUDA_CAPABILITIES` in bazel command line:\r\n```\r\n--copt=-DTF_EXTRA_CUDA_CAPABILITIES=3.0\r\n```", "Which version of gcc are you using? Another question: is it bazel 3.1.0? I can't find bazel 3.10\r\n\r\n> This is to confirm that the following recipe solved this problem in my case with tensorflow 2.3.2 + cuda 10.1 + cudnn 7.6.5 + bazel 3.10:\r\n> \r\n> 1. disable XLA (not supported with compute capability 3.0) by removing the line `build:xla` in `.tf_configure.bazelrc` and adding:\r\n> \r\n> ```\r\n> build --define=with_xla_support=false \r\n> build --action_env TF_ENABLE_XLA=0\r\n> ```\r\n> \r\n> 1. for tensorflow > 2.2 the code changed and it is necessary to define `TF_EXTRA_CUDA_CAPABILITIES` in bazel command line:\r\n> \r\n> ```\r\n> --copt=-DTF_EXTRA_CUDA_CAPABILITIES=3.0\r\n> ```\r\n\r\n", "> Which version of gcc are you using? Another question: is it bazel 3.1.0? I can't find bazel 3.10\r\n\r\n`gcc (Debian 8.3.0-6) 8.3.0`\r\n\r\nyes it is a typo, I used bazel 3.1.0\r\n", "Thanks for the prompt reply!\r\n\r\n> > Which version of gcc are you using? Another question: is it bazel 3.1.0? I can't find bazel 3.10\r\n> \r\n> `gcc (Debian 8.3.0-6) 8.3.0`\r\n> \r\n> yes it is a typo, I used bazel 3.1.0"]}, {"number": 46652, "title": "Keras model could save to h5 but not savedModel, call() missing argument", "body": "I am using TF 2.2, the model is a keras model written in `tf.keras.engine.training_v1.Model`. I could save the model to h5 using `model.save(save_format='h5)`, but if save using savedModel by just `model.save()`. the error is \r\n```\r\nTypeError: call() missing 1 required positional argument: 'state'\r\n```\r\nHow could it be?.. The big question here is that: why is there some keras model which work well and could saved to .h5 but have this error when saved to SavedModel\r\n\r\nFull stack:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 423, in learning_phase_scope\r\n    yield\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 951, in save\r\n    obj, export_dir, signatures, options, meta_graph_def)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 1008, in _build_meta_graph\r\n    checkpoint_graph_view)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_serialization.py\", line 75, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 143, in list_functions\r\n    self._serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1656, in _list_functions_for_serialization\r\n    Model, self)._list_functions_for_serialization(serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 2439, in _list_functions_for_serialization\r\n    .list_functions_for_serialization(serialization_cache))\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py\", line 87, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 77, in functions_to_serialize\r\n    serialization_cache).functions_to_serialize)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 92, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py\", line 53, in _get_serialized_attributes_internal\r\n    serialization_cache))\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 101, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 153, in wrap_layer_functions\r\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 272, in _replace_child_layer_functions\r\n    serialization_cache).functions)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 92, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 101, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 153, in wrap_layer_functions\r\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 272, in _replace_child_layer_functions\r\n    serialization_cache).functions)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 92, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 101, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 191, in wrap_layer_functions\r\n    fn.get_concrete_function()\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 546, in get_concrete_function\r\n    self.call_collection.add_trace(*args, **kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 421, in add_trace\r\n    fn.get_concrete_function(*args, **kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 547, in get_concrete_function\r\n    return super(LayerCall, self).get_concrete_function(*args, **kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 959, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 865, in _get_concrete_function_garbage_collected\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 524, in wrapper\r\n    ret = method(*args, **kwargs)\r\n  File \"/home/litchy/anaconda3/envs/rec/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 566, in call_and_return_conditional_losses\r\n    return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)\r\nTypeError: call() missing 1 required positional argument: 'state'\r\n\r\n```\r\nThe model is not short, so I am not posting it. If you need I would post it.", "comments": ["@Litchilitchy \r\nPlease share a simple indented stand alone code for us to replicate the issue faced.\r\n", "I am using the code of,\r\n\r\nfirst copy code from https://github.com/shenweichen/DeepCTR and use the `deepctr` package\r\n\r\nand \r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names\r\nfrom deepctr.models import DIEN\r\n\r\n\r\ndef get_xy_fd(use_neg=False, hash_flag=False, get_test=False):\r\n    feature_columns = [SparseFeat('user', 3, embedding_dim=10, use_hash=hash_flag),\r\n                       SparseFeat('gender', 2, embedding_dim=4, use_hash=hash_flag),\r\n                       SparseFeat('item_id', 3 + 1, embedding_dim=8, use_hash=hash_flag),\r\n                       SparseFeat('cate_id', 2 + 1, embedding_dim=4, use_hash=hash_flag),\r\n                       DenseFeat('pay_score', 1)]\r\n\r\n    feature_columns += [\r\n        VarLenSparseFeat(SparseFeat('hist_item_id', vocabulary_size=3 + 1, embedding_dim=8, embedding_name='item_id'),\r\n                         maxlen=4, length_name=\"seq_length\"),\r\n        VarLenSparseFeat(SparseFeat('hist_cate_id', 2 + 1, embedding_dim=4, embedding_name='cate_id'), maxlen=4,\r\n                         length_name=\"seq_length\")]\r\n\r\n    behavior_feature_list = [\"item_id\", \"cate_id\"]\r\n    uid = np.array([0, 1, 2])\r\n    ugender = np.array([0, 1, 0])\r\n    iid = np.array([1, 2, 3])  # 0 is mask value\r\n    cate_id = np.array([1, 2, 2])  # 0 is mask value\r\n    score = np.array([0.1, 0.2, 0.3])\r\n\r\n    hist_iid = np.array([[1, 2, 3, 0], [1, 2, 3, 0], [1, 2, 0, 0]])\r\n    hist_cate_id = np.array([[1, 2, 2, 0], [1, 2, 2, 0], [1, 2, 0, 0]])\r\n\r\n    behavior_length = np.array([3, 3, 2])\r\n\r\n    feature_dict = {'user': uid, 'gender': ugender, 'item_id': iid, 'cate_id': cate_id,\r\n                    'hist_item_id': hist_iid, 'hist_cate_id': hist_cate_id,\r\n                    'pay_score': score, \"seq_length\": behavior_length}\r\n\r\n    if use_neg:\r\n        feature_dict['neg_hist_item_id'] = np.array([[1, 2, 3, 0], [1, 2, 3, 0], [1, 2, 0, 0]])\r\n        feature_dict['neg_hist_cate_id'] = np.array([[1, 2, 2, 0], [1, 2, 2, 0], [1, 2, 0, 0]])\r\n        feature_columns += [\r\n            VarLenSparseFeat(SparseFeat('neg_hist_item_id', vocabulary_size=3 + 1, embedding_dim=8, embedding_name='item_id'),\r\n                             maxlen=4, length_name=\"seq_length\"),\r\n            VarLenSparseFeat(SparseFeat('neg_hist_cate_id', 2 + 1, embedding_dim=4, embedding_name='cate_id'),\r\n                             maxlen=4, length_name=\"seq_length\")]\r\n\r\n    x = {name: feature_dict[name] for name in get_feature_names(feature_columns)}\r\n    y = np.array([1, 0, 1])\r\n    if not get_test:\r\n        return x, y, feature_columns, behavior_feature_list\r\n    else:\r\n        return x\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    if tf.__version__ >= '2.0.0':\r\n        tf.compat.v1.disable_eager_execution()\r\n\r\n    USE_NEG = True\r\n    x, y, feature_columns, behavior_feature_list = get_xy_fd(use_neg=USE_NEG)\r\n\r\n    model = DIEN(feature_columns, behavior_feature_list,\r\n                 dnn_hidden_units=[4, 4, 4], dnn_dropout=0.6, gru_type=\"AUGRU\", use_negsampling=USE_NEG)\r\n\r\n    model.compile('adam', 'binary_crossentropy',\r\n                  metrics=['binary_crossentropy'])\r\n    history = model.fit(x, y, verbose=1, epochs=2, validation_split=0.5)\r\n    model.save(\"tf_dien\")\r\n```", "@Litchilitchy \r\nPlease share a colab gist with the issue reported.", "I choose to close the issue because the code is too much, I would open another one if I could find the minimum reproduce code.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46652\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46652\">No</a>\n"]}, {"number": 46651, "title": "Update load.py", "body": "Simple fix for keras model load for raggedTensor. Otherwise there is `AttributeError` about `raggedTensorSpec` not having `name`\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46651) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@blackyang It would probably make sense to add a unit test that reproduces the issue you did run into.\r\n\r\nI've been poking around trying to understand how signatures that refer to RaggedTensors are saved. As far as I understand it, function tracing and model saving take a RaggedTensor argument and do ```nest.flatten(arg, expand_composites=True)``` which results in the arguments being the underlying shape of the RaggedTensor values and row_splits elements.\r\n\r\nIt is possible that this has to be taking into consideration when evaluating a loaded model.", "@omalleyt12 Thanks you! I found 1 failed check about `import/copybara`, do you know how to see the detailed error message?"]}, {"number": 46650, "title": "How can I build this for Intel GPU (to use OpenCL)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Source \r\n- TensorFlow version: Release 2.5.1\r\n- Python version: Python 2.7.15+\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: Intel GPU \r\n\r\n\r\n**Describe the problem**\r\nCompiled with -DCL_DELEGATE_NO_GL flags in Makefile however I get the following error : \r\n./tensorflow/lite/delegates/gpu/api.h:262:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetInputShape(index,const Dimensions& dimensions) = 0;\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1> Add -DCL_DELEGATE_NO_GL in Makefile \r\n2> Added tensorflow/lite/delegates/gpu/*.cc to the list of sources in Makefile \r\n3> Included /usr/include to add cl.h \r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nCOMPLETE ERROR LOGS: \r\nIn file included from /usr/include/EGL/eglplatform.h:130:0,\r\n                 from /usr/include/EGL/egl.h:39,\r\n                 from ./tensorflow/lite/delegates/gpu/gl/portable_gl31.h:21,\r\n                 from ./tensorflow/lite/delegates/gpu/api.h:50,\r\n                 from tensorflow/lite/delegates/gpu/api.cc:16:\r\n./tensorflow/lite/delegates/gpu/api.h:262:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetInputShape(index,const Dimensions& dimensions) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:271:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetInputObjectDef(int index, ObjectDef def) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:272:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetOutputObjectDef(int index, ObjectDef def) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:273:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetAllInputObjectDefsTo(ObjectDef def) {\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:280:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetAllOutputObjectDefsTo(ObjectDef def) {\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:293:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status Build(std::unique_ptr<InferenceRunner>* runner) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:310:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status GetInputObject(int index, TensorObject* object) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:311:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status GetOutputObject(int index, TensorObject* object) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:312:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetInputObject(int index, TensorObject object) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:313:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status SetOutputObject(int index, TensorObject object) = 0;\r\n                 ^\r\n./tensorflow/lite/delegates/gpu/api.h:315:17: error: expected unqualified-id before \u2018int\u2019\r\n   virtual absl::Status Run() = 0;", "comments": ["You should use CMake to build it.\r\nhttps://www.tensorflow.org/lite/guide/build_cmake#opencl_gpu_delegate\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46650\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46650\">No</a>\n", "EGL_NO_X11 seems to do the trick", "Thank you for the comments will try this out and update here ."]}, {"number": 46649, "title": "MGB track", "body": "https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/python/training/tracking/base.py#L498-L990", "comments": ["@MGBtrust \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46647, "title": "Redo refactoring gather.h from TFLite reference_ops.h", "body": "New PR2 for issue #45196 (the old one was closed due to merging errors)", "comments": []}, {"number": 46646, "title": " Micro: port op CAST from Lite", "body": "PR5 (hopefully last PR) for issue #45608", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46645, "title": "Reloading weights give small difference", "body": "\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I modified a TPU colab notebook\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): colab\r\n- TensorFlow version (use command below): 2.4\r\n- Python version:\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: TPU v2\r\n- GPU model and memory: None\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nDuring the training, I am computing the validation accuracy at each epochs, with a callback function and then save the weight when the model improved.\r\nWhen reloading the weight inside the same session, the model give small difference regarding the validation metric. I don't know if the issue comes from the loading or saving part.\r\n\r\n\r\n**Describe the expected behavior**\r\nthe model should has the same validation performance .\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nlink of the colab to reproduce the results : \r\nhttps://colab.research.google.com/drive/1LnEgPmVtfuX9yaFZftpbOUlPPU4ecUvL#scrollTo=7Qv8rC4aVOFB&uniqifier=2\r\n\r\n\r\nAs you can see : 0.9588235294117647 is different from  0.9573529411764706\r\n> Epoch 1/5\r\n> \r\n> Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\r\n>  6/23 [======>.......................] - ETA: 6s - loss: 1.6750 - accuracy: 0.2327WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 11.4604s). Check your callbacks.\r\n> WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 11.4604s). Check your callbacks.\r\n> 23/23 [==============================] - 131s 410ms/step - loss: 1.6348 - accuracy: 0.2524\r\n> val_loss: 1.5019999742507935 -- val_categorical_accuracy: 0.365 -- samples : 680\r\n> \r\n>  model saved, improvement from 0.0 to 0.36470588235294116\r\n> \r\n> Epoch 2/5\r\n> \r\n> Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\r\n> 23/23 [==============================] - 9s 410ms/step - loss: 1.1962 - accuracy: 0.5953\r\n> val_loss: 0.5659999847412109 -- val_categorical_accuracy: 0.854 -- samples : 680\r\n> \r\n>  model saved, improvement from 0.36470588235294116 to 0.8544117647058823\r\n> \r\n> Epoch 3/5\r\n> \r\n> Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\r\n> 23/23 [==============================] - 9s 411ms/step - loss: 0.4679 - accuracy: 0.8442\r\n> val_loss: 0.19499999284744263 -- val_categorical_accuracy: 0.934 -- samples : 680\r\n> \r\n>  model saved, improvement from 0.8544117647058823 to 0.9338235294117647\r\n> \r\n> Epoch 4/5\r\n> \r\n> Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\r\n> 23/23 [==============================] - 9s 412ms/step - loss: 0.2451 - accuracy: 0.9188\r\n> val_loss: 0.125 -- val_categorical_accuracy: 0.954 -- samples : 680\r\n> \r\n>  model saved, improvement from 0.9338235294117647 to 0.9544117647058824\r\n> \r\n> Epoch 5/5\r\n> \r\n> Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\r\n> 23/23 [==============================] - 10s 416ms/step - loss: 0.1769 - accuracy: 0.9334\r\n> val_loss: 0.1289999932050705 -- val_categorical_accuracy: 0.959 -- samples : 680\r\n> \r\n>  model saved, improvement from 0.9544117647058824 to 0.9588235294117647\r\n> \r\n> Loading best model... ckpt_model.h5\r\n> final acc :  0.9573529411764706", "comments": ["@kashyapraval  I thank you for your reply. I have re-check it few times again few minutes ago and I still have the issue with tpu, but not gpu. Were you using TPU ? ", "@Shiro-LK after some trials, yes able to reproduce the issue. Shall have a look at it.", "@Shiro-LK,\r\nI did not face any issues while running the code with TF v2.4 on TPUs. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5894855508d0bd676e7d6b78a221fa17/46645.ipynb#scrollTo=5wU96EmMN6f-&line=1&uniqifier=1). Thanks!", "@amahendrakar  I thank you for your reply. Can you launch few times the script ? I try again, and it seems to have some randomness. It will not bug 100% of the time which is very weird.\r\n\r\nEDIT : you can also launch the 5 folds in my script which also have the issue.", "Even when the accuracy scores match, the prediction scores do not match exactly. Two checks made:\r\n1. Recording prediction scores during callbacks(end of each epoch) and comparing to the scores after loading corresponding to the checkpoint model. There is a slight mismatch (~always: even when the accuracies match)\r\n2. Using tpu_strategy.scope() Vs otherwise: Last cell in the [notebook](https://colab.research.google.com/drive/1MXEOIjEJKn_KW5wMaBLWFI6M4zf3sRXq?usp=sharing) \r\nThe prediction scores still differ slightly and also the weights. Suspected precision error somewhere?", "@kashyapraval  thank you for your reply. I will double check if the issue is still here with gpu to be sure it is related only to tpu", "@Shiro-LK the issue is with the TPU. [Here](https://colab.research.google.com/drive/15OZHS6YX5ZpBVGS8Mru1WKae91WdiXZz?usp=sharing) you may observe that irrespective of what pretrained model we choose, the difference in weights crops up (in mostly in the conv layers\r\nMoreover the difference exists when exactly one is loaded in the TPUStrategy's scope.", "@kashyapraval  Thanks, you are right. \r\n\r\n@amahendrakar  it seems the issue exist as I am not the only one to get it", "Can you try setting `seed` for the `kernel_initializer` in all the `tf.keras.layers` used in your model?\r\nSee similar [issue](https://github.com/tensorflow/tensorflow/issues/47722#issuecomment-806146182) to know more.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46645\">No</a>\n"]}, {"number": 46644, "title": "Unable to tf.saved_model.load() from a trained Keras model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\nI have a Saved Model.  When I attempt to load it in the JVM, it crashes the JVM - see https://github.com/tensorflow/java/issues/194 .  When I use `tf.saved_model.load()`, it fails complaining about, `The same saveable will be restored with two names: layer_with_weights-0/layer_with_weights-1/layer_with_weights-0/_table/.ATTRIBUTES/table`.\r\n\r\nThe model does work in TF-Serving and when using `keras.models.load_model()`\r\n\r\n**Describe the expected behavior**\r\nThe model should load everywhere and should not cause a core dump in the JVM.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe model is proprietary.  I am struggling with how to triage the issue into something that I can share.  If you have thoughts, please let me know!\r\n\r\n**Other info / logs**\r\nThe SavedModel is created from a Keras model.\r\n\r\nSee https://github.com/tensorflow/java/issues/194 for some JVM dump logs.", "comments": ["I have been attempting to triage a bit more.  I can reproduce 100% of the time on my model, I haven't been able to simplify to a test case that I can reproduce.  I wanted to share what I have done and learned to hopefully prompt some ideas on where to investigate next.\r\n\r\nFirst, this issue not only segfaults Java, it also segfaults Python.\r\n\r\nSecond, I attempted to save each of the layers of my model to see which of my layers is the issue.  I have limited it down to about 30 lines of code for the Keras Functional models that fail:\r\n```python\r\ndef categorical_embedding(vocabulary, embedding_dimensions, max_norm_embedding, name, num_biases): \r\n  categorical_input = keras.Input(shape=1, dtype=\"int64\", name=name)\r\n  \r\n  lookup_layer = keras.layers.experimental.preprocessing.IntegerLookup(\r\n    num_oov_indices=1, vocabulary=vocabulary, mask_value=None\r\n  )\r\n  lookup_layer.weights[0].name = \"lookup_weights\" # fix for serialization - see https://github.com/tensorflow/tensorflow/issues/41244\r\n  lookup = lookup_layer(categorical_input)\r\n  \r\n  embedding = keras.layers.Embedding(\r\n    len(vocabulary) + 1, embedding_dimensions, input_length=1, name=\"embedding\"\r\n  )(lookup)\r\n  bias = keras.layers.Embedding(\r\n    len(vocabulary) + 1, num_biases, input_length=1,\r\n    embeddings_initializer=keras.initializers.Zeros(),\r\n    name=\"bias\"\r\n  )(lookup)\r\n  \r\n  squeeze = keras.layers.Lambda(lambda net: K.squeeze(net, -2), name=\"squeeze_to_one_embedding\")\r\n  \r\n#   max_norm = keras.constraints.MaxNorm(max_norm_embedding, axis=-1)\r\n#   embeddings_constraint = keras.layers.Lambda(lambda net: max_norm(net), name=\"embeddings_constraint\")\r\n\r\n  return categorical_input, keras.Model(\r\n    inputs=categorical_input, outputs=[squeeze(embedding), squeeze(bias)], name=f\"{name}_categorical_embedding\"\r\n  )\r\n```\r\nUnfortunately, I cannot reproduce the issue this simplified test case.\r\n\r\nFurther, our model train is a two-phase train --- the first model with this functional model does not show this issue; the second model does.  This two-phased train involves training once and then transferring some of the input, trunk, and heads to another train.  The model that is failing is part of this transfer.\r\n\r\nI have tested with TF 2.3.1 and 2.4.0.  Both cannot load/save this model.\r\n\r\nOther warnings/errors that I have seen are:\r\n```python\r\nInvalidArgumentError: Shape [140185022619568,-4294967096] has dimensions with values below -1 (where -1 means unknown)\r\nInvalidArgumentError: Shape [140185009137680,140185009137680] is too large (more than 2**63 - 1 entries)\r\n2021-01-25 22:20:16,729 - absl - WARNING - Found untraced functions such as dense_9_layer_call_and_return_conditional_losses, dense_9_layer_call_fn, concatenate_3_layer_call_and_return_conditional_losses, concatenate_3_layer_call_fn, dense_11_layer_call_and_return_conditional_losses while saving (showing 5 of 195). These functions will not be directly callable after loading.\r\n2021-01-25 22:23:18,762 - tensorflow - WARNING - 11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f8890406440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n```\r\n\r\nAny thoughts on where to investigate next are much appreciated!", "Any luck in putting together a reproducible example?", "Unfortunately, no.  The issue still exists, however, I still cannot reproduce with code/data that I can share.\r\n\r\nIf you have any recommendations on how best to reproduce, let me know.  If not, I reckon, this should be closed.", "Closing this issue for now. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46644\">No</a>\n"]}, {"number": 46643, "title": "Find bogomips on aarch64", "body": "Detect CPU frequency on aarch64.  Fixes #42545 and #38260.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46643) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 46642, "title": "replace alternative operator to fix msvc build break", "body": "https://docs.microsoft.com/en-us/cpp/cpp/cpp-built-in-operators-precedence-and-associativity#alternative-spellings\r\n", "comments": []}, {"number": 46641, "title": "tf.transpose returns incorrect shape or throws concatenation error when part of keras model", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip installed\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Cuda 11.0/ 8.0.4\r\n- GPU model and memory: NVIDIA GeForce GTX 1050 / 4.0GB Memory\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n- When run as part of a keras model, tf.tranpose of a rank 2 tensor gives unexpected shape . \r\n- When run  eagerly tf.transpose gives expected shape. \r\n- If the first dimension is greater than 32 then tf.transpose either returns an incorrect shape or throws a concatenation error\r\n- This issue also affects tf.matmul(a, b, transpose_b=True)\r\n\r\n**Describe the expected behavior**\r\nGiven a tensor of shape(i, j) tf.transpose returns a tensor of  shape (j, i) . As it does in eager mode\r\nUsed for calculating similarities, similar in this example https://keras.io/examples/vision/metric_learning/\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1MIXzVp1Jqsu-eypWFeNavW1bk3-B0UTG?usp=sharing\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ea31d1156401c60c60c416f66052dd97/46641.ipynb). Thanks!", "@jasonhillary When I provided `batch_size` parameter to `model.predict`, both shapes are same as shown in this [gist](https://colab.research.google.com/gist/jvishnuvardhan/6c68afcc72034c530a2eb6dd48d7a84f/46641.ipynb). \r\n\r\nThe following line I changed from\r\n\r\n`transpose_model = m.predict(v)`\r\nto\r\n`transpose_model = m.predict(v,batch_size=64)`\r\n\r\nOutput is as shown below.\r\n```\r\neager shape:  (128, 64) model shape : (128, 64)\r\neager shape:  (128, 64) model shape : (128, 64)\r\n```\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan thank you very much, that did indeed resolve it. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46641\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46641\">No</a>\n"]}, {"number": 46640, "title": "AttributeError: 'Tensor' object has no attribute 'numpy'", "body": "Hi, guys, recently I'm trying to built my own metrics class using the sklearn.metrics, but when I running the update_state funcation inherit from the tensorflow.keras.metrics.Metric, I find the argument in update_state function which are y_true and y_pred is Tensor object but I need numpy array, I have tried the method given in the documentation which says using y_true.numpy but I got an error: AttributeError: 'Tensor' object has no attribute 'numpy'. I have tried many methods following the Internet but it still doesn't work. Could you help me solve this? Here are my code, thanks!\r\n\r\nclass SelfF1(Metric):\r\n    def __init__(self, average, name=\"self_f1\", **kwargs):\r\n        super(SelfF1, self).__init__(name=name, **kwargs)\r\n        self.f1_value = self.add_weight(name=\"sf\", initializer=\"zeros\", dtype=\"float64\")\r\n        self.average = average\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n\r\n        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1,))\r\n        if len(y_true.shape) == 2 and y_true.shape[1] != 1:\r\n            y_true = tf.reshape(tf.argmax(y_true, axis=1), shape=(-1,))\r\n\r\n        f1_value = f1_score(y_true=y_true.numpy(), y_pred=y_pred.numpy(), average=self.average)\r\n\r\n        self.f1_value.assign(f1_value)\r\n\r\n    def result(self):\r\n        return self.f1_value\r\n\r\n    def reset_states(self):\r\n        self.f1_value.assign(0.0)", "comments": ["@YangHan-Morningstar,\r\nOn trying to implement the custom metrics in a sample code I am facing an error stating `TypeError: __init__() missing 1 required positional argument: 'average'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/eb9bde2645ed403f4a337dab576c832d/46640.ipynb).\r\n\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using.\r\n\r\nAlso, please take a look at [this guide](https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_metrics) to implement custom metrics and check if helps. Thanks!", "My tensorflow version is 2.0.0 and I have followed this guide. I found the\ny_true and y_predict is Tensor object but I need numpy array.\n\nOn Mon, Jan 25, 2021 at 7:25 PM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> @YangHan-Morningstar <https://github.com/YangHan-Morningstar>,\n> On trying to implement the custom metrics in a sample code I am facing an\n> error stating TypeError: __init__() missing 1 required positional\n> argument: 'average'. Please find the gist of it here\n> <https://colab.research.google.com/gist/amahendrakar/eb9bde2645ed403f4a337dab576c832d/46640.ipynb>\n> .\n>\n> In order to reproduce the issue reported here, could you please provide\n> the TensorFlow version, the complete code and the dataset you are using.\n>\n> Also, please take a look at this guide\n> <https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_metrics>\n> to implement custom metrics and check if helps. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46640#issuecomment-766748894>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AQE4IZF3GEN3Q6WH5FKU2ODS3VIKVANCNFSM4WQSEMOQ>\n> .\n>\n", "@YangHan-Morningstar,\r\nCould you please share the Python sciprt/notebook you are running, so that we can reproduce the issue on our end. Thanks!", "Sure, here it is.\n\nfrom sklearn.metrics import recall_score\n\nclass Self_Recall(tf.keras.metrics.Metric):\n    def __init__(self, average=\"macro\", name=\"self_recall\", **kwargs):\n        super(Self_Recall, self).__init__(name=name, **kwargs)\n        self.recall_value = self.add_weight(name=\"recall_value\",\ninitializer=\"zeros\")\n        self.average = average\n\n    def update_state(self, y_true, y_pred):\n        y_true_numpy = y_true.numpy()\n        y_pred_numpy = y_pred.numpy()\n\n        value = recall_score(y_true_numpy, y_pred_numpy, average=self.average)\n        self.recall_value.assign(value)\n\n    def result(self):\n        return self.recall_value\n\n    def reset_states(self):\n        self.recall_value.assign(0.0)\n\n\nOn Tue, Jan 26, 2021 at 9:12 PM Abhilash Mahendrakar <\nnotifications@github.com> wrote:\n\n> @YangHan-Morningstar <https://github.com/YangHan-Morningstar>,\n> Could you please share the Python sciprt/notebook you are running, so that\n> we can reproduce the issue on our end. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46640#issuecomment-767532122>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AQE4IZCSA3IGN4ZHG3SDLRTS325T3ANCNFSM4WQSEMOQ>\n> .\n>\n", "@YangHan-Morningstar,\r\nBy adding the `run_eagerly=True` argument to `model.compile`, I was able to run the code without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ce9f58bb1b51fe2cd124c56c4b52877e/46640.ipynb). \r\n\r\nPlease go through similar issues [#27519](https://github.com/tensorflow/tensorflow/issues/27519) and [#35393](https://github.com/tensorflow/tensorflow/issues/35393#issuecomment-662096789) for reference. Thanks!", "I have tried your gist of it and it do work but when I copy the code in the gist to my PyCharm and run it, it still tell me the error, I do not change any code, just copy and run! My tensorflow version is 2.0.0 and here is my picture, I'm very confused...\r\n![image](https://user-images.githubusercontent.com/67748964/106389738-eabdc080-641f-11eb-8f59-bc5fa2a72eab.png)\r\n\r\n", "> My tensorflow version is 2.0.0\r\n\r\n@YangHan-Morningstar,\r\nCould you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue? Thanks!", "Nice! It works in the version v2.4.1, thanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46640\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46640\">No</a>\n"]}, {"number": 46639, "title": "Incomplete ImageProjectiveTransformV3 documentation.", "body": "\"NEAREST\" option is missing in the documentation: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/image_ops.cc/#L141", "comments": []}, {"number": 46638, "title": "Valid device NotFoundError when running BatchNormalization op of Tensorflow 2.0.0", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 2019\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):  N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAs declared in the specification, tf.keras.layers.BatchNormalization should support to set the dtype to 'float64' . However, per our experiment, running it as the Norm layer in float64  will trigger some unexpected error: tensorflow.python.framework.errors_impl.NotFoundError: Could not find valid device for node.Node:{{node FusedBatchNormV3}}\r\n\r\n**Describe the expected behavior**\r\nNo exception during execution\r\n\r\n**Standalone code to reproduce the issue**\r\nx = np.random.randn(1, 2, 4, 4)\r\nx=tf.convert_to_tensor(x, dtype=tf.float16)\r\ntf__Norm_64=tf.keras.layers.BatchNormalization(\r\n        axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\r\n        beta_initializer='zeros', gamma_initializer='ones',\r\n        moving_mean_initializer='zeros', moving_variance_initializer='ones',dtype='float64'\r\n)\r\nout_16_64 = tf_Norm_64(x_16)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@bugpromax \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/512a982aa8add5b3f5ad3a359d5bed80/untitled507.ipynb) and share all dependencies for us to replicate the issue reported.", "please check the [gist here](https://colab.research.google.com/drive/1VL5Mn55HmOAYaMWtLTpsVzipGhwtKbhe?usp=sharing)", "@bugpromax\r\nPlease share all dependencies, we do not have access to the gist shared.", "import tensorflow as tf\r\nimport numpy as np\r\n\r\nx = np.random.randn(1, 2, 4, 4)\r\nx_16=tf.convert_to_tensor(x, dtype=tf.float16)\r\ntf_Norm_64=tf.keras.layers.BatchNormalization(\r\naxis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\r\nbeta_initializer='zeros', gamma_initializer='ones',\r\nmoving_mean_initializer='zeros', moving_variance_initializer='ones',dtype='float64'\r\n)\r\nout_16_64 = tf_Norm_64(x_16)", "@bugpromax \r\nI ran the code shared on tf 2.4 and this error has been fixed in the stable version can you please upgrade to tf 2.4 and let us know.\r\nPlease fidn the gist here for [tf 2.4](https://colab.research.google.com/gist/Saduf2019/2fbfe8dcd7bbd4f3ff3ecb3c9c64eb74/untitled511.ipynb)", "I ran the code on tf 2.4 and found that the error can be fixed. Thanks for your reply\uff01", "@bugpromax \r\nGlad the issue is resolved, can you please move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46638\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46638\">No</a>\n"]}]