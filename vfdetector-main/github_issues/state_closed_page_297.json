[{"number": 45374, "title": "Tensorflow Developer Certificate Exam - PyCharm Plugin Problem", "body": "", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45374\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45374\">No</a>\n"]}, {"number": 45373, "title": "Converted TensorFlow Lite model is not a valid model in Android Studio", "body": "**System information**\r\n\r\nIssue encountered with own model but can also reproduced using the example code found here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb\r\n\r\nRunning in a Colaboratory notebook\r\n\r\nTensorFlow v2.3.0-0-gb36436b087 2.3.0\r\n\r\nAndroid Studio 4.1.1\r\n\r\n**Describe the current behavior**\r\n\r\nThe notebook runs as expected and the TensorFlow Lite model produces the expected output in Colaboratory.\r\n\r\nImporting the downloaded model into Android Studio 4.1.1 gives the error\r\n'Not a valid TensorFlow Lite model'\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nA successfully converted TensorFlow Lite LSTM model should be valid and usable in Android Studio\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe code used to reproduce is the example LSTM model\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb\r\n\r\n**Other info / logs** \r\n", "comments": ["The example scope is to demonstrate building a keras sequential model and its conversion into tflite.\r\nFor deploying a tf lite model into android platform you may try [examples](https://github.com/tensorflow/examples/tree/master/lite/examples) given here.", "The problem is with Android Studio.\r\n\r\nCopy pasting code from the examples given I can load and run the model even though Android Studio tells me it is an invalid model and refuses to import it. There is a ticket raised with  Android Studio.\r\n", "Thanks for your issue. Can you please tag the open ticket in this issue thread as well?", "On Google IssueTracker:\r\n\r\nSuccessfully converted TensorFlow Lite model is invalid model in Android Studio 4.1.1\r\n\r\nhttps://issuetracker.google.com/issues/174736305\r\n", "I have the same problem while importing. alongside this  whilie converting  my model\r\ntflite_model = converter.convert()  \r\n\r\nI am getting below warning.\r\n\r\nWARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\n\r\n\r\n", "@n9hal Did you end up finding a solution? I have the same warning on conversion. It does not run in the TFLite C++ api on Android\r\n", "@Parth220 No, Didn't find anything", "Any update on this one? I'm suffering from this problem too..", "Hi @pnovapps ! \r\nWe are checking to see whether you still need help in this issue. Have you checked in latest version of Android Studio/Tensorflow (2.5/2.6)yet ? Attaching relevant threads for reference. [link1](https://stackoverflow.com/a/66734683/11530462),[link2](https://github.com/tensorflow/tensorflow/issues/47571#issuecomment-791598653). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45373\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45373\">No</a>\n"]}, {"number": 45372, "title": "TextVectorization layer together with TensorBoard fails when trying to log the weights", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Version 2004 & Windows 10 Pro Version 20H2\r\n- TensorFlow installed from (source or binary): PyPi\r\n- TensorFlow version (use command below):  v2.3.1 & v2.4.0-rc3 & 2.5.0-dev20201203\r\n- Python version: 3.6.6\r\n- CUDA/cuDNN version: 10.1.243\r\n- GPU model and memory: GeForce GTX 1050 Ti (notebook) & GeForce GTX 980 Ti\r\n\r\n**Describe the current behavior**\r\nWhen trying to use TensorBoard with a model, which has a TextVectorization layer, the log_weights function in callbacks.py of tensorflow/python/keras runs into an exception when it tries to get the name of the layer where the weights reside - which I guess might be because the TextVectorization layer is still experimental, and as such this might be why.\r\n\r\n**Describe the expected behavior**\r\nEither the weights would have a name, or they would be skipped when TensorBoard tries to log them.\r\n\r\n**Standalone code to reproduce the issue**\r\nI've made an example showing the issue using Google Colab, and it can be accessed through this link: https://colab.research.google.com/drive/1wRbFp-O6txoUv01GA_thlwJu_VxkPeyX\r\n\r\n**Other info / logs**\r\nFor now I've added a few lines of code to TensorFlow locally, to just skip the layer if it's a TextVectorization layer - I don't know much about the internals of the layer, so I'm pretty much just shooting blindly there.\r\n![image](https://user-images.githubusercontent.com/15278940/101026115-c906a100-3576-11eb-9f76-e97e19db43cf.png)\r\n\r\nTraceback at the exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:/Projekter/Git/HeroAI/hero_ai.py\", line 334, in <module>\r\n    model = run()\r\n  File \"D:/Projekter/Git/HeroAI/hero_ai.py\", line 283, in run\r\n    history = train(model, train_dataset, test_dataset, callbacks)\r\n  File \"D:/Projekter/Git/HeroAI/hero_ai.py\", line 228, in train\r\n    callbacks=callbacks)\r\n  File \"C:\\Users\\marcu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1145, in fit\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"C:\\Users\\marcu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 428, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"C:\\Users\\marcu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 2339, in on_epoch_end\r\n    self._log_weights(epoch)\r\n  File \"C:\\Users\\marcu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 2397, in _log_weights\r\n    weight_name = weight.name.replace(':', '_')\r\nAttributeError: 'TrackableWeightHandler' object has no attribute 'name'\r\n\r\nProcess finished with exit code 1\r\n```", "comments": ["@HeroGamers,\r\nLooking at [this comment](https://github.com/tensorflow/tensorflow/issues/41244#issuecomment-730210764) from a similar issue, I was able to run the code without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/bb9bafc3228d94eccd5d235e41a46e8d/45372.ipynb). Thanks!", "@amahendrakar\nYup, that seems to be related to the same problem!\nGuessing this issue can be closed now then, since it has been referenced in the other issue, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45372\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45372\">No</a>\n"]}, {"number": 45370, "title": "TensorFlow 1.15.4 artifacts on Maven Central?", "body": "Hello TensorFlow team!\r\n\r\nAre you planning to upload a patch for TensorFlow 1.15.4  ( https://github.com/tensorflow/tensorflow/releases/tag/v1.15.4 ) to Maven Central? The latest available version on Maven is 1.15.0 ( https://mvnrepository.com/artifact/org.tensorflow/tensorflow )", "comments": ["We don't have anyone left working on Java at the moment. This is a task that should be picked up by SIG JVM.", "@mihaimaruseac thank you for your response! Is there a tag I can you use here to attract someone from SIG JVM?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "@Kislovskiy [Here](https://github.com/tensorflow/community/tree/master/sigs) is the link to the SIG community. Thanks!"]}, {"number": 45369, "title": "Align PPD op between TFL and TFLM", "body": "Avoid floating point imprecision issues on different platforms by\r\ncasting to double before critical calculations.\r\n\r\nThis is fixing issue: https://github.com/tensorflow/tensorflow/issues/45368", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45368, "title": "Detection postprocess operator output differs between TFL and TFLM", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source): 6c0245b27c3b5dd319d3021b05c89a0cd17beb20\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nDetection post process operator output differs between TFL and TFLM because of floating point imprecision on different platforms. It can be fixed by e.g. this change in both kernels:\r\n\r\n#if 1\r\n\r\nfloat ycenter = static_cast<float>(\r\n    static_cast<double>(box_centersize.y) /\r\n    static_cast<double>(scale_values.y) *\r\n    static_cast<double>(anchor.h) + static_cast<double>(anchor.y));\r\nfloat xcenter = static_cast<float>(\r\n    static_cast<double>(box_centersize.x) /\r\n    static_cast<double>(scale_values.x) *\r\n    static_cast<double>(anchor.w) + static_cast<double>(anchor.x));\r\nfloat half_h = static_cast<float>(\r\n    0.5 * (std::exp(static_cast<double>(box_centersize.h) /\r\n                    static_cast<double>(scale_values.h))) *\r\n    static_cast<double>(anchor.h));\r\nfloat half_w = static_cast<float>(\r\n    0.5 * (std::exp(static_cast<double>(box_centersize.w) /\r\n                    static_cast<double>(scale_values.w))) *\r\n    static_cast<double>(anchor.w));\r\n\r\n#else\r\n\r\nfloat ycenter = box_centersize.y / scale_values.y * anchor.h + anchor.y;\r\nfloat xcenter = box_centersize.x / scale_values.x * anchor.w + anchor.x;\r\nfloat half_h =\r\n    0.5f * static_cast<float>(std::exp(box_centersize.h / scale_values.h)) *\r\n    anchor.h;\r\nfloat half_w =\r\n    0.5f * static_cast<float>(std::exp(box_centersize.w / scale_values.w)) *\r\n    anchor.w;\r\n\r\n#endif\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["Tagging @advaitjain "]}, {"number": 45367, "title": "could I build  both amd and nvidia support?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@GitSoftwareNow \r\nPlease refer to [system requirements](https://www.tensorflow.org/install/gpu) for the requested support.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45367\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45367\">No</a>\n"]}, {"number": 45366, "title": "Add int8 and int16 support for FILL operator", "body": "This PR adds int8 and int16 support for the FILL operator to support quantization.", "comments": ["I have updated the PR to resolve merge conflicts caused by 49752e0f82cd. Feel free to comment @thaink as I have changed additional files to integrate the INT8 support.", "@teijeong Does fill op need quantization support?", "@thaink The broader quantization support is better since that makes us to run inferences with avoiding the quantization/dequantization pairs. Please review this and they have models that have Fill ops."]}, {"number": 45365, "title": "Update AUTHORS", "body": "Added my self", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45365) for more info**.\n\n<!-- need_sender_cla -->", "This is your first contribution. It does not warrant addition to the file"]}, {"number": 45364, "title": " \u6709\u5173tensorflow estimator   About tensorflow estimator", "body": "I am using the estimator model to process some financial data. The API is tf.estimator.DNNLinearCombinedRegressor However, the document does not provide a detailed description of the use of this API. I would like to ask: 1. If I set 960 lines of batch data for input and use ten batches for prediction. Do different batches affect the prediction results? For example, will batch 1 affect the calculation of batch 2? If you still can't understand my question, let me give another example. Suppose that the correct results can be obtained by inputting batch 1 and batch 2. But now, due to data error, all data of batch 1 become 0, while batch 2 has not changed. In this case, can you still get correct results by inputting batch 1 and batch 2? 2. If I set 960 rows of data for a batch, does the data in the first row affect the data calculation in the second row? This problem is similar to the first one, except that different batches are changed into different lines. Please answer my question, thank you!", "comments": ["@anavanab99 \r\n\r\nPlease, fill [issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "\r\n## URL(s) with the issue:\r\nhttps://tensorflow.google.cn/versions/r1.15/api_docs/python/tf/estimator/DNNLinearCombinedRegressor\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n?\r\n\r\nI don't think it is necessary to provide relevant code for this problem. It is just a supplement to the API description. If you need to provide relevant code, you can refer to your own API documentation https://tensorflow.google.cn/versions/r1.15/api_docs/python/tf/estimator/DNNLinearCombinedRegressor\r\n\r\nIs the link to the source code correct?\r\n\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n\r\nAre return values defined?\r\n\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45364\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45364\">No</a>\n"]}, {"number": 45363, "title": "RuntimeError: The layer has never been called and thus has no defined output shape.", "body": "when i used this code :\r\ndef blinear_efficient__atten_model(img_rows, img_cols):\r\n    K.clear_session()\r\n\r\n    in_lay = Input(shape=(img_rows, img_cols, 3))\r\n    base_model = EfficientNetB3(weights=\"imagenet\", include_top=False,input_shape=(224, 224, 3))\r\n\r\n    pt_depth = base_model.get_output_shape_at(0)[-1]\r\n\r\n    cnn_features_a = base_model(in_lay)\r\n    cnn_bn_features_a = BatchNormalization()(cnn_features_a)\r\n\r\n    # attention mechanism\r\n    # here we do an attention mechanism to turn pixels in the GAP on an off\r\n    atten_layer = Conv2D(64, kernel_size=(1, 1), padding=\"same\", activation=\"relu\")(Dropout(0.5)(cnn_bn_features_a))\r\n    atten_layer = Conv2D(16, kernel_size=(1, 1), padding=\"same\", activation=\"relu\")(atten_layer)\r\n    atten_layer = Conv2D(8, kernel_size=(1, 1), padding=\"same\", activation=\"relu\")(atten_layer)\r\n    atten_layer = Conv2D(1, kernel_size=(1, 1), padding=\"valid\", activation=\"sigmoid\")(atten_layer)  # H,W,1\r\n    # fan it out to all of the channels\r\n    up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C\r\n    up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding=\"same\", activation=\"linear\", use_bias=False, weights=[up_c2_w])\r\n    up_c2.trainable = True\r\n    atten_layer = up_c2(atten_layer)  # H,W,C\r\n\r\n    cnn_atten_out_a = multiply([atten_layer, cnn_bn_features_a])  # H,W,C\r\n\r\n    cnn_atten_out_b = cnn_atten_out_a\r\n\r\n    cnn_out_dot = multiply([cnn_atten_out_a, cnn_atten_out_b])\r\n    gap_features = GlobalAveragePooling2D()(cnn_out_dot)\r\n    gap_dr = Dropout(0.25)(gap_features)\r\n    dr_steps = Dropout(0.25)(Dense(2048, activation=\"relu\")(gap_dr))\r\n    out_layer = Dense(n_classes, activation=\"softmax\")(dr_steps)\r\n\r\n    b_eff_atten_model = Model(inputs=base_model.input, outputs=out_layer, name=\"blinear_efficient_atten\")\r\n\r\n    return b_eff_atten_model\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"\u53cc\u7ebf\u6027eff.py\", line 407, in <module>\r\n    eB_model = blinear_efficient__atten_model(img_rows, img_cols)  # \u8f93\u5165\u56fe\u50cf\u7684\u9ad8\u5ea6\uff0c\u5bbd\u5ea6\r\n  File \"\u53cc\u7ebf\u6027eff.py\", line 184, in blinear_efficient__atten_model\r\n    pt_depth = base_model.get_output_shape_at(0)[-1]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 2030, in get_output_shape_at\r\n    'output shape')\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 2603, in _get_node_attribute_at_index\r\n    'and thus has no defined ' + attr_name + '.')\r\nRuntimeError: The layer has never been called and thus has no defined output shape.", "comments": ["@wpeng233,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45363\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45363\">No</a>\n"]}, {"number": 45362, "title": "ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 50176 but received input with shape [None, 57600]", "body": "System information\r\n\r\nI have written codes similar to that in the Tensorflow page for checking the label on my image based on the model that I trained\r\n- OS Platform and Distribution : Windows 10\r\n- TensorFlow installed from: pip, tf 2.3.0, gpu\r\n- Python version: - 3.6.8\r\n\r\nI had run a simple code to test the model with the images\r\n```\r\nmodel = tf.keras.models.load_model(\r\n            \"D:\\\\Python Projects\\\\Final Year Project\\\\assets\\\\resource\\\\micro.h5\")\r\npath_img = pathlib.Path(\"D:/Python Projects/Final Year Project/assets/resource/train_images/Acinetobacter.baumanii/edited/img0.png\")\r\nimage = keras.preprocessing.image.load_img(path_img, target_size=(244, 244)\r\nimage_array = keras.preprocessing.image.img_to_array(image)\r\nimage_array = tf.expand_dims(image_array, 0)\r\nprediction = model.predict(image_array )\r\n```\r\n\r\nError Info\r\n```\r\nWARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"sequential_1_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 244, 244, 3).\r\nWARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"random_flip_input:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 244, 244, 3).\r\nTraceback (most recent call last):\r\n  File \"d:\\Python Projects\\Final Year Project\\controller\\Image_Recognition.py\", line 136, in toProcess\r\n    prediction = self.imgReg.model.predict(img_array)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 130, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1599, in predict\r\n    tmp_batch_outputs = predict_function(iterator)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 697, in _initialize\r\n    *args, **kwds))\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 973, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\r\n        return step_function(self, iterator)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\r\n        outputs = model.predict_step(data)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\r\n        return self(x, training=False)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\r\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\r\n        inputs, training=training, mask=mask)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\r\n        outputs = node.layer(*args, **kwargs)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\r\n        self.name)\r\n    c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\r\n        ' but received input with shape ' + str(shape))\r\n\r\n    ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 50176 but received input with shape [None, 57600]\r\n```\r\nI had run the code on Google Colab with the same model and image and it works there, but it doesn't on my local computer", "comments": ["@SeanLink11,\r\nOn running the given code snippet, I am facing an error stating `NameError: name 'self' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ce20278a9df4ed20a33316284122e530/45362.ipynb#scrollTo=W8b0FpBrHMW6).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and all the files required to run the code. \r\n\r\nAlternatively, you can share the gist of the Colab Notebook you are running. Thanks!", "@amahendrakar,\r\nHi, I have edited the code snippet for when it uses self, but do you want me to share the model and images so that you can test it?", "@amahendrakar I've been testing and I discovered is that if I pass the images with the dimension 224*224, then it works, other sizes doesn't, so I resize them to be that", "@amahendrakar I tested, and found that it doesn't need to be 224*224, as long as the dimensions' product is the same, which is equal to 50176, it works, however, for images of .tif extension, it doesn't work, why is that?", "> but do you want me to share the model and images so that you can test it?\r\n\r\n@SeanLink11,\r\nYes please. Could you please share the latest code and the dataset so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45362\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45362\">No</a>\n"]}, {"number": 45360, "title": "No matching distribution found for Tensorflow for pip-20.3", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Arch Linux\r\n- TensorFlow version: N/A (pip-20.3 can't install any version of Tensorflow)\r\n- Python version: 3.9.0\r\n- CUDA/cuDNN version: N/A (running on CPU)\r\n- GPU model and memory: N/A (running on CPU)\r\n\r\n**Describe the problem**\r\nWhen trying to install Tensorflow from pip-20.3, pip says:\r\n\r\n> ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\n> ERROR: No matching distribution found for tensorflow\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n> pip install tensorflow\r\n> pip3 install tensorflow\r\n> pip3.9 install tensorflow\r\n(All of these commands yield the same error message)\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@BearNinja123,\r\nCurrently TensorFlow is comptible with upto Python v3.8. Please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#cpu) for more information.   \r\n\r\nVersion | Python version | Compiler | Build tools\r\n-- | -- | -- | --\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0\r\ntensorflow-2.2.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 2.0.0\r\ntensorflow-2.1.0 | 2.7, 3.5-3.7 | GCC 7.3.1 | Bazel 0.27.1\r\n\r\n\r\nThe request for TensorFlow support on Python 3.9 is already being tracked in [#44485](https://github.com/tensorflow/tensorflow/issues/44485), please follow that thread for more information. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45360\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45360\">No</a>\n"]}, {"number": 45359, "title": "Unable to load libcurdart.so.10.1, libcuda.so.1", "body": "**System information**\r\n- OS Platform and Distribution:  Amazon Linux 2 AMI on tc2 micro EC2 instance\r\n- TensorFlow installed from (source or binary):  binary\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: Unknown/does not exist\r\n- GPU model and memory: None\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen attempting to run Tensorflow on an EC2 instance, the following error occurs:\r\n`$ python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n2020-12-02 23:53:45.322002: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-12-02 23:53:45.322135: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-12-02 23:53:46.627216: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-12-02 23:53:46.627358: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-12-02 23:53:46.627417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-19-184.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\r\n2020-12-02 23:53:46.627871: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-12-02 23:53:46.634896: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2400085000 Hz\r\n2020-12-02 23:53:46.635090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a194e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-12-02 23:53:46.635120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(-963.18164, shape=(), dtype=float32)`\r\n\r\nAs you can see, the commands still _work_.  However, there is about a 3-5 second delay before it finally executes while it searches for the CUDA files.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSpin up a tc2 micro instance on EC2 using the Amazon Linux 2 AMI\r\nConnect to EC2 instance\r\n`sudo yum groupinstall \"Development Tools\"`\r\n`sudo yum install python37`\r\n`curl -O https://bootstrap.pypa.io/get-pip.py`\r\n`python3 get-pip.py --user`\r\nPip install numpy and pandas as usual\r\n`pip install --no-cache-dir tensorflow`\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nThe instance does not contain a GPU, being a simple tc2 micro CPU instance.\r\nAttempting to fix with `sudo yum install libcudart10.1` (as recommended in other issues) returns the following error: \r\n`No package libcudart10.1 available.\r\nError: Nothing to do`\r\nA GPU is unnecessary.  Acceptable solutions would prevent it from returning the errors by either:\r\n-Preventing it from trying to load libcudart and going straight to CPU execution\r\n-Installing the necessary files so it doesn't return errors before going to CPU execution\r\nIf all else fails, the installation still seems to work, albeit with major lag time as tensorflow searches for nonexistent files.  My primary concern is eliminating this lag time, NOT getting a GPU to work.", "comments": ["@intelligentgoldfish,\r\nTensorFlow 2.x packages support both CPU and GPU. You are facing the warnings as TensorFlow is look for the GPU drivers and can safely ignore those warnings.\r\n\r\nAlternatively if you don't need GPU support, you can install the [TensorFlow CPU](https://pypi.org/project/tensorflow-cpu/) only package using the below command \r\n```\r\npip3 install tensorflow-cpu\r\n```\r\n\r\nThanks!", "Sounds good.  Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45359\">No</a>\n"]}, {"number": 45358, "title": "[Intel MKL] Add MatMul+BiasAdd+Add fusion", "body": "This PR add a new fusion pattern `MatMul + BiasAdd + Add`, which reuse some code of `Conv2D + BiasAdd + Add` because of similar pattern.\r\n\r\nFor tests, it adds two, one for remapper and the other for fused results.\r\n\r\nSigned-off-by: Wang Yanzhang yanzhang.wang@intel.com", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45358) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45358) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent."]}, {"number": 45357, "title": "how to understand handling val data with keras in tf2.1", "body": "I apply model.fit to handle val data.\r\nmodel.fit(dataset,\r\n                    epochs=4,\r\n                    steps_per_epoch=32,  \r\n                    validation_data=val_dataset, \r\n                    validation_steps=8,\r\n                    callbacks=callbacks,\r\n                    verbose=1\r\n                    )\r\nSteps respectively set are above, but logs only contain the training steps:\r\n```\r\n...\r\n28/32 [=========================>....] - ETA: 4s - loss: 0.0045 - accuracy: 0.8959\r\n29/32 [==========================>...] - ETA: 3s - loss: 0.0045 - accuracy: 0.8935\r\n30/32 [===========================>..] - ETA: 2s - loss: 0.0045 - accuracy: 0.8940\r\n31/32 [============================>.] - ETA: 1s - loss: 0.0045 - accuracy: 0.8926\r\n2020-12-03 09:35:34.813262: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-12-03 09:35:34.818206: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n\r\nEpoch 00002: saving model to .\\log-output\\saved_models\\model_epoch02_val_acc0.89.ckpt\r\n\r\n32/32 [==============================] - 181s 6s/step - loss: 0.0045 - accuracy: 0.8930 - val_loss: 0.0043 - val_accuracy: 0.8913\r\n\r\nEpoch 3/4\r\n...\r\n```\r\nIt seems that only the first 31 steps are related to train data and the last step also includes the extra 8 validation steps. Is that right?\r\nBy th way, how to deal with the error \"Cancelled: Operation was cancelled\"?\r\n\r\ntf 2.1\r\ncuda 10.1\r\npython 3.7\r\nwin10\r\nGPU 2080Ti", "comments": ["@jianku122 \r\n\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45356, "title": "Allow custom ops to avoid ConverterError", "body": "Enabling TensorFlow operations that are not by default supported by TensorFlow lite requires (at least in some cases) to explicitly allow custom ops. As far as I understand, the respective guide would be more useful with `converter.allow_custom_ops = True`, to avoid problems as encountered in issue #45321.", "comments": ["Sorry. Instead of this, the team is preparing a better error message regarding custom ops."]}, {"number": 45355, "title": "Have `make test` pass for Xtensa hifimini.", "body": "With this change, the following command succeeds:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=hifimini XTENSA_CORE=mini1m1m_RG test\r\n```\r\n\r\nRelated bugs:\r\n  * http://b/158651472\r\n  * http://b/170326552#comment3\r\n  * http://b/174707181", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45354, "title": "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNO\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nNAME=\"Ubuntu\"\r\nVERSION=\"18.10 (Cosmic Cuttlefish)\"\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\ntf installed via conda\r\n\r\n- TensorFlow version (use command below):\r\n 2.3.0\r\n- Python version:\r\nPython 3.7.6\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nn/a\r\n- CUDA/cuDNN version:\r\nn/a\r\n- GPU model and memory:\r\nn/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n> Epoch 1/100\r\n> WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0089s vs `on_train_batch_end` time: 0.0245s). Check your callbacks.\r\n> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: 'arguments' object has no attribute 'posonlyargs'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: 'arguments' object has no attribute 'posonlyargs'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> INFO:tensorflow:Assets written to: saved_models/ruh_best_stackedAE.hd5/assets\r\n> Epoch 2/100\r\n> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c2208e60> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: 'arguments' object has no attribute 'posonlyargs'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c2208e60> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: 'arguments' object has no attribute 'posonlyargs'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> INFO:tensorflow:Assets written to: saved_models/ruh_best_stackedAE.hd5/assets\r\n> Epoch 3/100\r\n> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c0ad8b90> and will run it as-is.\r\n> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\n> Cause: 'arguments' object has no attribute 'posonlyargs'\r\n> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c0ad8b90> and will run it as-is.\r\n> Please report this to the TensorFlow team. When \r\n\r\n**Describe the expected behavior**\r\nNo warning\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\n## to tensorflow github page bug report\r\n\r\nimport random\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\ndf_trial_train = pd.read_csv('df_trial_train_sample.txt' , sep = '\\t', index_col=0) \r\n\r\nxyz_coor_trial_train = pd.read_csv('xyz_coor_trial_train_sample.txt',sep = '\\t', index_col=0) \r\n\r\n\r\nn_train = len(df_trial_train)\r\nn_valid = int(n_train*.2)\r\n\r\n\r\nindex_valid = random.sample(range(n_train)  , n_valid)\r\nmask = np.zeros(n_train, dtype = bool)\r\n\r\nmask[index_valid] = True\r\n\r\n###############################################\r\n\r\n### Stacked AE\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n## corr coeff:\r\nfrom tensorflow.keras import backend as K\r\nimport tensorflow as tf\r\nimport tensorflow.keras as kr\r\nimport scipy as sp\r\ndef func_correlation_coefficient(y_true, y_pred):\r\n    x = y_true\r\n    y = y_pred\r\n    mx = K.mean(x)\r\n    my = K.mean(y)\r\n    xm, ym = x-mx, y-my\r\n    r_num = K.sum(tf.multiply(xm,ym))\r\n    r_den = K.sqrt( tf.multiply(  K.sum(K.square(xm)), K.sum(K.square(ym))  ) )\r\n    r = r_num / r_den\r\n#     r = sp.stats.pearsonr(x.numpy(),y.numpy())\r\n    r = K.maximum(K.minimum(r, 1.0), -1.0)\r\n    return r\r\n\r\n### end corr coeff\r\n\r\n\r\n\r\n## create root log dir for TensorBoard\r\nimport os\r\nroot_logdir = os.path.join(os.curdir, 'ruh_rootdir_logs')\r\n\r\ndef get_run_logdir(subdir_name):\r\n    import time\r\n    run_id = time.strftime(subdir_name+'_%Y_%m_%d_%H_%M_%S')\r\n    return os.path.join(root_logdir, run_id)\r\n\r\nruh_run_logdir = get_run_logdir(subdir_name = 'stacked_ae')\r\n\r\n\r\nmy_batch_size = 128\r\nmy_lr = .001\r\nmy_ngenes_train = df_trial_train.shape[1]\r\nmy_ncube_train = df_trial_train[~mask].shape[0]\r\nnunit_output = xyz_coor_trial_train.shape[1]\r\n\r\nmy_nepochs = 100\r\n\r\nn_neurons = my_ngenes_train # #not iterable\r\nn_neurons_latent = 32\r\nn_neurons1 = n_neurons_latent * 4 #int(n_neurons/2)\r\nn_neurons2 = n_neurons_latent * 2 #int(n_neurons/16)\r\n\r\n\r\n\r\n## input layer\r\nmy_Input_layer = kr.layers.Input(shape=(n_neurons,)) #shape=df_trial_train.shape[1:])\r\n\r\n## encoder:\r\nencoder_layer = kr.layers.Dense(n_neurons1, activation = 'relu')(my_Input_layer)\r\nencoder_layer = kr.layers.Dense(n_neurons2, activation = 'relu')(encoder_layer)\r\n\r\n## latent space\r\nlatent_layer = kr.layers.Dense(n_neurons_latent, activation = 'relu')(encoder_layer)\r\n\r\n## decoder:\r\n#decoder_input = kr.layers.Input(shape=(n_neurons_latent,))\r\ndecoder_layer = kr.layers.Dense(n_neurons2 , activation = 'relu')(latent_layer)\r\ndecoder_layer = kr.layers.Dense(n_neurons1 , activation = 'relu')(decoder_layer)\r\ndecoder_layer = kr.layers.Dense(n_neurons  , activation = 'relu')(decoder_layer)\r\n\r\n# my_outputs = kr.layers.Dense(n_neurons)(decoder_layer)\r\n\r\n## stacked ae\r\nstacked_ae = kr.models.Model(my_Input_layer, decoder_layer) #kr.models.Model(encoder_layer, my_outputs)\r\nstacked_ae.summary()\r\n\r\n## optimization + loss + metrics\r\nmyoptimizer = kr.optimizers.SGD(lr = my_lr, momentum=.9, nesterov=True) #, momentum=.01)\r\nmyoptimizer = kr.optimizers.Adam(lr = my_lr, beta_1=.9, beta_2=.999)\r\n\r\nstacked_ae.compile(loss = 'mse', optimizer = myoptimizer,metrics=[func_correlation_coefficient])\r\n\r\n\r\nprint('#samples/epoch = ', df_trial_train[~mask].shape[0]/my_batch_size, '\\n')\r\n\r\nearlystopping_stackedAE = kr.callbacks.EarlyStopping(patience=10, restore_best_weights=True)                   \r\ntensorboard_stackedAE = kr.callbacks.TensorBoard(ruh_run_logdir)\r\ncheckpoint_stackedAE = kr.callbacks.ModelCheckpoint('saved_models/ruh_best_stackedAE.hd5', save_best_only=True)\r\nhistory = stacked_ae.fit( x = df_trial_train[~mask]\r\n                         ,y = df_trial_train[~mask] #df_trial_train[~mask]#xyz_coor_trial_train[~mask]             \r\n                         ,epochs=100              \r\n                         ,validation_data=(df_trial_train[mask], df_trial_train[mask])#[df_trial_train[mask], df_trial_train[mask]]#(df_trial_train[mask], xyz_coor_trial_train[mask])              \r\n                         ,callbacks=[ earlystopping_stackedAE\r\n                                     ,tensorboard_stackedAE\r\n                                     ,checkpoint_stackedAE\r\n                                    ] \r\n                         ,batch_size = my_batch_size\r\n                         , verbose = 10\r\n                        )\r\n\r\n\r\n```\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@ruhollah2,\r\nOn running the code, I am facing an error stating `NameError: name 'df_trial_train' is not defined`. Could you please share all the necessary files required to run the code.\r\n\r\nAlso instead of `keras`, could you please use `tensorflow.keras` and check if you are facing the same issue. Thanks!", "@amahendrakar \r\nHere are the files\r\nhttps://drive.google.com/drive/folders/11X6y5k8k10VvyO0lV4Olarv8hmBIdYVw?usp=sharing\r\n\r\nI also updated the original posted code, so it is now self-contained. You only need to create a local dit `saved_models` or disable that checkpoint option ", "@ruhollah2,\r\nThank you for the update. I did not face any warnings while running the code, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5322fc5a0407e336a54644f35be8a3cf/45354.ipynb#scrollTo=K3KkFt5NCrEf).\r\n\r\nYou can suppress the warnings by changing the log level at the start of the program  \r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\nimport tensorflow as tf\r\n```\r\n\r\nor you can set the [autograph verbosity](https://www.tensorflow.org/api_docs/python/tf/autograph/set_verbosity\r\n) level using the below the below code \r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nos.environ['AUTOGRAPH_VERBOSITY'] = 1\r\n```\r\n\r\nThanks!", "@tensorflowbutler Thank you for your follow up. \r\n\r\nAs per your instruction, I added the following before training the model:\r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\n```\r\nHowever, now im facing with a larger set of errors and warnings. Strangely, though, the training proceeds and does not stop. \r\n\r\nHere is a partial log of the output w/ err/warning:\r\n\r\n\r\n```\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x7f50dc3e8b90>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.__init__.<locals>.permutation at 0x7f50dc3e8b90>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x7f50dc3e8170>\r\n    args: (<tf.Tensor 'args_0:0' shape=(54429,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x7f50dc3e8170>\r\n    args: (<tf.Tensor 'args_0:0' shape=(54429,) dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Converted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x7f50dc897a70>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, ({'ruhinput': <tf.Tensor 'args_1:0' shape=(54429, 3814) dtype=float64>}, {'mydec': <tf.Tensor 'args_2:0' shape=(54429, 3814) dtype=float64>, 'myreg': <tf.Tensor 'args_3:0' shape=(54429, 9) dtype=float64>}))\r\n    kwargs: {}\r\n\r\nConverted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x7f50dc897a70>\r\n    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, ({'ruhinput': <tf.Tensor 'args_1:0' shape=(54429, 3814) dtype=float64>}, {'mydec': <tf.Tensor 'args_2:0' shape=(54429, 3814) dtype=float64>, 'myreg': <tf.Tensor 'args_3:0' shape=(54429, 9) dtype=float64>}))\r\n    kwargs: {}\r\n\r\nEpoch 1/100\r\n  1/426 [..............................] - ETA: 0s - loss: 0.0571 - mydec_loss: 0.5701 - myreg_loss: 0.0945 - mydec_func_correlation_coefficient: 0.7762 - myreg_func_correlation_coefficient: 0.7411WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0293s). Check your callbacks.\r\n423/426 [============================>.] - ETA: 0s - loss: 0.0575 - mydec_loss: 0.5745 - myreg_loss: 0.1003 - mydec_func_correlation_coefficient: 0.7726 - myreg_func_correlation_coefficient: 0.7375INFO:tensorflow:Converted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nConverted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nINFO:tensorflow:<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40> is not cached for subkey ConversionOptions[{}]\r\n<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Error transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40>\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nError transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40>\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dc20ad40> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nINFO:tensorflow:Assets written to: saved_models/ruh_best_RegStackedAE.hd5/assets\r\n426/426 [==============================] - 5s 13ms/step - loss: 0.0575 - mydec_loss: 0.5745 - myreg_loss: 0.1003 - mydec_func_correlation_coefficient: 0.7726 - myreg_func_correlation_coefficient: 0.7375 - val_loss: 0.0576 - val_mydec_loss: 0.5751 - val_myreg_loss: 0.1024 - val_mydec_func_correlation_coefficient: 0.7721 - val_myreg_func_correlation_coefficient: 0.7358\r\nEpoch 2/100\r\n422/426 [============================>.] - ETA: 0s - loss: 0.0574 - mydec_loss: 0.5729 - myreg_loss: 0.0987 - mydec_func_correlation_coefficient: 0.7744 - myreg_func_correlation_coefficient: 0.7368INFO:tensorflow:Converted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nConverted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nINFO:tensorflow:<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200> is not cached for subkey ConversionOptions[{}]\r\n<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Error transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200>\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nError transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200>\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd9a200> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nINFO:tensorflow:Assets written to: saved_models/ruh_best_RegStackedAE.hd5/assets\r\n426/426 [==============================] - 5s 12ms/step - loss: 0.0574 - mydec_loss: 0.5729 - myreg_loss: 0.0987 - mydec_func_correlation_coefficient: 0.7744 - myreg_func_correlation_coefficient: 0.7368 - val_loss: 0.0574 - val_mydec_loss: 0.5735 - val_myreg_loss: 0.0971 - val_mydec_func_correlation_coefficient: 0.7746 - val_myreg_func_correlation_coefficient: 0.7232\r\nEpoch 3/100\r\n426/426 [==============================] - ETA: 0s - loss: 0.0573 - mydec_loss: 0.5718 - myreg_loss: 0.0981 - mydec_func_correlation_coefficient: 0.7756 - myreg_func_correlation_coefficient: 0.7357INFO:tensorflow:Converted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nConverted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nINFO:tensorflow:<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0> is not cached for subkey ConversionOptions[{}]\r\n<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Error transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0>\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nError transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0>\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dcd82cb0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nINFO:tensorflow:Assets written to: saved_models/ruh_best_RegStackedAE.hd5/assets\r\n426/426 [==============================] - 6s 13ms/step - loss: 0.0573 - mydec_loss: 0.5718 - myreg_loss: 0.0981 - mydec_func_correlation_coefficient: 0.7756 - myreg_func_correlation_coefficient: 0.7357 - val_loss: 0.0574 - val_mydec_loss: 0.5727 - val_myreg_loss: 0.0967 - val_mydec_func_correlation_coefficient: 0.7747 - val_myreg_func_correlation_coefficient: 0.7309\r\nEpoch 4/100\r\n426/426 [==============================] - ETA: 0s - loss: 0.0572 - mydec_loss: 0.5709 - myreg_loss: 0.0933 - mydec_func_correlation_coefficient: 0.7766 - myreg_func_correlation_coefficient: 0.7410INFO:tensorflow:Converted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nConverted call: <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950>\r\n    args: ()\r\n    kwargs: {'ruhinput': <tf.Tensor 'ruhinput:0' shape=(None, 3814) dtype=float32>}\r\n\r\nINFO:tensorflow:<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950> is not cached for subkey ConversionOptions[{}]\r\n<function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950> is not cached for subkey ConversionOptions[{}]\r\nINFO:tensorflow:Error transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950>\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 70, in transform_ast\r\n    node = activity.resolve(node, ctx, None)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 705, in resolve\r\n    return ActivityAnalyzer(context, parent_scope).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 445, in visit\r\n    result = super(Base, self).visit(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/ast.py\", line 271, in visit\r\n    return visitor(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 575, in visit_FunctionDef\r\n    node = self._visit_arg_annotations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 551, in _visit_arg_annotations\r\n    node = self._visit_arg_declarations(node)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py\", line 556, in _visit_arg_declarations\r\n    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)\r\nAttributeError: 'arguments' object has no attribute 'posonlyargs'\r\nError transforming entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950>\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f50dba86950> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nTraceback (most recent call last):\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 584, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 119, in convert\r\n    entity, program_ctx.options, program_ctx, custom_vars)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 412, in transform_function\r\n    extra_locals)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 373, in _transformed_factory\r\n    nodes, ctx = self._transform_function(fn, user_context)\r\n  File \"/avicenna/ruhollah/rohit_avicenna/myneusomatic/neusom_ruhv3/miniconda3_new_sahra/envs/ruhv3_neusom/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 339, in _transform_function\r\n    node = self.transform_ast(node, context)\r\n```\r\n\r\nAny idea?!\r\n", "@ruhollah2,\r\nCould you please try running the code in a new virtual environment and check if you are facing the same issue?\r\n\r\n> or you can set the [autograph verbosity](https://www.tensorflow.org/api_docs/python/tf/autograph/set_verbosity) level using the below the below code\r\n> \r\n> ```\r\n> import os\r\n> import tensorflow as tf\r\n> os.environ['AUTOGRAPH_VERBOSITY'] = 1\r\n> ```\r\n\r\nAlso, try changing the `AUTOGRAPH_VERBOSITY` level and check if it helps. Thanks!", "@amahendrakar \r\n\r\nNot sure what you mean by \"**virtual environment**\". Do you mean a new conda environment? (ie, should I create a new conda env with all required packages and then re-run this code in the new env?)", "@ruhollah2,\r\nYes please, create a new conda environment as per [this guide](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands) and run the code in it. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45354\">No</a>\n"]}, {"number": 45353, "title": "[Cherypick:r2.4] pin to old version(3.9.2)has broken docs Fixes #45300", "body": "PiperOrigin-RevId: 345296540\nChange-Id: I462cde68741c6cd69607de47a502a974bd9b5fb0", "comments": []}, {"number": 45352, "title": "[DO NOT SUBMIT]: Created a PR to test Serving.", "body": "Testing the serving build by creating a PR for an internal change.", "comments": []}, {"number": 45351, "title": "2.3.1 runs in jupyter but python script", "body": "\r\nmy code runs in jupyter but when I use python script. It gives me gpu oom error.\r\n", "comments": ["sorry  \r\ni didn't write:\r\nbase_model.trainable = False", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45351\">No</a>\n"]}, {"number": 45350, "title": "Contributing to TFlite Micro", "body": "Hi,\r\nI want to contribute to TFlite Micro. Please help me with getting started.\r\nI have some hardware which might be useful for me to contribute, it includes: STM32 Nucleo-L476RG, Arduino Uno, Nano, Micro, Esp8266, and Esp32\r\nI know Python and C programming.\r\n\r\n\r\nP.S. - I am a hobbyist and want to contribute.\r\nThanks.", "comments": ["Thanks for expressing your interest in contributing to TensorFlow.\r\nWe appreciate community reaching out and contributing to enhance TensorFlow's usage.\r\nPlease go through [contributor guidelines](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md) to start with.\r\nFeel free to contribute in any way you can; improving the guides, documentation, tutorials, fixing bugs that you may encounter or encountered by other users.\r\nWe accept code/document changes in the form of Pull Request (PR).\r\nSo make sure to provide as much information as you can with your PR to help us better assess the case and review it.\r\nI also encourage you to sign up for the [TensorFlow monthly newsletter](https://services.google.com/fb/forms/tensorflow/) for new updates.\r\n\r\n\r\n", "@ymodak Thanks for the quick reply, I have signed up for the newsletter and also read the guidelines. Can you point me to a **good first issue**\r\nBest,", "You can filter the GitHub issues on this repo with `good first issue` lablel. But I am afraid that we don't have any for `micro` at the moment. Never the less you can try taking a glance on `feature requests` or `bug` labelled micro issues.\r\nThank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45350\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45350\">No</a>\n"]}, {"number": 45349, "title": "Exclude targets that are known to not build with bazel.", "body": "Manually tested the following commands:\r\n```\r\nbazel clean\r\ntime bazel test tensorflow/lite/micro/...\r\n```\r\nResulted in:\r\n```\r\nExecuted 76 out of 76 tests: 76 tests pass.\r\nThere were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line oINFO: Build completed successfully, 1631 total actions\r\n\r\nreal\t1m15.333s\r\n```\r\n\r\nProgress towards http://b/174680668\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45348, "title": "\"bluepill\" target fails run in Renode emulator robot", "body": "@tensorflow/micro\r\n@petewarden\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  - Linux Ubuntu 18.04.5\r\n- TensorFlow installed from (source or binary):\r\n  - source\r\n- Tensorflow version (commit SHA if source):\r\n  - commit 7537865 (HEAD -> master, origin/master, origin/HEAD)\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n  - bluepill (ARM emulator)\r\n\r\n**Describe the problem**\r\n\r\nBuilding a test for use with the emulator (TARGET=bluepill) fails within the Renode emulator robot execution.  A failure message about a missing directory is given.  However, the directory path provided by the failure, is actually the binary the emulator was supposed to execute.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test_kernel_mul_test\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/Makefile:476: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/Makefile:476: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/testing/test_bluepill_binary.sh tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test '~~~ALL TESTS PASSED~~~'\r\n/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../tools/make/downloads/renode/test.sh /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.robot   -r /tmp/renode_bluepill_logs   --variable RESC:/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.resc   --variable RENODE_LOG:/tmp/renode_bluepill_logs/renode_log.txt   --variable DIR_WITH_TESTS:tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test\r\nPreparing suites\r\nStarted Renode instance on port 9999; pid 7612\r\nStarting suites\r\nRunning /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.robot\r\n+++++ Starting test 'bluepill.Run All Bluepill Tests'\r\n+++++ Finished test 'bluepill.Run All Bluepill Tests' in 0.00 seconds with status failed\r\n      \u2554\u2550\r\n      \u2551 Parent suite setup failed:\r\n      \u2551 Directory '/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test' does not exist.\r\n      \u255a\u2550\r\nCleaning up suites\r\nClosing Renode pid 7612\r\nAggregating all robot results\r\nOutput:  /tmp/renode_bluepill_logs/robot_output.xml\r\nLog:     /tmp/renode_bluepill_logs/log.html\r\nReport:  /tmp/renode_bluepill_logs/report.html\r\nSome tests failed :( See logs for details!\r\nUART LOGS:\r\ncat: /tmp/renode_bluepill_logs/renode_log.txt: No such file or directory\r\ntensorflow/lite/micro/tools/make/Makefile:532: recipe for target 'test_kernel_mul_test' failed\r\nmake: *** [test_kernel_mul_test] Error 1\r\n```\r\n\r\n```\r\nls -l /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test \r\n-rwxr-xr-x 1 ddavis ddavis 103580 Dec  2 10:14 /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test\r\n```\r\n\r\n```\r\nfile /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test\r\n/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, not stripped\r\n```\r\n\r\n", "comments": ["@petewarden @advaitjain Tested and found working as of https://github.com/ddavis-2015/tensorflow/commit/78d28301bcde34028a201a6288e6d409d66e254a master.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45348\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45348\">No</a>\n"]}, {"number": 45347, "title": "Feed batch of images in Java", "body": "Seems like documentation is missing for providing multiple inputs for tensorflow model (.pb) in Java. Could you help how to provide multiple jpg byte[] images to model? Version of Tensorflow java is 2.3. Type of model input is type float32[?,100,100,1]\r\n\r\n```\r\n      private static final int SIZE = 100;\r\n      private static final float MEAN = 256f;\r\n\r\n        Graph graph = new Graph();\r\n        GraphBuilder b = new GraphBuilder(graph);\r\n        final Output<String> input = b.placeholder(\"input\", DataType.STRING);      \r\n  Output<Float> graphOutput =\r\n                b.div(\r\n                        b.resizeBilinear( // Resize using bilinear interpolation\r\n                                b.expandDims(\r\n                                        b.cast(b.decodeJpeg(input, 1), Float.class),\r\n                                        b.constant(\"make_batch\", 0)),\r\n                                b.constant(\"size\", new int[]{SIZE, SIZE})),\r\n                        b.constant(\"scale\", MEAN));\r\n        byte[] image = ....;\r\n        Tensor inputTensor = Tensor.create(image);\r\n        List<Tensor<?>> tensorList = session.runner()\r\n                .feed(inputOp, inputTensor)\r\n                .fetch(graphOutput.op().name()).run();\r\n       // get image tensor\r\n        Tensor<Float> imageTensor = tensorList.get(0).expect(Float.class);\r\n        for (int i = 1; i < tensorList.size(); i++) {\r\n            tensorList.get(i).close();\r\n        }\r\n        inputTensor.close();\r\n```\r\n\r\n", "comments": ["@iglaweb Are you using [tensorflow/java](https://github.com/tensorflow/java/issues) here ? Can you please provide where exactly the documentation is missing ?", "@rthadur Yeah, I use tensorflow/java v.2.3.0 that was recently deprecated. I cannot figure out how to provide multiple inputs for the model.", "@iglaweb please post this issue on [tensorflow/java ](https://github.com/tensorflow/java/issues) where it would be relevant.", "Had the question solevd? can tensorflow support multiple inputs?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45347\">No</a>\n"]}, {"number": 45345, "title": "[Cherrypick:r2.4] Change protobuf version back to 3.9.2", "body": "Fixes #45300\n\nPiperOrigin-RevId: 345132065\nChange-Id: I271b1ffcbe7e34b905974d62415ee1efba4f5bb6", "comments": []}, {"number": 45344, "title": "Allow for gpu platforms other than CUDA in jax", "body": "This is a prerequisite in order to start building jax with suport for AMD gpus (ROCm).\r\n\r\n(The accompanying changes for jax can be found here: https://github.com/inailuig/jax/tree/rocm; I will open a PR there once this gets accepted)\r\n\r\nAlso see https://github.com/google/jax/issues/2012\r\n\r\n@hawkinsp ", "comments": ["This discussion is probably also relevant: https://github.com/tensorflow/tensorflow/pull/30381#discussion_r301614305", "I'm trying to force this through our CI system. If you wouldn't mind, I think it might go through if you would push another change to this PR (e.g., anything; improve a comment or something like that)."]}, {"number": 45343, "title": "[XLA] Fix regression for small element-wise kernels.", "body": "#42683 speed up element-wise kernels with big grid size. But it regressed those with small grid size as it increased the grid size when it wasn't needed.\r\nWe found one `%add.111 = f32[2] add(f32[2]p0, f32[2]p1)` kernel be >100x slower (1.888us vs 269us) in TF1.\r\n\r\n\r\nNow we do not change small grid sizes.\r\n\r\n@timshen91 @nluehr ", "comments": ["Can you add test cases that's like xla/service/gpu/tests/fusion.hlo, but specifically CHECKs for grid size (it's in the LLVM metadata)? Ideally one test for using the original size, another for using the few_waves size.", "> Can you add test cases that's like xla/service/gpu/tests/fusion.hlo, but specifically CHECKs for grid size (it's in the LLVM metadata)? Ideally one test for using the original size, another for using the few_waves size.\r\n\r\nThis new way of executing tests looks great. But is it documented somewhere?\r\nI can run it manully with //tensorflow/compiler/xla/service/gpu/tests:hlo_to_llvm_ir and FileCheck.\r\n\r\nBut how those tests are triggered by `bazel tests`?\r\nOr we need to always trigger them manually?\r\n\r\nIf did the changes requested.", "In general, `bazel query //my/dir/...` gives you all targets under the directory. This is useful for discovering tests.\r\n\r\nIn this specific case, test taregts are `//tensorflow/compiler/xla/service/gpu/tests:xxx.hlo.test`.\r\n\r\nUnfortunately I'm unaware of any documentation.", "Thanks. I do not understand how bazel find them. But they are found.\r\nThe PR is ready for review.", "Can you also add another test for large grid size that's capped by few_waves?", "I amended the last commit to add the second test and add comments to the first test.\r\n\r\n", "Thanks for the patch!", "Can you sync the repo and re-run those .hlo.test tests? I'm seeing two failures `launch_dimensions_big.hlo.test` and `elementwise.hlo.test`. It's likely related to me fixing `gpu_device_info.threads_per_core_limit` in `hlo_to_llvm_ir.cc` in the mean time.", "I rebased and updated the test and force pushed the changes.", "@nouiz  Can you please resolve conflicts? Thanks!", "The patch is checked in manually by me."]}, {"number": 45342, "title": "[TFLite] Add TABLE operator for LUT-based operators lowering", "body": "Hi,\r\n\r\nThis PR adds a TFLite TABLE operator which is similar to the TABLE operator of the [TOSA specification](https://developer.mlplatform.org/w/tosa/). The operator takes int8 or int16 inputs and look them up into the table associated to the operator to produce the outputs.\r\n\r\nThis operator can be used to lower non-linear quantized functions like the exponential to a LUT in the range of the quantized range. The following [proof-of-concept](https://github.com/Tessil/tensorflow/commit/84eedece6d8d409a040362a375d669a3a0997abb) commit quantizes the EXP operator by generating a LUT in the input range of the operator and replace the it by a TABLE operator in the exported TFLite model.\r\n\r\nThis PR only add the operator and don't provide any transformation yet, these will be part of a different PR. The `gen_lut` function also has been extended to support int8->int8, int8->int16 and int16->int8 tables in addition of the previously supported int16->int16 table.\r\n\r\nThibaut", "comments": ["Thanks for your contribution.\r\n\r\nThe new table operator will not be used for a part of the TF to TFL op lowering so it is hard to be used for the actual use cases. Are there any future plans for that? If now, how about just having this table operator as a custom op?", "@Tessil  Can you please check @abattery's comments and keep us posted ? Thanks!", "Since this operator is somewhat in an experimental stage, how about adding this operator as a custom op as a first step until this custom op will resolve the unsupported cases or unlock the new opportunities with concrete examples? Because the builtin op addition will demand most of the android developers for the extra binary size requirement", "Sorry for my late answer. I think it would be easier for now to leave the PR on the side as there are still some discussions in progress regarding the advantages of a separate TABLE operator compared to generating the LUT inside the `Prepare` method of each operator. Once we have a clearer understanding on how to move on with all this, we could eventually add the operator as custom op as first step.", "@Tessil  Any update on this PR? Please. Thanks!", "Hi @gbaned ,\r\n\r\nThe PR is put in suspend for now as some discussions are still required internally and with some of the TFLite team members to check if we move forward with a separate TABLE operator or not. Sorry for that.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "There is no enough discussion on this new approach's addition. How about closing this PR until we have enough concensus on this?", "Thanks Tessil, please take a look at the comments.\r\n\r\nThanks abattery, this is on on-going discussion so let's not close yet :)", "Thanks Tessil. Sorry I missed your reply (didn't realized that github folds your reply right after each comment and I was only checking there were no new discussions below https://github.com/tensorflow/tensorflow/pull/45342#issuecomment-845282707)\r\n\r\nThanks for fixing all the issues and explaining the bigger picture.", "Thank you very much for the review @jianlijianli. I fixed the merge conflicts that were remaining, the PR will need re-approval.", "Adding @karimnosseir @miaout17 into the thread for visibility of the external schema changes.", "Thanks @abattery for flagging potential challenges and suggesting custom op approach.\r\n\r\nTessil, following your comment in https://github.com/tensorflow/tensorflow/pull/45342#issuecomment-749597630, and since we already looked into the technical details, is it a good time to move this to a custom op? Once the PR is in and well tested, the promotion should be simple.\r\n\r\n@karimnosseir @miaout17 , please take a look as well.", "I have to look a bit on how to adapt the [proof-of-concept](https://github.com/Tessil/tensorflow/commit/84eedece6d8d409a040362a375d669a3a0997abb) as if we move the TABLE operator to a custom op we can't have a `TFL_TableOp` in `tfl_ops.td` and thus a `mlir::TFL::TableOp`.\r\n\r\nI'll try to adapt the proof-of-concept to use `mlir::TFL::CustomOp` and see how it works.", "@jianlijianli I updated the PR and moved the TABLE operator from a built-in op to a custom op.\r\n\r\nI also updated the [proof-of-concept](https://github.com/Tessil/tensorflow/commit/b0363b833e510d8fa4596f0007acbad888496ea1) to illustrate the lowering using a `mlir::TFL::CustomOp` instead of a `mlir::TFL::TableOp`.", "@Tessil  Can you please resolve conflicts? Thanks!", "@gbaned Thanks I fixed the conflicts..\r\n\r\nNote that with the removal of TensorFlow Lite Micro from this repository, the change I did in [tensorflow/lite/micro/kernels/softmax.cc](https://github.com/tensorflow/tensorflow/pull/45342/commits/3cde0d4288b355443483efd5cb19eaaf23b6c510#diff-91be54c4ee3217090907f1dbfe935d90945b5a253615ae542e3700305e115ff8) will need to be done in https://github.com/tensorflow/tflite-micro when syncing the TF repository after the change has been merged. Not sure what is the best way to proceed with this.", "@jianlijianli  Can you please assist on above comments from @Tessil. Thanks!", "Thanks Tessil for making the change.\r\n\r\n> the change I did in tensorflow/lite/micro/kernels/softmax.cc will ....\r\n\r\nIf I understand correctly, the change in softmax is only refactoring (so the common functions can support the new TABLE operator). Are there any tangible change in the implementation?", "Yes, the change is only a refactoring to adapt to the new more flexible `gen_lut` function signature. There is no tangible change in the implementation itself, the results will be exactly the same for the given parameters.", "@jianlijianli I fixed an implicit cast warning which caused an error in one of the CI. The PR will need re-approval, thanks!", "Is it possible to remove the new custom op from the default op registration? Instead, we can keep it as a part of `custom_ops` target under the tensorflow/lite/BUILD file.\r\n\r\nMost of common TFLite users do not requires a new table custom op for now and we would like to keep the TFLite library as compact as possible.", "I can remove it from the default registration and add it to the [custom_ops](https://github.com/tensorflow/tensorflow/blob/81908ee16f7e0efa611c408553271e48f68c9041/tensorflow/lite/kernels/BUILD#L779) library but out of curiosity are there specific builds generated with these custom ops? And how should we compile such builds (as the `custom_ops` library target doesn't seem to be referenced anywhere as dependency outside of the tests)?", "In bazel, it is possible to create a custom TFLite build target, depending on the custom_ops build target. This is the way to use the user generated custom ops."]}]