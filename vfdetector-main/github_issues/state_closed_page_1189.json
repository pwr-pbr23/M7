[{"number": 17517, "title": "add error message when importing contrib.tensorrt without libnvinfer", "body": "", "comments": ["@aaroey ", "Hi @jjsjann123, would you please help to rerun the test you've done mentioned in the email thread, with this change? Thanks.", "Sure. I'm waiting containers to build", "@aaroey Finished the same test (CUDA9+cudnn7 & CUDA8+cudnn7). Saw updated error message.\r\nThe changes didn't break anything.\r\n\r\n```\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-2-87ee6364e20f> in <module>()\r\n----> 1 import tensorflow.contrib.tensorrt as trt\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorrt/__init__.py in <module>()\r\n     20\r\n     21 # pylint: disable=unused-import,wildcard-import\r\n---> 22 from tensorflow.contrib.tensorrt.python import *\r\n     23 # pylint: enable=unused-import,wildcard-import\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorrt/python/__init__.py in <module>()\r\n     31       ' https://developer.nvidia.com/tensorrt to download and install'\r\n     32       ' TensorRT ****')\r\n---> 33   raise RuntimeError(no_trt_message)\r\n     34 # pylint: enable=unused-import,line-too-long\r\n\r\nRuntimeError: **** Failed to initialize TensorRT. This is either because the TensorRT installation path is not in LD_LIBRARY_PATH, or because you do not have it installed. If not installed, please go to https://developer.nvidia.com/tensorrt to download and install TensorRT ****\r\n```\r\n\r\n", "@gunan WDYT?", "pinging @aaroey about the progress"]}, {"number": 17516, "title": "Not thread safe about saved_model.loader.load_latency_microsecs", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.6\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.0.0 (clang-800.0.42.1)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.4.0)\r\ntensorflow (1.3.0)\r\ntensorflow-serving-api (1.3.0)\r\ntensorflow-tensorboard (0.1.8)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI'm having a log in tensorflow/serving\r\n```\r\n2018-03-07 19:11:57.388343: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 22100393 microseconds.\r\n```\r\nthe number is so big, so it should be wrong..\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n", "comments": []}, {"number": 17515, "title": "Branch 188191091", "body": "o Small BUILD file change needed to be fixed", "comments": []}, {"number": 17514, "title": "ImportError: No module named 'tensorflow.contrib.ios_examples.benchmark.benchmark.xcodeproj'", "body": "I am trying to create exe file for python application built on tkinter(8.6), python(3.6), keras(0.14), tensorflow(1.5),  cx_Freeze(5.1). All the package installs  were done through pip.\r\nWindows 7-64 bit\r\nI'm using command:- python setup.py build\r\nBelow is my setup.py file:-\r\n\r\n import cx_Freeze\r\n import sys\r\n import matplotlib\r\n import os\r\n import pandas\r\n import tkinter.filedialog\r\n import keras\r\n import sklearn\r\n import numpy\r\n import tensorflow\r\n import openpyxl\r\n import datetime\r\n base = None\r\n \r\n os.environ['TCL_LIBRARY'] = r'C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\tcl\\tcl8.6'\r\n os.environ['TK_LIBRARY'] = r'C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\tcl\\tk8.6'\r\n \r\n if sys.platform == 'win32':\r\n     base = \"Win32GUI\"\r\n from glob import glob\r\n #data_files = [(\"Microsoft.VC120.CRT\", glob(r'C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\redist\\x64\\Microsoft.VC120.CRT\\*.*'))]    \r\n executables = [cx_Freeze.Executable(\"app-3.py\",base=base)]\r\n \r\n cx_Freeze.setup(\r\n         name = \"foreacast\",\r\n         #options = {\"build_exe\": {\"packages\":[\"tkinter\",\"matplotlib\"],\"include_files\":[\"numpy\"]}}\r\n         options = { \"build_exe\": {\"packages\":[\"cx_Freeze\",\"datetime\",\"openpyxl\",\"tkinter\",\"numpy\",\"matplotlib\",\"pandas\",\"tkinter.filedialog\",\"keras\",\"sklearn\",\"tensorflow\"] }},\r\n         version = \"0.1\",\r\n         description = \"test\",\r\n         #data_files=data_files,\r\n         executables = executables)\r\nBelow is input file- app-3.py\r\n#from tkinter import Tk, Label, Button, Frame\r\nimport tkinter as tk\r\nfrom tkinter.filedialog import askopenfilename\r\nimport os\r\nimport tkinter.messagebox\r\nimport numpy as np\r\nimport xlrd\r\nimport datetime\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.layers import LSTM\r\nfrom keras.layers import Dense\r\nfrom keras.layers import Dropout\r\nfrom keras import optimizers\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom numpy.random import seed\r\nimport tensorflow as tf\r\nfrom tensorflow import set_random_seed \r\nfrom openpyxl import load_workbook\r\n# Here, we are creating our class, Window, and inheriting from the Frame\r\n# class. Frame is a class from the tkinter module. (see Lib/tkinter/__init__)\r\nclass Window(tk.Frame):\r\n\r\n    # Define settings upon initialization. Here you can specify\r\n    def __init__(self, master=None):\r\n        \r\n        # parameters that you want to send through the Frame class. \r\n        tk.Frame.__init__(self, master,background=\"#66b3ff\")   \r\n\r\n        #reference to the master widget, which is the tk window                 \r\n        self.master = master\r\n\r\n        #with that, we want to then run init_window, which doesn't yet exist\r\n        self.init_window()\r\n    \r\n        self.master.minsize(width=1400, height=900)\r\n        self.master.maxsize(width=1400, height=900)\r\n        self.master.configure(background=\"#8cb3d9\")\r\n    #Creation of init_window\r\n    def close_window():\r\n        root.destroy()\r\n        \r\n    def init_window(self):\r\n\r\n        # changing the title of our master widget      \r\n        self.master.title(\"Call Volume Forecasting\")\r\n\r\n        tk.Label(root, text=\"Call Volume Forecasting\",font = \"Helvetica 28 bold italic\",bg = \"#3333ff\",fg = \"white\",width=20).grid(row=0,column=0,columnspan=4,padx=400, pady=20,sticky=tk.W)\r\n        \r\n        self.CheckAdvisor=tk.IntVar()\r\n        self.CheckShareholder=tk.IntVar()\r\n        self.CheckRetirement=tk.IntVar()\r\n        self.CheckFast=tk.IntVar()\r\n        self.CheckVIP=tk.IntVar()\r\n        self.CheckCGF=tk.IntVar()\r\n        self.CheckWT=tk.IntVar()\r\n        self.CheckIOBRP=tk.IntVar()\r\n        self.CheckFT=tk.IntVar()\r\n        self.CheckNJBEST=tk.IntVar()\r\n        self.CheckSelectAll=tk.IntVar()\r\n        self.CheckType = tk.IntVar()\r\n        self.input_file = \"\"\r\n        \r\n        tk.Button(root,text=\"Choose Input File\",command=self.choose_input_file,font = \"Helvetica 18 bold italic\",bg = \"#3333ff\",fg = \"white\",width=15,height=1).grid(row=1, column = 0,columnspan=2, padx=200,pady=30,sticky=tk.W)\r\n                  \r\n        self.input_file = tk.Text(root,width=80,height=2)\r\n        self.input_file.grid(row=1, column=1,columnspan=3,padx=50,pady=20, sticky=tk.W)\r\n        \r\n        self.advisorstate = tk.Checkbutton(root, text=\"Advisor\",  variable= self.CheckAdvisor,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.advisorstate.grid(row=2, column = 0, padx=100, pady=30,sticky=tk.W)\r\n        \r\n        self.shareholderstate = tk.Checkbutton(root, text=\"Shareholder\",variable= self.CheckShareholder, font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.shareholderstate.grid(row=3, column = 0, padx=100, pady=30,sticky=tk.W)\r\n        \r\n        self.retirementstate= tk.Checkbutton(root, text=\"Retirement\",variable= self.CheckRetirement,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.retirementstate.grid(row=4, column = 0, padx=100, pady=30,sticky=tk.W)\r\n        \r\n        self.faststate = tk.Checkbutton(root, text=\"Fast\",variable=self.CheckFast,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.faststate.grid(row=5, column = 0, padx=100, pady=30,sticky=tk.W)\r\n        \r\n        self.vipstate = tk.Checkbutton(root, text=\"VIP\",variable=self.CheckVIP,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.vipstate.grid(row=6, column = 0, padx=100, pady=30,sticky=tk.W)\r\n        \r\n        self.cgf = tk.Checkbutton(root, text=\"CGF\",variable=self.CheckCGF,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.cgf.grid(row=2, column = 1, padx=10, pady=30,sticky=tk.W)\r\n        \r\n        self.wt = tk.Checkbutton(root, text=\"WT\",variable=self.CheckWT,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.wt.grid(row=3, column = 1, padx=10, pady=30,sticky=tk.W)\r\n        \r\n        self.iobrp = tk.Checkbutton(root, text=\"IOBRP\",variable=self.CheckIOBRP,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.iobrp.grid(row=4, column = 1, padx=10, pady=30,sticky=tk.W)\r\n        \r\n        self.ft = tk.Checkbutton(root, text=\"FT 529\",variable=self.CheckFT,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.ft.grid(row=5, column = 1, padx=10, pady=30,sticky=tk.W)\r\n        \r\n        self.njbest = tk.Checkbutton(root, text=\"NJBEST\",variable=self.CheckNJBEST,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\",width=10,anchor=tk.W)\r\n        self.njbest.grid(row=6, column = 1, padx=10, pady=30,sticky=tk.W)\r\n        \r\n        self.selectall = tk.Checkbutton(root, text=\"Select all skills\",variable=self.CheckSelectAll,command=self.cb_check,font = \"Helvetica 18 bold italic\",bg = \"light grey\",fg = \"black\")\r\n        self.selectall.grid(row=4, column = 2,padx=10,pady=30,sticky=tk.W)\r\n        \r\n        self.daily = tk.Radiobutton(root, text=\"Daily\",variable=self.CheckType,value=1,font = \"Helvetica 18 bold italic\",width=10,bg=\"light grey\",anchor=tk.W)\r\n        self.daily.grid(row=3, column = 3, pady=30,sticky=tk.W)\r\n        \r\n        self.monthly = tk.Radiobutton(root, text=\"Monthly\",variable=self.CheckType,value=2,font = \"Helvetica 18 bold italic\",width=10,bg=\"light grey\",anchor=tk.W)\r\n        self.monthly.grid(row=4, column = 3, pady=30,sticky=tk.W)\r\n        \r\n        self.both = tk.Radiobutton(root, text=\"Both\",variable=self.CheckType,value=3,font = \"Helvetica 18 bold italic\",width=10,bg=\"light grey\",anchor=tk.W)\r\n        self.both.grid(row=5, column = 3, pady=30,sticky=tk.W)\r\n        \r\n        tk.Button(root, text=\"Build\",font = \"Helvetica 18 bold italic\",bg = \"#3333ff\",fg = \"white\",width=10,height=1,command=self.build_models).grid(row=7, column = 0, padx=100,pady=30,sticky=tk.W)\r\n        tk.Button(root, text=\"Forecast\",font = \"Helvetica 18 bold italic\",bg = \"#3333ff\",fg = \"white\",width=10,height=1,command=self.forecast_models).grid(row=7, column = 1, padx=50,pady=30,sticky=tk.W)\r\n        tk.Button(root, text=\"Clear\",font = \"Helvetica 18 bold italic\",bg = \"#3333ff\",fg = \"white\",width=10,height=1,command = self.clear).grid(row=7, column = 2, padx=50,pady=30,sticky=tk.W)\r\n        tk.Button(root, text=\"Exit\",font = \"Helvetica 18 bold italic\",bg = \"#3333ff\",fg = \"white\",width=10,height=1,command = self.close).grid(row=7, column = 3, padx=50,pady=30,sticky=tk.W)         \r\n\r\n    def cb_check(self):\r\n        if self.CheckSelectAll.get():\r\n            self.advisorstate.config(state=tk.DISABLED)\r\n            self.CheckAdvisor.set(0)\r\n            self.shareholderstate.config(state=tk.DISABLED)\r\n            self.CheckShareholder.set(0)\r\n            self.retirementstate.config(state=tk.DISABLED)\r\n            self.CheckRetirement.set(0)\r\n            self.faststate.config(state=tk.DISABLED)\r\n            self.CheckFast.set(0)\r\n            self.vipstate.config(state=tk.DISABLED)\r\n            self.CheckVIP.set(0)\r\n            self.cgf.config(state=tk.DISABLED)\r\n            self.CheckCGF.set(0)\r\n            self.wt.config(state=tk.DISABLED)\r\n            self.CheckWT.set(0)\r\n            self.iobrp.config(state=tk.DISABLED)\r\n            self.CheckIOBRP.set(0)\r\n            self.ft.config(state=tk.DISABLED)\r\n            self.CheckFT.set(0)\r\n            self.njbest.config(state=tk.DISABLED)\r\n            self.CheckNJBEST.set(0)\r\n        else:\r\n            self.advisorstate.config(state=tk.NORMAL)\r\n            self.shareholderstate.config(state=tk.NORMAL)\r\n            self.retirementstate.config(state=tk.NORMAL)\r\n            self.faststate.config(state=tk.NORMAL)\r\n            self.vipstate.config(state=tk.NORMAL)\r\n            self.cgf.config(state=tk.NORMAL)\r\n            self.wt.config(state=tk.NORMAL)\r\n            self.iobrp.config(state=tk.NORMAL)\r\n            self.ft.config(state=tk.NORMAL)\r\n            self.njbest.config(state=tk.NORMAL)\r\n    \r\n    def close(self):\r\n        root.destroy()\r\n        \r\n    def clear(self):\r\n        #print(\"in claer\")\r\n        self.CheckAdvisor.set(0)\r\n        self.CheckShareholder.set(0)\r\n        self.CheckRetirement.set(0)\r\n        self.CheckFast.set(0)\r\n        self.CheckVIP.set(0)\r\n        self.CheckCGF.set(0)\r\n        self.CheckWT.set(0)\r\n        self.CheckIOBRP.set(0)\r\n        self.CheckFT.set(0)\r\n        self.CheckNJBEST.set(0)\r\n        self.CheckSelectAll.set(0)\r\n        self.CheckType.set(0)\r\n        self.input_file.delete('1.0', tk.END)\r\n        self.advisorstate.config(state=tk.NORMAL)\r\n        self.shareholderstate.config(state=tk.NORMAL)\r\n        self.retirementstate.config(state=tk.NORMAL)\r\n        self.faststate.config(state=tk.NORMAL)\r\n        self.vipstate.config(state=tk.NORMAL)\r\n        self.cgf.config(state=tk.NORMAL)\r\n        self.wt.config(state=tk.NORMAL)\r\n        self.iobrp.config(state=tk.NORMAL)\r\n        self.ft.config(state=tk.NORMAL)\r\n        self.njbest.config(state=tk.NORMAL)\r\n        self.input_file.config(state=tk.NORMAL)\r\n\r\n    def choose_input_file(self):\r\n        self.filename = askopenfilename()\r\n        if os.path.isfile(self.filename):\r\n            self.input_file.configure(state=tk.NORMAL)\r\n            self.input_file.insert(tk.INSERT,self.filename)\r\n            self.input_file.configure(state=tk.DISABLED)\r\n            fname = self.input_file.get(\"1.0\", \"end-1c\")\r\n            workbook = xlrd.open_workbook(fname,\"w\")\r\n            \r\n            #print(self.input_file)\r\n        else: \r\n            print(\"No file chosen\")\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"Please select input file\")\r\n     \r\n    def validation(self):\r\n        if len(self.input_file.get(\"1.0\", \"end-1c\")) == 0:\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"Please select input file\")\r\n        else:\r\n            print(\"file selected\")\r\n            self.validate_chbox()\r\n            \r\n            \r\n    def validate_chbox(self):\r\n        if self.CheckAdvisor.get() == 0 and self.CheckShareholder.get() == 0 and self.CheckRetirement.get() == 0 and self.CheckFast.get() == 0 and self.CheckVIP.get() == 0 and self.CheckCGF.get() == 0 and self.CheckWT.get() == 0 and self.CheckIOBRP.get() == 0 and self.CheckFT.get() == 0 and self.CheckNJBEST.get() == 0 and self.CheckSelectAll.get() == 0:\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"Please select the skill\")\r\n        else:\r\n            self.validate_radiobtn()\r\n            \r\n    def validate_radiobtn(self):\r\n        if self.CheckType.get() == 0:\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"Please select the forecast type\")\r\n    \r\n    def build_models(self):\r\n        self.validation()\r\n        self.build()\r\n    \r\n    def build(self):\r\n        if self.CheckSelectAll.get() == 1:\r\n            self.buildAllModels()\r\n        else:\r\n            self.build_advisor_selected()\r\n    \r\n    def buildAllModels(self):\r\n        print(\"in buildAllModels\")\r\n    \r\n    def forecast_models(self):\r\n        self.validation()\r\n        self.forecast()\r\n        \r\n    def forecast(self):\r\n        if self.CheckSelectAll.get() == 1:\r\n            self.forecastAllModels()\r\n        else:\r\n            self.forecast_advisor_selected() \r\n            \r\n    def build_advisor_selected(self):\r\n        if self.CheckAdvisor.get() == 1:\r\n            if self.CheckType.get() == 1:\r\n                print(\"daily\")\r\n                self.build_advisor_daily()\r\n            elif self.CheckType.get() == 2:\r\n                print(\"monthly\")\r\n                self.advisor_monthly()\r\n            else:\r\n                print(\"both\")\r\n                self.advisor_both()\r\n    \r\n    def forecast_advisor_selected(self):\r\n        if self.CheckAdvisor.get() == 1:\r\n            if self.CheckType.get() == 1:\r\n                print(\"daily\")\r\n                self.forecast_advisor_daily()\r\n            elif self.CheckType.get() == 2:\r\n                print(\"monthly\")\r\n                self.forecast_advisor_monthly()\r\n            else:\r\n                print(\"both\")\r\n                self.forecast_advisor_both()\r\n   \r\n    def build_advisor_daily(self):\r\n        required_data = self.read_advisor_daily()\r\n        print(required_data)\r\n        #global advisor_build \r\n        #if global advisor_build ==0:\r\n        self.build_advisor_daily_model(required_data)\r\n        #else:\r\n            #print(\"advisor model already built.Please forecast\")\r\n            \r\n    def read_advisor_daily(self):\r\n        fname = self.input_file.get(\"1.0\", \"end-1c\")\r\n        workbook = xlrd.open_workbook(fname,\"w\")\r\n        #sheets = workbook.sheet_names()\r\n        date_col = []\r\n        required_data = []\r\n        sh = workbook.sheet_by_name(\"Daily_Data\")\r\n        for rownum in range(1,sh.nrows):\r\n            row_valaues = sh.row_values(rownum)\r\n            date_col.append(datetime.datetime(*xlrd.xldate_as_tuple(row_valaues[0],workbook.datemode)))\r\n            required_data.append(row_valaues[1])\r\n    \r\n        required_data = pd.DataFrame(required_data)\r\n        required_data.replace('', np.nan, inplace=True)\r\n        required_data.dropna(inplace=True)\r\n        return required_data\r\n    \r\n    \r\n    def build_advisor_daily_model(self,required_data):\r\n        print(\"in build_advisor_daily_model\")\r\n        self.destroy()\r\n        print(required_data)\r\n        np.random.seed(12345) \r\n        tf.set_random_seed(12345)\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"Advisor model building started\")\r\n        print(type(required_data))\r\n        data_set = required_data\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"data set read\")\r\n        model_data_set = data_set.iloc[:,:]\r\n        model_data_set = model_data_set[model_data_set[0]>0]\r\n        print(len(model_data_set))\r\n        a1=len(model_data_set)\r\n        print(type(model_data_set))\r\n        tkinter.messagebox.showinfo(title=\"\", message=a1)\r\n        modified_data = model_data_set\r\n        modified_data = modified_data.values.reshape(-1,1)\r\n        print(modified_data.shape)\r\n        print(modified_data)\r\n         \r\n        global sc \r\n        sc = MinMaxScaler(feature_range=(0,1))\r\n        train = sc.fit_transform(modified_data)\r\n        print(train[0:5,:])\r\n        print(train.shape)\r\n        print(train.shape[0])\r\n        print(train.shape[1])\r\n        \r\n        global y_train\r\n        X_train = []\r\n        y_train = []\r\n        l = len(modified_data)\r\n        print(l)\r\n        for i in range(60,l):\r\n            X_train.append(train[i-60:i,:])\r\n            y_train.append(train[i,:])\r\n        print(len(X_train))\r\n        print(len(y_train))\r\n        X_train = np.array(X_train)\r\n        y_train = np.array(y_train)\r\n        print(X_train.shape)\r\n        #print(X_train)\r\n        print(y_train.shape)\r\n        #X_train = X_train.reshape(X_train.shape[1],1)\r\n        print(X_train.shape[0])\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"train data built\")\r\n        #total 60 columns, lag=20\r\n        global regressor\r\n        regressor = Sequential()\r\n        regressor.add(LSTM(units=60,return_sequences=True,input_shape=(X_train.shape[1],1)))\r\n        regressor.add(Dropout(0.2))\r\n        regressor.add(LSTM(units=60,return_sequences=True))\r\n        regressor.add(Dropout(0.2))\r\n        regressor.add(LSTM(units=60,return_sequences=True))\r\n        regressor.add(Dropout(0.2))\r\n        #regressor.add(LSTM(units=60,return_sequences=True))\r\n        #regressor.add(Dropout(0.2))\r\n        #regressor.add(LSTM(units=50,return_sequences=True))\r\n        #regressor.add(Dropout(0.2))\r\n        regressor.add(LSTM(units=60))\r\n        regressor.add(Dropout(0.2))\r\n        regressor.add(Dense(units=1))\r\n        #rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=0.001, decay=0.001)\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"compiling model\")\r\n        regressor.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"model compilation complete\")\r\n        regressor.fit(X_train,y_train,epochs=300,batch_size=32,shuffle=False)\r\n        global advisor_build\r\n        advisor_build = 1\r\n        print(y_train)\r\n        tkinter.messagebox.showinfo(title=\"\", message=\"Advisor model building completed\")\r\n        #return (self.regressor,advisor_build,y_train)\r\n    \r\n    def forecast_advisor_daily(self):\r\n        print(\"in forecast\")\r\n        global advisor_build\r\n        print(advisor_build)\r\n        global y_train\r\n        global sc\r\n        global regressor\r\n        #advisor_build = 1\r\n        if advisor_build == 1:\r\n            y_test = y_train\r\n            print(y_test)\r\n            print(len(y_test))\r\n            X_test_1 = []\r\n            prediciton_list = []\r\n            y_test = y_test.reshape(-1,1)\r\n            print(y_test.shape)\r\n\r\n            y_test = sc.transform(y_test)\r\n\r\n            X_test_1.append(y_test[-60:])\r\n            print(X_test_1)\r\n            X_test_1 = np.array(X_test_1)\r\n            print(X_test_1[0:5])\r\n            print(X_test_1.shape)\r\n            for x in range(20):\r\n\r\n                y_pred_1 = regressor.predict(X_test_1)\r\n\r\n                a = sc.inverse_transform(y_pred_1)\r\n                b = a[0][0]\r\n                X_test_1 = np.delete(X_test_1,0,axis=1)\r\n\r\n                a = y_pred_1[0][0]\r\n\r\n                X_test_1 = np.concatenate((X_test_1,np.zeros((1,1,1))),axis=1)\r\n                X_test_1 = np.insert(X_test_1,59,a,axis=1)\r\n                X_test_1 = np.delete(X_test_1,60,axis=1) \r\n\r\n                prediciton_list.append(b)\r\n\r\n            print(prediciton_list)\r\n            fname = self.input_file.get(\"1.0\", \"end-1c\")\r\n            workbook = xlrd.open_workbook(fname,\"w\")\r\n            date_col = []\r\n            required_data = []\r\n            sh = workbook.sheet_by_name(\"Daily_Data\")\r\n            for rownum in range(1,sh.nrows):\r\n                row_valaues = sh.row_values(rownum)\r\n                date_col.append(datetime.datetime(*xlrd.xldate_as_tuple(row_valaues[0],workbook.datemode)))\r\n                required_data.append(row_valaues[1])\r\n            required_data = pd.DataFrame(required_data)\r\n            print(required_data)\r\n            len1 = len(required_data)\r\n            required_data.replace('', np.nan, inplace=True)\r\n            z = required_data.last_valid_index()\r\n            print(z)\r\n            print(type(z))\r\n            ind = z\r\n            ind = ind + 1\r\n            y = required_data.loc[required_data.last_valid_index()]\r\n            print(y)\r\n            required_data.dropna(inplace=True)\r\n            print(required_data)\r\n            date_col = pd.DataFrame(date_col)\r\n            print(date_col)\r\n            end_date = date_col.iloc[z][0]\r\n            \r\n            z =  z + 2\r\n            y = z\r\n            print(z)\r\n            start_date = date_col.iloc[z][0]\r\n \r\n            print(start_date.date())\r\n \r\n \r\n            df2 = pd.DataFrame(prediciton_list)\r\n            print(df2)\r\n            df3 = []\r\n            for i in range(ind,ind+20):\r\n                df3.append(date_col.iloc[i][0])\r\n\r\n            df3 = pd.DataFrame(df3,columns = [\"Date\"])\r\n            print(df3)\r\n      \r\n \r\n            k = df3.loc[df3['Date'].isin(['2018-01-01','2018-01-15','2018-02-19','2018-03-30','2018-05-28','2018-07-04','2018-09-03','2018-11-23','2018-12-25'])]\r\n            print(k)\r\n            print(type(k))\r\n            print(len(k))\r\n            index_list = []\r\n         \r\n            if len(k) >= 1:\r\n                for z in range(len(k)):\r\n                    index_list.append(k.index[z])\r\n                    print(index_list)\r\n         \r\n                for l in range(len(index_list)):\r\n                    m = index_list[l]\r\n                    df2.xs(m)[0] = 0\r\n            else:\r\n                print(\"no holidays\")\r\n            print(df2)\r\n            book = load_workbook(fname)\r\n            writer = pd.ExcelWriter(fname, engine='openpyxl') \r\n            writer.book = book\r\n            writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\r\n            print(y)\r\n            df2.to_excel(writer, \"Daily_Output\", startcol=1,startrow=y,header=None,index=False)\r\n            \r\n            writer.save()\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"Advisor forecasting completed\")\r\n            \r\n        else:\r\n            tkinter.messagebox.showinfo(title=\"\", message=\"please build  first and then forecast\")\r\n    def destroy(self):\r\n        global advisor_build\r\n        global regressor\r\n        regressor = None\r\n        global y_train\r\n        y_train = None\r\n        global sc\r\n        sc = None\r\n        advisor_build = 0\r\n\r\n    \r\n       \r\n# =============================================================================\r\n#     def mean_absolute_percentage_error(y_true, y_pred): \r\n#         perc = [0 if x ==0 else np.abs((x-y)/x) for x,y in zip(y_true,y_pred)]\r\n#         return np.mean(perc[1]) * 100\r\n# =============================================================================\r\n\r\nroot = tk.Tk()\r\n#creation of an instance\r\n#holiday_list = ['2018-01-01','2018-01-15','2018-02-19','2018-03-30','2018-05-28','2018-07-04','2018-09-03','2018-11-23','2018-12-25']\r\nglobal advisor_build\r\nglobal regressor\r\nglobal y_train\r\nglobal sc\r\napp = Window(root)\r\n#mainloop \r\nroot.mainloop()        \r\n\r\nBelow is the error -\r\nC:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36>python setup.py build\r\nUsing TensorFlow backend.\r\nrunning build\r\nrunning build_exe\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 38, in <module>\r\n    executables = executables)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\dist.py\", line 349, in setup\r\n    distutils.core.setup(**attrs)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\c\r\nore.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\d\r\nist.py\", line 955, in run_commands\r\n    self.run_command(cmd)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\d\r\nist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\c\r\nommand\\build.py\", line 135, in run\r\n    self.run_command(cmd_name)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\c\r\nmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\distutils\\d\r\nist.py\", line 974, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\dist.py\", line 219, in run\r\n    freezer.Freeze()\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\freezer.py\", line 616, in Freeze\r\n    self.finder = self._GetModuleFinder()\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\freezer.py\", line 342, in _GetModuleFinder\r\n    finder.IncludePackage(name)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\finder.py\", line 661, in IncludePackage\r\n    self._ImportAllSubModules(module, deferredImports)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\finder.py\", line 288, in _ImportAllSubModules\r\n    recursive)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\finder.py\", line 288, in _ImportAllSubModules\r\n    recursive)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\finder.py\", line 288, in _ImportAllSubModules\r\n    recursive)\r\n  File \"C:\\Users\\bpachkor\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packag\r\nes\\cx_Freeze\\finder.py\", line 283, in _ImportAllSubModules\r\n    raise ImportError(\"No module named %r\" % subModuleName)\r\nImportError: No module named 'tensorflow.contrib.ios_examples.benchmark.benchmar\r\nk.xcodeproj'\r\n\r\nI have tried doing same steps for python 3.5, but with no luck.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code-Yes\r\nOS Platform and Distribution- Win 7 -64 bit\r\nTensorFlow installed from - pip\r\nTensorFlow version- 1.5\r\nBazel version-N/A\r\nCUDA/cuDNN version-N/A\r\nGPU model and memoryGPU-N/A , memory - 8GB RAM\r\nExact command to reproduce- python setup.py build", "I am also facing the same problem while building an .exe file.", "is there any other way of creating exe file for python 3.5 or 3.6 specifically? Please guide me on this.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@petewarden :- the issue is still not resolved, getting the same error.", "Try various versions of Tensorflow.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "the same problem (", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@Ramiel1996  I tried creating exe on different system by installing the same set of libraries and got lucky to have it worked on one of the system. I couldn't find the solution for above problem.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Looks like issue is resolved. \r\nThe particular file mentioned: tensorflow.contrib.ios_examples.benchmark.benchmark.xcodeproj is a xcodeproj file and should not corrupt python imports, @bhagyashripachkor it could be something wrong with your setup."]}, {"number": 17513, "title": "Fix minor typo in saved_model.md", "body": "Described as PR title.", "comments": []}, {"number": 17512, "title": "Fix broken link of distributed in graphs.md", "body": "This PR is to fix:\r\n- As you can see in https://www.tensorflow.org/programmers_guide/graphs, the link of typical distributed configuration is broken:\r\n    > If you are deploying TensorFlow in a @{$deploy/distributed$typical distributed configuration}, you might \r\n\r\n- The link of tensor-like type(https://www.tensorflow.org/programmers_guide/graphs#tensor_like_objects) is broken, changed it to https://www.tensorflow.org/programmers_guide/graphs#tensor-like_objects", "comments": ["It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Is there any admin help review this patch?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@frankchn Is there any admin help review this patch?"]}, {"number": 17511, "title": "android Semantic segmentation  ", "body": "Hello,\r\n\r\ncan tensorflow for android be used for semantic segmentation?\r\nThank you\r\n\r\nLafi", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "i want to ask the same question ?\r\n@tensorflowbutler \r\n### System information\r\n- **Have I written custom code : No\r\n- **OS Platform and Distribution : windows 10 \r\n- **TensorFlow installed from binary\r\n- **TensorFlow version :1.6\r\n- **Python version**: 3\r\n- **Bazel version *:N/A\r\n- **CUDA/cuDNN version**: cuda 9 - cudnn 7\r\n- **GPU model and memory**: geforce gtx 960 - 4 GB \r\n- **Exact command to reproduce**: N/A", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17510, "title": "Feature request: size of memory vectors in LSTM", "body": "## Motivation\r\n\r\nThere are two different memory vectors used in LSTM cell: internal state vector (_**c**_ symbol in tensorflow convention) and output vector (_**h**_ in tensorflow convention). Let\u2019s consider the possible sizes of both vectors:\r\n\r\n- _**c**_ (internal state vector) \u2013 has to be the same size for both input and output of a single cell (equation 5 below)\r\n\r\n- _**h**_ (output vector) \u2013 doesn\u2019t have to be the same (1-4), to be more specific: input size could be arbitrary, but the output size has to be the same as _**c**_ (6)\r\n\r\n![lstm_eq](https://user-images.githubusercontent.com/9368849/37099738-671646fa-2221-11e8-9de6-30c46bc36988.png)\r\n\r\nThe equations are copied from [a great paper](https://arxiv.org/pdf/1506.00019.pdf) of Lipton, Berkowitz and Elkan and again the notation is different: _**s**_=_**c**_).\r\n\r\nWhy setting different input and output size of _**h**_ vector is it useful? If \u2018because we can\u2019 doesn\u2019t satisfy you I can cite [OrderMatters paper](https://arxiv.org/pdf/1511.06391.pdf) (their notation is a bit different _**h**_=_**q**_).\r\n\r\n## Current implementation\r\n\r\nCurrently, in different LSTM cells constructors, there is only one parameter responsible for setting the size of both _**c**_ and _**h**_ vectors and it\u2019s called _**num_units**_. IMO it\u2019s not the best name for this param, but that\u2019s not my point here \u2013 there is no way to set different input and output size of _**h**_ vector.\r\n\r\n## Proposal\r\n\r\nWe could leave the _**num_units**_ param for backward compatibility with an integer value and the current behavior. On the other hand, if a user pass a tuple of length 2, we could interpret the param as : (input_size of h, output_size of h). Those two numbers are sufficient for describing both _**c**_ and _**h**_ sizes.\r\n\r\n## Implementation\r\n\r\nI have already implemented proposed modification for LSTMCell class and it works fine. I could implement the proposed feature for all LSTM-like cells and create PR, but first wanted to ask the community and tensorflowers if it useful form your perspective?\r\n\r\n## System information\r\n- **Have I written custom code**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n", "comments": ["Hi, friend. \r\n\r\nAre you looking for output projection?\r\nIn the follwowing paper, output projection is proposed, which allows `c` and `h` to have different sizes.\r\n\r\n>  Hasim Sak, Andrew Senior, and Francoise Beaufays.\r\n>   \"Long short-term memory recurrent neural network architectures for\r\n>    large scale acoustic modeling.\" INTERSPEECH, 2014.\r\n\r\nIt has already been implemented in `tf.nn.rnn_cell.LSTMCell`.\r\n\r\nIf one needs a more complicated tranformation from `h` to match the size of `c`, I would suggest him to write his own RNNCell instead of including it into the standard library.", "Hello Chong,\r\n\r\nI believe the output projection is something different because following the original LTSM equations we do not need any additional matrix to have different input and output sizes of _**h**_. And you're of course right, one can always implement his own RNNCell, but we already have many different version of LSTM Cell. That's why I asked: does TF community needs such LSTM implementation or not? :smiley: \r\n\r\nBest", "I don't really understand your (input_size of h, output_size of h). \r\nI glanced over two papers you mentioned above, but didn't find anything related to input size and output size. Did I miss something?\r\n\r\nCould you please explain it by pointing out the shapes of all matrices in LSTM update formulae?\r\nSay, if input_size of `h` is `m` and output_size of `h` is `n`, what's the shape of W^{gh} and other matrices?", "Hi Chong,\r\n\r\nof course! Using the notation from [Lipton, Berkowitz, and Elkan](https://arxiv.org/pdf/1506.00019.pdf):\r\n\r\n0. Let's suppose **h^(t-1) is size [m]**\r\n1. W^(gh) will be the size of [n, m] so the g^t will be the size of [n] -- same story for i^t, f^t, and o^t.\r\n2. Both s^(t-1) and s^t will be the size of [n]\r\n3. **h^t will be the size of [n]**\r\n\r\nThe other params:\r\n\r\n4) All b params will be size of [n]\r\n5) All input matrices W^(_x) will be size of [n, input_features_size]\r\n6) x^(t) will be size of [input_features_size]\r\n\r\nDoes it make sense to you?", "Probably no.\r\nHow come the shapes of h^(t-1) and h^(t) are different! If these two vectors are of different shape, you can't even maintain the RNN loop!\r\n\r\nSuppose at a certain time step `t0`, the size of hidden state changed from [m] (the size of h^(t0-1)) to [n] (the size of h^(t0)), how can you run the RNN loop for time step t0+1? The matrix multiplication W^(gh)h^(t0) will cause a mismatch.\r\n\r\nTry to write the code and you'll find it out.\r\n\r\n", "Yes, but that's exactly what is proposed in [OrderMatters](https://arxiv.org/pdf/1511.06391.pdf) paper!  After each timestep, the previous output state is concatenated with attention mechanism over the inputs (equation 7).\r\n\r\nI've already written all the code and it's working like a charm :smiley: ", "Oh I see it. Thanks for your patience.\r\n\r\nIn the OrderMatters paper, [they say](https://www.reddit.com/r/MachineLearning/comments/6efl5g/d_order_matters_attention_mechanisms/di9wws9/) their LSTM has no input, the input state size is `2h`, output state size is `h`, and the recurrent matrices are of shape `2h`-by-`h`.\r\n\r\nI think it is just a misnomer. Actually, you don't need the concatenation stuff: just rewrite the equation (3) as `q_t=LSTM(q_{t-1}, r_{t-1})`, where `q` is the LSTM state of size `h` and `r` is the input vector of size `h`(i.e.: vector `x` in Lipton, Berkowitz, and Elkan's notation), then this LSTM can fit into standard LSTM APIs.\r\n\r\nWhat's more, even if you use the notation in the paper, you'll need an attention mechanism over the memory `m`s, so you'll need to combine it with an `AttentionWrapper`, which is beyond the scope of an RNNCell.\r\n\r\nOf course you can post your code here (maybe a github repo link). If your API design is good enough and compatible with the TF library very well, it is worthwhile to include the new RNN cell into TF. And as far as I know, there is no open source implementation of OrderMatters. So it'll be very kind of you to do this.\r\n", "Oh, my! You're right! I can use a standard LSTM API, but why do authors even described this that complicated way? Do you have a clue?\r\n\r\nTo be sure: I will try to implement the OrderMatters mechanism with standard API and will let you know. And thank you for your suggestion about open-sourcing OrderMatters implementation, I will extract the part of my current project and post it on as a standalone repo.\r\n\r\nGetting back to the different input/output sizes of hidden state of LSTM cell: I'm not sure if it's required anymore, but I'll clean up my code and let you know of my implementation.", "Because the \"input\" is computed from previous step and cannot be fetched beforehand. The author may want to emphasize that this cell has no additional inputs.\r\n\r\nLooking forward to your implementation.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I need more time! :smile: ", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks for the discussion @dkoguciuk and @soloice \r\nMarking as \"awaiting response\" for now, since IIUC, the requested feature may not be as valuable as originally thought?", "Agree with you.", "Hello, thank you @asimshankar and @soloice! I guess this is sort of an edge case and no one really needs this functionality. I think we could just close the issue."]}, {"number": 17509, "title": "Estimators Importance sampling", "body": "Seems that [Keras/Tensorflow](http://idiap.ch/~katharas/importance-sampling/) has some form of external importance sampling support.\r\nDo you have a plan to add [a solution](https://arxiv.org/abs/1803.00942v1) for Estimators?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It is a Feature Request or a disclosure request about the internal roadmap. Development appear with burst from internal private code so it is hard to know what are you cooking in detail other than a quite general Roadmap file.\r\nCan you disable bot template filling requests on FR/Disclosure? Thanks", "Yes, we are working on disabling bot responses to FR. Thanks @bhack ", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Seems pretty unlikely. You can do importance sampling in the input or the model itself, can't you? It doesn't seem like it needs special support.", "I think that in the context of High level API the dataset api that it is producing optimized batches need to comunicate with the estimator that is aware of the batch loss. I think that both the components needs to have an API to interact among them. \r\nWhat do you think? Probably this type of communication could be useful also for other techniques related to curriculum learning like: https://arxiv.org/abs/1801.00904", "You can hack Estimator to do that by putting all the input logic into model_fn and having a dummy input_fn.\r\nCurrent separation of input from model gives us flexibility. We're not considering a duplex interaction.", "@ispirmustafa Yes I know that with software I can do almost everything. \r\nHonestly I am more interested to the comment that you don't like a duplex interaction between the two api. I doubt that high level api users will setup an hack like this one. \r\nSo I suppose that the TF team evaluation on this topic is that it is still not relevant for a large use base or not to become a mainstream soon."]}, {"number": 17508, "title": "jpeg.BUILD: Use --cpu instead of --android_cpu", "body": "```\r\nERROR: /var/lib/buildkite-agent/.cache/bazel/_bazel_buildkite-agent/70f524e03685b9df645342d13a051faa/external/jpeg/BUILD:126:12: Illegal ambiguous match on configurable attribute \"deps\" in @jpeg//:jpeg:\r\n--\r\n\u00a0 | @jpeg//:k8\r\n\u00a0 | @jpeg//:armeabi-v7a\r\n```\r\nTF build is broken with Bazel@HEAD, see https://buildkite.com/bazel/bazel-with-downstream-projects-bazel/builds/141#ca77fce7-7ea1-4427-a49b-1ab1305f6bfb\r\n\r\nIssue https://github.com/bazelbuild/bazel/issues/4652\r\n\r\nThe reason is, we recently change default value of --android_cpu to `armeabi-v7a`. https://github.com/bazelbuild/bazel/commit/fc30733995afd1a104051a73218b7a40a0428eb9\r\n\r\nThat results two config_setting enabled at the same time in jpeg.BUILD.\r\n\r\nWe should better use --cpu instead of --android_cpu to select for architecture.\r\n@jart @gregestren\r\nFYI, @buchgr ", "comments": ["@gunan Can you take a look or reassign to others?", "Do we need to edit any existing android build configs?", "From https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=android_cpu&type=\r\nI didn't see any usage of `android_cpu` in TF's build.", "Looks good to me. Bazel's config_setting rules don't actually change the way things are built -- they're a way to trigger a conditional, which then can affect anything that pays attention to config rules, like bazel.rc or select() rules.\r\n\r\nAFAIK, we've always built by using --config=<option> directly, so this change should be fine.", "Please merge this to other branches(r1.7, r1.6, r1.5) to fix #18450.", "While it will be useful, it is not a priority for us as the earlier releases are done, and users of those would be using tags mostly. Merging this to branches would not get the benefits if we merged this without a release.\r\n"]}, {"number": 17507, "title": "Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on", "body": "The error occurs when I have trained on one system and used `tf.Saver` to save a model and then I copied the saved model on  a second system and used the same code to restore the model. However, the absolute paths of the directories in which the code is executed are different. Hence I got this error:\r\n```\r\n2018-03-07 12:08:17.897739: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2018-03-07 12:08:41.813649: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813663: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813680: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813700: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813724: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813769: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813784: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813802: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n2018-03-07 12:08:41.813819: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\nTraceback (most recent call last):\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\r\n    return fn(*args)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\r\n    status, run_metadata)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1668, in <module>\r\n    main()\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1662, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1072, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/alex/work/python/bayes-test/bin/train.py\", line 165, in <module>\r\n    main(**vars(parser.parse_args()))\r\n  File \"/home/alex/work/python/bayes-test/bin/train.py\", line 97, in main\r\n    tu.load_parameters(saver, sess, data_folder)\r\n  File \"/home/alex/work/python/tensorflow_utils/tensorflow_utils/printing.py\", line 13, in load_parameters\r\n    saver.restore(session, ckpt.model_checkpoint_path)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1666, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\r\n\r\nCaused by op 'save/RestoreV2_1', defined at:\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1668, in <module>\r\n    main()\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1662, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/pydevd.py\", line 1072, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/opt/pycharm-2017.3.3/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/alex/work/python/bayes-test/bin/train.py\", line 165, in <module>\r\n    main(**vars(parser.parse_args()))\r\n  File \"/home/alex/work/python/bayes-test/bin/train.py\", line 87, in main\r\n    saver = tf.train.Saver(params)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\r\n    self.build()\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen/model.ckpt: Not found: /mnt/workspace/work/python/bayes-test/bin//results/not_centered/gen; No such file or directory\r\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\r\n```\r\nIsn't the saver suppose to save a somewhat system agnostic version of the tensors? The fact that there is hardcoded absolute paths make me very suspicous?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: No\r\nOS Platform and distribution: Ubuntu 16.04 LTS\r\nTensorflow installed from Anaconda \r\nTensorflow version: 1.4\r\nBazel version: Don't have bazel installed\r\nCUDA/cuDNN version: On the cluster - CUDA 9.0/cudnnv8, the other machine is CPU only\r\nGPU model and memory: V100 (P3 AWS instance)\r\nExact command:\r\n```\r\ndef load_parameters(saver, session, load_dir, force_delete=False):\r\n    if tf.gfile.Exists(load_dir):\r\n        ckpt = tf.train.get_checkpoint_state(load_dir)\r\n        if ckpt and ckpt.model_checkpoint_path:\r\n            saver.restore(session, ckpt.model_checkpoint_path)\r\n        elif force_delete:\r\n            shutil.rmtree(load_dir)\r\n            tf.gfile.MakeDirs(load_dir)\r\n    else:\r\n        tf.gfile.MakeDirs(load_dir)\r\n```\r\nThis is called with absolute paths for `load_dir` on the cluster machine and on the desktop machine. ", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Have you tried passing these libraries a relative path? Maybe it's storing an absolute path because an absolute path was provided.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 45 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/deeplearning/projects/Google/tensorflow/models/research/object_detection/training/model.ckpt-98472\r\n\r\nHI , anyone ,i met the same problem. the reason is that the program is stop and i restart, the problem is occur. but the files is all here:\r\n![image](https://user-images.githubusercontent.com/16716182/44182351-376e8d80-a139-11e8-8b5c-03b27c0204a9.png)\r\n\r\nplease tell me why?thanks a lot"]}, {"number": 17506, "title": "TfLiteCameraDemo crashed on Android 8.1 with call setUseNNAPI(true)", "body": "Hi , \r\nI follow steps in : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite to build tensoflowlite from sources.\r\n\r\ntrying run output demo apk on Google Pixel 2   create crash :\r\n\r\n```\r\n03-07 06:09:44.739 22823-22837/? I/Adreno: ESXAPILOG: API logging initialized: Name = com.example.android.tflitecamerademo, PID = 22823\r\n03-07 06:09:44.744 22823-22823/? W/linker: /data/app/com.example.android.tflitecamerademo-qSwQ-3Ztm2MtPAw8Lu3x4A==/lib/arm64/libtensorflowlite_jni.so: is missing DT_SONAME will use basename as a replacement: \"libtensorflowlite_jni.so\"\r\n03-07 06:09:44.744 22823-22823/? W/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol \"_ZN6tflite14getCurrentTimeEv\" referenced by \"/data/app/com.example.android.tflitecamerademo-qSwQ-3Ztm2MtPAw8Lu3x4A==/lib/arm64/libtensorflowlite_jni.so\"...\r\n03-07 06:09:44.745 22823-22823/? W/linker: /data/app/com.example.android.tflitecamerademo-qSwQ-3Ztm2MtPAw8Lu3x4A==/lib/arm64/libtensorflowlite_jni.so: is missing DT_SONAME will use basename as a replacement: \"libtensorflowlite_jni.so\"\r\n03-07 06:09:44.745 22823-22823/? W/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol \"_ZN6tflite14getCurrentTimeEv\" referenced by \"/data/app/com.example.android.tflitecamerademo-qSwQ-3Ztm2MtPAw8Lu3x4A==/lib/arm64/libtensorflowlite_jni.so\"...\r\n03-07 06:09:44.745 22823-22823/? E/zygote64: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n03-07 06:09:44.745 22823-22823/? D/AndroidRuntime: Shutting down VM\r\n03-07 06:09:44.746 22823-22823/? E/AndroidRuntime: FATAL EXCEPTION: main\r\n                                                   Process: com.example.android.tflitecamerademo, PID: 22823\r\n                                                   java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n                                                       at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)\r\n                                                       at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:48)\r\n                                                       at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:77)\r\n                                                       at com.example.android.tflitecamerademo.ImageClassifier.<init>(ImageClassifier.java:87)\r\n                                                       at com.example.android.tflitecamerademo.ImageClassifierFloatIntel.<init>(ImageClassifierFloatIntel.java:50)\r\n                                                       at com.example.android.tflitecamerademo.CameraActivity.testImage(CameraActivity.java:71)\r\n                                                       at com.example.android.tflitecamerademo.CameraActivity.onCreate(CameraActivity.java:36)\r\n                                                       at android.app.Activity.performCreate(Activity.java:6999)\r\n                                                       at android.app.Activity.performCreate(Activity.java:6990)\r\n                                                       at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214)\r\n                                                       at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2731)\r\n                                                       at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2856)\r\n                                                       at android.app.ActivityThread.-wrap11(Unknown Source:0)\r\n                                                       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1589)\r\n                                                       at android.os.Handler.dispatchMessage(Handler.java:106)\r\n                                                       at android.os.Looper.loop(Looper.java:164)\r\n                                                       at android.app.ActivityThread.main(ActivityThread.java:6494)\r\n                                                       at java.lang.reflect.Method.invoke(Native Method)\r\n                                                       at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)\r\n                                                       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807)\r\n```\r\n\r\nBuild command :  bazel build --cxxopt=--std=c++11 //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\n\r\nTensorflow WORKSPACE file changes:\r\n\r\n```\r\n# Uncomment and update the paths in these entries to build the Android demo.\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\",\r\n   api_level = 27,\r\n   # Ensure that you have the build_tools_version below installed in the\r\n    # SDK manager as it updates periodically.\r\n    build_tools_version = \"27.0.3\",\r\n    # Replace with path to Android SDK on your system\r\n    path = \"/home/XXX/Android/Sdk/\",\r\n)\r\n\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/home/dnozik/Code/Tensorflow/android-ndk-r14b/\",\r\n    # This needs to be 14 or higher to compile TensorFlow.\r\n#    # Please specify API level to >= 21 to build for 64-bit\r\n#    # archtectures or the Android NDK will automatically select biggest\r\n#    # API level that it supports without notice.\r\n#    # Note that the NDK version is not the API level.\r\n    api_level=27)\r\n```\r\n\r\n\r\nSymbols:\r\nXXX@XXX-VirtualBox:~/Code$ nm -S libtensorflowlite_jni.so \r\nnm: libtensorflowlite_jni.so: no symbols\r\n\r\nThanks for help.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code\r\n1.Add call to SetUseNNAPI(true) inside ImageClassifier.java constructor\r\n2.comment on  ` url 'https://google.bintray.com/tensorflow'  in  tensorflow-master\\tensorflow\\contrib\\lite\\java\\demo\\app\\build.gradle    -  It load old tensorflow lite library\r\n\r\nOS Platform and Distribution\r\n**_Ubuntu 17.10_**\r\nTensorFlow installed from\r\n**Github**\r\nTensorFlow version\r\n**Master Clone 3 days ago**\r\nBazel version \r\n**0.10.1**\r\nCUDA/cuDNN version\r\n**No**  VM  VirtualBox Machine\r\nGPU model and memory\r\n**No** VM  VirtualBox Machine\r\nExact command to reproduce\r\n\r\n **bazel build --cxxopt=--std=c++11 //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a**", "A fix for this should appear soon. It amounts to adding  \"duration_utils_jni.cc\", around line 14 of java/src/main/native/BUILD", "Thanks.  \r\nTfLiteCameraDemo is now working for me on Android 8.0 .\r\nIf I upgrade to 8.1 and make **call to setUseNNAPI inside ImageClassifier.java it crashed**.\r\n\r\n```\r\n03-13 04:28:33.877 1117-1235/? D/ContextHubService: Sending message 1025 version 0 from hubHandle 0, appInstance 1, callBackCount 1\r\n03-13 04:28:38.101 1117-2452/? I/ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=com.example.android.tflitecamerademo/.CameraActivity bnds=[641,1293][843,1555]} from uid 10052\r\n03-13 04:28:38.102 720-4235/? D/audio_hw_primary: enable_snd_device: snd_device(2: speaker)\r\n03-13 04:28:38.102 720-4235/? D/audio_route: Apply path: speaker\r\n03-13 04:28:38.103 720-4235/? D/ACDB-LOADER: ACDB -> send_audio_cal, acdb_id = 15, path = 0, app id = 0x11130, sample rate = 48000\r\n03-13 04:28:38.104 720-4235/? D/ACDB-LOADER: ACDB -> ACDB_CMD_GET_AUDPROC_GAIN_DEP_STEP_TABLE, vol index 0\r\n03-13 04:28:38.104 720-4235/? D/ACDB-LOADER: ACDB -> GET_AFE_TOPOLOGY_ID for adcd_id 15, Topology Id 112fc\r\n                                             \r\n                                             [ 03-13 04:28:38.104   720: 4235 D/         ]\r\n                                             Failed to fetch the lookup information of the device 0000000F \r\n03-13 04:28:38.104 720-4235/? D/ACDB-LOADER: Error: ACDB AFE returned = -19\r\n03-13 04:28:38.104 720-4235/? D/audio_hw_primary: enable_audio_route: usecase(1) apply and update mixer path: low-latency-playback speaker\r\n03-13 04:28:38.104 720-4235/? D/audio_route: Apply path: low-latency-playback speaker\r\n03-13 04:28:38.106 2163-2170/? E/ANDR-PERF-RESOURCEQS: Failed to apply optimization [2, 0]\r\n03-13 04:28:38.106 735-735/? D/QCOM\u00a0PowerHAL: LAUNCH HINT: ON\r\n03-13 04:28:38.108 735-735/? D/QCOM\u00a0PowerHAL: Activity launch hint handled\r\n03-13 04:28:38.112 2191-2788/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-13 04:28:38.119 1117-1567/? I/ActivityManager: Start proc 7226:com.example.android.tflitecamerademo/u0a129 for activity com.example.android.tflitecamerademo/.CameraActivity\r\n03-13 04:28:38.135 720-4235/? D/audio_hw_primary: out_write: retry previous failed cal level set\r\n03-13 04:28:38.156 7226-7240/? D/libEGL: loaded /vendor/lib64/egl/libEGL_adreno.so\r\n03-13 04:28:38.164 7226-7240/? D/libEGL: loaded /vendor/lib64/egl/libGLESv1_CM_adreno.so\r\n03-13 04:28:38.167 7226-7226/? W/linker: /data/app/com.example.android.tflitecamerademo-uITthh9AR9wFVxI5JDkgPQ==/lib/arm64/libtensorflowlite_jni.so: is missing DT_SONAME will use basename as a replacement: \"libtensorflowlite_jni.so\"\r\n03-13 04:28:38.170 7226-7226/? D/TfLiteCameraDemo: Created a Tensorflow Lite Image Classifier.\r\n03-13 04:28:38.175 7226-7240/? D/libEGL: loaded /vendor/lib64/egl/libGLESv2_adreno.so\r\n03-13 04:28:38.176 7226-7243/? D/OpenGLRenderer: HWUI GL Pipeline\r\n03-13 04:28:38.188 7226-7243/? I/Adreno: QUALCOMM build                   : 594927b, I916dfac403\r\n                                         Build Date                       : 10/11/17\r\n                                         OpenGL ES Shader Compiler Version: EV031.21.02.00\r\n                                         Local Branch                     : mybranch28618966\r\n                                         Remote Branch                    : quic/gfx-adreno.lnx.6.4.9-rel\r\n                                         Remote Branch                    : NONE\r\n                                         Reconstruct Branch               : NOTHING\r\n03-13 04:28:38.191 7226-7243/? I/Adreno: PFP: 0x005ff087, ME: 0x005ff063\r\n03-13 04:28:38.193 7226-7243/? I/zygote64: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasWideColorDisplay retrieved: 1\r\n03-13 04:28:38.193 7226-7243/? I/OpenGLRenderer: Initialized EGL, version 1.4\r\n03-13 04:28:38.193 7226-7243/? D/OpenGLRenderer: Swap behavior 2\r\n03-13 04:28:38.212 2446-2446/? I/MicroDetector: Keeping mic open: false\r\n03-13 04:28:38.212 2446-6181/? I/DeviceStateChecker: DeviceStateChecker cancelled\r\n03-13 04:28:38.212 2446-6216/? I/AudioController: internalShutdown\r\n03-13 04:28:38.212 2446-6216/? I/MicrophoneInputStream: mic_close com.google.android.apps.gsa.speech.audio.af@9889b3b\r\n03-13 04:28:38.212 2446-4234/? I/MicroRecognitionRunner: Stopping hotword detection.\r\n03-13 04:28:38.243 720-1274/? D/audio_hw_primary: disable_audio_route: usecase(9) reset and update mixer path: audio-record\r\n03-13 04:28:38.243 720-1274/? D/audio_hw_primary: disable_snd_device: snd_device(75: voice-rec-mic)\r\n03-13 04:28:38.245 720-1274/? D/sound_trigger_platform: platform_stdev_check_and_update_concurrency: concurrency active 0, tx 0, rx 0, concurrency session_allowed 1\r\n03-13 04:28:38.247 2446-6713/? I/MicroRecognitionRunner: Detection finished\r\n03-13 04:28:38.286 7226-7226/? I/CameraManagerGlobal: Connecting to camera service\r\n03-13 04:28:38.292 815-815/? I/CameraService: CameraService::connect call (PID -1 \"com.example.android.tflitecamerademo\", camera ID 0) for HAL version default and Camera API version 2\r\n03-13 04:28:38.292 815-815/? I/Camera2ClientBase: Camera 0: Opened. Client: com.example.android.tflitecamerademo (PID 7226, UID 10129)\r\n03-13 04:28:38.292 815-815/? I/CameraDeviceClient: CameraDeviceClient 0: Opened\r\n03-13 04:28:38.293 815-815/? I/CameraService: onTorchStatusChangedLocked: Torch status changed for cameraId=0, newStatus=0\r\n03-13 04:28:38.293 722-2109/? I/QCamera: <HAL><INFO> cameraDeviceOpen: 407: Open camera id 0 API version 768\r\n03-13 04:28:38.295 722-2109/? I/QCamera: <HAL><INFO> QCamera3HardwareInterface: 592: AV timer enabled: 0\r\n03-13 04:28:38.296 722-2109/? I/QCamera: <HAL><INFO> openCamera: 902: [KPI Perf]: E PROFILE_OPEN_CAMERA camera id 0\r\n03-13 04:28:38.296 722-2109/? D/EaselManagerClientImpl: resume: Resuming Easel.\r\n03-13 04:28:38.296 722-2109/? D/EaselControlClient: resume\r\n03-13 04:28:38.296 722-2109/? D/EaselControlClient: switchState: Switch from state 1 to state 2\r\n03-13 04:28:38.296 722-2109/? I/EaselManagerClientImpl: [PROFILE_TIMER] <Resume Easel> took 0.138125 ms.\r\n03-13 04:28:38.296 722-7246/? D/EaselControlClient: easelConnThread: Waiting for active state\r\n03-13 04:28:38.296 815-815/? I/CameraProviderManager: Camera device device@3.3/legacy/0 torch status is now NOT_AVAILABLE\r\n03-13 04:28:38.296 815-815/? I/CameraService: onTorchStatusChangedLocked: Torch status changed for cameraId=0, newStatus=0\r\n03-13 04:28:38.301 722-1959/? I/EaselThermalMonitor: (Low) bcm15602_tz: 29.74, back_therm: 27.00\r\n03-13 04:28:38.302 722-2109/? D/QCamera: Debug log file is not enabled\r\n03-13 04:28:38.303 722-2109/? I/mm-camera: <MCT   >< INFO> 118: mct_controller_new: Creating new mct_controller with session-id 4\r\n03-13 04:28:38.303 722-7251/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E sensor\r\n03-13 04:28:38.303 722-7251/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module sensor\r\n03-13 04:28:38.303 722-7252/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E iface\r\n03-13 04:28:38.303 722-7252/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module iface\r\n03-13 04:28:38.303 722-7254/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E isp\r\n03-13 04:28:38.303 722-7254/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module isp\r\n03-13 04:28:38.303 722-7254/? I/mm-camera: <ISP   >< INFO> 201: isp_module_start_session: session id 4 \r\n                                           \r\n                                           [ 03-13 04:28:38.303   722: 7251 I/         ]\r\n                                           ois_open: E\r\n03-13 04:28:38.303 722-7255/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E stats\r\n03-13 04:28:38.303 722-7255/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module stats\r\n03-13 04:28:38.303 722-7252/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module iface start_session rc = 1\r\n03-13 04:28:38.303 722-7252/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 1, success = 1\r\n03-13 04:28:38.303 722-7252/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X iface\r\n03-13 04:28:38.304 722-7257/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E pproc\r\n03-13 04:28:38.304 722-7257/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module pproc\r\n03-13 04:28:38.304 722-7258/? I/mm-camera: <MCT   >< INFO> 5080: mct_pipeline_start_session_thread: E imglib\r\n03-13 04:28:38.304 722-7258/? I/mm-camera: <MCT   >< INFO> 5087: mct_pipeline_start_session_thread: Calling start_session on Module imglib\r\n03-13 04:28:38.305 722-7258/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module imglib start_session rc = 1\r\n03-13 04:28:38.305 722-7258/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 2, success = 2\r\n03-13 04:28:38.305 722-7258/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X imglib\r\n03-13 04:28:38.305 722-7257/? D/eglc2d: EglC2DLoadProgram 0\r\n03-13 04:28:38.305 722-7257/? E/eglc2d: Homography warp program has been set\r\n03-13 04:28:38.305 722-7257/? D/eglc2d: EglC2DLoadProgram 1\r\n03-13 04:28:38.305 722-7257/? E/eglc2d: Grid warp program has been set\r\n03-13 04:28:38.305 722-7257/? D/eglc2d: EglC2DLoadProgram 2\r\n03-13 04:28:38.305 722-7257/? E/eglc2d: Grid split warp program has been set\r\n03-13 04:28:38.306 722-7257/? I/goog_llv: module_goog_llv_session_start:299 4\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod Reset\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: enable tripod:1\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod mode, average threshold: 0.004000\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod mode, variance threshold: 0.001000\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod mode, adaptive step: 0.001000\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod mode, deque size: 100\r\n03-13 04:28:38.306 722-7257/? I/GoogGyro: tripod mode, damping duration: 5.000000\r\n03-13 04:28:38.306 722-7257/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module pproc start_session rc = 1\r\n03-13 04:28:38.306 722-7257/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 3, success = 3\r\n03-13 04:28:38.306 722-7257/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X pproc\r\n03-13 04:28:38.306 722-7254/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module isp start_session rc = 1\r\n03-13 04:28:38.306 722-7254/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 4, success = 4\r\n03-13 04:28:38.306 722-7254/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X isp\r\n                                           \r\n                                           [ 03-13 04:28:38.307   722: 7251 I/         ]\r\n                                           ois_open: X\r\n03-13 04:28:38.307 722-7255/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module stats start_session rc = 1\r\n03-13 04:28:38.307 722-7255/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 5, success = 5\r\n03-13 04:28:38.307 722-7255/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X stats\r\n                                           \r\n                                           [ 03-13 04:28:38.311   722: 7251 I/         ]\r\n                                           [CAMQMI]sensor_set_formatted_cal_data: module_vendor = 1 \r\n03-13 04:28:38.311 722-7253/? I/mm-camera: <SENSOR>< INFO> 92: module_sensor_offload_init_config: E\r\n03-13 04:28:38.311 722-7251/? I/mm-camera: <MCT   >< INFO> 5090: mct_pipeline_start_session_thread: Module sensor start_session rc = 1\r\n03-13 04:28:38.311 722-7251/? I/mm-camera: <MCT   >< INFO> 5098: mct_pipeline_start_session_thread: started_num = 6, success = 6\r\n03-13 04:28:38.311 722-7251/? I/mm-camera: <MCT   >< INFO> 5105: mct_pipeline_start_session_thread: X sensor\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <MCT   >< INFO> 5001: mct_pipeline_start_stream_internal: Adding session stream streamid= 0xf for session=4\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <MCT   >< INFO> 5049: mct_pipeline_start_stream_internal: Linking session stream for session 4\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <MCT   >< INFO> 518: mct_stream_start_link: Start linking Session-stream 0x4000f\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <ISP   >< INFO> 840: isp_port_check_caps_reserve: port 0xf29f9440 ide 4000f type 10 dim 0 0\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 593: pproc_port_create_stream_topology: Stream type: 10 Has video stream: 0 4k: 0 EIS3: 0\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 596: pproc_port_create_stream_topology: Stream type: 10 nr_mode: 0\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 727: pproc_port_create_stream_topology: goog_llv preview: 0 video: 0 before EIS: 0\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 450: pproc_port_add_modules_to_stream: in identity 4000f stream 10 int_link = 0xf2764000\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods tmod and goog_eis for identity 4000f\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods goog_eis and goog_llv for identity 4000f\r\n03-13 04:28:38.314 722-2109/? I/goog_llv: module_goog_llv_client_created:222\r\n03-13 04:28:38.314 722-2109/? I/goog_llv: module_goog_llv_client_created:248 point session data 3 to client data\r\n03-13 04:28:38.314 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods goog_llv and ppeiscore for identity 4000f\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods ppeiscore and c2d for identity 4000f\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <C2D   >< INFO> 1630: c2d_module_notify_add_stream: width 0, height 0, stride 0, scanline 0, is_type 0\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods c2d and cpp for identity 4000f\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <CPP   >< INFO> 3442: cpp_module_util_update_dim: frame_len 0\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <CPP   >< INFO> 2201: cpp_module_notify_add_stream: :stream 10, width 0, height 0, stride 0,scanline 0, framelen 0\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <CPP   >< INFO> 2353: cpp_module_notify_add_stream: : stream 10, fmt 1, asf_mode 0, sharpness_level 0.000000,asf mask 0, denoise 0, denoise_mask 0, dsdn mask 0,dsdn enable 0, tnr mask 0, tnr enable 0, ds_mask 0, luma dsdn 0\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <PPROC >< INFO> 462: pproc_port_add_modules_to_stream: :LINK linking mods cpp and ezt for identity 4000f\r\n03-13 04:28:38.315 722-2109/? E/mm-camera: <STATS ><ERROR> 3028: stats_port_check_caps_reserve: Invalid Port capability type!\r\n03-13 04:28:38.315 722-2109/? I/chatty: uid=1047(cameraserver) HwBinder:722_2 identical 3 lines\r\n03-13 04:28:38.315 722-2109/? E/mm-camera: <STATS ><ERROR> 3028: stats_port_check_caps_reserve: Invalid Port capability type!\r\n03-13 04:28:38.315 722-2109/? I/mm-camera: <MCT   >< INFO> 5058: mct_pipeline_start_stream_internal: Session stream linked successfully session 4\r\n03-13 04:28:38.316 722-2109/? I/QCamera: <HAL><INFO> openCamera: 961: [KPI Perf]: X PROFILE_OPEN_CAMERA camera id 0, rc: 0\r\n03-13 04:28:38.316 722-2109/? I/QCamera: <HAL><INFO> initialize: 1181: E :mCameraId = 0 mState = 1\r\n03-13 04:28:38.316 722-2109/? I/QCamera: <HAL><INFO> initialize: 1214: X\r\n03-13 04:28:38.319 815-815/? W/CameraDeviceClient: createSurfaceFromGbp: Camera 0 with consumer usage flag: 256: Forcing asynchronous mode for stream\r\n03-13 04:28:38.320 815-815/? W/CameraDeviceClient: createSurfaceFromGbp: Camera 0: Overriding format 0x1 to IMPLEMENTATION_DEFINED\r\n03-13 04:28:38.320 722-2109/? D/QCamera3HWI: disableHdrPlusModeLocked: HDR+ mode disabled\r\n03-13 04:28:38.320 722-2109/? I/QCamera: <HAL><INFO> configureStreamsPerfLocked: 1988: stream[0] type = 0, format = 34, width = 1440, height = 1080, rotation = 0, usage = 0x100\r\n03-13 04:28:38.320 722-7249/? I/mm-camera: <MCT   >< INFO> 4035: mct_pipeline_process_set: command=800000a\r\n03-13 04:28:38.321 722-7249/? I/mm-camera: <MCT   >< INFO> 4035: mct_pipeline_process_set: command=8000018\r\n03-13 04:28:38.321 722-7249/? I/mm-camera: <MCT   >< INFO> 618: mct_stream_start_link: Link Metadata stream 0x40001: do nothing\r\n03-13 04:28:38.321 722-7249/? I/mm-camera: <MCT   >< INFO> 4139: mct_pipeline_process_set: Linking successful for stream 0x40001 stream type=7\r\n03-13 04:28:38.321 722-7249/? I/mm-camera: <MCT   >< INFO> 4035: mct_pipeline_process_set: command=8000004\r\n03-13 04:28:38.322 815-815/? D/Camera3-Device: Set real time priority for request queue thread (tid 7276)\r\n03-13 04:28:38.333 1117-1142/? I/ActivityManager: Displayed com.example.android.tflitecamerademo/.CameraActivity: +220ms\r\n03-13 04:28:38.334 7226-7242/? D/TfLiteCameraDemo: Timecost to put values into ByteBuffer: 4\r\n03-13 04:28:38.339 722-7253/? I/mm-camera: <SENSOR>< INFO> 151: module_sensor_offload_init_config: SENSOR_INIT returned\r\n03-13 04:28:38.339 722-7253/? I/mm-camera: <SENSOR>< INFO> 197: module_sensor_offload_init_config: EEPROM set up\r\n03-13 04:28:38.340 722-7253/? I/mm-camera: <SENSOR>< INFO> 208: module_sensor_offload_init_config: FLASH set up\r\n03-13 04:28:38.342 7226-7226/? W/IPCThreadState: Calling IPCThreadState::self() during shutdown is dangerous, expect a crash.\r\n03-13 04:28:38.342 7226-7226/? A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x130 in tid 7226 (flitecamerademo), pid 7226 (flitecamerademo)\r\n03-13 04:28:38.348 1117-1236/? W/InputDispatcher: channel '4e6c6f3 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)' ~ Consumer closed input channel or an error occurred.  events=0x9\r\n03-13 04:28:38.348 1117-1236/? E/InputDispatcher: channel '4e6c6f3 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)' ~ Channel is unrecoverably broken and will be disposed!\r\n03-13 04:28:38.348 1117-2452/? I/ActivityManager: Process com.example.android.tflitecamerademo (pid 7226) has died: fore TOP \r\n03-13 04:28:38.349 1117-1137/? W/zygote64: kill(-7226, 9) failed: No such process\r\n03-13 04:28:38.349 1117-1137/? I/zygote64: Successfully killed process cgroup uid 10129 pid 7226 in 0ms\r\n03-13 04:28:38.349 1117-1593/? I/WindowManager: WIN DEATH: Window{4e6c6f3 u0 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}\r\n03-13 04:28:38.349 1117-1593/? W/InputDispatcher: Attempted to unregister already unregistered input channel '4e6c6f3 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity (server)'\r\n03-13 04:28:38.349 1117-2452/? W/ActivityManager: Force removing ActivityRecord{63e0d14 u0 com.example.android.tflitecamerademo/.CameraActivity t31}: app died, no saved state\r\n03-13 04:28:38.349 701-701/? I/Zygote: Process 7226 exited cleanly (1)\r\n03-13 04:28:38.355 722-7253/? I/mm-camera: <SENSOR>< INFO> 228: module_sensor_offload_init_config: Actuator set up\r\n03-13 04:28:38.355 722-7253/? I/mm-camera: <SENSOR>< INFO> 269: module_sensor_offload_init_config: Success\r\n03-13 04:28:38.358 815-815/? I/Camera3-Device: disconnect: E\r\n03-13 04:28:38.358 722-2109/? I/QCamera: <HAL><INFO> close_camera_device: 13704: [KPI Perf]: E camera id 0\r\n03-13 04:28:38.358 735-735/? E/QCOM\u00a0PowerHAL: Invalid hint ID: 2560\r\n03-13 04:28:38.358 735-735/? D/QCOM\u00a0PowerHAL: Video Encode hint stop\r\n03-13 04:28:38.358 722-2109/? E/QCamera: <HAL><ERROR> stop: 1472: Attempt to stop inactive channel\r\n03-13 04:28:38.358 722-2109/? E/QCamera: <HAL><ERROR> stop: 263: Attempt to stop inactive channel\r\n03-13 04:28:38.358 722-2109/? E/QCamera: <HAL><ERROR> stop: 263: Attempt to stop inactive channel\r\n03-13 04:28:38.358 722-7249/? I/mm-camera: <MCT   >< INFO> 4035: mct_pipeline_process_set: command=800000b\r\n03-13 04:28:38.358 722-7249/? I/mm-camera: <MCT   >< INFO> 4296: mct_pipeline_process_set: Issuing DEL_STREAM on stream 0x40001 and stream type=7\r\n03-13 04:28:38.358 722-7249/? I/mm-camera: <MCT   >< INFO> 4312: mct_pipeline_process_set: Stream 0x40001 and stream type=7, successfully deleted\r\n03-13 04:28:38.358 722-2109/? I/QCamera: <HAL><INFO> closeCamera: 1100: [KPI Perf]: E PROFILE_CLOSE_CAMERA camera id 0\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 327: mct_controller_destroy: Initiating destroy sequence for session = 4\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 345: mct_controller_destroy: serv_thread closed\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 360: mct_controller_destroy: bus_handler thread closed\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 5158: mct_pipeline_stop_session: Initiating stop_session on session 4\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 4035: mct_pipeline_process_set: command=800000b\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 4296: mct_pipeline_process_set: Issuing DEL_STREAM on stream 0x4000f and stream type=10\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <IFACE >< INFO> 686: iface_unreserve_sink_port: stream_id f mode 0 \r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <ISP   >< INFO> 929: isp_port_check_caps_unreserve: ide 4000f port 0xf29f9440\r\n03-13 04:28:38.359 722-2109/? I/goog_llv: module_goog_llv_client_destroy:263\r\n03-13 04:28:38.359 722-2109/? I/mm-camera: <MCT   >< INFO> 4312: mct_pipeline_process_set: Stream 0x4000f and stream type=10, successfully deleted\r\n03-13 04:28:38.359 722-7284/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: sensor - E\r\n                                           \r\n                                           [ 03-13 04:28:38.359   722: 7284 I/         ]\r\n                                           ois_close: E\r\n03-13 04:28:38.359 722-7285/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: iface - E\r\n03-13 04:28:38.360 722-7286/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: isp - E\r\n03-13 04:28:38.360 722-7286/? I/mm-camera: <ISP   >< INFO> 505: isp_module_stop_session: session id 4\r\n03-13 04:28:38.360 722-7285/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: iface - X\r\n03-13 04:28:38.360 722-7287/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: stats - E\r\n03-13 04:28:38.360 722-7286/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: isp - X\r\n03-13 04:28:38.360 722-7288/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: pproc - E\r\n03-13 04:28:38.360 722-7289/? I/mm-camera: <MCT   >< INFO> 4892: mct_pipeline_stop_session_thread: Stop module name: imglib - E\r\n03-13 04:28:38.360 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 5\r\n03-13 04:28:38.360 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 4\r\n                                           \r\n                                           [ 03-13 04:28:38.361   722: 7284 I/         ]\r\n                                           ois_close: X\r\n03-13 04:28:38.361 722-7289/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: imglib - X\r\n03-13 04:28:38.361 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 3\r\n03-13 04:28:38.361 722-7288/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: pproc - X\r\n03-13 04:28:38.361 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 2\r\n03-13 04:28:38.362 722-7287/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: stats - X\r\n03-13 04:28:38.362 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 1\r\n03-13 04:28:38.375 722-7284/? I/mm-camera: <MCT   >< INFO> 4900: mct_pipeline_stop_session_thread: Stop module name: sensor - X\r\n03-13 04:28:38.375 722-2109/? I/mm-camera: <MCT   >< INFO> 5180: mct_pipeline_stop_session: Modules left: 0\r\n03-13 04:28:38.375 722-2109/? I/mm-camera: <MCT   >< INFO> 5193: mct_pipeline_stop_session: Stopped session 4 successfully\r\n03-13 04:28:38.375 722-2109/? I/mm-camera: <MCT   >< INFO> 5489: mct_pipeline_destroy: E: session:4\r\n03-13 04:28:38.375 722-2109/? I/mm-camera: <MCT   >< INFO> 5567: mct_pipeline_destroy: X: Pipeline destroyed successfully session =4\r\n03-13 04:28:38.375 722-2109/? I/mm-camera: <MCT   >< INFO> 431: mct_controller_destroy: X Successfully closed mct_controller session 4\r\n03-13 04:28:38.376 815-815/? I/CameraProviderManager: Camera device device@3.3/legacy/0 torch status is now AVAILABLE_OFF\r\n03-13 04:28:38.376 815-815/? I/CameraService: onTorchStatusChangedLocked: Torch status changed for cameraId=0, newStatus=1\r\n03-13 04:28:38.377 722-2109/? I/QCamera: <HAL><INFO> closeCamera: 1142: [KPI Perf]: X PROFILE_CLOSE_CAMERA camera id 0, rc: 0\r\n03-13 04:28:38.377 722-2109/? D/EaselManagerClientImpl: suspendLocked: Suspending Easel.\r\n03-13 04:28:38.377 722-2109/? D/EaselControlClient: suspend\r\n03-13 04:28:38.377 722-2109/? D/EaselControlClient: switchState: Switch from state 2 to state 1\r\n03-13 04:28:38.377 722-2109/? V/EaselControlClient: clearActivatePending\r\n03-13 04:28:38.377 722-2109/? V/EaselTimer: stop\r\n03-13 04:28:38.383 1117-2311/? D/WindowManager: relayoutVisibleWindow: Window{667fb76 u0 com.google.android.apps.nexuslauncher/com.google.android.apps.nexuslauncher.NexusLauncherActivity EXITING} mAnimatingExit=true, mRemoveOnExit=false, mDestroying=false\r\n03-13 04:28:38.383 1117-1142/? W/ActivityManager: setHasOverlayUi called on unknown pid: 7226\r\n03-13 04:28:38.396 2191-2788/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-13 04:28:38.406 735-735/? D/QCOM\u00a0PowerHAL: LAUNCH HINT: OFF\r\n03-13 04:28:38.407 2446-2446/? I/MicroDetectionWorker: #updateMicroDetector [detectionMode: [mDetectionMode: [1]]]\r\n03-13 04:28:38.407 2446-2446/? I/MicroDetectionWorker: #startMicroDetector [speakerMode: 0]\r\n03-13 04:28:38.408 722-7267/? I/mm-camera: <STATS_AIS >< INFO> 739: sensor_native_thread_handler: camera session close, exit the thread; free obj\r\n03-13 04:28:38.410 2446-2446/? I/MicroDetectionWorker: onReady\r\n03-13 04:28:38.410 2446-6176/? I/MicroRecognitionRunner: Starting detection.\r\n03-13 04:28:38.410 2446-6216/? I/MicrophoneInputStream: mic_starting com.google.android.apps.gsa.speech.audio.af@53e7f65\r\n03-13 04:28:38.412 720-1111/? W/DeviceHAL: Device 0xf4034000 open_input_stream: Invalid argument\r\n03-13 04:28:38.413 814-7291/? I/AudioFlinger: AudioFlinger's thread 0xf279d780 tid=7291 ready to run\r\n03-13 04:28:38.417 2446-6216/? I/MicrophoneInputStream: mic_started com.google.android.apps.gsa.speech.audio.af@53e7f65\r\n03-13 04:28:38.418 2163-2170/? E/ANDR-PERF-RESOURCEQS: Failed to apply optimization [2, 0]\r\n03-13 04:28:38.419 720-7292/? D/sound_trigger_platform: platform_stdev_check_and_update_concurrency: concurrency active 0, tx 1, rx 0, concurrency session_allowed 0\r\n03-13 04:28:38.419 720-7292/? D/audio_hw_primary: enable_snd_device: snd_device(75: voice-rec-mic)\r\n03-13 04:28:38.419 720-7292/? D/audio_route: Apply path: voice-rec-mic\r\n03-13 04:28:38.423 720-7292/? D/ACDB-LOADER: ACDB -> send_audio_cal, acdb_id = 41, path = 1, app id = 0x11132, sample rate = 48000\r\n03-13 04:28:38.423 720-7292/? D/ACDB-LOADER: ACDB -> ACDB_CMD_GET_AUDPROC_GAIN_DEP_STEP_TABLE, vol index 0\r\n                                             \r\n                                             [ 03-13 04:28:38.423   720: 7292 D/         ]\r\n                                             Failed to fetch the lookup information of the device 00000029 \r\n03-13 04:28:38.423 720-7292/? E/ACDB-LOADER: Error: ACDB AudProc vol returned = -19\r\n03-13 04:28:38.423 720-7292/? D/ACDB-LOADER: ACDB -> GET_AFE_TOPOLOGY_ID for adcd_id 41, Topology Id 112fb\r\n                                             \r\n                                             [ 03-13 04:28:38.423   720: 7292 D/         ]\r\n                                             Failed to fetch the lookup information of the device 00000029 \r\n03-13 04:28:38.423 720-7292/? D/ACDB-LOADER: Error: ACDB AFE returned = -19\r\n03-13 04:28:38.423 720-7292/? D/audio_hw_primary: enable_audio_route: usecase(9) apply and update mixer path: audio-record\r\n03-13 04:28:38.423 720-7292/? D/audio_route: Apply path: audio-record\r\n03-13 04:28:38.447 2446-2456/? E/ReloadingLock: Finalizing LOCKED Token[shortcuts 2018-03-13 04:28:30.345]\r\n03-13 04:28:38.491 2446-2446/? I/MicroDetectionWorker: onReady\r\n03-13 04:28:38.660 1117-4296/? I/OpenGLRenderer: Initialized EGL, version 1.4\r\n03-13 04:28:38.660 1117-4296/? D/OpenGLRenderer: Swap behavior 2\r\n03-13 04:28:38.675 722-7246/? I/EaselControlClient: easelConnThread: Opening easel_conn\r\n03-13 04:28:38.675 722-7246/? I/EaselControlClient: easelConnThread: waiting for handshake\r\n03-13 04:28:38.747 722-7246/? I/EaselControlClient: easelConnThread: handshake done\r\n03-13 04:28:38.747 722-7246/? E/EaselControlClient: captureBootTrace: Boot trace = [a01]\r\n03-13 04:28:38.747 722-7246/? V/EaselControlClient: easelConnThread: check isActivatePending\r\n03-13 04:28:38.748 722-7246/? D/EaselControlClient: easelConnThread: sending deactivate command\r\n03-13 04:28:38.774 722-2109/? I/EaselManagerClientImpl: [PROFILE_TIMER] <Suspend Easel> took 397.350494 ms.\r\n03-13 04:28:38.775 722-2109/? I/QCamera: <HAL><INFO> close_camera_device: 13706: [KPI Perf]: X\r\n03-13 04:28:38.775 815-815/? W/Camera3-OutputStream: disconnectLocked: While disconnecting stream 0 from native window, the native window died from under us\r\n03-13 04:28:38.775 815-815/? I/Camera3-Device: disconnect: X\r\n03-13 04:28:38.775 815-815/? I/Camera3-Device: disconnect: E\r\n03-13 04:28:38.776 815-815/? I/CameraService: disconnect: Disconnected client for camera 0 for PID 7226\r\n03-13 04:28:38.776 815-815/? I/Camera2ClientBase: Closed Camera 0. Client was: com.example.android.tflitecamerademo (PID 7226, UID 10129)\r\n03-13 04:28:38.776 815-815/? E/CameraService: binderDied: Java client's binder died, removing it from the list of active clients\r\n03-13 04:28:38.918 2315-2498/? W/OpenGLRenderer: Incorrectly called buildLayer on View: ShortcutAndWidgetContainer, destroying layer...\r\n03-13 04:28:41.327 720-1111/? D/audio_hw_primary: disable_audio_route: usecase(1) reset and update mixer path: low-latency-playback speaker\r\n03-13 04:28:41.329 720-1111/? D/audio_hw_primary: disable_snd_device: snd_device(2: speaker)\r\n03-13 04:28:52.202 1117-1275/? D/WificondControl: Scan result ready event\r\n03-13 04:28:52.253 1117-1261/? D/WificondScannerImpl: Filtering out 19 scan results.\r\n03-13 04:28:52.260 1117-1255/? W/WifiConfigManager: Looking up network with invalid networkId -1\r\n03-13 04:28:52.273 1117-1255/? W/WifiConfigManager: Looking up network with invalid networkId -1\r\n03-13 04:28:53.112 756-797/? I/CHRE: @ 3221.245: [AR_CHRE] still: 100\r\n03-13 04:28:56.314 756-797/? I/CHRE: @ 3224.448: [AR_CHRE] still: 100\r\n03-13 04:28:59.518 756-797/? I/CHRE: @ 3227.651: [AR_CHRE] still: 100\r\n03-13 04:28:59.896 1456-1489/? I/QcrilOemhookMsgTunnel: [0]processOemHookIndication length=21\r\n03-13 04:28:59.896 1456-1456/? D/QcrilMsgTunnelIfaceManager: handleMessage what = 0\r\n03-13 04:28:59.906 1379-1449/? V/QMI_OEMHOOK: Thread=ModemService received { when=0 what=0 obj=android.os.AsyncResult@36b26c3 target=com.qualcomm.qcrilhook.QmiOemHook }\r\n03-13 04:28:59.906 1379-1449/? V/QMI_OEMHOOK: QMI_OEM_HOOK_UNSOL received\r\n03-13 04:28:59.906 1379-1449/? D/QMI_OEMHOOK: QMI_OEM_HOOK_UNSOL received phoneId: 0\r\n03-13 04:28:59.906 1379-1449/? V/QMI_OEMHOOK: receive responseData = ef0308000100000003 message=null responseType= IS_UNSOL\r\n03-13 04:28:59.907 1379-1449/? V/QMI_OEMHOOK: receive respByteBuf after ByteBuffer.wrap(payload) = ef0308000100000003\r\n03-13 04:28:59.907 1379-1449/? V/QMI_OEMHOOK: receive respByteBuf = java.nio.HeapByteBuffer[pos=0 lim=9 cap=9]\r\n03-13 04:28:59.907 1379-1449/? E/QMI_OEMHOOK: requestId NOT in QMI OemHook range, No further processing\r\n03-13 04:29:02.721 756-797/? I/CHRE: @ 3230.855: [AR_CHRE] still: 100\r\n```\r\n\r\n", "P.S Without call to setUseNNAPI(true) sample crash also on Android 8.1", "Another log . I created activity without camera . passing frame from assets.\r\n\r\n```\r\n03-17 16:52:40.343 5284-5310/? E/ReloadingLock: Finalizing LOCKED Token[shortcuts 2018-03-17 16:51:55.915]\r\n03-17 16:52:45.329 5284-12571/? I/EventLogSendingHelper: Sending log events.\r\n03-17 16:52:47.094 12545-12545/? I/MemoryIntArray: created from parcel MemoryIntArray@243249334 mMemoryAddr=543454302208 mFd=43\r\n03-17 16:52:47.097 761-4939/? D/audio_hw_primary: enable_snd_device: snd_device(2: speaker)\r\n03-17 16:52:47.097 761-4939/? D/audio_route: Apply path: speaker\r\n03-17 16:52:47.098 761-4939/? D/ACDB-LOADER: ACDB -> send_audio_cal, acdb_id = 15, path = 0, app id = 0x11130, sample rate = 48000\r\n03-17 16:52:47.098 761-4939/? D/ACDB-LOADER: ACDB -> ACDB_CMD_GET_AUDPROC_GAIN_DEP_STEP_TABLE, vol index 0\r\n03-17 16:52:47.099 761-4939/? D/ACDB-LOADER: ACDB -> GET_AFE_TOPOLOGY_ID for adcd_id 15, Topology Id 112fc\r\n                                             \r\n                                             [ 03-17 16:52:47.099   761: 4939 D/         ]\r\n                                             Failed to fetch the lookup information of the device 0000000F \r\n03-17 16:52:47.099 761-4939/? D/ACDB-LOADER: Error: ACDB AFE returned = -19\r\n03-17 16:52:47.099 761-4939/? D/audio_hw_primary: enable_audio_route: usecase(1) apply and update mixer path: low-latency-playback speaker\r\n03-17 16:52:47.099 761-4939/? D/audio_route: Apply path: low-latency-playback speaker\r\n03-17 16:52:47.103 821-821/? D/android.hardware.power@1.2-service.wahoo-libperfmgr: AUDIO STREAMING ON\r\n03-17 16:52:47.104 12545-12545/? D/TfLiteCameraDemo: Created a Tensorflow Lite Image Classifier.\r\n03-17 16:52:47.111 12545-12545/? D/TfLiteCameraDemo: Timecost to put values into ByteBuffer: 4\r\n03-17 16:52:47.127 1192-4006/? W/InputDispatcher: channel 'a917b4d com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.TestLite (server)' ~ Consumer closed input channel or an error occurred.  events=0x9\r\n03-17 16:52:47.128 1192-4006/? E/InputDispatcher: channel 'a917b4d com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.TestLite (server)' ~ Channel is unrecoverably broken and will be disposed!\r\n03-17 16:52:47.128 1192-5238/? I/WindowManager: WIN DEATH: Window{a917b4d u0 com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.TestLite}\r\n03-17 16:52:47.128 1192-5238/? W/InputDispatcher: Attempted to unregister already unregistered input channel 'a917b4d com.example.android.tflitecamerademo/com.example.android.tflitecamerademo.TestLite (server)'\r\n03-17 16:52:47.128 1192-1203/? I/ActivityManager: Process com.example.android.tflitecamerademo (pid 12545) has died: fore TOP \r\n03-17 16:52:47.128 1192-1223/? W/libprocessgroup: kill(-12545, 9) failed: No such process\r\n03-17 16:52:47.128 1192-1223/? I/libprocessgroup: Successfully killed process cgroup uid 10136 pid 12545 in 0ms\r\n03-17 16:52:47.129 1192-1203/? W/ActivityManager: Force removing ActivityRecord{52cc38f u0 com.example.android.tflitecamerademo/.TestLite t16}: app died, no saved state\r\n03-17 16:52:47.129 742-742/? I/Zygote: Process 12545 exited cleanly (1)\r\n03-17 16:52:47.137 761-4939/? D/audio_hw_primary: out_write: retry previous failed cal level set\r\n03-17 16:52:47.138 821-821/? D/android.hardware.power@1.2-service.wahoo-libperfmgr: AUDIO STREAMING OFF\r\n03-17 16:52:47.145 1192-1240/? W/ActivityManager: setHasOverlayUi called on unknown pid: 12545\r\n03-17 16:52:47.159 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.164 600-600/? D/SurfaceFlinger: duplicate layer name: changing com.google.android.apps.nexuslauncher/com.google.android.apps.nexuslauncher.NexusLauncherActivity to com.google.android.apps.nexuslauncher/com.google.android.apps.nexuslauncher.NexusLauncherActivity#1\r\n03-17 16:52:47.181 4441-4441/? I/WallpaperService: engine resumed\r\n03-17 16:52:47.188 863-896/? D/CHRE: @ 100126.609: +: id 10, otherClientPresent 1, mode 3\r\n03-17 16:52:47.189 863-896/? D/CHRE: @ 100126.609: [ImuCal] Dynamic sensor configuration: high-performance.\r\n03-17 16:52:47.190 863-896/? D/CHRE: @ 100126.609: sensorType 9 allowed 1: mergedMode 3, otherClientPresent 1\r\n03-17 16:52:47.190 863-896/? D/CHRE: @ 100126.609: sensorType 12 allowed 1: mergedMode 3, otherClientPresent 1\r\n03-17 16:52:47.191 863-896/? D/CHRE: @ 100126.617: sensorType 14 allowed 0: mergedMode 3, otherClientPresent 0\r\n03-17 16:52:47.209 5284-5284/? W/SessionLifecycleManager: Handover failed. Creating new session controller.\r\n03-17 16:52:47.213 5284-5284/? I/OptInState: There is a new client and it does not support opt-in. Dropping request.\r\n03-17 16:52:47.228 5284-12293/? W/LocationOracle: No location history returned by ContextManager\r\n03-17 16:52:47.232 5284-5284/? I/MicroDetectionWorker: #updateMicroDetector [detectionMode: [mDetectionMode: [1]]]\r\n03-17 16:52:47.233 5284-5284/? I/MicroDetectionWorker: #startMicroDetector [speakerMode: 0]\r\n03-17 16:52:47.237 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.238 5284-12293/? I/MicroRecognitionRunner: Starting detection.\r\n03-17 16:52:47.238 5284-12317/? I/MicrophoneInputStream: mic_starting com.google.android.apps.gsa.speech.audio.af@b0d47b1\r\n03-17 16:52:47.241 761-761/? W/DeviceHAL: Device 0xf1244000 open_input_stream: Invalid argument\r\n03-17 16:52:47.241 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.242 871-12574/? I/AudioFlinger: AudioFlinger's thread 0xede24a80 tid=12574 ready to run\r\n03-17 16:52:47.245 5284-5284/? I/MicroDetectionWorker: onReady\r\n03-17 16:52:47.249 871-4028/? I/SoundTriggerHwService::Module: onCallbackEvent no clients\r\n03-17 16:52:47.249 5284-12317/? I/MicrophoneInputStream: mic_started com.google.android.apps.gsa.speech.audio.af@b0d47b1\r\n03-17 16:52:47.250 761-12575/? D/sound_trigger_platform: platform_stdev_check_and_update_concurrency: concurrency active 0, tx 1, rx 0, concurrency session_allowed 0\r\n03-17 16:52:47.250 761-12575/? D/audio_hw_primary: enable_snd_device: snd_device(75: voice-rec-mic)\r\n03-17 16:52:47.250 761-12575/? D/audio_route: Apply path: voice-rec-mic\r\n03-17 16:52:47.250 821-821/? D/android.hardware.power@1.2-service.wahoo-libperfmgr: AUDIO STREAMING ON\r\n03-17 16:52:47.253 761-12575/? D/ACDB-LOADER: ACDB -> send_audio_cal, acdb_id = 41, path = 1, app id = 0x11132, sample rate = 48000\r\n03-17 16:52:47.253 761-12575/? D/ACDB-LOADER: ACDB -> ACDB_CMD_GET_AUDPROC_GAIN_DEP_STEP_TABLE, vol index 0\r\n                                              \r\n                                              [ 03-17 16:52:47.253   761:12575 D/         ]\r\n                                              Failed to fetch the lookup information of the device 00000029 \r\n03-17 16:52:47.253 761-12575/? E/ACDB-LOADER: Error: ACDB AudProc vol returned = -19\r\n03-17 16:52:47.253 761-12575/? D/ACDB-LOADER: ACDB -> GET_AFE_TOPOLOGY_ID for adcd_id 41, Topology Id 112fb\r\n                                              \r\n                                              [ 03-17 16:52:47.253   761:12575 D/         ]\r\n                                              Failed to fetch the lookup information of the device 00000029 \r\n03-17 16:52:47.253 761-12575/? D/ACDB-LOADER: Error: ACDB AFE returned = -19\r\n03-17 16:52:47.253 761-12575/? D/audio_hw_primary: enable_audio_route: usecase(9) apply and update mixer path: audio-record\r\n03-17 16:52:47.253 761-12575/? D/audio_route: Apply path: audio-record\r\n03-17 16:52:47.265 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.265 1192-1203/? I/WifiService: acquireWifiLock uid=10037 lockMode=2\r\n03-17 16:52:47.268 5167-12388/? I/Places: ?: Couldn't find platform key file.\r\n03-17 16:52:47.271 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.275 1192-1203/? I/WifiService: releaseWifiLock uid=10037\r\n03-17 16:52:47.283 8925-8955/? W/PlayCommon: [77] PlayEventLogger.getAuthToken: No account for auth token provided\r\n03-17 16:52:47.285 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.286 5167-7917/? I/Places: ?: PlacesBleScanner start() with priority 2\r\n03-17 16:52:47.286 5167-7917/? I/PlaceInferenceEngine: [anon] Changed inference mode: 1\r\n03-17 16:52:47.286 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.288 8925-8955/? E/PlayCommon: [77] PlayEventLogger.uploadLog: Failed to connect to server: java.net.UnknownHostException: Unable to resolve host \"play.googleapis.com\": No address associated with hostname\r\n03-17 16:52:47.290 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.296 5167-5757/? I/chatty: uid=10037(com.google.android.gms) FlpThread identical 2 lines\r\n03-17 16:52:47.303 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.305 1192-11972/? I/WifiService: acquireWifiLock uid=10037 lockMode=2\r\n03-17 16:52:47.308 821-821/? D/android.hardware.power@1.2-service.wahoo-libperfmgr: AUDIO STREAMING OFF\r\n03-17 16:52:47.311 1192-5238/? I/WifiService: releaseWifiLock uid=10037\r\n03-17 16:52:47.320 5167-11613/? I/Places: ?: Couldn't find platform key file.\r\n03-17 16:52:47.325 5167-7917/? I/Places: ?: PlacesBleScanner start() with priority 2\r\n03-17 16:52:47.326 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.326 5284-5284/? I/MicroDetectionWorker: onReady\r\n03-17 16:52:47.330 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.333 5167-7917/? I/Places: ?: PlacesBleScanner start() with priority 2\r\n03-17 16:52:47.333 5167-7917/? I/PlaceInferenceEngine: [anon] Changed inference mode: 1\r\n03-17 16:52:47.334 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.336 5167-5757/? I/chatty: uid=10037(com.google.android.gms) FlpThread identical 1 line\r\n03-17 16:52:47.338 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.340 1192-11972/? I/WifiService: acquireWifiLock uid=10037 lockMode=2\r\n03-17 16:52:47.341 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.344 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.346 1192-5238/? I/WifiService: releaseWifiLock uid=10037\r\n03-17 16:52:47.347 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.352 5167-5757/? I/chatty: uid=10037(com.google.android.gms) FlpThread identical 2 lines\r\n03-17 16:52:47.353 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.354 1192-11972/? I/WifiService: acquireWifiLock uid=10037 lockMode=2\r\n03-17 16:52:47.360 5167-5757/? W/GCoreFlp: No location to return for getLastLocation()\r\n03-17 16:52:47.361 1192-5238/? I/WifiService: releaseWifiLock uid=10037\r\n03-17 16:52:47.363 1192-5238/? I/WifiService: acquireWifiLock uid=10037 lockMode=2\r\n03-17 16:52:47.366 1192-5238/? I/WifiService: releaseWifiLock uid=10037\r\n03-17 16:52:48.422 863-896/? I/CHRE: @ 100127.844: [AR_CHRE] IDLE => ON\r\n03-17 16:52:50.322 761-761/? D/audio_hw_primary: disable_audio_route: usecase(1) reset and update mixer path: low-latency-playback speaker\r\n03-17 16:52:50.331 761-761/? D/audio_hw_primary: disable_snd_device: snd_device(2: speaker)\r\n03-17 16:52:51.132 1192-1192/? V/SettingsProvider: Notifying for 0: content://settings/system/screen_brightness\r\n03-17 16:52:52.700 863-896/? D/CHRE: @ 100132.117: [NanoSensorCal] UPDATE OTC-GYRO Offset [rad/sec] | Temp [Celsius]: 0.000386, 0.000656, 0.004380 | 28.52\r\n03-17 16:52:52.700 863-896/? D/CHRE: @ 100132.117: [NanoSensorCal] UPDATE OTC-GYRO Temp Sensitivity [rad/sec/C]: 1000000.000000, 1000000.000000, 1000000.000000\r\n03-17 16:52:52.700 863-896/? D/CHRE: @ 100132.117: [NanoSensorCal] UPDATE OTC-GYRO Temp Intercept [rad/sec]: 0.000000, 0.000000, 0.000000\r\n```\r\n", "any update? crash too when setUseNNAPI(true) run detection not classification.", "for me it start working when I remove exit(1) from nnapi_delegate.cpp on an unsupported layer."]}, {"number": 17505, "title": "Modify a typo for the  HandwrittenConv of conv_ops_test.", "body": "A typo is fixed for the 'HandwrittenConv' test in the conv_ops_test.cc.\r\n\r\nFor the following input and filter, the output[4][4] should be evaluated by \" (1*7)+(4*8)+(7*0)+(2*11)+(5*12)+(8*0)+(3*0)+(6*0)+(9*0) \", not  \"(1*7)+(4*11)+(7*0)+(2*8)+(5*12)+(8*0)+(3*0)+(6*0)+(9*0)=121\r\n\". \r\n    // The image matrix is:\r\n    // |  1 |  2 |  3 |  4 |\r\n    // |  5 |  6 |  7 |  8 |\r\n    // |  9 | 10 | 11 | 12 |\r\n\r\n    // The filter matrix is:\r\n    // | 1 | 4 | 7 |\r\n    // | 2 | 5 | 8 |\r\n    // | 3 | 6 | 9 |\r\n\r\n", "comments": []}, {"number": 17504, "title": "Unable to build tensorflow 1.5 with mpi on AWS ec2 machine", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos (4.9.77-31.58.amzn1.x86_64)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.5\r\n- **Python version**: 3.5.5\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GRID K520, 4GB (aws g2 instance)\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nI have installed mpi using the following steps -\r\n```\r\nwget https://www.open-mpi.org/software/ompi/v3.0/downloads/openmpi-3.0.0.tar.gz\r\n\r\ntar -xvf openmpi-3.0.0.tar.gz\r\n\r\ncd openmpi-3.0.0\r\n\r\n./configure --disable-mpi-fortran --with-cuda=/usr/local/cuda-9.0/ --prefix /usr/local/\r\n\r\nmake\r\n\r\nmake install\r\n```\r\n\r\nAfter this, I am trying to build tensorflow from source - \r\n\r\n```\r\nexport JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk.x86_64/\r\n\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=1\r\nexport TF_NEED_S3=1\r\nexport TF_ENABLE_XLA=0\r\nexport TF_NEED_GDR=0\r\nexport TF_NEED_VERBS=0\r\nexport TF_NEED_OPENCL_SYCL=0\r\nexport TF_NEED_COMPUTECPP=0\r\nexport TF_NEED_CUDA=1\r\nexport TF_CUDNN_VERSION=7.0\r\nexport CUDA_TOOLKIT_PATH=/usr/local/cuda\r\nexport CUDNN_INSTALL_PATH=/usr/local/cuda\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,5.2\r\nexport TF_CUDA_CLANG=0\r\nexport TF_NEED_MPI=0\r\nexport MPI_HOME=/usr/local/mpi\r\nexport PATH=$PATH:/usr/local/mpi/include\r\n\r\n```\r\nI have included mpi home directory in PATH and LD_LIBRARY_PATH\r\n\r\nWhile running\r\n\r\n ```bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package ```\r\n\r\nI get the following error  -\r\n\r\n```\r\nERROR: /home/ec2-user/tensorflow/tensorflow/contrib/mpi/BUILD:48:1: C++ compilation of rule '//tensorflow/contrib/mpi:mpi_utils' failed (Exit 1)\r\nIn file included from ./tensorflow/contrib/mpi/mpi_utils.h:27:0,\r\n                 from tensorflow/contrib/mpi/mpi_utils.cc:18:\r\n./third_party/mpi/mpi.h:2673:41: fatal error: openmpi/ompi/mpi/cxx/mpicxx.h: No such file or directory\r\n #include \"openmpi/ompi/mpi/cxx/mpicxx.h\"\r\n                                         ^\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n```\r\n\r\nWhat am I missing here? Any help will be appreciated.", "comments": ["I think it is related to MPI C++ binding. PR #17414 is pending which might fix the issue.", "Closed through #17414"]}, {"number": 17503, "title": "set default values of args in print_tensors_in_checkpoint_file", "body": "set default values of args in function `print_tensors_in_checkpoint_file` to avoid backwards compatibility problems.   \r\n\r\ndetail in issue #17498", "comments": ["I have added a new commit, please review it, thx. @frankchn "]}, {"number": 17501, "title": "convert result mismatch between command-line  and python_api", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary: by \"pip3 install --upgrade tensorflow-gpu\"\r\n- **TensorFlow version (use command below)**:\r\ntensorflow-gpu (1.6.0)\r\n- **Python version**: \r\nPython 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: CUDA 9.0 cuDNN 7\r\n- **GPU model and memory**: Null\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n I save my pre-trained model into .pb file according to [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) and [optimize_for_inference.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)\r\nOnce I covert to .tflite by command-line with following cmd: \r\n> ~/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n--input_file=RD_Net_TransConv_fuse.pb \\\r\n--output_file=./RD_Net_TransConv_fuse.tflite \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--inference_type=FLOAT \\\r\n--input_data_types =FLOAT \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays=seq_4/Conv/BiasAdd \\\r\n--input_shapes=1,240,320,3 \\\r\n--logtostderr\r\n\r\nthe error show that \"TransposeConv\" is not supported : \r\n> 2018-03-07 15:07:49.317477: F tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TransposeConv.\r\n\r\nIf I use [python_api](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/python_api.md) to convert my tensor into .tflite, it work fine without any error msg.\r\nBut the .tflite can not be used in android....  it will crash when  I want to getOutputName or run\r\n\r\nerror msg in android:\r\n> Can't get Output Names, model error:Invalid handle to Interpreter.\r\n\r\ndoes tensorflow lite support \"TransposeConv\"? I don't see any information in [Compatibility Guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md)\r\n\r\nAny suggestion? Thanks~~~\r\n\r\n\r\n\r\n\r\n", "comments": ["1. If you don't see an operator in the README, it is likely not supported. TransposeConv is not yet supported. \r\n\r\n2. Could you please give the python call that you use to generate the model, so we can see if it is effectively the same. The interfaces are a little different (Python trying to be more intuitive), but its possible you are using them slightly differently.\r\n", "Hi @aselle \r\nI write a sub function to convert as following:\r\n```\r\ndef Save_lite(sess, input_tensors, net, pbName=\"TFLite_converted_model\", clear_devices = True):\r\n    print(\"----\")\r\n    print(net.name)\r\n    print(\"----\")\r\n    \r\n    output_node_names = net.name\r\n    output_node_names = output_node_names.split(\":\")\r\n    output_node_names = output_node_names[0]\r\n    input_graph_def = net.graph.as_graph_def()\r\n    \r\n    # Remove all the explicit device specifications for this node. This helps to\r\n    # make the graph more portable.\r\n    if clear_devices:\r\n        for node in input_graph_def.node:\r\n            node.device = \"\"\r\n    \r\n    \r\n    frozen_graphdef = graph_util.convert_variables_to_constants( \r\n        sess,\r\n        input_graph_def,\r\n        output_node_names.split(\",\")\r\n    )\r\n\r\n    output_graph_def = graph_util.remove_training_nodes(frozen_graphdef)\r\n    out_tensors = [net]\r\n    tflite_model = tf.contrib.lite.toco_convert(output_graph_def, [input_tensors], out_tensors)\r\n    open(pbName+\".tflite\", \"wb\").write(tflite_model)\r\n```", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Is there a timing for add \"TransposeConv\" to the TFLITE compatible operations? I have the same problem exporting my model to tflite.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "FYI, it seems that TransposeConv has been implemented: https://github.com/tensorflow/tensorflow/commit/07bb8c1bbc93fe1162d247511c89c136273ddd07#diff-ad4161550933630c3c68540dc7b03aeb", "True! Thanks I will check that again as soon as I can.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 17500, "title": "'colocate_gradients_with_ops' colocate with unused ops", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:v1.6.0-0-gd2e24b6039 1.6.0 \r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**: P100\r\n- **Exact command to reproduce**: here\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport time\r\n\r\nG = tf.get_default_graph()\r\n\r\n@tf.RegisterGradient(\"SummaryGrad\")\r\ndef summarize_grad_fn(op, x):\r\n    my_name_is_not_x = tf.Print(x, [x])\r\n    return x\r\n\r\ndef layer(x):\r\n    l = tf.layers.conv2d(x, 64, 3, data_format='channels_first')\r\n    l = tf.nn.relu(l)\r\n    with G.gradient_override_map({\"Identity\": \"SummaryGrad\"}):\r\n        return tf.identity(l)\r\n\r\nimg = tf.random_normal((64,3, 224,224))\r\nl = layer(img)\r\nl = layer(l)\r\nl = layer(l)\r\n\r\nloss = tf.reduce_mean(l)\r\n\r\nopt = tf.train.GradientDescentOptimizer(0.1)\r\ngrads = opt.compute_gradients(loss, colocate_gradients_with_ops=True)\r\nop = opt.apply_gradients(grads)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for k in range(20):\r\n        start = time.time()\r\n        sess.run(op)\r\n        if k > 2:\r\n            print(time.time() - start)\r\n```\r\n\r\nIf I use `colocate_gradients_with_ops=False`, or remove the `tf.Print` line, the above code runs with expected speed.\r\nOtherwise, it places the gradients on CPUs, resulting in 2x slow down, and a lot of H2D/D2H copy shown in profiling.\r\nPerhaps this colocate option can be made smarter.\r\n\r\nIn this case, Print op depends on some gradients, but no other gradients depend on the Print op. i.e., the Print op __does not appear on the subgraph which `grads` depends on__. Therefore the colocation seems totally unnecessary here.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "I see. I think it is working as expected, though perhaps not the behavior you would want.\r\n\r\nI assume that you distilled the repro from a more interesting use case, maybe you can tell us a bit more about the context? I'm assuming that there is something that prevents you from using `with tf.device`?\r\n\r\n@agarwal-ashish WDYT?", "The colocation constraint happens inside `tf.gradients` so I could not change this behavior from outside as long as I enable this option. I enable the option because it sometimes makes things slightly faster and usually not slower.\r\n\r\nI may be wrong about what this option is meant to do, but I assume it's meant to make `grads = tf.gradients(..)` faster. But given that `grads` does not depend on the Print op, there is no reason to colocate with the Print op. \r\n\r\nNormally when `tf.gradients` is called, no unused ops like this one will be added so the behavior will always make sense, unless one uses `gradien_override_map`.\r\nMy use case is to occasionally run summaries or print ops on the gradients.", "colocate_gradients_with_ops is a very simple heuristic which simply tries to colocate the gradients with the original op, and may or may not be the best placement policy. Optimal placement is hard in general and has been an area of active research.\r\n\r\nIn this case, I'd suggest using tf.device or tf.colocate_with (setting it on the Identity or inside the gradient) and see if that helps.\r\n\r\nClosing this issue since the code is working as expected."]}, {"number": 17499, "title": "Problem with the tensorflow installation", "body": "I'm having problems installing the cpu-only version of tensorflow, for this I use pip3, my OS is w10, I tried it with python 3.6.4 and 3.5.2 and in no case did it work, here is the error that generates me, besides the response to the script whose answer I do not understand, tells me that I do not have the dll's and all those things, but I installed was the version of only CPU, are these files required? ah and yes, I installed it with administrator permissions both the python and the tensorflow. . .\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: Error en una rutina de inicializaci\u00f3n de biblioteca de v\u00ednculos din\u00e1micos (DLL).\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#5>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: Error en una rutina de inicializaci\u00f3n de biblioteca de v\u00ednculos din\u00e1micos (DLL).\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nERROR: Failed to import the TensorFlow module.\r\n\r\nWARNING! This script is no longer maintained! \r\n=============================================\r\nSince TensorFlow 1.4, the self-check has been integrated with TensorFlow itself,\r\nand any missing DLLs will be reported when you execute the `import tensorflow`\r\nstatement. The error messages printed below refer to TensorFlow 1.3 and earlier,\r\nand are inaccurate for later versions of TensorFlow.\r\n\r\n- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Download and install CUDA 8.0 from\r\n  this URL: https://developer.nvidia.com/cuda-toolkit\r\n\r\n- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that\r\n  this DLL be installed in a directory that is named in your %PATH%\r\n  environment variable. Typically it is installed in 'C:\\Windows\\System32'.\r\n  If it is not present, ensure that you have a CUDA-capable GPU with the\r\n  correct driver installed.\r\n\r\n- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Note that installing cuDNN is a\r\n  separate step from installing CUDA, and it is often found in a\r\n  different directory from the CUDA DLLs. You may install the\r\n  necessary DLL by downloading cuDNN 5.1 from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\n- Could not find cuDNN.\r\n", "comments": []}, {"number": 17498, "title": "the new parameter in `print_tensors_in_checkpoint_file` breaks old code", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.6.0-0-gd2e24b6039 1.6.0\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\n\r\nThe function `print_tensors_in_checkpoint_file` in `tensorflow/python/tools/inspect_checkpoint.py` is changed in [this commit](https://github.com/tensorflow/tensorflow/commit/2ba34173fad0d5b7d986baeb8171bdc6afdcd7bb#diff-fb7984719b22f01a7748ef847e9eb731), a new parameter `all_tensor_names` is added.\r\n\r\nThis change breaks the old code using this function, including the examples in the [Programmer's Guide](https://www.tensorflow.org/versions/master/programmers_guide/saved_model#inspect_variables_in_a_checkpoint).\r\n\r\nI believe an elegant solution is setting the default value of the new parameter `all_tensor_names` to `False`\r\n\r\n", "comments": ["I will create a pull request to solve this."]}, {"number": 17497, "title": "use tf.concat, get error about ExpandDims, Prod, Slice not supported when use toco to convert the model to .tflite format", "body": "detail is describe in:\r\nhttps://github.com/tensorflow/tensorflow/issues/17461", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "\r\n@aselle Looks TFLite related", "@tensorflowbutler \r\n\r\n**System information**\r\n\r\nHave I written custom code: yes, the model definition in the attach files: \r\n[models.zip](https://github.com/tensorflow/tensorflow/files/1791589/models.zip)\r\nOS Platform and Distribution (Linux Ubuntu 14.04):\r\nTensorFlow installed from (build from source):\r\nTensorFlow version (r1.5):\r\nBazel version(0.8.1)\r\nGPU model and memory: CPU only\r\n\r\n**Exact command to reproduce**\r\ni train the model with tf.slim, then freeze with the python script : \r\n[python-script.zip](https://github.com/tensorflow/tensorflow/files/1791587/python-script.zip)\r\nthen i got a pb file and converting it to the .tflite format:\r\n```\r\n./bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=../test.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=litev1.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=lite_v1/InputPlaceholder --output_arrays=lite_v1/Output --input_shapes=1,35,35,1\r\n```", "@andydavis1 \r\nyes, it is about the TFLite. but i do not know the problem is about toco tools or the definition of the original network.\r\nseems tf.concat is ok in other cases, i mean, when tf.concat appear in other position, the model converting is successful, but when i use tf.concat after slim.flatten, there is an error.", "I'll close this one. Will use #17461 to track."]}, {"number": 17496, "title": "Cherrypicks for 1.5", "body": "182804819 not found in github", "comments": ["@gunan any idea of the fix for presubmits?", "Could you also cherrypick 725d049caea2b75eae373760127ed9b55138f7dc", "@yifeif can I merge this PR, or is a fix coming soon?", "Re-triggering", "Looks like a flaky test?\r\n```\r\n[ RUN      ] FileBlockCacheTest.CoalesceConcurrentReads\r\ntensorflow/core/platform/cloud/file_block_cache_test.cc:464: Failure\r\nValue of: WaitForNotificationWithTimeout(&notification, 10000)\r\n  Actual: false\r\nExpected: true\r\nTimeout waiting for concurrent thread to start.\r\n[  FAILED  ] FileBlockCacheTest.CoalesceConcurrentReads (110 ms)\r\n```"]}, {"number": 17495, "title": "Updating version for 1.5.1 patch release.", "body": "", "comments": []}, {"number": 17494, "title": "TF1.6 MKL bug in concatenation op", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7\r\n- **TensorFlow installed from (source or binary)**: Binary (Intel MKL wheel) https://software.intel.com/en-us/articles/intel-optimized-tensorflow-wheel-now-available\r\n- **TensorFlow version (use command below)**: b'unknown' 1.6.0\r\n- **Python version**: 3.6 \r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\nU-Net model graph compiles but error during training from concatenation op.\r\nThe code is here: https://github.com/mas-dse-greina/unet/blob/master/train.py\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n== cat /etc/issue ===============================================\r\nLinux lancelot24 3.10.0-693.11.6.el7.x86_64 #1 SMP Thu Jan 4 01:06:37 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7 (Core)\"\r\nVERSION_ID=\"7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-16)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux lancelot24 3.10.0-693.11.6.el7.x86_64 #1 SMP Thu Jan 4 01:06:37 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.14.1)\r\nprotobuf (3.5.1)\r\ntensorflow (1.6.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.6.0\r\ntf.GIT_VERSION = v1.6.0-0-gd2e24b6039\r\ntf.COMPILER_VERSION = v1.6.0-0-gd2e24b6039\r\nSanity check: array([1], dtype=int32)\r\n/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./p.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nThis is a bug in the TensorFlow 1.6. I am using the Intel-supplied pip wheel for MKL optimization. I ran the same code with the TF1.4 MKL wheel and my code worked just fine. The error messages indicate that there is a problem with the concatenation operation. I am not seeing this error with the generic TensorFlow 1.6 (i.e. pip install tensorflow). I believe it is limited to the MKL op for concatenation.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nWARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\r\nTrain on 24800 samples, validate on 6200 samples\r\nEpoch 1/10\r\nTraceback (most recent call last):\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\r\n    return fn(*args)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\r\n    target_list, status, run_metadata)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:777\r\n\t [[Node: concatenate/concat = _MklConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transConv6/BiasAdd, conv4b/Relu, concatenate/concat/axis, DMT/_29, conv4b/Relu:1, DMT/_30)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 571, in <module>\r\n    settings.OUT_CHANNEL_NO, settings.MODEL_FN, settings.MODE, args)\r\n  File \"train.py\", line 510, in train_and_predict\r\n    callbacks=[model_checkpoint, tensorboard_checkpoint])\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 1793, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 1283, in _fit_loop\r\n    outs = f(ins_batch)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\", line 2663, in __call__\r\n    fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:777\r\n\t [[Node: concatenate/concat = _MklConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transConv6/BiasAdd, conv4b/Relu, concatenate/concat/axis, DMT/_29, conv4b/Relu:1, DMT/_30)]]\r\n\r\nCaused by op 'concatenate/concat', defined at:\r\n  File \"train.py\", line 571, in <module>\r\n    settings.OUT_CHANNEL_NO, settings.MODEL_FN, settings.MODE, args)\r\n  File \"train.py\", line 443, in train_and_predict\r\n    model = model5_MultiLayer(args, False, False, img_rows, img_cols, input_no, output_no, print_summary=True)\r\n  File \"train.py\", line 183, in model5_MultiLayer\r\n    kernel_size=(3, 3), strides=(2, 2), padding='same')(conv5), conv4], axis=concat_axis)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/merge.py\", line 665, in concatenate\r\n    return Concatenate(axis=axis, **kwargs)(inputs)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 258, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 696, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/merge.py\", line 174, in call\r\n    return self._merge_function(inputs)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/merge.py\", line 380, in _merge_function\r\n    return K.concatenate(inputs, axis=self.axis)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\", line 2083, in concatenate\r\n    return array_ops.concat([to_dense(x) for x in tensors], axis)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1175, in concat\r\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 625, in _concat_v2\r\n    \"ConcatV2\", values=values, axis=axis, name=name)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"/home/bduser/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nAbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not create a concat primitive descriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:777\r\n\t [[Node: concatenate/concat = _MklConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _kernel=\"MklOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transConv6/BiasAdd, conv4b/Relu, concatenate/concat/axis, DMT/_29, conv4b/Relu:1, DMT/_30)]]\r\n", "comments": ["Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Need to access \"data\" to reproduce the issue with \"train.py\". ", "Please see the new test benchmark script which shows the issue:\nhttps://github.com/NervanaSystems/topologies/tree/master/memory_benchmarking\n\nI created a test bench with random data that will show the same issue. Note\nthat I am using the Intel-built TensorFlow MKL wheel and only using CPU to\ntrain. The issue seems to be in the concatenation of step.\n\nJust run the command `python benchmark_model.py --num_datapoints=10 --D2\n--dim_length=128` and it should show the error in TF1.6 MKL.\n\nError:\n\n(tf) [user@node17 memory_benchmarking]$ python benchmark_model.py\n--num_datapoints=10 --D2 --dim_length=128\nUsing TensorFlow backend.\n\nArgs = Namespace(D2=True, blocktime=0, bz=1, dim_length=128, epochs=3,\ninterop_threads=2, intraop_threads=67, lr=0.001, mkl_verbose=False,\nnum_channels=1, num_datapoints=10, num_outputs=1, print_model=False,\nsingle_class_output=False, use_upsampling=False)\n2D U-Net Segmentation\n  0%|\n                                                                          |\n0/10 [00:00<?, ?it/s]Traceback (most recent call last):\n  File \"benchmark_model.py\", line 208, in <module>\n    options=run_options, run_metadata=run_metadata)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py\",\nline 905, in run\n    run_metadata_ptr)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py\",\nline 1137, in _run\n    feed_dict_tensor, options, run_metadata)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py\",\nline 1355, in _do_run\n    options, run_metadata)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.py\",\nline 1374, in _do_call\n    raise type(e)(node_def, op, message)\n*tensorflow.python.framework.errors_impl.AbortedError: Operation received\nan exception:Status: 3, message: could not create a concat primitive\ndescriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:777*\n* [[Node: concatenate_1/concat = _MklConcatV2[N=2, T=DT_FLOAT,\nTidx=DT_INT32, _kernel=\"MklOp\",\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transConv6/BiasAdd,\nconv4b/Relu, concatenate_1/concat/axis, DMT/_29, conv4b/Relu:1, DMT/_30)]]*\n\nCaused by op u'concatenate_1/concat', defined at:\n  File \"benchmark_model.py\", line 161, in <module>\n    print_summary=args.print_model, n_out=args.num_outputs)\n  File \"/home/user/topologies/memory_benchmarking/model.py\", line 177, in\nunet2D\n    kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(conv5), conv4],\naxis=concat_axis)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/keras/layers/merge.py\",\nline 627, in concatenate\n    return Concatenate(axis=axis, **kwargs)(inputs)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/keras/engine/topology.py\",\nline 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/keras/layers/merge.py\",\nline 347, in call\n    return K.concatenate(inputs, axis=self.axis)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\",\nline 1768, in concatenate\n    return tf.concat([to_dense(x) for x in tensors], axis)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\",\nline 1175, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\",\nline 625, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\",\nline 787, in _apply_op_helper\n    op_def=op_def)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\",\nline 3271, in create_op\n    op_def=op_def)\n  File\n\"/home/user/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\",\nline 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint:\ndisable=protected-access\n\nAbortedError (see above for traceback): Operation received an\nexception:Status: 3, message: could not create a concat primitive\ndescriptor, in file tensorflow/core/kernels/mkl_concat_op.cc:777\n*[[Node: concatenate_1/concat = _MklConcatV2[N=2, T=DT_FLOAT,\nTidx=DT_INT32, _kernel=\"MklOp\",\n_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transConv6/BiasAdd,\nconv4b/Relu, concatenate_1/concat/axis, DMT/_29, conv4b/Relu:1, DMT/_30)]]*\n\n\nThanks.\n-Tony\n\n\nOn Mon, Apr 2, 2018 at 9:53 AM, Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> Need to access \"data\" to reproduce the issue with \"train.py\".\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-377975784>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEuyEkeXVAmp32gD60zuld3gtLOfxks5tkld7gaJpZM4SflsQ>\n> .\n>\n", "Thank you Tony. I can reproduce the issue now.\r\n ", "Thank you!\n\n-Tony\n\n\nOn Mon, Apr 2, 2018 at 1:17 PM, Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> Thank you Tony. I can reproduce the issue now.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-378030747>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReElcbVa-SdowbPp6YtbrondU_2gQoks5tkodXgaJpZM4SflsQ>\n> .\n>\n", "Found the root cause and had the fix.  \r\n\r\nA new PR will be created once internal code review and validations are done. ", "Thanks!\n\n\n\nOn Tue, Apr 3, 2018, 2:04 PM Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> Found the root cause and had the fix.\n>\n> A new PR will be created once internal code review and validations are\n> done.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-378397807>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEmLxN60hflgF1ydcx34lyel7KYc8ks5tk-PHgaJpZM4SflsQ>\n> .\n>\n", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I still see the bug in 1.7 and the 1.8 rc1. Can you confirm that the fix has been merged into those? \r\n\r\nThanks.\r\n-Tony\r\n", "Hi Tony,\r\n\r\nIt is not merged yet, as we are handling other concat related issues (e.g. empty tensor with ndims=0 as input).\r\nI will let you when we are ready for public PR.\r\n\r\nThanks,\r\nGZ\r\n\r\nFrom: Tony Reina [mailto:notifications@github.com]\r\nSent: Wednesday, April 25, 2018 5:06 PM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Zhuang, Guozhong <guozhong.zhuang@intel.com>; Comment <comment@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] TF1.6 MKL bug in concatenation op (#17494)\r\n\r\n\r\nI still see the bug in 1.7 and the 1.8 rc1. Can you confirm that the fix has been merged into those?\r\n\r\nThanks.\r\n-Tony\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-384470692>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Ab3J27_tsrSaFTSR6FF_8XJqs6dOHEIbks5tsQ94gaJpZM4SflsQ>.\r\n", "Many thanks.\n\nI've also discovered on building from the latest source that data_format\ngives an error because one MKL op is trying to use \"NDCHW\" as the value. I\nassume that has been reported but wanted to let you know.\n\nThanks so much to the team for the great work.\n\n\n\nOn Thu, Apr 26, 2018, 9:37 AM Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> Hi Tony,\n>\n> It is not merged yet, as we are handling other concat related issues (e.g.\n> empty tensor with ndims=0 as input).\n> I will let you when we are ready for public PR.\n>\n> Thanks,\n> GZ\n>\n> From: Tony Reina [mailto:notifications@github.com]\n> Sent: Wednesday, April 25, 2018 5:06 PM\n> To: tensorflow/tensorflow <tensorflow@noreply.github.com>\n> Cc: Zhuang, Guozhong <guozhong.zhuang@intel.com>; Comment <\n> comment@noreply.github.com>\n> Subject: Re: [tensorflow/tensorflow] TF1.6 MKL bug in concatenation op\n> (#17494)\n>\n>\n> I still see the bug in 1.7 and the 1.8 rc1. Can you confirm that the fix\n> has been merged into those?\n>\n> Thanks.\n> -Tony\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub<\n> https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-384470692>,\n> or mute the thread<\n> https://github.com/notifications/unsubscribe-auth/Ab3J27_tsrSaFTSR6FF_8XJqs6dOHEIbks5tsQ94gaJpZM4SflsQ>.\n>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-384707014>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEtVDz_YNmI9WYg_iL1KnALNGvhx0ks5tsffHgaJpZM4SflsQ>\n> .\n>\n", "Hi gzmkl, I rolled back tensorflow version to 1.6 and still has the problem, the python version is 3.5. Thanks.", "There is no public PR yet. I have tested my private branch with tony's code\r\n    https://github.com/NervanaSystems/topologies/tree/master/memory_benchmarking\r\nThe issue should be fixed. Thank you patient for waiting. I will drive hard to make the fix merged to public branch", "Hi gztf, thanks for the reply. I rolled back to 1.5, looks like it can be fixed. ", "I have tried 1.6.0 and 1.7.0(GPU version, anaconda install), they all show MKL bug;\r\nwhile in 1.5.0, this bug disappear.", "Same Problem with tensorflow 1.6 and python 3.5", "public PR has been approved and merged to TF master branch. ", "It was merged yesterday (5/16). ", "Thanks GZ. So if I download and build TensorFlow from source, then this\nshould be included in the MKL?\n\nBest,\n-Tony\n\n\nOn Thu, May 17, 2018 at 1:24 PM, Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> It was merged yesterday (5/16).\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-389997723>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEpOR70zA068nqC7HRoKpm_hYQVX8ks5tzdxqgaJpZM4SflsQ>\n> .\n>\n", "Hi Tony,\r\nYes, the fix is already in public TF GitHub. Before submitting that PR, I had already validated with\r\nyour code. Please let me know the result once you try. \r\n-Guozhong", "Tony,\r\nAnother info to you: we are preparing another PR to migrate to the latest MKL-DNN (v0.14).\r\nThe new DNN improves concat op performance\r\n     1. old DNN concat only had jit implementation when concat dim is 'C\" (that is, \"Channel\" dimension)\r\n     2. new DNN concat has jit implementation for any concat dim\r\nSo hopefully you can see performance improvement once that PR is in.\r\n-GZ", "Nagging Assignee @tonywang1990: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The fix has been merged to public Tensorflow master branch. \r\nYou will need to switch TF 1.8", "All, I am still facing the same issue when I use the wheel from TF source code compile. I did 'git checkout r1.8' before the compile. Please help me. Thank you.", "Nagging Assignee @tonywang1990: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tonywang1990: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I am still facing the same, hence working on lower version of TF.", "Nagging Assignee @tonywang1990: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tonywang1990: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It's been fixed. Please close.\n\nThanks\n\nOn Tue, Aug 7, 2018, 12:04 PM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @tonywang1990 <https://github.com/tonywang1990>: It has\n> been 30 days with no activity and this issue has an assignee. Please update\n> the label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-411165564>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEia27jZOdXqlaoYx-0PB-lHa8gqzks5uOeTYgaJpZM4SflsQ>\n> .\n>\n", "Hi,\r\nWhat's the tensorflow version with this fix?\r\nThanks.", "1.9 and above\n\nOn Thu, Aug 30, 2018, 3:20 PM libinta <notifications@github.com> wrote:\n\n> Hi,\n> What's the tensorflow version with this fix?\n> Thanks.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-417484587>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEsIdTtcSDGqF7nFoQwQ06ABBg3ZRks5uWGUdgaJpZM4SflsQ>\n> .\n>\n", "I still see the issue on 1.10. can you share which commit fixed this issue?thanks", "I still got this error in tf 1.9 but somehow fixed with 1.10. You guys can give it a shot", "Any update on this issue? I did try MKLDNN 0.14, 0.15 and 0.16 with TF1.9 and 1.10 but both gives same erro.", "@mrsabhar \r\nMaybe you should create a new item, with procedure of how to reproduce the problem. \r\nTony has confirmed that his issue (with procedure) has been fixed. Thanks!", "Yes. That would be very helpful. Would you have a simple python script that\nshows the behavior?\n\nOne thing to try: TF with MKL-DNN is now the default in the Anaconda repo.\nSo try just 'conda install -c ananconda tensorflow'. And see if it works\n\n\nBest,\nTony\n\nOn Mon, Oct 1, 2018, 9:40 AM Guozhong Zhuang <notifications@github.com>\nwrote:\n\n> @mrsabhar <https://github.com/mrsabhar>\n> Maybe you should create a new item, with procedure of how to reproduce the\n> problem.\n> Tony has confirmed that his issue (with procedure) has been fixed. Thanks!\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17494#issuecomment-425973322>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVReEqZf4z5wNLxZS1nxjUAD7oro_pTCks5ugkVigaJpZM4SflsQ>\n> .\n>\n", "I am also seeing this issue, using tensorflow 1.11, intelpython35, running on Intel Xeon Phi KNL.\r\n\r\nI can reliably reproduce the error on the system I am using with the script here:\r\nhttps://gist.github.com/coreyjadams/35e89feb1fb191c2788792f6268448fc\r\n\r\nThis is using the tensorflow downloaded from intel here: https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide (I took the version matching python 3.5)\r\n\r\nI noticed, by the way, that the convolutions before the concat operation were necessary for this crash to happen.  Without the convolution ops, this script runs fine.\r\n\r\n", "The bug also occurs when trying to use https://github.com/lmb-freiburg/hand3d, with tensorflow 1.11 and python 3.6.6 (anaconda).\r\n\r\n@mas-dse-greina : \r\n> So try just 'conda install -c ananconda tensorflow'. And see if it works\r\n\r\nThe user anaconda does not seem to exist any longer, the command fails with 404\r\n\r\nUpdate: It works when installing tensorflow with pip instead of anaconda.", "+1 on this issue still being observed in tensorflow 1.11.0, usimg intel's mkl compatible tensorflow dstribution, running on ubuntu16 CPU-only machine\r\n\r\nUpdate: same results with anaconda distribution. I can confirm that my case also has convolution that precede the concat op", "I have opened a new issue (#23556 ) since I don't have the power to reopen this one, but I think there are still lingering problems regarding this concat op.", "This issue was fixed recently and merged into the master https://github.com/tensorflow/tensorflow/pull/22606  Please let us know if this fixes your problems.", "Hi there,\r\n\r\nFixed the origina issue but now crashes later (in a part of code that looks like using mkl concat):\r\n\r\n```\r\nAbortedError (see above for traceback): Operation received an exception:Status: 5, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:652\r\n\t [[Node: conv1/BiasAdd = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_1_0_0, conv1/kernel/read, conv1/bias/read, DMT/_0, DMT/_1, DMT/_2)]]\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\r\n    target_list, status, run_metadata)\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 5, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:652\r\n\t [[Node: conv1/BiasAdd = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_1_0_0, conv1/kernel/read, conv1/bias/read, DMT/_0, DMT/_1, DMT/_2)]]\r\n```", "ELvErDe,\r\n\r\nI verified the original issue has been addressed (with master build) with coreyjadams's test script.\r\nWould you please provide a new test script for the \"later crash\"? I will troubleshoot the problem.\r\n\r\nThanks!", "Hi,\r\n\r\nI'll try but it's being used in a platform using Keras so not so easy to extract a simple test pattern. The only thing I can confirm for sure is that TF 1.5 is working properly, any newer fails.", "I mentioned on the other issue as well, but I can confirm my test script works with the master build.", "[mkl_conv_ops_cc_mkl_bug.zip](https://github.com/tensorflow/tensorflow/files/2581462/mkl_conv_ops_cc_mkl_bug.zip)\r\n\r\nHello,\r\n\r\nThe error message is:\r\n```\r\n2018-11-14 16:42:55.167116: I tensorflow/core/common_runtime/process_util.cc:63] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2018-11-14 16:43:00.480740: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at mkl_conv_ops.cc:697 : Aborted: Operation received an exception:Status: 5, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:694\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 5, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:694\r\n\t [[Node: FeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/BatchNorm/FusedBatchNorm = _MklConv2DWithBias[T=DT_FLOAT, _kernel=\"MklOp\", data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d/depthwise, FeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights/read/_94__cf__97, FeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d_bn_offset, DMT/_61, DMT/_62, DMT/_63)]]\r\n```\r\n\r\nAttached ZIP file contain a few line script reproducing the error (i'll care itself downloading a model) and a test image for inference.\r\nRunning it with my MKL build fails, with a non MKL build it works fine.\r\n\r\nI'm actually thinking this is related to MKL-DNN version *at build time* because my  1.5.1 were build using 0.13 I guess and newer with 0.16. I'm pretty confident building new TF with old MKL-DNN will make it work....\r\n\r\nThanks for your help,\r\n\r\nAdam.", "@gzmkl ", "Thank you for providing the test script. I will look into the issue soon", "Hi,\r\nI test with your code with \r\n   1. latest Tensorflow -- build from Tensorflow master branch\r\n   2. MKL DNN v0.16\r\nand do not see the issue.\r\nPlease check the attached test results. \r\n[test_results.txt](https://github.com/tensorflow/tensorflow/files/2582193/test_results.txt)\r\n", "Hi,\r\n\r\nAny hope you can try with 1.8 ? I confirmed the issue with 1.6/1.7/1.8 and haven't checked yet newer", "I defined saw this issue before but I am not sure when this issue was fixed (no clue by \r\nbrowsing through pull request history). \r\n\r\nPlease try a newer Tensorflow version 1.11 or 1.12 (?).\r\nThanks!", "Sh*** I couldn't either and really hoped to be able to release a working 1.6 TF :/", "I am sorry that we do not have much choice here. \r\nTF 1.6 was release half a year ago and we normally provide fixes in newer releases. \r\nDo you have problem in upgrading TF (say, to 1.11)?\r\nThank you!", "Well, I will but each new version break something for us until I backport a couple of patches so I'd go easy with updates, step by step. I'm trying MKL downgrade at build time, I suspect TF may disable this broken operation using MKL lib if it is old enough when building. Also I'll build 1.9 but I'm sure the same issue will be there (among other maybe ;))", "The cause of the issue might not be due to a specific MKL DNN version. \r\nMost likely it was due to some bug when we was doing Tensorflow integration. ", "Confirmed !\r\n\r\nMy feeling was right, rebuilding with MKL 0.13 and the bug is gone. Runtime version of MKL does not matter but there is definitely something happening during build regarding MKL version....\r\n\r\nStill interrested in digging deeper ? ", "I still have the problem for tensorflow 1.12, installed with conda. How to fix it?", "@eLvErDe \r\nI did \"conda update conda\" and \"conda update mkl\". But I'm still getting the error. \r\nI'm using python 3.6, tensorflow 1.9\r\nPlease help", "This bug, or at least a very related bug, is still open in Tensorflow 1.14. The concatenate operation leads to the error \"operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\" for the mkl package (tensorflow=1.14.0=mkl_py37h45c423b_0 from anaconda). After installing the eigen package from anaconda (tensorflow=1.14.0=eigen_py37h195cb1b_0), the error does not appear. I have attached an example program where the error appears and the printed error message\r\n[bug_concatenate_mkl.zip](https://github.com/tensorflow/tensorflow/files/3390398/bug_concatenate_mkl.zip)\r\n. ", "Hey everyone, I'm facing the same issue in Tensorflow 1.14 with Python 3.6.9. I tried `conda update -n base -c defaults conda` and `conda update mkl`, as well as `conda update eigen`. I took your suggestion @ae137 and installed the following eigen packages: win-64/tensorflow-1.14.0-eigen_py37hcf3f253_0.tar.bz2 and win-64/tensorflow-1.14.0-eigen_py36hf4fd08c_0.tar.bz2. I placed in them in my Anaconda3/pkgs folder and restarted Anaconda but I'm still facing the same error.\r\n\r\n`AbortedError: Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\r\n\t [[{{node Adam/gradients_1/concatenate_2/concat_grad/Slice_2}}]] [Op:__inference_keras_scratch_graph_9124]`\r\n\r\nDid I mess up/miss a step? Any help is appreciated, thanks."]}, {"number": 17493, "title": "tensorflow macOS build failed", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nN/A\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nmacOS 10.13\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nbuild from source branch r1.6\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.6\r\n\r\n- **Python version**: \r\n3.6\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.11.0-homebrew\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nApple LLVM version 9.0.0 (clang-900.0.39.2)\r\n\r\n- **CUDA/cuDNN version**:\r\n9.1/7.0.5\r\n\r\n- **GPU model and memory**:\r\nTitan X Pascal\r\n\r\n- **Exact command to reproduce**:\r\n`bazel build --config=opt --config=cuda --config=mkl //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n\r\n### Describe the problem\r\nTrying to build from source, but failed with the error below\r\n\r\n### Source code / logs\r\n```\r\nINFO: From Compiling tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.cc:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/Half.h(508): error: explicit specialization of class \"std::__1::numeric_limits<Eigen::half>\" must precede its first use (\r\n(388): here)\r\n\r\n1 error detected in the compilation of \"/var/folders/4z/2frllwtj73b9vg25g4m9sxsc0000gn/T//tmpxft_00002f28_00000000-6_gru_ops_gpu.cu.cpp1.ii\".\r\nERROR: /Users/odin/local/tensorflow/tensorflow/contrib/rnn/BUILD:240:1: output 'tensorflow/contrib/rnn/_objs/python/ops/_gru_ops_gpu/tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.pic.o' was not created\r\nERROR: /Users/odin/local/tensorflow/tensorflow/contrib/rnn/BUILD:240:1: not all outputs were created or valid\r\n```\r\n", "comments": ["I have successfully build tensorflow-gpu for python 3.6 with compute capability 6.1 CUDNN 7 Cuda 9.1, you can download from following links (CC stands for compute capability):\r\n\r\n[tensorflow 1.6 gpu mac version without XLA and CC: 6.1](https://pan.baidu.com/s/1R-gmwTPitrmtwPsZPAPJiQ) \r\n\r\n[tensorflow 1.6 gpu mac version with XLA and CC: 3.5 5.2](https://pan.baidu.com/s/1mxAYvOV3UkCYT9XXk4keXg)\r\n\r\n[tensorflow 1.6 gpu mac version with XLA and CC: 6.1](https://pan.baidu.com/s/1wLug3Pvq0-bqR6Y0tiriDQ)\r\n\r\nMaybe in the Mac system when you call \r\n\r\nsess = tf.Session()\r\n\r\nYou will get CUDA_ERROR_OUT_OF_MEMORY  , but the code will still keep running. Just ignore it.\r\n\r\nAfter you install the latest Keras from the GitHub, you can switch to example directory and run:\r\n\r\npython mnist_cnn.py \r\n/Users/zhipingxu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nUsing TensorFlow backend.\r\nx_train shape: (60000, 28, 28, 1)\r\n60000 train samples\r\n10000 test samples\r\nTrain on 60000 samples, validate on 10000 samples\r\nEpoch 1/12\r\n2018-03-07 23:10:16.691546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] OS X does not support NUMA - returning NUMA node zero\r\n2018-03-07 23:10:16.691676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.39GiB\r\n2018-03-07 23:10:16.800598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:859] OS X does not support NUMA - returning NUMA node zero\r\n2018-03-07 23:10:16.800690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 1 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7845\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 8.00GiB freeMemory: 7.85GiB\r\n2018-03-07 23:10:16.800747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1227] Device peer to peer matrix\r\n2018-03-07 23:10:16.800776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1233] DMA: 0 1 \r\n2018-03-07 23:10:16.800781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   Y N \r\n2018-03-07 23:10:16.800785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 1:   N Y \r\n2018-03-07 23:10:16.800791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0, 1\r\n2018-03-07 23:10:17.289678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6169 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-03-07 23:10:17.380943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7588 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2018-03-07 23:10:17.381334: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 7.41G (7956931840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2018-03-07 23:10:17.381483: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 6.67G (7161238016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n60000/60000 [==============================] - 7s 125us/step - loss: 0.2544 - acc: 0.9206 - val_loss: 0.0579 - val_acc: 0.9815\r\nEpoch 2/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0881 - acc: 0.9740 - val_loss: 0.0408 - val_acc: 0.9866\r\nEpoch 3/12\r\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0675 - acc: 0.9799 - val_loss: 0.0369 - val_acc: 0.9883\r\nEpoch 4/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0543 - acc: 0.9835 - val_loss: 0.0299 - val_acc: 0.9894\r\nEpoch 5/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0478 - acc: 0.9857 - val_loss: 0.0310 - val_acc: 0.9888\r\nEpoch 6/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0423 - acc: 0.9871 - val_loss: 0.0269 - val_acc: 0.9907\r\nEpoch 7/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0370 - acc: 0.9885 - val_loss: 0.0294 - val_acc: 0.9907\r\nEpoch 8/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0347 - acc: 0.9892 - val_loss: 0.0265 - val_acc: 0.9920\r\nEpoch 9/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.0299 - val_acc: 0.9912\r\nEpoch 10/12\r\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0273 - val_acc: 0.9921\r\nEpoch 11/12\r\n60000/60000 [==============================] - 5s 77us/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0282 - val_acc: 0.9910\r\nEpoch 12/12\r\n60000/60000 [==============================] - 5s 78us/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.0258 - val_acc: 0.9918\r\nTest loss: 0.025763810957170064\r\nTest accuracy: 0.9918\r\n\r\nEverything looks fine!\r\n\r\n\r\n\r\n", "The workspace.bzl in tensorflow directory should be modified as\r\n\r\n `tf_http_archive(\r\n      name = \"com_google_protobuf\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n      ],\r\n      sha256 = \"846d907acf472ae233ec0882ef3a2d24edbbe834b80c305e867ac65a1f2c59e3\",\r\n      strip_prefix = \"protobuf-396336eb961b75f03b25824fe86cf6490fb75e3a\",\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_google_protobuf_cc\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/396336eb961b75f03b25824fe86cf6490fb75e3a.tar.gz\",\r\n      ],\r\n      sha256 = \"846d907acf472ae233ec0882ef3a2d24edbbe834b80c305e867ac65a1f2c59e3\",\r\n      strip_prefix = \"protobuf-396336eb961b75f03b25824fe86cf6490fb75e3a\",\r\n  )`\r\n\r\nand the depthwise_conv_op_gpu.cu.cc, split_lib_gpu.cu.cc,concat_lib_gpu_impl.cu.cc in the  core/kernels,you need change all the lines like:\r\n\r\n` extern __shared__ __align__(sizeof(T)) unsigned char smem[]; `\r\n\r\ninto \r\n\r\n` extern __shared__  unsigned char smem[];`\r\n\r\nby delete `__align__(sizeof(T))` . Then everything will be OK.\r\n\r\n\r\n\r\n\r\n ", "@bennix Thanks. I will give it a try", "@bennix \u63e1\u722a \u8c22\u8c22 \u767e\u5ea6\u76d8\u592a\u6162\u4e86\u5efa\u8bae\u6362\u4e00\u4e2a onedrive or googledrive\r\n\r\nWhich version of Xcode you use ?Thanks.\r\n8.3.3 or ?", "[Google Drive](https://drive.google.com/drive/folders/1L3VD3D3O4LIyrMcuy2_uW8N24uvUBMYb?usp=sharing)\r\nXcode 8.2.1 complied \r\n\r\n\r\n", "@bennix \u5144\u5f1f \u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u6211\u7406\u89e3\u9519\u4e86 protobuf \u5728workspace.bzl\u91cc\u9762\u7684\u8ddf\u4f60\u8d34\u51fa\u6765\u7684\u662f\u4e00\u6837\u7684 \u4f60\u96be\u9053\u662f\u7528\u4e86r1.5\u7684\u6765\u66ff\u6362\u4e86 r1.6\u7684bzl? \u6211\u7f16\u8bd1\u7684\u65f6\u5019\u4e00\u76f4\u662f\u5728protobuf\u51fa\u9519\u7684\u3002\u3002\u9ebb\u70e6\u4f60\u518d\u770b\u770b\u4f60\u7684workspace.bzl", "@lightingghost \r\n\r\nuse tensorflow r1.5 protobuf version, modify your workspace.bzl  line 353 to 384\r\n  \r\n  tf_http_archive(\r\n      name = \"protobuf_archive\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n      ],\r\n      sha256 = \"e178a25c52efcb6b05988bdbeace4c0d3f2d2fe5b46696d1d9898875c3803d6a\",\r\n      strip_prefix = \"protobuf-b04e5cba356212e4e8c66c61bbe0c3a20537c5b9\",\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_google_protobuf\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n      ],\r\n      sha256 = \"e178a25c52efcb6b05988bdbeace4c0d3f2d2fe5b46696d1d9898875c3803d6a\",\r\n      strip_prefix = \"protobuf-b04e5cba356212e4e8c66c61bbe0c3a20537c5b9\",\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_google_protobuf_cc\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n          \"https://github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5b9.tar.gz\",\r\n      ],\r\n      sha256 = \"e178a25c52efcb6b05988bdbeace4c0d3f2d2fe5b46696d1d9898875c3803d6a\",\r\n      strip_prefix = \"protobuf-b04e5cba356212e4e8c66c61bbe0c3a20537c5b9\",\r\n  )", "@yrwy Thanks. I have already done this patch before, it works for building tf without mkl support. However, the problem I came across is related to mkl support on macOS. So I believe it still worth investigation.", "@lightingghost \r\n`INFO: From Compiling tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.cc:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/Half.h(508): error: explicit specialization of class \"std::__1::numeric_limits<Eigen::half>\" must precede its first use (\r\n(388): here)`\r\n\r\nThis isue maybe xcode 9.2 bug. I compile tensorflow with xcode 9.2 fail too.\r\n\r\nhttps://stackoverflow.com/questions/46356153/xcode-9-falls-to-build-partial-template-specialization-in-c", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@bennix \u54e5\uff0c\u80fd\u6c42\u4e00\u4e2acc3.0\u7684\u4e48\u3002\u611f\u8c22\u554a\u3002\r\n\r\nIgnoring visible gpu device (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.", "\u697c\u4e0a\u7684\u7528\u4f4e\u7248\u672c\u5427\r\n\r\n3.0 \u4e0d\u518d\u88ab\u652f\u6301\u4e86 \u5b98\u65b9\u4e0d\u518d\u652f\u6301", "Nagging Assignee @jart: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@ebrevdo could you take a look at these Mac Clang build errors relating to contrib/rnn and Eigen?", "I'm having the same issue but with r1.5.1.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Issue persists on r1.6 and 1.7.1 with both XCode 7.2 and 9.2.", "GPU support in macos is community maintained. We are happy to review and accept fixes, but we wont be able to work on these fixes ourselves.", "Same issue here with TensorFlow 1.12 and Xcode 10.1.\r\n \r\nThat line of code in 1.12 a bit different now : \r\n`extern __shared__ __align__(8) unsigned char shared_memory[];\r\n`\r\nI replaced it with : \r\n`extern shared unsigned char shared_memory[]; \r\n`\r\nBut generating  error: explicit type is missing (\"int\" assumed).  \r\n\r\n", "Hi @lightingghost ,we are checking to see if you still help in this issue, Have you tried 2.5 version which is available on Mac M1 ? Feel free to create a new issue if the issue persists.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17493\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17493\">No</a>\n"]}, {"number": 17492, "title": "Branch 188075262", "body": "Small merge conflict in tensorflow/contrib/timeseries/python/timeseries/BUILD to disable a test for msan and on windows", "comments": []}, {"number": 17491, "title": "Feature/typo 2018 03 07", "body": "Fixed minor typos :) ", "comments": ["Could you resolve the merge conflicts?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Closing for now, but feel free to reopen or send a new request with the conflicts addressed. Thanks!"]}, {"number": 17490, "title": "Branch 188037439", "body": "", "comments": ["Closing, will send another later. "]}, {"number": 17489, "title": "MKL: Optmized Relu by in-place computations", "body": "  Using OpKernelContext::forward_input_or_allocate_output()", "comments": ["Looks good. Do you mean 'Optimize Relu by using in place computation?'", "@tatianashp: We have seen improved performance when do in-place computation. You could say incorporating in-place computation to the Relu with mkldnn."]}, {"number": 17488, "title": "Feature request: tf.contrib.Predictor - add an optional ConfigProto argument to the constructor", "body": "Have I written custom code: -\r\nOS Platform and Distribution: -\r\nTensorFlow installed from: -\r\nTensorFlow version: -\r\nBazel version: -\r\nCUDA/cuDNN version: -\r\nGPU model and memory: -\r\nExact command to reproduce: -\r\n\r\nThe `tf.contrib.Predictor` subclasses are useful to quickly run inferences, but at the moment it's impossible to configure the `tf.Session` instance used for inference, because it is created in `__init__` without the possibility to pass a `config` to it.\r\n\r\nMy suggestion is then to add the explicit argument `config` to `Predictor`'s subclasses' init functions and pass it to the Session constructor.\r\n\r\nNote that, technically, for the `{Contrib|Core}EstimatorPredictor` classes one could already have a `session_config` defined in `estimator.config.session_config`, so perhaps this could be the fallback value when using these classes.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "added the fields requested", "Nagging Assignee @tatianashp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@GPhilo Thank you for your suggestion. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!\r\n"]}, {"number": 17487, "title": "SparseTensor", "body": "Hi, i want to have a prediction with continuous and categorial features.\r\ni faced a problem with the last line with SparseTensor\r\n\r\ni used Tensorflow version : 1.5.0 installed with anaconda\r\nos : windows 7\r\nconda version : 4.4.10\r\nconda-build version : 3.0.27\r\npython version : 3.6.3.final.0\r\n \r\n\r\nthere is my code : \r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\n\r\nimport itertools\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nimport warnings\r\nfrom sklearn.ensemble import IsolationForest\r\nwarnings.filterwarnings('ignore')\r\n\r\n\r\n\r\n# categorial with continuous\r\ntrain = pd.read_csv('Dataset3.csv', delimiter=';')\r\ntrain.drop('Matricule',axis = 1, inplace = True)\r\ntrain_numerical = train.select_dtypes(exclude=['object'])\r\ntrain_numerical.fillna(0,inplace = True)\r\ntrain_categoric = train.select_dtypes(include=['object'])\r\ntrain_categoric.fillna('NONE',inplace = True)\r\ntrain = train_numerical.merge(train_categoric, left_index = True, right_index = True)\r\n\r\n\r\ntest = pd.read_csv('Dataset3_test.csv', delimiter=';')\r\nMatricule = test.Matricule\r\ntest.drop('Matricule',axis = 1, inplace = True)\r\ntest_numerical = test.select_dtypes(exclude=['object'])\r\ntest_numerical.fillna(0,inplace = True)\r\ntest_categoric = test.select_dtypes(include=['object'])\r\ntest_categoric.fillna('NONE',inplace = True)\r\ntest = test_numerical.merge(test_categoric, left_index = True, right_index = True)\r\n\r\n\r\nclf = IsolationForest( random_state = 42)\r\nclf.fit(train_numerical)\r\ny_noano = clf.predict(train_numerical)\r\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])\r\ny_noano[y_noano['Top'] == 1].index.values\r\n\r\ntrain_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain_numerical.reset_index(drop = True, inplace = True)\r\n\r\ntrain_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain_categoric.reset_index(drop = True, inplace = True)\r\n\r\ntrain = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\r\ntrain.reset_index(drop = True, inplace = True)\r\n\r\ncol_train = list(train_numerical.columns)\r\ncol_train_bis = list(train_numerical.columns)\r\n\r\ncol_train_cat = list(train_categoric.columns)\r\n\r\ncol_train_bis.remove('DEM')\r\n\r\nmat_train = np.matrix(train_numerical)\r\nmat_test  = np.matrix(test_numerical)\r\nmat_new = np.matrix(train_numerical.drop('DEM',axis = 1))\r\nmat_y = np.array(train.DEM)\r\n\r\nprepro_y = MinMaxScaler()\r\nprepro_y.fit(mat_y.reshape(len(mat_y),1))\r\n\r\nprepro = MinMaxScaler()\r\nprepro.fit(mat_train)\r\n\r\nprepro_test = MinMaxScaler()\r\nprepro_test.fit(mat_new)\r\n\r\ntrain_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\r\ntest_num_scale  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_bis)\r\n\r\ntrain[col_train] = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\r\ntest[col_train_bis]  = test_num_scale\r\n\r\n# List of features\r\nCOLUMNS = col_train\r\nFEATURES = col_train_bis\r\nLABEL = \"SalePrice\"\r\n\r\nFEATURES_CAT = col_train_cat\r\nprint (FEATURES_CAT)\r\n\r\nengineered_features = []\r\n\r\n\r\nfor continuous_feature in FEATURES:\r\n    engineered_features.append(\r\n        tf.contrib.layers.real_valued_column(continuous_feature))\r\n\r\nfor categorical_feature in FEATURES_CAT:\r\n    sparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(\r\n        categorical_feature, hash_bucket_size=1000)\r\n    engineered_features.append(\r\n        tf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16, combiner=\"sum\"))\r\nprint (engineered_features)\r\n\r\n# Training set and Prediction set with the features to predict\r\ntraining_set = train[FEATURES + FEATURES_CAT]\r\nprediction_set = train.DEM\r\nprint (training_set)\r\n\r\n# Train and Test\r\nx_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,\r\n                                                    prediction_set, test_size=0.33, random_state=42)\r\ny_train = pd.DataFrame(y_train, columns = [LABEL])\r\ntraining_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)\r\n\r\n# Training for submission\r\ntraining_sub = training_set[FEATURES + FEATURES_CAT]\r\ntesting_sub = test[FEATURES + FEATURES_CAT]\r\n\r\n# Same thing but for the test set\r\ny_test = pd.DataFrame(y_test, columns = [LABEL])\r\ntesting_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)\r\n\r\n\r\ntesting_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)\r\n\r\nprint (training_set[FEATURES_CAT])\r\n\r\n\r\ndef input_fn_new(data_set, training=True):\r\n    continuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\r\n\r\n    categorical_cols = {k: tf.SparseTensor(\r\n        indices=[[i, 0] for i in range(data_set[k].size)], values=data_set[k].values, dense_shape=[data_set[k].size, 1])\r\n    for k in FEATURES_CAT}\r\n\r\n    # Merges the two dictionaries into one.\r\n    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\r\n    print(feature_cols)\r\n    if training == True:\r\n        # Converts the label column into a constant Tensor.\r\n        label = tf.constant(data_set[LABEL].values)\r\n\r\n        # Returns the feature columns and the label.\r\n        return feature_cols, label\r\n\r\n    return feature_cols\r\n\r\n# Model\r\nregressor = tf.contrib.learn.DNNRegressor(feature_columns = engineered_features,\r\n                                          activation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])\r\n\r\n\r\ntraining_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)\r\ncategorical_cols = {k: tf.SparseTensor(\r\n      indices=[[i, 0] for i in range(training_set[k].size)],\r\n      values=training_set[k].values,\r\n    dense_shape=[training_set[k].size, 1])\r\n                      for k in FEATURES_CAT}\r\n\r\n# Error: \r\n\r\nWARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\S9E55~1.GHO\\AppData\\Local\\Temp\\tmpl279_r04\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 576, in merge_with\r\n    self.assert_same_rank(other)\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 621, in assert_same_rank\r\n    other))\r\nValueError: Shapes (0,) and (?, ?) must have the same rank\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 651, in with_rank\r\n    return self.merge_with(unknown_shape(ndims=rank))\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 582, in merge_with\r\n    raise ValueError(\"Shapes %s and %s are not compatible\" % (self, other))\r\nValueError: Shapes (0,) and (?, ?) are not compatible\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"prediction.py\", line 156, in <module>\r\n    for k in FEATURES_CAT}\r\n  File \"prediction.py\", line 156, in <dictcomp>\r\n    for k in FEATURES_CAT}\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 131, in __init__\r\n    indices_shape = indices.get_shape().with_rank(2)\r\n  File \"C:\\Users\\s.ghorbel\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 653, in with_rank\r\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\r\nValueError: Shape (0,) must have rank 2\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hi @sami93 ,\r\nCould you please create a short script which reproduces this error. There are many lines in this report which seems not relevant. \r\nFYI: You may find `tf.estimator.pandas_input_fn` useful.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Hi @sami93 \r\nI've checked your code again. You can fix this problem by using regular tensor instead of sparse tensor. categorical column should work with that. So you will replace following line:\r\n\r\n```\r\ncategorical_cols = {k: tf.SparseTensor(\r\n    indices=[[i, 0] for i in range(data_set[k].size)], values=data_set[k].values, dense_shape=[data_set[k].size, 1])\r\nfor k in FEATURES_CAT}\r\n```\r\nwith following:\r\n```\r\ncategorical_cols = {k: tf.constant(data_set[k].values) for k in FEATURES_CAT}\r\n```\r\nHaving said that I recommend using `pandas_input_fn`.\r\nClosing this now. Please re-open it if it doesn't work.\r\n"]}]