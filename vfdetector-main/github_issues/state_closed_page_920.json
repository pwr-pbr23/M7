[{"number": 25856, "title": "freeze_graph unable to initialize local_variables", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nYes, I discovered this bug when running custom code.  However, I am attaching an example that illustrates the issue.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Version 10.14.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Tensorflow-cpu installed via PIP\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 1.12\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nWhen freezing a graph with a local variable, freeze_graph has an error stating \"Attempting to use uninitialized value...\".  The local variable in question was initialized via:\r\n\r\n```\r\n\twith tf.variable_scope(tf.get_variable_scope(),reuse=tf.AUTO_REUSE):\r\n\t\tb_init = tf.constant(10.0, shape=[2, 1], dtype=\"float32\",name = 'bi')\r\n\t\tb = tf.get_variable('b',initializer=b_init,collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n```\r\n\r\nI'm able to create a saved model and run the saved model.  However, I'm trying to freeze another graph for optimization.  This error will go away if I remove the 'LOCAL_VARIABLES' flag.  However, this variable then becomes global, which causes an issue with reloading my checkpoint (Tensorflow is unable to find the variable in the checkpoint).\r\n\r\n**Describe the expected behavior**\r\n\r\nI'd expect freeze_graph to initialize 'b' using 'b_init'.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport os, sys, json\r\nimport tensorflow as tf\r\nfrom tensorflow.python.lib.io import file_io\r\n\r\nfrom tensorflow.core.framework import variable_pb2\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import variables\r\nfrom tensorflow.python.framework.ops import register_proto_function\r\n\r\nfrom tensorflow.python.saved_model import tag_constants\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python import ops\r\nfrom tensorflow.tools.graph_transforms import TransformGraph\r\n\r\n#flags\r\ntf.app.flags.DEFINE_integer('model_version',1,'Models version number.')\r\ntf.app.flags.DEFINE_string('export_model_dir','../model_batch/versions', 'Directory where model will be exported to')\r\n\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\ndef main(_):\r\n\t''' main function'''\r\n\ta = tf.placeholder(dtype = tf.float32, shape = [2,1])\r\n\r\n\twith tf.variable_scope(tf.get_variable_scope(),reuse=tf.AUTO_REUSE):\r\n\t\tb_init = tf.constant(10.0, shape=[2, 1], dtype=\"float32\",name = 'bi')\r\n\t\tb = tf.get_variable('b',initializer=b_init,collections=[tf.GraphKeys.LOCAL_VARIABLES])\r\n\r\n\tb = tf.assign(b,a)\r\n\tc = []\r\n\r\n\tfor d in range(5):\r\n\t\tb = b * 1.1\r\n\r\n\tc.append(b)\r\n\tc = tf.identity(c,name = 'c')\r\n\r\n\tinit = tf.group(tf.global_variables_initializer(),\r\n                   tf.local_variables_initializer())\r\n\r\n\twith tf.Session() as sess:\r\n\r\n\t\t#init\r\n\t\tsess.run(init)\r\n\t\tprint(tf.get_default_graph().get_collection(tf.GraphKeys.LOCAL_VARIABLES))\r\n\r\n\t\t#create saved model builder class\r\n\t\texport_path_base = FLAGS.export_model_dir\r\n\t\texport_path = os.path.join(\r\n\t\t\ttf.compat.as_bytes(export_path_base),\r\n\t\t\ttf.compat.as_bytes(str(FLAGS.model_version)))\r\n\r\n\t\tif tf.gfile.Exists(export_path):\r\n\t\t\tprint ('Removing previous artifacts')\r\n\t\t\ttf.gfile.DeleteRecursively(export_path)\r\n\r\n\t\t#inputs\r\n\t\ttensor_info_a  = tf.saved_model.utils.build_tensor_info(a)\r\n\r\n\t\t#outputs\r\n\t\ttensor_info_c = tf.saved_model.utils.build_tensor_info(c)\r\n\r\n\t\tprint('Exporting trained model to', export_path)\r\n\t\tbuilder = tf.saved_model.builder.SavedModelBuilder(export_path)\r\n\r\n\t\t#define signatures\r\n\t\tprediction_signature = (\r\n\t\t\ttf.saved_model.signature_def_utils.build_signature_def(\r\n\t\t\t\tinputs={'cameras': tensor_info_a},\r\n\t\t\t\toutputs = {'depthmap' : tensor_info_c},\r\n\t\t\t\tmethod_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\r\n\r\n\t\tbuilder.add_meta_graph_and_variables(\r\n\t\t\tsess, [tf.saved_model.tag_constants.SERVING],\r\n\t\t\tsignature_def_map = {'predict_batch': prediction_signature})\r\n\r\n\t\t#export model\r\n\t\tbuilder.save(as_text=True)\r\n\r\n\t\twriter = tf.summary.FileWriter(\"output_batch\", sess.graph)\r\n\t\twriter.close()\r\n\r\n\t#load graph from saved model\r\n\tprint ('Freezing graph')\r\n\tinitializer_nodes = ''\r\n\toutput_node_names = 'c'\r\n\tsaved_model_dir = os.path.join(FLAGS.export_model_dir,str(FLAGS.model_version))\r\n\toutput_graph_filename = os.path.join(saved_model_dir,'frozen_graph.pb')\r\n\r\n\tfreeze_graph.freeze_graph(\r\n\t\tinput_saved_model_dir=saved_model_dir,\r\n\t\toutput_graph=output_graph_filename,\r\n\t\tsaved_model_tags = tag_constants.SERVING,\r\n\t\toutput_node_names=output_node_names,\r\n\t\tinitializer_nodes=initializer_nodes,\r\n\t\tinput_graph=None,\r\n\t\tinput_saver=False,\r\n\t\tinput_binary=False,\r\n\t\tinput_checkpoint=None,\r\n\t\trestore_op_name=None,\r\n\t\tfilename_tensor_name=None,\r\n\t\tclear_devices=False)\r\n\r\nif __name__ == '__main__':\r\n\ttf.app.run()\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["I wasn't able to include local_variables in my frozen graph, but I did come up with a work around.\r\n\r\nThe initial problem was that my checkpoint was created from a graph that contained local_variables.  Unfortunately, freezing the graph produced the error:\r\n\r\n`Attempting to use uninitialized value...`\r\n\r\nWhat I did to work-around the issue was to change the local variables to untrainable global variables.  I then filtered out the global variables not in my checkpoint using the following solution:\r\n\r\n[https://stackoverflow.com/a/39142780/6693924](https://stackoverflow.com/a/39142780/6693924)\r\n\r\nI'm able to create a savedModel and freeze its graph.\r\n\r\nRegarding the issue above, the problem is not unique to local variables.  I experienced the same issue when adding variable 'b' to any collection group other than 'global'.\r\n", "@jtressle Can we close this issue now, since you have found a workaround? Thanks!", "@ymodak yes we should be able to close it. Thanks for circling back.\r\n\r\nOne suggestion: can we add a note to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py mentioning only global variables can be saved in a frozen graph?\r\n\r\nThanks!", "Great. Thanks for the suggestion. @allenlavoie "]}, {"number": 25855, "title": "Fix deprecation warning with assertEquals", "body": "While running framework_tensor_shape_test with bazel the following\r\nwarnings surface:\r\n```\r\n/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2 \\\r\n    /execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/framework_tensor_shape_test.runfiles/ \\\r\n    org_tensorflow/tensorflow/python/framework/tensor_shape_test.py:203: \\\r\n    DeprecationWarning: Please use assertEqual instead.\r\n  self.assertEquals(ctor, tensor_shape.Dimension)\r\n```\r\nThis fix fixes the deprecation warnings.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 25854, "title": "cuda10+tensorflow1.12 on linux build failed", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.5.2\r\n- Installed using virtualenv? pip? conda?: python3 from system\r\n- Bazel version (if compiling from source): 0.18, 0.17\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: cuda10.0, cuDNN 7.4.2\r\n- GPU model and memory: Nvidia GTX1070\r\nBuild failed with\r\n```\r\n bazel build --config=opt --config=cuda --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mavx --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\nWARNING: Processed legacy workspace file /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tools/bazel.rc. This file will not be processed in the next release of Bazel. Please read https://github.com/bazelbuild/bazel/issues/6319 for further information, including how to upgrade.\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nDEBUG: /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nWARNING: /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/timeseries/python/timeseries/BUILD:354:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.12.0/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Aborted): bash failed: error executing command \r\n  (cd /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/home/bernard/opt/cuda_test/cuda10/cuda \\\r\n    CUDNN_INSTALL_PATH=/home/bernard/opt/cuda_test/cuda10/cuda \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/home/bernard/opt/cuda_test/cuda10/opencv/lib:/home/bernard/opt/cuda_test/cuda10/openmpi/lib:/home/bernard/opt/cuda_test/cuda10/lib:/home/bernard/opt/cuda_test/cuda10/cuda/lib64:/home/bernard/opt/cuda_test/cuda10/cuda/extras/CUPTI/lib64:/home/bernard/opt/cuda_test/cuda10/lib::/home/bernard/opt/cuda_test/cuda10/TensorRT/lib \\\r\n    NCCL_HDR_PATH=/usr/local/cuda-9.2/targets/x86_64-linux/lib/../include \\\r\n    NCCL_INSTALL_PATH=/usr/local/cuda-9.2/targets/x86_64-linux/lib \\\r\n    PATH=/home/bernard/opt/cuda_test/cuda10/opencv/bin:/home/bernard/opt/cuda_test/cuda10/openmpi/bin:/home/bernard/opt/cuda_test/cuda10/cuda/bin:/home/bernard/opt/cuda_test/cuda10/bin:/opt/openmpi-cuda/bin:/usr/local/cuda/bin:/home/bernard/bin:/home/bernard/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin:/home/bernard/opt/qt5/bin:/home/bernard/opt/opencv/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/home/bernard/opt/cuda_test/cuda10/lib/python3.5/site-packages \\\r\n    TENSORRT_INSTALL_PATH=/home/bernard/opt/cuda_test/cuda10/TensorRT/targets/x86_64-linux-gnu/lib \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=10.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n    TF_TENSORRT_VERSION=5.0.2 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/k8-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/k8-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py'): bash failed: error executing command \r\n  (cd /home/bernard/.cache/bazel/_bazel_bernard/8b714e31638c9283b6c7060cf778d169/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/home/bernard/opt/cuda_test/cuda10/cuda \\\r\n    CUDNN_INSTALL_PATH=/home/bernard/opt/cuda_test/cuda10/cuda \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/home/bernard/opt/cuda_test/cuda10/opencv/lib:/home/bernard/opt/cuda_test/cuda10/openmpi/lib:/home/bernard/opt/cuda_test/cuda10/lib:/home/bernard/opt/cuda_test/cuda10/cuda/lib64:/home/bernard/opt/cuda_test/cuda10/cuda/extras/CUPTI/lib64:/home/bernard/opt/cuda_test/cuda10/lib::/home/bernard/opt/cuda_test/cuda10/TensorRT/lib \\\r\n    NCCL_HDR_PATH=/usr/local/cuda-9.2/targets/x86_64-linux/lib/../include \\\r\n    NCCL_INSTALL_PATH=/usr/local/cuda-9.2/targets/x86_64-linux/lib \\\r\n    PATH=/home/bernard/opt/cuda_test/cuda10/opencv/bin:/home/bernard/opt/cuda_test/cuda10/openmpi/bin:/home/bernard/opt/cuda_test/cuda10/cuda/bin:/home/bernard/opt/cuda_test/cuda10/bin:/opt/openmpi-cuda/bin:/usr/local/cuda/bin:/home/bernard/bin:/home/bernard/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin:/home/bernard/opt/qt5/bin:/home/bernard/opt/opencv/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/home/bernard/opt/cuda_test/cuda10/lib/python3.5/site-packages \\\r\n    TENSORRT_INSTALL_PATH=/home/bernard/opt/cuda_test/cuda10/TensorRT/targets/x86_64-linux-gnu/lib \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=10.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n    TF_TENSORRT_VERSION=5.0.2 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/k8-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/k8-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py')\r\n2019-02-18 10:36:50.619656: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr \r\n/bin/bash: line 1: 27745 Aborted                 bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1 --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/k8-opt/genfiles/tensorflow_api/v1/ --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow._api.v1 bazel-out/k8-opt/genfiles/tensorflow/_api/v1/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/app/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/bitwise/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/compat/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/data/experimental/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/debugging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/distributions/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/dtypes/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/errors/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/feature_column/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/gfile/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/graph_util/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/activations/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/densenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/nasnet/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/resnet50/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg16/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/vgg19/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/applications/xception/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/backend/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/callbacks/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/constraints/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/imdb/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/mnist/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/datasets/reuters/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/estimator/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/initializers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/models/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/optimizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/image/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/preprocessing/text/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/regularizers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/keras/wrappers/scikit_learn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/layers/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/linalg/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/logging/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/losses/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/manip/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/math/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/metrics/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/nn/rnn_cell/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/profiler/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/python_io/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/quantization/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/random/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/resource_loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/strings/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/builder/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/loader/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/main_op/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/signature_def_utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/tag_constants/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/saved_model/utils/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sets/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sparse/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/spectral/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/summary/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/sysconfig/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/test/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/train/queue_runner/__init__.py bazel-out/k8-opt/genfiles/tensorflow/_api/v1/user_ops/__init__.py\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2.103s, Critical Path: 0.66s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\nnote: Build for tensorflow 1.13 rc2 with the same build options and with Bazel-0.19.2 was successful\r\nBut if build  tensorflow 1.12 with bazel 0.19 or above it complains that cuda doesn't have a config file or something, it was related to the first warning above.", "comments": ["@beew  TF 1.13 rc2 comes with pre built binaries for cuda 10 where as TF 1.12 supports cuda 9.\r\nTo use cuda 10 against TF 1.12, you have to build TF from sources yourself. Thanks!\r\n", "@ymodak \r\n\r\nI am building from source myself. Please read OP and reopen the issue if there is no solution, thanks."]}, {"number": 25853, "title": "[ROCm][XLA:GPU] Abstraction for using target specific intrinsics", "body": "Introduce abstraction so GPU targets can avoid use of hardcoded intrinsics while ir emission ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\nGooglers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25853).\n\n<!-- need_sender_cla -->", "I signed it!\n\nOn Mon, Feb 18, 2019 at 2:49 PM googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project (if not, look below for help).\n> Before we can look at your pull request, you'll need to sign a Contributor\n> License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed (or fixed any issues), please reply here (e.g. I\n> signed it!) and we'll verify it.\n> ------------------------------\n> What to do if you already signed the CLA Individual signers\n>\n>    - It's possible we don't have your GitHub username or you're using a\n>    different email address on your commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>\n> Corporate signers\n>\n>    - Your company has a Point of Contact who decides which employees are\n>    authorized to participate. Ask your POC to be added to the group of\n>    authorized contributors. If you don't know who your Point of Contact is,\n>    direct the Google project maintainer to go/cla#troubleshoot (Public\n>    version <https://opensource.google.com/docs/cla/#troubleshoot>).\n>    - The email used to register you as an authorized contributor must be\n>    the email used for the Git commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - The email used to register you as an authorized contributor must\n>    also be attached to your GitHub account\n>    <https://github.com/settings/emails>.\n>\n> Googlers can find more info about SignCLA and this PR by following this\n> link\n> <http://go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25853>\n> .\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25853#issuecomment-464909986>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AoU87GVKTn6ZqWyXb3avTsXcvbIB2ahFks5vOy3dgaJpZM4bBu7o>\n> .\n>\n", "CLAs look good, thanks!\n\nGooglers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25853).\n\n<!-- ok -->", "@bixia1 do you have time to look at this?", "@sumesh13 please resolve conflicts with upstream", "@bixia1 could you give this PR another round of check?", "@rthadur this is ready to pull."]}, {"number": 25852, "title": "reset_states raising 'NoneType' object is not subscriptable", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS X 10.14.3\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.0-dev20190215\r\n- Python version: 3.7\r\n\r\n\r\n**Describe the current behavior**\r\n```python\r\nimport tensorflow as tf\r\n\r\nimport tensorflow.keras as keras \r\n\r\nrnn=keras.layers.SimpleRNN(1, stateful=True)\r\n\r\nrnn.reset_states()\r\n```\r\n\r\ncauses\r\n\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-8-271e0ab7f330> in <module>\r\n      5 rnn=keras.layers.SimpleRNN(1, stateful=True)\r\n      6 \r\n----> 7 rnn.reset_states()\r\n\r\n/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py in reset_states(self, states)\r\n    889       batch_size = self.input_spec[0].shape[1]\r\n    890     else:\r\n--> 891       batch_size = self.input_spec[0].shape[0]\r\n    892     if not batch_size:\r\n    893       raise ValueError('If a RNN is stateful, it needs to know '\r\n\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nA meaningful error message is generated with instructions on why this doesn't work.", "comments": ["I think I can fix this for you and raise the error you want. I believe the issue is you're setting stateful to True. What this does is it uses the last state in the batches as the initial state for the sample. Which there doesn't appear to be any therefore attempting to change 'None'. \r\nCould you better describe what it is you're trying to do with the code?\r\n\r\nEDIT: upon further investigation this seems to be a documented error within keras. \r\n\r\nI attempted a solution, I need some help writing the test cases though.\r\n\r\nhttps://github.com/ajimenezUCLA/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent.py", "This should now be fixed by https://github.com/tensorflow/tensorflow/commit/6108cbd1dbfbb0ac9dd9d88ada1064925b7f5b19."]}, {"number": 25851, "title": "Create directory automatically in save_weights with h5 format", "body": "This fix tries to address the issue raised in #25835 where\r\nsave_weight with tf format creates directories automatically\r\nas needed, yet h5 format throws out excetion.\r\n\r\nThis fix update the save_weight with h5 format to address\r\nthe discrepancy between h5 and tf.\r\n\r\nThis fix fixes #25835.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 25850, "title": "Removal of \"third_party\" from iOS example", "body": "The example does not build external to Google due to third_party being included in the headers. Tensorflow is not typically put in a third_party directory on a personal machine. I believe this should build both internal/external but someone might need to verify internally. If not, this might need to be a flag or something.", "comments": ["Any updates on this? Seems like a pretty simple PR to approve.", "> Any updates on this? Seems like a pretty simple PR to approve.\r\nAdding @miaout17  .This is simple PR, but looks like internal -> external workflow is not working correctly. Ideally you would not need to change these headers as the workflow job will do that for you.", "@StevenHickson can you please resolve conflicts", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 25849, "title": "Add support for np.ndarray in ragged tensor construction.", "body": "First of all, thanks a lot for implementing the awesome ragged tensors! :)\r\n\r\nThis pull request adds support for `np.ndarray ` as nested type. With the pull request, the following is possible:\r\n```\r\ntf.ragged.constant([np.array([1,2]), np.array([4,5,6])])\r\n```\r\nWith the current head, this snippet throws:\r\n`TypeError: Eager execution of tf.constant with unsupported shape (value has 6 elements, shape is (3,) with 3 elements)`\r\n\r\nI guess storing data as lists of (differently sized)  numpy arrays is not too uncommon, e.g., in object detection there's usually a different number of bounding boxes per image.\r\n\r\nNote: I couldn't find a test file for `ragged_factory_op`, where should unit tests for this go?\r\n", "comments": ["Yep, I intended to, but I couldn't find a test file for `ragged_factory_op`. Should I create a new file `ragged_factory_op_test.py` or does it fit into one of the other test files?", "Up to you.\n\nOn Tue, Feb 19, 2019 at 1:26 PM Phil <notifications@github.com> wrote:\n\n> Yep, I intended to, but I couldn't find a test file for ragged_factory_op.\n> Should I create a new file ragged_factory_op_test.py or does it fit into\n> one of the other test files?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25849#issuecomment-465315469>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxV5Hl2cab7pYEgptn_LzvUjL3tFkks5vPGv4gaJpZM4bBkSs>\n> .\n>\n\n\n-- \n - Alex\n", "@PhilJd gentle ping to update tests", "Hi,\r\nI'm extremely sorry for the long delay, thanks for pinging!\r\n\r\nI've added tests and fixed the code to handle scalar np.arrays correctly.\r\nSpecifically, I've replaced `isinstance(item, (list, tuple, np.ndarray))` which verifies that `item` is not a scalar with `np.ndim(item) != 0`.\r\n\r\nOn a side note: My machine just broke and my temporary machine is not fully setup. I only ran the ragged test cases but not the complete tensorflow test suite as I would normally do.\r\n\r\nAgain, sorry for the delay!\r\nCheers,\r\nPhil"]}, {"number": 25848, "title": "tf.test.gpu_device_name() allocated all GPU memory", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 16.04\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nno \r\n\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n\r\n- TensorFlow version (use command below):\r\n1.4.1\r\n\r\n- Python version:\r\n3.6\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n\r\n- CUDA/cuDNN version:\r\n8.0\r\n\r\n- GPU model and memory:\r\n1050Ti / 4Gb\r\n\r\n\r\n**Describe the current behavior**\r\nMy code was 'checking for GPU' by calling tf.test.gpu_device_name()\r\nThen it would go to set GPUoptions to allow_growth.\r\nIt caused tf to allocate full GPU memory for the process.\r\nIf I remove tf.test.gpu_device_name() then allow_growth works as expected.\r\n\r\n**Describe the expected behavior**\r\ntf.test.gpu_device_name() to NOT allocate GPU memory. Only starting a session should.\r\n\r\n**Code to reproduce the issue**\r\n-\r\n\r\n**Other info / logs**\r\n-\r\n", "comments": ["In order to expedite the trouble shooting process can you please provide minimal code snippet to validate the issue reported here. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 25847, "title": "Error after installing tensorflow dll", "body": "hello \r\nI am facing this error just after installing tensorflow and try to use it \r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 59, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"C:\\Users\\Abeer\\AppData\\Roaming\\Python\\Python36\\site-packages\\google\\protobuf\\descriptor.py\", line 47, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: DLL load failed: The specified procedure could not be found\r\n\r\nhowever I followed all the steps in Tensorflow website \r\nwhat would be the reason and what to do urgently \r\n\r\nThanks ", "comments": ["Please provide following info. Thanks!\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 25846, "title": "[TF 2.0 API Docs] tf.math.add", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math/add\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nMuch like #25802, documentation for `tf.math.add` is created from a generated file `python/ops/gen_math_ops.py`; a link to the file that generates `python/ops/gen_math_ops.py` would be handy for users.\r\n\r\n`tf.math.add` could use a usage example, and a list of Errors raised. \r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nYes", "comments": ["Hey beginner here, On which branch can I find tf v2.0 ? cause it seems to end with 1.99  ", "@Sangarshanan you can download from [here](https://pypi.org/project/tf-nightly-2.0-preview/)", ">@Sangarshanan you can download from [here](https://pypi.org/project/tf-nightly-2.0-preview/)\r\n\r\nYes that's the pip package.\r\n\r\nThe package is built from `master` with a 2.0 config flag... I think @dynamicwebpaige knows the exact commands. Paige is someone working on a install/source page for the tf2 docs?\r\n\r\n> a link to the file that generates `python/ops/gen_math_ops.py` would be handy for users.\r\n\r\nYes! \r\nI believe it's [this file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc#L409), but I can't think of a way to find this by introspection while generating the docs. Anyone have ideas?\r\n\r\n( I usually find them by searching for quotes from the tf.org page )\r\n\r\n> `tf.math.add` could use a usage example, and a list of Errors raised.\r\n\r\n@josephhaaga can you send a PR?", "@MarkDaoust @Sangarshanan @josephhaaga \r\nYou can build TF 2.0 from source with:\r\n\r\n```\r\nexport TF_NEED_CUDA=0\r\ncd tensorflow\r\nyes \"\" | ./configure\r\n\r\nbazel build --config=opt --config=v2 tensorflow/tools/pip_package:build_pip_package\r\nmkdir pip_pkg\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package pip_pkg --nightly_flag \\\r\n  --project_name tf_nightly_2.0_preview\r\n\r\n```\r\nI do not think that anyone is working on adding installation from source to the docs - but that would be a great add! So would the guide to modifying `gen_math_ops.py` documentation. :smile:\r\n\r\nThanks for your interest in improving the TF 2.0 API docs! We appreciate it.", "I believe this could be closed due to #33773 ", "yes."]}, {"number": 25845, "title": "Error while retrain inception-v3", "body": "**System information**\r\n- Have I written custom code: No, it is the sample code to retrain inception-v3 in https://github.com/tensorflow/hub/raw/master/examples/image_retraining/retrain.py\r\n- OS Platform and Distribution: Windows 10 build 17134.590\r\n- Mobile device if the issue happens on mobile device: N/A\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 1.8.0\r\n- Python version:3.6.4\r\n- Bazel version: N/A\r\n- GCC/Compiler version: N/A\r\n- CUDA/cuDNN version: 9.2 / 7.4.2\r\n- GPU model and memory: GTX1070 8GB\r\n\r\n**Describe the current behavior**\r\nStart retrain.py as https://tensorflow.google.cn/hub/tutorials/image_retraining.\r\nAnd throw a error [could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED].\r\n\r\n**Describe the expected behavior**\r\nIt should initialize fine and start retrain.\r\n\r\n**Code to reproduce the issue**\r\nI have not change the sample code in https://github.com/tensorflow/hub/raw/master/examples/image_retraining/retrain.py.\r\n\r\n**Other info / logs**\r\nINFO:tensorflow:Looking for images in 'daisy'\r\nINFO:tensorflow:Looking for images in 'dandelion'\r\nINFO:tensorflow:Looking for images in 'roses'\r\nINFO:tensorflow:Looking for images in 'sunflowers'\r\nINFO:tensorflow:Looking for images in 'tulips'\r\nINFO:tensorflow:Using C:\\Users\\username\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\r\n\r\n'''\r\nlots of modle variable initialize info\r\n'''\r\n\r\n2019-02-18 23:55:23.138894: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-02-18 23:55:23.370513: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties:\r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.62GiB\r\n2019-02-18 23:55:23.376527: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-02-18 23:55:24.022863: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-18 23:55:24.026942: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0\r\n2019-02-18 23:55:24.028585: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N\r\n2019-02-18 23:55:24.030644: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nINFO:tensorflow:Creating bottleneck at /tmp/bottleneck\\daisy\\10140303196_b88d3d6cec.jpg_https~tfhub.dev~google~imagenet~inception_v3~feature_vector~1.txt\r\n2019-02-18 23:55:27.258220: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2019-02-18 23:55:27.260973: F T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\conv_ops.cc:713] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms)\r\n", "comments": ["This is likely due to tensorflow and cudnn version mismatch.  Can you please switch to following test build configuration :\r\n[tensorflow_gpu-1.8.0 cuda 7 cudnn 9](https://developer.nvidia.com/rdp/cudnn-archive)\r\n", "After I restart the system, the code can run successful. \r\nI remember I run the code twice. And the first time it download the model, it meet a network problem. Then the code stoped. The second time it download successful and I meet the problem.", "@ymodak And I want to know what version you would suggest. cuDNN 7 also have plenty of subversion, and it seems like 7.4.2 can't work fine everytime.\r\n\r\nThis time it have one more error [failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED].\r\nIt occur when I try to use the label_image.py in that guide.\r\nThe full log : \r\n\r\n2019-02-21 23:41:21.400448: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-02-21 23:41:21.651680: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties:\r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 8.00GiB freeMemory: 6.62GiB\r\n2019-02-21 23:41:21.656143: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-02-21 23:41:22.337959: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-21 23:41:22.341171: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0\r\n2019-02-21 23:41:22.342441: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N\r\n2019-02-21 23:41:22.343806: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-02-21 23:41:25.157352: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-02-21 23:41:25.159673: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-21 23:41:25.162267: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0\r\n2019-02-21 23:41:25.164891: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N\r\n2019-02-21 23:41:25.166364: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2019-02-21 23:41:28.616722: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_blas.cc:462] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2019-02-21 23:41:29.622645: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2019-02-21 23:41:29.625369: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:459] error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows\r\n2019-02-21 23:41:29.628533: F T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\conv_ops.cc:713] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms)", "That's strange. I would recommend using cudnn 9.0 since its [tested version](https://www.tensorflow.org/install/source#tested_build_configurations) against tf 1.8"]}, {"number": 25844, "title": "[TF 2.0 API Docs] tf.lite.TFLiteConverter", "body": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/lite/TFLiteConverter\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Links** (Fixed)\r\n\r\nIncorrect - https://github.com/tensorflow/tensorflow/blob/master/lite/python/lite.py\r\nCorrect - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/lite.py\r\n\r\n- **Description** (In PR #26067) \r\n\r\nThis is used to convert from a TensorFlow \"GraphDef or SavedModel\" into either a TFLite FlatBuffer or graph visualization.\r\n\r\nShould be \"\u2026GraphDef, Saved Model or tf.keras model\u2026\"\r\n\r\n- **Usage example** (In PR #26067) \r\n\r\nThis line of code should be repeated for each of the methods\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n- **Parameters Defined** (Fixed)\r\n\r\nMissing 2 parameters\r\n- optimizations\r\n- representative_dataset\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?** \r\n\r\nYes", "comments": ["Is this issue still unsolved? The PR seems to have solved it but it isn't still merged? Does that mean something is still left?", "I'm waiting for PR #26067 to merge."]}, {"number": 25843, "title": "TF 2.0: Can't use tf.keras.layers.LSTM on GPU.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution: Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `tf-nightly-gpu-2.0-preview==2.0.0.dev20190218`\r\n- Python version: 3.6.7\r\n- CUDA/cuDNN version: CUDA 10.0 CuDNN 7.4.2\r\n- GPU model and memory: ?\r\n\r\n\r\n**Describe the current behavior**\r\nGetting the following error when trying to fit a model using `tf.keras.layers.LSTM` with `tf.keras`:\r\n```\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-30-145a5e1acc45> in <module>()\r\n     18 model.fit(x=dataset,\r\n     19           epochs=1,\r\n---> 20           verbose=1)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    762           workers=0,\r\n    763           shuffle=shuffle,\r\n--> 764           initial_epoch=initial_epoch)\r\n    765 \r\n    766     # Case 3: Symbolic tensors or Numpy array-like.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1482         shuffle=shuffle,\r\n   1483         initial_epoch=initial_epoch,\r\n-> 1484         steps_name='steps_per_epoch')\r\n   1485 \r\n   1486   def evaluate_generator(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\r\n    244 \r\n    245       is_deferred = not model._is_compiled\r\n--> 246       batch_outs = batch_function(*batch_data)\r\n    247       if not isinstance(batch_outs, list):\r\n    248         batch_outs = [batch_outs]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n   1226       else:\r\n   1227         self._make_fit_function()\r\n-> 1228         outputs = self._fit_function(ins)  # pylint: disable=not-callable\r\n   1229 \r\n   1230     if reset_metrics:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)\r\n   3207         value = math_ops.cast(value, tensor.dtype)\r\n   3208       converted_inputs.append(value)\r\n-> 3209     outputs = self._graph_fn(*converted_inputs)\r\n   3210     return nest.pack_sequence_as(self._outputs_structure,\r\n   3211                                  [x.numpy() for x in outputs])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n    438       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\r\n    439           list(kwargs.keys()), list(self._arg_keywords)))\r\n--> 440     return self._call_flat(args)\r\n    441 \r\n    442   def _filtered_call(self, args, kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args)\r\n    507     # Only need to override the gradient in graph mode and when we have outputs.\r\n    508     if context.executing_eagerly() or not self.outputs:\r\n--> 509       outputs = self._inference_function.call(ctx, args)\r\n    510     else:\r\n    511       self._register_gradient()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args)\r\n    295             attrs=(\"executor_type\", executor_type,\r\n    296                    \"config_proto\", config),\r\n--> 297             ctx=ctx)\r\n    298       # Replace empty list with None\r\n    299       outputs = outputs or None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   except TypeError as e:\r\n     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnknownError: Fail to find the dnn implementation.\r\n\t [[{{node unified_lstm_8/CudnnRNN}}]]\r\n\t [[loss_8/dense_12_loss/binary_crossentropy/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_1/has_valid_nonscalar_shape/then/_47/has_invalid_dims/ExpandDims/_62]] [Op:__inference_keras_scratch_graph_9512]\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nIt should train the model correctly. It is running on CPU.\r\n\r\n**Code to reproduce the issue**\r\n```\r\ndef create_model(vocab_size=10):\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Embedding(vocab_size, 80),\r\n        tf.keras.layers.LSTM(64),\r\n        tf.keras.layers.Dense(1, activation='sigmoid')\r\n    ])\r\n    return model\r\n\r\nmodel = create_model(vocab_size=vocab_size)\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\n\r\ndataset1 = tf.data.Dataset.from_tensor_slices([[1, 2, 3], [4, 5,6]])\r\ndataset2 = tf.data.Dataset.from_tensor_slices([1, 2])\r\ndataset = tf.data.Dataset.zip((dataset1, dataset2))\r\nmodel.fit(x=dataset,\r\n          epochs=1,\r\n          verbose=1)\r\n```\r\n", "comments": ["Do you know where can we find `tf.keras.layers.CuDNNLSTM` in TF 2.0 ? \r\n\r\nI did a search for my question and find your issue(related) at here.", "@huan I believe `tf.keras.layers.CuDNNLSTM` will be deprecated in 2.0 in favor of `tf.keras.layers.UnifiedLSTM`. ", "Yes, I'm using a UnifiedLSTM, but I still can see the following error message, which suggest me to use the CuDNNLSTM. \r\n\r\nShould we get rid of those message about the CuDNNLSTM ?\r\n\r\n```\r\nW0219 03:21:45.296270 140664325056256 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fee9331e198>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\r\n```\r\n\r\nBTW I'm using tf.keras.layers.LSTM on GPU with TF 2.0 without any problem in the following environment:\r\n\r\n* Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n* OS Platform and Distribution: 4.15.0-45-generic\r\n* TensorFlow installed from (source or binary): binary\r\n* TensorFlow version (use command below): `tf-nightly-gpu-2.0-preview==2.0.0.dev20190218`\r\n* Python version: 3.6.7\r\n* CUDA/cuDNN version: CUDA 10.0 CuDNN 7.4.2\r\n* GPU model and memory: GTX 1080, 8GB\r\n", "I can't reproduce this in Colab, TF version '2.0.0-dev20190221'", "@Threynaud Could you check with recent version of tf-nightly-gpu-2.0-preview-2.0.0.dev20190226? Please let us know how it progresses. Thanks!", "I had the same issue. It turned out that I did not have cuDNN.\r\nAfter installing cuDNN v7.5.0.56 I no longer get this error.\r\nTensorFlow version 2.0.0-dev20190310.", "I think it was resolved. Closing due to lack of recent activity. Please open new ticket if you see similar issue. Thanks!", "I had the same issue with huan using Tensorflow 2.0.0-gpu-alpha version. After I reinstalled TF 2.0.0-nightly-gpu-dev040404 version it is resolved.", "Came across this and want to give my opinion that somebody may find it helpful. According to TF2.0 documentation: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM, TF automatically selects which layer implementation to use, based on the available environment. If there are GPUs available and you want to use cuDNN implementation (aka \"CuDNNLSTM\" in v1), just make sure your LSTM layers meet the following requirements:\r\n\r\n```\r\n1. activation == 'tanh'\r\n2. recurrent_activation == 'sigmoid'\r\n3. recurrent_dropout == 0\r\n4. unroll is False\r\n5. use_bias is True\r\n6. No use of masking.\r\n```\r\nThis worked in my case. I've been using `tf.keras.layers.LSTM` from TF2.0 and it was very slow while I was using `activation='relu'`, once I removed the `activation` (by default it uses `tanh`) the training improved a lot (from speed perspective, although in my case there wasn't any difference in performance/accuracy if using `relu` or `tanh`) . \r\nHowever, you keep seeing the warning `tensorflow.python.keras.layers.recurrent.UnifiedLSTM`, but that shouldn't be an issue!", "@ljakupi Thanks for you tip. I changed to `tf.keras.layers.LSTM` and it indeed utilizes the GPU. But it seems the inner structure is different from `CuDNNLSTM` as my model performs worse when changed to `tf.keras.layers.LSTM`. Changed back to `CuDNNLSTM` (meanwhile back to tensorflow 1.13.1), it performs as before.\r\nOr it might be related tensorflow 2.0 alpha? Not only LSTM thing?", "@pennz I don't believe there is such change in the core that it impacts your end results this much! What is \"performs worse\" in your case, slower in training or worse in quality (accuracy or whatever metric you are using)?\r\n\r\nQuick try: If your model in TF 1.13 performs better and you are using `relu`, try switching the activation to `tanh` and see if it has an impact in the performance in your TF 1.13 model. Since TF 2.0 LSTM uses `tanh` by default, it could be the case! I'm not sure about this since there can be many reasons, but try it, if you already didn't.  ", "> @pennz I don't believe there is such change in the core that it impacts your end results this much! What is \"performs worse\" in your case, slower in training or worse in quality (accuracy or whatever metric you are using)?\r\n> \r\n> Quick try: If your model in TF 1.13 performs better and you are using `relu`, try switching the activation to `tanh` and see if it has an impact in the performance in your TF 1.13 model. Since TF 2.0 LSTM uses `tanh` by default, it could be the case! I'm not sure about this since there can be many reasons, but try it, if you already didn't.\r\n\r\n@ljakupi Thanks for your reminder, I will check with the `tanh` and `relu` thing, to make sure what makes the difference. The \"performs worse\" meant that the accuracy is worse. I will do more experiment for this.\r\n\r\nP.S. tensorflow 2.0.0-beta0 reports different error message for LSTM, and I think model **won't** run in **GPU**, but in CPU and batchsize needs to be scaled down by 4 in my environment, and it is really slow training in CPU...while in 2.0.0-alpha0, model can run in GPU and fast. And the code is the same.\r\nThe message in TF2.0.0-beta0 is followed (which might be related to my env setup for TF 2.0 beta0).\r\n```\r\n019-06-10 01:38:28.009143: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21\r\n2019-06-10 01:38:28.535708: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21\r\n2019-06-10 01:38:29.153903: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n```\r\n\r\nUpdate:\r\nOh... I forgot to mention in TF 1.13, I use the `keras.layers.CuDNNLSTM`, not the one in tensorflow. I will do more experiment to compare the difference of keras and tensorflow version    models.\r\n\r\nHowever, I thought the activation used in `CuDNNLSTM` in my code, which uses TF 1.13 as backend, is tanh (refer to #https://github.com/keras-team/keras/issues/8510). So update to TF2.0, without any network configuration changed, the network should be the same, as I indeed use `tanh` in my TF 2.0.0-alpah0 code. However, use `relu` in `LSTM` in TF 2.0.0-alpah0 will be super slow.\r\n\r\nAnd the problem is the accuracy metric is worse (dropped from 91% to 89%), and I tried change different learning rate, the model in TF 2.0.0-alpah0 cannot achieve 91% accuracy, which might owe to my poor tuning ability.\r\n\r\nSo I suspect there might be some other parts have changed their default parameter, so the network is different.\r\n\r\nAnd my current resolution is stay in TF 1.13.\r\n\r\nFor my beta0 issue, detail can be seen #29584\r\n\r\nUpdate 2:\r\nRefer #29584, it is closed. It must be some other parts make my model not able to train in GPU.", "> @huan I believe `tf.keras.layers.CuDNNLSTM` will be deprecated in 2.0 in favor of `tf.keras.layers.UnifiedLSTM`.\r\n\r\nIs this still the plan?", "I know this is closed, but are there any good options right now to create a custom LSTM Cell that will use the GPU?  i.e. keras.layers.RNN(MyLSTMCell(units))  For example, what if I want to pass some custom states (calculated on the output of the cell) from an attention mechanism in time?\r\n\r\nIf I subclass LSTMCell I can do what I want, but I am forced onto the CPU."]}, {"number": 25842, "title": "GPU fusion code cleanup: Extract GpuInstructionFusion::IsFusible into gpu_fusible.cc", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\nGooglers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842).\n\n<!-- need_sender_cla -->", "I have signed the CLA", "@sana-damani please sign CLA", "https://cla.developers.google.com/clas shows that I signed it on Feb 18.\n\nSana\n\nOn Tue, Feb 19, 2019 at 1:13 PM rthadur <notifications@github.com> wrote:\n\n> @sana-damani <https://github.com/sana-damani> please sign CLA\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25842#issuecomment-465243527>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AUshHWrvxoAgR4Ocklk6SAAIi7rssJxDks5vPD6ugaJpZM4bBBWw>\n> .\n>\n", "@rthadur Any idea what we're waiting on here?", "> @rthadur Any idea what we're waiting on here?\r\n\r\nLooks like it needs another review before it can be merged. This is likely because I committed a new change before the merge was done.", "@rthadur I still see the \"Need a CLA for one or more commit authors\" line even though @sana-damani says they've signed the CLA.", "> @rthadur I still see the \"Need a CLA for one or more commit authors\" line even though @sana-damani says they've signed the CLA.\r\n\r\n@sanjoy  i believe there were multiple people who contributed to this PR , @sana-damani do you know if there is one more contributor for this PR ?", "I was the only contributor.\n\nOn Thu, Feb 21, 2019, 1:04 PM rthadur <notifications@github.com> wrote:\n\n> @rthadur <https://github.com/rthadur> I still see the \"Need a CLA for one\n> or more commit authors\" line even though @sana-damani\n> <https://github.com/sana-damani> says they've signed the CLA.\n>\n> @sanjoy <https://github.com/sanjoy> i believe there were multiple people\n> who contributed to this PR , @sana-damani <https://github.com/sana-damani>\n> do you know if there is one more contributor for this PR ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25842#issuecomment-466101231>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AUshHYW7E5bKGOe45Cr_G-fKMgzsolorks5vPt-hgaJpZM4bBBWw>\n> .\n>\n", "Hi @sana-damani, did you use the same username and email address for your commits? I see \"sdamani\" as the username on the commits.", "Thanks for pointing that out! I'll try and fix the commit author.\n\nOn Thu, Feb 21, 2019 at 1:41 PM Yifei Feng <notifications@github.com> wrote:\n\n> Hi @sana-damani <https://github.com/sana-damani>, did you use the same\n> username and email address for your commits? I see \"sdamani\" as the\n> username on the commits.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25842#issuecomment-466114623>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AUshHcShGdnloKu4Ny9_7HwDAjaKgSq4ks5vPuhPgaJpZM4bBBWw>\n> .\n>\n", "I have signed the CLA with the updated username", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- cla_yes -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- need_sender_cla -->", "I can see that sdamani with email s*******@gatech.edu has signed the CLA (but not sana-damani); maybe the system is not doing the right thing because your github username is sana-damani and sdamani?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- need_author_consent -->", "@sana-damani The last message from googlebot was sent because different emails appear in the commit history (s...@gatech.edu and s...@gmail.com). I can see that you signed the CLA with each of them, so I'm not entirely sure what's going on. In any case, it might be easier to stick to a single email address going forward. You're PR is being reviewed internally.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- cla_yes -->", "Is the Windows Bazel GPU build failure a real failure? If so, is there a way that I can reproduce and debug this failure?", "I don't think the windows failure is related.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- cla_yes -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25842) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 25841, "title": "[tflite][java] how to deal with result of runForMultipleInputsOutputs()", "body": "I am running posenet on android with tflite.\r\nThe model has multiple output arrays with the following dimensions:\r\n`1x14x14x17, 1x14x14x34, 1x14x14x32, 1x14x14x32`\r\n\r\nTherefore running the java tfliter interpreter with\r\n```\r\nimport org.tensorflow.lite.Interpreter;\r\nInterpreter tflite;\r\ntflite.runForMultipleInputsOutputs(inputs,outputs)\r\n```\r\n\r\ni can access the four output tensors with `tflite.getOutputTensor(i)` or with `outputs.get(i)` (with i el. [0,3]) as `outputs` is a `HashMap` filled with `java.nio.HeapByteBuffer` objects.\r\n\r\nHow can I convert these outputs or tflite tensors to java multi-dimensional arrays (something like `float[][][][];`) to be able to perform mathematical computations on them?", "comments": ["Defining the outputs like the following lets you work with native java arrays, which is what i wanted:\r\n\r\n    out1 = new float[1][14][14][17];\r\n    out2 = new float[1][14][14][34];\r\n    out3 = new float[1][14][14][32];\r\n    out4 = new float[1][14][14][32];\r\n    Map<Integer, Object> outputs = new HashMap<>();\r\n    outputs.put(0, out1);\r\n    outputs.put(1, out2);\r\n    outputs.put(2, out3);\r\n    outputs.put(3, out4);", "@gustavz I couldn't find any documents teaching running posenet on Android with the given tflite model file. Do you know the image input size for the given \"multi_person_mobilenet_v1_075_float.tflite\"?", "@JianbangZ  [  1 353 257   3] is the input size for the given \"multi_person_mobilenet_v1_075_float.tflite\".", "input is use the same function?", "@LiuPangYao Yes if you look at the Intepreter source code here, you'll realise that run() uses runForMultipleInputsOutputs() with but just with one output.\r\nhttps://github.com/tensorflow/tensorflow/blob/6353d940289a225cfbc104cc647b3c6970077faa/tensorflow/lite/java/src/main/java/org/tensorflow/lite/Interpreter.java#L227-L276\r\n", "Anyone run  \"multi_person_mobilenet_v1_075_float.tflite\" successfully on Android or iOS?", "Hey. I have the same problem in ios swift. Tell me how to do this operation in swift", "```java\r\n// The shape of *1* output's tensor\r\nint[] OutputShape;\r\n// The type of the *1* output's tensor\r\nDataType OutputDataType;\r\n// The multi-tensor ready storage\r\noutputProbabilityBuffers = new HashMap<>();\r\n\r\nByteBuffer x;\r\n// For each model's tensors (there are getOutputTensorCount() of the for this tflite model)\r\nfor (int i = 0; i < tflite.getOutputTensorCount(); i++) {\r\n    OutputShape = tflite.getOutputTensor(i).shape();\r\n    OutputDataType = tflite.getOutputTensor(i).dataType();\r\n    x = TensorBuffer.createFixedSize(OutputShape, OutputDataType).getBuffer();\r\n    outputProbabilityBuffers.put(i, x);\r\n    LOGGER.d(\"Created a buffer of %d bytes for tensor %d.\", x.limit(), i);\r\n}\r\nLOGGER.d(\"Created a tflite output of %d output tensors.\", outputProbabilityBuffers.size());\r\n```\r\n\r\nhttps://stackoverflow.com/a/60368924/5441588", "> Anyone run \"multi_person_mobilenet_v1_075_float.tflite\" successfully on Android or iOS?\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/44821#issuecomment-1003115362"]}, {"number": 25840, "title": "Fixed invalid link in model_pruning readme", "body": "Current link to deep cnn is invalid and leads to the start page for tutorials.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\nGooglers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25840).\n\n<!-- need_sender_cla -->", "I signed it!\r\n\r\n", "CLAs look good, thanks!\n\nGooglers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25840).\n\n<!-- ok -->"]}, {"number": 25839, "title": "Tensorflow save & restore without using filesystem", "body": "**System information**\r\n- TensorFlow version (you are using): Up to date\r\n- Are you willing to contribute it (Yes/No): Python is not my daily driver language\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI would like to retrieve(instead of save) training information and restore it to a tensorflow session when necessary (without using file system). I want to bypass filesystem.\r\n\r\nI have looked the followings and searched but was not successful.\r\n\r\nhttps://www.tensorflow.org/guide/saved_model\r\nhttps://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\r\n\r\nWhy does this feature not appear already present?\r\n\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\nDistributed system, would be an easier way to persist and handle training data\r\n\r\n**Any Other info.**\r\n(as a side note, not important, this Tensorflow approach using filesystem might be plausible for Python. Nonetheless, I am using Scala Tensorflow and I would like to bypass the filesystem entirely and use Cassandra DB for a distributed environment. If I know how to do it in Python. It might be a similar approach in the Scala version, if not using the main APIs, by using byte codes, etc..)", "comments": ["@cosmir17 The save and restore of models in tensorflow are done through a `file system` plugin system. It does not mean you have to use a file system, it only means there should be a \"file read & write\" like API. TF naturally support gcs (with `gs://...`) and s3 (with `s3://...`) which technically not exactly a file systems. Apache Ignite is also supported through `igfs://`.\r\n\r\nFor Cassandra, an implementation will be needed to have a file systems like interface to communicate and save/restore from Cassandra.\r\n\r\nThe file systems supports have been mostly moved to sig-io:\r\nhttps://github.com/tensorflow/io\r\n\r\nand there is a google group for discussion:\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!forum/io\r\n\r\n\r\n", "@yongtang, thank you for your clarification. Yes, Tensorflow uses file system as a way of persisting training data (both implicitly and explicitly). The sig-io is a python library but I can't use  it since the scala tensorflow is not compatible with sig-io.\r\n\r\n1. **I wanted to know a line of code or method that I can use to extract training data(as an object) and import it to (tf)session when necessary without me handling file path etc**\r\n\r\nto elaborate =>\r\nI found that there is a way to retrieve updated weight values.\r\nhttps://www.quora.com/How-do-I-print-weights-of-a-fully-connected-neural-network-in-tensorflow\r\n//train your network here\r\nsess.run(optimizer, feed_dict={x:data, y:labels}\r\nprint(\"layer 1 weights:\", sess.run(W1))\r\nprint(\"layer 2 weights:\", sess.run(W2))\r\n\r\n**Rather than handling each individual tensor information, I want to extract the whole training information (as an object) and import it to (tf)session when neccessary.**\r\n\r\n2. Cassandra, I am using Scala as I noted in the post, there is already a way to integrate with Cassandra (akka, persistence) so it won't be an issue.", "I am closing this ticket. I should have asked for a Java tensorflow approach."]}, {"number": 25838, "title": "How to send a file path tensor(dtype=string, like: './dataset/coef.txt') to numpy.loadtxt() Function? ", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 25837, "title": "Fixed the warnings in the operator.cc file", "body": "Fixed two warnings in the file", "comments": ["This is already fixed in the our code base. Thanks for keeping contributing to TFlite, Amit!"]}, {"number": 25836, "title": "Fixed non-trivial designated initializer error", "body": "This was causing the TC to fail", "comments": ["@shashishekhar , i have resolved the conflicts, can you pls review the PR"]}, {"number": 25835, "title": "keras model's saving format is inconsistent (tf and h5)", "body": "hi, I found the behavior is inconsistent when the keras model's saving format changed.\r\nthe keras model have two saving format(h5 and tf)\r\n\r\n**Describe the current behavior**\r\nthe reproduce code as below:\r\n```python\r\n#!/usr/bin/env python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nprint(tf.__version__)\r\n\r\n(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\r\n\r\ntrain_labels = train_labels[:1000]\r\ntest_labels = test_labels[:1000]\r\n\r\ntrain_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\r\ntest_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0\r\n\r\n\r\ndef create_model():\r\n  model = tf.keras.models.Sequential([\r\n    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\r\n    keras.layers.Dropout(0.2),\r\n    keras.layers.Dense(10, activation=tf.nn.softmax)\r\n  ])\r\n\r\n  model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n                loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n                metrics=['accuracy'])\r\n\r\n  return model\r\n\r\n\r\nmodel = create_model()\r\n\r\ncheckpoint_path = \"log_file/cp.bin\"\r\n\r\n\r\nmodel.fit(train_images, train_labels,  epochs=10, verbose=0,\r\n          validation_data=(test_images, test_labels))  # pass callback to training\r\n# model.save_weights(checkpoint_path, save_format='h5')\r\nmodel.save_weights(checkpoint_path, save_format='tf')\r\n\r\nmodel = create_model()\r\nloss, acc = model.evaluate(test_images, test_labels)\r\nprint(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))\r\n\r\nmodel.load_weights(checkpoint_path)\r\nloss, acc = model.evaluate(test_images, test_labels)\r\nprint(\"trained model, accuracy: {:5.2f}%\".format(100 * acc))\r\n```\r\nthe photo below is the behavior in my computer.\r\n![image](https://user-images.githubusercontent.com/13925796/52948264-f2f7cf00-33b3-11e9-9ad1-fff9716911c8.png)\r\n\r\n**Describe the expected behavior**\r\nwhen we change save_format from `tf` to `h5`, the expection(OSError) should not happen. ", "comments": ["Created a PR #25851 to address the different behavior between tf and h5."]}, {"number": 25834, "title": "YOLOv3 TFLite GPU and CPU perform at same speed", "body": "**System information**\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: Android\r\n- Mobile device: Google Pixel, Google Pixel 2 and Xiaomi 6\r\n- TensorFlow installed from: Binary \r\n  `implementation 'org.tensorflow:tensorflow-lite:0.0.0-gpu-experimental'`\r\n- TensorFlow version: 1.13.0\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nModel inference time is the same for GPU and CPU (~5500 ms)\r\n\r\n**Describe the expected behavior**\r\nExpecting it to be faster on GPU\r\n\r\n**Code to reproduce the issue**\r\n```\r\nInterpreter.Options options = new Interpreter.Options();\r\nGpuDelegate delegate = new GpuDelegate();\r\noptions.addDelegate(delegate);\r\n// loadModelFile is the same with that function in the sample\r\nInterpreter tflite = new Interpreter(loadModelFile(this), options);\r\n\r\nMap<Integer, Object> output = new HashMap<>();\r\nfloat[][][][] output1 = new float[1][19][19][255];\r\nfloat[][][][] output2 = new float[1][38][38][255];\r\noutput.put(0, output1);\r\noutput.put(1, output2);\r\n\r\ntflite.runForMultipleInputsOutputs(getInput(), output);\r\n\r\nprivate Object[] getInput() {\r\n  Bitmap bitmap = BitmapFactory.decodeResource(getResources(), R.drawable.dog_cycle_car);\r\n  // Mat and Improc are from OpenCV\r\n  Mat mat = new Mat();\r\n  Mat convertedMat = new Mat();\r\n  Mat resizedMat = new Mat();\r\n  Utils.bitmapToMat(bitmap, mat);\r\n  mat.convertTo(convertedMat, CvType.CV_8UC1);\r\n  Size size = new Size(608.0, 608.0);\r\n  Imgproc.resize(convertedMat, resizedMat, size, 0.0, 0.0, Imgproc.INTER_AREA);\r\n  Bitmap resizedBitmap = Bitmap.createBitmap(resizedMat.cols(), resizedMat.rows(), Bitmap.Config.ARGB_8888);\r\n  Utils.matToBitmap(resizedMat, resizedBitmap);\r\n  ByteBuffer imgData = convertBitmapToByteBuffer(resizedBitmap);\r\n  Object[] inputArray = new Object[1];\r\n  inputArray[0] = imgData;\r\n  return inputArray;\r\n}\r\n```\r\n\r\nThe model I used https://drive.google.com/open?id=1XqNO1Qo5CJwzeP1d0w-mOyyk7DWJKfkk\r\n", "comments": ["For mobile phones, the YOLOv3 model you provided is a big one. It's likely to be IO-bounded and LeakyRelu is not supported by the GPU Delegate.", "@yeminnhtut \r\nI also find the processing time is almost the same. But I encountered another question, when I add GPU delegate the processing results are not totally the same between CPU and GPU. \r\n\r\n1.What about yours results,totally the same? \r\n2.Did you convert your bitmap using 255.0f to normalize or 127.5f to normalize?\r\n\r\n\r\n```\r\nfloatValues[0][i][j][0]=((pixelValue >> 16) & 0xFF)/255.0f ;\r\nfloatValues[0][i][j][1]=((pixelValue >> 8) & 0xFF)/255.0f ;\r\nfloatValues[0][i][j][2]=(pixelValue& 0xFF) /255.0f;\r\n```\r\n\r\n```\r\nfloatValues[0][i][j][0]=(((pixelValue >> 16) & 0xFF)-127.5f)/127.5f;\r\nfloatValues[0][i][j][1]=(((pixelValue >> 8) & 0xFF)-127.5f)/127.5f;\r\nfloatValues[0][i][j][2]=((pixelValue& 0xFF)-127.5f) /127.5f;\r\n```\r\n\r\nExpecting your answers!\r\nThank you very much.", "Are you still facing an issue ? Can you rerun and share the newest data ?\r\n\r\nThanks", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25834\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25834\">No</a>\n"]}, {"number": 25833, "title": "Add python and os information in environment capture script", "body": "reference to #25461, Added:\r\n* **python** version\r\n* **os platform**\r\n\r\n@dynamicwebpaige, please take a look at it, Thanks.", "comments": ["Ping @aselle! @a6802739 has added functionality to the environment capture script. :slightly_smiling_face: ", " @aselle @yifeif , could you please have a look at this? Thanks."]}, {"number": 25832, "title": "Fix //tensorflow/python/client/session_clusterspec_prop_test", "body": "The testClusterSpecPropagationWorker1Placement and\r\ntestMultipleLocalDevices sub tests are failing as they do not establish\r\na default session before calling the evaluate method.  This commit fixes the issue.\r\nThe failures seem to have been introduced by #b17d53c.\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/25831", "comments": ["@markdryan @rthadur @saeta\r\nThese fixes for unit testes of clusterspec propagation are already covered in #24466 .\r\nCould we finish that pull request first? Thanks.", "@shishaochen Ok thanks.  I'll close this PR."]}, {"number": 25831, "title": "The unit test //tensorflow/python/client/session_clusterspec_prop_test is failing", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v1.8.0-17632-g14ecf71 1.12.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\n$ bazel test --config=opt -- //tensorflow/python:session_clusterspec_prop_test\r\nDEBUG: /home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/external/build_bazel_rules_apple/apple/repositories.bzl:35:5: \r\nWARNING: `build_bazel_rules_apple` depends on `bazel_skylib` loaded from https://github.com/bazelbuild/bazel-skylib.git (tag 0.6.0), but we have detected it already loaded into your workspace from None (tag None). You may run into compatibility issues. To silence this warning, pass `ignore_version_differences = True` to `apple_rules_dependencies()`.\r\n\r\nWARNING: /home/user/src/tensorflow/tensorflow/python/BUILD:3178:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/python:session_clusterspec_prop_test (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 test target...\r\nFAIL: //tensorflow/python:session_clusterspec_prop_test (see /home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/python/session_clusterspec_prop_test/test.log)\r\nTarget //tensorflow/python:session_clusterspec_prop_test up-to-date:\r\n  bazel-bin/tensorflow/python/session_clusterspec_prop_test\r\nINFO: Elapsed time: 4.492s, Critical Path: 4.03s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 1 process: 1 local.\r\nINFO: Build completed, 1 test FAILED, 2 total actions\r\n//tensorflow/python:session_clusterspec_prop_test                        FAILED in 4.0s\r\n  /home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/python/session_clusterspec_prop_test/test.log\r\n\r\nINFO: Build completed, 1 test FAILED, 2 total actions\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n```\r\n$ bazel test --config=opt -- //tensorflow/python:session_clusterspec_prop_test\r\nDEBUG: /home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/external/build_bazel_rules_apple/apple/repositories.bzl:35:5: \r\nWARNING: `build_bazel_rules_apple` depends on `bazel_skylib` loaded from https://github.com/bazelbuild/bazel-skylib.git (tag 0.6.0), but we have detected it already loaded into your workspace from None (tag None). You may run into compatibility issues. To silence this warning, pass `ignore_version_differences = True` to `apple_rules_dependencies()`.\r\n\r\nWARNING: /home/user/src/tensorflow/tensorflow/python/BUILD:3178:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/python:session_clusterspec_prop_test (1 packages loaded, 1518 targets configured).\r\nINFO: Found 1 test target...\r\nTarget //tensorflow/python:session_clusterspec_prop_test up-to-date:\r\n  bazel-bin/tensorflow/python/session_clusterspec_prop_test\r\nINFO: Elapsed time: 2.186s, Critical Path: 0.54s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 2 processes: 2 local.\r\nINFO: Build completed successfully, 3 total actions\r\n//tensorflow/python:session_clusterspec_prop_test               (cached) PASSED in 4.4s\r\n\r\nINFO: Build completed successfully, 3 total actions\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\n$ bazel test --config=opt -- //tensorflow/python:session_clusterspec_prop_test\r\n\r\n**Other info / logs**\r\n\r\n```\r\n======================================================================\r\nERROR: testClusterSpecPropagationWorker1Placement (__main__.SessionClusterSpecPropagationTest)\r\ntestClusterSpecPropagationWorker1Placement (__main__.SessionClusterSpecPropagationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py\", line 109, in testClusterSpecPropagationWorker1Placement\r\n    output = self.evaluate(const)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1692, in evaluate\r\n    return sess.run(tensors)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1811, in test_session\r\n    yield cached\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5245, in get_controller\r\n    yield default\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 480, in _mode\r\n    yield\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5245, in get_controller\r\n    yield default\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 4405, in device\r\n    yield\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1811, in test_session\r\n    yield cached\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1692, in evaluate\r\n    return sess.run(tensors)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1419, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 930, in run\r\n    run_metadata_ptr)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1078, in _run\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n\r\n======================================================================\r\nERROR: testMultipleLocalDevices (__main__.SessionClusterSpecPropagationTest)\r\ntestMultipleLocalDevices (__main__.SessionClusterSpecPropagationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py\", line 211, in testMultipleLocalDevices\r\n    output = self.evaluate(sum3)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1692, in evaluate\r\n    return sess.run(tensors)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1811, in test_session\r\n    yield cached\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5245, in get_controller\r\n    yield default\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 480, in _mode\r\n    yield\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5438, in get_controller\r\n    yield g\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 5245, in get_controller\r\n    yield default\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 4405, in device\r\n    yield\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 2523, in _constrain_devices_and_set_default\r\n    yield sess\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1811, in test_session\r\n    yield cached\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1692, in evaluate\r\n    return sess.run(tensors)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1419, in run\r\n    return super(ErrorLoggingSession, self).run(*args, **kwargs)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 930, in run\r\n    run_metadata_ptr)\r\n  File \"/home/user/.cache/bazel/_bazel_user/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1078, in _run\r\n    raise RuntimeError('The Session graph is empty.  Add operations to the '\r\nRuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\r\n\r\n----------------------------------------------------------------------\r\n```\r\n", "comments": ["PR https://github.com/tensorflow/tensorflow/pull/25832 fixes the issue.", "The PR has been merged. Therefore closing this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25831\">No</a>\n"]}, {"number": 25830, "title": "CUDNN_STATUS_INTERNAL_ERROR while using tensorflow.keras.applications.VGG16", "body": "I am trying to use a pretrained network from tensorflow.keras.applications with 1.13rc2 and it crashes with a cudnn error.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from source: 1.13.0-rc2\r\n- TensorFlow version (use command below):\r\n- Python version: 3.6.5\r\n- Bazel version: 0.22\r\n- GCC/Compiler version: 7.3\r\n- CUDA/cuDNN version: 10.0 / 7.4.2\r\n- GPU model and memory: GeForce RTX 2070 8GB\r\n\r\n**Code to reproduce the issue**\r\n\r\nMinimal working example:\r\n\r\n```python\r\nimport numpy as np\r\nfrom keras.applications import VGG16\r\nif __name__ == \"__main__\":\r\n    model = VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))\r\n    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\r\n    X_train = np.ones((2000, 224, 224, 3))\r\n    y_train = np.ones((2000, 1000))\r\n    model.fit(x=X_train, y=y_train, epochs=50, batch_size=16)\r\n```\r\n**Other info / logs**\r\n\r\nUsing TensorFlow backend.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n2019-02-18 09:11:29.560595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399705000 Hz\r\n2019-02-18 09:11:29.561392: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2116980 executing computations on platform Host. Devices:\r\n2019-02-18 09:11:29.561431: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-02-18 09:11:30.251516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-02-18 09:11:30.252153: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ddff10 executing computations on platform CUDA. Devices:\r\n2019-02-18 09:11:30.252175: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5\r\n2019-02-18 09:11:30.252593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.725\r\npciBusID: 0000:26:00.0\r\ntotalMemory: 7.76GiB freeMemory: 7.64GiB\r\n2019-02-18 09:11:30.252614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-02-18 09:11:30.253693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-18 09:11:30.253709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-02-18 09:11:30.253716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-02-18 09:11:30.254007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7436 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:26:00.0, compute capability: 7.5)\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\nEpoch 1/50\r\n2019-02-18 09:11:34.331098: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n2019-02-18 09:11:35.167778: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-02-18 09:11:35.167818: W ./tensorflow/stream_executor/stream.h:2099] attempting to perform DNN operation using StreamExecutor without DNN support\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 9, in <module>\r\n    model.fit(x=X_train, y=y_train, epochs=50, batch_size=16)\r\n  File \"/home/mate/dev/backend/env/backend/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/mate/dev/backend/env/backend/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\r\n    outs = f(ins_batch)\r\n  File \"/home/mate/dev/backend/env/backend/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\r\n    return self._call(inputs)\r\n  File \"/home/mate/dev/backend/env/backend/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\r\n    fetched = self._callable_fn(*array_vals)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InternalError: cuDNN launch failure : input shape([16,3,224,224]) filter shape([3,3,3,64])\r\n\t [[{{node block1_conv1/convolution}}]]\r\n\t [[{{node loss/mul}}]]\r\n", "comments": ["Same issue here. It was even present on 1.13.0-rc1. I tried compiling rc2 without XLA, but it did not help.", "@Artem-B This looks like what we've seen internally. Do you want to take on this?", "Instead of\r\n`from keras.applications import VGG16`\r\nI used\r\n`from tensorflow.keras.applications import VGG16`\r\nand retested this under a self-compiled TensorFlow 1.13.1. It works without any issues now.", "@csakvarimate , I was able to run in  Tensorflow GPU version 2.4  successfully without any error by modifying code, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/68467d5b386b4fc0819e5a88bda4c57b/25830.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25830\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25830\">No</a>\n"]}, {"number": 25829, "title": "how to specify session target when using Estimator API", "body": "Hi, I am trying to run my training graph in a remote server with remote session. I am able to do it by starting two tasks and specify the target of tf.Session as the first server. But seems there is noway to specify the target for tf.Session. Is there any workaround for this?", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 25828, "title": "[TF 2.0 API Docs] tf.keras.activations.serialize", "body": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/activations/serialize\r\n* **Correct Links** https://github.com/tensorflow/tensorflow/blob/master/python/keras/activations.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py.\r\n* **Clear Description**\r\n  The description is not opinionated about when to use this symbol, or what happens when arguments are passed to the symbol.\r\n* **Usage Example**\r\n  No usage example is provided.\r\n* **Parameters Defined**\r\n  Parameters are poorly defined, and not formatted appropriately.\r\n* **Returns Defined**\r\n  Returns are not defined.\r\n* **Raises Listed and Defined**\r\n  Errors are not defined.", "comments": ["It's a documentation of Python r1.13, and the link correctly sends us to https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/activations.py\r\n@dynamicwebpaige @rohanmeh  Am I missing soemthing here? ", "Is someone currently working on this?", "I can handle this. I can also do the deserialize function. Do we need a separate issue / pr for that?", "I have updated the entire activations doc including the functions `get`, `serialize`, `deserialize`, `linear` etc. and created a pull request.", "Thanks @asmitapoddar, I'll go review that for you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25828\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25828\">No</a>\n"]}, {"number": 25827, "title": "[TF 2.0 API Docs] tf.keras.activations.tanh", "body": "**System information**\r\n- TensorFlow version: 2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/activations/tanh\r\n* **Correct Links** https://github.com/tensorflow/tensorflow/blob/master/python/keras/activations.py is incorrect. The correct link should be https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/activations.py.\r\n* **Clear Description**\r\n  No description of what the symbol does or what happens when arguments are passed to the symbol.\r\n* **Usage Example**\r\n  No usage example is provided.\r\n* **Parameters Defined**\r\n  Parameters are not defined.\r\n* **Returns Defined**\r\n  Returns are not defined.\r\n* **Raises Listed and Defined**\r\n  Errors are not defined.", "comments": ["I modified tanh(),sigmoid() and exp() functions", "@dynamicwebpaige : could you point the source code of the docs_src? \r\ni could not find the source code for this docs at  https://github.com/tensorflow/docs/ \r\ni could add the docs if pointed out the file", "Automatically closing this out since I understand it to be resolved by the PR #29725 (merged already), but please let me know if I'm mistaken.Thanks!\r\n"]}]