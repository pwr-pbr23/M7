[{"number": 37369, "title": "feature request: add tf_random_seed argument for TPUConfig", "body": "<em>tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.15 and 2.0\r\n- Are you willing to contribute it (Yes/No): I would like to yet not quite sure how\r\n\r\n**Describe the feature and the current behavior/state.**\r\nadd `tf_random_seed ` option for `TPUConfig` ([here](https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUConfig)) as for `RunConfig` ([here](https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig)), so as to control the random seed in tf graph (and also the data sampling process?)\r\n\r\n**Will this change the current api? How?**\r\nonly one more argument will be added for `TPUConfig`\r\n\r\n**Who will benefit with this feature?**\r\npeople who want deterministic results on TPU training. \r\n\r\nThis feature request comes from the trials to following [this paper](https://arxiv.org/abs/2002.06305): wanna see if bert finetuning also get affected a lot on the other datasets while wanna see the result quickly (on GPU it takes days to train one fold)", "comments": ["@crystina-z,\r\nSorry for the delayed response. The API, [tf.estimator.RunConfig](https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig) has the argument, **`tf_random_seed`**. Can you please let us know if this is what you are looking for? \r\n\r\nIf not, The [documentation of Estimators](https://www.tensorflow.org/guide/estimator) states:\r\n\r\n> Warning: Estimators are not recommended for new code. Estimators run v1.Session-style code which is more difficult to write correctly, and can behave unexpectedly, especially when combined with TF 2 code. Estimators do fall under our compatibility guarantees, but will receive no fixes other than security vulnerabilities. See the migration guide for details.\r\n\r\n\r\nCan you please let us know if this Feature is still relevant? Thanks!", "@rmothukuru \r\nHi! Yea I guess I didn't realize when using TPU, the `RunConfig` could be used as usual..thanks for the response! "]}, {"number": 37368, "title": "Remove dependency on TF constant folding pass in mlir/lite", "body": "`mlir/lite` currently depends on the `mlir/tensorflow:tf_dialect_passes` and `mlir/tensorflow:tf_dialect_lib` bazel targets which pull in the `mlir/tensorflow` constant folding pass which adds a huge amount of dependencies.\r\nAs far as I can tell it is not required anywhere in `mlir/lite`, so this PR splits out the decode constant pass into its own very small build target which can be used by `mlir/tflite` directly.\r\n\r\nThis should greatly reduce the build time required to build the `mlir/lite` components. @jpienaar could you take a look?", "comments": ["@jpienaar Thanks for the fast review. Do you think this could be cherry-picked onto the r2.2 branch as well?\r\n\r\nI am trying to reproduce the build failure locally, but the build takes hours without a remote cache. In the meantime e0a9485c54664a273146eca7fc4601eef2d75f99 might fix the failure.", "e0a9485c54664a273146eca7fc4601eef2d75f99  fixed the `//tensorflow/compiler/mlir/tensorflow/tests:decode_constant.mlir.test` test, though for some reason `tensorflow/compiler/mlir/lite/tests/end2end:ophint_lstm.pbtxt.test` and `tensorflow/compiler/mlir/lite/tests/end2end:fake_quant_per_channel.pbtxt.test` are still failing. @jpienaar Any idea what's going on there?", "I don't see any breakages if I patch this one in locally ... ", "Was in wrong terminal when I ran the test, too many open terminals, checking again.", "I added the full `tf_dialect_passes` back to the `tf_to_tfl_flatbuffer` target in 1e29d6b65bc7f4b3819d8d17cbd9a9a946252415 which fixes the test failures.", "Seems to be missing a few dependencies still, but I can do a quick update and send it out."]}, {"number": 37367, "title": "Fix MultiWorkerMirroredStrategy validation in Model.fit", "body": "PiperOrigin-RevId: 299150128\r\nChange-Id: Ie0ef99dcbd1afc91ad1a0e19c56638c5e48a7865", "comments": []}, {"number": 37366, "title": "tf_upgrade_v2 fails to deal with set_session", "body": "**System information**  \r\n- Linux Ubuntu 16.04: \r\n- TensorFlow 2.0\r\n- Python 3.6\r\n\r\nI use `tf_upgrade_v2` to convert my script from TF1.14 to 2.0. But the converted script run into an error. \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test_mspeech_origin.py\", line 23, in <module>\r\n    set_session(tf.compat.v1.Session(config=config))\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 400, in set_session\r\n    '`set_session` is not available '\r\nRuntimeError: `set_session` is not available when using TensorFlow 2.0.\r\n```\r\n\r\nFinally I changed the code manually to make it work.\r\n```\r\nsess = tf.compat.v1.Session(config)\r\ntf.compat.v1.keras.backend.set_session(sess)\r\n```\r\n\r\nIs there anything going with `set_session` when use `tf_upgrade_v2`?", "comments": ["@PhanatosZou \r\nWe see that with respect to this issue there is existing discussion, please refer [to this](https://github.com/OlafenwaMoses/ImageAI/issues/372#issuecomment-539216312)", "Also please refer to [this link](https://github.com/OlafenwaMoses/ImageAI/issues/367#issuecomment-578531046) and let us know if it helps", "@Saduf2019 Seems like a possible way to make it work is to downgrade to a lower version. Would it be fixed in TF2.0 or further versions?", "`set_session` is deprecated too with TF 2.X. So you have to use `compat.v1` for using it in TF2."]}, {"number": 37365, "title": "ResNet models in tf.keras.applications contain a bias term which should not be there.", "body": "Pretrained ResNet models available as part of `tf.keras.applications` include a `bias` weight with all the convolutional layers which is weird. What is even weirder is that the pretrained weights contain `all zeros` for the bias weights, which is definitely a problem. \r\n\r\nResNet models do not use a bias term because of the use of `batch normalization`. Even the TensorFlow models repository, the [ResNet construction code](https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet_model.py) does not contain a bias term in convolutions.\r\n\r\nThe following code shows the weights in the resnet50 model in `tf.keras.applications` as can be seen the bias terms are all zeros.\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\nmodel = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet')\r\nprint(model.trainable_variables)\r\n```\r\n\r\nA small portion of the output shows the bias terms as all zeros.\r\n\r\n```\r\narray([[[[ 1.76406968e-02,  2.18379945e-02,  6.38491847e-03, ...,\r\n          -1.56918354e-02,  1.33828130e-02, -7.58931879e-03],\r\n         [ 6.57748384e-03, -1.13832625e-02, -1.44122150e-02, ...,\r\n           1.07535999e-02,  1.99317057e-02, -5.90330362e-03],\r\n         [ 1.96981058e-02,  6.84878789e-03, -1.30715151e-03, ...,\r\n          -8.99719913e-03,  1.00973761e-02, -1.09837623e-02],\r\n         ...,\r\n         [ 4.02560830e-03, -2.51277094e-03, -1.91410668e-02, ...,\r\n           1.84022412e-02, -1.05592925e-02,  3.84159223e-03],\r\n         [-1.21582337e-02, -2.44973949e-03, -8.21000524e-03, ...,\r\n          -3.52650182e-03,  9.62345582e-03, -1.55217517e-02],\r\n         [-1.57500952e-02, -5.96316298e-03,  4.53999359e-03, ...,\r\n           4.88574570e-03,  4.60040662e-03,  8.99072620e-05]]]],\r\n      dtype=float32)>, <tf.Variable 'conv5_block3_3_conv/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv5_block3_3_bn/gamma:0' shape=(2048,) dtype=float32, numpy=\r\narray([1.3451786, 1.3965728, 1.4453218, ..., 1.2092956, 1.5969722,\r\n       1.4321095], dtype=float32)>, <tf.Variable 'conv5_block3_3_bn/beta:0' shape=(2048,) dtype=float32, numpy=\r\narray([-1.4512578, -1.6519743, -1.6319023, ..., -1.6061822, -1.7218091,\r\n       -1.9375533], dtype=float32)>]\r\n\r\n```\r\n\r\nThis is definitely an issue which needs to be cleared up as a lot of people are depending upon `tf.keras.applications`.", "comments": ["I have tried on colab with TF version 2.1.0, 2.2.0-dev20200305 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/fe1cc7f0f62c04d52390653aa1d598df/untitled707.ipynb). Thanks!", "This is a rather serious issue requiring an urgent fix because too many people rely upon `tf.keras.applications` for pretrained models. As of yet there are no V2 versions of slim models available and hence `tf.keras.applications` is the only resort. \r\n\r\nHence, unless this issue is resolved, usage of TF V2 for code porting and new code writing is going to be a big burden.", "I think you might be right, as the Kaiming He himself said [here](https://github.com/KaimingHe/deep-residual-networks/issues/10) that batch normalization should do away with the need for bias in the convolutional layers. If I understand it correctly, fixing this issue would just be a simple matter of setting `use_bias = False` when exporting the ResNet models. I can open a PR and start working soon. Can someone confirm that this is the right direction? ", "@jaketae It seems a fair point to start. But the inconsistency does not end here. A major difference between V1 and V2 models in ResNet is the use of BN in V2 while V1 does not use BN. If the current models are observed, it is clear that they both have BN layers. ", "@ujjwal-ai I'm not sure on your second point on BN. The [original paper](https://arxiv.org/pdf/1512.03385.pdf) on ResNet states that BN is used \"right after each convolution and before activation.\" ", "Then what is the exact difference between V1 and V2? Maybe I am wrong here. So any help would be appreciated", "@ujjwal-ai we should probably remove and upload a new checkpoint. But I'm not sure how this is blocking you from using keras applications model?", "This is not stopping me. I can use it by restricting the variables to be updated. The moot point is that for a new person already unaware of this issue, it can be dangerously confusing if he/she is not careful.", "@tanzhenyu Do you think the default export setting for ResNet should be changed so that `use_bias` is set to `False`?", "@jaketae sorry for jumping here but yes I think that 'use_bias=False' is the right thing to do.", "Hi,\r\n\r\nIs there any fix on the way to this issue?\r\nI can't do `tf.keras.applications.ResNet50(use_bias=False)`, since `use_bias` is a hardcoded set to `True` here https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/resnet.py#L471\r\n\r\nOf course, I can hack the way through it but would be nice to have a fix.\r\n\r\nThanks\r\n", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210524, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/6048195d58584b781d0dfd72c125a6da/35650.ipynb). Thanks!", "Any updates on this? This problem still exists in the newest version. Extra bias terms can lead to extra unnecessary calculations and params. In fact, even for ResNet50, extra bias terms lead to more than 10k extra parameters!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37365\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37365\">No</a>\n"]}, {"number": 37364, "title": "ConvLSTM2D Mixed Precision casting", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 16.04\r\n\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): 2.1.0\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nPresumably, dtype isn't correctly cast for ConvLSTM2D when using mixed_precision policy. Issue is not present in other convolution layers such as Conv2D.\r\n\r\n\r\n**Describe the expected behavior**\r\nFilter of the Conv2D op for ConvLSTM2D should be float16 when using 'mixed_float16' mixed_precision policy\r\n\r\n**Standalone code to reproduce the issue** \r\n````\r\nimport tensorflow as tf\r\n\r\npolicy=tf.keras.mixed_precision.experimental.Policy('mixed_float16')\r\ntf.keras.mixed_precision.experimental.set_policy(policy)\r\n\r\nx=tf.keras.Input(shape=(1,10,10,3))\r\n\r\n\r\n\r\nclstm1 =  tf.keras.layers.ConvLSTM2D(\r\n    filters=1,\r\n    strides=1,\r\n    kernel_size=1,\r\n    padding='same',\r\n    return_sequences=True)(x)\r\n````\r\n\r\n**Other info / logs** \r\n\r\n```\r\n/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    502                 \"%s type %s of argument '%s'.\" %\r\n    503                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\r\n--> 504                  inferred_from[input_arg.type_attr]))\r\n    505 \r\n    506         types = [values.dtype]\r\n\r\nTypeError: Input 'filter' of 'Conv2D' Op has type float32 that does not match type float16 of argument 'input'.\r\n```\r\n", "comments": ["@nshoman,\r\nI was able to reproduce the issue with [TF2.1](https://colab.sandbox.google.com/gist/amahendrakar/c45aca54869703bfd02b1e0b23203668/37364.ipynb), however the issue seems to be fixed with [TF-nightly](https://colab.sandbox.google.com/gist/amahendrakar/1d52785593f67345e46e6e9be01cf8e7/37364-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37364\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37364\">No</a>\n"]}, {"number": 37363, "title": "test issue", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": []}, {"number": 37362, "title": "[r2.2:Cherryppick] Split unroll_batch_matmul pass into own build target", "body": "This is a cherry-pick of #37356\r\n\r\n@jpienaar Since this doesn't include functional changes it would be amazing if it could be cherry-picked onto the 2.2 release branch.", "comments": ["I think you are missing the removal of these lines https://github.com/tensorflow/tensorflow/blob/b720399a6efd37259b2dc51912e217f49b4efa60/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.cc#L28-L29 \r\n\r\nIt was in #37356 but it is not here. Is it possible the cherrypick was wrong?", "@mihaimaruseac If I compare 0e86d517ea2956be302282f0845c79ca641fb01f and this PR side by side the only difference are the changes in [`tensorflow/compiler/mlir/tensorflow/transforms/batchmatmul_to_einsum.cc`](https://github.com/tensorflow/tensorflow/commit/0e86d517ea2956be302282f0845c79ca641fb01f#diff-cc764124765cbb5a4340353f6371f496) which are not relevant on the `r2.2` branch since the file doesn't exist, or am I missing something?", "Oh, sorry, I was looking at the wrong file.\r\n\r\n\r\nHowever, there are still differences between the PR on master and the PR on this branch: On master https://github.com/tensorflow/tensorflow/pull/37356/files#diff-f20d136d02b72175cd9891df563f8d62R267-R280. On this branch https://github.com/tensorflow/tensorflow/pull/37362/files#diff-f20d136d02b72175cd9891df563f8d62R267-R287 There are more deps added on this branch than on master.", "> However, there are still differences between the PR on master and the PR on this branch\r\n\r\nThis is intentional since during the merge of #37356 those dependencies where added to resolve internal build errors mentioned in https://github.com/tensorflow/tensorflow/pull/37356#issuecomment-595965631\r\n\r\nSee 0e86d517ea2956be302282f0845c79ca641fb01f for the diff of the merged PR into master.", "Makes sense. Thank you"]}, {"number": 37361, "title": "CMSIS-NN kernel is slower than C-reference kernel", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution: Linux Ubuntu 18.04 in WSH on Win10\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version: 4030aa1fe5bdd846301f379d1f1a0e58efbceae4\r\n- Target platform: SparkFun Edge (Cortex M4F)\r\n\r\n**Describe the problem**\r\nSince commit 4030aa1fe5bdd846301f379d1f1a0e58efbceae4 the convolutional layers (conv, depthwise_conv) from the C-reference kernel are equally fast as the optimized CMSIS-NN kernel or even faster. Due to the 4x SIMD acceleration it is expected that the CMSIS-NN kernel significantly faster. The issue was NOT introduced by this commit, it just made the issue visible.\r\nTo my understanding the root cause is the compiler option '-fno-builtin'. Removing this option from the Makefile (e.g. for the SparkFun edge board in tensorflow/lite/micro/tools/make/targets/apollo3evb_makefile.inc) speeds up the CMSIS-NN kernel by factor of 3-6 while the reference kernel does not change.\r\nNote: in order to let TFL micro use the CMSIS-NN kernel an int8 quantized model must be used. Otherwise, the TFL micro interpreter falls back to the reference kernel, anyway. Unfortunately, I was not able to find an int8 quantized model under tensorflow/lite/micro/examples\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n1. Create a project <my_project> using an appropriate int8 quanized model. e.g. by copying the tensorflow/lite/micro/examples/hello_world example.\r\n   Replace the model and input data by a model with convolutional layers and int8 quantization!\r\n   \r\n2. Instrument the call to the interpreter with some pin toggling, e.g.\r\n  am_hal_gpio_output_set(38);\r\n  TfLiteStatus invoke_status = interpreter->Invoke();\r\n  am_hal_gpio_output_clear(38);\r\n\r\n3. Build the project for the reference kernel, measure execution time:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile clean\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge <my_project>_bin\r\n--> measure model execution time\r\n\r\n4. Build the project for the CMSIS-NN kernel, measure execution time:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile clean\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge <my_project>_bin\r\n--> measure model execution time\r\n\r\n5. Remove '-fno-builtin' option from tensorflow/lite/micro/tools/make/targets/apollo3evb_makefile.inc\r\n(delete the line, not just comment out)\r\n\r\n6. Build the project for the reference kernel without '-fno-builtin', measure execution time:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile clean\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge <my_project>_bin\r\n--> measure model execution time\r\n\r\n7. Build the project for the CMSIS-NN kernel without '-fno-builtin', measure execution time:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile clean\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge <my_project>_bin\r\n--> measure model execution time\r\n\r\nThe execution times from 4 is not (much) shorter than from 3, eventually it is even longer.\r\nThe execution times from 7 is 3-6x times shorter than from 6, which is the expected SIMD acceleration.\r\n\r\n", "comments": ["I have attached an example project that includes a cifar10 example. The network consists of three convolutional layers. Place the example into the tensorflow/lite/micro/examples/ directory and execute the above listed steps for it:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge cifar10_bin\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge cifar10_bin\r\n\r\nThe execution times show that the interpreter benefits from the CMSIS-NN kernel only if '-fno-builtin' is not specified:\r\n\r\n14.05s: Reference Kernel, with '-fno-builtin'\r\n13.13s: CMSIS-NN  Kernel, with '-fno-builtin'\r\n14.01s: Reference Kernel, without '-fno-builtin'\r\n 2.33s:  CMSIS-NN  Kernel, without '-fno-builtin'\r\n\r\nThe CMSIS-NN kernel is speeded up by 6x.\r\n\r\n[cifar10.zip](https://github.com/tensorflow/tensorflow/files/4297754/cifar10.zip)\r\n", "Hi @ml-0, '-fno-builtin' **do not** utilize optimized implementations of e.g. memcpy and memset, which are heavily used by CMSIS-NN. This could be the reason why you see a difference. I assume you use GCC? Here's some more info:\r\n\r\nhttps://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html\r\n\r\nThanks for showing interest in the CMSIS-NN lib!\r\n", "Hi @freddan80, thanks for your reply. I know that '-fno-builtin' can be used to add optimized versions of build-in functions. What would be the intention of using this option? I guess it is to speed-up the CMSIS-NN kernel, right? \r\nUnfortunately, what I observe is the opposite: with '-fno-builtin' specified the execution time of the CMSIS-NN kernel on the SparkFun Edge (and on my Cypress PSoC6 board) is the same as for (or even slower than) the reference kernel. Without '-fno-builtin' in the Makefile the CMSIS-NN kernel is up to 6x faster.\r\nDo you have the chance to mesarure the execution time on an Cortex M4F device (e.g. SparkFun Edge) with and without this option? And to compare this with the reference kernel?\r\n", "Sorry for the confusion. I edit:ed my previous comment.\r\n>  '-fno-builtin' **do not** utilize optimized implementations of e.g. memcpy and memset\r\n\r\n", "Hi @freddan80, I see that you have edited your previous post and inverted the \"do not utilize\". Does it mean that the built-in versions of memcpy and memset are faster and should be used? Then my question is: why is the option '-fno-builtin' specified in all Makefiles for Cortex M3 and M4 target (apollo3evb_makefile.inc, bluepill_makefile.inc, ecm3531_makefile.inc, stm32f4_makefile.inc). At least on my SparkFun Edge board it makes the performance of the CMSIS kernel lower than is could be. Shouldn't such 'officially supported' boards also demonstrate the benefit of CMSIS-NN?", "> Does it mean that the built-in versions of memcpy and memset are faster and should be used?\r\n\r\nYes, they are faster.\r\n\r\n> Then my question is: why is the option '-fno-builtin' specified in all Makefiles for Cortex M3 and M4 target (apollo3evb_makefile.inc, bluepill_makefile.inc, ecm3531_makefile.inc, stm32f4_makefile.inc).\r\n\r\nInteresting observation! We haven't used these target configs for benchmarking CMSIS-NN (using FPGA boards with ref systems)\r\n\r\n> Shouldn't such 'officially supported' boards also demonstrate the benefit of CMSIS-NN?\r\n\r\nCurrently most usecases are based on unit8 models, for which we don't have much CMSIS-NN support. For that reason I guess this issue hasn't been spotted yet.\r\n\r\n@MeghnaNatraj , do you know the background to why '-fno-builtin' is set in the target configs?\r\n\r\n@ml-0 , thanks for spotting this! ", "https://github.com/tensorflow/tensorflow/pull/37936 should fix this issue\r\n", "Marking this as resolved as #37936 is merged.", "For the record.. -ffreestanding is another option that enables -fno-builtin implicitly."]}, {"number": 37360, "title": "ERROR:root:Internal Python error in the inspect module.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nERROR:root:Internal Python error in the inspect module.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n  File \"<ipython-input-17-af47826a3752>\", line 2, in <module>\r\n    hail = tf.constant('Hello World')\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\nAttributeError: 'AttributeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n  File \"<ipython-input-17-af47826a3752>\", line 2, in <module>\r\n    hail = tf.constant('Hello World')\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\nAttributeError: 'AttributeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Snehal.Dahiphale\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@snehal1405 \r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n\r\nAlso from the error posted, could you please refer to [this link](https://github.com/tensorflow/tensorflow/issues/36167), [link2](https://github.com/tensorflow/tensorflow/issues/33378#issuecomment-542541810) and [this link3](https://github.com/tensorflow/tensorflow/issues/35341#issuecomment-568656442) to help you  resolve the issue", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37360\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37360\">No</a>\n"]}, {"number": 37359, "title": "Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\nYes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\nmacOS 10.14.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\nvivo X9 (Android 7.1.2)\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\nimplementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n\r\n**Describe the current behavior**\r\n\r\nI converted a Keras model to tflite on Mac mini with Tensorflow 2.1.0 installed. But I got error when load the tflite model to Tensorflow lite Interpreter in AndroidStudio 3.5.3:\r\n`Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?Op builtin_code out or range: 82. Are you using old TFLite binary with newer model?Registration failed.`\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should work like loading mobilenet_v1_1.0_224.tflite from Google's example.\r\nSomeone help me please. Thanks a lot.\r\n\r\n**Standalone code to reproduce the issue** \r\nHere is my Kotlin codes in AndroidStudio:\r\ninit {\r\n        loadModelFile(MainActivity.mainActivity.assets, \"converted_model.tflite\")?.let {\r\n            mInterpreter = Interpreter(it)\r\n        }\r\n}\r\n\r\nprivate fun loadModelFile(assets: AssetManager, modelFilename: String): MappedByteBuffer? {\r\n       val fileDescriptor = assets.openFd(modelFilename)\r\n       val inputStream = FileInputStream(fileDescriptor.fileDescriptor)\r\n       val fileChannel = inputStream.channel\r\n        val startOffset = fileDescriptor.startOffset\r\n        val declaredLength = fileDescriptor.declaredLength\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)\r\n}\r\n\r\nHere is converting codes for Keras model to tflite:\r\n\r\nimport tensorflow as tf\r\nif __name__ == '__main__':\r\n    model = tf.keras.models.load_model('speech_model251_e_0_step_45500.base.h5')\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    tflite_model = converter.convert()\r\n    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n**Other info / logs** \r\njava.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Op builtin_code out or range: 74. Are you using old TFLite binary with newer model?Op builtin_code out or range: 82. Are you using old TFLite binary with newer model?Registration failed.\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:73)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:52)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114)", "comments": ["This model worked about 7 months ago on iOS APP with Xcode and cocoapods. I think maybe now Tensorflow lite is newer and my model is too old. If only I could use older TensorFlow Lite. But I can't, because it's always version 0.0.0-nightly. ", "@LukeChow \r\n1) Did you use TF1.x to create the model or `TF2.1`?\r\n2) can you share the model and a standalone code? Thanks!", "@LukeChow\r\n\r\nDid you use TF1.x to create the model or TF2.1?\r\ncan you share the model and a standalone code? Thanks!", "> @LukeChow\r\n> \r\n> Did you use TF1.x to create the model or TF2.1?\r\n> can you share the model and a standalone code? Thanks!\r\n@jvishnuvardhan \r\n\r\nThe model was created with TF1.x. I'm now using Tensorflow Lite 1.x compiled by myself. Loading model works with it. But the output is not correct comparing to result in iOS which using the same model and same data. The Tensorflow Lite SDKs are both 1.x in iOS and Android (downloaded around August 2019).\r\n\u2014\u2014\r\niOS codes (result is as expected):\r\nself.interpreter = [[TFLInterpreter alloc] initWithModelPath:modelPath error:&error];\r\n[self.interpreter allocateTensorsWithError:&error];\r\nself.inputTensor = [self.interpreter inputTensorAtIndex:0 error:&error];\r\nself.outTensor = [self.interpreter outputTensorAtIndex:0 error:&error];\r\n[self.inputTensor copyData:data error:&error];\r\n [self.interpreter invokeWithError:&error];\r\nNSMutableData *resultData = [NSMutableData dataWithData: [self.outTensor dataWithError:&error]];\r\n\u2014\u2014\r\nAndroid codes:\r\nloadModelFile(MainActivity.mainActivity.assets, \"converted_model.tflite\")?.let {\r\nmInterpreter = Interpreter(it)\r\n}\r\nval resultData = ByteArray(shape1 * shape2 * 4)\r\nmInterpreter.run(ByteBuffer.wrap(data), ByteBuffer.wrap(resultData))", "@LukeChow Can you Please share the model and a standalone code to reproduce the issue? Thanks!", "> > @LukeChow\r\n> > Did you use TF1.x to create the model or TF2.1?\r\n> > can you share the model and a standalone code? Thanks!\r\n> > @jvishnuvardhan\r\n> \r\n> The model was created with TF1.x. I'm now using Tensorflow Lite 1.x compiled by myself. Loading model works with it. But the output is not correct comparing to result in iOS which using the same model and same data. The Tensorflow Lite SDKs are both 1.x in iOS and Android (downloaded around August 2019).\r\n> \u2014\u2014\r\n> iOS codes (result is as expected):\r\n> self.interpreter = [[TFLInterpreter alloc] initWithModelPath:modelPath error:&error];\r\n> [self.interpreter allocateTensorsWithError:&error];\r\n> self.inputTensor = [self.interpreter inputTensorAtIndex:0 error:&error];\r\n> self.outTensor = [self.interpreter outputTensorAtIndex:0 error:&error];\r\n> [self.inputTensor copyData:data error:&error];\r\n> [self.interpreter invokeWithError:&error];\r\n> NSMutableData *resultData = [NSMutableData dataWithData: [self.outTensor dataWithError:&error]];\r\n> \u2014\u2014\r\n> Android codes:\r\n> loadModelFile(MainActivity.mainActivity.assets, \"converted_model.tflite\")?.let {\r\n> mInterpreter = Interpreter(it)\r\n> }\r\n> val resultData = ByteArray(shape1 * shape2 * 4)\r\n> mInterpreter.run(ByteBuffer.wrap(data), ByteBuffer.wrap(resultData))\r\n\r\nThis is caused by other parts of the code. \ud83d\ude05"]}, {"number": 37358, "title": "Anyone have an interest in making ReduceLROnPlateau compatible with weight decay optimizers?", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0, should work with 2.1 too\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?** No\r\n\r\n**Who will benefit with this feature?** Those using decoupled weight decay optimizers with reduce LR callback\r\n\r\n**Any Other info.**\r\n\r\nIt has been shown that decoupling weight decay from the learning rate can simply hyper parameter search and leads to better performance.\r\n\r\nhttps://arxiv.org/abs/1711.05101\r\n\r\nTensorflow has implementations for Adam and SGD.\r\n\r\nhttps://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/SGDW\r\n\r\nHowever the docs mention that when we decay the lr, we also need to decay the weight decay itself by the same factor. This is easy to do if we are using our own static schedulers like in the example they provided but i think reduce LR on plateau is still a valid technique and adding the weight decay-decay into this callback is fairly straightforward.\r\n\r\nAll we would really need to do is check if there is weight decay and if there is, just decay it just the same as with the lr. Existing functionality would remain unchanged and if there is weight decay, it should automatically be decayed anyway with the lr right? even if that is not the case, a simple additional argument \"decay_wd=False\" should suffice.\r\n\r\n```\r\n      if self.monitor_op(current, self.best):\r\n        self.best = current\r\n        self.wait = 0\r\n      elif not self.in_cooldown():\r\n        self.wait += 1\r\n        if self.wait >= self.patience:\r\n          old_lr = float(K.get_value(self.model.optimizer.lr))\r\n          old_wd = float(K.get_value(self.model.optimizer.weight_decay))\r\n          if old_lr > self.min_lr:\r\n            new_lr = old_lr * self.factor\r\n            new_wd = old_wd * self.factor\r\n            new_lr = max(new_lr, self.min_lr)\r\n            K.set_value(self.model.optimizer.weight_decay, new_wd)\r\n            K.set_value(self.model.optimizer.lr, new_lr)\r\n            if self.verbose > 0:\r\n              print('\\nEpoch %05d: ReduceLROnPlateau reducing learning '\r\n                    'rate to %s.' % (epoch + 1, new_lr))\r\n            self.cooldown_counter = self.cooldown\r\n            self.wait = 0\r\n```\r\n", "comments": ["@ben-arnao Please post this issue [here](https://github.com/tensorflow/addons/issues) as it is more appropriate to the tensorflow addons repo than tensorflow itself as this has been implemented in addons as shown [here](https://github.com/tensorflow/addons/blob/1af92905ed03f05fcf6f4918783c3d151a8b8350/tensorflow_addons/optimizers/weight_decay_optimizers.py#L266-L336).\r\n\r\nI'm closing this issue now. "]}, {"number": 37357, "title": "pathlib.Path support", "body": "**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\nYes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIn 3.4 python added the `pathlib` module for handling of file system paths. Currently, the corresponding `pathlib.Path` objects cannot be passed to tensorflow functions directly as they expect strings. \r\n\r\n**Will this change the current api? How?**\r\nFunctions that expect a file or directory path would accept both string and `Path` parameters.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone using both pathlib and tensorflow.\r\n\r\n**Any Other info.**\r\nThe (probably incomplete) list of functions that should accept `PathLike` parameters:\r\n```\r\ntf.io.read_file\r\ntf.io.TFRecordWriter\r\ntf.io.write_file\r\ntf.io.write_graph\r\n\r\ntf.data.TextLineDataset\r\ntf.data.TFRecordDataset\r\ntf.data.FixedLengthRecordDataset\r\n\r\ntf.saved_model.load\r\ntf.saved_model.save\r\ntf.train.Checkpoint\r\ntf.train.CheckpointManager\r\ntf.train.checkpoints_iterator\r\ntf.train.get_checkpoint_state\r\ntf.train.latest_checkpoint\r\ntf.train.list_variables\r\ntf.train.load_checkpoint\r\ntf.train.load_variable\r\n\r\ntf.estimator.Estimator\r\n\r\ntf.feature_column.categorical_column_with_vocabulary_file\r\ntf.feature_column.embedding_column\r\ntf.feature_column.sequence_categorical_column_with_vocabulary_file\r\ntf.feature_column.shared_embeddings\r\n\r\ntf.lookup.TextFileInitializer\r\n\r\ntf.summary.create_file_writer\r\n\r\nkeras.Model.save\r\nkeras.Model.save_weights\r\nkeras.Model.load_weights\r\nkeras.models.load_model\r\nkeras.models.save_model\r\nkeras.callbacks.CSVLogger\r\nkeras.callbacks.ModelCheckpoint\r\nkeras.callbacks.TensorBoard\r\n\r\nkeras.utils.get_file\r\nkeras.utils.plot_model\r\n```", "comments": ["@ngc92 Sorry. It is not clear. Where do you want to implement the feature? in `pathlib` or `tensorflow`? Thanks!", "this is a change to tensorflow. I think it would also be best not to specialize to `pathlib.Path` (though that is probably the main use case), but to make everything based on the `os.PathLike` interface for generality.", "I'll be able to work on this later in the year", "I have submitted a PR that adds pathlib support for the keras functions mentioned above. It introduces a generic helper function that converts a pathlib.Path to str and is a no-op for python versions that do not support pathlib.\r\n\r\nThe same approach would also work for all other tensorflow functions that do not take Tensors as arguments. I can submit a PR for that, but I am unsure of where to place the helper function.", "I think we should mostly do the conversion just before calling the filesystem layer (e.g., in `tf.io.gfile....` methods).\r\n\r\nFor the cases where those methods are not used and developers used the natural Python functions, I think we should first attempt a conversion to the wrapped ones. Only if this conversion does not make sense should we try to convert path-like objects to string in the other cases.\r\n\r\nThe utility can reside in TF proper, might need a public `tf.` name (via `tf_export` decorator).", "I wasn't aware of this discussion but I ran into the same problem when moving some of our code to `tf.io.gfile` and opend #41173 which seems to implement @mihaimaruseac's suggestions and adds pathlib support to `tf.io.gfile`.", "I'm not sure this issue should have been closed. It's still not possible to use `pathlib.Path` in TensorFlow 2.6:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom pathlib import Path\r\n\r\ntf.io.read_file(Path(\"test.txt\"))\r\n# ValueError: Attempt to convert a value (PosixPath('test.txt')) with\r\n# an unsupported type (<class 'pathlib.PosixPath'>) to a Tensor.\r\n```\r\n\r\n**Stacktrace:**\r\n<details>\r\n\r\n```stacktrace\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-9-5b1376127ba4> in <module>\r\n      2 from pathlib import Path\r\n      3\r\n----> 4 tf.io.read_file(Path(\"test.txt\"))\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/ops/io_ops.py in read_file(filename, name)\r\n    137     A tensor of dtype \"string\", with the file contents.\r\n    138   \"\"\"\r\n--> 139   return gen_io_ops.read_file(filename, name)\r\n    140\r\n    141\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py in read_file(filename, name)\r\n    554     try:\r\n    555       return read_file_eager_fallback(\r\n--> 556           filename, name=name, ctx=_ctx)\r\n    557     except _core._SymbolicException:\r\n    558       pass  # Add nodes to the TensorFlow graph.\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py in read_file_eager_fallback(filename, name, ctx)\r\n    573\r\n    574 def read_file_eager_fallback(filename, name, ctx):\r\n--> 575   filename = _ops.convert_to_tensor(filename, _dtypes.string)\r\n    576   _inputs_flat = [filename]\r\n    577   _attrs = None\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)\r\n    161         with Trace(trace_name, **trace_kwargs):\r\n    162           return func(*args, **kwargs)\r\n--> 163       return func(*args, **kwargs)\r\n    164\r\n    165     return wrapped\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1564\r\n   1565     if ret is None:\r\n-> 1566       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1567\r\n   1568     if ret is NotImplemented:\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    344                                          as_ref=False):\r\n    345   _ = as_ref\r\n--> 346   return constant(v, dtype=dtype, name=name)\r\n    347\r\n    348\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    270   \"\"\"\r\n    271   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 272                         allow_broadcast=True)\r\n    273\r\n    274\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281       with trace.Trace(\"tf.constant\"):\r\n    282         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 283     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    284\r\n    285   g = ops.get_default_graph()\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    306 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    307   \"\"\"Creates a constant on the current device.\"\"\"\r\n--> 308   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    309   if shape is None:\r\n    310     return t\r\n\r\n[...]/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    104       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n    105   ctx.ensure_initialized()\r\n--> 106   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n    107\r\n    108\r\n\r\nValueError: Attempt to convert a value (PosixPath('test.txt')) with an unsupported type (<class 'pathlib.PosixPath'>) to a Tensor.\r\n```\r\n</details>", "The same goes with functions like `tf.train.load_variable`. It does not support os.PathLike as for now", "Same for `tf.summary.create_file_writer`, which was listed by the OP but not affected by #41173, it seems. This is as of TF 2.8.0."]}, {"number": 37356, "title": "Split unroll_batch_matmul pass into own bazel build target", "body": "79aab7dd7b5864e223183d040a0d89ddf7865bb3 moved the BatchMatMul unrolling pass from `mlir/lite` to `mlir/tensorflow`. However this added `mlir/tensorflow:tensorflow_passes` as a dependency to `mlir/lite:tensorflow_lite_legalize_tf` which includes many unnecessary build requirements like xla passes and many more. This PR splits the pass into its own `mlir/tensorflow:unroll_batch_matmul_pass` target which can be used by TFLite to reduce build times.\r\n\r\nSome context: We are relying on some of the `mlir/lite` build targets in https://github.com/plumerai/compute-engine to customize the TFLite conversion process. [Upgrading to the TensorFLow `r.2.2` branch](https://github.com/larq/compute-engine/pull/258) would triple our CI build times from 15 min to 46 min.\r\nWith those changes our CI times would _only_ increase to 27 min (still quite long, but at least manageable).\r\nI know we are using non official supported build rules, but since this change will also benefit build times inside the TensorFlow monorepo, I think it is a reasonable change to make.", "comments": ["You'll also need to remove the included in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.cc#L28 else I believe bazel build would fail for that library.", "> You'll also need to remove the included in `transforms/unroll_batch_matmul.cc#L28` else I believe bazel build would fail for that library.\r\n\r\n:+1: I removed it as well. I thought about doing that earlier, but wasn't sure if it might be used since bazel didn't complain locally.\r\n\r\n", "@jpienaar For some reason I can't reproduce the CI failure locally. Hopefully b667aef3f612d3374bfb48137a965578ad522f27 will fix it.", "Here are the internal errors , @lgeiger can you please verify ?\r\n\r\n`./third_party/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.h:19:10: error: module //third_party/tensorflow/compiler/mlir/tensorflow:unroll_batch_matmul_pass does not depend on a module exporting 'third_party/llvm/llvm-project/llvm/include/llvm/ADT/ArrayRef.h'\r\n`\r\n\r\n`./third_party/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.h:20:10: error: module //third_party/tensorflow/compiler/mlir/tensorflow:unroll_batch_matmul_pass does not depend on a module exporting 'third_party/llvm/llvm-project/mlir/include/mlir/IR/Location.h'`\r\n\r\n`./third_party/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.h:21:10: error: module //third_party/tensorflow/compiler/mlir/tensorflow:unroll_batch_matmul_pass does not depend on a module exporting 'third_party/llvm/llvm-project/mlir/include/mlir/IR/PatternMatch.h'`\r\n\r\n`./third_party/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.h:22:10: error: module //third_party/tensorflow/compiler/mlir/tensorflow:unroll_batch_matmul_pass does not depend on a module exporting 'third_party/llvm/llvm-project/mlir/include/mlir/IR/TypeUtilities.h`\r\n\r\n`./third_party/tensorflow/compiler/mlir/tensorflow/transforms/unroll_batch_matmul.h:24:10: error: module //third_party/tensorflow/compiler/mlir/tensorflow:unroll_batch_matmul_pass does not depend on a module exporting 'third_party/tensorflow/core/util/matmul_bcast.h'`"]}, {"number": 37355, "title": "Raspberry Pi 3: ERROR: tensorflow-2.1.0-cp35-none-linux_armv7l.whl is not a supported wheel on this platform.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi 3 Model B+\r\n- TensorFlow installed from (source or binary): binary (.whl): https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-2.1.0-cp35-none-linux_armv7l.whl\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: Tried pip in both venv and system wide.\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n```\r\npi@raspberrypi:~ $ python3.7 --version\r\nPython 3.7.3\r\npi@raspberrypi:~ $ pip3.7 --version\r\npip 20.0.2 from /home/pi/.local/lib/python3.7/site-packages/pip (python 3.7)\r\npi@raspberrypi:~ $ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tRaspbian\r\nDescription:\tRaspbian GNU/Linux 10 (buster)\r\nRelease:\t10\r\nCodename:\tbuster\r\n```\r\n\r\n**Describe the problem**\r\nAttempting to install tensorflow for Raspberry Pi 3, using this guide: https://www.tensorflow.org/install/pip\r\nMy Raspberry Pi 3 with Raspbian 10 does not seem able to find or install tensorflow==2.1.0. It only finds 1.14.x.\r\n\r\nI tried the various steps in the tutorial, and when attempting to install the RPI3 version found at this link: https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-2.1.0-cp35-none-linux_armv7l.whl\r\nI get this error (same in venv):\r\n```\r\npi@raspberrypi:~ $ pip3.7 install tensorflow-2.1.0-cp35-none-linux_armv7l.whl --user\r\nERROR: tensorflow-2.1.0-cp35-none-linux_armv7l.whl is not a supported wheel on this platform.\r\n```\r\nAttempting to install tensorflow defaults to 1.14:\r\n```\r\npi@raspberrypi:~ $ pip3.7 install tensorflow --user\r\nLooking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\r\nCollecting tensorflow\r\n  Downloading https://www.piwheels.org/simple/tensorflow/tensorflow-1.14.0-cp37-none-linux_armv7l.whl (79.6 MB)\r\n     |\u2589                               | 2.1 MB 1.5 MB/s eta 0:00:51^C\r\nERROR: Operation cancelled by user\r\n```\r\n", "comments": ["I tried on RaspberryOS arm64 version, it doesn't work neither.", "Did you find a solution? I have a similar problem but on a Pi2b", "You're trying to install a build for python 3.5, but you have python 3.7. You can find updated builds [here](https://github.com/lhelontra/tensorflow-on-arm/releases). So run:\r\n`pip3 install https://github.com/lhelontra/tensorflow-on-arm/releases/download/v2.4.0/tensorflow-2.4.0-cp37-none-linux_armv7l.whl`", "@jepperaskdk Many bugs have been fixed in the latest version of TF. Could you please try with Latest Version of TF2.6 and let us know if the issue still persists? please check comment: https://github.com/tensorflow/tensorflow/issues/37355#issuecomment-751334345 Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37355\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37355\">No</a>\n", "> You're trying to install a build for python 3.5, but you have python 3.7. You can find updated builds [here](https://github.com/lhelontra/tensorflow-on-arm/releases). So run: `pip3 install https://github.com/lhelontra/tensorflow-on-arm/releases/download/v2.4.0/tensorflow-2.4.0-cp37-none-linux_armv7l.whl`\r\n\r\n@rjadr I just did what you told. but when download status is 99%, it says \"killed\". would you help me? ", "> You're trying to install a build for python 3.5, but you have python 3.7. You can find updated builds [here](https://github.com/lhelontra/tensorflow-on-arm/releases). So run: `pip3 install https://github.com/lhelontra/tensorflow-on-arm/releases/download/v2.4.0/tensorflow-2.4.0-cp37-none-linux_armv7l.whl`\r\n\r\nthank you, it works for me"]}, {"number": 37354, "title": "Speed up AES in tf-2.1.0", "body": "hi,\r\nI hava implemented AES encryption in tensorflow,but it is too slow.\r\nI guess there are lots of map_fn operation which make it slowly.But I don't know how to fix it\r\nhttps://stackoverflow.com/questions/60545000/aes-encryption-in-tensorflow-is-too-slow\r\n\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\ndef right_shift_and(num, a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.bitwise_and(tf.bitwise.right_shift(num, a), b)\r\n\r\n\r\ndef and_left_shift(num, a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.left_shift(tf.bitwise.bitwise_and(num, a), b)\r\n\r\n\r\ndef bitwise_and(a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.bitwise_and(a, b)\r\n\r\n\r\ndef right_shift(a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.right_shift(a, b)\r\n\r\n\r\ndef left_shift(a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.left_shift(a, b)\r\n\r\n\r\ndef bitwise_xor(a, b):\r\n    if isinstance(a, int):\r\n        a = tf.constant(a, dtype=tf.int64)\r\n    if isinstance(b, int):\r\n        b = tf.constant(b, dtype=tf.int64)\r\n    a = tf.cast(a, tf.int64)\r\n    b = tf.cast(b, tf.int64)\r\n    return tf.bitwise.bitwise_xor(a, b)\r\n\r\n\r\nclass AES:\r\n    def __init__(self, text, key):\r\n        \"\"\"\r\n        1. KeyExpansion\u2014round keys are derived from the cipher key using Rijndael's key schedule. AES requires a separate 128-bit round key block for each round plus one more.\r\n        2. Initial round key addition:\r\n           add_round_key\u2014each byte of the state is combined with a byte of the round key using bitwise xor.\r\n        3. 9, 11 or 13 rounds:\r\n           sub_bytes\u2014a non-linear substitution step where each byte is replaced with another according to a lookup table.\r\n           shift_rows\u2014a transposition step where the last three rows of the state are shifted cyclically a certain number of steps.\r\n           MixColumns\u2014a linear mixing operation which operates on the columns of the state, combining the four bytes in each column.\r\n           add_round_key\r\n        4. Final round (making 10, 12 or 14 rounds in total):\r\n           sub_bytes\r\n           shift_rows\r\n           add_round_key\r\n           Know more: https://en.wikipedia.org/wiki/Advanced_Encryption_Standard\r\n        \"\"\"\r\n\r\n        self.text = text\r\n        self.key = key\r\n\r\n    def get_encrypt(self):\r\n        return self.aes_encrypt(self.gen_16_bytes(self.text), self.aes_key_schedule(self.key))\r\n\r\n    def get_decrypt(self):\r\n        return self.gen_num(self.aes_decrypt(self.text, self.aes_key_schedule(self.key)))\r\n\r\n    @staticmethod\r\n    def sub_word(_4byte_block):\r\n        # https://en.wikipedia.org/wiki/Rijndael_S-box\r\n        S_BOX = [[99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118],\r\n                 [202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114, 192],\r\n                 [183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49, 21],\r\n                 [4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117],\r\n                 [9, 131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132],\r\n                 [83, 209, 0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207],\r\n                 [208, 239, 170, 251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168],\r\n                 [81, 163, 64, 143, 146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210],\r\n                 [205, 12, 19, 236, 95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115],\r\n                 [96, 129, 79, 220, 34, 42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219],\r\n                 [224, 50, 58, 10, 73, 6, 36, 92, 194, 211, 172, 98, 145, 149, 228, 121],\r\n                 [231, 200, 55, 109, 141, 213, 78, 169, 108, 86, 244, 234, 101, 122, 174, 8],\r\n                 [186, 120, 37, 46, 28, 166, 180, 198, 232, 221, 116, 31, 75, 189, 139, 138],\r\n                 [112, 62, 181, 102, 72, 3, 246, 14, 97, 53, 87, 185, 134, 193, 29, 158],\r\n                 [225, 248, 152, 17, 105, 217, 142, 148, 155, 30, 135, 233, 206, 85, 40, 223],\r\n                 [140, 161, 137, 13, 191, 230, 66, 104, 65, 153, 45, 15, 176, 84, 187, 22]]\r\n        S_BOX_TF = tf.constant(S_BOX, dtype=tf.int64)\r\n        result = tf.constant(0, dtype=tf.int64)\r\n        for position in range(4):\r\n            i = bitwise_and(right_shift(_4byte_block, (position * 8 + 4)), 15)\r\n            j = bitwise_and(right_shift(_4byte_block, position * 8), 15)\r\n            row = tf.gather_nd(S_BOX_TF, tf.expand_dims(i, 0))\r\n            result = bitwise_xor(result, left_shift(tf.gather_nd(row, tf.expand_dims(j, 0)), position * 8))\r\n        return result\r\n\r\n    @staticmethod\r\n    def rot_word(_4byte_block):\r\n        return left_shift(bitwise_and(_4byte_block, 16777215), 8) + right_shift(_4byte_block, 24)\r\n\r\n    @staticmethod\r\n    def init_w(_16bytes_key, idx):\r\n        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):\r\n            return right_shift(_16bytes_key, 96)\r\n        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):\r\n            return right_shift_and(_16bytes_key, 64, 4294967295)\r\n        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):\r\n            return right_shift_and(_16bytes_key, 32, 4294967295)\r\n        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):\r\n            return bitwise_and(_16bytes_key, 4294967295)\r\n        else:\r\n            return tf.constant(0, dtype=tf.int64)\r\n\r\n    @staticmethod\r\n    def assign_value(w, src_idx, dst_idx, dst_w):\r\n        if tf.math.equal(src_idx, dst_idx):\r\n            return dst_w\r\n        else:\r\n            return tf.gather_nd(w, tf.expand_dims(src_idx, 0))\r\n\r\n    def opera_w(self, idx, w):\r\n        RCon = [16777216, 33554432, 67108864, 134217728, 268435456, 536870912, 1073741824, 2147483648, 452984832,\r\n                905969664]\r\n        RCon_TF = tf.constant(RCon, dtype=tf.int64)\r\n        temp = tf.gather_nd(w, tf.expand_dims(idx - tf.constant(1, dtype=tf.int64), 0))\r\n        if tf.math.equal(idx % 4, tf.constant(0, dtype=tf.int64)):\r\n            temp = bitwise_xor(self.sub_word(self.rot_word(temp)),\r\n                               tf.gather_nd(RCon_TF, tf.expand_dims(idx // 4 - 1, 0)))\r\n        dst_w = bitwise_xor(tf.gather_nd(w, tf.expand_dims(idx - tf.constant(4, dtype=tf.int64), 0)), temp)\r\n        update_w = tf.map_fn(lambda src_idx: self.assign_value(w, src_idx, idx, dst_w),\r\n                             tf.range(tf.constant(44, dtype=tf.int64)))\r\n        idx = idx + tf.constant(1, dtype=tf.int64)\r\n        return idx, update_w\r\n\r\n    def gen_key_w(self, w, idx):\r\n        w0 = tf.gather_nd(w, tf.expand_dims(idx * 4, 0))\r\n        w1 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 1, 0))\r\n        w2 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 2, 0))\r\n        w3 = tf.gather_nd(w, tf.expand_dims(idx * 4 + 3, 0))\r\n        key = left_shift(w0, 96) + left_shift(w1, 64) + left_shift(w2, 32) + w3\r\n\r\n        return self.gen_16_bytes(key)\r\n\r\n    def aes_key_schedule(self, _16bytes_key):\r\n        \"\"\"\r\n        https://en.wikipedia.org/wiki/AES_key_schedule\r\n        TODO: Now the key generator has many left shift operations which would cause index out of boundary,\r\n              but it still works.\r\n        \"\"\"\r\n        w = tf.map_fn(lambda idx: self.init_w(_16bytes_key, idx), tf.range(tf.constant(44, dtype=tf.int64)))\r\n        idx = tf.constant(4, dtype=tf.int64)\r\n        cond = lambda idx, w: tf.math.less(idx, tf.constant(44, dtype=tf.int64))\r\n        body = lambda idx, w: self.opera_w(idx, w)\r\n        w_update = tf.while_loop(cond, body, loop_vars=[idx, w])[1]\r\n\r\n        return tf.map_fn(lambda idx: self.gen_key_w(w_update, idx), tf.range(tf.constant(11, dtype=tf.int64)))\r\n\r\n    def add_round_key(self, state, round_keys, index):\r\n        return self._16bytes_xor(state, tf.gather_nd(round_keys, tf.expand_dims(tf.constant(index, dtype=tf.int64), 0)))\r\n\r\n    @staticmethod\r\n    def _16bytes_xor(_16bytes_1, _16bytes_2):\r\n        return tf.map_fn(lambda i: bitwise_xor(tf.gather_nd(_16bytes_1, tf.expand_dims(i, 0)),\r\n                                               tf.gather_nd(_16bytes_2, tf.expand_dims(i, 0))),\r\n                         tf.range(tf.constant(16, dtype=tf.int64)))\r\n\r\n    @staticmethod\r\n    def sub_bytes_map(idx, state):\r\n        # https://en.wikipedia.org/wiki/Rijndael_S-box\r\n        S_BOX = [[99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118],\r\n                 [202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114, 192],\r\n                 [183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49, 21],\r\n                 [4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117],\r\n                 [9, 131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132],\r\n                 [83, 209, 0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207],\r\n                 [208, 239, 170, 251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168],\r\n                 [81, 163, 64, 143, 146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210],\r\n                 [205, 12, 19, 236, 95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115],\r\n                 [96, 129, 79, 220, 34, 42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219],\r\n                 [224, 50, 58, 10, 73, 6, 36, 92, 194, 211, 172, 98, 145, 149, 228, 121],\r\n                 [231, 200, 55, 109, 141, 213, 78, 169, 108, 86, 244, 234, 101, 122, 174, 8],\r\n                 [186, 120, 37, 46, 28, 166, 180, 198, 232, 221, 116, 31, 75, 189, 139, 138],\r\n                 [112, 62, 181, 102, 72, 3, 246, 14, 97, 53, 87, 185, 134, 193, 29, 158],\r\n                 [225, 248, 152, 17, 105, 217, 142, 148, 155, 30, 135, 233, 206, 85, 40, 223],\r\n                 [140, 161, 137, 13, 191, 230, 66, 104, 65, 153, 45, 15, 176, 84, 187, 22]]\r\n        S_BOX_TF = tf.constant(S_BOX, dtype=tf.int64)\r\n        i = right_shift(tf.gather_nd(state, tf.expand_dims(idx, 0)), 4)\r\n        j = bitwise_and(tf.gather_nd(state, tf.expand_dims(idx, 0)), 15)\r\n        row = tf.gather_nd(S_BOX_TF, tf.expand_dims(i, 0))\r\n        return tf.gather_nd(row, tf.expand_dims(j, 0))\r\n\r\n    def sub_bytes(self, state):\r\n        return tf.map_fn(lambda idx: self.sub_bytes_map(idx, state), tf.range(16, dtype=tf.int64))\r\n\r\n    @staticmethod\r\n    def sub_bytes_inv_map(idx, state):\r\n        I_S_BOX = [[82, 9, 106, 213, 48, 54, 165, 56, 191, 64, 163, 158, 129, 243, 215, 251],\r\n                   [124, 227, 57, 130, 155, 47, 255, 135, 52, 142, 67, 68, 196, 222, 233, 203],\r\n                   [84, 123, 148, 50, 166, 194, 35, 61, 238, 76, 149, 11, 66, 250, 195, 78],\r\n                   [8, 46, 161, 102, 40, 217, 36, 178, 118, 91, 162, 73, 109, 139, 209, 37],\r\n                   [114, 248, 246, 100, 134, 104, 152, 22, 212, 164, 92, 204, 93, 101, 182, 146],\r\n                   [108, 112, 72, 80, 253, 237, 185, 218, 94, 21, 70, 87, 167, 141, 157, 132],\r\n                   [144, 216, 171, 0, 140, 188, 211, 10, 247, 228, 88, 5, 184, 179, 69, 6],\r\n                   [208, 44, 30, 143, 202, 63, 15, 2, 193, 175, 189, 3, 1, 19, 138, 107],\r\n                   [58, 145, 17, 65, 79, 103, 220, 234, 151, 242, 207, 206, 240, 180, 230, 115],\r\n                   [150, 172, 116, 34, 231, 173, 53, 133, 226, 249, 55, 232, 28, 117, 223, 110],\r\n                   [71, 241, 26, 113, 29, 41, 197, 137, 111, 183, 98, 14, 170, 24, 190, 27],\r\n                   [252, 86, 62, 75, 198, 210, 121, 32, 154, 219, 192, 254, 120, 205, 90, 244],\r\n                   [31, 221, 168, 51, 136, 7, 199, 49, 177, 18, 16, 89, 39, 128, 236, 95],\r\n                   [96, 81, 127, 169, 25, 181, 74, 13, 45, 229, 122, 159, 147, 201, 156, 239],\r\n                   [160, 224, 59, 77, 174, 42, 245, 176, 200, 235, 187, 60, 131, 83, 153, 97],\r\n                   [23, 43, 4, 126, 186, 119, 214, 38, 225, 105, 20, 99, 85, 33, 12, 125]]\r\n        I_S_BOX_TF = tf.constant(I_S_BOX, dtype=tf.int64)\r\n        i = right_shift(tf.gather_nd(state, tf.expand_dims(idx, 0)), 4)\r\n        j = bitwise_and(tf.gather_nd(state, tf.expand_dims(idx, 0)), 15)\r\n        row = tf.gather_nd(I_S_BOX_TF, tf.expand_dims(i, 0))\r\n        return tf.gather_nd(row, tf.expand_dims(j, 0))\r\n\r\n    def sub_bytes_inv(self, state):\r\n        return tf.map_fn(lambda idx: self.sub_bytes_inv_map(idx, state), tf.range(16, dtype=tf.int64))\r\n\r\n    @staticmethod\r\n    def shift_rows_map(idx, state):\r\n        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))\r\n        else:\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))\r\n\r\n    def shift_rows(self, state):\r\n        return tf.map_fn(lambda idx: self.shift_rows_map(idx, state), tf.range(tf.constant(16, dtype=tf.int64)))\r\n\r\n    @staticmethod\r\n    def shift_rows_inv_map(idx, state):\r\n        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))\r\n        else:\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))\r\n\r\n    def shift_rows_inv(self, state):\r\n        return tf.map_fn(lambda idx: self.shift_rows_inv_map(idx, state), tf.range(tf.constant(16, dtype=tf.int64)))\r\n\r\n    @staticmethod\r\n    def bit_length(x):\r\n        bit_len = 0\r\n        while x > 0:\r\n            x = x // 2\r\n            bit_len += 1\r\n        return bit_len\r\n\r\n    def mul(self, poly1, poly2):\r\n        result = tf.cast(0, dtype=tf.int64)\r\n        for index in range(self.bit_length(poly2)):\r\n            if tf.math.greater(bitwise_and(poly2, left_shift(1, index)), tf.constant(0, dtype=tf.int64)):\r\n                result = bitwise_xor(result, left_shift(poly1, index))\r\n        return result\r\n\r\n    def mod(self, poly, mod=283):\r\n        while self.bit_length(poly) > 8:\r\n            poly = bitwise_xor(poly, left_shift(mod, self.bit_length(poly) - 9))\r\n        return poly\r\n\r\n    def opera_matrix_mul(self, row, col, idx, state, state_init, inverse=False):\r\n        # https://en.wikipedia.org/wiki/Rijndael_MixColumns\r\n        if inverse:\r\n            MIX_C = [[14, 11, 13, 9], [9, 14, 11, 13], [13, 9, 14, 11], [11, 13, 9, 14]]\r\n        else:\r\n            MIX_C = [[2, 3, 1, 1], [1, 2, 3, 1], [1, 1, 2, 3], [3, 1, 1, 2]]\r\n        MIX_C_TF = tf.constant(MIX_C, dtype=tf.int64)\r\n        i = tf.gather_nd(MIX_C_TF, tf.expand_dims(row, 0))\r\n        j = tf.gather_nd(i, tf.expand_dims(idx, 0))\r\n        new_state = bitwise_xor(state_init, self.mul(j, tf.gather_nd(state, tf.expand_dims(idx + col * 4, 0))))\r\n        idx = idx + 1\r\n        return idx, new_state\r\n\r\n    def matrix_mul_map(self, state, row, col, inverse=False):\r\n        idx = tf.constant(0, dtype=tf.int64)\r\n        s_init = tf.constant(0, dtype=tf.int64)\r\n        cond = lambda idx, s_init: tf.math.less(idx, tf.constant(4, dtype=tf.int64))\r\n        body = lambda idx, s_init: self.opera_matrix_mul(row, col, idx, state, s_init, inverse=inverse)\r\n        s_update = tf.while_loop(cond, body, loop_vars=[idx, s_init])[1]\r\n        return self.mod(s_update)\r\n\r\n    def matrix_mul(self, state, inverse=False):\r\n        loop_num = tf.constant(4, dtype=tf.int64)\r\n        return tf.map_fn(\r\n            lambda row: tf.map_fn(lambda col: self.matrix_mul_map(state, row, col, inverse), tf.range(loop_num)),\r\n            tf.range(loop_num))\r\n\r\n    @staticmethod\r\n    def exchange_columns(idx, state):\r\n        if tf.math.equal(idx, tf.constant(0, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(0, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(1, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(4, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(2, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(8, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(3, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(12, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(4, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(1, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(5, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(5, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(6, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(9, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(7, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(13, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(8, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(2, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(9, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(6, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(10, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(10, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(11, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(14, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(12, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(3, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(13, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(7, dtype=tf.int64), 0))\r\n        elif tf.math.equal(idx, tf.constant(14, dtype=tf.int64)):\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(11, dtype=tf.int64), 0))\r\n        else:\r\n            return tf.gather_nd(state, tf.expand_dims(tf.constant(15, dtype=tf.int64), 0))\r\n\r\n    def mix_columns(self, state):\r\n        matrix_state = tf.reshape(self.matrix_mul(state), [-1])\r\n        return tf.map_fn(lambda idx: self.exchange_columns(idx, matrix_state),\r\n                         tf.range(tf.constant(16, dtype=tf.int64)))\r\n\r\n    def mix_columns_inv(self, state):\r\n        matrix_state = tf.reshape(self.matrix_mul(state, inverse=True), [-1])\r\n        return tf.map_fn(lambda idx: self.exchange_columns(idx, matrix_state),\r\n                         tf.range(tf.constant(16, dtype=tf.int64)))\r\n\r\n    @staticmethod\r\n    def gen_16_bytes(num):\r\n        shift_num_list = tf.constant([120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 0], dtype=tf.int64)\r\n        result = tf.map_fn(lambda shift_num: right_shift_and(num, shift_num, 255), shift_num_list)\r\n        return result\r\n\r\n    @staticmethod\r\n    def gen_num(_16bytes):\r\n        shift_num = tf.constant([120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 0], dtype=tf.int64)\r\n        result = tf.map_fn(lambda idx: left_shift(tf.gather_nd(_16bytes, tf.expand_dims(idx, 0)),\r\n                                                  tf.gather_nd(shift_num, tf.expand_dims(idx, 0))),\r\n                           tf.range(16, dtype=tf.int64))\r\n\r\n        return tf.reduce_sum(result)\r\n\r\n    def aes_encrypt(self, plaintext, round_keys):\r\n        state = plaintext\r\n        state = self.add_round_key(state, round_keys, 0)\r\n        for _round in range(1, 10):\r\n            state = self.sub_bytes(state)\r\n            state = self.shift_rows(state)\r\n            state = self.mix_columns(state)\r\n            state = self.add_round_key(state, round_keys, _round)\r\n        state = self.sub_bytes(state)\r\n        state = self.shift_rows(state)\r\n        state = self.add_round_key(state, round_keys, 10)\r\n        return state\r\n\r\n    def aes_decrypt(self, cipher_text, round_keys):\r\n        state = cipher_text\r\n        state = self.add_round_key(state, round_keys, 10)\r\n        for _round in range(1, 10):\r\n            state = self.shift_rows_inv(state)\r\n            state = self.sub_bytes_inv(state)\r\n            state = self.add_round_key(state, round_keys, 10 - _round)\r\n            state = self.mix_columns_inv(state)\r\n        state = self.shift_rows_inv(state)\r\n        state = self.sub_bytes_inv(state)\r\n        state = self.add_round_key(state, round_keys, 0)\r\n        return state\r\n\r\n\r\nstart = time.time()\r\ntext = tf.constant(215254590896, dtype=tf.int64)\r\nfor i in range(10):\r\n  text += tf.constant(1, dtype=tf.int64)\r\n  key = tf.constant(2155745895, dtype=tf.int64)\r\n  cipher_text = AES(text, key).get_encrypt()\r\n  print(cipher_text)\r\n  print(AES(cipher_text, key).get_decrypt())\r\nprint(time.time() - start\r\n```\r\n\r\nMy tensorflow version is 2.1.0\r\n\r\n", "comments": []}, {"number": 37353, "title": "nvidia-smi missing from tensorflow:latest-gpu-py3-jupyter docker container (TF 2.1.0)", "body": "Hey all,\r\n\r\nI just upgraded my codebase to TF 2.1.0 and as such also started using the \"latest\" container instead of the 1.15.x container I was using before.\r\n\r\nMy pipeline relies on `nvidia-smi` to get information about the memory utilization of the GPUs and other things, but I was disappointed to see that the tool has been seemingly removed from the container in the newer versions.\r\n\r\nCan anyone else confirm this? I just get a \"no such file or directory\" and I can't find the binary or symbolic link in `/usr/bin/`.\r\n\r\nThanks!", "comments": ["Actually it seem the problem is only with my specific setup. Because if I run:\r\n\r\n    docker run --gpus=all tensorflow/tensorflow:latest-gpu-py3-jupyter nvidia-smi\r\n\r\nit works...\r\nCould it be because I use docker-compose and set the default runtime to be `nvidia` for all containers?", "Nevermind, I just had to clear all my cached images and build again. Somehow there were some leftovers that were messing with the base image."]}, {"number": 37352, "title": "TF-TRT is slower than native-TF with 512*512 image", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  [EAST ](https://github.com/argman/EAST)model\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Ubuntu 16.04\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below):  1.15.0\r\n- Python version: - Bazel\r\nversion (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from\r\nsource): gcc-7.1\r\n- CUDA/cuDNN version: 10.0/7.6.5\r\n- GPU model and memory:Default mode, Tesla V100-sxm2-16gb GPU\r\n\r\n**Describe the current behavior**\r\nWe test [EAST ](https://github.com/argman/EAST)model using TF-TRT and native-TF on GPU V100.\r\nIf image size is 256 * 256\uff0cfor one inference TF-TRT takes 3ms and native-TF takes 4ms.\r\nIf image size is 512 * 512\uff0cfor one inference TF-TRT takes 5ms and native-TF takes 4.5ms.\r\nIf image size is 1024 * 1024\uff0cfor one inference TF-TRT takes 40ms and native-TF takes 25ms.\r\n\r\n\r\n**Standalone code to reproduce the issue** \r\nWe upload our [saved_model.pb](https://github.com/lxl910915/Test/blob/master/SavedModel-1024-1024.tar.gz).\r\nUntar it to /tmp/SavedModel-1024-1024.\r\nFor running saved_model, the shell is CUDA_VISIBLE_DEVICES=0 python [east_sm.py](https://github.com/lxl910915/Test/blob/master/east_sm.py). One inference costs 25ms.\r\nFor running tf-trt, the shell is CUDA_VISIBLE_DEVICES=0 python [east_tftrt.py](https://github.com/lxl910915/Test/blob/master/east_tftrt.py). One inference costs 40ms.\r\n\r\nThen, we use nvprof to prof tf-trt `CUDA_VISIBLE_DEVICES=0 nvprof python east_tftrt.py`, and we find that genericReformat::copyPackedKernel occupy 60% time.\r\n\r\n```\r\n==33264== NVTX result:\r\n==33264== Warning: Found 198911 invalid range marker(s)\r\n==33264==   Thread \"<unnamed>\" (id = 268433152)\r\n==33264==     Domain \"TensorRT\"\r\n==33264==       Range \"<unnamed>\"\r\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\r\n          Range:  100.00%  1.57525s     72779  21.644us  7.3260us  850.74us  <unnamed>\r\n GPU activities:   58.34%  4.46830s     33826  132.10us  2.3030us  2.0179ms  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)\r\n                   13.70%  1.04961s      5675  184.95us  53.311us  385.95us  trt_volta_scudnn_128x64_relu_interior_nn_v1\r\n                    9.91%  759.32ms      4597  165.18us  55.007us  206.62us  trt_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1\r\n```\r\nThe detal log is [here](https://github.com/lxl910915/Test/blob/master/log.tftrt.op3).\r\n\r\nWe change minimum_segment_size value:\r\nminimum_segment_size = 200, no TRTEngineop are generated, inference time is 32ms.\r\nminimum_segment_size = 20, inference time is 32ms.\r\nminimum_segment_size = 10, inference time is 40ms.\r\nminimum_segment_size = 3, inference time is 47ms.\r\n\r\nBut copyPackedKernel takes 60% time in above cases. Then we prof the 256 * 256 image, copyPackedKernel only takes 20% times.\r\n```\r\n==30031== NVTX result:\r\n==30031== Warning: Found 110489 invalid range marker(s)\r\n==30031==   Thread \"<unnamed>\" (id = 3548374784)\r\n==30031==     Domain \"TensorRT\"\r\n==30031==       Range \"<unnamed>\"\r\n            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\r\n          Range:  100.00%  1.62226s     54141  29.963us  7.5820us  880.76us  <unnamed>\r\n GPU activities:   25.34%  103.18ms      3008  34.301us  7.0400us  152.83us  void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)\r\n                   22.51%  91.647ms      2313  39.622us  10.560us  121.47us  trt_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1\r\n                   21.18%  86.217ms     22902  3.7640us  1.5360us  16.640us  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)\r\n                    8.89%  36.172ms      2626  13.774us  8.4160us  19.840us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=4, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=8, int=8, int=1, int=1, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=4, int=1Type>)\r\n```", "comments": ["same issue!", "CC @tfeher @bixia1 @DEKHTIARJonathan ", "same issue +1", "any ideas? @bixia1 @sanjoy ", "This is the same as https://github.com/tensorflow/tensorrt/issues/183 and MattConley is working on it.", "same issue +1", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 37351, "title": "tf.where raises ValueError for RaggedTensor arguments", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): OS X\r\n- TensorFlow installed from (source or\r\nbinary): `pip install tensorflow`\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nCalling tf.where with a RaggedTensor argument raises `ValueError: TypeError: object of type 'RaggedTensor' has no len()`.\r\n\r\n**Describe the expected behavior**\r\nNo exception raised. According to https://www.tensorflow.org/api_docs/python/tf/ragged, tf.where is supposed to support RaggedTensor.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\ndigits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\r\ntf.where(tf.equal(digits, 1), 1, 0)\r\n```\r\n\r\n**Other info / logs** \r\n```\r\nIn [4]: tf.where(tf.equal(digits, 1), 1, 0)\r\n---------------------------------------------------------------------------\r\n_FallbackException                        Traceback (most recent call last)\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2(condition, t, e, name)\r\n   8679         _ctx._context_handle, tld.device_name, \"SelectV2\", name,\r\n-> 8680         tld.op_callbacks, condition, t, e)\r\n   8681       return _result\r\n\r\n_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-4-a793e17a60b8> in <module>\r\n----> 1 tf.where(tf.equal(digits, 1), 1, 0)\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py in where_v2(condition, x, y, name)\r\n   3928       return gen_array_ops.where(condition=condition, name=name)\r\n   3929   elif x is not None and y is not None:\r\n-> 3930     return gen_math_ops.select_v2(condition=condition, t=x, e=y, name=name)\r\n   3931   else:\r\n   3932     raise ValueError(\"x and y must both be non-None or both be None.\")\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2(condition, t, e, name)\r\n   8683       try:\r\n   8684         return select_v2_eager_fallback(\r\n-> 8685             condition, t, e, name=name, ctx=_ctx)\r\n   8686       except _core._SymbolicException:\r\n   8687         pass  # Add nodes to the TensorFlow graph.\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py in select_v2_eager_fallback(condition, t, e, name, ctx)\r\n   8706   _attr_T, _inputs_T = _execute.args_to_matching_eager([t, e], ctx)\r\n   8707   (t, e) = _inputs_T\r\n-> 8708   condition = _ops.convert_to_tensor(condition, _dtypes.bool)\r\n   8709   _inputs_flat = [condition, t, e]\r\n   8710   _attrs = (\"T\", _attr_T)\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1312\r\n   1313     if ret is None:\r\n-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1315\r\n   1316     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    315                                          as_ref=False):\r\n    316   _ = as_ref\r\n--> 317   return constant(v, dtype=dtype, name=name)\r\n    318\r\n    319\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    256   \"\"\"\r\n    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 258                         allow_broadcast=True)\r\n    259\r\n    260\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    264   ctx = context.context()\r\n    265   if ctx.executing_eagerly():\r\n--> 266     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    267     if shape is None:\r\n    268       return t\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     95   ctx.ensure_initialized()\r\n---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     97\r\n     98\r\n\r\nValueError: TypeError: object of type 'RaggedTensor' has no len()\r\n```", "comments": ["@Andreas5739738, I tried replicating the issue but getting different error. Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4138a70a375e358fe5022fe3358db691/untitled424.ipynb).\r\nHere \r\n```\r\ntf.where(\r\n    condition, x=None, y=None, name=None\r\n)\r\n```  \r\nx and y must be broadcastable to the same shape. \r\nCan you confirm the issue. Thanks!", "It looks like in your notebook you are testing with TF 1.15 (I see `/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/tensor_util.py` in the error messages)?\r\n\r\nHere is a different repro case where the tensor dimensions are the same, which results in the same error:\r\n```\r\n>>> tf.where(tf.equal(digits, 1),tf.ones_like(digits),tf.zeros_like(digits))\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 8680, in select_v2\r\n    tld.op_callbacks, condition, t, e)\r\ntensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3930, in where_v2\r\n    return gen_math_ops.select_v2(condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 8685, in select_v2\r\n    condition, t, e, name=name, ctx=_ctx)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 8706, in select_v2_eager_fallback\r\n    _attr_T, _inputs_T = _execute.args_to_matching_eager([t, e], ctx)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 263, in args_to_matching_eager\r\n    t, dtype, preferred_dtype=default_dtype, ctx=ctx))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1314, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 317, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 258, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 266, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: TypeError: object of type 'RaggedTensor' has no len()\r\n```\r\n", "I could replicate the issue with tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/c29154968a86ae94e4973533b1385df1/untitled431.ipynb). Thanks", "The semantics of tf.where changed from TF1 to TF2 (in particular the broadcasting semantics changed); and it looks like the ragged version of tf.where only overrides where_v1, not where_v2.  We will need to write an updated version of ragged_where with the v2 semantics.\r\n\r\nAs a stop-gap solution until then, you can use tf.compat.v1.where(), which does support ragged tensors.", "Note: since v1 where doesn't do broadcasting, you may need to do it yourself, depending on what your use case looks like.  E.g., for the gist above we'd need  to use something like:\r\n\r\n```\r\ndigits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\r\ntf.compat.v1.where(tf.equal(digits, 1), tf.ones_like(digits), tf.zeros_like(digits))\r\n```", "I tried it in tf 2.2.0 and giving me the same error. See the example that I used \r\n```\r\nb = tf.ragged.constant([[True, False, True], [False, True]])\r\nx = tf.ragged.constant([[\"A\", \"B\", \"C\"], [\"D\", \"E\"]])\r\ny = tf.ragged.constant([['a', \"b\", \"c\"], [\"d\", \"e\"]])\r\n\r\n```\r\n**ValueError: TypeError: object of type 'RaggedTensor' has no len()**", "You tried using `tf.compat.v1.where` in tf 2.2.0?  The following works for me:\r\n\r\n```\r\nb = tf.ragged.constant([[True, False, True], [False, True]])\r\nx = tf.ragged.constant([[\"A\", \"B\", \"C\"], [\"D\", \"E\"]])\r\ny = tf.ragged.constant([['a', \"b\", \"c\"], [\"d\", \"e\"]])\r\ntf.compat.v1.where(b, x, y)\r\n```\r\n\r\nNote that I'm calling `tf.compat.v1.where`, and *not* `tf.where`.  As I said, it looks like the v2 version of `tf.where` hasn't been updated to handle ragged tensors yet, but we will try to update it soon.", "I have tried in colab with TF versions 2.2,2.3-rc1,nightly versions(`2.4.0-dev20200712`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/22aa2a664bae02e3ae23f16e566fc4c7/untitled116.ipynb).Thanks!", "Fixed in d753f3aff1ee4d23572e059f5a2d49269bbebac9.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37351\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37351\">No</a>\n"]}, {"number": 37350, "title": "fixed: issue #36332", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37350) for more info**.\n\n<!-- need_sender_cla -->", "@OmerLiberman thank you for your contribution, please sign CLA.", "@gbaned \r\nsigned.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37350) for more info**.\n\n<!-- cla_yes -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37350) for more info**.\n\n<!-- ok -->", "@OmerLiberman Can you please check mihaimaruseac's comments and keep us posted. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 37349, "title": "Arcport buildsys patch", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37349) for more info**.\n\n<!-- need_sender_cla -->", "@alexeysmirnovspb Thank you for your contribution. Can you please sign CLA and resolve the conflicts? Thanks!", "@alexeysmirnovspb it still shows CLA is pending , can you please sign CLA. Thanks!", "Sorry, this pull request has been done by mistake. Closing it."]}, {"number": 37348, "title": "Improve ETA estimate for model.fit", "body": "This PR improves the keras.Progbar by allwoing it to skip the first step when determining the average duration of a step for ETA estimation. Since the first step can be significantly slower due to setup procedures, this helps to generate a better estimate for the remaining time.", "comments": ["@ngc92 Can you please fix build failures ? Thanks!", "cc @fchollet \r\n\r\nIt's fine to do this by default and not add an argument. The argument doesn't really make sense here.\r\n\r\ncurrent == 0: time_per_step = 0\r\ncurrent == 1: time_per_step = now - self._start\r\ncurrent > 1: time_per_step = (now - self._time_after_first_step) / (steps - 1)\r\ncurrent == 2: set self._time_after_first_step", "@ngc92 Can you please check @alextp's comments and keep us posted. Thanks!", "@ngc92 Any update on this PR? Please. Thanks!", "@gbaned sorry, I currently only have my laptop, where running any bazel command either takes half a day or results in an OOM. Will look at this (and the other PR) next week with another computer", "@alextp I've removed the argument. I think there is a slight mistake in your comment, `current == 2: set self._time_after_first_step` should be `current == 1: set self._time_after_first_step`, right? The function is called after a step has been completed, so at `current==1` we get the time after the first step.", "@ngc92 I think you're right."]}, {"number": 37347, "title": "Quantization problem while reproducing person detection example", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution: Ubuntu 18.04.4 LTS\r\n- Tensorflow version: 1.15\r\n- Target platform: OpenMV Cam H7 (https://openmv.io/products/openmv-cam-h7)\r\n\r\n**Problem description**\r\nI am trying to reproduce the person detection example (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md).\r\nThe document is not completely updated but with slight modifications I am able to train, freeze and convert the model into TFLite.\r\n\r\nBecause of the target, I need full integer quantization so, I set the input and output as uint8.\r\n\r\nWhen I try to load the model in the OpenMV, the quantization layer fails with the following error:\r\n\r\n> _tensorflow/lite/micro/kernels/quantize.cc:51 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 was not true._\r\n\r\n\r\nI guess that the problem is in the post-training quantization, as the output model has an input of uint8 type and afterwards, it has a quantize layer which tries to convert uint8 to int8.\r\n\r\n\r\n**Post-training quantization**\r\n\r\n```\r\ndef representative_dataset_gen():\r\n  record_iterator = tf.python_io.tf_record_iterator(path='coco_dataset/val.record-00000-of-00010')\r\n  count = 0\r\n  for string_record in record_iterator:\r\n    example = tf.train.Example()\r\n    example.ParseFromString(string_record)\r\n    a=io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])\r\n    image = PIL.Image.open(a)\r\n    image = image.resize((96, 96))\r\n    image = image.convert('L')\r\n    array = np.array(image)\r\n    array = np.expand_dims(array, axis=2)\r\n    array = np.expand_dims(array, axis=0)\r\n    array = ((array / 127.5) - 1.0).astype(np.float32)\r\n    yield([array])\r\n    count += 1\r\n    if count > 300:\r\n        break\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph('frozen.pb',['input'], ['MobilenetV1/Predictions/Reshape_1'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.representative_dataset = representative_dataset_gen\r\n \r\ntflite_quant_model = converter.convert()\r\nopen(\"quantized.tflite\", \"wb\").write(tflite_quant_model)\r\n```\r\n\r\n", "comments": ["Yes, you're correct. It expects a float32/int16 as the input to the model. In order to use a fully int-8 model use our experimental branch - https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection_experimental. This model has some accuracy issues so it's under experimental.  I'll update this post when I find a workaround. \r\n\r\nFollow-up question: Are you required to train a model from scratch?", "We have not had a use case which uses quantize to requantize from uint8 to int8.  One hack we have used when we have an int8 model with uint8 inputs, is to keep the model as int8 and subtract 128 from each input value to convert uint8 to int8.", "If you are required to train a model from scratch, you can directly generate a fully int-8 model by updating the following lines in your code to:\r\n\r\n```\r\nconverter.inference_input_type = tf.int8\r\nconverter.inference_output_type = tf.int8\r\n```\r\n\r\nThis model will not have quantize/dequantize nodes. You can use [Netron](https://lutzroeder.github.io/netron/) to visualize it and verify. \r\n\r\nHowever, as @njeffrie mentioned above, it's your responsibility to now ensure that the inputs to the model during inference are int8 (if you have uint8 inputs from your device, then just subtract 128 from each value to convert it to int8).\r\n\r\nClosing the issue. Feel free to re-open it if your issue is not resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37347\">No</a>\n", "@Gorospe Sure! Feel free to tag/mention my Github name in a new github issue discussing the MobileNetV2 error and I can take a look at it.", "I deleted the comment as I updated Tensorflo Lite for Micro library and now it works perfectly.\r\nThank you!", "Hi Everyone,\r\n\r\nI have followed all step successfully as defined in this readme file to reproduce the same result for person detection. \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection_experimental/training_a_model.md\r\n\r\nBut I can't reproduce the expected result. It gives the same score continuously whether a person on a frame or not.\r\nHere is the output of the serial monitor:\r\n\r\n```\r\nStarting capture\r\nImage captured\r\nReading 3080 bytes from ArduCAM\r\nFinished reading\r\nDecoding JPEG and converting to greyscale\r\nImage decoded and processed\r\nPerson score: -1 No person score: 1\r\n```\r\n\r\nCan someone please help me to reproduce the same output\r\n\r\nThanks a ton,\r\nBhavika", "Hello,\r\n\r\nI just can tell that I was able to train the Mobilenet V1 0.25 and quantized it to int8 as MeghnaNatraj commented. The performancewas really bad, as I checked It with 100 images (half of them with person), and it had 50% acc with 0% precision, but (if I remember correctly) the outputs weren't always the same. \r\n\r\nHave you check whether the output variables are the indicated type (depending on the quantization, could be different)?\r\n\r\nI also tried to train different networks, such as the Mobilenet V2 and V3, and the mobilenet V2 with a depth_multiplier of 0.10 worked well for me (better accuracy with a similar size of network). Take into account that if you want to try this, you will need to change the default depth_multiplier parameter.\r\n\r\nEventhough, I'm not an expert, so I hope a contributor might help you more\r\n\r\nGood luck,\r\nJoseba\r\n\r\n", "Thanks @Gorospe for your quick reply.\r\n\r\nI have tried to implement both `person_detection `and `person_detection_experimental` model. But didn't get success to run on Arduino.\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection_experimental\r\n\r\nAs the TinyML book suggest I have tried to train models on `TensorFlow version 1.14`. I Can able to achieve good accuracy at step `eval_image_classifier.py`.\r\n\r\nIt simply indicate that my model is trained well.\r\n\r\nNow, I have doubt that problem is with quantization method. While trying mutiple quantization int8/uint8, I got the various below error message on serial monitor in Arduino. I have install `TensorFlowLite Version 1.14.0-ALPHA` on Arduino.\r\n\r\n- Invoke() called after initialization failed\r\n- Didn't find op for builtin opcode 'QUANTIZE' version '1'\r\n\r\nI have tried both below method for TFLite conversion:\r\n\r\n1.\r\n```\r\nconverter =\r\ntf.lite.TFLiteConverter.from_frozen_graph('vww_96_grayscale_frozen.pb',\r\n['input'], ['MobilenetV1/Predictions/Reshape_1'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8\r\nconverter.inference_output_type = tf.int8\r\n```\r\n\r\n2.\r\n```\r\nconverter =\r\ntf.lite.TFLiteConverter.from_frozen_graph('vww_96_grayscale_frozen.pb',\r\n['input'], ['MobilenetV1/Predictions/Reshape_1'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\n\r\ntflite_quant_model = converter.convert()\r\nopen(\"vww_96_grayscale_quantized.tflite\", \"wb\").write(tflite_quant_model)\r\n```\r\nCan you please @MeghnaNatraj @Gorospe help me to resolve my issue.\r\n\r\nThanks,\r\nBhavika\r\n\r\n", "Hello @bhavikapanara \r\n\r\nI guess the problem can be in the training / quantization phase or in the version of the library of Tensorflow Lite used for the Arduino. If I remember correctly, I used the first method you stated for quantization as well, but then I runt it on a STM32 microcontroller, where I included the library by hand, taking the necessary files from the last version of github.\r\n\r\nHave you tried to use another pretrained network? If you want, I can send you my mobilenet so that you can confirm that the library works correctly.", "I have converted our model as specified in the documentation and am hitting the same error here. All Github links from the official documentation are dead. Anyone suggest the fix for this ? \r\n\r\nhttps://www.tensorflow.org/lite/microcontrollers/get_started_low_level \r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization\r\nhttps://www.tensorflow.org/lite/convert/ \r\n\r\n`quantize.cpp:58 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 || inp was not true.\r\n19:11:56.480 -> Node QUANTIZE (number 0f) failed to prepare with status 1\r\n19:11:56.837 -> AllocateTensors() failed\r\n19:11:57.345 -> `"]}, {"number": 37346, "title": "Training of tf.keras.layers.RNN with preceding Reshape using tf.shape fails", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- Mobile device if the issue happens on mobile device: -\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.2.0-dev20200303\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: CPU only\r\n- GPU model and memory: CPU only\r\n\r\n**Describe the current behavior**\r\nThe model compiles, but training fails.\r\n\r\n**Describe the expected behavior**\r\nI would expect training to succeed.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch_size = 1\r\nnum_units = 1\r\ndim_other = 10\r\n\r\n# build model\r\nmodel = tf.keras.Sequential()\r\n\r\nmodel.add(tf.keras.layers.Input(shape=(None, dim_other)))\r\n\r\ndim_time_read = tf.shape(model.output)[1]\r\nmodel.add(tf.keras.layers.Reshape(target_shape=(dim_time_read, dim_other)))\r\n\r\nmodel.add(tf.keras.layers.RNN(cell=tf.keras.layers.GRUCell(units=num_units)))\r\n\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\n# train\r\ntraining_input1 = np.zeros([batch_size, 1, dim_other])\r\ntraining_input2 = np.zeros([batch_size, 2, dim_other])\r\ntraining_output = np.zeros([batch_size, num_units])\r\n\r\nmodel.fit(training_input1, training_output)\r\nmodel.fit(training_input2, training_output)\r\n```\r\n\r\n**Other info / logs**\r\nApparently, the Reshape layer is not required in this stripped down example. If one leaves it out, training succeeds. However, in my actual setup I need a Reshape layer before the RNN layer due to a preceding Conv2D layer.\r\n\r\nThe context is training a CRNN with variable length input. Using padding and masking is not an option unfortunately, since tf.keras.layers.Conv2D does currently not support masking.\r\n\r\nIf my usage of tf.shape is wrong, if there is an alternative or workaround, please let me know.\r\n\r\n**Traceback in case of failure:**\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: strided_slice:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 27, in <module>\r\n    model.fit(training_input, training_output)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 62, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 775, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"/home/test/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 74, in quick_execute\r\n    \"tensors, but found {}\".format(keras_symbolic_tensors))\r\ntensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'strided_slice:0' shape=() dtype=int32>]\r\n\r\n```\r\n", "comments": ["I could replicate the issue please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/ecddb668c05648186c1f19484fdffc48/untitled73.ipynb)", "I think this error is expected since it you are feeding a symbolic tensor from model.output.shape to tf.keras.layers.Reshape(). Note that target_shape param for Reshape layer is expected to be tuple of integers, rather than tensors. The error message is also quite explicit about that slide op which is produced by `dim_time_read = tf.shape(model.output)[1]`\r\n\r\nWhen u need reshape the output from previous layer, you could specify -1 if a particular dim is unknown. I can comment further if you have your model code posted.", "@qlzh727 Thank you very much, I wasn't aware of the possibility to specify -1 for a particular unknown dimension. Setting `dim_time_read = -1` works perfectly. Below you find sample code for the CRNN, in case one is interested. I am closing the ticket.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nbatch_size = 1\r\nnum_units = 2\r\nnum_filters = 1\r\ndim_other = 10\r\n\r\nmodel = tf.keras.Sequential()\r\n\r\nmodel.add(tf.keras.layers.Input(shape=(None, dim_other, 1)))\r\n\r\nmodel.add(tf.keras.layers.Conv2D(filters=num_filters, kernel_size=(10, 4), strides=[2, 1]))\r\n\r\nconv_output_width = model.output.shape[2]\r\n\r\nmodel.add(tf.keras.layers.Reshape(target_shape=(-1, conv_output_width * num_filters)))\r\n\r\nmodel.add(tf.keras.layers.RNN(cell=tf.keras.layers.GRUCell(units=num_units)))\r\n\r\nmodel.add(tf.keras.layers.Dense(units=num_units))\r\n\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n\r\n# train\r\ntraining_input1 = np.zeros([batch_size, 10, dim_other, 1])\r\ntraining_input2 = np.zeros([batch_size, 12, dim_other, 1])\r\ntraining_output = np.zeros([batch_size, num_units])\r\n\r\nmodel.fit(training_input1, training_output)\r\nmodel.fit(training_input2, training_output)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37346\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37346\">No</a>\n"]}, {"number": 37345, "title": "freebsd build tensor v2.1.0", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nFreeBSD  12.1-RELEASE-p1 FreeBSD 12.1-RELEASE-p1 GENERIC  amd64\r\n\r\n- TensorFlow installed from (source or binary):\r\nsource, \r\n- TensorFlow version:\r\nv2.1.0\r\n- Python version:\r\npython --version\r\nPython 3.7.6\r\n- Installed using virtualenv? pip? conda?:\r\npip\r\n- Bazel version (if compiling from source):\r\nbazel --version\r\nbazel 0.29.0\r\n- GCC/Compiler version (if compiling from source):\r\ngcc --version\r\ngcc (FreeBSD Ports Collection) 9.2.0\r\n\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nas per https://www.tensorflow.org/install/source\r\n\r\nrunning: bazel build --config=opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/fbc06f9baef46cade6e35d9e4137e37c/external/local_config_mlir/BUILD:1834:1: Linking of rule '@local_config_mlir//:mlir-tblgen' failed (Exit 1)\r\nld: error: undefined symbol: backtrace\r\n>>> referenced by Signals.cpp\r\n>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a\r\n\r\nld: error: undefined symbol: backtrace_symbols_fd\r\n>>> referenced by Signals.cpp\r\n>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /opt/tensorflow/tensorflow/python/tools/BUILD:97:1 Linking of rule '@local_config_mlir//:mlir-tblgen' failed (Exit 1)\r\nINFO: Elapsed time: 0.282s, Critical Path: 0.05s\r\nINFO: 1 process: 1 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["you have to link `libexecinfo`. Add `--linkopt=-lexecinfo` to your bazel command line", "it doesn't matter what I do, that opt fails:\r\n```\r\n# bazel build --config=opt --linkopts=-lexecinfo //tensorflow/tools/pip_package:build_pip_package\r\nERROR: Unrecognized option: --linkopts=-lexecinfo\r\n```\r\n\r\nedit: ignore me, linkopt! Thank you! Lets see how it goes.", "ok, I tried a clean, same error it looks/slightly different:\r\n\r\nCommand: `tensorflow# bazel build --config=opt --linkopt=-lexecinfo //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n```INFO: From ProtoCompile tensorflow/core/protobuf/tpu/compile_metadata.pb.h:\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/mlir/lite/quantization/quantization_info.pb.h:\r\nbazel-out/freebsd-py2-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nERROR: /opt/tensorflow/tensorflow/compiler/mlir/lite/quantization/BUILD:104:1: Linking of rule '//tensorflow/compiler/mlir/lite/quantization:op_quant_spec_getters_gen' failed (Exit 1)\r\nld: error: undefined symbol: backtrace\r\n>>> referenced by Signals.cpp\r\n>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a\r\n\r\nld: error: undefined symbol: backtrace_symbols_fd\r\n>>> referenced by Signals.cpp\r\n>>>               Signals.o:(PrintStackTraceSignalHandler(void*)) in archive bazel-out/host/bin/external/llvm/libsupport.a\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 691.338s, Critical Path: 43.27s\r\nINFO: 2982 processes: 2982 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "Linking libexecinfo should work. Please add `--host_linkopt=-lexecinfo`, that is do something like  `bazel build --config=opt --linkopt=-lexecinfo --host_linkopt=-lexecinfo //tensorflow/tools/pip_package:build_pip_package`. You may also need `--cxxopt=-std=c++14 --host_cxxopt=-std=c++14`", "ok, so!\r\n\r\n```\r\nbazel build --config=opt --linkopt=-lexecinfo --host_linkopt=-lexecinfo //tensorflow/tools/pip_package:build_pip_package\r\n\r\nINFO: Elapsed time: 11909.924s, Critical Path: 181.67s\r\nINFO: 19961 processes: 19961 local.\r\nINFO: Build completed successfully, 20742 total actions\r\n```\r\n\r\nThe build was successful.. and then:\r\n\r\n```\r\n# ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\nSun 8 Mar 2020 10:32:35 UTC : === Preparing sources in dir: /tmp/tmp.XXXXXXXXXX.0hYTgRyc\r\n/opt/tensorflow /opt/tensorflow\r\n/opt/tensorflow\r\n/tmp/tmp.XXXXXXXXXX.0hYTgRyc/tensorflow/include /opt/tensorflow\r\n/opt/tensorflow\r\nSun 8 Mar 2020 10:32:48 UTC : === Building wheel\r\n....\r\nSun 8 Mar 2020 10:33:19 UTC : === Output wheel file is in: /tmp/tensorflow_pkg\r\nroot@warvm-server01:/opt/tensorflow# pip install /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-freebsd_12_1_RELEASE_p1_amd64.whl\r\n....\r\n  /tmp/pip-build-env-6i11fzxp/overlay/lib/python3.7/site-packages/numpy/distutils/system_info.py:716: UserWarning: Specified path /usr/include/python3.7m is invalid.\r\n    return self.get_paths(self.section, key)\r\n  scipy/fft/_pocketfft/pypocketfft.cxx:15:10: fatal error: 'pybind11/pybind11.h' file not found\r\n  #include <pybind11/pybind11.h>\r\n           ^~~~~~~~~~~~~~~~~~~~~\r\n  1 error generated.\r\n  scipy/fft/_pocketfft/pypocketfft.cxx:15:10: fatal error: 'pybind11/pybind11.h' file not found\r\n  #include <pybind11/pybind11.h>\r\n           ^~~~~~~~~~~~~~~~~~~~~\r\n```\r\n\r\nscipy install error. Ok, time to work that out, just looks like a dependency issue.\r\n\r\n```\r\n# pkg install py37-pybind11 pybind11\r\n# pip install /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-freebsd_12_1_RELEASE_p1_amd64.whl\r\n....\r\n```\r\n\r\nI need to go to bed now and i'll leave this building, I assume it wont be short and report back in the morning. Thank you!", "o0o0o0o0o, yeah!\r\n\r\n```\r\nSuccessfully installed astor-0.8.1 cachetools-4.0.0 google-auth-1.11.2 google-auth-oauthlib-0.4.1 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.2.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\r\n```\r\n\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37345\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37345\">No</a>\n", "Are you willing to make a port of the 2.0 version?", "Trying to do this again, it now does not work:\r\n> bazel clean && bazel build --config=opt --linkopt=-lexecinfo --host_linkopt=-lexecinfo //tensorflow/tools/pip_package:build_pip_package\r\n\r\n```\r\nexternal/pybind11/include/pybind11/detail/common.h:510:30: note: previous definition is here\r\ntemplate <typename T> struct intrinsic_type<T&>                   { typedef typename intrinsic_type<T>::type type; };\r\n                             ^\r\nIn file included from tensorflow/python/framework/op_def_registry.cc:20:\r\nIn file included from ./tensorflow/python/lib/core/pybind11_status.h:21:\r\nIn file included from bazel-out/freebsd-opt/bin/external/local_config_python/python_include/pybind11/pybind11.h:44:\r\nIn file included from bazel-out/freebsd-opt/bin/external/local_config_python/python_include/pybind11/attr.h:13:\r\nIn file included from bazel-out/freebsd-opt/bin/external/local_config_python/python_include/pybind11/cast.h:13:\r\nIn file included from bazel-out/freebsd-opt/bin/external/local_config_python/python_include/pybind11/pytypes.h:12:\r\nbazel-out/freebsd-opt/bin/external/local_config_python/python_include/pybind11/detail/common.h:522:30: error: redefinition of 'intrinsic_type<T &&>'\r\ntemplate <typename T> struct intrinsic_type<T&&>                  { typedef typename intrinsic_type<T>::type type; };\r\n                             ^~~~~~~~~~~~~~~~~~~\r\nexternal/pybind11/include/pybind11/detail/common.h:511:30: note: previous definition is here\r\ntemplate <typename T> struct intrinsic_type<T&&>                  { typedef typename intrinsic_type<T>::type type; };\r\n                             ^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1295.408s, Critical Path: 81.63s\r\nINFO: 5956 processes: 5956 local.\r\nFAILED: Build did NOT complete successfully\r\n```"]}, {"number": 37344, "title": "documentation improvement for `tf.debugging.assert_shapes`", "body": "documentation fix for #37228", "comments": []}, {"number": 37343, "title": "Documentation fix: Cosine Similarity", "body": "the example calculations for cosine similarity were missing the minus sign, and the `cosine_similarity` function does not perform an average over different examples.\r\n\r\n", "comments": []}, {"number": 37342, "title": "TF2.1 cannot save model trained by distribution strategy while TF2.0 could do", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\nYes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\nUbuntu 16.04\r\n\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\nTF2.1 and TF2.0\r\n\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\nFrom source\r\n\r\n- CUDA/cuDNN version: - GPU model and memory:\r\nCUDA 10.1\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe model trained under distribution strategy could not be saved in TF2.1 while it could be saved in TF2.0.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nThe exapmle code I copy from another issue [issue ](https://github.com/tensorflow/tensorflow/issues/36477):\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef build_and_compile_model():\r\n    \r\n    input = tf.keras.Input((20,))\r\n    x = tf.keras.layers.BatchNormalization()(input)\r\n    y = tf.keras.layers.Dense(2)\r\n    \r\n    model = tf.keras.Model(inputs=input, outputs=y)\r\n    \r\n    model.compile(\r\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n        metrics=['accuracy'])\r\n    \r\n    return model\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    model = build_and_compile_model()\r\nmodel.save('test', save_format='tf')\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n![image](https://user-images.githubusercontent.com/33815430/75964388-1c719300-5f02-11ea-900b-9d7372607abe.png)\r\n#https://github.com/tensorflow/tensorflow/issues/36477\r\n\r\n\r\n", "comments": ["@JiayuanSternLi,\r\nCould you please check if it works with the latest nightly version and let us know if it works? Thanks!", "> with the latest nightly version and let us know if it works? Thanks!\r\n\r\nYup, tf2.2 is good now", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37342\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37342\">No</a>\n"]}, {"number": 37341, "title": "cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19\r\n\r\n- TensorFlow version: branch r2.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 0.29\r\n- GCC/Compiler version (if compiling from source): \r\nhadi@hadi-GL502VSK:~/tensorflow$ gcc --version\r\ngcc (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 1070 GTX 8 GB GDDR5\r\n\r\n```\r\nhadi@hadi-GL502VSK:~/tensorflow$ bazel build --verbose_failures --config=v2 //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=80\r\nINFO: Reading rc options for 'build' from /home/hadi/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2\r\nINFO: Reading rc options for 'build' from /home/hadi/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages --python_path=/usr/bin/python3 --config=xla --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 --config=cuda --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /home/hadi/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /home/hadi/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true\r\nINFO: Found applicable config definition build:tensorrt in file /home/hadi/tensorflow/.bazelrc: --action_env TF_NEED_TENSORRT=1\r\nINFO: Found applicable config definition build:cuda in file /home/hadi/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file /home/hadi/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain\r\nINFO: Found applicable config definition build:v2 in file /home/hadi/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nDEBUG: /home/hadi/.cache/bazel/_bazel_hadi/9c22e2cd2b722a33d5eae32d8a25ecc1/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nINFO: Build options --action_env and --define have changed, discarding analysis cache.\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:rocm_rocdl_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/bfloat16:bfloat16.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:arena.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:bitmap.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:bits.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:blocking_counter.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:errors.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:raw_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:refcount.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:status.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:status_test_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/core:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:array_slice.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:cleanup.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:compactptrset.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:edit_distance.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatmap.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatrep.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:flatset.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:inlined_vector.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:int_type.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:iterator_range.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:manual_constructor.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:map_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:optional.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:priority_queue_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:subtle/map_traits.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/gtl:top_n.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/hash:crc32c.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/hash:hash.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:block.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:block_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:buffered_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:compression.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:format.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:inputstream_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:proto_encode_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:random_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:record_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:record_writer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:snappy/snappy_inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:snappy/snappy_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:table_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:two_level_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_compression_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/io:zlib_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:distribution_sampler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:exact_uniform_int.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:philox_random.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:philox_random_test_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:random.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:random_distributions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:simple_philox.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/random:weighted_picker.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:base64.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:ordered_code.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:proto_serialization.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:proto_text_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/strings:stringprintf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/lib/math:math_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2172:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cpu_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:cuda_libdevice_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:demangle.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:env_time.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:error.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:file_system_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:fingerprint.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:grpc_services.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:host_info.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:human_readable_json.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:init_main.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:load_library.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logger.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:logging.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:macros.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mem.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:monitoring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:mutex.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:net.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:null_file_system.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:numa.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:platform_strings_computed.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:prefetch.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/i_cpu_utils_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_compiler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:protobuf_internal.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:regexp.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:rocm_rocdl_path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:snappy.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stream_executor_no_cuda.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:subprocess.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tensor_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:test_benchmark.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tracing.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:tstring.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:types.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:unbounded_work_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/bfloat16:bfloat16.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:arena.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:bitmap.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:bits.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:blocking_counter.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:errors.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:notification.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:raw_coding.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:refcount.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:status.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:status_test_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:stringpiece.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/core:threadpool_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:array_slice.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:cleanup.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:compactptrset.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:edit_distance.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatmap.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatrep.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:flatset.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:inlined_vector.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:int_type.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:iterator_range.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:manual_constructor.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:map_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:optional.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:priority_queue_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:subtle/map_traits.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/gtl:top_n.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/hash:crc32c.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/hash:hash.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:block.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:block_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:buffered_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:compression.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:format.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:inputstream_interface.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:path.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:proto_encode_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:random_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:record_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:record_writer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:snappy/snappy_inputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:snappy/snappy_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table_builder.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:table_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:two_level_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_compression_options.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_inputstream.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/io:zlib_outputbuffer.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:distribution_sampler.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:exact_uniform_int.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:philox_random.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:philox_random_test_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:random.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:random_distributions.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:simple_philox.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/random:weighted_picker.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:base64.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:numbers.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:ordered_code.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:proto_serialization.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:proto_text_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:scanner.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:str_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:strcat.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/strings:stringprintf.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/lib/math:math_util.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/monitoring.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:default/stacktrace_handler.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/android_armv7a_cpu_utils_helper.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/clock_cycle_profiler.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2199:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal_impl: please do not import '//tensorflow/core/platform:profile_utils/cpu_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2347:12: in srcs attribute of cc_library rule //tensorflow/core:gif_internal: please do not import '//tensorflow/core/platform:gif.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2760:1: in srcs attribute of cc_library rule //tensorflow/core:stream_executor: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2760:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2367:12: in srcs attribute of cc_library rule //tensorflow/core:jpeg_internal: please do not import '//tensorflow/core/platform:jpeg.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:dim_comparator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:group_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:sparse_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal_impl: please do not import '//tensorflow/core/util/sparse:group_iterator.cc' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2650:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:dim_comparator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:group_iterator.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in srcs attribute of cc_library rule //tensorflow/core:framework_internal: please do not import '//tensorflow/core/util/sparse:sparse_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/core/BUILD:2605:1\r\nWARNING: /home/hadi/tensorflow/tensorflow/core/BUILD:2777:12: in srcs attribute of cc_library rule //tensorflow/core:stream_executor_no_cuda: please do not import '//tensorflow/core/platform:stream_executor.h' directly. You should either move the file to this package or depend on an appropriate rule there\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:checkpoint_reader.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_status_helper.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:c_api_experimental.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_attrtype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_datatype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_status.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c:tf_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:633:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_checkpoint_reader.so: please do not import '//tensorflow/c/eager:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:684:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_toco_api.so: please do not import '//tensorflow/lite/toco/python:toco_python_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:492:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_quantize_training.so: please do not import '//tensorflow/core:graph/quantize_training.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:583:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_scoped_annotation.so: please do not import '//tensorflow/core/platform:annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:583:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_scoped_annotation.so: please do not import '//tensorflow/core/profiler/internal:python_scoped_annotation.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:c_api_experimental.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_attrtype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_datatype.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_file_statistics.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_status.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c:tf_tensor.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:667:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_py_exception_registry.so: please do not import '//tensorflow/c/eager:c_api.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:572:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_stacktrace_handler.so: please do not import '//tensorflow/core/platform:stacktrace_handler.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:526:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_util_port.so: please do not import '//tensorflow/core:util/port.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/internal:python_traceme.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/internal:traceme_recorder.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:615:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_traceme.so: please do not import '//tensorflow/core/profiler/lib:traceme.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:600:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_transform_graph.so: please do not import '//tensorflow/tools/graph_transforms:transform_graph.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:600:1: in srcs attribute of cc_binary rule //tensorflow/python:_pywrap_transform_graph.so: please do not import '//tensorflow/tools/graph_transforms:transform_utils.h' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'tf_python_pybind_extension', the error might have been caused by the macro implementation in /home/hadi/tensorflow/tensorflow/tensorflow.bzl:2454:16\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:4127:1: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: /home/hadi/tensorflow/tensorflow/python/BUILD:86:1: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 30564 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/hadi/.cache/bazel/_bazel_hadi/9c22e2cd2b722a33d5eae32d8a25ecc1/external/local_config_tensorrt/BUILD:52:1: Executing genrule @local_config_tensorrt//:tensorrt_include failed (Exit 1)\r\ncp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n```\r\n\r\n**Describe the problem**\r\nI keep getting the error **cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory** when I try to build. I dont know how to get the file\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nConfig:\r\nhadi@hadi-GL502VSK:~/tensorflow$ ./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.29.1 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.7/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.7/dist-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: \r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: y\r\nTensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.1 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 6 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include/x86_64-linux-gnu\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n", "comments": ["@HadiSDev Run `dpkg -S <filename>` to find a package that provides the given file, and install it.\r\n```bash\r\n$ dpkg -S NvInferPlugin.h\r\nlibnvinfer-plugin-dev: /usr/include/x86_64-linux-gnu/NvInferPlugin.h\r\n$ sudo apt install libnvinfer-plugin-dev\r\n```", "I followed the install cuda with apt from here:\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\nAnd I get:\r\n`dpkg-query: no path found matching pattern *NvInferPlugin.h*`\r\n\r\nIt looks like just installing libnvinfer-plugin-dev would install versions for cuda 11 so I'm not sure if that's actually the correct thing to do.\r\n\r\nI'm trying to build tensorflow v2.3.0 with cuda 10.1", "Same problem with tensorflow v2.4 with cuda 11.0. Followed tensorflow's updated gpu guide for v2.4. Ubuntu 18.04, fresh install.\r\n\r\n> ERROR: /home/hulk1/.cache/bazel/_bazel_hulk1/48430a6c18eba808de3072c91e479af7/external/local_config_tensorrt/BUILD:52:1: Executing genrule @local_config_tensorrt//:tensorrt_include failed (Exit 1)\r\n> cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory\r\n\r\n`sudo apt-get install libnvinfer-plugin7=7.1.3-1+cuda11.0`\r\n`libnvinfer-plugin7 is already the newest version (7.1.3-1+cuda11.0).`\r\n\r\n", "> sudo apt install libnvinfer-plugin-dev\r\n\r\nSuggestion from @jeethu worked, but again I was installing TF 2.4 with Cuda 11. I also did not reboot my machine after installing all the libraries with apt, which may have been the problem? \r\n\r\nEither way, seems like this needs to be incorporated into tensorflow's gpu installation instructions. Something seems off.\r\n\r\n", "@vonclites I'm adding that package to the GPU installation instructions page -- it should get through our pipeline within a couple days. Thanks for the new report!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37341\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37341\">No</a>\n"]}, {"number": 37340, "title": "dataset file-based cache uses excessively amount of memory", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nfile-based dataset cache increase excessively amount of memory.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\n  dataset = dataset.interleave(filename_to_dataset, cycle_length=num_parallel_calls,\r\n                               num_parallel_calls=num_parallel_reads)\r\n\r\n  dataset = dataset.cache(\"cache\")\r\n  dataset = readers._maybe_shuffle_and_repeat(\r\n      dataset, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@burgerkingeater please let us know which version of tensorflow are you facing the issue.please update the template it helps us resolve the issue faster.\r\nI have replicated the code shared by you please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/78b4465a9dc9c2a4928d3f6df1d89fd1/untitled75.ipynb)", "@burgerkingeater \r\nplease update on the above comment", "@burgerkingeater\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37340\">No</a>\n"]}]