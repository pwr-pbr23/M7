[{"number": 38836, "title": "NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Mac OS Catalina\r\n- TensorFlow installed from: binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.0\r\n\r\n**Describe the current behavior**\r\n\r\nI get the following error\r\n\r\n> NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array.\r\n\r\nWhen executing the following code\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\n\r\ntf.config.experimental_run_functions_eagerly(True)\r\n\r\n\r\ndef get_mnist_data(normalize=True, categorize=True):\r\n    img_rows, img_cols = 28, 28\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\n    if tf.keras.backend.image_data_format() == 'channels_first':\r\n        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n        input_shape = (1, img_rows, img_cols)\r\n    else:\r\n        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n        input_shape = (img_rows, img_cols, 1)\r\n\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n\r\n    if normalize:\r\n        x_train /= 255\r\n        x_test /= 255\r\n\r\n    if categorize:\r\n        y_train = tf.keras.utils.to_categorical(y_train)\r\n        y_test = tf.keras.utils.to_categorical(y_test)\r\n\r\n    return x_train, y_train, x_test, y_test, input_shape\r\n\r\n\r\ndef get_model(input_shape, num_classes=10):\r\n    model = tf.keras.Sequential()\r\n    model.add(tfp.layers.Convolution2DFlipout(6, input_shape=input_shape, kernel_size=3, padding=\"SAME\",\r\n                                              activation=tf.nn.relu))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add(tfp.layers.DenseFlipout(num_classes))\r\n    return model\r\n\r\n\r\ndef train():\r\n    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()\r\n\r\n    batch_size = 64\r\n\r\n    model = get_model(input_shape)\r\n\r\n    model.summary()\r\n\r\n    model.compile(loss=\"categorical_crossentropy\")\r\n\r\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=1)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\nThis error is caused by the statement `tf.config.experimental_run_functions_eagerly(True)`. However, if I remove that statement, I get another well known, older and extremely annoying problem/bug that is described in this other issue: https://github.com/tensorflow/tensorflow/issues/33729 that doesn't allow me to do anything for my work.\r\n\r\n**Describe the expected behavior**\r\n\r\nNO BUG or ERROR.\r\n\r\nSee also https://github.com/tensorflow/tensorflow/issues/38775 and https://stackoverflow.com/q/61388919/3924118.", "comments": ["@nbro \r\ni ran the code shared, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/1019acec7dad151c8950fbdee682a93d/untitled148.ipynb)", "@Saduf2019 You are not using TensorFlow 2.1.0 in that gist. \r\n\r\nThe new versions of TF are even buggier, so I would like to avoid discussions related to newer versions now (unless they solve my problems, which would be like a miracle).", "@nbro \r\nthe error on 2.1 is as per [this gist](https://colab.sandbox.google.com/gist/Saduf2019/becf16d3881ca46fdede5d74a9263b7b/untitled150.ipynb)", "@Saduf2019 You're using `tensorflow-probability   0.10.0rc0` in that gist. Use TFP 0.9.0 (the last stable version).", "@nbro \r\nI am able to replicate this issue with the specifications requested please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/cf4adafc61aedcbf3d32e1baf02ed576/38836.ipynb)\r\n\r\nI also ran the code shared by you on nightly and do not face any errros, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/1c8ac54efa0b60e865f1e845ddf8ce75/38836.ipynb) for the same", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38836\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38836\">No</a>\n", "Hi, I am also getting the exact same issue, but sorry for not sharing the code as it is on a project.\r\nIs there any solution for this?\r\ni am getting this error when _eager execution_ is enabled, but i can get it to work when it is disabled,\r\ni need _eager execution_ for debugging my code.\r\n", "so sad that he got ghosted... \r\nI've got the same error", "@Ramkumar47 \r\n\r\nPlease create a new issue as this issue is in closed status.", "@Ramkumar47 Any luck? Getting the exact same issue with this:\r\n\r\n```\r\ndata_augmentation = keras.Sequential(\r\n    [\r\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\",\r\n                                                     input_shape=(img_height,\r\n                                                                  img_width,\r\n                                                                  3)),\r\n        layers.experimental.preprocessing.RandomRotation(0.1),\r\n        layers.experimental.preprocessing.RandomZoom(0.1),\r\n    ]\r\n)\r\n```\r\n\r\n\r\nError Trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/yathavan/Documents/python_whiteboard/DRAFT_cvproject/flowers/flowers.py\", line 136, in <module>\r\n    data_augmentation = keras.Sequential(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 517, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py\", line 144, in __init__\r\n    self.add(layer)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 517, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py\", line 223, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 951, in __call__\r\n    return self._functional_construction_call(inputs, args, kwargs,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1090, in _functional_construction_call\r\n    outputs = self._keras_tensor_symbolic_call(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\r\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 863, in _infer_output_signature\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\", line 866, in call\r\n    output = control_flow_util.smart_cond(training, random_rotated_inputs,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/utils/control_flow_util.py\", line 114, in smart_cond\r\n    return smart_module.smart_cond(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/framework/smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\", line 861, in random_rotated_inputs\r\n    get_rotation_matrix(angles, img_hd, img_wd),\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\", line 757, in get_rotation_matrix\r\n    array_ops.zeros((num_angles, 2), dtypes.float32),\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2819, in wrapped\r\n    tensor = fun(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2868, in zeros\r\n    output = _constant_if_small(zero, shape, dtype, name)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2804, in _constant_if_small\r\n    if np.prod(shape) < 1000:\r\n  File \"<__array_function__ internals>\", line 5, in prod\r\n  File \"/usr/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 3030, in prod\r\n    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n  File \"/usr/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 87, in _wrapreduction\r\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 852, in __array__\r\n    raise NotImplementedError(\r\nNotImplementedError: Cannot convert a symbolic Tensor (random_rotation/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```"]}, {"number": 38835, "title": "[Intel MKL] Implement new DNNL1.x MatMul primitive cache", "body": "This PR has done:\r\n* Implement primive cache for new primitive `MatMul` in DNNL 1.x. \r\n* Remove redundant `Reorder` and change destination type for BF16 MatMul, it helps to enable primitive cache for BF16 MatMul. \r\n\r\n`MatMul` has similar semantic with InnerProduct, but they have different parameters and attributes in DNNL. Current we just use it for non-fused MatMul in TF.\r\n\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["@Zantares Can you please check @penpornk's comments and keep us posted. Thanks!", "made a rebase and addressed the code, please take a look, thanks!"]}, {"number": 38834, "title": "[Intel MKL] Implement new DNNL1.x MatMul primitive cache", "body": "This PR is to implement primive cache for new primitive `MatMul` in DNNL 1.x.\r\n`MatMul`  has similar semantic with `InnerProduct`. Current we use it for non-fused MatMul if TF.\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["Close this PR because it contains wrong commit, I'll resubmit with another PR, thanks."]}, {"number": 38833, "title": "[tflite] make evaluation tasks build", "body": "Fix dependency problem. Not all linkers can check functions in previous libraries. The `//tensorflow/lite/tools/evaluation/tasks:task_executor_main` needs `tflite::evaluation::CreateTaskExecutor(int*, char**)` which is in `:run_eval_lib`. We need `:run_eval_lib` after `task_exceutor_main`. Otherwise we'll see error like\r\n\r\n```\r\nERROR: /Volumes/Seagate5T/tf-clean/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/BUILD:41:1: Linking of rule '//tensorflow/lite/tools/evaluation/tasks/coco_object_detection:run_eval' failed (Exit 1)\r\nbazel-out/arm64-v8a-opt/bin/tensorflow/lite/tools/evaluation/tasks/libtask_executor_main.a(task_executor_main.o): In function `main':\r\n/private/var/tmp/_bazel_freedom/adcaa36b2ac85ab2f5a2434777d27f58/execroot/org_tensorflow/tensorflow/lite/tools/evaluation/tasks/task_executor_main.cc:21: undefined reference to `tflite::evaluation::CreateTaskExecutor(int*, char**)'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:run_eval failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1.753s, Critical Path: 1.15s\r\nINFO: 3 processes: 3 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nwhen building with something like\r\n```\r\nbuild --config android_arm64 \\\r\n  tensorflow/lite/tools/evaluation/tasks/coco_object_detection:run_eval\r\n```", "comments": ["close this because @multiverse-tf has a better fix"]}, {"number": 38832, "title": "Weights mismatch in model.load_weights does not rise a ValueError", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nI constructed a model using the Keras API and save the weights of the model using\r\nthe function model.save_weight for later usage.\r\n\r\nLater I rebuilt the model and loaded the weights using model.load_weights.\r\nIf during re-building the model I change parts of the architecture, for instance the number of layers. When trying to load the weights I get the reasoble error:\r\n\r\n    ValueError: You are trying to load a weight file containing 4 layers into a model with 5 layers.\r\n\r\nHowever, when I change the number of units, no ValueError is prompted.\r\nNote, that this only happens if I have eager mode disabled with:\r\n\r\n    tf.compat.v1.disable_eager_execution()\r\n\r\nIf eager mode is on it correctly outputs an error.\r\nThe question is, what does TensorFlow do if there is no error prompted? How does it deal with the mismatch of weights then?\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n    import tensorflow as tf\r\n     tf.compat.v1.disable_eager_execution()\r\n     from tensorflow.keras.models import Model\r\n     from tensorflow.keras.layers import Input, Dense, LeakyReLU\r\n\r\n    def DenseBlock(inputs, units, layers):\r\n        x = inputs\r\n        for i in range(layers):\r\n                x = Dense(units)(x)\r\n                x = LeakyReLU()(x)\r\n        return x\r\n\r\n    def model_1():\r\n            # Input\r\n            g_input = Input(shape=(10,))\r\n\r\n            # Dense block\r\n            x = DenseBlock(g_input, 12, 3)\r\n\r\n            # Final layer\r\n            g_output = Dense(1)(x)\r\n\r\n            G = Model(g_input, g_output, name='Model_1')\r\n            return G\r\n\r\n    def model_2():\r\n            # Input\r\n            g_input = Input((10,))\r\n\r\n            # Dense block\r\n            x = DenseBlock(g_input, 10, 3)\r\n\r\n            # Final layer\r\n            g_output = Dense(1)(x)\r\n\r\n            G = Model(g_input, g_output, name='Model_2')\r\n            return G\r\n\r\n    Model1 = model_1()\r\n    Model2 = model_2()\r\n\r\n    Model1.save_weights(\"weights_test.h5\")\r\n    Model2.load_weights(\"weights_test.h5\")\r\n\r\nNote that if you instead change the number of layers from 3 to 4 in model_2 then you get the expected ValueError:\r\n\r\n    ValueError: You are trying to load a weight file containing 4 layers into a model with 5 layers.\r\n\r\n Also If you comment out disabling eager mode it also gives you the expected error:\r\n\r\n    ValueError: Shapes (10, 10) and (10, 12) are incompatible\r\n\r\n", "comments": ["\r\nI have tried in colab with TF version 2.1.0 ,2.2.0-rc3 and was able to reproduce the issue.Please, find the [gist](https://colab.sandbox.google.com/gist/ravikyram/c6bf3e4c844abe7c40c9cd3e0dab93af/untitled814.ipynb) for changing layers from 3 to 4 in model_2 & [gist ](https://colab.sandbox.google.com/gist/ravikyram/273a64282b40630b6668d454382c6775/untitled815.ipynb) for disabling eager mode. Thanks!", "@ramonpeter Agree that code is not throwing an error in eager mode when there is a mismatch in the number of nodes between `Model1` and `Model2`. However, it is an intended behavior. If you want the code to throw an error, then you can select `skip_mismatch` as follows. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/ef7dcbeb4dfd467889296ca9f0823b38/untitled815.ipynb).\r\n`Model2.load_weights(\"weights_test.h5\",skip_mismatch=True)`\r\n\r\nIn eager mode (static and dynamic shapes are same), shape check happens and throws the following error \r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-a4a39fa80210> in <module>()\r\n     41 \r\n     42 Model1.save_weights(\"weights_test.h5\")\r\n---> 43 Model2.load_weights(\"weights_test.h5\",skip_mismatch=False)\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)\r\n   1126     \"\"\"\r\n   1127     if not self.is_compatible_with(other):\r\n-> 1128       raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n   1129 \r\n   1130   def most_specific_compatible_shape(self, other):\r\n\r\nValueError: Shapes (10, 10) and (10, 12) are incompatible\r\n```\r\nHowever, in graph mode (static and dynamic shapes are different), and there won't be any mismatch with the static shape. Thanks!\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "Okey. But how are the weights then loaded into the model? Obviously the number of weights disagree. So what is TensorFlow doing when I try to load the weights?\r\n\r\nThanks", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210526, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/1cd30cfe913150eac3aabf5d4c7e98e1/38832.ipynb). Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38832\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38832\">No</a>\n"]}, {"number": 38831, "title": "tf.keras.utils.get_file inconsistent behavior with keras.utils.get_file", "body": "**System information**\r\n- OS Platform and Distribution: Colab\r\n- TensorFlow version: v2.2.0-rc3-0-gaad398b5e9 2.2.0-rc3\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n`tensorflow.keras.utils.get_file` by default saves any file to a subdirectory of `~/.keras`. This behavior is specified [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc3/tensorflow/python/keras/utils/data_utils.py#L214-L215).\r\n\r\n**Describe the expected behavior**\r\nThe function should behave the same as `keras.utils.get_file`, which uses the path specified in the `KERAS_HOME` environment variable instead of `~/.keras` if it is set. This behavior is specified [here](https://github.com/keras-team/keras/blob/2.3.1/keras/utils/data_utils.py#L172-L176)\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1pfS-BgACkgkCQ9nXT_iz123lvdlTk9Hg\r\n\r\n**Other info / logs**\r\nThis is relevant especially for cases where the user is not able to specify the `fname` parameter manually to set an absolute path. One example for this mentioned in #33501 are the weights downloaded by `tensorflow.keras.applications` models. In my case, the user home directory is write-protected on the compute nodes of our HPC cluster and the fallback `/tmp` also should not be used.\r\nThe issue keras-team/keras#11923 set the behavior in keras.", "comments": ["Was able to reproduce the issue with TF v2.1, [TF v2.2.0-rc3](https://colab.research.google.com/gist/amahendrakar/63951386b8d66b2268a8da5699374db1/38831.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6731926f540542a0267a2b00ae271f5a/38831-tf-nightly.ipynb). Please find the attached gist. Thanks! ", "This is still an issue with the latest Tensorflow. By running the Colab notebook mentioned above (https://colab.research.google.com/drive/1pfS-BgACkgkCQ9nXT_iz123lvdlTk9Hg), it's shown that Tensorflow v2.5.0-0-ga4dfb8d1a71 2.5.0 still ignores the environment variable `KERAS_HOME`. Furthermore, there is no way to change the download location without modifying Python codes - the `get_file` function always use `~/.keras` or `/tmp/.keras` [1]. The issue prevents downloading tf datasets to a custom location. For example,\r\n```Python\r\nfrom tensorflow.keras.datasets import cifar10\r\ncifar10.load_data()\r\n```\r\nAlways downloads the CIFAR-10 dataset to one of the two locations mentioned above.\r\n\r\n[1] https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/utils/data_utils.py#L224-L231", "While running the above mentioned colab, I'm getting error `AttributeError: module 'keras.utils' has no attribute 'get_file'`.", "> `AttributeError: module 'keras.utils' has no attribute 'get_file'`\r\n\r\nYeah, the latest version of Keras is synced with Tensorflow, and `keras/utils/__init__.py` no longer has the line ` from .data_utils import get_file` [1]. I can call `keras.utils.data_utils.get_file`, but the latter does not have the expected behavior, either.\r\n\r\nTo reproduce the expected behavior, I need to run `pip install 'keras<2.4'` first. Here are results on my machine:\r\n```\r\n$ ipython\r\nPython 3.9.5 (default, May 24 2021, 12:50:35) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.24.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import os\r\n   ...: os.environ['KERAS_HOME'] = '/tmp/my_keras_home'\r\n   ...: \r\n   ...: import tensorflow\r\n   ...: import keras\r\n   ...: \r\n   ...: print('Tensorflow', tensorflow.version.GIT_VERSION, tensorflow.version.VERSION)\r\n   ...: print(tensorflow.keras.utils.get_file('example.html', 'http://example.com/'))\r\n   ...: print()\r\n   ...: \r\n   ...: print('Keras', keras.__version__)\r\n   ...: print(keras.utils.data_utils.get_file('example.html', 'http://example.com/'))\r\nUsing TensorFlow backend.\r\nTensorflow unknown 2.5.0\r\n/tmp/.keras/datasets/example.html\r\n\r\nKeras 2.3.1\r\n/tmp/my_keras_home/datasets/example.html\r\n\r\n```\r\n\r\nSomehow placing `!pip install 'keras<2.4'` at the first line of the Colab results in mysterious errors.\r\n\r\n[1] https://github.com/keras-team/keras/commit/b5cb82c689eac0e50522be9d2f55093dadfba24c ", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38831\">No</a>\n"]}, {"number": 38830, "title": "ImportError: DLL load failed: The specified module could not be found", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:No\r\n![tensorflow import error](https://user-images.githubusercontent.com/16195067/80086569-8825c300-8577-11ea-92c3-ffee44a67b25.png)\r\n\r\n- **TensorFlow installed from (source or binary)**:  pip install\r\n- **TensorFlow version (use command below)**: 2.1.0\r\n- **Python version**:3.6.6\r\n- **Bazel version (if compiling from source)**: --\r\n- **GCC/Compiler version (if compiling from source)**: --\r\n- **CUDA/cuDNN version**: --\r\n- **GPU model and memory**: CPU -8gb Ram \r\n- **Exact command to reproduce**: import tensorflow\r\n\r\n![tensorflow import error](https://user-images.githubusercontent.com/16195067/80086905-ff5b5700-8577-11ea-8817-674d31e620b6.png)\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n", "comments": ["@SahithiParsi \r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from T[ensorflow website.\r\n](https://www.tensorflow.org/install/source_windows)\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nAlso, refer similar issues.\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "Most likely you forgot to install the proper MSVC redistributable. See the countless duplicate issues", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "installed visual studio .issue resolved.closing the issue. Thanks for the support!!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38830\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38830\">No</a>\n"]}, {"number": 38829, "title": "Tensorboard projector does not display logits when using TPUEstimator", "body": "I develop a neural network using `TPUEstimator` in TensorFlow 2.1 to run on TPU. I try to project neural network logits using a TensorBoard as in the [proposed solution](https://github.com/tensorflow/tensorboard/issues/2471#issuecomment-580423961), but nothing is displayed. \r\n\r\nFirst, in `model_fn`, I register the projected logit (using `register_embedding`). Then I create a neural network and get logits from it (by calling `get_model`). Next, I reshape this logit (I set the name of this logit to the same as during registration) and send it to `host_call_fn`. In `host_call_fn`, I create a summary file and write the received logit into it using `tf2.summary.write (tag = 'projector', tensor = tensor_embeddings, step = gs, name = EMBEDDINGS_TENSOR_NAME)`. And nothing is displayed. Although if you initialize the random tensor in `host_call_fn`, the tensor is displayed.\r\n![image](https://user-images.githubusercontent.com/10575983/80080378-f87a1780-856a-11ea-874c-cc13aa7bfa82.png)\r\n\r\nHere is the complete program code:\r\n```\r\nimport tensorflow.compat.v1 as tf\r\nimport tensorflow as tf2\r\nfrom tensorboard.plugins import projector\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Conv2D, Activation, Input, BatchNormalization, Layer\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2\r\nimport numpy as np\r\nimport tensorflow_datasets as tfds\r\nimport os\r\n\r\nheight = 5\r\nwidth = 5\r\nn_filters = 8\r\nuse_tpu = \"COLAB_TPU_ADDR\" in os.environ\r\ntrain_batch_size = 8 * (8 if use_tpu else 1)\r\nsteps = 100\r\nlearning_rate = 1e-4\r\niterations_per_loop = 100\r\nlog_step_count_steps = 100\r\nuse_async_checkpointing = False\r\nEMBEDDINGS_TENSOR_NAME = 'reshaped_head_conv_0_0'\r\nMETA_DATA_FNAME = 'meta.tsv'\r\n\r\nif use_async_checkpointing:\r\n    save_checkpoints_steps = None\r\nelse:\r\n    save_checkpoints_steps = max(500, iterations_per_loop)\r\nmodel_dir=\"/content/my_storage/model\"\r\ndata_dir=\"/content/my_storage/datasets\"\r\ngcp_project = \"my_project\"\r\ntpu_zone = \"us-central1\"\r\n\r\nif use_tpu:\r\n    tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\n    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n                                tpu, zone=tpu_zone, project=gcp_project)\r\n    master = tpu_cluster_resolver.get_master()\r\nelse:\r\n    tpu_cluster_resolver = None\r\n    master = None\r\n\r\nclass Conv2d:\r\n    def __init__(self, x, kernel, name, strides=(1, 1), padding='SAME', activation='relu', reuse=True):\r\n        with tf.variable_scope(name, reuse=reuse):\r\n            self.name = name\r\n            self.x = tf.nn.conv2d(x, kernel, strides=strides, padding=padding, \r\n                                  name=name)\r\n            bn_name = name + '_bn'\r\n            self.x = tf.layers.batch_normalization(self.x,\r\n                                              scale=False,\r\n                                              name=bn_name)\r\n            ac_name = name + '_ac'\r\n            self.x = tf.nn.relu(self.x, name=ac_name)\r\n\r\n    def get_x(self):\r\n        return self.x\r\n\r\nclass OutputLayer(Layer):\r\n    def __init__(self, name, **kwargs):\r\n        super(OutputLayer, self).__init__(name=name, **kwargs)\r\n\r\n    def call(self, inputs):\r\n        return inputs\r\n\r\ndef make_input_fn(dataset_fn, params):\r\n\r\n    def input_fn(params):\r\n        x_train = dataset_fn()[0][\"train\"]\r\n        batch_size = params[\"batch_size\"]\r\n        y_true = tf.random.uniform(\r\n                    shape=(batch_size // (8 if use_tpu else 1), 32*32*n_filters,), \r\n                    minval=0.0, maxval=1.0, dtype=tf.dtypes.float32, seed=7777)\r\n\r\n        def preprocess(x, y):\r\n            x = tf.cast(x, tf.float32) * (1. / 255)\r\n            labels_dic = {}\r\n            for h in range(height):\r\n                for w in range(width):\r\n                    labels_dic[\"head_conv_{}_{}\".format(h, w)] = y_true\r\n            return x, labels_dic\r\n\r\n        dataset = (x_train\r\n                    .map(preprocess, \r\n                         num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n                    .repeat()\r\n                    .shuffle(128, seed=7777, reshuffle_each_iteration=True)\r\n                    .batch(batch_size, drop_remainder=True)\r\n                    .prefetch(-1))\r\n        return dataset\r\n\r\n    return input_fn\r\n\r\ndef get_model(features, theta, input_shape, reuse):\r\n    with tf.variable_scope('model', reuse=reuse):\r\n        seqs = []\r\n        i = 0\r\n        for h in range(height):\r\n            seq = []\r\n            for w in range(width):\r\n                name = \"conv_{}_{}\".format(h, w)\r\n                if seq == []:\r\n                    if h==0 and w==0: \r\n                        filters = (3, 3, 3, theta[i])\r\n                    else:\r\n                        filters = (3, 3, theta[i-1], theta[i])\r\n                else:\r\n                      filters = (3, 3, theta[i-1], theta[i])\r\n                kernel = tf.Variable(lambda: \r\n                                     tf.truncated_normal(filters, stddev=5e-2), \r\n                                     name=name)\r\n                if seq == []:\r\n                    if not(h==0 and w==0): \r\n                        features = seqs[-1][0].get_x()\r\n                else:\r\n                    features = seq[-1].get_x()\r\n                seq.append(Conv2d(\r\n                            features,\r\n                            kernel,\r\n                            name=name,\r\n                            reuse=reuse))\r\n                i += 1\r\n            seqs.append(seq)\r\n        outputs = []\r\n        heads = []\r\n        i = 0\r\n        for seq in seqs:\r\n            for x in seq:\r\n                outputs.append(OutputLayer(name=\"output_\"+x.name)(x.get_x()))\r\n                heads.append(tf.estimator.RegressionHead(\r\n                                               label_dimension=32*32*theta[i],\r\n                                               name=\"head_\"+x.name))\r\n                i += 1\r\n        head = tf.estimator.MultiHead(heads)\r\n    return head, outputs\r\n\r\ndef register_embedding(embedding_tensor_name, meta_data_fname, log_dir):\r\n  if not os.path.isdir(log_dir):\r\n     os.makedirs(log_dir)\r\n  config = projector.ProjectorConfig()\r\n  embedding = config.embeddings.add()\r\n  embedding.tensor_name = embedding_tensor_name\r\n  embedding.metadata_path = meta_data_fname\r\n  projector.visualize_embeddings(log_dir, config)\r\n\r\ndef save_labels_tsv(labels, filepath, log_dir):\r\n  if not os.path.isdir(log_dir):\r\n     os.makedirs(log_dir)\r\n  with open(os.path.join(log_dir, filepath), 'w') as f:\r\n    for label in labels:\r\n      f.write('{}\\n'.format(label))\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    def host_call_fn(gs, loss, lr, tensor_embeddings):\r\n        gs = gs[0]\r\n\r\n        with tf2.summary.create_file_writer(\r\n            model_dir,\r\n            max_queue=iterations_per_loop).as_default():\r\n          with tf2.summary.record_if(True):\r\n            tf2.summary.write(tag='projector', tensor=tensor_embeddings,\r\n                              step=gs, name=EMBEDDINGS_TENSOR_NAME)\r\n            tf2.summary.scalar('loss', loss[0], step=gs)\r\n            tf2.summary.scalar('learning_rate', lr[0], step=gs)\r\n\r\n          return tf.summary.all_v2_summary_ops()\r\n\r\n    batch_size = params['batch_size']\r\n\r\n    theta = width * height * [n_filters]\r\n\r\n    assert EMBEDDINGS_TENSOR_NAME == \"reshaped_head_conv_0_0\"\r\n    register_embedding(\"reshaped_head_conv_0_0\", META_DATA_FNAME, model_dir)\r\n\r\n    head, logits_train = get_model(features, theta, params['input_shape'], \r\n                                   reuse=False)\r\n    logits_train_dic = {}\r\n    i = 0\r\n    for h in range(height):\r\n        for w in range(width):\r\n            logits_train_dic[\"head_conv_{}_{}\".format(h, w)] = \\\r\n                tf.reshape(logits_train[i], (batch_size, 32*32*8,), \r\n                           name=\"reshaped_head_conv_{}_{}\".format(h, w))\r\n            i += 1\r\n    pred_classes = tf.argmax(logits_train, axis=1)\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=pred_classes)\r\n\r\n    new_labels = {}\r\n    for key in labels:\r\n        new_labels[key] = labels[key][0]\r\n    loss = 0.0\r\n    for key in logits_train_dic:\r\n        logit_train = logits_train_dic[key]\r\n        loss += tf.square(labels[key]-logit_train)\r\n    loss_op = tf.reduce_mean(loss)\r\n\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\r\n    if params['use_tpu']:\r\n        optimizer = tf.tpu.CrossShardOptimizer(optimizer)\r\n    train_op_fn = lambda loss_op: optimizer.minimize(\r\n                                  loss_op,\r\n                                  global_step=tf.train.get_global_step())\r\n\r\n    gs_t = tf.reshape(tf.train.get_global_step(), [1])\r\n    loss_t = tf.reshape(loss_op, [1])\r\n    lr_t = tf.reshape(params['learning_rate'], [1])\r\n\r\n    y = np.zeros((batch_size,), np.int32)\r\n    save_labels_tsv(y, META_DATA_FNAME, model_dir)\r\n\r\n    host_call = (host_call_fn, [gs_t, loss_t, lr_t, logits_train_dic[\"head_conv_0_0\"]])\r\n                \r\n    estim_specs = tf.estimator.tpu.TPUEstimatorSpec(\r\n                  mode=mode, loss=loss_op, train_op=train_op_fn(loss_op), \r\n                  host_call=host_call)\r\n    return estim_specs\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\ntf.disable_v2_behavior()\r\n\r\ndataset_fn = lambda: tfds.load(name='cifar10', with_info=True, as_supervised=True, \r\n                               try_gcs=True, data_dir=data_dir)\r\ninfo = dataset_fn()[1]\r\nn_samples = info.splits['train'].get_proto().statistics.num_examples\r\nn_classes = info.features['label'].num_classes\r\ntrain_shape = info.features['image'].shape\r\ntf.config.set_soft_device_placement(True)\r\n\r\nconfig = tf.estimator.tpu.RunConfig(\r\n              master=master,\r\n              model_dir=model_dir,\r\n              save_checkpoints_steps=save_checkpoints_steps,\r\n              log_step_count_steps=log_step_count_steps,\r\n              session_config=tf.ConfigProto(\r\n                  graph_options=tf.GraphOptions(\r\n                      rewrite_options=rewriter_config_pb2.RewriterConfig(\r\n                          disable_meta_optimizer=True))),\r\n              tpu_config=tf.estimator.tpu.TPUConfig(\r\n                  iterations_per_loop=iterations_per_loop,\r\n                  per_host_input_for_training=tf.estimator.tpu.InputPipelineConfig\r\n                  .PER_HOST_V2))\r\n\r\nparams = {\r\n    'use_tpu': use_tpu,\r\n    'input_shape': train_shape,\r\n    'learning_rate': learning_rate\r\n}\r\n\r\nmodel = tf.estimator.tpu.TPUEstimator(\r\n          model_fn, use_tpu=use_tpu,\r\n          config=config,\r\n          train_batch_size=train_batch_size,\r\n          params=params)\r\nmodel.train(make_input_fn(dataset_fn, params), steps=steps)\r\n```\r\nAnd [here](https://colab.research.google.com/gist/Kirill94a/7ab0a13a2bd836937c3be323c2287cdb/tensorboard-and-tpuestimator-issue.ipynb) is Colab Notebook (runs on CPU, since when working on TPU it is impossible to save tensorboard logs to a local disk, but the issue is the same for both CPU and TPU).\r\n\r\nHow to display logits in Tensorboard projector?", "comments": ["I have tried in colab with TF 2.1.0 with [CPU](https://colab.sandbox.google.com/gist/ravikyram/fb2348c0d946db8561fe360d62582c39/untitled809.ipynb) and [TPU](https://colab.sandbox.google.com/gist/ravikyram/0a070a698ff2dc1447cbfc1171e51a7f/untitled810.ipynb#scrollTo=aPEJqHtYB7J8).I am seeing `UnimplementedError: From /job:tpu_worker/replica:0/task:0:` with TPU. Is this the expected behavior? Thanks!\r\n`", "Yes, because when using TPU it is impossible to save the trained model and summary to a local drive (as far as I know), it can only be saved to a cloud storage bucket ([more details](https://cloud.google.com/tpu/docs/troubleshooting#cannot_use_local_filesystem)).", "OK, so how to solve this issue?", "@KirillAI \r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.7 and let us know if you are facing the same error.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38829\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38829\">No</a>\n"]}, {"number": 38827, "title": "Extremely slow retraining after loading model", "body": "When it comes to loading a model from a `.h5` file, and fitting more data to it- the training process becomes incredibly slow compared to initial training. *Slow as in 10 seconds to 43 seconds per epoch*\r\n\r\n_[https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu) was followed 04/22/2020_\r\nI use pip, I'm not using Anaconda, etc. Nor am I using a notebook.\r\n\r\n- OS = Windows 10 x64\r\n- Python version = 3.7 \r\n- Tensorflow = 2.1.0\r\n- CudaToolkit =  10.1\r\n- cuDNN SDK = 7.6\r\n- NVIDIA GPU driver = 445.75\r\n\r\n_The following I'm assuming came with tensorflow because I didn't install them myself:_\r\n\r\n- Keras-Applications = 1.0.8\r\n- Keras-Preprocessing = 1.1.0\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n_The code below trains a model, saves it, deletes it then loads the previously saved model to train again_\r\n\r\n```\r\n# Imports\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\r\nfrom tensorflow.keras.models import load_model\r\n\r\n\r\n\r\n# Create dummy dataset\r\ndummydata = pd.DataFrame(np.random.random_sample((10000, 51)))\r\n\r\npredictors_list = dummydata.columns.tolist()\r\npredictors_list.remove(predictors_list[-1])\r\n\r\nX_rgs = dummydata[predictors_list]\r\ny_rgs = dummydata[dummydata.columns[-1]]\r\n\r\n\r\n\r\n\r\n# Train, Test split\r\ntrain_length = int(len(dummydata)*0.70)\r\nX_rgs_train = X_rgs[:train_length]\r\nX_rgs_test = X_rgs[train_length:]\r\ny_rgs_train = y_rgs[:train_length]\r\ny_rgs_test = y_rgs[train_length:]\r\n\r\n\r\n\r\n\r\n# pandas to numpy\r\nX_rgs_train = X_rgs_train.to_numpy()\r\nX_rgs_test = X_rgs_test.to_numpy()\r\n\r\n\r\n\r\n# Reshape data\r\ny_rgs_train = y_rgs_train.values\r\ny_rgs_train = y_rgs_train.reshape(len(y_rgs_train), 1)\r\ny_rgs_train = np.ravel(y_rgs_train)\r\n\r\ny_rgs_test = y_rgs_test.values\r\ny_rgs_test = y_rgs_test.reshape(len(y_rgs_test), 1)\r\ny_rgs_test = np.ravel(y_rgs_test)\r\n\r\n\r\nX_train_lstm = []\r\ny_train_lstm = []\r\n\r\nfor i in range(60, X_rgs_train.shape[0]):\r\n    X_train_lstm.append(X_rgs_train[i-60:i])\r\n    y_train_lstm.append(X_rgs_train[i, 0])\r\n\r\n\r\nlen_y_train_lstm = len(y_train_lstm) \r\ny_train_lstm = y_rgs_train[:len_y_train_lstm]\r\nX_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)\r\n\r\n\r\nX_test_lstm = []\r\ny_test_lstm = []\r\n\r\nfor i in range(60, X_rgs_test.shape[0]):\r\n    X_test_lstm.append(X_rgs_test[i-60:i])\r\n    y_test_lstm.append(X_rgs_test[i, 0])\r\n\r\nlen_y_test_lstm = len(y_test_lstm) \r\ny_test_lstm = y_rgs_test[:len_y_test_lstm]\r\nX_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm)\r\n\r\n\r\n\r\n\r\n\r\n# Model architecture and vars\r\nEPOCHS = 1 \r\nBATCH_SIZE = 32 \r\n\r\nmodel = Sequential()\r\nmodel.add(LSTM(128, input_shape=(X_train_lstm.shape[1:]), return_sequences=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization()) \r\n\r\nmodel.add(LSTM(128, return_sequences=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(128, return_sequences=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(128))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(Dense(1))\r\n\r\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\r\n\r\n\r\n\r\n\r\nmodel.fit(X_train_lstm, y_train_lstm, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test_lstm, y_test_lstm)) # fit\r\nmodel.save(\"model_ISSUE.h5\") # save entire model\r\n\r\n\r\ndel model \r\n\r\n\r\nmodel = load_model('model_ISSUE.h5') # load entire model\r\nmodel.fit(X_train_lstm, y_train_lstm, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test_lstm, y_test_lstm)) # fit\r\n\r\n```\r\n\r\nOutput:\r\n```\r\n2020-04-29 22:15:21.184146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-04-29 22:15:23.126105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-04-29 22:15:23.151009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-04-29 22:15:23.155805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-04-29 22:15:23.161197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-04-29 22:15:23.166549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-04-29 22:15:23.170036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-04-29 22:15:23.176026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-04-29 22:15:23.180542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-04-29 22:15:23.191606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-04-29 22:15:23.194041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-04-29 22:15:23.196244: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-04-29 22:15:23.199798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-04-29 22:15:23.204240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-04-29 22:15:23.206834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-04-29 22:15:23.208947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-04-29 22:15:23.210997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-04-29 22:15:23.213076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-04-29 22:15:23.215705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-04-29 22:15:23.218272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-04-29 22:15:23.221158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-04-29 22:15:23.773119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-04-29 22:15:23.775514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-04-29 22:15:23.776821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-04-29 22:15:23.778805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4702 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1)\r\n\r\nTrain on 6940 samples, validate on 2940 samples\r\n2020-04-29 22:15:28.206970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-04-29 22:15:28.443339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n6940/6940 [==============================] - 10s 1ms/sample - loss: 0.8105 - mean_absolute_error: 0.6987 - val_loss: 0.1208 - val_mean_absolute_error: 0.2886\r\n\r\nTrain on 6940 samples, validate on 2940 samples\r\n6940/6940 [==============================] - 43s 6ms/sample - loss: 0.2288 - mean_absolute_error: 0.3845 - val_loss: 0.0986 - val_mean_absolute_error: 0.2647\r\n```\r\nAs seen above, it becomes incredibly slow to retrain the model after it's loaded. _(10s --> 43s)_\r\n\r\n\r\nI've seen one other person seem to have this problem and their 'solution' was to \"swap to pytorch\"\r\n\r\nHow can I go about dealing with this issue?\r\n\r\nRegards,\r\n\r\n", "comments": ["@Saduf2019 Sorry for pinging you but this has me scratching my head. Any ideas?", "@HowAlgorithmic \r\nI see that the code shared is incomplete, for us to replicate the issue faced please provide with complete stand alone code.\r\nI ran the code shared and face the error shared in [this gist.](https://colab.sandbox.google.com/gist/Saduf2019/cb7fab0d8efa80bbab3cedad329d74b1/38827.ipynb)", "> \r\n> \r\n> @HowAlgorithmic\r\n> I see that the code shared is incomplete, for us to replicate the issue faced please provide with complete stand alone code.\r\n> I ran the code shared and face the error shared in [this gist.](https://colab.sandbox.google.com/gist/Saduf2019/cb7fab0d8efa80bbab3cedad329d74b1/38827.ipynb)\r\n\r\n@Saduf2019 \r\nUpdated original post with full code. Apologies.\r\n", "I am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/b2891df366299f3ecb473d1bd3d58d24/38827.ipynb)", "@HowAlgorithmic I am not able reproduce the issue. Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/4e8e9b337b5eafbd0f8a66f227999292/38827.ipynb).\r\n\r\nI imported time module and found that original model took 17.12 sec where as the loaded model took 11.53 sec. Thanks\r\n\r\n```\r\n217/217 [==============================] - 6s 29ms/step - loss: 0.7584 - mean_absolute_error: 0.6758 - val_loss: 0.0871 - val_mean_absolute_error: 0.2533\r\nTime taken :  17.129685878753662\r\n217/217 [==============================] - 6s 29ms/step - loss: 0.2162 - mean_absolute_error: 0.3690 - val_loss: 0.0891 - val_mean_absolute_error: 0.2551\r\nTime taken :  11.534339427947998\r\n```", "@jvishnuvardhan I see. These are my results when running locally via .py in powershell _(which is what I want to be able to do)_:\r\n\r\n```\r\n6940/6940 [==============================] - 10s 1ms/sample - loss: 0.8340 - mean_absolute_error: 0.7115 - val_loss: 0.1143 - val_mean_absolute_error: 0.2813\r\nTime taken :  9.873769760131836\r\n6940/6940 [==============================] - 42s 6ms/sample - loss: 0.2509 - mean_absolute_error: 0.3996 - val_loss: 0.1338 - val_mean_absolute_error: 0.3014\r\nTime taken :  42.50903582572937\r\n```\r\nThe code used was the same in [your gist](https://colab.research.google.com/gist/jvishnuvardhan/4e8e9b337b5eafbd0f8a66f227999292/38827.ipynb) except instead of `pip install tf_nightly`, I used `pip install tensorflow`. \r\nWhen trying with tf nightly, it refused to even use my gpu\r\n\r\n\r\npip freeze:\r\n```\r\nabsl-py==0.9.0\r\nastor==0.8.1\r\ncachetools==4.1.0\r\ncertifi==2020.4.5.1\r\nchardet==3.0.4\r\ngast==0.2.2\r\ngoogle-auth==1.14.1\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.28.1\r\nh5py==2.10.0\r\nidna==2.9\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nMarkdown==3.2.1\r\nnumpy==1.18.4\r\noauthlib==3.1.0\r\nopt-einsum==3.2.1\r\npandas==1.0.3\r\npip-autoremove==0.9.1\r\nprotobuf==3.11.3\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npython-dateutil==2.8.1\r\npytz==2020.1\r\nrequests==2.23.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.0\r\nscipy==1.4.1\r\nsix==1.14.0\r\ntensorboard==2.1.1\r\ntensorflow==2.1.0\r\ntensorflow-estimator==2.1.0\r\ntermcolor==1.1.0\r\nurllib3==1.25.9\r\nWerkzeug==1.0.1\r\nwrapt==1.12.1\r\n```\r\n\r\n\r\n\r\nfull output:\r\n\r\n```\r\n2020-05-06 04:18:36.565163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-05-06 04:18:39.604719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-05-06 04:18:39.631656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-05-06 04:18:39.637489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-05-06 04:18:39.643940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-05-06 04:18:39.650458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-05-06 04:18:39.654610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-05-06 04:18:39.661559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-05-06 04:18:39.666526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-05-06 04:18:39.678926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-05-06 04:18:39.682112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-05-06 04:18:39.684808: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-05-06 04:18:39.689897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-05-06 04:18:39.697481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-05-06 04:18:39.701595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-05-06 04:18:39.706359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-05-06 04:18:39.710467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-05-06 04:18:39.714917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-05-06 04:18:39.718904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-05-06 04:18:39.723358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-05-06 04:18:39.727834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-05-06 04:18:40.445091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-06 04:18:40.448941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-05-06 04:18:40.451388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-05-06 04:18:40.455276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4702 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1)\r\nTrain on 6940 samples, validate on 2940 samples\r\n2020-05-06 04:18:45.121013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-05-06 04:18:45.369838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n6940/6940 [==============================] - 10s 1ms/sample - loss: 0.8340 - mean_absolute_error: 0.7115 - val_loss: 0.1143 - val_mean_absolute_error: 0.2813\r\nTime taken :  9.873769760131836\r\nTrain on 6940 samples, validate on 2940 samples\r\n6940/6940 [==============================] - 42s 6ms/sample - loss: 0.2509 - mean_absolute_error: 0.3996 - val_loss: 0.1338 - val_mean_absolute_error: 0.3014\r\nTime taken :  42.50903582572937\r\n```", "@HowAlgorithmic Can you please check one more time with my shared gist and let us know what times you are noticing with `tf-nightly`. Thanks!\r\nI ran several times and noticed numbers like below\r\n```\r\n217/217 [==============================] - 20s 91ms/step - loss: 0.9828 - mean_absolute_error: 0.7744 - val_loss: 0.0898 - val_mean_absolute_error: 0.2562\r\nTime taken :  27.21509337425232\r\n217/217 [==============================] - 20s 92ms/step - loss: 0.2791 - mean_absolute_error: 0.4215 - val_loss: 0.0884 - val_mean_absolute_error: 0.2551\r\nTime taken :  26.51246166229248\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38826, "title": "Failed to load the native TensorFlow runtime.", "body": "I have installed Tensorflow successfully on my computer but can not load it to use. Please help. Below is stack trace. Many thanks.\r\n\r\nMicrosoft Windows [Version 10.0.18362.778]\r\n(c) 2019 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\Users\\B>python\r\nPython 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\B\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@vosybac \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nAlso, refer similar issues.\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 #38615 and see if it helps you.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as duplicate", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38826\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38826\">No</a>\n"]}, {"number": 38825, "title": "Why the output of my tflite model running on the CPU and GPU of the Android phone is not the same", "body": "**System information**\r\n- windows10:\r\n- python3.7:\r\n- tensorflow-gpu 2.1.0 installed via pip:\r\n- androidstudio 3.6.2:\r\n- org.tensorflow:tensorflow-lite-gpu:2.1.0:\r\n- org.tensorflow:tensorflow-lite:2.1.0:\r\n\r\n**As the title says, the tflite model I converted runs on the CPU of the Android phone and the result on the GPU is inconsistent. I tried two Android phones with the same problem (SoC is Snapdragon 660 / Snapdragon 845)\r\nThe result of the model running on the Android CPU is consistent with that on the computer. I think this should explain that the model itself is not a problem?\r\n`https://github.com/TCBocean/tflite_test`\r\nThis is the code of my Android Studio project. This is a very simple project. I use Log.e to view the output.\r\nAmong them, the 52 ~ 53 behavior of MainActivity.java opens the GpuDelegate, and then deletes it to get the CPU operation result.\r\nMy GPU operation results are:\r\n```\r\n2020-04-23 14: 24: 01.682 9335-9335 / com.stars.tflite_test1 E / 1111: output1: 1.2991362E28\r\n2020-04-23 14: 24: 01.682 9335-9335 / com.stars.tflite_test1 E / 1111: output2: Infinity\r\n```\r\nMy CPU operation result is\r\n```\r\n2020-04-23 14: 25: 59.974 10058-10058 / com.stars.tflite_test1 E / 1111: output1: 378560.0\r\n2020-04-23 14: 25: 59.974 10058-10058 / com.stars.tflite_test1 E / 1111: output2: 6.6762416E10\r\n```\r\nIt can be seen that there are obvious differences\r\nBelow is my model generation code:**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass test_model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(test_model, self).__init__()\r\n        self.conv1 = tf.keras.layers.Conv2D(filters=40, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv2 = tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv3 = tf.keras.layers.Conv2D(filters=98, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv4 = tf.keras.layers.Conv2D(filters=33, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv5 = tf.keras.layers.Conv2D(filters=14, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output1 = self.conv1(inputs)\r\n        output1 = self.conv2(output1)\r\n        output_temp = output1\r\n        output1 = self.conv4(output1)\r\n        output2 = self.conv3(output1)\r\n        output2 = tf.concat([output2, output_temp], axis=-1)\r\n        output2 = self.conv5(output2)\r\n\r\n        return output1, output2\r\n\r\n\r\nmodel = test_model()\r\ntest_input = tf.ones((1, 6, 6, 1))\r\n\r\ntf.keras.backend.set_learning_phase(False)\r\ntest_output1 = model(test_input)\r\nfor output in test_output1:\r\n    print(output)\r\n\r\nmodel._set_inputs(inputs=test_input)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen(\"./save6/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nCan anyone help me see what went wrong?\r\nthank you very much : )\r\n\r\n\r\n", "comments": ["Can no one really help me?\r\nI tried to change the version in build.gradle to 1.15.0 and 2.2.0, where the output of GPU output and CPU output of version 1.15.0 are consistent, and 2.2.0 and 2.1.0 can not get the same result.\r\nBut I also found that the GPU inference speed of 2.x.0 is twice that of 1.15.0. Is it because the GPU inference of 2.x.0 has been simplified? Therefore, the output progress of 2.x.0 is not high?", "Sorry, I saw those Python code which requires me to install and compile TF (2hrs last time I was debugging substring op test) so I procrastinated and forgot about it.  Now, re-reading your stuff, I see you attached the model, so let's go with that.  I think the shapes of the weights are a bit off.\r\n\r\nDEPTHWISE_CONV_2D at the beginning takes in 1x6x6x1 and has the output of 1x6x6x40.  Then the weights must have the shape of 40x?x?x1, but you have 1x?x?x40.  GPU has a different memory layout than the CPU and will produce a different output.\r\n\r\n", "@impjdi \r\nIf you say that, this position is indeed strange. There is also a magical problem. I obviously used ordinary convolution, but it became DEPTHWISE convolution, and such a change did not cause deviation in CPU inference.", "@impjdi \r\nI found out that because the size of the 4th dimension of my input is only 1, it becomes DEPTHWISE convolution.\r\nI changed the input to (1, 6, 6, 2), and it became a normal convolution.\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\nclass test_model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(test_model, self).__init__()\r\n        self.conv1 = tf.keras.layers.Conv2D(filters=40, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv2 = tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv3 = tf.keras.layers.Conv2D(filters=98, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv4 = tf.keras.layers.Conv2D(filters=33, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n        self.conv5 = tf.keras.layers.Conv2D(filters=14, kernel_size=3, padding=\"SAME\", kernel_initializer=tf.ones)\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        output1 = self.conv1(inputs)  # 40\r\n        output1 = self.conv2(output1)  # 56\r\n        output_temp = output1\r\n        output1 = self.conv4(output1)  # 33\r\n        output2 = self.conv3(output1)  # 98\r\n        output2 = tf.concat([output2, output_temp], axis=-1)  # 98+56\r\n        output2 = self.conv5(output2)  # 14\r\n\r\n        return output1, output2\r\n\r\n\r\nmodel = test_model()\r\ntest_input = tf.ones((1, 6, 6, 2))\r\n\r\ntf.keras.backend.set_learning_phase(False)\r\ntest_output1 = model(test_input)\r\nfor output in test_output1:\r\n    print(output)\r\n\r\nmodel._set_inputs(inputs=test_input)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n# converter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\nopen(\"./save6/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\nAfter putting the modified model into my Android demo, the CPU operation result is the same as that on the PC side, while the GPU operation result is only the output2 result is the same, the output1 result still shows a big difference, because output1 is taken from the middle layer ?", "emmmmmmmmmm, I found that the output2 output is correct. It is not the credit of the first convolution changed to ordinary convolution, but I set it.\r\n```\r\nGpuDelegate.Options gpu_options = new GpuDelegate.Options();\r\ngpu_options.setPrecisionLossAllowed (false); // It seems that the default is true\r\ngpu_options.setInferencePreference (1);\r\nGpuDelegate delegate = new GpuDelegate(gpu_options);\r\n```\r\nIt seems that setPrecisionLossAllowed is working. When I comment it out, the GPU output will become abnormal again.\r\nHowever, no matter how it is set, the result of output1 will still have problems on the GPU", "I can basically be sure that setPrecisionLossAllowed (false) brought the correct result. I don't know why the official will set it to true by default without explanation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38825\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38825\">No</a>\n", "Thanks for the update @TCBocean \r\n\r\nIf that's the case, it's often either of the two (or both):\r\n* The network is not numerically stable and its design needs to be updated, or\r\n* There's a bug in the accumulator and its precision must be increased."]}, {"number": 38824, "title": "What is the minimum subset of cuda toolkit to install for tensorflow gpu to work?", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: Cuda 10.1 && cuDNN 7.6.5\r\n- GPU model and memory: Nvidia Geforce GTX 950M 2G\r\n\r\n\r\n\r\n**Describe the problem**\r\nActually, there is not much of a problem. I'm just wondering what are the necessary parts for tensorflow gpu to work. I guess a subset of CUDA runtime dynamic libraries, CUPTI, and cuDNN runtime dynamic library should suffice? However, I failed to find detailed information about this in the installation guide.", "comments": ["@lcdlyxrqy \r\ncould you please refer to these links for assistance:\r\n[link1](https://www.tensorflow.org/install/gpu)\r\n[link2](https://blog.quantinsti.com/install-tensorflow-gpu/)\r\nplease proceed with he installation and in case you face any issues you may create a issue/let us know on the same with all the details.", "> @lcdlyxrqy\r\n> could you please refer to these links for assistance:\r\n> [link1](https://www.tensorflow.org/install/gpu)\r\n> [link2](https://blog.quantinsti.com/install-tensorflow-gpu/)\r\n> please proceed with he installation and in case you face any issues you may create a issue/let us know on the same with all the details.\r\n\r\nWell, I'm not actually facing an installation issue. I just want to know which of CUDA toolkit components are necessary for tensorflow gpu to work. It could be useful when I'm trying to use tensorflow on some storage-limited machines since the CUDA and cuDNN dll libraries are quite large, even with the development tools, documentations, etc., already excluded. I've read through the installation guide already but no luck there. Are all those CUDA runtime libraries (.dll) really needed, or is there only a subset (say, only cudart64_XXX.dll) is needed?", "answer to last question is still of great interest, as it is kind of nightmare to find working combinations of driver/cuda/cudnn for ubuntu 16/18/20 to run latest tensorflow 2.2\r\n\r\nanybody of the dev know what minimal install packages of cuda are needed for tensorflow 2.2?\r\n\r\ninstalling the \"cuda-11-0 \" package as \"meta-package\" install lots of dependencies.. is there an \"non-meta\" minimal variant?\r\ni assume the packages are already her in this repo to find:\r\nhttps://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/\r\n\r\nthx, greatly appreciate some reaktion\r\n", "@lcdlyxrqy,\r\n\r\nPlease take a look at this [link](https://www.tensorflow.org/install/gpu) which provides a detailed guide on installation with GPU support along with pre requisites, and [link](https://www.tensorflow.org/install/source#gpu) which provides the compatible version of CUDA and CUDNN version for each versions of `Tensorflow`. Let me know if it helps. Thanks!", "One Year for that answer? really.\r\nAnyway. Thanks. i will look it up.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38824\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38824\">No</a>\n", "Cuda runtime components should be enough. In fact only \"CUDART\" option should be ticked, but it is not on Windows. Cuda \r\n ubuntu Docker runtime works which is very small. "]}, {"number": 38823, "title": "Could not import Tensorflow?", "body": "In my machine Tensorflow 2.1.0 is OK. The tensorflow 2.1.0 was installed using pip.\r\nBut Tensorflow 1.3.0 is not working after installing using pip in different environment.\r\nIt gives the following error: \r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Ibrahim Khalilullah\\.conda\\envs\\MaskrcnnTF1point3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>\r\n\r\n```\r\nPreviously I can run both of them (Tensorflow 2.1.0 and Tensorflow 1.3.0). However, I changed some software (reinstalling anaconda and some packages with different environments).\r\nI want to use both of them (Tensorflow 2.1.0 and Tensorflow 1.3.0).\r\nIs there any solution please?\r\n\r\nMy working platform:\r\nWindows 10\r\nAnaconda 3\r\npython 3.6\r\nMicrosoft Visual C++ Redistributable for Visual Studio 2015-2019\r\n\r\n\r\n\r\n\r\n", "comments": ["@ibrahimLearning \r\n\r\nStarting with TensorFlow 1.6, binaries use AVX instructions which may not run on older CPUs.\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\n\r\nplease refer to these existing issues on the same error faced\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204.\r\n\r\nThanks!", "TensorFlow 1.3? That is very old and not supported.\r\n\r\nI see you were able to install 2.1", "@ravikyram \r\nBut I used Tensorflow 1.3 on this machine before!!!", "> \r\n> \r\n> TensorFlow 1.3? That is very old and not supported.\r\n> \r\n> I see you were able to install 2.1\r\n\r\nThanks for your comment. I developed several projects on Tensorflow 1.3. What Will I do now? Please give some suggestion, if there any!", "You should be able to update. There is a script that helps in upgrading to TF2.0 APIs too.https://www.tensorflow.org/guide/migrate", "@ibrahimLearning Clean up (`.conda\\envs\\MaskrcnnTF1point3\\lib\\site-packages\\tensorflow`) and force-reinstall it: e.g. `pip install -I tensorflow-gpu==1.3`. If you want to use different versions, you should use different anaconda environments.", "@ibrahimLearning \r\n\r\nIs this still an issue? Was this resolved by following @wookayin  suggestion? Please close the issue if it was resolved already. Thanks!", "> @ibrahimLearning\r\n> \r\n> Is this still an issue? Was this resolved by following @wookayin suggestion? Please close the issue if it was resolved already. Thanks!\r\n\r\nNot yet resolved after following @wookayin  suggestion. However I will try later by following @mihaimaruseac suggestion. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38823\">No</a>\n", "> Are you satisfied with the resolution of your issue?\r\n> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38823)\r\n> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38823)\r\n\r\nIt will be helpful if I can run Tensorflow 1.3 on my machine in different anaconda environment.\r\n"]}, {"number": 38822, "title": "Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found", "body": "OS : Windows\r\nError:\r\nC:\\Users\\OneDrive\\Desktop\\Cheque Clearance Project\\2 Bank-Cheque-OCR-master\\Bank-Cheque-OCR-master\\scripts>python main.py\r\nUsing TensorFlow backend.\r\n2020-04-22 21:10:43.537143: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-04-22 21:10:43.546929: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-04-22 21:10:45.486138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-04-22 21:10:46.270844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-04-22 21:10:46.283679: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-04-22 21:10:46.290302: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\r\n2020-04-22 21:10:46.296248: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\r\n2020-04-22 21:10:46.303130: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\r\n2020-04-22 21:10:46.309457: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2020-04-22 21:10:46.317877: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\r\n2020-04-22 21:10:46.325132: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\r\n2020-04-22 21:10:46.330768: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-04-22 21:10:46.360475: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-04-22 21:10:46.368318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-04-22 21:10:46.379055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]\r\nTraceback (most recent call last):\r\nFile \"main.py\", line 13, in\r\nif img_color.ndim == 3:\r\nAttributeError: 'NoneType' object has no attribute 'ndim'\r\n\r\nIs there any solution for this,please do also mention the steps\r\n\r\nRegards", "comments": ["@shanethomas1029,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "yes please wait I will attach it", "> yes please wait I will attach it\r\n\r\n@shanethomas1029  \r\nAny updates regarding this? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38822\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38822\">No</a>\n", "I had the same issue\r\nI tried to verify the installation of tensorflow\r\n\r\n(venv) C:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python38\\Scripts>python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n2020-06-19 22:19:01.250810: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-06-19 22:19:01.276424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-06-19 22:19:29.912082: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n2020-06-19 22:19:29.924171: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-06-19 22:19:30.035621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Siddarth\r\n2020-06-19 22:19:30.046836: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Siddarth\r\n2020-06-19 22:19:30.202986: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-06-19 22:19:30.846192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29b99ba7da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-19 22:19:30.861260: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(814.5987, shape=(), dtype=float32)\r\n", "I had this issue\r\n2020-07-13 10:52:25.069042: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-07-13 10:52:25.132497: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\nAny help will be highly welcome thanks", "> Any help will be highly welcome thanks\r\n\r\n@nancyepey,\r\nPlease submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 38821, "title": "TF 2.1.0 savedModel input_fn from TF 1.15.x", "body": "TensorFlow installed from : binary\r\n\r\nTensorFlow version : 2.1.0\r\n\r\nPython version: 3.7.3\r\n\r\n\r\n\r\n\r\n\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\n\r\nprint(tf.__version__)\r\n\r\n############### Function we wrote ############\r\n\r\n@tf.function\r\ndef tile_nd_ragged2(a, b):\r\n  # Need a sentinel, otherwise it's hard to give it the initial shape we need.\r\n  # We'll drop the sentinel at the end.\r\n  acc = tf.ragged.constant([[[]]], dtype=a.dtype)\r\n  \r\n  print('acc is', acc)\r\n  # Work one row at a time...\r\n  # for i1 in tf.range(len(a.nested_row_lengths()[0])):    # Should be able to write `for a1, b1 in zip(a, b)` soon.\r\n  def outer_loop_test(i1, _):\r\n    return i1 < len(a.nested_row_lengths()[0])\r\n\r\n  def outer_loop_body(i1, acc):\r\n    \r\n    a1 = a[i1]\r\n    b1 = b[i1]\r\n\r\n    # If the components have variable length, we can't use a TensorArray anymore,\r\n    # so use a RaggedTensor instead.\r\n    acc1 = tf.ragged.constant([[]], dtype=a.dtype)\r\n    def loop_test(i2, _):\r\n      shape = None\r\n      if isinstance(a1, tf.RaggedTensor):\r\n        print(\" --- ragged --- \")\r\n        print(a1)\r\n        print(shape)\r\n        shape = tf.shape(a1.nested_row_lengths()[0])[0]\r\n      else:\r\n        print(\" --- tensor --- \")\r\n        print(a1)\r\n        \r\n        shape = tf.shape(a1)[0]\r\n        print(tf.shape(a1))\r\n        print(shape)\r\n\r\n      return i2 < shape\r\n      #return i2 < tf.cast(a1.nested_row_lengths()[0][i1], tf.int32)\r\n    def loop_body(i2, acc1):\r\n      #print(a1[i2])\r\n      a2 = a1[i2]\r\n      b2 = b1[i2]\r\n\r\n      for _ in range(len(b2)):\r\n        acc1 = tf.concat([acc1, tf.expand_dims(a2, 0)], axis=0)\r\n      return i2 + 1, acc1\r\n\r\n    _, acc1 = tf.while_loop(loop_test, loop_body, [0, acc1],shape_invariants=[tf.TensorShape([]), tf.TensorShape([None, None])])\r\n    acc1 = acc1[1:]  # Drop the sentinel.\r\n    acc = tf.concat([acc, tf.expand_dims(acc1, 0)], axis=0)    # Add the row to the final result.\r\n\r\n    return i1 + 1, acc\r\n\r\n  _, acc = tf.while_loop(\r\n      outer_loop_test, outer_loop_body,\r\n      [0, acc],\r\n      shape_invariants=[\r\n                        tf.TensorShape([]),\r\n                        tf.TensorShape([None, None, None])\r\n                        ]\r\n      )\r\n  acc = acc[1:]  # Drop the sentinel.\r\n  return acc\r\n\r\n\r\n\r\n###############  export_input_fn ############\r\n\r\n\r\ndef export_input_fn():\r\n    serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name =\"text\") \r\n\r\n    s1Split = tf.strings.split([serialized_tf_example],result_type=\"RaggedTensor\")\r\n    s1Split = tf.strings.split(s1Split,sep='@',result_type=\"RaggedTensor\")\r\n    result  = tile_nd_ragged2(s1Split,s1Split)\r\n    result_tf = result.to_tensor()[:1,:,:][0][0]\r\n    #result_tf = result.to_tensor()\r\n    result_int = tf.strings.to_number(result_tf,out_type=tf.int32)\r\n\r\n    features ={}\r\n    features[\"f1\"]=result_int ### this will be tf.Tensor([1], shape=(1,), dtype=int32)\r\n    \r\n    reciever_tensor = {\"text\": serialized_tf_example}\r\n    print(reciever_tensor)   \r\n    return tf.estimator.export.ServingInputReceiver(features, reciever_tensor)\r\n\r\n########### Training ###############\r\nx_feature = tf.feature_column.numeric_column('f1')\r\ntrain_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\r\n      x = {\"f1\": np.array([1., 2., 3., 4.])},      # Input features\r\n      y = np.array([1.5, 3.5, 5.5, 7.5]),         # true labels\r\n      batch_size=1,\r\n      num_epochs=1,\r\n      shuffle=True)\r\n\r\nregressor = tf.estimator.LinearRegressor(feature_columns=[x_feature])\r\nregressor.train(input_fn=train_input_fn, steps=10)\r\n\r\nsamples = np.array([1])\r\npredict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(x={\"f1\": samples},num_epochs=1,shuffle=False)\r\npredictions = list(regressor.predict(input_fn=predict_input_fn))\r\nprint(\"---------\")\r\nprint(predictions)\r\n\r\n\r\nprint(\"--------- training finished ---------\")\r\n\r\n\r\nregressor.export_saved_model(\"./model\",export_input_fn,as_text=False)\r\n```\r\n\r\nI have above code originally written in TF 1.15.0 , currently i am trying to port it to TF 2.1.0. I am basically trying to generate savedModel using customized feature transformation as above . When I run the above code it works well but its due to `tf.disable_v2_behavior()` .\r\n\r\nI am currently trying to comment out \r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n```\r\nand use \r\n\r\n```\r\nimport tensorflow  as tf\r\n```\r\nand try to convert  to TF 2.1.0 . \r\n\r\nNow TF 2.1.0 has no `tf.placeholder`  so i tried converting it using \r\n```serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name =\"text\") ```\r\n\r\nand got error \r\n```TypeError: Expected int32, got None of type 'NoneType' instead```  at```serialized_tf_example = tf.Variable(tf.zeros([None]), dtype=tf.string, name='text')```\r\n\r\nThis might not be the right way to do it but all i want is to get savedModel having feature processing inside savedModel in TF 2.1.0 . \r\n\r\nAny help will be appreciated. ", "comments": ["any-update on this ? ", "@17patelumang \r\nCan you please share the standalone code from tf 2.1 where the error is faced for us to replicate the issue, or if possible please share a gist of the code and error faced for us to analyse", "@Saduf2019  code i already provided above :) ", "@17patelumang \r\nI ran the code shared, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/106bcca967ad7fafce2572bc8029a9fc/2.ipynb) , does this confirm your issue. else please share a colab gist for us to analyse.", "@Saduf2019  yes . however i want to run it without `tf.disable_v2_behavior()` ", "@17patelumang - You can check out the Saved Model guides linked below for some pointers, and I would encourage you to post this on Stack Overflow, as there is a larger community that can help there. If you can narrow down the issue to a particular bug, please open a new issue with a minimal reproduction of that bug.\r\n\r\nhttps://www.tensorflow.org/guide/saved_model", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38821\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38821\">No</a>\n"]}, {"number": 38820, "title": "[r2.2:Cherrypick] [tf.data] Memory-safe implementation of sharing access to the memory cache", "body": null, "comments": ["Closing this PR as https://github.com/tensorflow/tensorflow/pull/38844 is in place "]}, {"number": 38819, "title": "Update documentation to switch from deprecated tf.extract_image_patches to tf.image.extract_patches", "body": "This PR is from #38818 (Thanks @fbordignon) which updates the\r\ndeprecated tf.extract_image_patches to use tf.image.extract_patches instead.\r\nAlso fix ksizes to sizes in docstring\r\n\r\nThis PR fixes #38818.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 38818, "title": "Documentation updates", "body": "ksizes should be sizes on:\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4806\r\n\r\nalso on lines 4805 and 4835 the call needs updating to\r\n\r\n`tf.image.extract_patches`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4805\r\n\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4835\r\n\r\n", "comments": ["@fbordignon Added a PR #38819 for the fix. Thanks for pointing out!", "Great, thanks!"]}, {"number": 38817, "title": "merge.concatenate layer not connected to input layer. Summary not printing correct total number of weights.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am working on training a classifier to classify two distributions with an adversary that learns the noise from the distributions. Model.summary() indicates that my adversary model is not connected to input. merge.concatenate layer seems to break the models continuity but I do not understand why.  Loss is not decreasing when I train this model. The combined model consists of 2 models (classifier and adversary) with 501 and 1276 weights respectively. Total number of trainable weights listed by model.summary is 1276 instead of 1777. \r\n\r\n**Describe the expected behavior**\r\n\r\nLoss should decrease during training, combined model should have 1777 weights and adversary model should have an entry in summary.connected to.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nN = 62500\r\n\r\n# Make data - 2 class that are 2D gaussian distributed. Gaussian noise affecting y coord of Y=1 class\r\ncov0 = np.array([[1,-0.5],[-0.5,1]])\r\ncov1 = np.array([[1,0],[0,1]])\r\n\r\ntrain_data0 = np.random.multivariate_normal([0,0],cov0,N)\r\ntrain_labels0 = np.zeros((N,1))\r\ntrain_data1 = np.random.multivariate_normal([1,1],cov1,N)\r\ntrain_labels1 = np.ones((N,1))\r\ntrain_z = np.random.normal(0,1,N*2)\r\ntrain_data1[:,1] = train_data1[:,1]+train_z[N:]\r\n#train_z[:N] = 0\r\ntrain_data = np.vstack([train_data0,train_data1])\r\ntrain_labels = np.append(train_labels0,train_labels1)\r\n\r\n#shuffle data\r\nindices = np.random.permutation(len(train_data))\r\ntrain_data = train_data[indices]\r\ntrain_labels =train_labels[indices]\r\ntrain_z = train_z[indices]\r\n\r\n#train test split\r\ntrain_data, valid_data, train_labels, valid_labels, train_z, valid_z = train_test_split(train_data,train_labels,train_z,test_size=50000)\r\n\r\n#Models \r\ninputs = Input(shape=(train_data.shape[1],))\r\n\r\n# Classifier model\r\nDx = Dense(20, activation=\"tanh\")(inputs)\r\nDx = Dense(20, activation=\"relu\")(Dx)\r\nDx = Dense(1, activation=\"sigmoid\")(Dx)\r\nf = Model([inputs],[Dx])\r\n\r\n#adversary model\r\nfrom keras.layers.merge import concatenate\r\nout = f(inputs)\r\nout = Dense(20,activation=\"relu\")(out)\r\nout = Dense(20,activation=\"relu\")(out)\r\nmu = Dense(5,activation=\"linear\")(out)\r\nsigma = Dense(5,activation=backend.exp)(out)\r\npi = Dense(5,activation=\"softmax\")(out)\r\nout = concatenate([mu,sigma,pi])\r\nr = Model([inputs],[out]) \r\n\r\n# Loss for r \r\ndef rloss(lam):\r\n  def loss_r(y_true,y_pred):\r\n    #y_true = y_true.flatten()\r\n    mu = y_pred[:,:5]\r\n    sig = y_pred[:,5:10]\r\n    pi = y_pred[:,10:]\r\n    pdf = 0\r\n    for i in range(5):\r\n      pdf += pi[:,i] *(1.0/(sig[:,i]*np.sqrt(2.0*np.pi)))*backend.exp(-((y_true-mu[:,i])**2)/(2.0*(sig[:,i]**2)))\r\n    return lam * tf.math.reduce_mean(-backend.log(pdf))\r\n  return loss_r\r\n\r\n\r\nf.compile(loss = backend.binary_crossentropy, optimizer = SGD())\r\n\r\n#combined model\r\nadv1 = Model([inputs], [f(inputs), r(inputs)])\r\nadv1.compile(loss=[backend.binary_crossentropy,rloss(-50)],optimizer=SGD(momentum=0.0))\r\n\r\n# adversary\r\nadv2 = Model(inputs,[r(inputs)])\r\nadv2.compile(loss=[rloss(1.0)],optimizer=SGD(momentum=0.0))\r\n\r\n# adv1 summary total trainable params != sum of params of individual models\r\nadv1.summary()\r\n\r\n#adv2 missing \"connected to\"\r\nadv2.summary()\r\n\r\n#Loss of adversary does not decrease as expected\r\nf.trainable = False\r\nr.trainable = True\r\nadv2.fit(train_data,train_z,epochs=20)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI am trying to reproduce the model of the paper. Paper's code is on github: https://github.com/glouppe/paper-learning-to-pivot/blob/master/code/Toy.ipynb\r\n", "comments": ["@johnmcgowan1,\r\nImporting `keras` directly instead of `tensorflow.keras` seems to work. I was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/253ed225016ac2afcd15736146df4463/38817.ipynb). \r\n\r\nYou can read more about it, from [this StackOverflow](https://stackoverflow.com/a/51831434) comment. Thanks!", "@amahendrakar Thank you for your attention. I have changed to keras but this does not solve the problem Note in rloss that you should be using (-keras.backend.log), in the colab you sent you use keras.backend.log. If you change this to negative you will see the loss still hardly decreases at all. I still expect the number of weights in the first summary to be 1777 and to have a connected comment in summary. ", "I was able to solve this by setting KERAS_BACKEND to theano. And compiling the adversary again after setting weights to trainable. Still only 1276 weights are printed, but the loss is decreasing as it should be. Functioning code here:\r\n\r\nimport numpy as np\r\nimport os\r\nimport theano\r\nos.environ['KERAS_BACKEND'] ='theano'\r\nimport keras\r\nfrom keras.layers import Input, Dense, Concatenate\r\nfrom keras import initializers, backend\r\nfrom keras.models import Model, Sequential\r\nfrom keras.optimizers import SGD\r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nN = 62500\r\n\r\n# Make data\r\ncov0 = np.array([[1,-0.5],[-0.5,1]])\r\ncov1 = np.array([[1,0],[0,1]])\r\n\r\ntrain_data0 = np.random.multivariate_normal([0,0],cov0,N)\r\ntrain_labels0 = np.zeros((N,1))\r\ntrain_data1 = np.random.multivariate_normal([1,1],cov1,N)\r\ntrain_labels1 = np.ones((N,1))\r\ntrain_z = np.random.normal(0,1,N*2)\r\ntrain_data1[:,1] = train_data1[:,1]+train_z[N:]\r\n#train_z[:N] = 0\r\ntrain_data = np.vstack([train_data0,train_data1])\r\ntrain_labels = np.append(train_labels0,train_labels1)\r\n\r\n# Plot data\r\nplt.scatter(train_data[train_labels==0,0],train_data[train_labels==0,1],c=\"r\",label='Y=0')\r\nplt.scatter(train_data[train_labels==1,0],train_data[train_labels==1,1],c=\"b\",label='Y=1')\r\nplt.legend()\r\nplt.show()\r\n\r\ntrain_z = train_z.reshape(-1,1)\r\n\r\nindices = np.random.permutation(len(train_data))\r\ntrain_data = train_data[indices]\r\ntrain_labels =train_labels[indices]\r\ntrain_z = train_z[indices]\r\n\r\n#train test split\r\ntrain_data, valid_data, train_labels, valid_labels, train_z, valid_z = train_test_split(train_data,train_labels,train_z,test_size=50000)\r\n\r\n#Models \r\ninputs = Input(shape=(train_data.shape[1],))\r\n\r\nDx = Dense(20, activation=\"tanh\")(inputs)\r\nDx = Dense(20, activation=\"relu\")(Dx)\r\nDx = Dense(1, activation=\"sigmoid\")(Dx)\r\nf = Model([inputs],[Dx])\r\n\r\nfrom keras.layers.merge import concatenate, Add\r\nout = f(inputs)\r\nout = Dense(20,activation=\"relu\")(out)\r\nout = Dense(20,activation=\"relu\")(out)\r\nmu = Dense(5,activation=\"linear\")(out)\r\nsigma = Dense(5,activation=\"exponential\")(out)\r\npi = Dense(5,activation=\"softmax\")(out)\r\nout = concatenate([mu,sigma,pi])\r\nr = Model([inputs],[out]) \r\n\r\n# Loss for r\r\ndef rloss(lam):\r\n  def loss_r(y_true,y_pred):\r\n    y_true = y_true.ravel()\r\n    mu = y_pred[:,:5]\r\n    sig = y_pred[:,5:10]\r\n    pi = y_pred[:,10:]\r\n    pdf = 0\r\n    for i in range(5):\r\n      pdf += pi[:,i] *(1.0/(sig[:,i]*np.sqrt(2.0*np.pi)))*keras.backend.exp(-((y_true-mu[:,i])**2)/(2.0*(sig[:,i]**2)))\r\n    return lam * keras.backend.mean(-keras.backend.log(pdf))\r\n  return loss_r\r\n\r\n\r\nf.compile(loss = keras.backend.binary_crossentropy, optimizer = keras.optimizers.SGD())\r\n\r\nadv1 = Model([inputs], [f(inputs), r(inputs)])\r\nadv1.compile(loss=[keras.backend.binary_crossentropy,rloss(-50)],optimizer=keras.optimizers.SGD(momentum=0.0))\r\n\r\nadv2 = Model([inputs],[r(inputs)])\r\nadv2.compile(loss=[rloss(1.0)],optimizer=keras.optimizers.SGD(momentum=0.0))\r\n\r\nadv1.summary()\r\nadv2.summary()\r\n\r\nf.trainable = False\r\nr.trainable = True\r\nadv2.compile(loss=[rloss(1.0)],optimizer=keras.optimizers.SGD(momentum=0.0))\r\nadv2.fit(train_data,train_z,epochs=20)"]}, {"number": 38816, "title": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, RESHAPE, SHAPE, SOFTMAX, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": []}, {"number": 38815, "title": "Docker Image tensorflow:latest-gpu contains 450 MB of pip cache under root directory", "body": "Docker Image tensorflow:latest-gpu contains 450+ MB of pip cache under root user's home directory.\r\n\r\nSteps to reproduce:\r\n\r\n    docker run --rm -it docker.apple.com/tensorflow/tensorflow:latest-gpu bash\r\n\r\nthen inside the container:\r\n\r\n    root@9eae8825ebd9:/# cd \r\n    root@9eae8825ebd9:~# du -h -d 1\r\n    458M\t./.cache\r\n    458M\t.\r\n\r\nI noticed this while pulling the tensorflow:2.1.0-gpu-py3 Image and then pulled latest to see if the issue had been fixed since...\r\n\r\nOther images may be affected as well, I haven't verified.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38815\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38815\">No</a>\n", "Thanks for your report! The commit linked above should remove the extra space, unless the pip cache comes from something outside of our Dockerfiles. The change should apply today or tomorrow.", "Thanks for the very quick turnaround! \r\n\r\nSmall question - not sure how to interpret the labels here (TF 2.1). \r\nDoes it describe where the problem is, and/or where the fix will be applied?\r\n\r\nIn other words, am I to expect a new docker image for 2.1.0, or should I upgrade to latest to obtain the space savings?"]}, {"number": 38814, "title": "EagerTensor - Tensorboard & Projector.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- I have used a combination of some custom code with tensorflow provided scripts. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.4\r\n- TensorFlow installed from (source or binary): pip \r\n- TensorFlow version (use command below): >>> '2.1.0'\r\n- Python version: 3.7.7\r\n- GPU model and memory: Radeon Pro 560X 4GB\r\n\r\n\r\n**Describe the current behavior**\r\nI recieve an error of trying to capture EagerTensor.\r\n\r\n:168] XLA service 0x7fd4c0649fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-22 13:05:21.461935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"unstructuredData.py\", line 32, in <module>\r\n    saver = tf.compat.v1.train.Saver([tf_data])\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 840, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\r\n    build_restore=build_restore)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 505, in _build_internal\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 206, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 110, in save_op\r\n    tensors.append(spec.tensor)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 52, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 91, in f\r\n    x = v.read_value()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 635, in read_value\r\n    value = self._read_variable_op()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 613, in _read_variable_op\r\n    self._dtype)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\", line 483, in read_variable_op\r\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 468, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1280, in convert_to_tensor\r\n    raise RuntimeError(\"Attempting to capture an EagerTensor without \"\r\nRuntimeError: Attempting to capture an EagerTensor without building a function.\r\n\r\n\r\n**Describe the expected behavior**\r\nTensorflow runs and saves the logs so tensorboard may render the results.\r\n\r\n \r\n**Standalone code to reproduce the issue**\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np \r\nimport pandas as pd \r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.decomposition import PCA\r\n\r\n\r\n##Global Varables \r\nPATH = os.getcwd()\r\n\r\n##Log path for embedding\r\nLOG_DIR = PATH + '/project-tensorboard/log-1/'\r\n\r\n##load Data\r\ndf = pd.read_csv(\"us.csv\", index_col=0)\r\n\r\n#Load the metadata\r\nmetadata = os.path.join(LOG_DIR, 'df_labels.tsv')\r\n\r\n#Generating PCA\r\npca = PCA(n_components=2, random_state=123, svd_solver='auto')\r\n\r\ndf_pca = pd.DataFrame(pca.fit_transform(df))\r\ndf_pca = df_pca.values\r\n\r\n#Tensorflow from data\r\ntf_data = tf.Variable(df_pca)\r\n\r\nwith  tf.compat.v1.Session() as sess:\r\n    tf.executing_eagerly()\r\n    saver = tf.compat.v1.train.Saver([tf_data])\r\n    sess.run(tf_data.initializer)\r\n    saver.save(sess, os.path.join(LOG_DIR, 'tf_data.ckpt'))\r\n    config = projector.ProjectorConfig()\r\n\r\n    embedding = config.embeddings.add()\r\n    embedding.tensor_name = tf_data.tensor_name\r\n\r\n    embedding.metadata_path = metadata\r\n\r\n    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\r\n```\r\n\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nGrab any COVID-19 data in a CSV format. Store it in the root directory. Run tensorboard. Run script. View EagerTensor error.\r\n\r\n**Other info / logs** \r\nI have tried v1 imports. I have tried Tensorflow GPU. I have removed and added the tf.executing_eagerly(). I am trying to build the embedding projector locally however, the EagerTensor error has no solution.\r\n", "comments": ["@d3pr3553d,\r\nIn order to expedite the trouble-shooting process, could you please share all the files you are using in your code.\r\n\r\nAlso, please add ``` (i.e. three back ticks) before and after your code to preserve the indentation and formatting. Thanks!", "> In order to expedite the trouble-shooting process, could you please share all the files you are using in your code.\r\n> \r\n> Also, please add ``` (i.e. three back ticks) before and after your code to preserve the indentation and formatting. Thanks!\r\n\r\n@d3pr3553d \r\nAny updates regarding this issue? Thanks!", "The data came from this repository. You can clone it and use it freely.\r\nhttps://github.com/nytimes/covid-19-data\r\n\r\nUse the 'us.csv' file like I did.", "@d3pr3553d,\r\nAs per [this comment](https://github.com/tensorflow/tensorflow/issues/35785#issuecomment-573547196) from a similar issue, adding the line `tf.compat.v1.disable_eager_execution()` did resolve the error.\r\n\r\nNow, I am facing a different error stating `AttributeError: 'ResourceVariable' object has no attribute 'tensor_name'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/50786f8c93e007888c2cc9d4bed75177/38814.ipynb#scrollTo=wDD4uCwDnXtc). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38813, "title": "latest-devel-gpu and devel-gpu docker images out of sync", "body": "latest-devel and devel are the same image as expected, but that's not the case for latest-devel-gpu and devel-gpu.\r\n\r\n$ docker images\r\nREPOSITORY | TAG | IMAGE ID | CREATED | SIZE\r\n-|-|-|-|-\r\ntensorflow/tensorflow | latest-devel | 468b5e19fd6a | 6 hours ago | 1.97GB\r\ntensorflow/tensorflow | devel | 468b5e19fd6a | 6 hours ago | 1.97GB\r\ntensorflow/tensorflow | latest-devel-gpu | 08aacdcc1422 | 7 hours ago | 4.17GB\r\ntensorflow/tensorflow | devel-gpu | 72b4573fd1c4| 30 hours ago | 4.17GB", "comments": ["@settle \r\nthis issue seems like a duplicate of #38811 in that case can you please close one of them as duplicate.", "@Saduf2019 #38811, #38812, and this one (#38813) are related but all different issues regarding various docker images being out of date or out of sync.", "I am closing this as a duplicate of #38812, because they are very similar.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38813\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38813\">No</a>\n"]}, {"number": 38812, "title": "Some similar Docker images don't have the same image ID", "body": "latest and 2.1.0 are the same image as expected, but that's not the case for latest-gpu and 2.1.0-gpu.\r\n\r\n$ docker images\r\nREPOSITORY | TAG | IMAGE ID | CREATED | SIZE\r\n-|-|-|-|-\r\ntensorflow/tensorflow | latest | 9bf93bf90865 | 3 months ago | 2.47GB\r\ntensorflow/tensorflow | 2.1.0 | 9bf93bf90865 | 3 months ago | 2.47GB\r\ntensorflow/tensorflow | latest-gpu | 3c0df9ad26cc | 3 months ago | 4.09GB\r\ntensorflow/tensorflow | 2.1.0-gpu | cb908459d986 | 3 months ago | 4.09GB", "comments": ["Thanks for your report. Can you explain more about the problem here? Our Docker CI is flaky and can lead to this sort of thing, and although it's not ideal, I don't know of any urgent reasons we'd want to ensure the images are exactly mirrored at all times, as long as they work.", "Moved from #38813:\r\n\r\n>latest-devel and devel are the same image as expected, but that's not the case for latest-devel-gpu and devel-gpu.\r\n>\r\n>$ docker images\r\n>REPOSITORY | TAG | IMAGE ID | CREATED | SIZE\r\n>-|-|-|-|-\r\n>tensorflow/tensorflow | latest-devel | 468b5e19fd6a | 6 hours ago | 1.97GB\r\n>tensorflow/tensorflow | devel | 468b5e19fd6a | 6 hours ago | 1.97GB\r\n>tensorflow/tensorflow | latest-devel-gpu | 08aacdcc1422 | 7 hours ago | 4.17GB\r\n>tensorflow/tensorflow | devel-gpu | 72b4573fd1c4| 30 hours ago | 4.17GB", "@angerson I agree this probably isn't the more urgent of issues and is mostly to correct the ambiguity when automating testing so as not to repeat latest- with explicit versioned images.  Also allows someone before creating a docker container to know the explicit version of latest.\r\n\r\nIn the second case (devel- tags) it probably matters less so since non-latests versions have been dropped from devel images.  In which case, maybe remove one of the duplicate tag sets to simplify things, e.g., devel and devel-gpu?", "For `devel`, we decided to publish both for a reason I don't recall; I think because `latest-devel` was probably in use by many users already, and Docker Hub does not have a convenient mechanism for deprecating tags. I've updated the Docker Hub page with an extra note to mention that they're the same, though.", "@settle Could you please check https://github.com/tensorflow/tensorflow/issues/38812#issuecomment-619171137 and let us know if you still need help on this ? if it is resolved then please feel free to move this issue to close status ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38812\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38812\">No</a>\n"]}, {"number": 38811, "title": "Need to update nightly-devel and nightly-devel-gpu docker images", "body": "Currently (as expected):\r\n$ docker run --rm -it tensorflow/tensorflow:nightly bash\r\n\\# python -c \"import tensorflow as tf; print(tf.__version__)\"\r\n2.2.0-dev20200422\r\n\r\nHowever:\r\n$ docker run --rm -it tensorflow/tensorflow:nightly-devel bash\r\n\\# python -c \"import tensorflow as tf; print(tf.__version__)\"\r\n1.12.0-rc0\r\n\r\nSame goes for the nightly-devel-gpu docker image.", "comments": ["Thanks for your report. As noted in the Docker Hub pages, `-devel` tags are not for using TensorFlow, but for developing changes to TensorFlow:\r\n\r\n>devel images come with Bazel and are ideal for developing changes to TensorFlow at master. /tensorflow_src includes the TensorFlow source tree at the latest nightly commit where the Pip package built successfully in the container. We no longer provide images for developing on top of older versions of TF (1.12.0 was the last release where this was the case).\r\n\r\nAlthough TensorFlow being installed is indeed confusing, it is not a broken image.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38811\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38811\">No</a>\n", "@angerson As I understand it, nightly tags have the most recent Pip package built from master, and together with -devel would includes the most up-to-date build environment.  My intention is to use nightly-devel for developing changes to TensorFlow (creating a new TensorFlow Lite delegate) and automate testing to catch when experimental features have changed and I need to change my code base to align with them.  However, at the moment these nightly-devel and nightly-devel-gpu docker images are about 16 months old.", "Ah, my mistake, I didn't notice you were referring to `nightly-devel` specifically. `nightly-devel` was renamed to `devel`; `latest-devel` and `devel` are the same. Please use that instead."]}, {"number": 38810, "title": "Verbose between epochs in tf version 2.2.0-rc3", "body": "Started to receive this today when **colab upgraded to 2.2.0-rc3.** Yesterday I've trained and tf.version was 2.2.0-rc2.\r\nThe model I'm using is created using tf.keras.\r\n\r\nEpoch 1/2\r\n2020-04-22 18:49:48.629597: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n1/2 [==============>...............] - ETA: 0s - loss: 0.8884 - categorical_accuracy: 0.7188 \r\n\r\n>2020-04-22 18:49:48.646518: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\r\n2020-04-22 18:49:48.646786: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 133 callback api events and 133 activity events.\r\n2020-04-22 18:49:48.663147: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48\r\n2020-04-22 18:49:48.670211: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.trace.json.gz\r\n2020-04-22 18:49:48.672098: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.026 ms\r\n2020-04-22 18:49:48.689016: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48Dumped tool data for overview_page.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.overview_page.pb\r\nDumped tool data for input_pipeline.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.kernel_stats.pb\r\n\r\n2/2 [==============================] - 1s 306ms/step - loss: 0.9273 - categorical_accuracy: 0.6797 - val_loss: 0.7531 - val_categorical_accuracy: 0.7508\r\nEpoch 2/2\r\n2/2 [==============================] - 1s 253ms/step - loss: 0.8796 - categorical_accuracy: 0.7188 - val_loss: 0.6971 - val_categorical_accuracy: 0.7675\r\n\r\n**Between epochs I'm getting all this mumbo jumbo, previous version never resulted in this.**", "comments": ["@Arvindia \r\ncan you please share a simple stand alone code for us to replicate this.", "**This is my model which worked perfectly in 2.2-rc2.**\r\n\r\n    def model_create(self, input_flatten_shape=None, reshape=None):\r\n        input_flatten = input_flatten_shape\r\n        fingerprint = layers.Input(shape=input_flatten_shape,\r\n                                   name='fingerprint_input')\r\n        fingerprint_4d = layers.Reshape(reshape)(fingerprint)\r\n        first_conv2d_layer = layers.Conv2D(64,(20,8),\r\n                                          padding='same',\r\n                                          strides=(1,1),\r\n                                          activation='relu')(fingerprint_4d)\r\n        first_dropout = layers.Dropout(self.dropout_rate)(first_conv2d_layer)\r\n        first_pool_layer = layers.MaxPool2D(pool_size=(2,2),\r\n                                           strides=(2,2), \r\n                                           padding='same')(first_dropout)\r\n        second_conv2d_layer = layers.Conv2D(64, (10,4),\r\n                                           padding='same',\r\n                                           strides=(1,1),\r\n                                           activation='relu')(first_pool_layer)\r\n        second_dropout = layers.Dropout(self.dropout_rate)(second_conv2d_layer)\r\n        second_pool_layer = layers.MaxPool2D(pool_size=(2,2),\r\n                                            strides=(2,2),\r\n                                            padding='same')(second_dropout)\r\n        #flatten = layers.Flatten()(second_pool_layer)\r\n        flatten = layers.Flatten()(second_dropout)\r\n        final_fc = layers.Dense(self.output_units, activation='softmax')(flatten)\r\n        self.model = Model(inputs=fingerprint, outputs=final_fc)\r\n        ConvModel.__model_compile(self, self.model)\r\n        return self.model\r\n\r\n    def __model_compile(self, model):\r\n        model.compile(optimizer=self.optimizer,\r\n                loss='categorical_crossentropy',\r\n                metrics=['categorical_accuracy'])\r\n        ConvModel.__logs(self)\r\n\r\n    def __logs(self):\r\n        self.model_ckpt_path = self.logs+\"/checkpoints/\"\r\n        self.model_weights = self.logs+\"/model_weights/weights\"\r\n        self.logdir_board = callbacks.TensorBoard(\r\n                                          log_dir=self.logs+\"/logs_board\", \r\n                                          histogram_freq=1000, \r\n                                          update_freq=500,\r\n                                          write_images=False, \r\n                                          embeddings_freq=0)\r\n        # Save the model after every epoch or some period.\r\n        self.model_ckpt = callbacks.ModelCheckpoint(\r\n                                          self.model_ckpt_path,\r\n                                          monitor='val_loss',\r\n                                          mode='auto',\r\n                                          save_weights_only=False,\r\n                                          save_best_only=False,\r\n                                          save_freq=500) \r\n    def model_train(self, x_train=None, y_train=None, \r\n                    x_val=None, y_val=None,\r\n                    epochs=1, batch_size=64):\r\n        #print('model_train:', time.ctime())\r\n        self.model.fit(x=x_train, y=y_train, \r\n                      validation_data=(x_val, y_val),\r\n                      epochs=epochs, batch_size=batch_size,\r\n                      callbacks=[self.logdir_board, self.model_ckpt],\r\n                      verbose=1)", "@Arvindia \r\ni ran the code on nightly, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/9444377b1b2e33f28c29ef6c80545880/untitled149.ipynb)", "@Saduf2019  I'm still getting the same error. Ran using nightly", "@Arvindia the code is not complete if you could provide a fully working standalone colab of the issue it will help faster resolution. \r\nwhich platform are you running the code on, we fixed profiler to work on Windows in 2.2.0-rc3 which resulted in these messages. These are debug messages to see if the profiling is successful.", "@goldiegadde Here is the link to my github repository : [https://github.com/Arvindia/Speech-Recognition.git](url)\r\nI'm running in colab using GPU.\r\n\r\nHere is all the verbose I'm getting from start:\r\n\r\n```\r\n2020-04-23 23:49:16.382747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n>> Downloading speech_commands_v0.02.tar.gz 100.0%\r\nSuccessfully downloaded speech_commands_v0.02.tar.gz 2428923189bytes\r\nINFO:tensorflow:Successfully downloaded speech_commands_v0.02.tar.gz (2428923189 bytes)\r\nI0423 23:50:20.806859 140270006437760 download_extract.py:47] Successfully downloaded speech_commands_v0.02.tar.gz (2428923189 bytes)\r\ncreating datasets...\r\nno.of wanted words 10\r\nno.of training files:  31228\r\nno.of validation files:  3467\r\nno.of test files:  3851\r\n2020-04-23 23:52:59.078208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-23 23:52:59.140469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:52:59.141232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\r\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\r\n2020-04-23 23:52:59.141295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-04-23 23:52:59.438951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-04-23 23:52:59.559854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-04-23 23:52:59.587268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-04-23 23:52:59.869298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-04-23 23:52:59.934182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-04-23 23:53:00.440004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-04-23 23:53:00.440200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.440883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.441404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-04-23 23:53:00.485204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\r\n2020-04-23 23:53:00.485503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f27100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-23 23:53:00.485557: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-04-23 23:53:00.657127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.658256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f26f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-04-23 23:53:00.658327: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n2020-04-23 23:53:00.659922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.660637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\r\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\r\n2020-04-23 23:53:00.660700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-04-23 23:53:00.660751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-04-23 23:53:00.660773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-04-23 23:53:00.660792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-04-23 23:53:00.660818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-04-23 23:53:00.660844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-04-23 23:53:00.660863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-04-23 23:53:00.660940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.661877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:00.662412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-04-23 23:53:00.666331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-04-23 23:53:07.080023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-04-23 23:53:07.080090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-04-23 23:53:07.080115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-04-23 23:53:07.089191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:07.089919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-04-23 23:53:07.090479: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-04-23 23:53:07.090597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\r\nCreating model ...\r\n2020-04-23 23:53:07.474138: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n2020-04-23 23:53:07.479072: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 1 GPUs\r\n2020-04-23 23:53:07.535285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\r\n2020-04-23 23:53:07.708516: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\r\nINFO:tensorflow:Collecting validation data:\r\nI0423 23:53:07.708695 140270006437760 train1.py:152] Collecting validation data:\r\n2020-04-23 23:53:07.892614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-04-23 23:53:08.811312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nINFO:tensorflow:Training:\r\nI0423 23:55:10.771466 140270006437760 train1.py:164] Training:\r\n====================================================================================================\r\nrun_step-0\r\n====================================================================================================\r\n1\r\nEpoch 1/2\r\n2020-04-23 23:55:15.142494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-04-23 23:55:19.753216: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n1/2 [==============>...............] - ETA: 0s - loss: 2.5445 - categorical_accuracy: 0.09382020-04-23 23:55:19.774968: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\r\n2020-04-23 23:55:19.775444: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 161 callback api events and 161 activity events.\r\n2020-04-23 23:55:19.802973: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19\r\n2020-04-23 23:55:19.808442: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19/f34a72ca0adf.trace.json.gz\r\n2020-04-23 23:55:19.816096: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.031 ms\r\n2020-04-23 23:55:19.817386: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19Dumped tool data for overview_page.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19/f34a72ca0adf.overview_page.pb\r\nDumped tool data for input_pipeline.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19/f34a72ca0adf.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19/f34a72ca0adf.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_19/f34a72ca0adf.kernel_stats.pb\r\n2/2 [==============================] - 1s 479ms/step - loss: 5.4786 - categorical_accuracy: 0.0938 - val_loss: 2.5750 - val_categorical_accuracy: 0.1110\r\nEpoch 2/2\r\n2/2 [==============================] - 1s 297ms/step - loss: 2.3521 - categorical_accuracy: 0.1641 - val_loss: 2.3145 - val_categorical_accuracy: 0.1073\r\n2\r\nEpoch 1/2\r\n2020-04-23 23:55:23.755341: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n1/2 [==============>...............] - ETA: 0s - loss: 2.3077 - categorical_accuracy: 0.15622020-04-23 23:55:23.774772: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\r\n2020-04-23 23:55:23.774966: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 131 callback api events and 131 activity events.\r\n2020-04-23 23:55:23.779834: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23\r\n2020-04-23 23:55:23.783134: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23/f34a72ca0adf.trace.json.gz\r\n2020-04-23 23:55:23.784225: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.026 ms\r\n2020-04-23 23:55:23.784931: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23Dumped tool data for overview_page.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23/f34a72ca0adf.overview_page.pb\r\nDumped tool data for input_pipeline.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23/f34a72ca0adf.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23/f34a72ca0adf.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_23/f34a72ca0adf.kernel_stats.pb\r\n2/2 [==============================] - 1s 323ms/step - loss: 2.3212 - categorical_accuracy: 0.1406 - val_loss: 2.3003 - val_categorical_accuracy: 0.1110\r\nEpoch 2/2\r\n2/2 [==============================] - 1s 265ms/step - loss: 2.2834 - categorical_accuracy: 0.1719 - val_loss: 2.2950 - val_categorical_accuracy: 0.1408\r\n3\r\nEpoch 1/2\r\n2020-04-23 23:55:28.022401: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n1/2 [==============>...............] - ETA: 0s - loss: 2.2768 - categorical_accuracy: 0.15622020-04-23 23:55:28.040704: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\r\n2020-04-23 23:55:28.040994: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 131 callback api events and 131 activity events.\r\n2020-04-23 23:55:28.050350: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28\r\n2020-04-23 23:55:28.054894: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28/f34a72ca0adf.trace.json.gz\r\n2020-04-23 23:55:28.056706: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.038 ms\r\n2020-04-23 23:55:28.057694: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28Dumped tool data for overview_page.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28/f34a72ca0adf.overview_page.pb\r\nDumped tool data for input_pipeline.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28/f34a72ca0adf.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28/f34a72ca0adf.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to /content/model_log_dirs/logs_board/train/plugins/profile/2020_04_23_23_55_28/f34a72ca0adf.kernel_stats.pb\r\n2/2 [==============================] - 1s 336ms/step - loss: 2.2701 - categorical_accuracy: 0.1484 - val_loss: 2.2907 - val_categorical_accuracy: 0.1315\r\nEpoch 2/2\r\n2/2 [==============================] - 1s 276ms/step - loss: 2.2100 - categorical_accuracy: 0.1875 - val_loss: 2.2971 - val_categorical_accuracy: 0.1292\r\n```\r\n\r\n\r\n", "Please use ` ``` ` around large code blocks so that they look readable (see edit of above comment)\r\n\r\nAlso, can you please try controlling the logging level? It seems somehow you are printing information logs too, not only warnings and errors.", "@mihaimaruseac I'm not printing any logs. It worked perfectly in tensorflow 2.2.0-rc2 without all those verbose between **epochs** and prior to start of the **training**.\r\nIt was as shown below\r\n\r\n```\r\n2020-04-23 23:49:16.382747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n>> Downloading speech_commands_v0.02.tar.gz 100.0%\r\nSuccessfully downloaded speech_commands_v0.02.tar.gz 2428923189bytes\r\nINFO:tensorflow:Successfully downloaded speech_commands_v0.02.tar.gz (2428923189 bytes)\r\nI0423 23:50:20.806859 140270006437760 download_extract.py:47] Successfully downloaded speech_commands_v0.02.tar.gz (2428923189 bytes)\r\ncreating datasets...\r\nno.of wanted words 10\r\nno.of training files:  31228\r\nno.of validation files:  3467\r\nno.of test files:  3851\r\nCreating model ...\r\nINFO:tensorflow:Collecting validation data:\r\nI0423 23:53:07.708695 140270006437760 train1.py:152] Collecting validation data:\r\nINFO:tensorflow:Training:\r\nI0423 23:55:10.771466 140270006437760 train1.py:164] Training:\r\n====================================================================================================\r\nrun_step-0\r\n====================================================================================================\r\n1\r\nEpoch 1/2\r\n1/2 [==============================] - 1s 479ms/step - loss: 5.4786 - categorical_accuracy: 0.0938 - val_loss: 2.5750 - val_categorical_accuracy: 0.1110\r\nEpoch 2/2\r\n2/2 [==============================] - 1s 297ms/step - loss: 2.3521 - categorical_accuracy: 0.1641 - val_loss: 2.3145 - val_categorical_accuracy: 0.1073\r\n```", "I am having the same issue. These statements follow profile dumps in the form of new folders in the tensorboard logdir (logdir/run.../train/plugins/profile/).\r\n\r\nI tried changing the TensorBoard callback parameter 'profile_batch' to different values (including 0) and it had no effect. Removing the callback altogether fixes the excessive logging and dumps, but this is obviously not a practical solution.\r\n\r\nNote that I am using v2.2.0.", "Another note is that my models are running in graph mode (not eager). This may not be compatible with the TensorBoard profiler, though I should still be able to disable it with profile_batch=0.", "This commit (https://github.com/tensorflow/tensorflow/commit/7b43b3ce08035b6c502b1aa4caa23ba59e4710f2) should have fixed https://github.com/tensorflow/tensorflow/issues/38810#issue-605005604\r\nIn 2.2.0, it should only profile once for a model.fit. So there shouldn't have many verbose logs in between epochs.\r\n\r\n\r\n@ghannum, do you have a replicate for your issue? profile_batch=0 should disable profiling in graph mode. \r\n", "@ghannum would it also be possible for you to try TF nightly and see if that will fix your issue?", "@qiuminxu I'd love to, but my GPUs are busy training a long job. @Arvindia - would you be able to test this out?", "> \r\n> \r\n> @qiuminxu I'd love to, but my GPUs are busy training a long job. @Arvindia - would you be able to test this out?\r\n\r\nSame error is cropping up no change", "Setting `profile_batch=0` does not work when using graph mode, somehow the callback keeps profiling each batch. You can use the following workaround:\r\n\r\n```python\r\ntb_cb = tf.keras.callbacks.TensorBoard(log_dir='logs', profile_batch=0)\r\n\r\ndef noop():\r\n    pass\r\n\r\ntb_cb._enable_trace = noop\r\n```", "@Arvindia https://github.com/Arvindia/Speech-Recognition.git is not accessible. Is it possible to share a fully working colab/gist for us to replicate the issue?", "@qiuminxu setting `profile_batch=0` solved the problem. I'm running in eager mode. \ud83d\udc4d Thanks everyone.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38810\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38810\">No</a>\n", "this issue is not resolved. profile_batch=0 does not achieve the desired effect in graph mode.", "@liob We couldn't reproduce your issue. That would be very helpful if you can provide a minimum reproducible example for us to debug the issue.  "]}, {"number": 38809, "title": "OSError:savedmodel file does not exist at .. path/savedmodel.pbtxt:saved model.pb", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution windows 8\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):pip\r\n- TensorFlow version:2.2.0rc3\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:yes\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:nvdia gforce 940m\r\n\r\n\r\n\r\nwhen i tried to run object detection model for first time in starting everything was going fine but at the end of the program i got this error \r\n\r\n\r\n<PIL.Image.Image image mode=RGB size=1352x900 at 0xF58A584A88>\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\nG:\\A!\\compressed\\models\\research\\object_detection\\object_detection_tutorialasdf.\r\npy in <module>\r\n    270\r\n    271 model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\r\n--> 272 masking_model = load_model(\"mask_rcnn_inception_resnet_v2_atrous_coco_20\r\n18_01_28\")\r\n    273\r\n    274\r\n\r\nG:\\A!\\compressed\\models\\research\\object_detection\\object_detection_tutorialasdf.\r\npy in load_model(model_name)\r\n    132   model_dir = pathlib.Path(model_dir)/\"saved_model\"\r\n    133\r\n--> 134   model = tf.saved_model.load(str(model_dir))\r\n    135   model = model.signatures['serving_default']\r\n    136\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\saved_mod\r\nel\\load.py in load(export_dir, tags)\r\n    526     ValueError: If `tags` don't match a MetaGraph in the SavedModel.\r\n    527   \"\"\"\r\n--> 528   return load_internal(export_dir, tags)\r\n    529\r\n    530\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\saved_mod\r\nel\\load.py in load_internal(export_dir, tags, loader_cls)\r\n    535     # sequences for nest.flatten, so we put those through as-is.\r\n    536     tags = nest.flatten(tags)\r\n--> 537   saved_model_proto = loader_impl.parse_saved_model(export_dir)\r\n    538   if (len(saved_model_proto.meta_graphs) == 1\r\n    539       and saved_model_proto.meta_graphs[0].HasField(\"object_graph_def\"))\r\n:\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\saved_mod\r\nel\\loader_impl.py in parse_saved_model(export_dir)\r\n     81                   (export_dir,\r\n     82                    constants.SAVED_MODEL_FILENAME_PBTXT,\r\n---> 83                    constants.SAVED_MODEL_FILENAME_PB))\r\n     84\r\n     85\r\n\r\nOSError: SavedModel file does not exist at: C:\\Users\\zerocoolz1\\.keras\\datasets\\\r\nmask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\\saved_model/{saved_model.pb\r\ntxt|saved_model.pb}\r\n\r\n\r\n\r\nand when i went to the directory i found these files\r\n1: checkpoint\r\n2:model.ckpt.data-00000-of-000001\r\n3:model.ckpt.index\r\n4:pipeline.config", "comments": ["@zero-coolz1 \r\n\r\nWill it be possible to share simple standalone code to reproduce the issue here.It helps us in localizing the issue faster.Thanks!", "i just ran the code extracted from object_detection_tutorial.pynb and converted that into file.py\r\n", "@zero-coolz1 \r\n\r\n Please close this thread if your issue was resolved. Thanks!", "@zero-coolz1 \r\n\r\nAny update on this issue please.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38809\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38809\">No</a>\n"]}, {"number": 38808, "title": "[r2.2:Cherrypick] Fix last partial batch loss regression in 2.2", "body": "PiperOrigin-RevId: 307666011\r\nChange-Id: I4ede295280b78e18b5b8b52f0c211d5c0a7913e2\r\n\r\nFixes issue \r\n#38596\r\n", "comments": []}, {"number": 38807, "title": "[r2.2:Cherrypick][tf.data] This CL changes how the in-memory cache resource is managed, making it possible for the cache dataset to support both a) sharing of the cache across iterators and b) serialization. As a consequence, this CL enables sharing of the cache across iterators for tf.distribute and tf.data service use cases (which require serialization support).", "body": "PiperOrigin-RevId: 307469217\nChange-Id: Ia4f4384752609b83cb10078ebeb20dfc6c8a2d8f", "comments": ["Thank you @geetachavan1. Do you plan to cherrypick the other cache CL I pointed out on the internal bug separately? I am not sure whether it is easier to do it separately or in one PR but we need both CLs to be cherrypicked.\r\n\r\nThe ID of the other CL is 307736215."]}, {"number": 38806, "title": "TF Lite GPU delegate support for desktop Linux systems", "body": "Rationale: Since OpenGL ES 3.1 is widely available for desktop and \"sort-of-desktop\" computers (like Raspberry Pi 4, Asus Tinkerboard), I believe it would be beneficial for TF Lite GPU delegate to be available there. Basically, I'm moved by the same thoughts as presented in P/R #36180.\r\n\r\nI believe most of the code should be usable on \"desktop\" systems as-is, the only problems were due to `<EGL.h>` pulling in `<X.h>` and `<Xlib.h>` with their defines. I also changed the `egl_sync.cc` code to load EGL functions dynamically instead of using `EGL_EGLEXT_PROTOTYPES` - the latter was causing the library to not load due to missing symbols in Mesa's/GLVND's EGL.\r\n\r\nI've tried to stick to the Bazel build system, and even that is basically used to add `libEGL.so` and `libGLESv2.so` to the list of linked libraries for the delegate. The option to link these libraries is `--config=gles`.", "comments": ["@impjdi can you advise on the EGL-specific changes?", "@sfalexrog  Can you please resolve conflicts? Thanks!", "Looks like most of what this PR has boiled down to is already implemented in the master branch (specifically, by this commit: https://github.com/tensorflow/tensorflow/commit/7280cb31337d73a2fc869d7ba7cdcaf5295ad26e), so I believe it is okay to close this without merging.", "https://github.com/tensorflow/tensorflow/issues/55522\r\nany hints on running tflite gpu/gl on desktop via python? arm64 or x64?"]}]