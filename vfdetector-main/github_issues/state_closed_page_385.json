[{"number": 42438, "title": "No module named 'tensorflow.python.platform' ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version: Version 2.3\r\n- Python version:3.8\r\n- Installed using virtualenv? pip? conda?: in a conda eviroment with pip\r\n\r\n\r\nI want to import tensorflow but everytime  I get \r\ntensorflow.python.platform import self_check\r\nModuleNotFoundError: No module named 'tensorflow.python.platform' \r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI have already tried different tensorflow 2.x version and also completed uninstalled anconda and reinstall it. I also tried it in different enviorments. \r\nAlso I had tensorflow running, but I update and also deleted some of the Microsoft Visual C++ Redistributable due to another problem. I did update and reinstalled all of the version but tensorflow is still not working.\r\n\r\nAlso I looked in the file and there is no python.plattform. Is there anyway to copy it or does anyone have some other solution?\r\n\r\n\r\n", "comments": ["@skgreb \r\n\r\nPlease, follow the steps as mentioned [here.](https://www.tensorflow.org/install/source_windows).\r\nHave you installed pip package?\r\nInstall the PIP package. You can either download the pre-built package, or build from source by following the instructions here: http://tensorflow.org/get_started/os_setup.md#create-pip\r\n\r\nDoes import tensorflow work in a Python shell?\r\n\r\nIf not, try reinstalling with `pip install --upgrade --force-reinstall <package>.`\r\n\r\nThanks!", "@ravikyram \r\nI tried all the setup and it finally worked by using python3.7 and also with python3.6 and with the command pip install tensorflow\r\nThank you for your help\r\n", "@skgreb \r\n\r\nPlease, close this thread if your issue was resolved.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42438\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42438\">No</a>\n"]}, {"number": 42437, "title": "sparkfun-tensorflow-codelab", "body": "Page: https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\nBroken commands:\r\n\r\nis: make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin\r\nshould be: make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge micro_speech_bin\r\n\r\nis: test -f tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin && echo \"Binary was successfully created\" || echo \"Binary is missing\"\r\nshould be: test -f tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/micro_speech.bin && echo \"Binary was successfully created\" || echo \"Binary is missing\"\r\n\r\nAnd so on. All command where is lite/experimental/micro/ > lite/micro/\r\n\r\nWhere is /AmbiqSuite-Rel2.0.0/ > /AmbiqSuite-Rel2.2.0/\r\n\r\n\r\nAnd also \"Report a mistake\" link is broken.\r\n", "comments": ["@taunoe,\r\nCould you please submit a new issue from [this link](https://github.com/googlecodelabs/tools/issues). So that we can track the issue there. Thanks!", "Ok , I will do that.", "I opened new issue there: https://github.com/googlecodelabs/tools/issues/450"]}, {"number": 42436, "title": "cudart64_101.dll and nvcuda.dll not found", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Unlike the problem where the use had a GPU, I do not have one (as far as I know),\r\nI am using latest Tensorflow on windows10 with Python3.7     Here is my Traceback:\r\nUsing TensorFlow backend.\r\n2020-08-17 18:29:14.951355: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-08-17 18:29:14.962198: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-08-17 18:30:32.541365: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n2020-08-17 18:30:32.552535: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-08-17 18:30:32.806754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: my-pc\r\n2020-08-17 18:30:32.824316: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: my-pc\r\n2020-08-17 18:30:33.789209: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d8417a3ed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-17 18:30:33.812819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n", "@nickums \r\nPlease find which directory these dlls are in, and then update your PATH to include that directory. \r\nalso make sure you update appropriate cuda environment paths.\r\nSee [https://www.tensorflow.org/install/gpu#software_requirements](https://www.tensorflow.org/install/gpu#software_requirements)\r\n\r\n\r\n#36111 #41909 #42354 [link](https://stackoverflow.com/questions/59823283/could-not-load-dynamic-library-cudart64-101-dll-on-tensorflow-cpu-only-install) [link1](https://python-forum.io/Thread-Tensorflow-cudart64-101-dll-could-not-find-dll) for the path of these files.\r\n[link2](https://stackoverflow.com/questions/49397373/tensorflow-gpu-importerror-could-not-find-nvcuda-dll/49397448) nvcuda.dll related error.", "Thanks for responding.  Looking at tensorflow hardware requirements, .it seems I need an NVIDIA GPU.\r\nNot possible with my humble laptop so I'll start again with the 'lite' android-oriented version.", "@nickums \r\nPlease move this issue to resolved status if this is not an issue anymore.\r\nIn case with the new approach you face any issues please create a new issue.", "lite is not the answer, stil need to create models with tensorflow 1st.\r\nBut can image processing be done without an NVIDIA GPU?", "@nickums \r\nIt would be slow,please try colab and let us know.\r\n\r\n", "now I've relocated nvcuda.dll  to the python DLL directory the error no oonger occurs, and my program is running\r\nalbeit without a GPU.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42436\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42436\">No</a>\n", "@nickums \r\nThanks for your update, glad the issue is resolved.", "thankyouvery much  for bringing colab to my attention, enabling me to use a GPU.  \r\nWithout one my code runs for hours...."]}, {"number": 42435, "title": "Keras `Layer.call` args signature inconsistent with actual code", "body": "## URL(s) with the issue:\r\n\r\n<https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call>\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe `call` method is listed as `call(inputs, **kwargs)`, and documents\r\nthat `inputs` is an \u201cInput tensor, or list/tuple of input tensors.\u201d But\r\nactual code usage shows that `call` may accept multiple positional\r\narguments depending on the actual layer implementation. For instance:\r\n\r\n  - <https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_add_metric_method>\r\n  - <https://github.com/tensorflow/models/blob/27bda1fc2d3557555ee8a48bbf1fb04f5c2f59e8/official/nlp/bert/bert_models.py#L68-L73>\r\n\r\nThis is confusing when reviewing code that defines a custom layer,\r\nbecause the docs for `call` don\u2019t reflect the actual usage.\r\n\r\n\r\n### Submit a pull request?\r\n\r\n> Are you planning to also submit a pull request to fix the issue?\r\n\r\nNo; I don\u2019t have enough domain expertise to be confident about the\r\ndetails.\r\n", "comments": ["@wchargin I think this was resolved with small update in the nightly docs. Please check [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer?version=nightly#call).\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 42434, "title": "pip3.7 --> 3.8 to align with the previous line", "body": "", "comments": ["We used the same Python3.7 auditwheel across all binaries. "]}, {"number": 42433, "title": "Remove unnecessary assignment in BaseResourceVariable", "body": "This PR removes an unnecessary attribute assignment as it already happens a few lines earlier:\r\nhttps://github.com/tensorflow/tensorflow/blob/c257a5d21025e32ac6f954e50c51d8657ee62fb3/tensorflow/python/ops/resource_variable_ops.py#L424", "comments": []}, {"number": 42432, "title": "TFLiteConverter fails when converting a quantized model trained with distributed strategy", "body": "most of the code is taken from tensorflow tutorials\r\nrunning on Linux 18.04\r\nTF version: v2.3.0-rc2-23-gb36436b087 2.3.0 (installed with pip)\r\npython 3.7\r\nCUDA 10.1\r\n\r\nafter training a quantized model, i'm trying to to convert to TFLite but it fails. same code with quant_enable=False works fine\r\n\r\n**Standalone code to reproduce the issue**\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, Input, Model, regularizers, models, optimizers, losses\r\nimport tensorflow_model_optimization as tfmot\r\nfrom functools import partial\r\nfrom pathlib import Path\r\nfrom models.network_factory import get_network\r\n\r\n\r\ndef get_model():\r\n    conv_params = {'padding': 'same', 'use_bias': False, 'strides': 2,\r\n                   'kernel_regularizer': regularizers.l2(0.01)}\r\n\r\n    inputs = Input(shape=(32, 32, 3))\r\n    x = layers.Conv2D(16, 3, **conv_params)(inputs)\r\n    x = layers.BatchNormalization()(x)\r\n    x = layers.ReLU()(x)\r\n    x = layers.Conv2D(32, 3, **conv_params)(x)\r\n    x = layers.BatchNormalization()(x)\r\n    x = layers.ReLU()(x)\r\n    x = layers.Conv2D(64, 3, **conv_params)(x)\r\n    x = layers.BatchNormalization()(x)\r\n    x = layers.ReLU()(x)\r\n    x = layers.Flatten()(x)\r\n    x = layers.Dropout(0.7)(x)\r\n    x = layers.Dense(10, kernel_regularizer=regularizers.l2(0.01))(x)\r\n    return Model(inputs=inputs, outputs=x, name=\"SimpleNet\")\r\n\r\n\r\ndef apply_quantization_to_layer(layer):\r\n    # default quantization\r\n    if type(layer) in [layers.Conv2D, layers.DepthwiseConv2D,\r\n                       layers.Dense, layers.BatchNormalization,\r\n                       layers.Add, layers.ReLU]:\r\n        return tfmot.quantization.keras.quantize_annotate_layer(layer)\r\n    return layer\r\n\r\n\r\ndef quantize_model(in_model, clone_fn=apply_quantization_to_layer):\r\n    annotated_model = models.clone_model(in_model, clone_function=partial(clone_fn))\r\n    with tfmot.quantization.keras.quantize_scope():\r\n        quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\r\n    return quant_aware_model\r\n\r\n\r\nquant_enable = True\r\nstrategy = tf.distribute.MirroredStrategy()\r\nprint(f\"\\nnumber of GPUs: {strategy.num_replicas_in_sync}\\n\")\r\nwith strategy.scope():\r\n    model = get_model()\r\n    model.summary()\r\n\r\n    # Quantize the model.\r\n    if quant_enable:\r\n        # raise Exception(\"need to debug distributed training with quantization\")\r\n        model = quantize_model(model)\r\n\r\n    model.compile(optimizer=optimizers.Adam(),\r\n                  loss=losses.SparseCategoricalCrossentropy(from_logits=True),\r\n                  metrics=['accuracy'])\r\nnum_replicas_in_sync = strategy.num_replicas_in_sync\r\n\r\nbatch_size, val_batch_size = 5, 5\r\nds_train = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(100)],\r\n                                               [np.random.randint(10) for _ in range(100)]))\r\nds_train = ds_train.batch(batch_size)\r\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\r\nds_test = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(20)],\r\n                                              [np.random.randint(10) for _ in range(20)]))\r\nds_test = ds_test.batch(val_batch_size)\r\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nhistory = model.fit(ds_train, epochs=4, validation_data=ds_test, verbose=1)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = False\r\ntflite_model = converter.convert()", "comments": ["@eladc4,\r\nOn running the code with TF v2.3, I am facing an error stating `TypeError: tuple indices must be integers or slices, not MirroredVariable`. \r\n\r\nHowever, the issue seems to be resolved with the latest TF-nightly, as I was able to convert the model without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6e113688e93a5f8aaea0ca52d12c2fea/42432-tf-nightly.ipynb). Thanks!", "that's the error i get, so i guess i'll be solved in TF 2.4\r\nthanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42432\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42432\">No</a>\n"]}, {"number": 42431, "title": "Remove unreachable codes of Bincount GPU kernels", "body": "Remove unreachable codes of Bincount GPU kernels", "comments": []}, {"number": 42430, "title": "Pre-trained weights channel ordering clarification.", "body": "Hello!\r\n\r\nMy question is about the pre-trained mobilenet-v1 model weights provided in tensorflow.keras.applications. When I use it in the TF default HWC format, everything seems to be fine, but when I set the keras backend to `'channels_first'` the weights doesn't seem to change. **Does this setting change the weight ordering, or does it only change the way the layers are interpreted?** \r\n\r\nI already asked it on Stackoverflow with the tensorflow TAG but no answers so far:\r\nhttps://stackoverflow.com/q/63284543/10453391\r\n\r\nIf it doesn't change, what is the correct way to change the pre-trained weights ordering?` keras.utils.conv_utils.convert_kernel` is deprecated but TensorRT leans on channels first ordering heavly so I do not understand the lack of support for this.\r\n\r\nThis issue was already asked long ago but it is pretty outdated:\r\nhttps://github.com/keras-team/keras/issues/3994\r\n\r\nThanks in advance!\r\n", "comments": ["@norbertmarko Usually in some cases changing the order of channels (with tensorflow backend) might cause some problems. Working with \"channels_last\" is less troublesome because of a great amount of other (non convolutional) functions that work only on the last axis.\r\n\r\nI think this is the reason for the issue.\r\n\r\nAlthough as explained [here](https://stackoverflow.com/questions/44774234/why-tensorflow-uses-channel-last-ordering-instead-of-row-major), the order of channels shouldn't matter. I am not sure why this is happening.\r\n\r\nCan you please provide us a  **minimal example(gist) like mnist** or try reproducing this issue on a much simpler dataset, reproducing the entire issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42429, "title": "Why is Graph 4x slower than Eager on large model? (TF 2.3.0)", "body": "[Follow-up](https://github.com/tensorflow/tensorflow/issues/39665). Plots are from running TF on Colab GPU.\r\n\r\nWhat's the deal? Isn't Graph supposed to be speed-optimized?\r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/90391241-d8cca900-e09d-11ea-9233-ee9b8906105e.png\" width=\"650\">\r\n\r\n<hr>\r\n\r\n<details>\r\n  <summary><b>Test code</b></summary>\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport random\r\nimport matplotlib.pyplot as plt\r\nfrom termcolor import cprint\r\nfrom time import time\r\n\r\nfrom tensorflow.keras.layers import Input, Dense, Conv1D\r\nfrom tensorflow.keras.layers import Dropout, GlobalAveragePooling1D\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nimport tensorflow.keras.backend as K\r\n\r\n# tf.compat.v1.disable_eager_execution()\r\n\r\n###############################################################################\r\ndef reset_seeds(reset_graph_with_backend=None, verbose=1):\r\n    if reset_graph_with_backend is not None:\r\n        K = reset_graph_with_backend\r\n        K.clear_session()\r\n        tf.compat.v1.reset_default_graph()\r\n        if verbose:\r\n            print(\"KERAS AND TENSORFLOW GRAPHS RESET\")\r\n\r\n    np.random.seed(1)\r\n    random.seed(2)\r\n    tf.compat.v1.set_random_seed(3)\r\n    if verbose:\r\n        print(\"RANDOM SEEDS RESET\")\r\n\r\nprint(\"TF version: {}\".format(tf.__version__))\r\nreset_seeds()\r\n\r\ndef timeit(func, iterations, *args, _verbose=0, **kwargs):\r\n    times = []\r\n    t0 = time()\r\n    for _ in range(iterations):\r\n        t1 = time()\r\n        func(*args, **kwargs)\r\n        times.append(time() - t1)\r\n        print(end='.'*int(_verbose))\r\n    print(\"Time/iter: %.4f sec\" % ((time() - t0) / iterations))\r\n    plt.stem(times)\r\n    plt.ylim(0, 15)\r\n\r\n###############################################################################\r\ndef make_model_large(batch_shape):\r\n    ipt   = Input(batch_shape=batch_shape)\r\n    x     = Conv1D(64,  400, strides=4, padding='valid')(ipt)\r\n    x     = Conv1D(128, 200, strides=1, padding='valid')(x)\r\n    for _ in range(40):\r\n        x = Conv1D(256,  12, strides=1, padding='same')(x)\r\n    x     = Conv1D(512,  20, strides=2, padding='valid')(x)\r\n    x     = Conv1D(1028, 10, strides=2, padding='valid')(x)\r\n    x     = Conv1D(256,   1, strides=1, padding='valid')(x)\r\n    x     = GlobalAveragePooling1D()(x)\r\n    x     = Dense(256, activation='relu')(x)\r\n    x     = Dropout(0.5)(x)\r\n    x     = Dense(128, activation='relu')(x)\r\n    x     = Dense(64,  activation='relu')(x)\r\n    out   = Dense(1,   activation='sigmoid')(x)\r\n    model = Model(ipt, out)\r\n    model.compile(Adam(lr=1e-4), 'binary_crossentropy')\r\n    return model\r\n\r\ndef make_data(batch_shape):\r\n    return np.random.randn(*batch_shape), \\\r\n           np.random.randint(0, 2, (batch_shape[0], 1))\r\n\r\ndef test_all():\r\n    for model_fn, model_name, iters in zip(make_model_fns, model_names,\r\n                                           iterations):\r\n        for batch_shape, shape_name in zip(batch_shapes, shape_names):\r\n            reset_seeds(reset_graph_with_backend=K)\r\n            data = make_data(batch_shape)\r\n            model = model_fn(batch_shape)\r\n\r\n            model.train_on_batch(*data)\r\n            timeit(model.train_on_batch, iters, *data, _verbose=1)\r\n            \r\n            cprint(\">> {}, {} done <<\\n\".format(model_name, shape_name), 'blue')\r\n            del model\r\n###############################################################################\r\n\r\nbatch_shape_large  = (32, 14000, 30)\r\nbatch_shape = batch_shape_large\r\nmodel_fn = make_model_large\r\n\r\nbatch_shapes = batch_shape_large,\r\nmake_model_fns = make_model_large,\r\niterations = [200]\r\nshape_names = [\"Large data\"]\r\nmodel_names = [\"Large model\"]\r\n\r\ntest_all()\r\n```\r\n\r\n</details>", "comments": ["@OverLordGoldDragon \r\n\r\nI have tried in colab  with TF-GPU 2.3.0.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/b44ded3ff86c82ae9e6b308b4f1cfe0e/untitled258.ipynb).IYou are also seeing the same behavior?.Thanks!", "@ravikyram No, I'm not - and this time, the results are worse than in any prior test:\r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/90526186-22da8b00-e181-11ea-9817-572d0ac33aae.png\" width=\"650\">\r\n\r\nThe only culprit to my mind is Colab's GPU, which is known to change between sessions. Can you run again, and check GPU? This run's:\r\n\r\n```\r\nGPU: Tesla K80\r\nGen RAM Free: 11.7 GB  | Proc size: 2.1 GB\r\nGPU RAM Free: 2995MB | Used: 8446MB | Util  74% | Total 11441MB\r\n```\r\n\r\n<details>\r\n    <summary><b>GPU info code</b></summary>\r\n\r\n```python\r\n!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n!pip install gputil\r\n!pip install psutil\r\n!pip install humanize\r\n\r\nimport psutil\r\nimport humanize\r\nimport os\r\nimport GPUtil as GPU\r\n\r\nGPUs = GPU.getGPUs()\r\ngpu = GPUs[0]\r\n\r\nprocess = psutil.Process(os.getpid())\r\nprint(\"GPU:\", gpu.name)\r\nprint(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\nprint(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n```\r\n\r\n</details>", "So a number of comments looking at this colab:\r\n\r\n1. compat.v1.disable_eager_execution is not supposed to put you in a performance-optimized graph. It puts you in a legacy graph compatibility mode that is meant to keep behavior the same as the equivalent APIs in TF 1.x. Performance in compat.v1 graphs takes a backseat to general eager performance.\r\n\r\nThe appropriate way to use performance-optimized-graphs in TF2 is with `tf.function`: https://www.tensorflow.org/guide/function\r\n\r\n2. Though not under TF 1.x, `model.train_on_batch` mainly exists for backwards compatibility reason. It is not how we recommend you train your models.\r\nWe recommend using `model(x, training=True/False)` directly, using `model.fit/evaluate`, using `model.train_step`, etc. See the Keras guide to customizing `fit` as well: https://keras.io/guides/customizing_what_happens_in_fit/\r\n\r\nFor those same reasons, `model.train_on_batch` is generally much less performant than any of the above alternatives.\r\n\r\nNote that we will only automatically `tf.function` your training process if you use `model.fit/evaluate`. If you use the model call or train_step directly you'll have to apply your own `tf.function`s as you deem fit.\r\n\r\n3. While we accept numpy data as input, it's not the most performant way to feed data to your model (as we currently have to do copies to convert it to tensors). For maximum performance you should use `tf.data`. If you need to use numpy-like operations w/ tf or tf.data you can check out the recently-announced tf-numpy (https://www.tensorflow.org/guide/tf_numpy). We do have some tentative plans on the roadmap to make large numpy inputs to Keras models more performant.\r\n\r\nWe're also planning a \"performance guide\" for Keras, which should cover all of the above as well as some other things users might not be aware of.\r\n\r\nPlease let us know if you have any questions!", "@tomerk Thanks for the insight, had no clue `tf.compat.v1` wasn't the supposed way to Graph. I'd definitely recommend an explicit Eager vs. Graph guide.\r\n\r\nHowever, I commented the line, and switched to `.fit`, and `@tf.function def return model.train_step`; they run 13% and 7%, respectively, slower than `.train_on_batch` with `tf.compat.v1.disable_eager_execution()`, still on numpy data. The idea is to have new numpy data input at each iteration, so whether we handle it before passing in or TF handles it shouldn't make much a difference - and our reference is relative to TF1.x, still with numpy inputs. (But yes, for _fixed_ data, one-time conversion is faster.)\r\n\r\nI also confirmed the GPU difference; Tesla T4 runs twice as fast in Graph, averaging ~4 sec/iter vs. ~8 sec with K80, while not making much a difference with Eager. I wonder if same will hold with `model.fit`.", "I'll test again later on K80 and see if it makes a difference; if Graph is 8 sec again with all three modes while Eager is 4 sec, there's still some explaining to do. And to clarify, this is the Graph function I use:\r\n\r\n```python\r\n@tf.function\r\ndef step(*args, **kwargs):\r\n    return model.train_step(*args, **kwargs)\r\n```", "@tomerk Tested with `tf.function` as described; no difference. _However_; I once again was unable to reproduce the 2 sec/iter for Eager, implying only one thing: GPUs were unluckily swapped in my original test. This makes far more sense.\r\n\r\nMy question persists, however; how is it that \"optimized graph\" isn't notably faster than Eager (using prev comment's function)? \r\n\r\n\r\n"]}, {"number": 42428, "title": "tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux Ubuntu 18.04:\r\n- TensorFlow installed from binary:\r\n- TensorFlow version : 2.3\r\n- Python version: 3.7\r\n- Installed using  pip:\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: nvidia GTX 960 M 4GB \r\n\r\n\r\n\r\n**problem**\r\nafter installing TensorFlow object detection tf2  mentioned in the documentation and after I tried to run:\r\n```python object_detection/builders/model_builder_tf2_test.py``` \r\nto test the installation I get this error log \r\n\r\n```\r\npython object_detection/builders/model_builder_tf2_test.py\r\n2020-08-17 13:10:21.225777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nRunning tests under Python 3.7.8: /usr/bin/python3\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\r\n2020-08-17 13:10:22.824358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-08-17 13:10:22.851969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.852268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:22.852290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:22.853853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:22.854843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:22.855102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:22.856654: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:22.857867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:22.861423: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:22.861615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.861964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.862213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-17 13:10:22.862466: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-17 13:10:22.868196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz\r\n2020-08-17 13:10:22.868535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56384f304fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-17 13:10:22.868552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-17 13:10:22.900165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.900633: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56384f398e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-08-17 13:10:22.900669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0\r\n2020-08-17 13:10:22.900888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.901165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:22.901207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:22.901232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:22.901260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:22.901275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:22.901290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:22.901304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:22.901319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:22.901400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.901698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.901920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-08-17 13:10:22.901949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.25s\r\nI0817 13:10:22.908455 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.25s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_center_net_model\r\n[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\r\nI0817 13:10:22.913183 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_create_experimental_model\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\r\n2020-08-17 13:10:22.999558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:22.999942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:22.999975: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.000010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.000030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.000048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.000067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.000085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.000102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.000169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.000491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.000758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)): 0.09s\r\nI0817 13:10:23.004207 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)): 0.09s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\r\n2020-08-17 13:10:23.019474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.019798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.019830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.019888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.019906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.019922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.019939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.019955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.019972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.020037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.020339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.020594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)): 0.02s\r\nI0817 13:10:23.023944 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\n2020-08-17 13:10:23.038026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.038352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.038381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.038411: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.038427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.038443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.038459: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.038475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.038490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.038550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.038828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.039064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\r\nI0817 13:10:23.041950 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n2020-08-17 13:10:23.054686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.054981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.055017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.055045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.055061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.055075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.055090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.055104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.055118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.055170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.055425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.055642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.02s\r\nI0817 13:10:23.058731 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n2020-08-17 13:10:23.071706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.072017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.072062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.072104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.072120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.072135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.072170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.072197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.072213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.072268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.072563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.072785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.02s\r\nI0817 13:10:23.076769 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n2020-08-17 13:10:23.096834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.097437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.097544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.097675: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.097731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.097811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.097845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.097895: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.097944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.098055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.098505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.098873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.03s\r\nI0817 13:10:23.103684 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.03s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n2020-08-17 13:10:23.123831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.124163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.124220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.124245: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.124258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.124268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.124279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.124290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.124321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.124407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.124841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.125292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.02s\r\nI0817 13:10:23.128272 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\n2020-08-17 13:10:23.142464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.142849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.142915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.142995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.143023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.143060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.143087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.143097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.143108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.143195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.143486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.143737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.02s\r\nI0817 13:10:23.146383 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.02s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\n2020-08-17 13:10:23.153174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.153561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.153604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.153644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.153656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.153666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.153676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.153707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.153718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.153781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.154044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.154298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.01s\r\nI0817 13:10:23.156916 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.01s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\n2020-08-17 13:10:23.163432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.163782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-08-17 13:10:23.163826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-08-17 13:10:23.163880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-08-17 13:10:23.163893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-08-17 13:10:23.163923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-08-17 13:10:23.163949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-08-17 13:10:23.163994: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-08-17 13:10:23.164006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-08-17 13:10:23.164086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.164724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-08-17 13:10:23.164977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 0.01s\r\nI0817 13:10:23.167692 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 0.01s\r\n[  FAILED  ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\r\nI0817 13:10:23.169691 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\r\nI0817 13:10:23.171179 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\r\nI0817 13:10:23.171630 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\r\nI0817 13:10:23.173022 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\n[ RUN      ] ModelBuilderTF2Test.test_session\r\n[  SKIPPED ] ModelBuilderTF2Test.test_session\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\nI0817 13:10:23.174277 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\nI0817 13:10:23.174678 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\nI0817 13:10:23.175496 139894328768320 test_util.py:1973] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n======================================================================\r\nERROR: test_create_center_net_model (__main__.ModelBuilderTF2Test)\r\ntest_create_center_net_model (__main__.ModelBuilderTF2Test)\r\nTest building a CenterNet model from proto txt.\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"object_detection/builders/model_builder_tf2_test.py\", line 224, in test_create_center_net_model\r\n    model = model_builder.build(config, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 956, in _build_center_net_model\r\n    center_net_config.feature_extractor)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1026, in _build_center_net_feature_extractor\r\n    bgr_ordering=feature_extractor_config.bgr_ordering\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_resnet_feature_extractor.py\", line 145, in resnet_v2_101\r\n    bgr_ordering=bgr_ordering\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/center_net_resnet_feature_extractor.py\", line 47, in __init__\r\n    bgr_ordering=bgr_ordering)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/center_net_meta_arch.py\", line 71, in __init__\r\n    super(CenterNetFeatureExtractor, self).__init__(name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_from_config_with_crop_feature(True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 267, in bound_param_test\r\n    test_method(self, testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 292, in test_create_faster_rcnn_from_config_with_crop_feature\r\n    _ = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_from_config_with_crop_feature(False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 267, in bound_param_test\r\n    test_method(self, testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 292, in test_create_faster_rcnn_from_config_with_crop_feature\r\n    _ = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 271, in test_create_faster_rcnn_model_from_config_with_example_miner\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 263, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 262, in test_create_faster_rcnn_models_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 263, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 262, in test_create_faster_rcnn_models_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 263, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 262, in test_create_faster_rcnn_models_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)\r\ntest_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/testing/parameterized.py\", line 263, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 262, in test_create_faster_rcnn_models_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 789, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)\r\ntest_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 282, in test_create_rfcn_model_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 764, in _build_faster_rcnn_model\r\n    **common_kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/rfcn_meta_arch.py\", line 248, in __init__\r\n    output_final_box_features=output_final_box_features)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 508, in __init__\r\n    ], name='FirstStageRPNFeatures'))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 117, in __init__\r\n    name=name, autocast=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)\r\ntest_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 220, in test_create_ssd_fpn_model_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 375, in _build_ssd_model\r\n    is_training=is_training)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 350, in _build_ssd_feature_extractor\r\n    return feature_extractor_class(**kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py\", line 317, in __init__\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py\", line 120, in __init__\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 194, in __init__\r\n    super(SSDKerasFeatureExtractor, self).__init__(name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n======================================================================\r\nERROR: test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)\r\ntest_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder_test.py\", line 212, in test_create_ssd_models_from_config\r\n    model = model_builder.build(model_proto, is_training=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 1062, in build\r\n    add_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 375, in _build_ssd_model\r\n    is_training=is_training)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/model_builder.py\", line 350, in _build_ssd_feature_extractor\r\n    return feature_extractor_class(**kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py\", line 88, in __init__\r\n    name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 194, in __init__\r\n    super(SSDKerasFeatureExtractor, self).__init__(name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 308, in __init__\r\n    self._init_batch_counters()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 317, in _init_batch_counters\r\n    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 262, in __call__\r\n    return cls._variable_v2_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 256, in _variable_v2_call\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 237, in <lambda>\r\n    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2646, in default_variable_creator_v2\r\n    shape=shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1652, in _init_from_args\r\n    name=\"initial_value\", dtype=dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\r\n    return constant_op.constant(value, dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 97, in convert_to_eager_tensor\r\n    ctx.ensure_initialized()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\r\n    context_handle = pywrap_tfe.TFE_NewContext(opts)\r\ntensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid\r\n\r\n----------------------------------------------------------------------\r\nRan 20 tests in 0.516s\r\n\r\nFAILED (errors=11, skipped=1)\r\n\r\n```\r\nalso even when I tried to run inside docker container using the build instruction in the documentation I get the same message \r\n```tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid```\r\n\r\nI tried to reinstall cuda and nvidia drivers but with the same issue \r\n\r\n", "comments": ["@hadikoub,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/41990#issuecomment-670224813) from a similar issue and let us know if it helps. Thanks!", "Hi, I had the same problem as you, did you solve it please?\r\n", "Hi, \r\nAs it turns out, TF2 GPU is not supported on older GPUs (I had Nvidia GTX 960m ). It only supports Cuda compute capability >=3.5\r\nRefer: https://github.com/tensorflow/tensorflow/issues/41990#issuecomment-670626077"]}, {"number": 42427, "title": "Failed to build v2.3.0 from source in debug mode", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.3.0\r\n- Python version: Python 3.6.9\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.2/NA\r\n- GPU model and memory:\r\nRTX 2080 Ti 11G\r\n\r\n\r\n**Describe the problem**\r\nI built v2.3.0 debug version with\r\n```\r\nbazel build --config=dbg --strip never //tensorflow/compiler/mlir/...\r\n```\r\n\r\nwhile bazel complains\r\n\r\n```\r\nERROR: /workspace/tensorflow/tensorflow/compiler/mlir/BUILD:139:1: Linking of rule '//tensorflow/compiler/mlir:tf-mlir-translate' failed (Exit 1)                               \r\ntensorflow/core/kernels/data/experimental/io_ops.cc:120: error: undefined reference to 'tensorflow::data::experimental::SaveDatasetOp::kFileFormatVersion'                      \r\ntensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kCompression'                            \r\ntensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kReaderFunc'                             \r\ntensorflow/core/kernels/data/experimental/io_ops.cc:234: error: undefined reference to 'tensorflow::data::experimental::LoadDatasetOp::kReaderFuncTarguments'                   \r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kCompression'         \r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kReaderFunc'          \r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kShardFunc'           \r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kReaderFuncTarguments'\r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:372: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kShardFuncTarguments' \r\ntensorflow/core/kernels/data/experimental/snapshot_dataset_op.cc:696: error: undefined reference to 'tensorflow::data::experimental::SnapshotDatasetV2Op::kFileFormatVersion'   \r\ncollect2: error: ld returned 1 exit status                                                                                                                                      \r\nINFO: Elapsed time: 1469.870s, Critical Path: 372.47s                                                                                                                           \r\nINFO: 7815 processes: 7815 local.                                                                                                                                               \r\nFAILED: Build did NOT complete successfully                                                                                                                                     \r\n```\r\n\r\nOn contrast, I can build successfully with \r\n\r\n```\r\nbazel build //tensorflow/compiler/mlir/...\r\n```\r\n", "comments": ["@zldrobit \r\nPlease share all commands executed before you ran into this error.", "# 1 .Clone `TensorFlow` repo\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\n```\r\n\r\nand checkout `v2.3.0` release tag\r\n\r\n```\r\ncd tensorflow \\\r\ngit checkout v2.3.0\r\n```\r\n\r\n# 2. Run configure.py \r\n\r\n```\r\npython3 configure.py\r\n```\r\n\r\nwith default configuration\r\n\r\n```\r\nroot@7ee9f0e2c99e:/workspace/tensorflow# python3 configure.py                                                                                            \r\nYou have bazel 3.1.0 installed.                                                                                                                          \r\nPlease specify the location of python. [Default is /usr/bin/python3]:                                                                                    \r\n                                                                                                                                                         \r\n                                                                                                                                                         \r\nFound possible Python library paths:                                                                                                                     \r\n  /usr/lib/python3/dist-packages                                                                                                                         \r\n  /usr/local/lib/python3.6/dist-packages                                                                                                                 \r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]                                                        \r\n                                                                                                                                                         \r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:                                                                                         \r\nNo OpenCL SYCL support will be enabled for TensorFlow.                                                                                                   \r\n                                                                                                                                                         \r\nDo you wish to build TensorFlow with ROCm support? [y/N]:                                                                                                \r\nNo ROCm support will be enabled for TensorFlow.                                                                                                          \r\n                                                                                                                                                         \r\nDo you wish to build TensorFlow with CUDA support? [y/N]:                                                                                                \r\nNo CUDA support will be enabled for TensorFlow.                                                                                                          \r\n                                                                                                                                                         \r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]:                                                                                  \r\nClang will not be downloaded.                                                                                                                            \r\n                                                                                                                                                         \r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:  \r\n                                                                                                                                                         \r\n                                                                                                                                                         \r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:                                                                         \r\nNot configuring the WORKSPACE for Android builds.                                                                                                        \r\n                                                                                                                                                         \r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.            \r\n        --config=mkl            # Build with MKL support.                                                                                                \r\n        --config=monolithic     # Config for mostly static monolithic build.                                                                             \r\n        --config=ngraph         # Build with Intel nGraph support.                                                                                       \r\n        --config=numa           # Build with NUMA support.                                                                                               \r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.                                                     \r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.                                                                                   \r\nPreconfigured Bazel build configs to DISABLE default on features:                                                                                        \r\n        --config=noaws          # Disable AWS S3 filesystem support.                                                                                     \r\n        --config=nogcp          # Disable GCP support.                                                                                                   \r\n        --config=nohdfs         # Disable HDFS support.                                                                                                  \r\n        --config=nonccl         # Disable NVIDIA NCCL support.                                                                                           \r\n```\r\n\r\n# 3. Bulid debug version\r\n```\r\nbazel build --config=dbg --strip never //tensorflow/compiler/mlir/...\r\n```\r\n\r\nPS: For convinience, I use tensorflow docker as building environment.", "@Saduf2019 I also created a colab notebook for command illustration https://colab.research.google.com/drive/1dMx3v4-IrGmBHEmDlKcB2J_daJLpfDp8?usp=sharing, but the compilation is very time consuming.", "@jpienaar @joker-eph looks like this is a problem during mlir build? could you reassign this issue?", "@gunan seem like static constexpr member variable that are missing a definition outside of the class, which is needed pre-C++17.\r\nThe compiler elides the uses in optimized build so this only shows up in debug builds.\r\n\r\nThere are in `tensorflow/core/kernels/data/experimental`", "> @gunan seem like static constexpr member variable that are missing a definition outside of the class, which is needed pre-C++17.\r\n> The compiler elides the uses in optimized build so this only shows up in debug builds.\r\n> \r\n> There are in `tensorflow/core/kernels/data/experimental`\r\n\r\nyes, that does the trick -- I prepared a PR #42745", "@zldrobit,\r\n\r\n@jgehw has already submitted a PR for the same and your issue should be fixed. But we recommend you to kindly update to the latest stable version of tensorflow from source using this [guide](https://www.tensorflow.org/install/source#tested_build_configurations), [debug builds link](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#debug-builds) and feel free to report if you still face any issues. Thanks!", "@sanatmpa1  I am closing this issue, as the PR addressed the problem. \r\nNow I could successfully build the debug version of TensorFlow v2.6.0 with\r\n```\r\nbazel build --config=dbg --strip never //tensorflow/compiler/mlir/...\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42427\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42427\">No</a>\n"]}, {"number": 42426, "title": "Full integer Quantization of SSD-Mobilenet V2 doesn't work", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):  binary\r\n- Tensorflow version (commit SHA if source): '2.4.0-dev20200805'\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arm Mbed OS\r\n\r\n**Describe the problem**\r\n\r\nI need to convert a SSD-Mobilenet V2 model for an 8-bit microcontroller which runs Mbed OS and would like to use optimized CMSIS-NN kernels. Model was trained and exported with [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). \r\n\r\nHowever, the saved and exported model cannot be converted to TfLite. Truncated error message is as follows: \r\n```\r\nException: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___8168\" at \"StatefulPartitionedCall@__inference_signature_wrapper_9547\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n```\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nCode to replicate the problem can be found here: \r\nhttps://colab.research.google.com/drive/1vR6L0uUQQb3PTL8Ze0keIVGjSLusa_WI?usp=sharing", "comments": ["@ymodak please let me know if there's anything i can do to help with the resolution of this issue. ", "Thanks for the issue. I cannot view the attached colab can you please change its permissions visible to public?", "@ymodak thanks for the quick response. I have updated the sharing link. ", "Please look at [this guide](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md) for TFLite inference. \r\n\r\nFor post-training quant, Be sure to use a\r\n[representative dataset](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization)\r\nand set the following options on the converter:\r\n\r\n```\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\r\n                                       tf.lite.OpsSet.TFLITE_BUILTINS]\r\nconverter.representative_dataset = <...>\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Can we reopen this issue? It doesn't work for me either. Any type of quantization I have ever tried fails for ssd_mobilenet_v2. I have the same error but mine is: ```failed while converting 'main'```. Please help!", "@ChowderII Where are you getting the model from? Did you follow [these instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md)? \r\n\r\nif yes, please post your code for post-training quantization if you are trying that", "@srjoglekar246 \r\nhm, I may have forgotten to export to TFlite first. I thought only the conversion was necessary. Let me do that first and I'll report back\r\nThanks!", "@srjoglekar246  So I have tried it and I receive the following errors:\r\n```Traceback (most recent call last):\r\n  File \"export_tflite_graph_tf2.py\", line 126, in <module>\r\n    app.run(main)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"export_tflite_graph_tf2.py\", line 118, in main\r\n    export_tflite_graph_lib_tf2.export_tflite_model(pipeline_config,\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/export_tflite_graph_lib_tf2.py\", line 245, in export_tflite_model\r\n    concrete_function = detection_module.inference_fn.get_concrete_function(\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1299, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1205, in _get_concrete_function_garbage_collected\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 725, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2976, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3371, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3897, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"/home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/export_tflite_graph_lib_tf2.py:169 inference_fn  *\r\n        predicted_tensors = self._model.predict(image, true_image_shapes=None)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:591 predict  *\r\n        predictor_results_dict = self._box_predictor(feature_maps)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/core/box_predictor.py:202 call  *\r\n        return self._predict(image_features, **kwargs)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/predictors/convolutional_keras_box_predictor.py:204 _predict  *\r\n        prediction = head_obj(net)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/predictors/heads/head.py:69 call  *\r\n        return self._predict(features)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/object_detection/predictors/heads/keras_class_head.py:143 _predict  *\r\n        class_predictions_with_background = layer(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:999 __call__  **\r\n        self._maybe_build(inputs)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2670 _maybe_build\r\n        self.build(input_shapes)  # pylint:disable=not-callable\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py:198 build\r\n        self.kernel = self.add_weight(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:614 add_weight\r\n        variable = self._add_variable_with_custom_getter(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:805 _add_variable_with_custom_getter\r\n        new_variable = getter(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:130 make_variable\r\n        return tf_variables.VariableV1(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:260 __call__\r\n        return cls._variable_v1_call(*args, **kwargs)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:206 _variable_v1_call\r\n        return previous_getter(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:67 getter\r\n        return captured_getter(captured_previous, **kwargs)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:712 variable_capturing_scope\r\n        v = UnliftedInitializerVariable(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/variables.py:264 __call__\r\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:227 __init__\r\n        initial_value = initial_value()\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:81 __call__\r\n        return CheckpointInitialValue(\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:117 __init__\r\n        self.wrapped_value.set_shape(shape)\r\n    /home/brackman/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1215 set_shape\r\n        raise ValueError(\r\n\r\n    ValueError: Tensor's shape (1, 1, 576, 273) is not compatible with supplied shape (1, 1, 576, 9)\r\n```\r\n\r\nWhat is that tensor? Right now, I tried to download the ssd_mobilenet_v2 from the model zoo and directly convert it (I just want to know it's possible before training). I unfortunately have no idea what that error means. Maybe I goofed up in the pipeline?", "Look at the last section in [this colab](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb) for an example of how to export & convert to TFLite.", "They only mention how to convert it with \r\n```bash\r\npython models/research/object_detection/export_tflite_graph_tf2.py \\\r\n  --pipeline_config_path output/pipeline.config \\\r\n  --trained_checkpoint_dir output/checkpoint \\\r\n  --output_directory tflite\r\n```\r\nWhich is what I am doing. Maybe I should create a separate issue? ", "Which model areyou downloading? Can you send me the name of model you downloading from the [TF2 Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)?\r\n\r\nAlso, note that you need the latest TF nightly for this to work.\r\n\r\nIf this still doesn't work for you, can you post your exact commands for me to take a look?", "I tried using every SSD_mobilenet_v2. I never was able to do any type of quantization on any of them. I am also running tf-nightly\r\nI tried the `graph_rewriter` but the model would never begin training.\r\nCurrently I was able to export SSD MobileNet V2 FPNLite 320x320 using tflite so I am currently training it. I hope it will survive convertion.\r\nAs for the command, I am using : I am training it using model_main_tf2.py\r\nThen I try to export it using export_tflite_graph_tf2.py\r\nAfter that, I try this code\r\n```python\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8  # or tf.uint8\r\nconverter.inference_output_type = tf.int8  # or tf.uint8\r\ntflite_quant_model = converter.convert()\r\n```\r\nGiven from the [Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) guide from Tensorflow.\r\n\r\nI feel like I am doing something fundamentally wrong but I've poking at it for well over a month now.\r\nI need to have it run on INT8 because I am trying to have the model run on a custom chip. ", "You need to add `tf.lite.OpsSet.TFLITE_BUILTINS` to `tf.lite.OpsSet.TFLITE_BUILTINS_INT8`\r\n\r\nAlso, you need to implement representative_dataset_gen to produce inputs in the correct format. Its usually something like this:\r\n\r\n```\r\ndef representative_dataset_gen():\r\n  for i in range(100):\r\n    image = tf.io.read_file(os.path.join(data_dir, image_files[i % NUM_FILES]))\r\n    image = tf.compat.v1.image.decode_jpeg(image)\r\n    image = preprocess(image)\r\n\r\n    yield [image]\r\n```\r\n\r\nYou can see an implementation of `preprocess` [here](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py#L258)."]}, {"number": 42423, "title": "`tf.data.experimental.sample_from_datasets` imports all the dataset into GPU memory", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution**: Ubuntu 18.04.5 LTS \r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: 2.3.0\r\n-   **Python version**: 3.7.3\r\n-   **CUDA/cuDNN version**: CUDA 10.1 & cuDNN 7.6.5\r\n-   **GPU model and memory**: NVIDIA RTX 2070 8GB (Single GPU)\r\n\r\n### Describe the problem\r\nI was using `tf.data` API to build an input pipeline for my inbalanced dataset. So I used `tf.data.experimental.sample_from_datasets` function as [the tutorial](https://tensorflow.google.cn/tutorials/structured_data/imbalanced_data?hl=en#using_tfdata) recommended. \r\n\r\nMy dataset's shape is shown below:\r\n```python\r\n>>> print(x.shape)\r\n(63, 1330, 3001, 8)\r\n>>> print(y.shape)\r\n(63, 5)\r\n```\r\n\r\nBefore I use `tf.data.experimental.sample_from_datasets` function. My system memory usage was approximately 9 GB, and **GPU Memory Usage** only 15 MiB /  7949MiB . Which I had did before `sample_from_datasets` was:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom sklearn.model_selection import ShuffleSplit\r\n\r\n# load dataset from files\r\nx = np.load('result/experiment_2_0816/x.npy')\r\ny = np.load('result/experiment_2_0816/y.npy')\r\n\r\n# there is five classes\r\nA = []\r\nB = []\r\nC = []\r\nD = []\r\nE = []\r\n\r\n# distribute dataset by labels\r\n# A,B,C,D,E are just indices of the data (not slices)\r\nfor i in range(63):\r\n    if y[i].argmax() == 0:\r\n        A.append(i)\r\n    elif y[i].argmax() == 1:\r\n        B.append(i)\r\n    elif y[i].argmax() == 2:\r\n        C.append(i)\r\n    elif y[i].argmax() == 3:\r\n        D.append(i)\r\n    elif y[i].argmax() == 4:\r\n        E.append(i) \r\n\r\n# split validation set\r\nA = next(ShuffleSplit(n_splits=1, test_size=0.1).split(A))\r\nB = next(ShuffleSplit(n_splits=1, test_size=0.1).split(B))\r\nC = next(ShuffleSplit(n_splits=1, test_size=0.1).split(C))\r\nD = next(ShuffleSplit(n_splits=1, test_size=0.1).split(D))\r\nE = next(ShuffleSplit(n_splits=1, test_size=0.1).split(E))\r\n\r\ndef make_dataset(features, labels):\r\n    ds = tf.data.Dataset.from_tensor_slices((features, labels)).cache()\r\n    ds = ds.shuffle(100).repeat()\r\n    return ds\r\n\r\n# using `tf.data.Dataset.from_tensor_slices` function to build pipelines\r\nA_train = make_dataset(x[A[0]], y[A[0]])\r\nB_train = make_dataset(x[B[0]], y[B[0]])\r\nC_train = make_dataset(x[C[0]], y[C[0]])\r\nD_train = make_dataset(x[D[0]], y[D[0]])\r\nE_train = make_dataset(x[E[0]], y[E[0]])\r\nA_val = make_dataset(x[A[1]], y[A[1]])\r\nB_val = make_dataset(x[B[1]], y[B[1]])\r\nC_val = make_dataset(x[C[1]], y[C[1]])\r\nD_val = make_dataset(x[D[1]], y[D[1]])\r\nE_val = make_dataset(x[E[1]], y[E[1]])\r\n\r\n# collect garbage\r\ndel x,y\r\nimport gc\r\ngc.collect()\r\n```\r\n\r\nHowever, once we execute\r\n```python\r\nresampled_train = tf.data.experimental.sample_from_datasets([A_train, B_train, C_train, D_train, E_train], weights=[0.84, 3.15, 0.9, 0.54782609, 1.8])\r\nresampled_val = tf.data.experimental.sample_from_datasets([A_val, B_val, C_val, D_val, E_val], weights=[0.84, 3.15, 0.9, 0.54782609, 1.8])\r\n```\r\nthe **GPU memory usage** suddenly rise to **7491MiB /  7949MiB **. The function loaded all the data into GPU memory, which was unnecessary and waste of GPU resources. Here we were doing nothing about Neural Network Models. The model hasn't been created at all.\r\n\r\nSo I wonder whether it is a bug or necessary step to load data into GPU. Or I've done some steps wrong?", "comments": ["@Zhao-Kuangshi,\r\nWhen trying to reproduce your issue, I encountered the error, \r\n\r\n`FileNotFoundError: [Errno 2] No such file or directory: 'result/experiment_2_0816/x.npy'` . Can you please share the files, `x.npy` and `y.npy`. Thanks!", "> \r\n> \r\n> @Zhao-Kuangshi,\r\n> When trying to reproduce your issue, I encountered the error,\r\n> \r\n> `FileNotFoundError: [Errno 2] No such file or directory: 'result/experiment_2_0816/x.npy'` . Can you please share the files, `x.npy` and `y.npy`. Thanks!\r\n\r\nThanks for your prompt reply. Github Issues cannot seem to upload files. And my `x.npy` is really a huge file (which is 7.5G). So I recommand you to use code below:\r\n\r\n```python\r\nx = np.random.rand(63, 1330, 3001, 8)\r\ny = np.random.rand(63,5)\r\n```\r\n\r\nto replace `np.load()` lines in my original code.\r\n\r\nBefore doing that, you should ensure you've got enough computer memory because the matrix with the shape `(63, 1330, 3001, 8)` is really large. You can also use a smaller matrix to reproduce my code, it will not change the essence.", "@Zhao-Kuangshi I tried running initial part of your code without tf.data, it is still crashing without the data pipeline. \r\n\r\nPlease verify it. [Here](https://colab.research.google.com/gist/jvishnuvardhan/7d1732bcb3284a6c4a1fa97e01130c31/untitled10.ipynb) is the gist for your reference. Thanks!", "> \r\n> \r\n> @Zhao-Kuangshi I tried running initial part of your code without tf.data, it is still crashing without the data pipeline.\r\n> \r\n> Please verify it. [Here](https://colab.research.google.com/gist/jvishnuvardhan/7d1732bcb3284a6c4a1fa97e01130c31/untitled10.ipynb) is the gist for your reference. Thanks!\r\n\r\nI tried it on Colab. It crashed because of OOM. Because the array with shape `(63, 1330, 3001, 8)` was really large. My workstation has 32GB of RAM and 8GB of GPU Memory. So `(63, 1330, 3001, 8)` numpy,array will not cause crashing. Due to smaller memory limitation on Colab, a smaller data such as `x = np.random.rand(63, 1330, 3001)` is also representative, as I have mentioned before. \r\n\r\nIn most of user cases, **a user usually has larger RAM than GPU Memory**. When facing big data, a user will try using pipelines or generators or cache such as `tf.data` to save GPU memory (and avoid program crashing out). While other functions in `tf.data` module almost did not increase memory usage, `sample_from_datasets` did consume GPU memory. So **the point is the change of  GPU memory usage after using `sample_from_datasets`**.", "Hi @Zhao-Kuangshi.\r\n\r\nI'm unable to reproduce this issue on my work station, which has 64GB of RAM and 8GB of GPU memory. I suspect that the issue might not be related to sample_from_datasets, since sample_from_datasets isn't expected to use any GPU memory at all.\r\n\r\nOne thing to try is adding\r\n\r\n```tf.debugging.set_log_device_placement(True)```\r\n\r\nat the start of the program, to see what ops are being executed on GPU.", "@Zhao-Kuangshi Is this still an issue for you? Did you check the [above comment](https://github.com/tensorflow/tensorflow/issues/42423#issuecomment-678378103) and follow the instructions to check what ops are executed on GPU. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42422, "title": "fp16/bf16 is much slower than fp32", "body": "I tested `fp16` and `bf16` training performance on `Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz` CPU, which I guess does not support `fp16` or `bf16` computation, however, the training went through without throwing me any errors, but the performance was much worse than `fp32`. I was wondering how TensorFlow handles such case, i.e. running `fp16` or `bf16` on a `Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz` CPU.", "comments": ["@zhao1157,\r\nCould you please provide the code you have used or the commands you have run to test the performance and also the TensorFlow version you are using? Thanks!", "Tf version tested: 1.14.0 and 2.2.0\r\n\r\nCode used: [https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks](url)\r\n\r\nCommand for testing `fp32`: `python tf_cnn_benchmarks.py --input_preprocessor=default --optimizer=sgd --batch_size=50 --data_name=imagenet --model=resnet50 --variable_update=replicated --device=cpu --data_format=NHWC` \r\n\r\nCommand for testing `fp16`: `python tf_cnn_benchmarks.py --input_preprocessor=default --optimizer=sgd --batch_size=50 --data_name=imagenet --model=resnet50 --variable_update=replicated --device=cpu --data_format=NHWC --fp16_loss_scale=500 --use_fp16=True --fp16_vars=False --fp16_inc_loss_scale_every_n=10 --fp16_enable_auto_loss_scale=True`\r\n\r\nAs for `bf16`, I used Intel's MLPerf v0.7 code [https://github.com/mlperf/training_results_v0.7/tree/master/Intel/benchmarks/resnet/1-node-8s-cpx-1-tensorflow/mlperf_resnet](url), and in `run_and_time.sh`, we have to set `use_bfloat16`  `True` or `False` to comparing the performance of `bf16` and `fp32`.\r\n\r\n\r\n", "Apologies for the delay in response but [readme](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks#tf_cnn_benchmarks-high-performance-benchmarks) file helps explain the discrepancy.\r\n`\r\ntf_cnn_benchmarks is no longer maintained. Although it will run with TensorFlow 2, it was written and optimized for TensorFlow 1, and has not been maintained since TensorFlow 2 was released. \r\n`"]}, {"number": 42421, "title": "Segmentation fault in tf.image.combined_non_max_suppression", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-38999-g56548c2425 2.4.0-dev20200811\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nA segfault occurs when `max_total_size` is large.  If I execute the same input repetitively, I get different errors in different executions such as `Segmentation Fault`, `what():  vector::_M_fill_insert`, and `what():  terminate called recursively`.\r\n\r\n**Describe the expected behavior**\r\nI would expect a runtime exception in python rather than a segfault.  \r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\ntf.image.combined_non_max_suppression(boxes=tf.ones((11,8,2,4)), scores=tf.ones((11,8,2)), max_output_size_per_class=5, max_total_size=311452676677046672)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nSegmentation fault (core dumped)\r\n```\r\n```\r\nwhat():  terminate called recursively\r\n```\r\n```\r\nwhat():  vector::_M_fill_insert\r\n```", "comments": ["@mjkim720 \r\nI ran your code on 1.15 and do not see \"Segmentation fault (core dumped)\", as there is support for tf 1.15 and 2.x, please upgrade to later versions and let us know if you are still facing any issue.\r\nplease find the gist for [tf 1.15](https://colab.research.google.com/gist/Saduf2019/6c1152184e8961c317eef2c45fdcf74f/untitled372.ipynb).", "Actually, I used the nightly version as of 20200811, not 1.15. I can reproduce the issue with the latest version in Colab.  The session crashed due to the fault in c++ [here](https://colab.research.google.com/drive/1s7vRS_K-OcUL1_rF8T1fHiv_p924ezmB?usp=sharing). ", "Was able to reproduce the issue in TF 2.6.0-dev20210528,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/44e8b9890a41820a2f9b5aa0a87dfab5/untitled62.ipynb#scrollTo=SlSYBpJ3diVv)..Thanks !", "With the latest tf-nightly I believe the issue has been resolved with no crash anymore:\r\n```\r\n# python3\r\nPython 3.8.10 (default, Jun  2 2021, 10:49:15) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-09-02 15:21:04.937701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-09-02 15:21:04.937746: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> tf.image.combined_non_max_suppression(boxes=tf.ones((11,8,2,4)), scores=tf.ones((11,8,2)), max_output_size_per_class=5, max_total_size=311452676677046672)\r\n2021-09-02 15:21:06.423863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2021-09-02 15:21:06.423905: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2021-09-02 15:21:06.423943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-87-192): /proc/driver/nvidia/version does not exist\r\n2021-09-02 15:21:06.424317: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 7096, in raise_from_not_ok_status\r\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute CombinedNonMaxSuppression as input #3(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:CombinedNonMaxSuppression]\r\n>>> \r\n\r\n```", "@mjkim720 I will close this issue for now, but feel free to re-open if the issue persists.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42421\">No</a>\n"]}, {"number": 42420, "title": "Error in Validation split percentage - Image Classification tutorial", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nUnder Load using Keras.preprocessing > Create Dataset, the percentage under training_ds for validation_split is set to 0.2. I believe is supposed to be 0.8.\r\n\r\n\r\n### Clear description\r\n\r\nWhen you used 0.8 on the number of images in the directory, it will result to 2936, but 0.2 is way smaller. \r\n\r\n", "comments": ["@Saduf2019 @jvishnuvardhan The error is in the documentation itself; In both tutorials (on github and on tensorflow's website), there is an error on the percentage when the program splits the data into training dataset and validation dataset. I believe the correct percentage is 0.8 for training and 0.2 for validation.", "@roca77 Thanks for raising the issue. \r\nThe percentage `0.2` is correct. The split is percentage of data reserved for validation which is `0.2`. You can check the documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)\r\n\r\nThe documentation says that\r\n\r\n> validation_split | Optional float between 0 and 1, fraction of data to reserve for validation.\r\n> -- | --\r\n\r\nPlease verify once and close the issue. Thanks!", "Closing; Thanks for checking"]}, {"number": 42418, "title": "Tensorflow 2.3 modules not found", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 10\r\n- TensorFlow installed from conda\r\n- TensorFlow version: 2.3\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen installing Tensorflow via conda to my machine, Keras fails to load models properly, returning KeyError 0.  Conda installs Tensorflow 2.1, and it was recommended that I upgrade to the lastest tf/keras versions, which I did via pip:\r\n`pip install tensorflow --upgrade`\r\n\r\nHowever, this then produced the following errors when I attempted to run a file which imported tensorflow:\r\n`Traceback (most recent call last):\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"bot_2.py\", line 12, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Thomas DeWitt\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nFailed to load the native TensorFlow runtime.`\r\n\r\nI've uninstalled Tensorflow and reinstalled it twice, once with pip and once with conda.  The pip install returns a warning about the assorted .exe files not being associated with PATH:\r\n`WARNING: The scripts estimator_ckpt_converter.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\Thomas DeWitt\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.`\r\n\r\nThe conda install works, but again fails to load models with tf.keras.models.load_model('model')\r\n\r\nI'm not sure if this is a problem on my machine or with the latest Tensorflow release, as I usually operate in Colab and I've never needed to run Tensorflow locally before.", "comments": ["Try Installing CuDnn,Which is essential to run Tensorflow to run in  the local machine", "@intelligentgoldfish \r\nPlease refer to these links with same error and let us know:\r\n[link](https://stackoverflow.com/questions/59822162/error-installing-tensorflow-with-pip-install) [link1](https://superuser.com/questions/1372793/the-script-is-installed-in-directory-which-is-not-path) ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I don't have admin access on my machine, so I'm not able to simply add the variables to the path.", "@intelligentgoldfish \r\nFor the issue to be resolved you will have to make the changes as suggested.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42418\">No</a>\n"]}, {"number": 42417, "title": "tf.keras.layers.Conv1D fails for RaggedTensor input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, probably not relevant\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nI'm not sure if this is a bug or feature request, but I would expect/hope the below to work.\r\n\r\ntf.keras.layers.Conv1D fails on a batch of type `tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor`. Specifically it appears to fail on the `convert_to_tensor` step in the same manner as in https://github.com/tensorflow/tensorflow/issues/37351.\r\n\r\n**Describe the expected behavior**\r\n\r\nIdeally the convolution would execute as expected and produce a RaggedTensor output that reflects the shape of the input RaggedTensor and the convolution applied.\r\n\r\nTo get some insight on my use case, I am working on an unsupervised time series classification problem where the length of each input could be a giveaway and provide useless downstream embeddings. Specifically, I am using dilated convolutions to compress information about the series and using final pooling layers over the temporal dimension to produce equal size embeddings from unequal length input tensors. My first implementation used Conv1D layers with a batch size of 1, and runs fine, except that using batch size 1 limits training speed and the size of the dataset I can work with. I was hoping RaggedTensor would allow me to scale up my implementation. I suspect the lack of non-uniform sizes would preclude a GPU implementation, but I believe even using simple batching would provide a much needed speed up.\r\n\r\nI would also be open to workarounds, if one knows of a better way to formulate this. Perhaps there is a way to operate on the padded tensor and then trim off the Conv outputs that had access to the padding as part of their input on an element-by-element basis within the batch (probably as a function of each of their true length passed in parallel)?\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nx = tf.ragged.constant([np.random.random(10+x) for x in range(5)])\r\nx = tf.expand_dims(x, -1)\r\ntf.keras.layers.Conv1D(7, 3)(x)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-209-09f9a8bce491> in <module>\r\n      4 x = tf.ragged.constant([np.random.random(10+x) for x in range(5)])\r\n      5 x = tf.expand_dims(x, -1)\r\n----> 6 tf.keras.layers.Conv1D(7, 3)(x)\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    983 \r\n    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):\r\n--> 985           outputs = call_fn(inputs, *args, **kwargs)\r\n    986 \r\n    987         if self._activity_regularizer:\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\r\n    245       inputs = array_ops.pad(inputs, self._compute_causal_padding(inputs))\r\n    246 \r\n--> 247     outputs = self._convolution_op(inputs, self.kernel)\r\n    248 \r\n    249     if self.use_bias:\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in convolution_v2(input, filters, strides, padding, data_format, dilations, name)\r\n   1016       data_format=data_format,\r\n   1017       dilations=dilations,\r\n-> 1018       name=name)\r\n   1019 \r\n   1020 \r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in convolution_internal(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\r\n   1146           data_format=data_format,\r\n   1147           dilations=dilations,\r\n-> 1148           name=name)\r\n   1149     else:\r\n   1150       if channel_index == 1:\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    572                   func.__module__, arg_name, arg_value, 'in a future version'\r\n    573                   if date is None else ('after %s' % date), instructions)\r\n--> 574       return func(*args, **kwargs)\r\n    575 \r\n    576     doc = _add_deprecated_arg_value_notice_to_docstring(\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    572                   func.__module__, arg_name, arg_value, 'in a future version'\r\n    573                   if date is None else ('after %s' % date), instructions)\r\n--> 574       return func(*args, **kwargs)\r\n    575 \r\n    576     doc = _add_deprecated_arg_value_notice_to_docstring(\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py in conv1d(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\r\n   1887           data_format=data_format,\r\n   1888           dilations=dilations,\r\n-> 1889           name=name)\r\n   1890     else:\r\n   1891       result = squeeze_batch_dims(\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\r\n    943           input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,\r\n    944           padding=padding, explicit_paddings=explicit_paddings,\r\n--> 945           data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\r\n    946     except _core._SymbolicException:\r\n    947       pass  # Add nodes to the TensorFlow graph.\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\r\n   1023         \"'conv2d' Op, not %r.\" % dilations)\r\n   1024   dilations = [_execute.make_int(_i, \"dilations\") for _i in dilations]\r\n-> 1025   _attr_T, _inputs_T = _execute.args_to_matching_eager([input, filter], ctx)\r\n   1026   (input, filter) = _inputs_T\r\n   1027   _inputs_flat = [input, filter]\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, default_dtype)\r\n    265         dtype = ret[-1].dtype\r\n    266   else:\r\n--> 267     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n    268 \r\n    269   # TODO(slebedev): consider removing this as it leaks a Keras concept.\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in <listcomp>(.0)\r\n    265         dtype = ret[-1].dtype\r\n    266   else:\r\n--> 267     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n    268 \r\n    269   # TODO(slebedev): consider removing this as it leaks a Keras concept.\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1497 \r\n   1498     if ret is None:\r\n-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1500 \r\n   1501     if ret is NotImplemented:\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    336                                          as_ref=False):\r\n    337   _ = as_ref\r\n--> 338   return constant(v, dtype=dtype, name=name)\r\n    339 \r\n    340 \r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    262   \"\"\"\r\n    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 264                         allow_broadcast=True)\r\n    265 \r\n    266 \r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    273       with trace.Trace(\"tf.constant\"):\r\n    274         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 275     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    276 \r\n    277   g = ops.get_default_graph()\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    298 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    299   \"\"\"Implementation of eager constant.\"\"\"\r\n--> 300   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    301   if shape is None:\r\n    302     return t\r\n\r\n~/venvs/pinpoint/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     97   ctx.ensure_initialized()\r\n---> 98   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     99 \r\n    100 \r\n\r\nValueError: TypeError: object of type 'RaggedTensor' has no len()\r\n```", "comments": ["@zowen,\r\nPlease refer this [Tensorflow Documentation for Ragged Tensor](https://www.tensorflow.org/guide/ragged_tensor#keras) which demonstrates on how to build a Model using `Ragged Tensor` and let us know if it helps. Thanks!", "Sure, I read through that before trying anything with Ragged Tensors. Since convolutions are not conceptually bound to fixed dimensions I would hope that it could be applied to a ragged tensor, leading me to raise this bug/feature request.", "@rmothukuru I agree with @zowen. It is not clear from the documentation or the exceptions whether keras convolutional ops support `RaggedTensor`. Can you clarify: Do tf.keras.Conv*D ops support `RaggedTensor` (and this is a bug) or don't they?\r\n\r\nIf they are _not_ supported I suggest the following:\r\n1. Mention it explicitly in the docs.\r\n2. Change the exception message to something like `TypeError: Convolution not supported for RaggedTensor`.\r\n\r\nTo add a similar use case in tf 2.3, py 3.7:\r\n```py\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import models, layers\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Input([None, None, 3], dtype=tf.int64, ragged=True))\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(None, None, 3)))\r\n```\r\ngets\r\n```sh\r\nTypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None, 3), dtype=int64), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), \r\ndtype=int64)), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)). Consider casting elements to a supported type.\r\n```\r\nThis seems more sensible given the \"Consider casting to a supported type.\" suggests that the type is not supported.\r\nFull stack trace\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\", line 548, in make_tensor_proto\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\", line 548, in <listcomp>       \r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\", line 87, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None, 3), dtype=int64), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)) \r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"c:\\Users\\iriley\\.vscode\\extensions\\ms-python.python-2021.1.502429796\\pythonFiles\\lib\\python\\debugpy\\__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"c:\\Users\\iriley\\.vscode\\extensions\\ms-python.python-2021.1.502429796\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 444, in main\r\n    run()\r\n  File \"c:\\Users\\iriley\\.vscode\\extensions\\ms-python.python-2021.1.502429796\\pythonFiles\\lib\\python\\debugpy/..\\debugpy\\server\\cli.py\", line 285, in run_file\r\n    runpy.run_path(target_as_str, run_name=compat.force_str(\"__main__\"))\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"c:\\Users\\iriley\\Documents\\projects\\Project1\\simple_conv.py\", line 6, in <module>\r\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(None, None, 3)))\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper \r\n    result = method(self, *args, **kwargs)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 221, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__       \r\n    input_list)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1117, in _functional_construction_call\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 247, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1018, in convolution_v2\r\n    name=name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1148, in convolution_internal       \r\n    name=name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2592, in _conv2d_expanded_batch     \r\n    name=name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 978, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 473, in _apply_op_helper\r\n    raise err\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 470, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1499, in convert_to_tensor       \r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 338, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 264, in constant\r\n    allow_broadcast=True)\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 282, in _constant_impl   \r\n    allow_broadcast=allow_broadcast))\r\n  File \"C:\\Users\\iriley\\Anaconda3\\envs\\py37_tf23\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\", line 552, in make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\nTypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None, 3), dtype=int64), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), \r\ndtype=int64)), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)). Consider casting elements to a supported type.\r\n```\r\n\r\nI can open another issue if that's necessary but it seemed better to add weight to this one.", "Was able to reproduce the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/d0d8ca5776f525038dc3ea74fec05869/untitled63.ipynb)..Thanks !", "@zowen I can reproduce the issue with `tf-nightly` (`TF2.8.dev`). \r\n As it is related to keras, Is it possible for you to move this issue to keras-team/keras repo?\r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42417\">No</a>\n"]}, {"number": 42416, "title": "Update ADOPTERS.md", "body": "Adding our Organizations. We extensively use tensorflow for all our AI applications.\r\n\r\n(I am also confused why this page is empty)", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42416) for more info**.\n\n<!-- need_sender_cla -->", "@dheerajpai  Can you please sign CLA. Thanks!", "@dheerajpai  Any update on this PR? Please. Thanks!", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42416) for more info**.\n\n<!-- ok -->", "@gbaned  Thanks so much for following up. I am quite surprised the adopter list is empty. ", "Can we just delete this file? It's clearly not representative of actual adoption, and it's unclear what it could be used for.", "Think that's probably wise. @dheerajmpai I don't believe this file gets a lot of traffic (as you may have noticed!). This might be better served on a tensorflow.org page. Can you let us know how you'd benefit from being listed, and we can point you in a better direction?", "@dheerajmpai  Can you please check @theadactyl's comments and keep us posted ? Thanks!", "Sure @theadactyl makes sense to delete this file. By publishing our use cases of Tensorflow we would get a better outreach. Not much of a benefit otherwise. ", "Thank you all , created a pull request [here](https://github.com/tensorflow/tensorflow/pull/42868) to delete the file."]}, {"number": 42415, "title": "Add aws_logging", "body": "@mihaimaruseac \r\nThis PR implements `Aws::Utils::Logging::LogSystemInterface`", "comments": []}, {"number": 42414, "title": "port TF Lite micro speech example to CEVA-DSP BX1", "body": "\r\nThis is a port of the Micro Speech example to CEVA-DSP BX1.\r\nthe PR is a continuation of PR37831 (https://github.com/tensorflow/tensorflow/pull/37831)\r\n\r\nThe issues raised there should be resolved now.\r\n\r\n", "comments": ["@yair-ehrenwald can you please update the branch , seems to be branch out of date ?", "> @yair-ehrenwald can you please update the branch , seems to be branch out of date ?\r\n\r\n\r\nShould be ok I think, @advaitjain merged and pushed to the branch? Let me know is there's something I should do.", "> > @yair-ehrenwald can you please update the branch , seems to be branch out of date ?\r\n> \r\n> Should be ok I think, @advaitjain merged and pushed to the branch? Let me know is there's something I should do.\r\n\r\n@yair-ehrenwald it looks like there are some conflicts since my last merge. If you could merge again then I'll approve and we can get this in.", "> @yair-ehrenwald it looks like there are some conflicts since my last merge. If you could merge again then I'll approve and we can get this in.\r\n\r\nDone....\r\n"]}, {"number": 42413, "title": "Export golang functions", "body": "These functions allow to run `saved_model` models in golang when those models have external library dependencies like `tensorflow_text` normalizers in BERT tokenizers.\r\nAlso export functions to determine size of the TF type - this is used when you want to preallocate space for the tensor in advance.\r\nAnd added reshape method which is self-explainatory.", "comments": []}, {"number": 42412, "title": "InternalError : failed to call ThenRNNBackward... on version 2.3 but not 2.1", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:/\r\n- TensorFlow installed from (source or binary): Installed with pip\r\n- TensorFlow version (use command below): tensorflow 2.3\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): /\r\n- GCC/Compiler version (if compiling from source): /\r\n- CUDA/cuDNN version: CUDA 10.1 and CuDnn 7.5\r\n- GPU model and memory: GeForce GTX 1070 with 6,2Gb memory\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nIn march, i coded the Tacotron-2 model with tensorflow 2.1 and trained it without issue (but some strange thing but not the subject of this issue)\r\nNow i want to retrain it with version 2.3 and at random step (less than 250), i have an error : \u00ab\u00a0InternalError : failed to call ThenRnnBackward with model config ...\u00a0\u00bb\r\n\r\nToday i downgraded tensorflow to version 2.1 and run the training loop and i am actually at step 1500 without the issue\r\n\r\nI also tried to downgrade at version 2.2 but the error still occurs\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nI can\u2019t share the whole code because it\u2019s too big (part of a big project) but here is a small description : \r\n- Model is tacotron-2 implementation inspired from pytorch NVIDIA so it has 1 BidirectionalLSTM in the encoder and 2 LSTMCell in the decoder\r\n- I use K.rnn to use a custom decoder step\r\n- The error occurs at the tape.gradient() call\r\n- I use custom training loop where i split the whole input frames into sub frames (because memory issue) so for a mel-spec of 400 frames, i make 8 optimization step of 50 frames (with passing the last LSTM-states to the next 50-frames block optimization step (it\u2019s really strange that my 6Gb memory only accepts 50 frames with batch_size 16 (75 frames run OOM))\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe model is actually training but i will share my training loop code and anything other you want when it\u2019s finished... i can also check my CuDnn version but i\u2019m pretty sure it\u2019s 7.5\r\n", "comments": ["> I can\u2019t share the whole code because it\u2019s too big (part of a big project) but here is a small description \r\n\r\n@Ananas120,\r\nWithout a reproducible code it is hard for us to pinpoint the issue. Could you please remove the dependencies and provide a simplest possible repro, so that it will be easier for us to debug the error. Thanks!", "Yes i will post my model architecture and training loop in 3 or 4 days... do you need also the dataset processing or just shapes / dtype to make fake inputs are ok (the processing is a custom mel spectrogram fn and tf.data.Dataset mapping) ?", "@Ananas120,\r\nThe original data and pre-processing steps would not be necessary. Fake inputs which can reproduce the error would be fine. Thanks!", "Ok nice ! i will share my code tomorrow morning on my github (i\u2019ll post the link here) (the architecture and the training step) (the training loop is just a for loop on the dataset and call to callbacks so not important)", "@amahendrakar  here is the link of the repo : https://github.com/Ananas120/Tacotron-2-tf2.0\r\n\r\nI don\u2019t test the training code (i just copy-paste the original one and removed the calls to \u2018self.xxx\u2019 by removing the self and passing the variable as argument) so i hope it works (i also added fake inputs to show the dtype and approximate shape)\r\n\r\nThe model is a C/C of the original i used (and had error) so normally it can be initialized without issue !\r\n\r\nEdit : something i noticed is that if i replace the \u00ab\u00a0call()\u00a0\u00bb by the \u00ab\u00a0call_old()\u00a0\u00bb in the Decoder, the error occurs much faster (step 50-150 instead of 150-300)", "@Ananas120,\r\nOn running the code I am facing an error stating `TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/cdb819e8cd25e8d81953837dcb4a69cb/42412.ipynb).\r\n\r\nCould you please provide a minimal reproducible code, so that we can look into this? Alternatively, you can run the code on Google Colab and share the notebook with us. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Sorry for the time, my vakanties will nearly ends so i need to finish my project so i train with the version 2.1 for now, I will retest with version 2.3 and share more code if it crashes in 1 or 2 weeks (you can close this issue if you want, i can re-open one if needed)", "@Ananas120,\r\nThank you for the update. Please feel free to re-open the issue when necessary. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42412\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42412\">No</a>\n", "@amahendrakar i updated my github by cleaning the code and replacing my SV2TTS tacotron by the original tacotron\r\nAlso i trained it and also have the error after around 300 steps\r\n\r\nI also have a strange warning when running the model saying that the input type of my BiLSTM-forward node isn\u2019t of the right type but the error is only shown on the command line of jupyter (and not in the notebook itself)\r\n\r\nHope my code will work !", "@Ananas120,\r\nThank you for the update. \r\n\r\nOn running the `train.py` file, I am facing an error stating `TypeError: __init__() missing 1 required positional argument: 'vocab_size'`.  Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/99a34554cbc7c1deff0b94c987a9cca5/42412.ipynb#scrollTo=IeM-n0BPBC2y). Thanks!", "@amahendrakar  i updated your colab code by C/C the train.py and correct bugs (so now it runs correctly as you can see)\r\nError occurs around step 200-400 so i think if you can run more than 1k steps without the error, it should be perfect but it never happens for me... \r\nAlso i think with a better GPU than mine you can increase the max_train_step (for me 50 is the max for non-graph mode and 25 on graph mode) with batch_size 48 (non-graph) and 64 (graph) \r\n\r\nNote : \u00ab\u00a0graph mode\u00a0\u00bb means only the `call()`method is in tf.function and not the optimization step function (when i put the optimize_step in graph i\u2019m not sure but i think it also raises an error)", "> @amahendrakar i updated your colab code by C/C the train.py and correct bugs (so now it runs correctly as you can see)\r\n\r\n@Ananas120,\r\nSeems like the changes have not been saved. Could you please make the same changes in your GitHub repo. Alternatively you can run the code on [Google Colab](https://colab.research.google.com/) and share the notebook with us. Thanks!", "Ah zut... i will do this today and say you when it\u2019s done \r\n\r\nEdit : @amahendrakar  it\u2019s done, in fact the changes were already saved but with my account... i updated the github repo\r\nI put max_frames to 25 but i think with more GPU memory you can upgrade this value to 50 or more (for me, with 6Gb GPU memory, it\u2019s 25 in graph-mode and 50 in sequential-mode)", "@amahendrakar  i corrected my github and today i had the same issue with a simple CNN model ended by a LSTM layer (in tf 2.3.1) so i suppose the LSTM layer has an issue in version > 2.1...", "@Ananas120,\r\nThank you for the update. I was able to run the code without any issues on TF v2.3, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c77e0956a871f2c57e9d6fba5bb7ba12/42412.ipynb). \r\n\r\nPlease try running the code in a virtual environment and check if you are still facing the same issue. Thanks!", "Ok thank\u2019s but in your gist i see you ran on 1 step and for me the error occurs only at step 300-400... so the code runs well for me too but not for a real training ^^\u2019", "@Ananas120,\r\nCould you please point out the required changes to be made to run the code for 400 steps? Thanks!", "Yes you should just run the \u00ab\u00a0train_step(...)\u00a0\u00bb function for n times (like \u00e0 simple for _ in range(500): loss = train_step(...)\u00a0\u00bb", "@Ananas120,\r\nI did not face any errors even on running the `train_step` function for 500 times. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c30551922fa8edda8bd2d001532da5d4/42412.ipynb#scrollTo=IfpfhWMBW09b). Thanks!", "Ok thank you but then i don\u2019t know why the error occurs for me... maybe because i run on Windows or i used an older version of jupyterlab... i updated it and will see if it happens ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42412\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42412\">No</a>\n"]}, {"number": 42411, "title": "Export golang functions", "body": "These functions allow to run `saved_model` models in golang when those models have external library dependencies like `tensorflow_text` normalizers in BERT tokenizers.\r\nAlso export functions to determine size of the TF type - this is used when you want to preallocate space for the tensor in advance.\r\nAnd added reshape method which is self-explainatory.", "comments": []}, {"number": 42409, "title": "Cannot initialize variables on GPU with keras?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.2\r\n- CUDA/cuDNN version: 10.2/7.4.2\r\n- GPU model and memory: Tesla V100-PCIe 32GB\r\n\r\n**Describe the current behavior**\r\nWhen I call `model.fit()` for a Keras model on the GPU, I get the following error message:\r\n```python\r\nInvalidArgumentError: Cannot assign a device for operation quantum_circuit/quantum_layer/ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node quantum_circuit/quantum_layer/ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\r\nResourceApplyAdam: CPU XLA_CPU XLA_GPU \r\n_Arg: GPU CPU XLA_CPU XLA_GPU \r\nReadVariableOp: GPU CPU XLA_CPU XLA_GPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  quantum_circuit_quantum_layer_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  adam_adam_update_resourceapplyadam_m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  adam_adam_update_resourceapplyadam_v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  quantum_circuit/quantum_layer/ReadVariableOp (ReadVariableOp) \r\n  Adam/Adam/update/ResourceApplyAdam (ResourceApplyAdam) \r\n\r\n\t [[{{node quantum_circuit/quantum_layer/ReadVariableOp}}]] [Op:__inference_train_function_6330]\r\n```\r\n\r\nI can avoid it if in the `build()` method of my custom Keras layers I call `add_weight()` inside a `tf.device('/CPU:0')` context (I tried this after I read the top post in issue https://github.com/tensorflow/tensorflow/issues/1310, from 2016!)\r\n\r\nIs this what should be done? It seems that the GPU is heavily underused if I do that.\r\n\r\n**Describe the expected behavior**\r\nI would expect Keras/TF to handle device assignment on its own, and not force me to adapt the code for each machine where it runs.\r\n\r\n**Standalone code to reproduce the issue**\r\nCode is way too long", "comments": ["I've also tried to explicitly call the code in my custom initializers (which I pass to `build(..., initializer=...)`) inside a `tf.device('CPU:0')` context, and to use `tf.config.set_soft_device_placement(True)`, but that leads me to the same error.", "What is the type of the variable?  `ResourceApplyAdam` has GPU kernels for floating point types.\r\n\r\n@jaingaurav should we be logging the dtypes from the error message above?", "In my model I use `float64` and `complex128` variables", "@ziofil  Could you please try on latest stable version of tf 2.5 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42409\">No</a>\n", "same on tf1.15"]}, {"number": 42408, "title": "TensorflowJs Incompatible shapes Error", "body": "I build Unet architecture with TensorFlow Js.\r\nBut I faced a problem with Incompatible shapes error.\r\nMy input was [512, 512, 3] 3d tensor and label is [512, 512] 2d tensor.\r\n\r\nmy model was\r\n\r\n    const input_layer = tf.input({ shape: [512, 512, 3], name: 'image_input'});\r\n    \r\n    const conv1 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(input_layer);\r\n    const batch1 = tf.layers.batchNormalization().apply(conv1);\r\n    const act1 =  tf.layers.activation({activation: 'relu'}).apply(batch1);\r\n    const conv11 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(act1);\r\n    const batch11 = tf.layers.batchNormalization().apply(conv11);\r\n    const act11 =  tf.layers.activation({activation: 'relu'}).apply(batch11);\r\n    const conv1_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act11);\r\n    \r\n    const conv2 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(conv1_out);\r\n    const batch2 = tf.layers.batchNormalization().apply(conv2);\r\n    const act2 =  tf.layers.activation({activation: 'relu'}).apply(batch2);\r\n    const conv22 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(act2);\r\n    const batch22 = tf.layers.batchNormalization().apply(conv22);\r\n    const act22 =  tf.layers.activation({activation: 'relu'}).apply(batch22);\r\n    const conv2_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act22);\r\n    \r\n    const conv3 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(conv2_out);\r\n    const batch3 = tf.layers.batchNormalization().apply(conv3);\r\n    const act3 =  tf.layers.activation({activation: 'relu'}).apply(batch3);\r\n    const conv33 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(act3);\r\n    const batch33 = tf.layers.batchNormalization().apply(conv33);\r\n    const act33 =  tf.layers.activation({activation: 'relu'}).apply(batch33);\r\n    const conv3_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act33);\r\n    \r\n    const conv4 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(conv3_out);\r\n    const batch4 = tf.layers.batchNormalization().apply(conv4);\r\n    const act4 =  tf.layers.activation({activation: 'relu'}).apply(batch4);\r\n    const conv44 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(act4);\r\n    const batch44 = tf.layers.batchNormalization().apply(conv44);\r\n    const act44 =  tf.layers.activation({activation: 'relu'}).apply(batch44);\r\n    const conv4_out = tf.layers.maxPooling2d({ poolSize: [2, 2] }).apply(act44);\r\n    const conv4_dropout = tf.layers.dropout({rate: 0.5}).apply(conv4_out);\r\n    \r\n    const conv5 = tf.layers.conv2d({ filters: filter*16, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(conv4_dropout);\r\n    const batch5 = tf.layers.batchNormalization().apply(conv5);\r\n    const act5 =  tf.layers.activation({activation: 'relu'}).apply(batch5);\r\n    const conv55 = tf.layers.conv2d({ filters: filter*16, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(act5);\r\n    const batch55 = tf.layers.batchNormalization().apply(conv55);\r\n    const act55 =  tf.layers.activation({activation: 'relu'}).apply(batch55);\r\n    const conv5_dropout = tf.layers.dropout({rate: 0.5}).apply(act55);\r\n    \r\n    //Second part (up climb)\r\n    const deconv6 = tf.layers.conv2dTranspose({ filters: filter*8, kernelSize: [3, 3], strides: [2, 2], padding: \"same\" }).apply(conv5_dropout);\r\n    const deconv6_con = tf.layers.concatenate({axis: 3}).apply([deconv6, act44]);\r\n    const deconv6_conv1 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv6_con);\r\n    const deconv6_batch1 = tf.layers.batchNormalization().apply(deconv6_conv1);\r\n    const deconv6_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv6_batch1);\r\n    const deconv6_conv11 = tf.layers.conv2d({ filters: filter*8, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv6_act1);\r\n    const deconv6_batch11 = tf.layers.batchNormalization().apply(deconv6_conv11);\r\n    const deconv6_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv6_batch11);\r\n    const deconv6_dropout = tf.layers.dropout({rate: 0.5}).apply(deconv6_act11);\r\n    \r\n    const deconv7 = tf.layers.conv2dTranspose({ filters: filter*4, kernelSize: [3, 3], strides: [2, 2], padding: \"same\" }).apply(deconv6_dropout);\r\n    const deconv7_con = tf.layers.concatenate({axis: 3}).apply([deconv7, act33]);\r\n    const deconv7_conv1 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv7_con);\r\n    const deconv7_batch1 = tf.layers.batchNormalization().apply(deconv7_conv1);\r\n    const deconv7_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv7_batch1);\r\n    const deconv7_conv11 = tf.layers.conv2d({ filters: filter*4, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv7_act1);\r\n    const deconv7_batch11 = tf.layers.batchNormalization().apply(deconv7_conv11);\r\n    const deconv7_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv7_batch11);\r\n    const deconv7_dropout = tf.layers.dropout({rate: 0.5}).apply(deconv7_act11);\r\n    \r\n    const deconv8 = tf.layers.conv2dTranspose({ filters: filter*2, kernelSize: [3, 3], strides: [2, 2], padding: \"same\" }).apply(deconv7_dropout);\r\n    const deconv8_con = tf.layers.concatenate({axis: 3}).apply([deconv8, act22]);\r\n    const deconv8_conv1 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv8_con);\r\n    const deconv8_batch1 = tf.layers.batchNormalization().apply(deconv8_conv1);\r\n    const deconv8_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv8_batch1);\r\n    const deconv8_conv11 = tf.layers.conv2d({ filters: filter*2, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv8_act1);\r\n    const deconv8_batch11 = tf.layers.batchNormalization().apply(deconv8_conv11);\r\n    const deconv8_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv8_batch11);\r\n    \r\n    const deconv9 = tf.layers.conv2dTranspose({ filters: filter, kernelSize: [3, 3], strides: [2, 2], padding: \"same\" }).apply(deconv8_act11);\r\n    const deconv9_con = tf.layers.concatenate({axis: 3}).apply([deconv9, act11]);\r\n    const deconv9_conv1 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv9_con);\r\n    const deconv9_batch1 = tf.layers.batchNormalization().apply(deconv9_conv1);\r\n    const deconv9_act1 =  tf.layers.activation({activation: 'relu'}).apply(deconv9_batch1);\r\n    const deconv9_conv11 = tf.layers.conv2d({ filters: filter, kernelSize: [3, 3], activation: \"relu\", padding: \"same\", kernelInitializer: \"heNormal\" }).apply(deconv9_act1);\r\n    const deconv9_batch11 = tf.layers.batchNormalization().apply(deconv9_conv11);\r\n    const deconv9_act11 =  tf.layers.activation({activation: 'relu'}).apply(deconv9_batch11);\r\n    \r\n    const output_layer = tf.layers.conv2d({ kernelSize: [1, 1], activation: \"softmax\", filters: 5}).apply(deconv9_act11);\r\n    \r\n    const model = tf.model({ inputs: input_layer, outputs: output_layer, name: \"Unet\" });\r\n    \r\n    model.compile({ loss: 'categoricalCrossentropy', optimizer: 'adam', metrics: ['accuracy'] });\r\n\r\nand my train code was\r\n\r\n    const xs = await tf.data.generator(data);        // input tensor3d [512, 512, 3]\r\n    const ys = await tf.data.generator(labels);      // input tensor2d [512, 512]\r\n    \r\n    const ds = await tf.data.zip({xs, ys}).shuffle(2).batch(2);\r\n    \r\n    const model = await initModel();\r\n    model.summary();\r\n    \r\n    await model.fitDataset(ds, {epochs: 5}).then(info => {\r\n      console.log('Accuracy', info.history.acc);\r\n    });\r\n\r\nAnd I got this error message\r\n\r\n    Incompatible shapes: [2,512,512] vs. [2,512,512,5]\r\n\r\n", "comments": ["@Shanmax1996,\r\nIssues related to TensorFlow.js are handled in the tensorflow/tfjs repo. Could you please submit a new issue from [this link](https://github.com/tensorflow/tfjs/issues/new) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 42407, "title": "Failed to load the native TensorFlow runtime.", "body": "Hi,\r\n\r\nAfter pip installing tensorflow I get the following message when importing it.\r\n\r\nimport tensorflow\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-9-d6579f534729>\", line 1, in <module>\r\n    import tensorflow\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\yaniv_cfrphva\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "Edit: ~Are you using Windows?~ You are, as can be seen from the stack trace.\r\nIn this case, have you installed the [ Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)? If not, this is a quite likely cause.", "@yanivbarlev \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156), to ensure your system suits the requirements.\r\n\r\n\r\nalso, refer similar issues and let us know:\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204 #39007\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42407\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42407\">No</a>\n", "ImportError: /usr/lib64/libm.so.6: version `GLIBC_2.23' not found (required by /data//anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nImportError: /usr/lib64/libm.so.6: version `GLIBC_2.23' not found (required by /data//anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n", "Failed to load the native TensorFlow runtime.\r\nI am facing this issue", "**(Not for conda) Simple thing to do is ADD TO THE PATH...**\r\n\r\nCheck where the packages are installed (the directory...)  \r\n        WARNING: The script (name).exe is installed in '_C:\\Users\\(name)\\AppData\\Roaming\\Python\\Python39\\Scripts_' which is not \r\n        on PATH. **Consider adding this directory to PATH** or, if you prefer to suppress this warning, use --no-warn-script-location.\r\n\r\nthen import the module and verify...", "Facing this issue on Ubuntu 20 and tf 1.12.0\r\n\r\nany solutions?"]}, {"number": 42406, "title": "Add None check to restorer", "body": "When the graph has nothing to restore, `saver_lib.import_meta_graph` returns `None`. \r\nThis commit adds a None check for `restorer`.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42406) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42406) for more info**.\n\n<!-- ok -->"]}, {"number": 42405, "title": "Pybind11 exception with tensorflow 2.2 env in python cpp communication", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.2\r\n- TensorFlow version (use command below):2.2\r\n- Python version:3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10, 10.1,8.0 / 7.6.5\r\n- GPU model and memory:  NVIDIA Geforce GTX 1050 Ti & 12 GB\r\n\r\n**Describe the current behavior**\r\nProblem : \r\n\r\nBelow code is working fine while running through tensorflow2.0 env but same code if I run through tensorflow2.2 env then it's give below exception at PYObject_CallObject(pFunc, NULL)\r\n\r\nError : Microsoft c++ exception : pybind11::error_already_set at memory location XXXXXX\r\n\r\n**Describe the expected behavior**\r\nshould not through pybind11::error_already_set while just importing tensorflow library\r\n\r\n**Standalone code to reproduce the issue**\r\nBelow is CPP calling python file source code for a reference.\r\n       #define PY_SSIZE_T_CLEAN\r\n       #include <Python.h>\r\n       using namespace std;\r\n    \tint main(int argc, char *argv[])\r\n\t{\r\n\tPyObject *pName, *pModule, *pFunc;\r\n\tPyObject *pArgs, *pValue;\r\n\tint i;\r\n\tstring pythonFunction = \"sample_fun\";\r\n\tstring pythonFile     = \"sample\"\r\n    string tensoflow_env  = \"tensorflow_env_path\";\r\n    wchar  *env = Py_DecodeLocale(tensoflow_env.c_str(),NULL);\r\n    Py_SetPythonHome(env);\r\n\tPy_Initialize();\r\n\tpName = PyUnicode_DecodeFSDefault(pythonFile.c_str());\r\n\t/* Error checking of pName left out */\r\n\r\n\tpModule = PyImport_Import(pName);\r\n\tPy_DECREF(pName);\r\n\r\n\tif (pModule != NULL) {\r\n    pFunc = PyObject_GetAttrString(pModule, pythonFunction.c_str());\r\n    /* pFunc is a new reference */\r\n\r\n    if (pFunc && PyCallable_Check(pFunc)) {\r\n        \r\n        pValue = PyObject_CallObject(pFunc, NULL);\r\n        if (pValue != NULL) {\r\n            Py_DECREF(pValue);\r\n        }\r\n        else {\r\n            Py_DECREF(pFunc);\r\n            Py_DECREF(pModule);\r\n            PyErr_Print();\r\n            fprintf(stderr,\"Call failed\\n\");\r\n            return 1;\r\n        }\r\n    }\r\n    else {\r\n        if (PyErr_Occurred())\r\n            PyErr_Print();\r\n        fprintf(stderr, \"Cannot find function \\\"%s\\\"\\n\", argv[2]);\r\n    }\r\n    Py_XDECREF(pFunc);\r\n    Py_DECREF(pModule);\r\n\t}\r\n\telse {\r\n\t\tPyErr_Print();\r\n\t\tfprintf(stderr, \"Failed to load \\\"%s\\\"\\n\", argv[1]);\r\n\t\treturn 1;\r\n\t}\r\n\tif (Py_FinalizeEx() < 0) {\r\n    return 120;\r\n\t}\r\n\treturn 0;\r\n}\r\n\r\nBelow is sample.py file for a reference.\r\n\r\n    def sample_fun():\r\n\t   import tensorflow as tf\r\n       return 'Success'\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nBy running above code with tensorflow 2.2 then issue is easily reproduce. \r\n", "comments": ["@spratik Pleast try using tensorflow 2.3.0 in a new environment and let me know if the issue still persists. Thanks!", "I have checked with tensorflow 2.3.0 environment with Python 3.7.7. Issue is still persists.  Thanks!", "Can you please provide more information? The full stacktrace of the error perhaps. We did start using pybind11 in version 2.1 so this is probably related. \r\n\r\nOur pybind11 code has a lot of error checks that throw that particular error. [Example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tfe_wrapper.cc#L100)\r\n\r\nUnfortunately since the default import for tensorflow is working, I don't think the issue lies in the tensorflow import. There is perhaps something in your code that is throwing one of the pybind11 errors.", "I have taken reference of sample CPP code(**Above in description** )which call python **sample_fun** .  from below link.\r\nhttps://docs.python.org/3.8/extending/embedding.html\r\n\r\nBelow is call stack for your reference.\r\n![image](https://user-images.githubusercontent.com/27050597/91275752-32b82780-e79e-11ea-84e8-666502dac205.png)\r\n![image](https://user-images.githubusercontent.com/27050597/91275775-3a77cc00-e79e-11ea-8717-fb0dcd7c5221.png)\r\n![image](https://user-images.githubusercontent.com/27050597/91275796-3fd51680-e79e-11ea-9339-14bd0454cdb3.png)\r\n\r\nBelow is Exception which I am getting whenever \"import tensorflow as tf \" line is executed in python\r\n![image](https://user-images.githubusercontent.com/27050597/91275982-7e6ad100-e79e-11ea-99f4-c52f7b2c54ee.png)\r\n\r\nI have also check memory location mention in screen short.it's seems to be non readable  character.\r\n\r\nwith that above sample code . I can able to reproduce issue easily whenever \"import tensorflow as tf \" line is executed for tensorflow 2.2 environment . \r\n\r\nLet me know anything required to modify in sample CPP code in order to remove Exception.", "So a simply import tensorflow in Python3.8 is failing on Windows? Even if you remove your code? Usually throwing error_already_set from C++ leads to a Python exception. Can you somehow see the Python exception behind that C++ exception?", "I have tried with python 3.7.6 and 3.7.7. there is no issue if I simply run  import tensorflow. I have not checked with python 3.8 version. Problem arise when call python file through C++. Then only this pybind11: error already set error is coming. \r\n\r\nI have tried  using try and except block for catch error.  But problem is that except block is unable to catch exception and return safely. Instead python throw an pybind11 error already set exception while import tensorflow as tf line into Cpp wrapper.\r\nBelow is code . Which I have tried. \r\ntry:\r\n   Import tensorflow as tf\r\nexcept Exception as e :\r\n    return str(e)\r\n\r\nMeans, I am not getting any exception from python side even though except block already there.. whenever import tensorflow line executed at that time cpp wrapper received pybind11 error already set error. \r\n\r\nLet me know anything else you want to check", "Okay so I guess you're trying to invoke a Python file from C++. And the regular import works, so there is something happening from the C++ invocation. Do you have exceptions enabled? Can you potentially print the error in your C++ code before the line that throws the error is executed? \r\n\r\nUnfortunately I'm not sure what we can do here. ", "Can you try importing the module using pybind11 import functionality as documented [here](https://pybind11.readthedocs.io/en/stable/advanced/embedding.html#importing-modules)?\r\n\r\nEDIT: Updated link.", "below Do you have exceptions enabled? --> Yes I have enable it then only you can see the pop message as I mention in my previous comment.\r\n\r\nCan you potentially print the error in your C++ code before the line that throws the error is executed?--> there is no error before the line that throws the error in c++.\r\n\r\nBelow are experiment I have tried in order to resolved issue but unfortunately I couldn't \r\n1)  I think By mistake you have given different link of Pybind11.  Anyway I have already tried with pybind11 wrapper taken below document as reference.\r\n    https://pybind11.readthedocs.io/en/stable/advanced/embedding.html\r\n\r\n    use **py::module::import** function . with that also getting same error same error(pybind11::error_already_set at \r\n    memory location XXXXX).\r\n\r\n  2 ) I have also  tried with one more wrapper called **boost :: python** with that also I am getting same error as mention above.\r\n\r\n3) Checked **tensorflow 2.2 with python 3.8.5** with that also face same issue as mention above.\r\n\r\nI believe that there is issue either from pybind11 side or tensorflow side. I am not sure.  if you can reproduce issue in your system then I think you will get clear idea about Issue.\r\n\r\nPlease Let me know anything else you want me to check.  ", "Yes, sorry about that, my intent was to post the pybind11 docs link that you provided. Regardless, it appears you've already tried that.\r\n\r\nCan you potentially try simpler imports? That might help us narrow down if it's python or pybind11 calling back into pybind11.\r\n\r\n`from tensorflow.python import _pywrap_utils` for example.\r\n\r\nIf you can provide me with a branch to checkout with a bazel target that is the bare minimum `py::module::import` and instructions to repro, I can see if I can repro the issue on a Windows VM. ", "I am not sure about branch but I have install pybind11 package from below link\r\nhttps://pypi.org/project/pybind11/\r\n\r\nI assume that pybind11 is wrapper around existing python cpp communication source code which I mention in main description. \r\n![image](https://user-images.githubusercontent.com/27050597/91572781-5c22b000-e964-11ea-8cf7-ab413583a704.png)\r\n\r\nbelow is bare minimum source code which to reproduce issue.\r\n\r\n**C++ code.**\r\n\r\n#define PY_SSIZE_T_CLEAN\r\n#include <Python.h>\r\n#include <iostream>\r\nusing namespace std;\r\nint main(int argc, char *argv[])\r\n{\r\nPyObject *pName, *pModule;\r\nstd::string pythonFile = \"sample\"\r\nstd::string tensoflow_env = \"tensorflow_env22_path\";\r\nwchar env = Py_DecodeLocale(tensoflow_env.c_str(),NULL);\r\nPy_SetPythonHome(env);\r\nPy_Initialize();\r\npName = PyUnicode_DecodeFSDefault(pythonFile.c_str());\r\npModule = PyImport_Import(pName);\r\n\r\nPy_DECREF(pName);\r\nPy_DECREF(pModule);\r\n\r\nif (Py_FinalizeEx() < 0) {\r\nreturn 120;\r\n}\r\nreturn 0;\r\n}\r\n\r\n**Python Code :**\r\nBelow is sample.py file for a reference.\r\n\r\nimport tensorflow as tf\r\n\r\n\r\n**Note** that you have to set below path in system environment path variable. then only above code will work.\r\n<Tensorflow_flow_env22>\\\r\n<Tensorflow_flow_env22>\\Scripts\r\n<Tensorflow_flow_env22>\\Library\\bin\r\n\r\nI have used Visual studio 2015 with v140 compiler. \r\n", "Unfortunately, I cannot help you without a bazel target. Due to resource restrictions, I cannot try and execute client source code and repro their environment for user specific issues. Can you please convert this into a [bazel target](https://docs.bazel.build/versions/master/be/c-cpp.html#cc_binary) for me to run? That way I can just easily execute and repro the error and see if it occurs on all operating systems. Unfortunately, I will not be able to duplicate your setup and run your individual source code. \r\n\r\nFrom what I can see, this is not a standalone issue with TensorFlow, but rather an issue that propagates when importing the TensorFlow Python module from C++. It may be better suited for StackOverFlow as well as per [our guidelines](https://github.com/tensorflow/tensorflow#contribution-guidelines). \r\n\r\nI also noticed you mentioned that the address of the error is an unreadable character. Have you tried a try catch block and then reading the Python error that has been set using `PyErr_PrintEx` ([docs](https://docs.python.org/3/c-api/exceptions.html#c.PyErr_PrintEx))? \r\n\r\nAdditionally does the error still occur on more basic imports like `from tensorflow.python import _pywrap_utils` for example?\r\n", "**_Can you please convert this into a bazel target for me to run?_** --> due to some security reason, I can't able share bazel target.\r\n\r\nI have uploaded same question in stack overflow long time back. I have not get any response so far.  May be because of not tagged in tensorflow group. I have tagged to tensorflow group now.  let's see if I will get any break through I will update here.  below is stackoverflow question for your reference. \r\nhttps://stackoverflow.com/questions/63389566/pybind11-exception-with-tensorflow-2-2-env-in-python-cpp-communication\r\n\r\n**_I also noticed you mentioned that the address of the error is an unreadable character. Have you tried a try catch block and then reading the Python error that has been set using PyErr_PrintEx (docs)?_**\r\n\r\nUnfortunately PyErr_printEx is unable to print anything on the terminal while Pybind11:error_already_set exception occurred . I am not sure why PyErr_printEx  is not printing anything but PyErr_printEx is working fine if there is any error like argument is missing during function call in python. for those kind of error , PyErr_printEx  function is working and showing proper error.  ( **Note That I have done this experiment after disabling all exception in visual studio 2015 so that program won't crash.** )\r\n\r\nI have already tried with Try and catch block in C++ wrapper as well. unfortunately in try block only getting same exception. catch block doesn't get anything even though there is py:bind11::error_already_set exception has been thrown from PyImport_Import function.\r\n\r\n **Problem ::** while executing  PyImport_Import(\"sample\") line , getting py:bind11::error_already_set exception. Currently there is no mechanism to catch pybind11 error which is set internally during execution of PyImport_Import function. If we have that then we can see what could be possible reason. \r\n\r\ntry {\r\n   PyObject *pobj = PyImport_Import(\"sample\");\r\n   if(!pobj){\r\n         throw py::error_already_set ()\r\n   }\r\n}\r\ncatch (py::error_already_set &e){\r\n\r\n}\r\n\r\nNote : sample.py file same as in my previous comment.\r\n\r\n\r\n\r\nBelow is snipped of memory location while pybind11:error_already_set at memory location  exception occurred.  you can see that there is non readable char.  do you have idea how to read this ?\r\n![image](https://user-images.githubusercontent.com/27050597/91701664-3e885d00-eb95-11ea-880b-375c86cab3fd.png)\r\n\r\n**_Additionally does the error still occur on more basic imports like from tensorflow.python import _pywrap_utils for example?_**\r\n\r\nYes error is still persist. \r\n\r\n\r\nI hope that I am able to convey actually problem happening while importing tensorflow. we can see clearly that this is problem from either pybind11 or tensorflow side.  Do you have any idea? ", "The fact that it is happening or basic imports may mean that it's a systemic issue where the sandwich of your `C++ code -> Python C API -> Python Import of TensorFlow -> Using pybind11 to call C++` is just something that is not supported. I think the next step I'd try is to setup a barebones pybind11 Python module and see if you can import it via your code. So for example I have a [math pybind11 + bazel module](https://github.com/av8ramit/pybind_example/tree/master/module) here you can try. Then we can at least narrow it to either TensorFlow or pybind11. \r\n\r\n", "As I am very new for bazel. I have installed bazel from site which you shared. below is error that I am getting while running github source code which you have shared.\r\n\r\n![image](https://user-images.githubusercontent.com/27050597/91830538-87f1ae80-ec60-11ea-821d-e866b550e3b9.png)\r\n![image](https://user-images.githubusercontent.com/27050597/91830577-94760700-ec60-11ea-91c7-3274bc526326.png)\r\n\r\nI have an question. is there any specific reason you want to build source code with bazel. without bazel also, I can able to run source code. \r\n\r\nI have set bazel envrionment path in system env  and set python env path", "Oh there is no need for it to be with bazel. I thought it may be convenient for you. Does it work without bazel?", "Yes this is working without bazel itself. I have already specify my setup details in main description. I believe that I have provided sufficient information from my side regarding issue. can you please try to resolve issue from your side ?", "Thanks for your patience and answering the questions I had. Unfortunately, I'm not sure what else the issue could be. I'm really sorry I was unable to pinpoint it. I think the fact that a simple pybind11 module can be loaded shows that the issue is in TensorFlow, but without a simpler unit test or bazel target, I cannot reproduce this easily.\r\n\r\nI'll keep this issue open in the event someone else has seen similar errors. ", "As I am very new to bazel. below is my basic  doubt regarding bazel.\r\n- Is bazel target complete package? means  that If I provide bazel target with above source code. You can directly run bazel target in your system without worry about required software install and set environment ? \r\n\r\nI believe that the software which I mention in description those are common software in order to work with tensorflow 2.2. I assume that installing these softwares wouldn't be such issue. ", "Bazel is just the build system, so you'll need toolchains and python dependencies installed and appropriate environment variables set. Since you're just trying to import a pip package, I don't think bazel is an issue. ", "You mean to say that bazel is build system similar  like makefile  right ?\r\n\r\nIn this cases, I believe that you don't need to bazel target. Because you only need required software as I mention in main description \r\n\r\nI have created repository for this source code. Below is link for a reference. \r\nhttps://github.com/spratik/python_cpp_communication\r\n\r\nI have mention required details regarding environment setup and configuration in readme.md file.\r\nI hope with above source code you can easily reproduce issue. Let me know if you face any issue.\r\n", "Are you able to reproduce issue?  Please let me know if you need any help from my side to reproduce issue.", "Yes, bazel and makefile serve a similar purpose, but bazel targets are significantly easier to run for us.\r\n\r\nUnfortunately, I have not tried to reproduce your environment due to resource and policy reasons, but hopefully maybe someone else in the community has seen this before. ", "Assume if I provide bazel target also. There also you need v140 (visual studio 2015 ) complier and above mentioned required software.  Irrespective of method we choose , you need required software in order to reproduce issue.  The GitHub link which I shared with you in which I mention clear guidelines what step you need to follow to setup the project. That is very easy to configure. Hardly it will take some time to configure. \r\nCan't it possible from your end to configure same project configuration which I mention in GitHub link?", "I manage to create bazel target as per your request. \r\nPlease find below github link for same for your reference.\r\nhttps://github.com/spratik/Python_CPP_Bazel_target\r\n\r\nPlease read readme.md file where I have mention required step to execute before run bazel target. \r\nI hope that now you can easily run bazel target in your system. still I if you face any issue please let me know.", "Hello spratik,\r\n\r\nAs we discussed on our email correspondences, I was encouraging you to create a bazel test within the tensorflow repo. Regardless, I will still take ownership of the miscommunication. As a courtesy since I did originally tell you that a bazel target would easily allow me to execute, I tried running your bazel target and ran into the following issue `main/python_cpp.cc:2:20: fatal error: Python.h: No such file or directory`. Additionally I think you have some typos in the setup instructions, particularly the copy instructions.\r\n\r\nUnfortunately, I am unable to help you further, but hopefully you'll be able to resolve the issue. I recommend pursuing the avenue of trying to find a way to print the error message we discussed in the previous comments. Good luck!", "I have mention in readme.md file that you need copy below folders\r\n\r\n<tensorflow2.2>\\include\r\n<tensorflow2.2>\\libs\r\n\r\nThen past into below folder path.\r\n <path>/Python_CPP_Bazel_target/thirdParty/tensorflow\r\n\r\nIf you copy successful then I don't think you will get above error. \r\n\r\nDid you copy above folders ?\r\n\r\nUsually this error occurred due to file is not present in include folder. If file is present in include folder then you shouldn't be getting this error.\r\nCan you please check Python.h file present in include folder?\r\n\r\nif everything above you have done already and still you are facing same issue then I will create bazel  target within tensorflow. ", "As per your recommendation , I have created bazel target within tensorflow environment itself.\r\nPlease find below GitHub link for a reference.\r\nhttps://github.com/spratik/python_cpp_with_tensorflow_bazel_target\r\n\r\nI have mention required steps in readme.md file. hopefully now you can able to run bazel target without getting any error. Please let me know if you face any issue. \r\n\r\nActually this problem we are discussion since 26 days and nothing get concluded. hopefully after reproducing issue you can give some suggestion whether actually it's problem from tensorflow side or other issue. we can fix accordingly. ", "I am wrapping some of the tensorflow functionality in C++ application using pybind11. I am getting same errors: \r\n**Exception thrown at 0x00007FFA6B693B29 in bindingSample.exe: Microsoft C++ exception: pybind11::error_already_set at memory location 0x0000006092BFDD70**. (see pictures)\r\nThey are appearing when model is being constructed and compiled and right after that exceptions stop. Although these exceptions are not critical and I can still train my model.\r\n![tensorflowPybind11](https://user-images.githubusercontent.com/22094617/93089240-afef0200-f6a3-11ea-8d0d-e48caf41078a.png)\r\n", "Also appear in data loader call", "I have also observed the same. Is it good idea to ignore exception thrown whenever we import tensorflow libs through C++ Wrapper and by using pybind11/pyobject ? \r\n\r\nIs this issue really not critical? What is consequences if we ignored it? \r\n\r\nThere is something happen whenever we are import tensorflow libs.  Is there any way you can figured out why exception has been thrown whenever we will import tensorflow libs?  This exception is not thrown for loading other libs like Opencv,numpy,json,....etc", "I actually don't know if it is good to ignore it :) Exceptions handling in pybind11 is a bit unclear (pybind11::error_already_set is not intuitive). And I tried to do `PyErr_Print();`  right after exception appears. However, exceptions throw stops right after specific functions call (model build or data generator build), so `PyErr_Print();` doesn't print out anything. However, these exceptions appear only when Tensorflow functionality call is from C++ (pybind11). I didn't experience anything (any exceptions) while I am training models in Python environments (IDE like PyCharm or call from console). I have my binding here [https://github.com/rytisss/CPPPythonBindDeepLearning](https://github.com/rytisss/CPPPythonBindDeepLearning), you can check (it has also submodule to another repository where networks are declared, do recursive clone if you want to check it).\r\nAbout the other libs, I don't really know. I am using OpenCV in my projects a lot. I am currently working on this, if something comes up, I will let you know :)", "sorry for late response. \r\n\r\n_- I didn't experience anything (any exceptions) while I am training models in Python environments (IDE like PyCharm or call from console)_ ---> if we only execute python file then its working fine without any exception . I believe that  repository which you shared there also you have faced pybind11:error already set exception  whenever python file call from C++ wrapper using pybind11 as you have used tensorflow lib ?\r\n\r\n _I tried to do PyErr_Print(); right after exception appears. However, exceptions throw stops right after specific functions call (model build or data generator build)_, so PyErr_Print()_; --> I have also observed same.  whenever User call py::module::import(\"trainingListener\") this function at that time only pybind11:error already set  exception occurred as you have used tensorflow lib. means inside import function itself this exception is coming. \r\n\r\nI feel that pybind11:error already set  exception is not handled correctly in tensor flow 2.2 package thus **this is bug from tensorflow 2.2 package**. we are even not sure because of what reason pybind11:error already set error is coming whenever User used tensorflow lib so **what do you suggest regarding this bug**?\r\n\r\n\r\n", "I actually did not make a decision yet :) although wrapping python with c++ (using pybind11) seems to be really constrained (in my specific case), because the end application will be using C#.Net. I experienced that CLR (common language runtime [c++ and c# bridge]) cannot handle python module creation in C++/Managed C++ side (**Common Language Runtime Detected an Invalid Program**) so probably I wont try to make a solution with pybind11. Another way that I will be moving will probably be to use two separate applications communicating through sockets (localhost).\r\n", "I have understood that in your specific cases you want to call C++ code from C# but at that end you will be calling C++ code only with different method so pybind11 exception will definitely come.  As per your previous comment , you are successfully reproduce this issue and we are also not sure about whether it's good to ignore pybind11 exception or not.  I believe that this is enough proofs that this is bug from tensorflow 2.2. we should report this bug.", "Yes, it is like you explained, I just need the intermediate layer of CLR between C# and C++. Although it doesn't change that point of exception handling. As you mentioned, the exceptions might be handled in weird way. Moreover, pybind11 exception in this case is really not intuitive (not self-explanatory and not even close to it)", "@spratik It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest stable version of TF ( 2.5.0) and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42405\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42405\">No</a>\n"]}]