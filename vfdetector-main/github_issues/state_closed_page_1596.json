[{"number": 5032, "title": "AttributeError: 'module' object has no attribute 'batch_fft'", "body": "Hi, \n\nI just reinstalled rebuilt tensorflow from source to use CUDA v8 (I changed GPU to gtx1070)\n\nI was running tf.batch_fft perfectly fine previously. But now it returns \n\nAttributeError: 'module' object has no attribute 'batch_fft'\n\nCan someone point me to where this batch_fft is implemented now? I am using version 0.11.0rc0 now. \n\nI can't remember if I was using 0.10 previously or not. Did the API change?\n\nThanks in advance! :) \n", "comments": ["Use `tf.fft` now\n\n(For the curios, see commit 9287c2f08c8bf407074071a8a5ff57a4a54db05e)\n\nHope that helps!\n"]}, {"number": 5031, "title": "Branch 136159650", "body": "", "comments": ["@drpngx, thanks for your PR! By analyzing the history of the files in this pull request, we identified @nsthorat, @dsmilkov and @charlesnicholson to be potential reviewers.\n", "Jenkins, test this please.\n"]}, {"number": 5030, "title": "Branch 136351181", "body": "", "comments": []}, {"number": 5029, "title": "Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz ", "body": "Firstly, there is no internet access. And I'm sure protobuf is installed successly:\n\n```\nprotoc --version\nlibprotoc 3.1.0\n```\n\nBut there is the error on the tensorflow's configure:\n\n```\n./configure \n/data/home/darrenqiu/tensorflow-master /data/home/darrenqiu/tensorflow-master\nPlease specify the location of python. [Default is /usr/local/bin/python]: \nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\nNo Hadoop File System support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/site-packages]\n\n/usr/local/lib/python2.7/site-packages\nDo you wish to build TensorFlow with GPU support? [y/N] n\nNo GPU support will be enabled for TensorFlow\nConfiguration finished\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n.........\nERROR: package contains errors: tensorflow/contrib/metrics.\nERROR: error loading package 'tensorflow/contrib/metrics': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/028d9ecced2b5d3d3b3ba6868668372d/external/protobuf: Error downloading http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/028d9ecced2b5d3d3b3ba6868668372d/external/protobuf/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz: Proxy address 10.14.36.84:8080 is not a valid URL.\n```\n\nAre There other ways to solve in the absence of a network?\n", "comments": ["Bazel is intended for hermetic builds and when setting up the workspace for the first time, it will download required external dependencies at the precise state it wants. For example, at this time, tensorflow uses protobuf with a specific fix (see [`workspace.bzl`](https://github.com/tensorflow/tensorflow/blob/c20da14/tensorflow/workspace.bzl#L101)\n\nLong story short, when setting up the workspace for the first time (or after a `bazel clean`), a network access is required.\n", "@asimshankar \nNow, the network access has been set, I'm trying to 'git clone' or 'wget', it's ok, but when I do the configure, somehow the error is still exist? \n", "Do you wish to build TensorFlow with GPU support? [y/N] n\nNo GPU support will be enabled for TensorFlow\nConfiguration finished\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n.........\nERROR: package contains errors: tensorflow/c.\nERROR: error loading package 'tensorflow/c': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/6e7ef39e0a4c86cda32543deecf0d6bd/external/protobuf: Error downloading http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz to /root/.cache/bazel/_bazel_root/6e7ef39e0a4c86cda32543deecf0d6bd/external/protobuf/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz: Proxy address 10.14.36.84:8080 is not a valid URL.\n", "This seems to be a result of how the proxy is configured on your machine.\nThis is out of our area of expertise, but perhaps you will find some hints in this bazel thread: https://github.com/bazelbuild/bazel/issues/587\n", "Thank you\uff01 @asimshankar @sunil3590\nTo solve it, I did the following (hack) \n1. cd some_safe_folder\n2. wget https://archive.openswitch.net/gmock-1.7.0.zip\n3. python -m SimpleHTTPServer 8000\n4. Change line 79 of models/syntaxnet/tensorflow/tensorflow/workspace.bzl from url = \"https://archive.openswitch.net/gmock-1.7.0.zip\" to url = \"http://localhost:8000/gmock-1.7.0.zip\"\nBasically what you're doing is, downloading the required package manually and setting up a server to serve the package from your local machine.\n", "> Thank you\uff01 @asimshankar @sunil3590\r\n> To solve it, I did the following (hack)\r\n> \r\n> 1. cd some_safe_folder\r\n> 2. wget https://archive.openswitch.net/gmock-1.7.0.zip\r\n> 3. python -m SimpleHTTPServer 8000\r\n> 4. Change line 79 of models/syntaxnet/tensorflow/tensorflow/workspace.bzl from url = \"https://archive.openswitch.net/gmock-1.7.0.zip\" to url = \"http://localhost:8000/gmock-1.7.0.zip\"\r\n>    Basically what you're doing is, downloading the required package manually and setting up a server to serve the package from your local machine.\r\n@darren-qiu @asimshankar @ry @jmhodges @eggie5 \r\nhi, when i bazel build tensorflow, there are some wrong like\"no such package '@gif_archive//':\". and  i try your advice\uff0cin the file(tensorflow/workspace.bzl, `tf_http_archive(\r\n 266         name = \"gif_archive\",\r\n 267         build_file = clean_dep(\"//third_party:gif.BUILD\"),\r\n 268         sha256 = \"34a7377ba834397db019e8eb122e551a49c98f49df75ec3fcc92b9a794a4f6d1\",\r\n 269         strip_prefix = \"giflib-5.1.4\",\r\n 270         system_build_file = clean_dep(\"//third_party/systemlibs:gif.BUILD\"),\r\n 271         urls = [\r\n 272             \"http://127.0.0.1:8000/giflib-5.1.4.tar.gz\",\r\n 273             \"http://mirror.tensorflow.org/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz\",\r\n 274             \"http://pilotfiber.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz\",\r\n 275         ],\r\n 276     ))`   when i repeat bazel bulid, there some message\"127.0.0.1 - - [18/Apr/2020 05:02:29] \"GET /giflib-5.1.4.tar.gz HTTP/1.1\" 404 -\" and i also get \"\"no such package '@gif_archive//':\".\"\r\n hope you give me some advice"]}, {"number": 5028, "title": "Branch 136428122", "body": "", "comments": ["@drpngx, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @tensorflower-gardener and @vrv to be potential reviewers.\n", "Jenkins, test this please.\n", "Generated a new request with newest changes #5044\n"]}, {"number": 5027, "title": "Trouble with mnist_rnn model", "body": "When running with script 'tensorflow/tensorflow/examples/skflow/mnist_rnn.py', I got the following error.\n\nTraceback (most recent call last):\n  File \"mnist_rnn.py\", line 68, in <module>\n    classifier.fit(X_train, y_train, logdir=\"/tmp/mnist_rnn\")\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 257, in fit\n    monitors=monitors)\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 662, in _train_model\n    train_op, loss_op = self._get_train_ops(features, targets)\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 963, in _get_train_ops\n    _, loss, train_op = self._call_model_fn(features, targets, ModeKeys.TRAIN)\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 946, in _call_model_fn\n    return self._model_fn(features, targets, mode=mode)\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 493, in _model_fn\n    predictions, loss = model_fn(features, targets)\n  File \"mnist_rnn.py\", line 60, in rnn_model\n    return learn.models.logistic_regression(encoding, y)\n  File \"/home/xing/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/models.py\", line 148, in logistic_regression\n    'weights', [x.get_shape()[1], y.get_shape()[-1]], dtype=dtype)\nAttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\n\nIs there something wrong with learn package? My tensor version is 0.11.0rc0, installed with pip.\n", "comments": ["There is something to be fixed, see also #4930 \nClosing this as a duplicate, further discussion on #4930\n"]}, {"number": 5026, "title": "Change Tensor summary to print tensor without losing shape information in output", "body": "issue description https://github.com/tensorflow/tensorflow/issues/1702\nPlease close [this](https://github.com/tensorflow/tensorflow/pull/4884) because I make a github mistake there.\nPlease tell me , if there exists some code format error.\n", "comments": ["Can one of the admins verify this patch?\n", "@guotong1988, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @benoitsteiner to be potential reviewers.\n", "I finish.\n", "done\n", "finish\n", "please wait a moment..\n", "done\n", "Done.\n", "Jenkins, test this please.\n", "Please take a look at: https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/2051/consoleFull\n(SummarizeTest failure)\n", "OK\n", "I know the reason of tensor_test.cc and fixed it. But I don't know the reason of TIMEOUT.\n", "Github suffered an outage, and it likely affected jenkins as well, perhaps a repeat of the DDoS.\n\nJenkins, test this please.\n", "Something wrong with the tests, let's try tomorrow.\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "I think something about this change is indeed causing timeouts.  Possibly the new summarization code is too slow and is executed in some of the tests that are timing out.\n", "So what should I do. Do you think it is a good idea to write two methods. One for print and another is the origin one.\n", "I would try to investigate whether this change is indeed causing runtime of those tests to increase (you can test locally to find out), and then see if there's something you can do about it?  I can't say which is better without knowing more information from your end.\n", "Oh.. Would you please tell me the instructions to run all the test?\nI only know how to run a single one:)\n", "You need to run `bazel test -c opt tensorflow/...`, or select a test, like `//tensorflow/contrib/bayesflow:entropy_test` which took 300 seconds instead a just a few.\n", "Oh..I 'm sorry. I think I can do it. It is 3 am now and It's a little slow with my brain.\n", "I found the reason and fixed it.\n", "Nice!  Can you add a test to tensor_test.cc that would have caught the problem too?\n", "Done.\n", "Jenkins, test this please.\n", "well I will fix it.\n", "When the `shape` is empty , the `DebugString` method of the unit-test need the value to be return.\n\nI have test it by `common_runtime_function_test` , `framework_tensor_test` and `framework_function_test`\n", "Jenkins, test this please.\n", "Done.\n", "Jenkins, test this please.\n", "I can't fix it because I don't know the reason.\n", "Probably a transient error in the config. Trying again.\n\nJenkins, test this please.\n", "I have run `bazel test -c opt //tensorflow/contrib/learn:dnn_linear_combined_test` locally , but it passed.\nIt used 116.2s.\n", "Yeah, that test appears to have become flaky recently (failed last night's build). It seems to be a fairly recent problem.\n", "Jenkins, test this please.\n"]}, {"number": 5025, "title": "Minor Python code health improvements", "body": "Minor Python code health improvements\n", "comments": ["Can one of the admins verify this patch?\n", "@frankfqchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @tensorflower-gardener and @keveman to be potential reviewers.\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "I signed it!\n", "Please sync & rebase. The CLA doesn't seem to have passed properly. Could you go back to the web site and make sure it's done? Then \"I signed it!\" again.\n", "I think you are okay with the CLA so:\n\n1) Make sure your github commits use the email address you signed the CLA with\n2) Make sure you add this email to your github account.\n3) Respond to this PR and it should trigger the CLA check again.\n", "Closing -- feel free to ping this thread when you can sign the CLA (and resolve the conflicts)\n"]}, {"number": 5024, "title": "Fixed error with NaN an None elements in Wide & Deep Learning Tutorial", "body": "There was an error after reading the dataset, looks like the last line (of the dataset) contains NaN values, giving an error when converting to integer (to generate the labels):\n\n> Traceback (most recent call last):\n>   File \"tensorflow/examples/learn/wide_n_deep_tutorial.py\", line 203, in <module>\n>     tf.app.run()\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n>     sys.exit(main(sys.argv[:1] + flags_passthrough))\n>   File \"tensorflow/examples/learn/wide_n_deep_tutorial.py\", line 199, in main\n>     train_and_eval()\n>   File \"tensorflow/examples/learn/wide_n_deep_tutorial.py\", line 184, in train_and_eval\n>     df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n>   File \"/usr/lib/python2.7/dist-packages/pandas/core/series.py\", line 2023, in apply\n>     mapped = lib.map_infer(values, f, convert=convert_dtype)\n>   File \"inference.pyx\", line 920, in pandas.lib.map_infer (pandas/lib.c:44780)\n>   File \"tensorflow/examples/learn/wide_n_deep_tutorial.py\", line 184, in <lambda>\n>     df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n> TypeError: argument of type 'NoneType' is not iterable\n\nThis was fixed droping every line that contains NaN elements:\n\n>   # remove NaN elements\n>   df_train = df_train.dropna(how='any', axis=0)\n>   df_test = df_test.dropna(how='any', axis=0)\n", "comments": ["@fabriciojoc, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @caisq and @danmane to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thank you for looking into this! It doesn't seem right to me that we should see NaNs in an example. Do you know where they come from?\n", "@drpngx , looks like it's a problem with read_csv from pandas library. Only the last example contains NaN, in case of continuous features, and None, in case of categorical ones. Here you san see two examples:\n\nEducation column (categorical) before droping None and NaN examples:\n\n> 0        Bachelors\n> 1        Bachelors\n> 2          HS-grad\n> 3             11th\n> 4        Bachelors\n> 5          Masters\n> 6              9th\n> 7          HS-grad\n> 8          Masters\n> 9        Bachelors\n> 10    Some-college\n> 11       Bachelors\n> 12       Bachelors\n> 13      Assoc-acdm\n> 14       Assoc-voc\n> ...\n> 32547         HS-grad\n> 32548     Prof-school\n> 32549    Some-college\n> 32550    Some-college\n> 32551            10th\n> 32552       Assoc-voc\n> 32553         Masters\n> 32554         Masters\n> 32555    Some-college\n> 32556      Assoc-acdm\n> 32557         HS-grad\n> 32558         HS-grad\n> 32559         HS-grad\n> 32560         HS-grad\n> 32561            None\n> Name: education, Length: 32562, dtype: object\n\nEducation column (categorical) after droping None and NaN examples:\n\n> 0        Bachelors\n> 1        Bachelors\n> 2          HS-grad\n> 3             11th\n> 4        Bachelors\n> 5          Masters\n> 6              9th\n> 7          HS-grad\n> 8          Masters\n> 9        Bachelors\n> 10    Some-college\n> 11       Bachelors\n> 12       Bachelors\n> 13      Assoc-acdm\n> 14       Assoc-voc\n> ...\n> 32546      Assoc-acdm\n> 32547         HS-grad\n> 32548     Prof-school\n> 32549    Some-college\n> 32550    Some-college\n> 32551            10th\n> 32552       Assoc-voc\n> 32553         Masters\n> 32554         Masters\n> 32555    Some-college\n> 32556      Assoc-acdm\n> 32557         HS-grad\n> 32558         HS-grad\n> 32559         HS-grad\n> 32560         HS-grad\n> Name: education, Length: 32561, dtype: object\n\nThe same happens for continuous features and label (in this case, both are integers).\n\nAge column before droping NaN examples:\n\n> 0     39\n> 1     50\n> 2     38\n> 3     53\n> 4     28\n> 5     37\n> 6     49\n> 7     52\n> 8     31\n> 9     42\n> 10    37\n> 11    30\n> 12    23\n> 13    32\n> 14    40\n> ...\n> 32547    43\n> 32548    65\n> 32549    43\n> 32550    43\n> 32551    32\n> 32552    43\n> 32553    32\n> 32554    53\n> 32555    22\n> 32556    27\n> 32557    40\n> 32558    58\n> 32559    22\n> 32560    52\n> 32561   NaN\n> Name: age, Length: 32562, dtype: float64\n\nAge column after removing NaN examples:\n\n> 0     39\n> 1     50\n> 2     38\n> 3     53\n> 4     28\n> 5     37\n> 6     49\n> 7     52\n> 8     31\n> 9     42\n> 10    37\n> 11    30\n> 12    23\n> 13    32\n> 14    40\n> ...\n> 32546    37\n> 32547    43\n> 32548    65\n> 32549    43\n> 32550    43\n> 32551    32\n> 32552    43\n> 32553    32\n> 32554    53\n> 32555    22\n> 32556    27\n> 32557    40\n> 32558    58\n> 32559    22\n> 32560    52\n> Name: age, Length: 32561, dtype: float64\n\nI never used pandas library before, so I don't know if there's a better way to solve this problem in read_csv method. However, dropna should do the trick.\n\nThank you.\n", "@davidsoergel , do you have any insights on this?\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins , test this please.\n", "@davidsoergel can you please approve this PR?\n"]}, {"number": 5023, "title": "cherry-picks for 0.11.0rc1 ", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @gunan, @vrv and @dave-andersen to be potential reviewers.\n", "Cherry-pick the bazel certificate issue fix as well. @tensorflow-jenkins test this please.\n", "@tensorflow-jenkins test this please.\n", "The failed GPU test has been flaky. May I get a LG?\n", "For the flakes, do you want to test these?\n- fix the windows cmake: 136491988, 136504874, 136513790 \n- gradients_test: 136498075\n", "Windows cmake needs many more fixes in the release branch, so please ignore\nthat one. For gradients test lets cherrypick that as it will probably flake\nin release tests too.\n\nOn Oct 18, 2016 6:18 PM, \"drpngx\" notifications@github.com wrote:\n\n> For the flakes, do you want to test these?\n> - fix the windows cmake: 136491988, 136504874, 136513790\n> - gradients_test: 136498075\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5023#issuecomment-254655702,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AHlCOeCVwN2k94VbG8KcBoY65Blpw21Sks5q1UWwgaJpZM4KZRtC\n> .\n", "Sounds good. Will cherrypick the fix for gradient test once #5054 is in.\n", "@tensorflow-jenkins test this please.\n", "As we do not have windows support on this branch, we can call all tests passing.\nMerging.\n"]}, {"number": 5022, "title": "SyncReplicasOptimizer hangs", "body": "I'm using `SyncReplicasOptimizerV2` with a shared queue that closes at the end of an epoch. The workers catch the OutOfRange exception and one of them resets the session. (I think that's the expected workflow).\n\nI think the workers sometimes get stuck in the sync op, maybe if they are waiting on other workers that started after the queue ran out. Is this an expected behavior, and if so what is the recommended way to prevent this?\n", "comments": ["@jmchen-g \n", "Can you give more context here? So your training went fine for the first epoch and you stop the training at the end of an epoch and it didn't stop correctly? The token is used to exit one step, not to start one. So it should be fine if the worker started after the token is out.\n\nWhen do the workers get stuck in the sync op? The only expected hang is that when some worker took the token AND died AND didn't restart AND no backups available. This can be solved by adding a timeout for the session.\n\nIt will be good to figure out the exact reason of the hang before thinking about solutions. :)\n", "Thanks, I haven't been able to pinpoint the exact cause yet, I'll check the case you mentioned. Closing and resetting the token queue from another worker (#5016) seemed to help, but I think I'll have to try to reproduce with a test case to know for sure.\n", "@daeyun : Were you able to reproduce with a test case?\n", "@asimshankar I haven't had a chance yet. I'm doing async training for now.\n", "Closing due to inactivity. Please comment with new information and I will reopen.\n"]}, {"number": 5021, "title": "Branch 136158550", "body": "do not merge.\n", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @zhangyaobit, @vrv and @jhseu to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5020, "title": "Fixes and improvements for Windows platform code", "body": "- Changes for more efficient work with Windows file system (based on our previous contribution to RocksDb project)\n- Implementation for ReadOnlyMemoryRegion on Windows.\n- Fixes for WindowsFileSystem::GetChildren(), WindowsFileSystem::RenameFile(), port.cc Hostname().\n- Other minor fixes.\n", "comments": ["Can one of the admins verify this patch?\n", "@vit-stepanovs, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry, @meteorcloudy and @keveman to be potential reviewers.\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Looks like the CLA bot might need some time to propagate (assuming your account is covered by a corporate CLA?). Can you try checking https://cla.developers.google.com/clas to see if the system has picked up your CLA yet?\n\nLooking forward to reviewing this, thanks!\n", "Hi Derek,\n\nI indeed don\u2019t see the CLA via the below link. We have signed it ~ 3 hours ago, so maybe indeed it needs more time to propagate. I will check again in a few hours.\n\nThank you,\nVit\n\nFrom: Derek Murray [mailto:notifications@github.com]\nSent: Monday, October 17, 2016 5:48 PM\nTo: tensorflow/tensorflow tensorflow@noreply.github.com\nCc: Vit Stepanovs vistepan@microsoft.com; Mention mention@noreply.github.com\nSubject: Re: [tensorflow/tensorflow] Fixes and improvements for Windows platform code (#5020)\n\nLooks like the CLA bot might need some time to propagate (assuming your account is covered by a corporate CLA?). Can you try checking https://cla.developers.google.com/clashttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcla.developers.google.com%2Fclas&data=01%7C01%7Cvistepan%40microsoft.com%7C758720f6aef74218373f08d3f6f0597d%7C72f988bf86f141af91ab2d7cd011db47%7C1&sdata=I4%2FMPrbq%2B3%2B4ZsAiezgjNAalIuiz%2FODJNUGYc8TLDA0%3D&reserved=0 to see if the system has picked up your CLA yet?\n\nLooking forward to reviewing this, thanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F5020%23issuecomment-254375594&data=01%7C01%7Cvistepan%40microsoft.com%7C758720f6aef74218373f08d3f6f0597d%7C72f988bf86f141af91ab2d7cd011db47%7C1&sdata=EgdVP2S9gJkD6kaAbZieehDTJUGVLmIXhaQ0ffl3tuI%3D&reserved=0, or mute the threadhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAVvkk0eOelctjQhZed--n0mAvnLfQH61ks5q1BckgaJpZM4KZPaG&data=01%7C01%7Cvistepan%40microsoft.com%7C758720f6aef74218373f08d3f6f0597d%7C72f988bf86f141af91ab2d7cd011db47%7C1&sdata=xQKWEjjyTT7L6hBRIi%2F7wRlwhRHU%2BLA3o79l2cM8WhI%3D&reserved=0.\n", "I signed it!\n", "@willnorris, can we check this CLA manually? Can I check a CLA manually?\n", "@willnorris I verified that the corporate CLA is in place, but is there anything else that Vit needs to do before @googlebot will recognize his account?\n", "@willnorris, FYI #5051, #5052, and #5053 seem to have the same issue.\n", "(moving CLA conversation to email)\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5019, "title": "Branch 136156106", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @zhangyaobit, @tensorflower-gardener and @jhseu to be potential reviewers.\n"]}, {"number": 5018, "title": "Add basic WebDriver functional tests of TensorBoard.", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@DrMarcII, thanks for your PR! By analyzing the history of the files in this pull request, we identified @dsmilkov, @keveman and @danmane to be potential reviewers.\n", "This cl is meant mostly as a proof of concept showing how these types of tests can be written. There should be a higher level discussion about the utility of these tests as well as some more detailed discussion about how the specifics of the test implementation and execution. \n", "@danmane Could you take a look?\n", "I'm so happy work is being done with Bazel web testing. I'd love to merge this into TensorFlow today. The problem is there are blockers which prevent that from happening at this time. We had a chat offline about this.\n\nThe main reason we can't merge this today is the additional 350MB of download and the additional 550MB of disk space. Everyone building TensorFlow from source will have to pay this price, even if they're not interested in testing TensorBoard. This is because we put `bazel fetch //tensorflow/...` in our `./configure` file to work around a bug in Bazel. So any external that's transitively referenced by our codebase is going to be fetched.\n\nWe would definitely like to use rules_web in the future. So here's our concrete list of requirements:\n1. No `git_repository()`\n2. No `bind()`\n3. External URLs can't be uploaded to servers [blocked](http://www.blockedinchina.net/) by a certain firewall. Otherwise we'll get a ton of issues.\n4. Make available in `//third_party/bazel_rules/rules_webtesting` because we'd like to use this as our testing solution both internally and externally.\n5. We would like to use statically compiled Headless Chromium without any dependencies[1] aren't listed in `aptitude search ~prequired -F\"%p\"` or rigorously specified by Bazel. Otherwise we have to deal with all these difficult to troubleshoot issues where people complain about things not working. Right now `chrome-precise64.zip` isn't hermetically sealed and depends on 74 `.so` files from the system. We'd rather pay the price of downloading another 100MB if it means it's guaranteed to work.\n6. If it hasn't been designed this way already, the build needs to guarantee that if we don't link a particular browser in the `browsers = [...]` list, then we won't pay the price of downloading it. We only want to pay for the functionality we're using.\n7. Support for Mac and Linux. In the future we'll need Windows.\n8. Google Noto fonts out of the box. Closure Rules already configure PhantomJS to use them [rules_closure/third_party](https://github.com/bazelbuild/rules_closure/tree/master/third_party). Similar code exists internally at Google.\n9. Bit-for-bit determinism of screenshot tests across G3/Linux/Mac/Windows with Headless Chromium. I managed to achieve this with Closure Rules on Linux. But I failed to achieve the same results on Darwin. This isn't a strict requirement. But without this, screenshot testing will likely be impossible and all tests will probably have to be hand-coded web driver tests.\n\n[1] Here's how to build static headless Chromium. Be sure to ship the binary with a LICENSE file that contains the copyright notice / license for every single thing that gets statically linked.\n\n``` sh\n# https://www.chromium.org/developers/gn-build-configuration\n# https://chromium.googlesource.com/chromium/src/+/lkgr/headless/README.md\n# https://chromium.googlesource.com/chromium/blink.git/+/master\n\nsudo apt-get install build-essential bison gperf\nmkdir chromium\ncd chromium/\ngit clone https://chromium.googlesource.com/chromium/tools/depot_tools.git\nexport PATH=$(pwd)/depot_tools:\"$PATH\"\nfetch --no-history chromium\ndu -sh .\ndf -h\ncd src\ngclient runhooks\ngn gen out/Release --args='import(\"//build/args/headless.gn\") is_component_build=false optimize_for_size=true symbol_level=0 remove_webcore_debug_symbols=true'\nninja -C out/Release headless_shell\nls -hal out/Release/headless_shell\nstrip -s out/Release/headless_shell\n```\n", "> 1. No git_repository()\n\nDone.\n\n> 1. No bind()\n\nDone.\n\n> 1. External URLs can't be uploaded to servers blocked by a certain firewall. Otherwise we'll get a ton of issues.\n\nWe should be able to take care of this however we solve the same problem for other dependencies.\n\n> 1. Make available in //third_party/bazel_rules/rules_webtesting because we'd like to use this as our testing solution both internally and externally.\n\nDo you mean in Google? I am planning on pulling this in 2017Q1 and using it as the basis for web testing in Google.\n\n> 1. We would like to use statically compiled Headless Chromium without any dependencies[1] aren't listed in aptitude search ~prequired -F\"%p\" or rigorously specified by Bazel. Otherwise we have to deal with all these difficult to troubleshoot issues where people complain about things not working. Right now chrome-precise64.zip isn't hermetically sealed and depends on 74 .so files from the system. We'd rather pay the price of downloading another 100MB if it means it's guaranteed to work.\n\nI have successfully got this working for Linux. Currently headless_shell is not supported on MacOS, but I am thinking it may not be as much of an issue there (Mac OS has a more standardized configuration, so using regular Chrome/Chromium may be okay).\n\n> 1. If it hasn't been designed this way already, the build needs to guarantee that if we don't link a particular browser in the browsers = [...] list, then we won't pay the price of downloading it. We only want to pay for the functionality we're using.\n\nThis is already true.\n\n> 1. Support for Mac and Linux. In the future we'll need Windows.\n\nAlready supports Mac and Linux. Haven't tried to support Windows, but don't predict any significant blockers at this point.\n\n> 1. Google Noto fonts out of the box. Closure Rules already configure PhantomJS to use them rules_closure/third_party. Similar code exists internally at Google.\n\nI will look at how the Closure Rules does this and see about getting working.\n\n> 1. Bit-for-bit determinism of screenshot tests across G3/Linux/Mac/Windows with Headless Chromium. I managed to achieve this with Closure Rules on Linux. But I failed to achieve the same results on Darwin. This isn't a strict requirement. But without this, screenshot testing will likely be impossible and all tests will probably have to be hand-coded web driver tests.\n\nI am not a fan of screenshot tests as small changes in the environments can have significant effects on the screenshots. That said, we should be able to get consistency within controlled environments (we have done a fairly good job of this in the past couple years in G3).\n", "I'm really intrigued by this PR, it would be awesome to get the full suite of TensorBoard testing working in opensource/bazel as well as internally.\n\nRight now we use screendiff testing internally, but don't have a way to run them externally; it would be great if we could. But, the internal infra takes care of the environment sensitivity you mention; not sure how we would solve that externally.\n\nWe also should not include the goldens in the TensorFlow repo since it would bloat the git history for everyone, so we would need to setup another repo and depend on it... which would create another level of indirection and possibility of de-synchronization :/ \n\nI set up a meeting to chat offline about this all in more depth. \n", "Also: At the moment TensorBoard only depends on the eventsfiles, so there is no need for the graph or checkpoints in the functional test dir.\n\nTensorBoard's behavior is pretty sensitive to the data we test on (e.g. edge cases involving very large number of runs, or very long tag names, etc). One feature I would like is to multiplex the tests across multiple different data sets, and create a nice dev environment for launching TensorBoard source against these various test sets (with livereload etc). Not something that this PR should solve, just musing about infra I would like :) \n", "> Dan: We also should not include the goldens in the TensorFlow repo since it would bloat the git history.\n> \n> Marc I am not a fan of screenshot tests as small changes in the environments can have significant effects on the screenshots.\n\nThe size of the PNG files _shouldn't_ be too problematic if we rewrite the screenshot tests to only be of the specific tiny components being tested.\n\nI'd love to have only webdriver tests. It's just that TensorBoard is a visualization tool. So we definitely have to have screenshot tests for at least the plots.\n\n> Currently headless_shell is not supported on MacOS\n\nIf Headless Chromium doesn't work on Mac and Windows, then would it be possible for us to configure this tooling so the web tests, when run on those platforms, become a no-op with a warning? Also what about Windows? I've been talking to people and Windows seems to be in the works right now. So the build has to work on Windows and Mac from day one, even if \"working\" means doing nothing.\n\n\nOOC: Mr. Jenkins: test this please\n", "> If Headless Chromium doesn't work on Mac and Windows, then would it be possible for us to configure this tooling so the web tests, when run on those platforms, become a no-op with a warning? Also what about Windows? I've been talking to people and Windows seems to be in the works right now. So the build has to work on Windows and Mac from day one, even if \"working\" means doing nothing.\n\nYes. I actually do this in the tests I run in rules_webtesting: https://github.com/bazelbuild/rules_webtesting/blob/master/go/BUILD#L78-L81\n", "The linux tests failed because it is trying to launch chrome using xvfb-run, which is not available on your jenkins machines (this will be fixed by headless chrome). The Mac OS test executed and passed though.\n", "I have updated this pull request in response to Justine's comments. Most importantly:\n-  Switched to headless chromium browser using noto fonts.\n-  Defined browser target in tensorflow project:\n\nNote this change requires a bazel version > 0.3.2 because successfully launching a Chrome based browser in the Bazel sandbox requires the new flag \"--sandbox_tmpfs_path=/run/shm\" (added to bazel.rc.template).\n", "Bazel 0.3.2 came out eighteen days ago. OOC @wicke @gunan how comfortable do we feel in general about bumping up the Bazel requirement? Is it something we try to do infrequently to keep our users happy? Do a lot of users get Bazel from package managers that lag behind on updates?\n\nWhat happens if the user doesn't pass the `--sandbox_tmpfs_path=/run/shm` flag? Does it fail to build? If so, why can't Bazel have that flag set by default?\n", "In master branch, bazel should be already bumped up to 0.3.2 by @davidzchen \nHe can confirm.\n", "Sorry if I wasn't clear, it actually needs a version greater than 0.3.2 (0.3.2 doesn't include the sandbox_tmpfs_path flag).\n\nWithout this flag the execution of the test fails as Chrome tries to write /dev/shm (which is symlinked to /run/shm), and it is read-only in the default sandbox. This flag causes the Bazel sandbox to mount a tmpfs filesystem at /run/shm that Chrome can then write to.\n", "https://github.com/bazelbuild/bazel/releases\n0.3.2 seems to be the latest release.\nWe definitely will not depend on an unreleased bazel version.\nSo, when bazel releases a new version, you can expect us to upgrade within 1 week, in the worst case.\n", "Is there any way to workaround Headless Chrome needing a tmpfs filesystem mounted? If there isn't, then I would like to see Bazel changed so a configuration flag isn't needed for builds to work.\n", "gunan:\n\n> We definitely will not depend on an unreleased bazel version.\n> So, when bazel releases a new version, you can expect us to upgrade within 1 week, in the worst case.\n\nI certainly didn't expect an update to an unreleased; stated it more as a constraint that needed to be fulfilled before this PR can be completed.\n\nJustine:\n\n> Is there any way to workaround Headless Chrome needing a tmpfs filesystem mounted? If there isn't, then I would like to see Bazel changed so a configuration flag isn't needed for builds to work.\n\nI haven't been able to find anyway to avoid the tmpfs filesystem for Headless Chrome. As I see it now, we three options:\n1. Run the tests outside the sandbox by marking it local = True.\n2. Use the configuration flag (when Bazel 0.4.0 gets released).\n3. Push Bazel to either:\n   \n   a. mount a writable tmpfs filesystem at /run/shm in the sandbox by default.\n   b. create a rule-level mechanism for defining tmpfs mounts in the sandbox. \n", "To confirm: yes, tensorflow master has been upgraded to Bazel 0.3.2  as of 544143180d3c606b2d410570a66d6a5e9db09f8c.\n", "Any updates on this PR from anybody?  What's the status?\n", "Current status is this is blocked on the next Bazel release IIUC.\n", "@jart To clarify, is this blocked on the release following 0.3.2?\n", "I am about to internally make the change to bazel 0.4.\nwe should have bazel 0.4 everywhere on Wednesday.\n\nOn Mon, Nov 7, 2016 at 7:08 PM, David Z. Chen notifications@github.com\nwrote:\n\n> @jart https://github.com/jart To clarify, is this blocked on the\n> release following 0.3.2?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5018#issuecomment-259032953,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AHlCOYlrsGmUQC301GvFlC3wSEgqVobiks5q7-epgaJpZM4KZOMw\n> .\n", "@DrMarcII Could you please rebase.\n@gunan is the bazel update completed?\n", "Not yet, we need to manually upgrade all windows and mac machines\n", "This has been rebased.\n", "@wicke @gunan I'm going to be adding the feature to Bazel allowing for multiple mirror download URLs  hopefully this week. Then we'll beseech Bazel to cut a new release ASAP. Then we'll write our own Skylark replacements for new_http_archive, http_file, etc. that allow for multiple mirror URLs. Then we'll incorporate that into TensorFlow, rules_webtesting, rules_closure, rules_go, etc.\n\nDo you think the reliability risks posed by introducing the new dependencies introduced by this CL are great enough that we'll want to wait until the new reliable mirror functionality is available before merging? Or do you think it's safe to assume that risk now and merge?\n", "@gunan @wicke On second thought, we might have no choice but to wait for that feature before merging, because this PR references rules_go, which is using download URLs that should be blocked in certain countries.\n", "Thanks for working on this, @jart. For my understanding, why would we need to write our own Skylark replacements for the http rules?\n", "Ping on this -- this may not be high priority, just checking in on what the next steps would be.", "@jart has implemented [fallback URLs](https://github.com/bazelbuild/bazel/commit/ed7ced0018dc5c5ebd6fc8afc7158037ac1df00d) in Bazel, and I have added the Skylark implementations of the [http repository rules](https://github.com/bazelbuild/bazel/blob/master/tools/build_defs/repo/http.bzl).\r\n\r\nThese are not in the 0.4.2 Bazel release but will be in the next one.", "Are we ready to try againon this? @DrMarcII could you merge and push again?", "Closing for now. Looks like we have to wait for `>` 0.4.2.", "We're upgraded to Bazel 0.4.2. So it should be safe to proceed I think. I'd recommend though that rules_webtesting adopt the multiple URLs feature that I added to Bazel recently. See our workspace.bzl for an example of how it's used.", "Can one of the admins verify this patch?", "According to @davidzchen, some of the things we need for this are not in 0.4.2?\r\nCould you rebase and test with 0.4.2?", "I have rebased and updated this patch.", "I now consider this review blocked on https://github.com/bazelbuild/rules_webtesting/pull/86 which I've sent to rules_webtesting to make its download reliability awesome.", "https://github.com/bazelbuild/rules_webtesting/pull/86 is merged and this PR has been updated.\r\n\r\nCurrently, the tests are failing when I run them locally, but I think it is a bug in tensorboard. When trying to start it I get the following error message:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/google/home/fisherii/github/tensorflow/bazel-bin/tensorflow/tensorboard/tensorboard.runfiles/org_tensorflow/tensorflow/tensorboard/tensorboard.py\", line 26, in <module>\r\n    from werkzeug.serving import run_simple\r\nImportError: No module named werkzeug.serving\r\n\r\n", "That's a known issue. We recently added that dependency and @dandelionmane is working to fix it right now.", "The tensorboard issue has been fixed, and this test is now passing. Is there anything else that needs to be done before this can be committed?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@jart is this ready to merge if tests pass?", "@DrMarcII it looks like there are some real build errors. Can you please investigate?", "@DrMarcII Belay that order. Merging this pull request would most likely create a lot of work for our sync rotation. I'm going to patch this CL internally. I'm going to make the necessary configuration changes to make this work both internally and externally with our syncing code on your behalf, unless you would like to do that yourself. Then you can patch that CL and submit it yourself as a pair programmed CL.", "@jart thanks for looking into this.", "@jart I am going to close this for now to keep our PR list small - I assume it's on your TODO list to get this working internally first -- please coordinate with @DrMarcII once you get something working to get this PR in.  Thanks!", "Will do. It's definitely on the near-term agenda. Expect a CL soon @DrMarcII."]}, {"number": 5017, "title": "TF Quit working with  /lib/libstdc++.so.6: version `CXXABI_1.3.8' not found, I then reinstalled ", "body": "I had it working, and then went to use it once again (after some \"normal\" Ubuntu system updates one of which may have been bazel?) And I got the traceback with the CXXABI_1.3.8' not found\n\nSo how should I remove the whole install and try again? or something easier?\n\nNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nWhile I found this on SO I did not feel I should be messing around with this?\nhttp://stackoverflow.com/questions/23494103/version-cxxabi-1-3-8-not-found-required-by\n### Environment info\n\nOperating System:\nLinux Ubuntu 16.04 Python3.5 Anaconda in root Using an NVIDIA 1060 board\nInstalled version of CUDA 8 and cuDNN: cudNN v5.1\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nls /usr/local/cuda/lib64/libcudnn*\n/usr/local/cuda/lib64/libcudnn.so    /usr/local/cuda/lib64/libcudnn.so.5.1.5\n/usr/local/cuda/lib64/libcudnn.so.5  /usr/local/cuda/lib64/libcudnn_static.a\n\nNot sure what got updated but I got this message when importing tensorflow (which I had installed from source. So I reinstalled from source,, and got the same result but with the added message about should not run from source tree??\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   ImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)\n   Error importing tensorflow.  Unless you are using bazel,\n   you should not try to import tensorflow from its source directory;\n   please exit the tensorflow source tree, and relaunch your python interpreter\n   from there.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`) \n28166c086204c5ca4134086f250469a3802546ea\n2. The output of `bazel version`\nBuild label: 0.3.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\nBuild timestamp: 1475861110\nBuild timestamp as int: 1475861110\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n\nReinstall.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\ntom@tomServal:~$ python -c \"import tensorflow; print(tensorflow.**version**)\"\nTraceback (most recent call last):\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/tom/anaconda3/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/tom/anaconda3/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/**init**.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py\", line 60, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/**init**.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/home/tom/anaconda3/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/tom/anaconda3/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so)\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n", "comments": ["Do you have the `LD_LIBRARY_PATH` environment variable set? If so, what to?\n\nI suspect that somehow when you're using python, it tries to link `pywrap_tensorflow.so` with `/home/tom/anaconda3/lib/libstdc++.so.6` which might be different from the `libstdc++` against which the TensorFlow library was built (perhaps somewhere in `/usr/lib/`).\n\nPerhaps you can provide the output of:\n- `echo $LD_LIBRARY_PATH`\n- `ldd /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so` when anaconda is activated\n- `ldd /home/tom/anaconda3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so` after deactivating anaconda\n\nThough, I must admit, this seems like its some interaction between your environment when building TensorFlow from source and the environment in anaconda. Perhaps this is more suited for a stackoverflow question.\n", "I do not even have tensorflow in site-packages of anaconda. Is it possible that tensorflow installation from source will conflict with tensorflow installed in other conda environment?\n", "That is a good point that occurred to me as I was going to sleep, I never explicitly installed TensorFlow via Anaconda.I only installed via source since I'm on 16.05 of Ubuntu and wanted the latest Nvidia drivers for the new 1060 GPU, and it worked fine  but I did do an update of all Anaconda some days afterwards and that may have been the screw up, now pondering how to fix it.. I suppose a uninstall of the Anaconda version (if any, then pip uninstall the built from source version then try a reinstall? Opinions welcome, I'll raise the issue on the Anaconda issues as well.\n", "@asimshankar Thank you for your reply I agree that it seems Anaconda has screwed it up, I do not activate Anaconda but use the base install (root) which Anaconda has used by modifying the system to access Anaconda Python in all cases from the command prompt.\nWould appreciate any guidance how to fix, I'll raise with Anaconda channel as well.\nSo in response to your questions: (note as mentioned I do not Activate Anaconda)\n\n```\ntom@tomServal:~$ echo $LD_LIBRARY_PATH\n:/usr/local/cuda/lib64\ntom@tomServal:~$ ldd /home/tom/anaconda3/lib/python3.5/site-   packages/tensorflow/python/_pywrap_tensorflow.so\nlinux-vdso.so.1 =>  (0x00007fff1f58f000)\nlibcudart.so.8.0 => /usr/local/cuda/lib64/libcudart.so.8.0 (0x00007f875ce98000)\nlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f875cc6f000)\nlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f875c966000)\nlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f875c749000)\nlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f875c3c6000)\nlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f875c1b0000)\nlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f875bde7000)\n/lib64/ld-linux-x86-64.so.2 (0x000055bcc7b32000)\nlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f875bbde000)\ntom@tomServal:~$ \n```\n", "The `ldd` output here suggests that you're linking with `/usr/lib/x86_64-linux-gnu/libstdc++.so.6`, but the error output you alluded to above (`ImportError: /home/tom/anaconda3/bin/../lib/libstdc++.so.6:`) was linking with `/home/tom/anaconda3/lib/libstdc++.so.6`.\n\nSo I'm not quite sure what exactly is happening but it does seem to be something specific to the environment on your setup.  Perhaps you can create an isolated environment with the [docker installation](https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#docker-installation)? Doesn't quite solve your precise setup, but something to look into?\n", "try to do this:\n\n```\n# cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /home/tom/anaconda3/lib/\n```\n\nand it should work, at least it works for me.\n", "@gaussic Many thanks, It did the trick. saved me from ripping it all up and reinstalling from scratch (which of course might not have worked!)\n", "This trick also worked from me. Thank you.", "For me, anaconda may have been the problem.\r\n`conda install libgcc` updated libgcc from 4.x to 5.x and [fixed the problem](http://stackoverflow.com/a/40181952/6832816).", "Perhaps more correct, as `/usr/lib/x86_64-linux-gnu/libstdc++.so.6` is just a link:\r\n\r\n    ln -sf /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21 libstdc++.so.6\r\n\r\nI recommend using a virtual environment for this. Note that copying the actual library file from `/usr/lib` doesn't work. You have to create the link.\r\n\r\nThis isn't the first time I've had trouble with Anaconda's `'libgcc`. Many times actually. I almost wish they'd stop trying to package it and just use the system version. It would be nice to have on older distros, though, if it wasn't so problematic. \r\n\r\n### Update 1\r\n\r\nI was able to get this working by downgrading to `libgcc=4.8.5` from within conda. I also had to downgrade `zeromq`, because it broke `jupyter`. \r\n\r\n### Update 2\r\n\r\nActually it's sporadic. It stopped working, but I'm not sure why. There appears to be problems with the `tensorflow` conda package. Even when it imports without errors, it has missing attributes. \r\n\r\nI ended up uninstalling both `tensorflow` and `libgcc`, then reinstalled `tensorflow` using pip. Now all appears to work. ", "this work for me.\r\nconda install -c anaconda tensorflow\r\n", "@gaussic in centos I get \r\n$ ls /usr/lib/x86_64-linux-gnu/\r\nls: cannot access /usr/lib/x86_64-linux-gnu/: No such file or directory\r\n\r\nwhat do you suggest?\r\n\r\n---\r\nupdate:\r\nI have this\r\nls /usr/lib/gcc/x86_64-redhat-linux/4.8.5/libstdc++.so \r\n/usr/lib/gcc/x86_64-redhat-linux/4.8.5/libstdc++.so\r\nbut not libstdc++.so.6 now, what should I do?", "![screenshot from 2018-07-04 02-39-02](https://user-images.githubusercontent.com/24300927/42244699-a45330cc-7f33-11e8-8884-77c476dfad36.png)\r\n\r\nI am trying to implement darkflow which is a repo for yolo object detection algorithms , but constantly i am getting this error .I am using ubuntu 16.04 LTS .\r\n", "See https://github.com/FoldingAtHome/fah-issues/issues/1147 for an explanation of what might be going on.\r\n\r\nYou must just have the wrong GCC for the package you've installed. ", "try this `conda update -f libstdcxx-ng`", "We used the following and it solved this problem:\r\n`conda uninstall gcc`", "If you are not using conda:\r\nThe gcc dynamic linker needs this path\r\n\r\n`export LD_LIBRARY_PATH=${prefix}/lib:$LD_LIBRARY_PATH`\r\nPractically: edited .bashrc with the following line:\r\n\r\n`export LD_LIBRARY_PATH=/usr/lib64/:$LD_LIBRARY_PATH`\r\n(depending on your system you may need /usr/lib/)\r\n\r\nHow did I find the path:\r\n\r\n`locate libstdc++.so.6`\r\n\r\nHow it works:\r\nhttps://gcc.gnu.org/onlinedocs/libstdc++/faq.html#faq.how_to_install", "> If you are not using conda:\r\n> The gcc dynamic linker needs this path\r\n> \r\n> `export LD_LIBRARY_PATH=${prefix}/lib:$LD_LIBRARY_PATH`\r\n> Practically: edited .bashrc with the following line:\r\n> \r\n> `export LD_LIBRARY_PATH=/usr/lib64/:$LD_LIBRARY_PATH`\r\n> (depending on your system you may need /usr/lib/)\r\n> \r\n> How did I find the path:\r\n> \r\n> `locate libstdc++.so.6`\r\n> \r\n> How it works:\r\n> https://gcc.gnu.org/onlinedocs/libstdc++/faq.html#faq.how_to_install\r\n\r\nJust for reference, I'm using linuxbrew and pyenv. When I type `import tensorflow` in a python shell, it always gives the error. I fixed this by editing my ~/.zshrc file with adding one line:\r\n\r\n`export LD_LIBRARY_PATH=/usr/lib64/:$LD_LIBRARY_PATH`\r\n\r\nOriginally I thought it should be `~/.linuxbrew/lib/libstdc++.so.6`.\r\nAnyway, I reload the zsh with `source ~/.zshrc` and it worked! Thanks @mmehedin !"]}, {"number": 5016, "title": "Add a resource container for sync tokens in SyncReplicasOptimizerV2.", "body": "Not sure if this aligns with how resource containers are planned to be used in tensorflow. I wanted to be able to reset sync token queues without also resetting other variables defined in the optimizer.\n", "comments": ["Can one of the admins verify this patch?\n", "@daeyun, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jmchen-g, @martinwicke and @ilblackdragon to be potential reviewers.\n", "@jmchen-g \n", "Does this solve your reported hang issue? Thanks.\n", "Closing due to lack of response, but feel free to re-open if you have more comments. \n"]}, {"number": 5015, "title": "Fix typo in xla_prerelease.md", "body": "TLA => XLA\n", "comments": ["@wujingyue, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener and @haosdent to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed CLA. Please verify. Thank you. \n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "LGTM!\n", "Jenkins, test this please.\n"]}, {"number": 5014, "title": "Python Tools Missing", "body": "The tools found under tensorflow/python/tools are not packaged along with the pip package making them only usable through bazel (as demonstrated in their header documentation).  It's not clear to me how bazel is told which bits of python should be part of the pip package but these would be very useful to have access to from python code (ie: optimize_for_inference_lib).\n", "comments": ["Thanks @sebastient. CCing @petewarden  who will have thoughts on how we want to structure and export these tools\n", "You can fix this by adding the appropriate files/targets to the pip_backage rule [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/BUILD#L34). \n\nBasically, you want to add all the `py_binary` targets defined in tensorflow/python/tools/BUILD (but none of the tests.\n\nI'd love a PR.\n", "Is this issue fixed with the merged PR ? \n", "Testing this out last week from master did install the tools as expected though I haven\u2019t had a chance to track down the commit which added it to close this ticket yet.\u00a0 Thank you.\n\nFrom: Fabrizio Milo notifications@github.com\nReply-To: tensorflow/tensorflow reply@reply.github.com\nDate: Saturday, November 12, 2016 at 9:15 PM\nTo: tensorflow/tensorflow tensorflow@noreply.github.com\nCc: S\u00e9bastien Taylor me@staylor.ca, Mention mention@noreply.github.com\nSubject: Re: [tensorflow/tensorflow] Python Tools Missing (#5014)\n\nIs this issue fixed with the merged PR ? \n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n", "Issue seems to be resolved.\r\nClosing."]}, {"number": 5013, "title": "Branch 136382518", "body": "", "comments": ["Jenkins, test this please.\n", "@tensorflow-jenkins test this please.\n", "Jenkins, test this please.\n", "So all jobs except the Windows cmake one passed. The timeout seen in the previous GPU run looks like a flaky timeout. @gunan , any idea about the Windows cmake failure? It appears that the compilation passes, and the network dropped (deterministically?) in the last step.\n", "http://ci.tensorflow.org/job/tensorflow-pull-requests-multijob/2203/ appears to have also passed and reported successfully. I'm waiting for the queue to clear up a little bit to start another build.\n", "Jenkins, test this please.\n", "Sync'd and rebased, now at #5028.\n"]}, {"number": 5012, "title": "Error executing download_and_preprocess_imagenet", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System: macOS Yosemite\n\nInstalled version of CUDA and cuDNN: \nNone (CPU only)\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n   https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0rc0-py3-none-any.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.11.0rc0\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nWhen following the guide (https://github.com/tensorflow/models/tree/master/inception) for configuring inceptionv3 I ran this command;\nbazel-bin/inception/download_and_preprocess_imagenet \"${DATA_DIR}\"\n### What other attempted solutions have you tried?\n\nNone\n### Logs or other output that would be helpful\n\nFinished downloading and preprocessing the ImageNet data.\nSaving results to /Volumes/Seagate External/imagenet\nSuccessfully read 615299 bounding boxes across 544546 images.\nDetermining list of input files and labels from /Volumes/Seagate External/imagenet/raw-data/validation/.\nFinished finding files in 100 of 1000 classes.\nFinished finding files in 200 of 1000 classes.\nFinished finding files in 300 of 1000 classes.\nFinished finding files in 400 of 1000 classes.\nFinished finding files in 500 of 1000 classes.\nFinished finding files in 600 of 1000 classes.\nFinished finding files in 700 of 1000 classes.\nFinished finding files in 800 of 1000 classes.\nFinished finding files in 900 of 1000 classes.\nFinished finding files in 1000 of 1000 classes.\nTraceback (most recent call last):\n File \"/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py\", line 704, in <module>\n   tf.app.run()\n File \"/Users/karllattimer/Projects/tensorflow-testing/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n   sys.exit(main(sys.argv[:1] + flags_passthrough))\n File \"/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py\", line 698, in main\n   FLAGS.validation_shards, synset_to_human, image_to_bboxes)\n File \"/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py\", line 597, in _process_dataset\n   filenames, synsets, labels = _find_image_files(directory, FLAGS.labels_file)\n File \"/private/var/tmp/_bazel_karllattimer/ed3d80c94eb22e8491a82fd78ab7022c/inception/bazel-out/local-fastbuild/bin/inception/build_imagenet_data.runfiles/inception/inception/data/build_imagenet_data.py\", line 529, in _find_image_files\n   random.shuffle(shuffled_index)\n File \"/Users/karllattimer/Projects/tensorflow-testing/venv/lib/python3.5/random.py\", line 272, in shuffle\n   x[i], x[j] = x[j], x[i]\n", "comments": ["It seems you're using Python 3.5 and the `download_and_preprocess_imagenet` tool is written for 2.7. (I'm guessing, but could you confirm that the last line of the output was: `TypeError: 'range' object does not support item assignment`?)\n\nCan you try with either using python 2.7 or changing [line number 529](https://github.com/tensorflow/models/blob/master/inception/inception/data/build_imagenet_data.py#L529) in `inception/data/build_imagenet_data.py` from `random.shuffle(shuffled_index)` to `random.shuffle(list(shuffled_index))` before rerunning `bazel build inception/download_and_preprocess_imagenet`?\n\nThanks.\n", "@klattimer, any luck with changing what @asimshankar suggests?\n", "I'm hoping to get time shortly. \n", "@klattimer Closing due to lack of response, but we're happy to reopen if you're still having the problem.\n", "I was facing same problem. Proposed solution fixes it."]}, {"number": 5011, "title": "Remove duplicated arg description in doc string", "body": "sequence_length description is repeated in bidirectional_dynamic_rnn documentation. It looks like it split the dtype description into two sections. I believe that dtype is required if either initial state is not provided (like bidirectional_rnn) and that these changes should reflect that.\n", "comments": ["Can one of the admins verify this patch?\n", "@nschuc, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ebrevdo and @kosklain to be potential reviewers.\n", "LGTM.\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n"]}, {"number": 5010, "title": "Matrix Triangular Solve GPU op", "body": "Adds a GPU version of the triangular solver op using cuBLAS trsm.\n", "comments": ["Can one of the admins verify this patch?\n", "@c0g, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ebrevdo and @josh11b to be potential reviewers.\n", "Thanks for the PR!  A few comments.\n", "Ah in that case let's leave it as double. You're right.\n\nOn Oct 17, 2016 9:20 AM, \"c0g\" notifications@github.com wrote:\n\n> ## _@c0g_ commented on this pull request.\n> \n> In tensorflow/core/kernels/matrix_triangular_solve_op.cc\n> https://github.com/tensorflow/tensorflow/pull/5010:\n> \n> > -    {\n> > -        Base::ValidateSquareSolver(context, input_matrix_shapes);\n> > -    }\n> >   +\n> > -    TensorShapes GetOutputMatrixShapes(\n> > -        const TensorShapes& input_matrix_shapes) const final\n> > -    {\n> > -        return TensorShapes({ TensorShape({ input_matrix_shapes[0].dim_size(1),\n> > -            input_matrix_shapes[1].dim_size(1) }) });\n> > -    }\n> >   +\n> > -    int64 GetCostPerUnit(const TensorShapes& input_matrix_shapes) const final\n> > -    {\n> > -        double rows = static_cast<double>(input_matrix_shapes[0].dim_size(0));\n> > -        double num_rhss = static_cast<double>(input_matrix_shapes[1].dim_size(1));\n> > -        double cost = rows \\* rows \\* num_rhss;\n> \n> This is the original tensorflow op code (see above). Possibly because\n> double can represent larger numbers than int? I doubt anyone will try a\n> matrix multiply large enough to overflow a 64 bit int though. Happy to\n> change to int64.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5010, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim1ZVajP4Q6Mph62ruIpHz25QrFSYks5q06BhgaJpZM4KYwau\n> .\n", "Do we still need changes?\n", "Jenkins, test this please.\n", "I have not yet made the requested changes.\n\n> On 19 Oct 2016, at 07:03, drpngx notifications@github.com wrote:\n> \n> Do we still need changes?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "@ebrevdo : I reverted to the original file to fix white space then made your other requested changes.\n", "I don't see the revert. Please push?\n", "@drpngx you're right I have no idea what happened to them. The changes should now be up. Sorry for the lag/commit spam.\n", "Jenkins, test this please.\n", "Seems to be passing now, only looks to be waiting on verification of @ebrevdo requested changes. \n", "Jenkins, test this please.\n"]}, {"number": 5009, "title": "Make example trainer build again", "body": "@mrry \n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @rohan100jain, @vinuraja and @josh11b to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5008, "title": "Compilation on Power8 and CUDA 7.5", "body": "I am compiling tensorflow on a Power8 CPU with CUDA enabled and I am getting the following error when running this command:\n\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\nERROR: /tensorflow/tensorflow/core/kernels/BUILD:46:1: output 'tensorflow/core/kernels/_objs/strided_slice_op_gpu/tensorflow/core/kernels/strided_slice_op_gpu.cu.pic.o' was not created.\nERROR:/tensorflow/tensorflow/core/kernels/BUILD:1714:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 118 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.\ngcc: internal compiler error: Killed (program cc1plus)\n\nMy gcc version is 4.8.4 on Ubuntu 14.04\n\nIs this version of GCC supported for the compilation of tensorflow? Do I need a different version? Has anyone encountered a similar problem?\n", "comments": ["gcc 4.8.4 should be fine (I think), however we haven't had enough experience with Power8, so I'm not sure what's happening there. From the logs here, it seems that `gcc` is failing?\n\nPerhaps you can try to diagnose further using `bazel build -s -c opt --config=cuda //tensorflow/tools/pip_package:buid_pip_package`?\n\n(Do you have the same problem without `--config=cuda`?)\n", "Automatically closing due to lack of recent activity. Please let us know when further information is available and we will reopen. Thanks!\n", "Exactly same issue I am facing. Compilation is getting killed all of a sudden. Any idea??", "@abdasgupta, could you open a new issue referencing this one and providing all the information asked for in the template (i.e. platform, version of os, version of compiler, version of tensorflow, and maybe amount of memory in your system.)\r\n"]}, {"number": 5007, "title": "Update classify_image.py code to use latest pre-trained model", "body": "The code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py references the older pre-trained model at http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz however, a new pre-trained model is available at http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz and is referenced in other parts of the code tree (such as https://github.com/tensorflow/models/tree/master/inception).\n\nPlease update the code in classify_image.py to reflect the latest pre-trained  model.\n", "comments": ["This seems a pretty straightforward find/replace issue. Anyone against me fixing it?\n", "@ghego I still see the older TGZ referenced\n", "@ghego : Thanks for taking the initiative to update this!\n\n@sudhashbahu : The pull request that @ghego made hasn't been merged yet. Follow along in the discussion for #5085 \n", "Any news?", "Close due to inactivity, Please see the detailed discussion on #5085", "Does anyone have a late 2019 or 2020 version? Because 600k biases images were removed from Image Net."]}, {"number": 5006, "title": "Use an OrderedDict in convert_collection_to_dict", "body": "When printing the dict, it's helpful to have the layers in the order they were created.\n", "comments": ["@jonasrauber, thanks for your PR! By analyzing the history of the files in this pull request, we identified @sguada and @tensorflower-gardener to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "We should update the docstring comment.\n\n@sguada any suggestion?\n", "It looks good, could you update the docstring of the function?\n", "Docstring updated\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n"]}, {"number": 5005, "title": "Mismatch between TFLearn documentation and tutorial", "body": "Hi all,\n\nThe changes to the metric creation in Estimator in tflearn don't match the current documentation on monitors. For example:\n\nhttps://www.tensorflow.org/versions/r0.11/tutorials/monitors/index.html\n\nsuggests:\n\n```\nvalidation_metrics = {\"accuracy\": tf.contrib.metrics.streaming_accuracy,\n                      \"precision\": tf.contrib.metrics.streaming_precision,\n                      \"recall\": tf.contrib.metrics.streaming_recall}\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n    test_set.data,\n    test_set.target,\n    every_n_steps=50,\n    metrics=validation_metrics)\n```\n\nwheras \n\nhttps://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/contrib/learn/python/learn/estimators/rnn.py\n\ncontains:\n\n```\n# Single head metrics.\n      if isinstance(predictions, dict):\n        raise ValueError(\n            'Metrics passed provide only name, no prediction, '\n            'but predictions are dict. '\n            'Metrics: %s, Targets: %s.' % (metrics, targets))\n```\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nNone\n### Environment info\n\nOperating System:\n\nMax OSX El Capitan\n\nInstalled version of CUDA and cuDNN:\n\nN/A - cpu version\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n0.11.0rc0\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nhttps://gist.github.com/alexshires/d9674c58e352ad81be43f5f7da74c7e1\n### What other attempted solutions have you tried?\n\nLooking up MetricSpec configuration - no examples or help available\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n\nhttps://gist.github.com/alexshires/5310a751e9b767fbd3595570d618c342\n", "comments": ["Thanks for the detailed report @alexshires !\n\n@martinwicke @ispirmustafa : IIRC, you guys were looking to switch to `MetricSpec` from a dict (a274c662b3f090193ead4138791896ffb65d680e). Would you be the right persons to fix the tutorial?\n", "@sandersk, @ispirmustafa, looks like the monitors tutorial references an old form of metrics. Should we fix it, or are you making a new one for hooks anyway?\n", "@martinwicke, since we need to update regardless, I think it would be ideal to replace the Monitors tutorial with a new one on Hooks. I will work with @ispirmustafa on that.\n", "That's perfect, thanks!\n\nOn Thu, Oct 27, 2016 at 2:35 PM, Sanders Kleinfeld <notifications@github.com\n\n> wrote:\n> \n> @martinwicke https://github.com/martinwicke, since we need to update\n> regardless, I think it would be ideal to replace the Monitors tutorial with\n> a new one on Hooks. I will work with @ispirmustafa\n> https://github.com/ispirmustafa on that.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5005#issuecomment-256776051,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_WRgrPyv4F2-2Otn2M05lWeP-hRmks5q4RkTgaJpZM4KYhc_\n> .\n", "I made a quick and dirty hack to the example code on my own fork for those who (like me) got stuck because of this: [https://github.com/dbfr3qs/tensorflow/commit/e1006cf8307662e1984dba6560e67e246a7ba46cy](https://github.com/dbfr3qs/tensorflow/commit/e1006cf8307662e1984dba6560e67e246a7ba46c)\n", "We're still working on new tutorial content, but this particular issue is out of date."]}, {"number": 5004, "title": "Update the version of re2 to support building with g++ 6.2.", "body": "Fixes the build on Ubuntu 16.10\n", "comments": ["@jhseu, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jart, @kirilg and @tensorflower-gardener to be potential reviewers.\n", "Jenkins, test this please\n", "Jenkins, test this please.\n"]}, {"number": 5003, "title": "C API crashes on simple problems  ", "body": "I am trying to incorporate Tensorflow into a larger OS X project, so using the stand-alone static library build (from contrib/makefile) and C API.\n\nOnce all the linking issues are resolved, the simplest Tensorflow programs compile fine, but do not run. I have so far found two issues when creating operations similarly to the c_api_test file:\n- When adding a constant Operation, Tensorflow crashes on exit from TF_SetAttrTensor(). The issue is that the managed buffer is deallocated, but still has refcount of 1. I am not sure why this happens since the managed buffer should supposedly be passed to the node_builder (which should retain the reference), but the buffer still gets deallocated.\n- Trying to work around that, it almost immediately hits another issue: TF_FinishOperation crashes because node_builder.Finalize call does not set the props of the Node and so ret->name() returns NULL.\n\nI do not know the codebase well enough (just started today), so perhaps you could point me to a possible underlying cause.\n\nUsing OS X 10.11.6, Xcode 8, libc++ and C++14. Tensorflow current as of October 16.\n", "comments": ["One thing you might be able to do is build the static or shared library with Bazel and then link that into your OS X project. If this does not work, please let us know, and we'll reopen the issue.\n\nWe appreciate you reporting this issue, but please take into consideration that the contrib/makefile build system is community supported on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). Although we will happily review any PRs improving it.\n", "@sergiyprotsiv Were you able to solve the second issue related to TF_FinishOperation? I'm having the same problem.", "The issue was resolved by building TF with Bazel as the developers suggested - none of the issues were present and I did not investigate the static build after that", "Thanks! I really want to make the static builds work for my application so I think I'll investigate a bit more."]}]