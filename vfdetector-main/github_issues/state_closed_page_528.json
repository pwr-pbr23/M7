[{"number": 37888, "title": "windows build with r2.2 failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 x64 1909\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0rc2\r\n- Python version: 3.8.1\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n- GPU model and memory:\r\nRTX2080Ti GDDR6 11GB\r\n\r\n\r\n**Describe the problem**\r\nbuild failed\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nINFO: Call stack for the definition of repository 'local_config_python' which is a python_configure (rule definition at D:/repo/tensorflow/third_party/py/python_configure.bzl:280:20):\r\n - D:/repo/tensorflow/tensorflow/workspace.bzl:97:5\r\n - D:/repo/tensorflow/WORKSPACE:19:1\r\nERROR: An error occurred during the fetch of repository 'local_config_python':\r\n   Traceback (most recent call last):\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 263\r\n                _create_local_python_repository(<1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 209, in _create_local_python_repository\r\n                _check_python_bin(<2 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in _check_python_bin\r\n                raw_exec(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in raw_exec\r\n                get_bash_bin(repository_ctx)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 66, in get_bash_bin\r\n                which(repository_ctx, \"bash\")\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 27, in which\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\nINFO: Could not find files for the given pattern(s).\r\nERROR: While resolving toolchains for target //third_party/eigen3:eigen3: invalid registered toolchain '@local_config_python//:py_toolchain': no such package '@local_config_python//': Traceback (most recent call last):\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 263\r\n                _create_local_python_repository(<1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 209, in _create_local_python_repository\r\n                _check_python_bin(<2 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in _check_python_bin\r\n                raw_exec(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in raw_exec\r\n                get_bash_bin(repository_ctx)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 66, in get_bash_bin\r\n                which(repository_ctx, \"bash\")\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 27, in which\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\nINFO: Could not find files for the given pattern(s).\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: invalid registered toolchain '@local_config_python//:py_toolchain': no such package '@local_config_python//': Traceback (most recent call last):\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 263\r\n                _create_local_python_repository(<1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 209, in _create_local_python_repository\r\n                _check_python_bin(<2 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in _check_python_bin\r\n                raw_exec(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/py/python_configure.bzl\", line 143, in raw_exec\r\n                get_bash_bin(repository_ctx)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 66, in get_bash_bin\r\n                which(repository_ctx, \"bash\")\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 27, in which\r\n                execute(repository_ctx, <1 more arguments>)\r\n        File \"D:/repo/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n                fail(<1 more arguments>)\r\nRepository command failed\r\nINFO: Could not find files for the given pattern(s).\r\nINFO: Elapsed time: 6.220s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (101 packages loaded, 322 targets configured)\r\n```", "comments": ["Did you run `./configure`? Can you try `bazel clean --expunge`, followed by `python configure.py` and then the build command?", "Also, see #37802 in case these have the same root cause", "sorry, my bad\r\n\r\nI accidently uninstalled MSYS2", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37888\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37888\">No</a>\n"]}, {"number": 37887, "title": "Wrong loss calculation with multi-output models when using model.fit.", "body": "**System information** \r\n- Have I written custom code: Yes, though the code sample below is adapted from an official tensorflow tutorial with minimal changes.\r\n- OS Platform and Distribution: Ubuntu 18.04 \r\n- TensorFlow installed from: official pip package, version 2.1.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: CUDA 10.1, GTX 1070\r\n\r\n\r\n**Describe the current behavior**\r\nConsider the following mnist example\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ninputs = tf.keras.Input(shape=(784,), name='digits')\r\nx = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\nx = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\r\noutputs = tf.keras.layers.Dense(10, name='predictions', activation='softmax')(x)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.SGD(),\r\n    loss={\"predictions\": tf.keras.losses.SparseCategoricalCrossentropy()},\r\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\r\n)\r\n\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784).astype('float32') / 255\r\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\r\ny_train = y_train.astype('float32')\r\ny_test = y_test.astype('float32')\r\n\r\nx_val = x_train[-10000:]\r\ny_val = y_train[-10000:]\r\nx_train = x_train[:-10000]\r\ny_train = y_train[:-10000]\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).repeat().batch(64)\r\n\r\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\r\nval_dataset = val_dataset.batch(64, drop_remainder=True)\r\n\r\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\r\ntest_dataset = test_dataset.batch(64)\r\n\r\nmodel.fit(train_dataset, epochs=3, steps_per_epoch=1000, validation_data=val_dataset)\r\n```\r\nThe output is \r\n```bash\r\nEpoch 1/3\r\n1000/1000 [==============================] - 4s 4ms/step - loss: 0.9192 - accuracy: 0.7615 - val_loss: 0.4060 - val_accuracy: 0.8914\r\nEpoch 2/3\r\n1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8939 - val_loss: 0.3147 - val_accuracy: 0.9127\r\nEpoch 3/3\r\n1000/1000 [==============================] - 3s 3ms/step - loss: 0.3211 - accuracy: 0.9080 - val_loss: 0.2796 - val_accuracy: 0.9196\r\n```\r\nThis works just fine as the loss decreases and the accuracy increases.\r\n\r\nHowever, if I simply add another dummy output to the model, the training will become erroneous. Let's just change the model definition line to `model = tf.keras.Model(inputs=inputs, outputs=[x, outputs])`\r\n\r\nNow the output is:\r\n```bash\r\nWARNING:tensorflow:Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.\r\nEpoch 1/3\r\nWARNING:tensorflow:Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.\r\nWARNING:tensorflow:Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.\r\n1000/1000 [==============================] - 4s 4ms/step - loss: 5.7781 - predictions_loss: 5.7781 - predictions_accuracy: 0.1048 - val_loss: 5.5196 - val_predictions_loss: 5.5196 - val_predictions_accuracy: 0.1243\r\nEpoch 2/3\r\n1000/1000 [==============================] - 4s 4ms/step - loss: 5.3866 - predictions_loss: 5.3866 - predictions_accuracy: 0.1202 - val_loss: 5.2255 - val_predictions_loss: 5.2255 - val_predictions_accuracy: 0.0967\r\nEpoch 3/3\r\n1000/1000 [==============================] - 4s 4ms/step - loss: 5.1167 - predictions_loss: 5.1167 - predictions_accuracy: 0.0996 - val_loss: 5.1479 - val_predictions_loss: 5.1479 - val_predictions_accuracy: 0.0992\r\n```\r\nBasically the network is not trained at all because as the warning says: *Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.*\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nThe expect behavior is that by adding additional outputs to the model should not affect the training process in anyway. Note that in `model.compile`, I specified the loss function using a dictionary, so I don't need to modify the rest of the code after adding a dummy output.\r\n\r\n\r\n", "comments": ["## Update ##\r\nI just found out that, if you alter the order of the outputs by doing `model = tf.keras.Model(inputs=inputs, outputs=[outputs, x])`, then the script works as expected. This means the first loss object you give will always be associated with the first output.\r\n\r\nI would say this is still a bug because the purpose of passing a dictionary to `loss` is to make everything explicit, so I don't have to worry about the order. This should work like python kwargs.", "@Hongtao-Niro,\r\nI was able to reproduce the error with TF 2.1. However, the issue seems to be fixed in TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/bba34c53fef4e0fd34ab0210cf5bd87a/37887-tf-nightly.ipynb). Thanks!", "Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37887\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37887\">No</a>\n"]}, {"number": 37886, "title": "After training the model using keras, tensorflow1.15 performs Post-training integer quantization, but the MCU prediction results are inconsistent with tflite output", "body": "@tensorflow/micro\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):  conda install tensorflow=1.15\r\n- Tensorflow version (commit SHA if source): 1.15.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arm-cortex M4\r\n\r\n**Describe the problem**\r\nMy English level is not very good, thank you very much for your help.\r\nI want to complete a voice wake-up MCU, after training the model using keras, tensorflow1.15 performs Post-training integer quantization, but the MCU prediction results are inconsistent with tflite output.\r\nWhen I run tflite tests using tensorflow, the output is correct, but the MCU output is wrong.\r\nSame model input, tflite goes through the first layer depth_wise output\uff1a\r\n![41585108178_ pic](https://user-images.githubusercontent.com/27952292/77500064-e3886680-6e8e-11ea-8b75-72218b61b898.jpg)\r\nSame model input, mcu goes through the first layer depth_wise output\uff1a\r\n![51585108202_ pic](https://user-images.githubusercontent.com/27952292/77500142-221e2100-6e8f-11ea-8c65-e9685d505ec4.jpg)\r\n\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n1. Convert to a TensorFlow Lite model\r\n```\r\ndef conver_tflite_int8():\r\n    converter = tf.lite.TFLiteConverter.from_keras_model_file(\"./dscnn_dense_model_depthwise/checkpoint-03e-loss_0.029.hdf5\")\r\n    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.inference_input_type = tf.int8\r\n    converter.inference_output_type = tf.int8\r\n    train_data = read_data()\r\n    def representative_dataset_gen():\r\n        for input_value in train_data:\r\n            yield [input_value]\r\n    converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen)\r\n    tflite_model_quant = converter.convert()\r\n    with open(\"./converted_model_float_dense_depthwise.tflite\", \"wb\") as wb:\r\n        wb.write(tflite_model_quant)\r\n```\r\n2. Load tflite prediction\r\n```\r\ndef load_int_perlayer():\r\n    txts = glob.glob(\"./first_test*.txt\")\r\n\r\n    interpreter_quant = tf.lite.Interpreter(model_path=str(\"./converted_model_int8_dense_depthwise.tflite\"))\r\n    interpreter_quant.allocate_tensors()\r\n    tensor_list = interpreter_quant.get_tensor_details()\r\n    for i in tensor_list:\r\n        print(i)\r\n\r\n    datas = []\r\n    for i in txts:\r\n        data = []\r\n        with open(i, 'r') as tr:\r\n            lines = tr.readlines()\r\n            for j in lines:\r\n                data.append([float(z) for z in j[:-1].split(' ')])\r\n        datas.append(data)\r\n    datas = np.array(datas)\r\n    data_min = -248.\r\n    data_max = 38.\r\n\r\n    for i in tqdm(range(len(datas))):\r\n        with open('./layer_out/mfcc_float.csv', 'w') as wc:\r\n            for j in datas[i].reshape((74, 10)):\r\n                wc.write(str(j) + '\\n')\r\n        data = (((datas[i].reshape((1, 74, 10, 1)) + 105) / 143) * 127.).astype(np.int8)\r\n        with open('./layer_out/mfcc_int.csv', 'w') as wc:\r\n            for j in data.reshape((74, 10)):\r\n                wc.write(str(j) + '\\n')\r\n\r\n        input_index = interpreter_quant.get_input_details()[0][\"index\"]\r\n        output_index = interpreter_quant.get_output_details()[0][\"index\"]\r\n        interpreter_quant.set_tensor(input_index, data.reshape((1, 74, 10, 1)))\r\n        interpreter_quant.invoke()\r\n        predictions = interpreter_quant.get_tensor(output_index)\r\n        print(predictions[0])\r\n```\r\n3. Convert to a C array\r\n```\r\nxxd -i ./converted_model_int8_dense_depthwise.tflite > model.cc\r\n```\r\nmodel.cc screenshot\r\n![61585108480_ pic](https://user-images.githubusercontent.com/27952292/77500247-77f2c900-6e8f-11ea-8e53-185d971527b3.jpg)\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37886\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37886\">No</a>\n"]}, {"number": 37885, "title": "Error when deserialising BatchNormalization layers from yaml", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes (see example below)\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10, Anaconda3\r\n\r\n- TensorFlow installed from: binary (pip)\r\n- TensorFlow version (use command below): tensorflow-gpu 2.1.0 (from pip)\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: GTX 1080\r\n\r\n**Describe the current behavior**\r\nWhen deserialising from yaml a model that contains a BatchNormalization layer, I get the exception `yaml.constructor.ConstructorError: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:tensorflow.python.training.tracking.data_structures.ListWrapper'`. Indeed, inspecting the yaml shows that this tag is in the BN layer, as follows:\r\n```\r\n[... other yaml]\r\n  - class_name: BatchNormalization\r\n    config:\r\n      axis: !!python/object/apply:tensorflow.python.training.tracking.data_structures.ListWrapper\r\n      - - 3\r\n[... other yaml]\r\n``` \r\n\r\nI have included a script below that seems able to reproduce this. Oddly, I then tried the same script on a Ubuntu system with `tensorflow==2.1.0` and that appeared ok, so this might only apply to tensorflow-gpu.\r\n\r\n**Describe the expected behavior**\r\nThe script below serialises and deserialises to/from yaml without errors.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\n\r\ninput_layer = tf.keras.layers.Input(shape=(32,32,3))\r\noutput = tf.keras.layers.BatchNormalization()(input_layer)\r\nmodel = tf.keras.Model(inputs=input_layer, outputs=output)\r\n\r\nyaml_out = model.to_yaml()\r\nmodel2 = tf.keras.models.model_from_yaml(yaml_out)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nFull traceback:\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\bin\\reproduce-bug.py\", line 13, in <module>\r\n    model2 = tf.keras.models.model_from_yaml(yaml_out)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py\", line 76, in model_from_yaml\r\n    config = yaml.load(yaml_string)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\__init__.py\", line 114, in load\r\n    return loader.get_single_data()\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 51, in get_single_data\r\n    return self.construct_document(node)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 60, in construct_document\r\n    for dummy in generator:\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 413, in construct_yaml_map\r\n    value = self.construct_mapping(node)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 218, in construct_mapping\r\n    return super().construct_mapping(node, deep=deep)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 143, in construct_mapping\r\n    value = self.construct_object(value_node, deep=deep)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 100, in construct_object\r\n    data = constructor(self, node)\r\n  File \"C:\\Users\\nitbi_000\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\yaml\\constructor.py\", line 429, in construct_undefined\r\n    node.start_mark)\r\nyaml.constructor.ConstructorError: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:tensorflow.python.training.tracking.data_structures.ListWrapper'\r\n  in \"<unicode string>\", line 24, column 13:\r\n          axis: !!python/object/apply:tensorflow ...\r\n```", "comments": ["@nitbix \r\ni ran the code shared by you and do not face any error, please find [gist here](https://colab.sandbox.google.com/gist/Saduf2019/17744bd21409ca2f71ee262f36cb5a6b/37885.ipynb)", "@Saduf2019 thanks for checking. I tried tensorflow-gpu in colab and that seems to work as well.\r\n\r\nI dug a bit more and narrowed it down a bit. This only happens with later versions of pyyaml - with 5.3.1 it fails on all environments I tested, with both tensorflow and tensorflow-gpu. Seems to be a change from 5.1 (ok) to 5.2 (not ok).\r\n\r\nAt this point I don't know if it's a bug in pyyaml or its behaviour has changed by design and something needs to be changed in tensorflow, that's where my knowledge of pyyaml stops.\r\n\r\nI've managed to reproduce it in colab as well simply by changing the pyyaml version.", "@nitbix\r\nCan you please share the gist of google colab you have reproduced the error.", "@Saduf2019 https://colab.research.google.com/gist/nitbix/b9db4179a0d72b1797f83909c89e69ae/37885.ipynb\r\n\r\nthe only difference from yours is the pyyaml version", "@nitbix\r\ni ran the same gist on the latest version of tensorflow and the error does not exist on the latest version of tensorflow, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/722179fab93a1892082c8b743f9f42aa/37885.ipynb)", "\ud83d\udc4d I guess someone must have already fixed this then. I'll keep an eye out for 2.2.0. In the meanwhile, for posterity, a temporary workaround for 2.1.0 is to downgrade pyyaml to <5.1.", "@nitbix \r\nplease confirm if we may move this issue to closed status ", "Yup, I'll reopen it if it recurs in the future. Thanks.\n\nOn Thu, 2 Apr 2020 at 18:58, Saduf2019 <notifications@github.com> wrote:\n\n> @nitbix <https://github.com/nitbix>\n> please confirm if we may move this issue to closed status\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37885#issuecomment-608013165>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AATCVCG6TVNMHKCZU6Q6VZDRKTG5NANCNFSM4LTEHILA>\n> .\n>\n\n\n-- \n  Alan\n", "Moving this to closed status with user confirmation", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37885\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37885\">No</a>\n", "version:2.2.0rc4 still has this problem.\r\n\r\n```\r\nConstructorError: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:tensorflow.python.framework.tensor_shape.TensorShape'\r\n  in \"<unicode string>\", line 4, column 22:\r\n      build_input_shape: !!python/object/apply:tensorflow ... \r\n```", "@lengthmin \r\nI ran the code on tf nightly and 2.2 and did not face any issues, please find the gist here for [nightly](https://colab.research.google.com/gist/Saduf2019/4e5901e610a4afea0012f9aab41dcf07/untitled233.ipynb) and [2.2](https://colab.research.google.com/gist/Saduf2019/376b2908838a0188d60d63582635ab70/untitled231.ipynb).\r\n\r\nPlease share a colab gist in case you face any issues.", "I am still getting the same error while executing on spark cluster even on   tf nightly and 2.2\r\n\r\npipeline = Pipeline(stages=[estimator])\r\nstart = timeit.default_timer()\r\nfitted_pipeline = pipeline.fit(df)\r\n\r\nError\r\nConstructorError: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:tensorflow.python.framework.tensor_shape.TensorShape'\r\n  in \"<unicode string>\", line 4, column 22:\r\n      build_input_shape: !!python/object/apply:tensorflow ... \r\n", "The detailed log file is attached. Please let me know if any solution\r\n\r\n![Capture](https://user-images.githubusercontent.com/53963317/107110095-2b2b9d00-686b-11eb-8da3-2cf530d679df.PNG)\r\n", "@snigdhasen \r\nCould you please create a new issue as this is closed.", "I have created new issue\nhttps://github.com/tensorflow/tensorflow/issues/47163\n\nOn Mon, Feb 8, 2021 at 10:36 AM Saduf2019 <notifications@github.com> wrote:\n\n> @snigdhasen <https://github.com/snigdhasen>\n> Could you please create a new issue as this is closed.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37885#issuecomment-774868770>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AM3WUNOWKCLYU3CDKX4FN23S55WOVANCNFSM4LTEHILA>\n> .\n>\n\n\n-- \nRegards,\nSnigdha Sen\n"]}, {"number": 37884, "title": "Try to convert a custom SSD_MobileNet model to tflite, but get the error: Check failed: dim_size >= 1 (0 vs. 1)", "body": "System information:\r\n\r\n- Windows 10\r\n\r\n- Python 3.6.10\r\n\r\n- Tensorflow 2.0.0\r\n\r\n```\r\nimport tensorflow as tf\r\n# pb path\r\npath = \"C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/frozen_inference_graph-SteelRoll.pb\"\r\n# input and output\r\ninputs = [\"image_tensor\"]\r\noutputs = [\"detection_boxes\", \"detection_classes\", \"detection_scores\", \"num_detections\"]\r\n# convert pb to tflite\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(path, inputs, outputs, input_shapes={\"image_tensor\":[1,640,360,3]})\r\nconverter.post_training_quantize = True\r\ntflite_model = converter.convert()\r\n# save\r\nopen(\"frozen_inference_graph-SteelRoll.tflite\", \"wb\").write(tflite_model)\r\n```\r\nHowever, when I run the above code, error messages will show up as the following:\r\n```\r\n2020-03-25 09:48:40.298641: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nC:\\Users\\LAWSSSS\\.conda\\envs\\tfcpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py:846: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\r\n  \" instead.\" % name)\r\nTraceback (most recent call last):\r\n  File \"C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/test.py\", line 18, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\Users\\LAWSSSS\\.conda\\envs\\tfcpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\Users\\LAWSSSS\\.conda\\envs\\tfcpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"C:\\Users\\LAWSSSS\\.conda\\envs\\tfcpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-03-25 09:48:42.916392: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.916652: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.916927: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-25 09:48:42.917171: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.917396: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.917617: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.917915: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.918138: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.918357: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.918575: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.918843: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.919088: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.919315: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-03-25 09:48:42.919565: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.919837: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.920075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.920288: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-25 09:48:42.920582: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.920799: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.921020: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.921263: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.921479: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.921704: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.922236: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.922514: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.922751: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.923035: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:42.923274: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.923526: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:42.947959: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.948212: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.948444: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.948713: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.949022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.949258: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.949485: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.949774: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.950029: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-25 09:48:42.950303: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-25 09:48:42.950636: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-25 09:48:42.950916: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-03-25 09:48:42.951170: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.951404: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.951638: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.951923: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.952150: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.952382: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.952614: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-03-25 09:48:42.952849: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.953080: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.953305: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.953526: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.953802: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.954023: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.954241: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.954527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.954812: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-03-25 09:48:42.955065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.955311: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.955544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.955805: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-25 09:48:42.956042: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.956253: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.956469: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.956688: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-25 09:48:42.956921: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.957130: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.957348: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.957562: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-25 09:48:42.957856: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.958068: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.958285: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.958497: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-03-25 09:48:42.958953: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-25 09:48:42.959338: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3\r\n2020-03-25 09:48:42.959836: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-03-25 09:48:42.960451: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2020-03-25 09:48:42.961178: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.961393: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.961612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.961940: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.962246: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.962459: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.962731: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.962943: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.963160: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.963396: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-03-25 09:48:42.963608: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-03-25 09:48:42.963905: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-03-25 09:48:42.964158: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.964369: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.964578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.964863: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-03-25 09:48:42.965125: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.965416: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:42.965733: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.965983: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:42.966222: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.966470: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:42.966816: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-03-25 09:48:42.967131: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-03-25 09:48:43.049924: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1791 operators, 3037 arrays (0 quantized)\r\n2020-03-25 09:48:43.216798: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1770 operators, 2983 arrays (0 quantized)\r\n2020-03-25 09:48:43.404253: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1770 operators, 2983 arrays (0 quantized)\r\n2020-03-25 09:48:43.509305: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)\r\nFatal Python error: Aborted\r\n```\r\nHow do I solve `Check failed: dim_size >= 1 (0 vs. 1)`.?\r\nThanks in advance.", "comments": ["Also, I notice that there are many \"unsupported operation\" showing up in the error message, do these faults have anything to do with my problem?", "@LAWSSSS \r\n\r\nPlease try including the code before tflite=converter.convert()\r\n\r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\nFor more information refer #35590\r\nIf the issue is still not resolved please provide us the complete code snippet used  along with supported files.Thanks!", "@ravikyram Thanks for the kind response. I added the code before `tflite=converter.convert()`. However, the same error still exists. Here is my complete code snippet:\r\n```\r\nimport tensorflow as tf\r\n# pb path\r\npath = \"C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/frozen_inference_graph-SteelRoll.pb\"\r\n# input and output\r\ninputs = [\"image_tensor\"]\r\noutputs = [\"detection_boxes\", \"detection_classes\", \"detection_scores\", \"num_detections\"]\r\n# convert pb to tflite\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(path, inputs, outputs, input_shapes={\"image_tensor\":[1,640,360,3]})\r\nconverter.post_training_quantize = True\r\n\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n# save\r\nopen(\"frozen_inference_graph-SteelRoll.tflite\", \"wb\").write(tflite_model)\r\n```\r\nAnd here is my model file if you need to check out: [frozen_model_file](https://github.com/LAWSSSS/Frozen_Pb/blob/master/frozen_inference_graph-SteelRoll.pb). I trained it with SSD MobileNet V2.\r\nThanks for your help in advance.", "@LAWSSSS I am not sure how you created the *.pb file. It is throwing data type mismatch error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/0ecb928c2d2df120d05a82259c485049/untitled46.ipynb). Can you please let us know what steps you followed to create *.pb file? Thanks!\r\n\r\n```\r\nloc(\"Preprocessor/map/while/LoopCond\"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor<2x!tf.resource<tensor<*xf32>>>'\r\nloc(\"Preprocessor/map/while/LoopCond\"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor<2x!tf.resource<tensor<*xf32>>>'\r\nloc(\"Preprocessor/map/while/LoopCond\"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor<2x!tf.resource<tensor<*xi32>>>'\r\n```", "@LAWSSSS Can you please take a look at my previous response? Thanks!", "@jvishnuvardhan Sorry for the late response, and thanks for your kind help. I've been working on another project recently and forgot to check this issue. I use the following code 'export_inference_graph.py' to generate .pb file:\r\n\r\n```\r\nr\"\"\"Tool to export an object detection model for inference.\r\n\r\nPrepares an object detection tensorflow graph for inference using model\r\nconfiguration and a trained checkpoint. Outputs inference\r\ngraph, associated checkpoint files, a frozen inference graph and a\r\nSavedModel (https://tensorflow.github.io/serving/serving_basic.html).\r\n\r\nThe inference graph contains one of three input nodes depending on the user\r\nspecified option.\r\n  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]\r\n  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]\r\n    containing encoded PNG or JPEG images. Image resolutions are expected to be\r\n    the same if more than 1 image is provided.\r\n  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing\r\n    serialized TFExample protos. Image resolutions are expected to be the same\r\n    if more than 1 image is provided.\r\n\r\nand the following output nodes returned by the model.postprocess(..):\r\n  * `num_detections`: Outputs float32 tensors of the form [batch]\r\n      that specifies the number of valid boxes per image in the batch.\r\n  * `detection_boxes`: Outputs float32 tensors of the form\r\n      [batch, num_boxes, 4] containing detected boxes.\r\n  * `detection_scores`: Outputs float32 tensors of the form\r\n      [batch, num_boxes] containing class scores for the detections.\r\n  * `detection_classes`: Outputs float32 tensors of the form\r\n      [batch, num_boxes] containing classes for the detections.\r\n  * `detection_masks`: Outputs float32 tensors of the form\r\n      [batch, num_boxes, mask_height, mask_width] containing predicted instance\r\n      masks for each box if its present in the dictionary of postprocessed\r\n      tensors returned by the model.\r\n\r\nNotes:\r\n * This tool uses `use_moving_averages` from eval_config to decide which\r\n   weights to freeze.\r\n\r\nExample Usage:\r\n--------------\r\npython export_inference_graph \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path path/to/ssd_inception_v2.config \\\r\n    --trained_checkpoint_prefix path/to/model.ckpt \\\r\n    --output_directory path/to/exported_model_directory\r\n\r\nThe expected output would be in the directory\r\npath/to/exported_model_directory (which is created if it does not exist)\r\nwith contents:\r\n - inference_graph.pbtxt\r\n - model.ckpt.data-00000-of-00001\r\n - model.ckpt.info\r\n - model.ckpt.meta\r\n - frozen_inference_graph.pb\r\n + saved_model (a directory)\r\n\r\nConfig overrides (see the `config_override` flag) are text protobufs\r\n(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override\r\ncertain fields in the provided pipeline_config_path.  These are useful for\r\nmaking small changes to the inference graph that differ from the training or\r\neval config.\r\n\r\nExample Usage (in which we change the second stage post-processing score\r\nthreshold to be 0.5):\r\n\r\npython export_inference_graph \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path path/to/ssd_inception_v2.config \\\r\n    --trained_checkpoint_prefix path/to/model.ckpt \\\r\n    --output_directory path/to/exported_model_directory \\\r\n    --config_override \" \\\r\n            model{ \\\r\n              faster_rcnn { \\\r\n                second_stage_post_processing { \\\r\n                  batch_non_max_suppression { \\\r\n                    score_threshold: 0.5 \\\r\n                  } \\\r\n                } \\\r\n              } \\\r\n            }\"\r\n\"\"\"\r\nimport tensorflow as tf\r\nfrom google.protobuf import text_format\r\nfrom object_detection import exporter\r\nfrom object_detection.protos import pipeline_pb2\r\n\r\nslim = tf.contrib.slim\r\nflags = tf.app.flags\r\n\r\nflags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '\r\n                    'one of [`image_tensor`, `encoded_image_string_tensor`, '\r\n                    '`tf_example`]')\r\nflags.DEFINE_string('input_shape', None,\r\n                    'If input_type is `image_tensor`, this can explicitly set '\r\n                    'the shape of this input tensor to a fixed size. The '\r\n                    'dimensions are to be provided as a comma-separated list '\r\n                    'of integers. A value of -1 can be used for unknown '\r\n                    'dimensions. If not specified, for an `image_tensor, the '\r\n                    'default shape will be partially specified as '\r\n                    '`[None, None, None, 3]`.')\r\nflags.DEFINE_string('pipeline_config_path', None,\r\n                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\r\n                    'file.')\r\nflags.DEFINE_string('trained_checkpoint_prefix', None,\r\n                    'Path to trained checkpoint, typically of the form '\r\n                    'path/to/model.ckpt')\r\nflags.DEFINE_string('output_directory', None, 'Path to write outputs.')\r\nflags.DEFINE_string('config_override', '',\r\n                    'pipeline_pb2.TrainEvalPipelineConfig '\r\n                    'text proto to override pipeline_config_path.')\r\nflags.DEFINE_boolean('write_inference_graph', False,\r\n                     'If true, writes inference graph to disk.')\r\ntf.app.flags.mark_flag_as_required('pipeline_config_path')\r\ntf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')\r\ntf.app.flags.mark_flag_as_required('output_directory')\r\nFLAGS = flags.FLAGS\r\n\r\n\r\ndef main(_):\r\n  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\r\n  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:\r\n    text_format.Merge(f.read(), pipeline_config)\r\n  text_format.Merge(FLAGS.config_override, pipeline_config)\r\n  if FLAGS.input_shape:\r\n    input_shape = [\r\n        int(dim) if dim != '-1' else None\r\n        for dim in FLAGS.input_shape.split(',')\r\n    ]\r\n  else:\r\n    input_shape = None\r\n  exporter.export_inference_graph(\r\n      FLAGS.input_type, pipeline_config, FLAGS.trained_checkpoint_prefix,\r\n      FLAGS.output_directory, input_shape=input_shape,\r\n      write_inference_graph=FLAGS.write_inference_graph)\r\n\r\n\r\nif __name__ == '__main__':\r\n  tf.app.run()\r\n```\r\nI use the following command combined with the code:\r\n`python export_inference_graph.py --pipeline_config_path=./data/ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix ./data/model.ckpt-19393 --output_directory ./data/exported_model_directory`\r\n\r\n", "@LAWSSSS Sorry for the delay in my response. I ran your code with `tf-nightly` and was able to convert the .pb to .tflite model. I added only one line as shown below\r\n\r\n`converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n`\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/f3f7e6034bb67815c186b67efedfd6db/untitled46.ipynb).\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37884\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37884\">No</a>\n"]}, {"number": 37883, "title": "tf.keras.layers.conv*d is slow compared to tf.nn.conv*d", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution : Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source): 3.8.0\r\n- GCC/Compiler version (if compiling from\r\nsource): 9.3.0\r\n- CUDA/cuDNN version: - GPU model and memory:\r\n10.2/7.6.5\r\n\r\n**Describe the current behavior**\r\nI initially discovered this issue last year. I switched to pytorch as a solution for that project. However, it seems the issue still exists on the master branch of tensorflow as of today. I will try to remember as much detail as I can based on my investigation last year.\r\n\r\ntf.keras.layers.conv\\*d calls nn_ops.Convolution to perform the convolution. However, nn_ops.Convolution is inefficient for dilated convolution, since it uses _WithSpaceToBatch to handle dilation. space_to_batch allocates and copies the memory. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spacetobatch_functor.cc https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spacetobatch_functor_gpu.cu.cc)  The performance issue is more severe for conv3d, since 3d volumes can be huge.  \r\n\r\nAfter space_to_batch, nn_ops.Convolution then calls _NonAtrousConvolution, which calls gen_nn_ops.conv\\*d for the actual convolution. Then batch_to_space is called to restore shape.\r\n\r\nOn the contrary, tf.nn.conv\\*d directly calls gen_nn_ops.conv\\*d for dilated convolution, which I guess calls the corresponding cudnn dilated convolution routines. It's efficient and fast.\r\n\r\n**Describe the expected behavior**\r\nnn_ops.Convolution should directly call gen_nn_ops.conv\\*d for dilated convolution. It seems _WithSpaceToBatch is not necessary. cudnn supports dilated convolutions. Switching to gen_nn_ops.conv\\*d can improve the performance with little efforts.\r\n\r\nMaybe this change can also potentially fix #23101?\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThank you so much for the help!", "comments": ["@KoykL,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code sample to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "> @KoykL,\r\n> In order to expedite the trouble-shooting process, could you please provide a minimal code sample to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n\r\nAny updates regarding this issue? Thanks!\r\n", "I don't have the environment to reproduce the issue with me. Closed for now. Sorry for that."]}, {"number": 37882, "title": "How to apply cosine similarity loss function in unsupervised training?", "body": "In the Figure below is showed a simple deep learning architecture capable of learning embeddings for sentences. The training set is composed by sentence pairs `[[sentence_a],[sentence_b]]` that have the same semantics.\r\n\r\n[![enter image description here][1]][1]\r\n\r\nThe objective is to fine-tune the embeddings of the sentences to be similar (since sentences in the pair have the same semantics). Consequently, a possible loss function would be `CosineSimilarity` loss.\r\n\r\n\r\n\r\n`Encoder 1` and `Encoder 2` have the same definition:\r\n\r\n```python\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass LSTMEncoder(layers.Layer):\r\n\r\n    def __init__(self,\r\n                 units,  # dimensionality of the output space\r\n                 input_dim,  # vocab of size\r\n                 output_dim,  # embedding dimension\r\n                 name='encoder',\r\n                 **kwargs):\r\n        super(Encoder, self).__init__(name=name, **kwargs)\r\n        self.embedding = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\r\n        self.lstm = layers.LSTM(units=units)\r\n\r\n    def call(self, inputs):\r\n        emb = self.embedding(inputs)\r\n        return self.lstm(emb)\r\n```\r\n\r\nAnd the SEntence Representations model `(SERModel)` looks like:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom source.layer.rnn_encoder import LSTMEncoder\r\n\r\n\r\nclass SERModel(tf.keras.Model):\r\n    \"\"\"\r\n    Defines a SEntence Representations Model\r\n    \"\"\"\r\n\r\n    def __init__(self,\r\n                 units,  # dimensionality of the output space\r\n                 input_dim,  # vocab of size\r\n                 output_dim,  # embedding dimension\r\n                 name='SEntence Representations Model',\r\n                 **kwargs):\r\n        super(SERModel, self).__init__(name=name, **kwargs)\r\n        self.encoder = LSTMEncoder(units=units, input_dim=input_dim, output_dim=output_dim)\r\n\r\n    def call(self, inputs):\r\n        sentence_a, sentence_b = inputs\r\n        return self.encoder(sentence_a), self.encoder(sentence_b)\r\n\r\n```\r\n\r\nTo train the model one can simply do as shown next:\r\n\r\n\r\n```python\r\nfrom source.model.SERModel import SERModel\r\nimport tensorflow as tf\r\n\r\n\r\ndef run_test():\r\n    \r\n    # load train data\r\n    train_data = load_data()\r\n\r\n    ser = SERModel(units=128, input_dim=10000, output_dim=64)\r\n\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n\r\n    ser.compile(optimizer, loss=tf.keras.losses.CosineSimilarity())\r\n    ser.fit(train_data, epochs=3, batch_size=64)\r\n\r\n\r\nif __name__ == '__main__':\r\n    run_test()\r\n\r\n```\r\n\r\nAt this point is where I need help. The loss requires `y_true` and `y_pred`, but as can be seen, this is unsupervised training and there is no `y_true`. So, would you have an approach that would allow me to train the above architecture using `CosineSimilarity` loss?\r\n\r\n\r\nThank you very much in advance.\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/Px8hL.png", "comments": ["@Ceceu Please take a look at the answers of this issue [here](https://www.researchgate.net/post/Loss_Functions_for_unsupervised_image_segmentation).\r\n\r\nAlso as this issue is not related to bug/performance, build/install, docs or related issues, can you please post this question in stackoverflow as there is a wider community to respond and close this issue. Thanks!", "@Ceceu Are you able to figure this issue out? Did you post it in stackoverflow?", "Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments for us to open the issue again. "]}, {"number": 37881, "title": "tf.tpu.experimental.initialize_tpu_system raises GRPC error", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: NA\r\n- TensorFlow installed from (source or\r\nbinary): using google colab\r\n- TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source): 3.6\r\n\r\n**Describe the current behavior**\r\nWhen I try to setting TPU system in google colab in tensorflow 2.0.0, tf.tpu.experimental.initialize_tpu_system raises GRPC error. \r\nIt worked normally until about 12 hours ago and I don't change any codes.\r\nWhat I try to do to solve this problem?\r\n\r\n**Standalone code to reproduce the issue** \r\nhttps://gist.github.com/fwatty-1218/48d4f1be7b66245321376c4e2af3352a\r\n\r\n**Any other info / logs**\r\nIf I use tensorflow 2.1.0, it works fine, but I want to use tensorflow 2.0.0 because I want to use TPU.", "comments": ["@fwatty-1218 \r\ni have run the code shared in your gist on same version and tpu but face a different error,please find the gist [here](https://colab.sandbox.google.com/gist/Saduf2019/6f9a9a21af272bb3974dcb44a9592a0b/37881.ipynb)", "Looking at the gist, the process leading up to the error is the same, so the cause of the error may be due to the assigned TPU device?", "@fwatty-1218 I ran your code with `TF2.2rc2` version and I cannot reproduce the error. Can you please try `TF2.2rc2` version and let us know whether the issue resolved for you or not. [Here](https://colab.research.google.com/gist/jvishnuvardhan/3d5e409c1e85e1355289b0b43afed0ef/untitled45.ipynb) is the gist for your reference. Thanks!\r\n\r\nPlease close the issue if the issue was resolved for you. Thanks! ", "Thanks for solving my problem!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37881\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37881\">No</a>\n"]}, {"number": 37880, "title": "Build Fail Due to \"ImportError: No module named enum\" (python 3.7)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (macOS Mojave, version 10.14.6):\r\n- TensorFlow installed from (source, https://github.com/tensorflow/tensorflow.git):\r\n- TensorFlow version: 2\r\n- Python version: 3.7\r\n- Installed using pip\r\n- Bazel version (if compiling from source): 2.2.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nFollowing the extract instruction here: https://www.tensorflow.org/install/source \r\nSpecified python 3.7 in ./configure\r\n\r\nRun:  **bazel build //tensorflow/tools/pip_package:build_pip_package --host_force_python=PY3**\r\n\r\nThe build failed, saying \"ImportError: No module named enum\". See the detail below. \r\n**Already googled and tried  pip install --upgrade pip enum34, but still not working.**\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nERROR: /Users/leiwang/GoogleDrive/models/tensorflow/tensorflow/python/keras/api/BUILD:133:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 37, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 46, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/private/var/tmp/_bazel_leiwang/db84a35c42355241097f16166c7580af/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /Users/leiwang/GoogleDrive/models/tensorflow/tensorflow/tools/pip_package/BUILD:65:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)\r\nINFO: Elapsed time: 1.875s, Critical Path: 1.19s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37880\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37880\">No</a>\n", "solved"]}, {"number": 37879, "title": "Update version numbers for TensorFlow 2.2.0-rc2", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 2 -> 2\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.2.0-rc1\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"2.2.0rc1\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 37878, "title": "r2.2-rc2 cherry-pick request: [Intel MKL] Upgrade DNNL to v1.2.2.", "body": "DNNL v1.2.2 (new name for MKL-DNN): \r\n(i) Fixes memory leak in scratchpad destructor.\r\n(ii) Reduces sgemm performance regression within the `dnnl_sgemm` API.\r\n\r\nThis PR only affects TensorFlow-MKL.", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37878) for more info**.\n\n<!-- need_author_consent -->", "Manually setting CLA to yes because this cherrypicks commit https://github.com/tensorflow/tensorflow/pull/37767/commits/8d82addeab1af2c58a45a9aa85061fc192283b3c from PR https://github.com/tensorflow/tensorflow/pull/37767, which is already merged into master.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37878) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 37877, "title": "[TF2.2:Cherrypick]Fixing a memory leak in Keras.", "body": "Fixes: https://github.com/tensorflow/tensorflow/issues/37515\nPiperOrigin-RevId: 302568217\nChange-Id: I28d0eaf3602fea0461901680df24899f135ce649", "comments": ["Thank you very much Geeta! I was actually in a middle of creating a cherrypick myself :-)"]}, {"number": 37876, "title": "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112000). Check your callbacks.", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10 Pro x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or\r\nbinary): source\r\n- TensorFlow version (use command below): master branch, commit 99e754b3a189eefab15fdbf326115d312e44fc7b\r\n- Python version: 3.7\r\n- Bazel\r\nversion (if compiling from source): the default downloaded by Bazelisk\r\n- GCC/Compiler version (if compiling from\r\nsource): MSVS2019 v16.5.0\r\n- CUDA/cuDNN version: CUDA 10.2, cuDNN 7.6.5\r\n- GPU model and memory: Geforce GTX 1080, 8GB or Geforce RTX 2080, 8GB (same problem)\r\n\r\n**Describe the current behavior**\r\n![on_train_batch_end](https://user-images.githubusercontent.com/5251612/77467782-a59f2a00-6e1d-11ea-82e1-b45377442294.png)\r\n2/3 of time is spent in method `on_train_batch_end` without any user callbacks (i.e. it seems it spends time in TensorFlow internals)\r\n\r\n**Describe the expected behavior**\r\n`on_train_batch_end` doesn't take a majority of training time if no user callbacks that do heavy ops in it are specified.\r\n\r\n**Standalone code to reproduce the issue** \r\nYou need at least 64GB of RAM to execute this:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nnum_inputs=1440*3\r\nnum_outputs=2\r\n\r\nN = 1000*1000\r\ntrain_X = np.random.randn(N, num_inputs)\r\ntrain_y = np.random.randn(N, num_outputs)\r\n\r\ntf.keras.backend.set_floatx('float32')\r\nmodel = keras.Sequential()\r\nn_hidden = 2*num_inputs\r\n\r\nactivation1 = tf.nn.relu\r\nmodel.add(layers.Dense(n_hidden, activation=activation1, input_shape=(num_inputs,)))\r\nfor i in range(4):\r\n    model.add(layers.Dense(n_hidden, activation=activation1))\r\nmodel.add(layers.Dense(num_outputs))\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\r\n              loss=tf.keras.losses.mse,\r\n              metrics=(tf.keras.metrics.mse,))\r\n\r\nmodel.fit(train_X, train_y, epochs=1000, batch_size=512, verbose=2)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nD:\\Programs\\Anaconda\\python.exe \"C:\\Program Files\\JetBrains\\PyCharm 2019.3.3\\plugins\\python\\helpers\\pydev\\pydevconsole.py\" --mode=client --port=1305\r\nimport sys; print('Python %s on %s' % (sys.version, sys.platform))\r\nsys.path.extend(['D:\\\\Dev\\\\Views\\\\Trading-git\\\\CudaNN\\\\src\\\\Anaconda', 'D:/Dev/Views/Trading-git/CudaNN/src/Anaconda'])\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.\r\nPyDev console: using IPython 7.8.0\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] on win32\r\nrunfile('D:/Dev/Views/Trading-git/CudaNN/src/Anaconda/Reproduction01.py', wdir='D:/Dev/Views/Trading-git/CudaNN/src/Anaconda')\r\n2020-03-24 22:40:00.449504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_102.dll\r\n2020-03-24 22:41:58.323992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-03-24 22:41:58.347918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties: \r\npciBusID: 0000:0b:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.8855GHz coreCount: 20 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2020-03-24 22:41:58.348257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_102.dll\r\n2020-03-24 22:41:58.352623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-03-24 22:41:58.356230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-03-24 22:41:58.357648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-03-24 22:41:58.361747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-03-24 22:41:58.364018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-03-24 22:41:58.372291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-03-24 22:41:58.373318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0\r\n2020-03-24 22:41:58.373720: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-03-24 22:41:58.382851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d1a0667d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-03-24 22:41:58.383116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-03-24 22:41:58.383724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties: \r\npciBusID: 0000:0b:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.8855GHz coreCount: 20 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2020-03-24 22:41:58.384041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_102.dll\r\n2020-03-24 22:41:58.384254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-03-24 22:41:58.384441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-03-24 22:41:58.384612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-03-24 22:41:58.384788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-03-24 22:41:58.384962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-03-24 22:41:58.385136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-03-24 22:41:58.385759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0\r\n2020-03-24 22:41:58.938950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1085] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-24 22:41:58.939152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1091]      0 \r\n2020-03-24 22:41:58.939263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 0:   N \r\n2020-03-24 22:41:58.939991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6278 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:0b:00.0, compute capability: 6.1)\r\n2020-03-24 22:41:58.943050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d1c48bade0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-03-24 22:41:58.943286: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\r\nEpoch 1/1000\r\n2020-03-24 22:42:13.278214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.188999). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.198997). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.199499). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200001). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.199999). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200000). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200000). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200000). Check your callbacks.\r\nWARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200000). Check your callbacks.\r\n```\r\n", "comments": ["This may be due to the fact that you've given verbose=2 in your fit model. You can try verbose = 1.", "According to https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit :\r\n\r\n> verbose: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Note that the progress bar is not particularly useful when logged to a file, so verbose=2 is recommended when not running interactively (eg, in a production environment).\r\n\r\nSo `verbose=2` seems to be not that verbose to trigger such a warning: it prints something on epoch end, which is rarer than the batch end. In contrast, they suggest on the internet to change from `verbose=1` to `verbose=2` in order to avoid such warning, because I guess `verbose=1` prints something on every batch.", "@srogatch,\r\nThe `verbose` argument lets you control what output you see on each epoch. For more information please check this [StackOverflow](https://stackoverflow.com/a/47905435) comment. \r\n\r\nRegarding the warning logs, could you please try changing the logging level and check if it works?\r\n```\r\nimport os\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\r\nimport tensorflow as tf\r\n```\r\n Thanks!", "@amahendrakar , thanks for your suggestions about suppressing the logs. However, the point missed in this approach is that excessive output from Tensorflow seems to indicate a bug in it. As you can see in the diagram I attached, it looks like a lot of time is spent on a side activity. ", "For me the issue also has nothing to do with the callbacks (it persists after removing all callbacks). For me, the warning appears after I either increase my batch size from 32 to 64 or increase my image width from 32 to 64 pixels. ", "I am also experiencing this, even without callbacks. ", "Same issue, I just use `ModelCheckpoint` and `TerminateOnNaN`.", "Same issue. Also have no relations with callbacks (issue remains even without callbacks). According to @ybagdasa, I tried batch size with 16,32,64,256, issues remains in all cases.", "Try Stochastic Gradient Descent, remove the 'batch_size = 512' from model.fit and it shouldn't give you the warning.", "I got this warning on the first epoch and then not again. However, the first epoch also didn't finish which makes me suspect that this warning is masking some other runtime problem. \r\n\r\n![image](https://user-images.githubusercontent.com/40213289/83208743-16afd600-a11c-11ea-8023-7c02a35c38e2.png)\r\n\r\nThe warning comes from [this file](https://github.com/keras-team/keras/blob/master/keras/callbacks/callbacks.py) and highlights any method that slows down in comparison to the benchmark function \"batch update\" which runs every epoch on the same number of weights. \r\n\r\n```\r\nwarnings.warn(\r\n                'Method (%s) is slow compared '\r\n                'to the batch update (%f). Check your callbacks.'\r\n                % (hook_name, delta_t_median), RuntimeWarning)\r\n```\r\n\r\nI think the error might have to do with the **Early Stop** callback function since, when I removed it the error never appeared again. Even when I added the **Reduce Learning Rate** callback. But haven't run a rigorous test to replicate the error so not sure.", "> @amahendrakar , thanks for your suggestions about suppressing the logs. However, the point missed in this approach is that excessive output from Tensorflow seems to indicate a bug in it. As you can see in the diagram I attached, it looks like a lot of time is spent on a side activity.\r\n\r\nHi @srogatch,\r\n\r\nPlease let me how you can resolve such an issue, and even small workaround also acceptable.\r\n\r\n(Apart from hiding warnings as suggested in above comments)\r\n", "@bhaskar24 , I believe this must be resolved by a tensorflow code change. As far as I remember, I didn't have a workaround for the issue.", "Thanks for your reply. But I have compiled the recent version of TensorFlow but still facing the same.\r\n\r\nNo issue.!", "I have the same issue and the input size is also tiny ( 32*32) ", "Same Issue on my neural network. Please update when the issue will be resolved. I agree that bidding warning is not a solution.\r\n", "I have this issue as well with no callbacks implemented aside from what is the default operation of fit(). I only have this issue with convolutional models, but I've only run fully connected and convolutional models. I have not run any recurrent models.", "Running tf2.3rc2 on TPU and I am facing the same issue as well.", "Same issue with tf2.3, no callbacks.\r\nSame behaviour using `verbose=1` or `verbose=2`", "@EnderWiggin14 The warning issue is also prevalent for LSTM as well. I didn't face this without callbacks though", "Have this warning plus also warning about  Autograph transform", "Same issue with tf2.3, tensorboard callback, `verbose=1`", "setting verbose=2 gets rid of the warning", "This is caused when other operations which runs at the end of each batch consumes longer time than batch themselves. \r\nOne of the causes might be, we have really smaller batches. So, any operations is slow compared to your original batches.\r\n\r\nIncreasing batch size actually solved the problem for me.\r\n\r\nsee @bstriner comment in [Link](https://github.com/keras-team/keras/issues/5008)", "I saw exactly the same warning. In my case, it was the problem of the Tensorboard callback. I used batch size of 32 and probably, Tensorboard's callback took longer for saving and writing log files than an iteration of 32 examples.  I had removed Tensorboard from my callbacks' list and the Warning has been disappeared.", "Same thing the post above me said, when I removed the Tensorboard callback it seemed to disappear", "Well, I do not know why this happens. However, the error disappeared when I reduced the batch size from 64 to 32 and increased image size from 150 to 256. Still have all my callbacks intact.", "I faced the same issue using tf-2.3. Downgrading to tf-2.2 resolved the problem for me.\r\n\r\nI tried every suggested solution without success:\r\n- Supress the warnings using verbose parameter does not help and is a bad workaround. \r\n- Decreasing batch size does not help\r\n- Turn off all callbacks leads to same on_train_batch_end time as with callbacks\r\n\r\nMaybe tf devs should investigate this bug which exists in tf 2.3 but not in tf 2.2", "> I faced the same issue using tf-2.3. Downgrading to tf-2.2 resolved the problem for me.\r\n> \r\n> I tried every suggested solution without success:\r\n> \r\n> * Supress the warnings using verbose parameter does not help and is a bad workaround.\r\n> * Decreasing batch size does not help\r\n> * Turn off all callbacks leads to same on_train_batch_end time as with callbacks\r\n> \r\n> Maybe tf devs should investigate this bug which exists in tf 2.3 but not in tf 2.2\r\n\r\nYou should be increasing the Batch size! decreasing it will worsen it.", "Facing the same issue on August 2020. \r\n`Batch Size of 32, Images dimension are 224,224 as for VGG16. `", "I was having the same warning\r\n```\r\nLoading model\r\nEpoch 1/3\r\n   2/1688 [..............................] - ETA: 6:36 - loss: 2.2862 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.4677s). Check your callbacks.\r\n1688/1688 [==============================] - 5s 3ms/step - loss: 0.4661 - accuracy: 0.8339 - val_loss: 0.3578 - val_accuracy: 0.8735\r\nEpoch 2/3\r\n1688/1688 [==============================] - 4s 2ms/step - loss: 0.3157 - accuracy: 0.8861 - val_loss: 0.2872 - val_accuracy: 0.8923\r\nEpoch 3/3\r\n1688/1688 [==============================] - 4s 2ms/step - loss: 0.2734 - accuracy: 0.8991 - val_loss: 0.2711 - val_accuracy: 0.9012\r\n```\r\n\r\nI could remove the warning by adding `profile_batch=0` (to disable profiling) to the [Tensorboard callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard). Now my call back looks like this,\r\n```\r\ntbCallBack = TensorBoard(log_dir='logs', update_freq='epoch', write_graph=True, profile_batch=0)\r\n```\r\nI am using Tensorflow 2.3.0.\r\n\r\n```\r\nLoading model\r\nEpoch 1/3\r\n1688/1688 [==============================] - 4s 2ms/step - loss: 0.4849 - accuracy: 0.8240 - val_loss: 0.3673 - val_accuracy: 0.8658\r\nEpoch 2/3\r\n1688/1688 [==============================] - 4s 2ms/step - loss: 0.3282 - accuracy: 0.8810 - val_loss: 0.3016 - val_accuracy: 0.8902\r\nEpoch 3/3\r\n1688/1688 [==============================] - 4s 2ms/step - loss: 0.2792 - accuracy: 0.8978 - val_loss: 0.2671 - val_accuracy: 0.9022\r\n```\r\n\r\nand below lines removes other warnings.\r\n```\r\nimport os\r\n# To disable all logging output from TensorFlow\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\" \r\n```", "[\r\n![Screenshot (8)](https://user-images.githubusercontent.com/52927091/97406657-254d2400-192c-11eb-84d1-55efeb4a18e7.png)\r\n](url)\r\n\r\nWhy WARNING: TensorFlow callbacks method ? How can I resolve it???\r\n", "> This may be due to the fact that you've given verbose=2 in your fit model. You can try verbose = 1.\r\n\r\nthis will just suppress it. ", "Hi Everyone,\r\n\r\nAfter using it for a while, I found this is really not a bug. It is just for each training batch, keras is doing some callbacks. The warning shows up because the callback is taking longer than the training itself. It might be that you are doing some expensive ops. Note that other than the callbacks you defined by yourself, keras has some default callbacks, as shown here:\r\nhttps://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/keras/callbacks.py#L254-L271", "Hi.\r\nThis problem occurred when I used custom callbacks that took a long time in <= 2.2.\r\nI solved this problem by hacking a small part of CallbackList.\r\n\r\nThe warning message is due to [this](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304).\r\n```python\r\nclass CallbackList(object):\r\n..\r\n..\r\n    def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n        \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n        if not self.callbacks:\r\n            return\r\n        hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n        if hook == 'begin':\r\n            self._t_enter_batch = time.time()\r\n        if hook == 'end':\r\n            # Batch is ending, calculate batch time.\r\n            self._delta_t_batch = time.time() - self._t_enter_batch\r\n\r\n        logs = logs or {}\r\n        t_before_callbacks = time.time()\r\n        for callback in self.callbacks:\r\n            batch_hook = getattr(callback, hook_name)\r\n            batch_hook(batch, logs)\r\n        self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n\r\n        delta_t_median = np.median(self._delta_ts[hook_name])\r\n        if (self._delta_t_batch > 0. and\r\n              delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\r\n            # here is the warning message!\r\n            logging.warning(\r\n                'Method (%s) is slow compared '\r\n                'to the batch update (%f). Check your callbacks.', hook_name, \r\n                delta_t_median)\r\n..\r\n..\r\n```\r\n\r\nIf you don't need to check the time of your callbacks, you can delete the message and assign a new CallbackList to the original CallbackList as below.\r\n\r\n```python\r\nfrom tensorflow.python.keras.callbacks import CallbackList\r\nclass CustomCallbackList(CallbackList):\r\n    def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n        \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n        if not self.callbacks:\r\n            return\r\n        hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n\r\n        logs = logs or {}\r\n        for callback in self.callbacks:\r\n            batch_hook = getattr(callback, hook_name)\r\n            batch_hook(batch, logs)\r\n\r\ntf.python.keras.callbacks.CallbackList = CustomCallbackList\r\n```", "> Hi.\r\n> This problem occurred when I used custom callbacks that took a long time in <= 2.2.\r\n> I solved this problem by hacking a small part of CallbackList.\r\n> \r\n> The warning message is due to [this](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304).\r\n> \r\n> ```python\r\n> class CallbackList(object):\r\n> ..\r\n> ..\r\n>     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n>         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n>         if not self.callbacks:\r\n>             return\r\n>         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n>         if hook == 'begin':\r\n>             self._t_enter_batch = time.time()\r\n>         if hook == 'end':\r\n>             # Batch is ending, calculate batch time.\r\n>             self._delta_t_batch = time.time() - self._t_enter_batch\r\n> \r\n>         logs = logs or {}\r\n>         t_before_callbacks = time.time()\r\n>         for callback in self.callbacks:\r\n>             batch_hook = getattr(callback, hook_name)\r\n>             batch_hook(batch, logs)\r\n>         self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n> \r\n>         delta_t_median = np.median(self._delta_ts[hook_name])\r\n>         if (self._delta_t_batch > 0. and\r\n>               delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\r\n>             # here is the warning message!\r\n>             logging.warning(\r\n>                 'Method (%s) is slow compared '\r\n>                 'to the batch update (%f). Check your callbacks.', hook_name, \r\n>                 delta_t_median)\r\n> ..\r\n> ..\r\n> ```\r\n> \r\n> If you don't need to check the time of your callbacks, you can delete the message and assign a new CallbackList to the original CallbackList as below.\r\n> \r\n> ```python\r\n> from tensorflow.python.keras.callbacks import CallbackList\r\n> class CustomCallbackList(CallbackList):\r\n>     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n>         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n>         if not self.callbacks:\r\n>             return\r\n>         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> \r\n>         logs = logs or {}\r\n>         for callback in self.callbacks:\r\n>             batch_hook = getattr(callback, hook_name)\r\n>             batch_hook(batch, logs)\r\n> \r\n> tf.python.keras.callbacks.CallbackList = CustomCallbackList\r\n> ```\r\n\r\nDid this work for you? It's giving me an error.\r\n\r\n`AttributeError: module 'tensorflow' has no attribute 'python'`\r\n\r\nBesides, I think this isn't really solving the problem. It may eliminate the error message but the on_train_batch_end will be still taking longer than the learning itself. I have no callbacks and I want to fix this. Nice idea looking at the source code anyway.\r\n\r\n", "> > Hi.\r\n> > This problem occurred when I used custom callbacks that took a long time in <= 2.2.\r\n> > I solved this problem by hacking a small part of CallbackList.\r\n> > The warning message is due to [this](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304).\r\n> > ```python\r\n> > class CallbackList(object):\r\n> > ..\r\n> > ..\r\n> >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> >         if not self.callbacks:\r\n> >             return\r\n> >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> >         if hook == 'begin':\r\n> >             self._t_enter_batch = time.time()\r\n> >         if hook == 'end':\r\n> >             # Batch is ending, calculate batch time.\r\n> >             self._delta_t_batch = time.time() - self._t_enter_batch\r\n> > \r\n> >         logs = logs or {}\r\n> >         t_before_callbacks = time.time()\r\n> >         for callback in self.callbacks:\r\n> >             batch_hook = getattr(callback, hook_name)\r\n> >             batch_hook(batch, logs)\r\n> >         self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n> > \r\n> >         delta_t_median = np.median(self._delta_ts[hook_name])\r\n> >         if (self._delta_t_batch > 0. and\r\n> >               delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\r\n> >             # here is the warning message!\r\n> >             logging.warning(\r\n> >                 'Method (%s) is slow compared '\r\n> >                 'to the batch update (%f). Check your callbacks.', hook_name, \r\n> >                 delta_t_median)\r\n> > ..\r\n> > ..\r\n> > ```\r\n> > \r\n> > \r\n> > If you don't need to check the time of your callbacks, you can delete the message and assign a new CallbackList to the original CallbackList as below.\r\n> > ```python\r\n> > from tensorflow.python.keras.callbacks import CallbackList\r\n> > class CustomCallbackList(CallbackList):\r\n> >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> >         if not self.callbacks:\r\n> >             return\r\n> >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> > \r\n> >         logs = logs or {}\r\n> >         for callback in self.callbacks:\r\n> >             batch_hook = getattr(callback, hook_name)\r\n> >             batch_hook(batch, logs)\r\n> > \r\n> > tf.python.keras.callbacks.CallbackList = CustomCallbackList\r\n> > ```\r\n> \r\n> Did this work for you? It's giving me an error.\r\n> \r\n> `AttributeError: module 'tensorflow' has no attribute 'python'`\r\n> \r\n> Besides, I think this isn't really solving the problem. It may eliminate the error message but the on_train_batch_end will be still taking longer than the learning itself. I have no callbacks and I want to fix this. Nice idea looking at the source code anyway.\r\n\r\nIf tensorflow is in the environment used, the error you mentioned does not appear. You can check it in [my example](https://github.com/PaperCodeReview/PixPro-TF/blob/master/callback.py#L20).\r\nOf course, it just removes the message as you said. If you already know that `on_train_batch_end` has heavy operations, it is very utilizable. Otherwise, check your train_step loop whether any problem exists.", "> > > Hi.\r\n> > > This problem occurred when I used custom callbacks that took a long time in <= 2.2.\r\n> > > I solved this problem by hacking a small part of CallbackList.\r\n> > > The warning message is due to [this](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304).\r\n> > > ```python\r\n> > > class CallbackList(object):\r\n> > > ..\r\n> > > ..\r\n> > >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> > >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> > >         if not self.callbacks:\r\n> > >             return\r\n> > >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> > >         if hook == 'begin':\r\n> > >             self._t_enter_batch = time.time()\r\n> > >         if hook == 'end':\r\n> > >             # Batch is ending, calculate batch time.\r\n> > >             self._delta_t_batch = time.time() - self._t_enter_batch\r\n> > > \r\n> > >         logs = logs or {}\r\n> > >         t_before_callbacks = time.time()\r\n> > >         for callback in self.callbacks:\r\n> > >             batch_hook = getattr(callback, hook_name)\r\n> > >             batch_hook(batch, logs)\r\n> > >         self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n> > > \r\n> > >         delta_t_median = np.median(self._delta_ts[hook_name])\r\n> > >         if (self._delta_t_batch > 0. and\r\n> > >               delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\r\n> > >             # here is the warning message!\r\n> > >             logging.warning(\r\n> > >                 'Method (%s) is slow compared '\r\n> > >                 'to the batch update (%f). Check your callbacks.', hook_name, \r\n> > >                 delta_t_median)\r\n> > > ..\r\n> > > ..\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > If you don't need to check the time of your callbacks, you can delete the message and assign a new CallbackList to the original CallbackList as below.\r\n> > > ```python\r\n> > > from tensorflow.python.keras.callbacks import CallbackList\r\n> > > class CustomCallbackList(CallbackList):\r\n> > >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> > >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> > >         if not self.callbacks:\r\n> > >             return\r\n> > >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> > > \r\n> > >         logs = logs or {}\r\n> > >         for callback in self.callbacks:\r\n> > >             batch_hook = getattr(callback, hook_name)\r\n> > >             batch_hook(batch, logs)\r\n> > > \r\n> > > tf.python.keras.callbacks.CallbackList = CustomCallbackList\r\n> > > ```\r\n> > \r\n> > \r\n> > Did this work for you? It's giving me an error.\r\n> > `AttributeError: module 'tensorflow' has no attribute 'python'`\r\n> > Besides, I think this isn't really solving the problem. It may eliminate the error message but the on_train_batch_end will be still taking longer than the learning itself. I have no callbacks and I want to fix this. Nice idea looking at the source code anyway.\r\n> \r\n> If tensorflow is in the environment used, the error you mentioned does not appear. You can check it in [my example](https://github.com/PaperCodeReview/PixPro-TF/blob/master/callback.py#L20).\r\n> Of course, it just removes the message as you said. If you already know that `on_train_batch_end` has heavy operations, it is very utilizable. Otherwise, check your train_step loop whether any problem exists.\r\n\r\nPardon, but what do you mean by 'If tensorflow is in the environment used'?\r\n\r\nAbout the original problem of this thread... I'm getting the error even without any heavy operations in the callbacks. Can a problem inside a train_step loop cause this problem? I looked at the source code and I believe the order of the issue is like below. However, the code seems it's just because of the callbacks' on_train_batch_end.\r\n\r\nhttps://github.com/keras-team/keras/blob/master/keras/engine/training.py#L1118\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L381\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304\r\n\r\nTo be more specific with my issue, I don't get the error if I don't use any callbacks, but the total elapsed time in one epoch is the same. Also, the error appears only at first and doesn't appear anymore afterward.\r\nThank you.", "> > > > Hi.\r\n> > > > This problem occurred when I used custom callbacks that took a long time in <= 2.2.\r\n> > > > I solved this problem by hacking a small part of CallbackList.\r\n> > > > The warning message is due to [this](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304).\r\n> > > > ```python\r\n> > > > class CallbackList(object):\r\n> > > > ..\r\n> > > > ..\r\n> > > >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> > > >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> > > >         if not self.callbacks:\r\n> > > >             return\r\n> > > >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> > > >         if hook == 'begin':\r\n> > > >             self._t_enter_batch = time.time()\r\n> > > >         if hook == 'end':\r\n> > > >             # Batch is ending, calculate batch time.\r\n> > > >             self._delta_t_batch = time.time() - self._t_enter_batch\r\n> > > > \r\n> > > >         logs = logs or {}\r\n> > > >         t_before_callbacks = time.time()\r\n> > > >         for callback in self.callbacks:\r\n> > > >             batch_hook = getattr(callback, hook_name)\r\n> > > >             batch_hook(batch, logs)\r\n> > > >         self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\r\n> > > > \r\n> > > >         delta_t_median = np.median(self._delta_ts[hook_name])\r\n> > > >         if (self._delta_t_batch > 0. and\r\n> > > >               delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\r\n> > > >             # here is the warning message!\r\n> > > >             logging.warning(\r\n> > > >                 'Method (%s) is slow compared '\r\n> > > >                 'to the batch update (%f). Check your callbacks.', hook_name, \r\n> > > >                 delta_t_median)\r\n> > > > ..\r\n> > > > ..\r\n> > > > ```\r\n> > > > \r\n> > > > \r\n> > > > If you don't need to check the time of your callbacks, you can delete the message and assign a new CallbackList to the original CallbackList as below.\r\n> > > > ```python\r\n> > > > from tensorflow.python.keras.callbacks import CallbackList\r\n> > > > class CustomCallbackList(CallbackList):\r\n> > > >     def _call_batch_hook(self, mode, hook, batch, logs=None):\r\n> > > >         \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\r\n> > > >         if not self.callbacks:\r\n> > > >             return\r\n> > > >         hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\r\n> > > > \r\n> > > >         logs = logs or {}\r\n> > > >         for callback in self.callbacks:\r\n> > > >             batch_hook = getattr(callback, hook_name)\r\n> > > >             batch_hook(batch, logs)\r\n> > > > \r\n> > > > tf.python.keras.callbacks.CallbackList = CustomCallbackList\r\n> > > > ```\r\n> > > \r\n> > > \r\n> > > Did this work for you? It's giving me an error.\r\n> > > `AttributeError: module 'tensorflow' has no attribute 'python'`\r\n> > > Besides, I think this isn't really solving the problem. It may eliminate the error message but the on_train_batch_end will be still taking longer than the learning itself. I have no callbacks and I want to fix this. Nice idea looking at the source code anyway.\r\n> > \r\n> > \r\n> > If tensorflow is in the environment used, the error you mentioned does not appear. You can check it in [my example](https://github.com/PaperCodeReview/PixPro-TF/blob/master/callback.py#L20).\r\n> > Of course, it just removes the message as you said. If you already know that `on_train_batch_end` has heavy operations, it is very utilizable. Otherwise, check your train_step loop whether any problem exists.\r\n> \r\n> Pardon, but what do you mean by 'If tensorflow is in the environment used'?\r\n> \r\n> About the original problem of this thread... I'm getting the error even without any heavy operations in the callbacks. Can a problem inside a train_step loop cause this problem? I looked at the source code and I believe the order of the issue is like below. However, the code seems it's just because of the callbacks' on_train_batch_end.\r\n> \r\n> https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L1118\r\n> https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L381\r\n> https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/keras/callbacks.py#L304\r\n> \r\n> To be more specific with my issue, I don't get the error if I don't use any callbacks, but the total elapsed time in one epoch is the same. Also, the error appears only at first and doesn't appear anymore afterward.\r\n> Thank you.\r\n\r\nThe reason I mentioned train_step loop is that operations in train_step may not work properly. As you said, this message due to `delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1` is only printed when you have callbacks. If this message came out only once, it was just a message under that condition. I think the warning was issued because it took some time to initialize, such as `on_epoch_begin` or `on_train_batch_begin`. There are no other problems.", "For me, when I use epochs = 1000 the message appears. If I change to 999 or less, no message.", "@srogatch Hi, could you let me know how did you profile the runtime and create such a nice figure?", "@witignite It was a long time ago, so I already don't remember, but I guess it's a standard Python profiler found with Google search.", "I am receiving this warning when I use a TensorBoard callback as follows:\r\n```\r\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(\r\n      log_dir=profile.path.tensorboard,\r\n      update_freq=\"epoch\"\r\n      )\r\n```\r\n", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Based on this identical discussion in [keras-team/keras](https://github.com/keras-team/keras/issues/5008#issuecomment-733702237), this can be solved by setting `steps_per_execution=N` (where `N` is a high, positive int) in your `model.compile()` call. This will cause you to need to specify `steps_per_epoch` in `model.fit()`, however."]}, {"number": 37875, "title": "r2.2 cherry-pick request: Update tensorboard dependency to 2.2.x", "body": "This change cherry-picks ae408cc2fb55644feb5d6ae8089e0496b97481da\r\nwhich bumps TensorBoard dependencies to 2.2.x.\r\n\r\nTensorBoard release: https://pypi.org/project/tensorboard/2.2.0/\r\n", "comments": []}, {"number": 37874, "title": "Allow tf.image.random_crop to return multiple crops", "body": "It would be nice if there was an option for `tf.image.random_crop` to return more than a single crop at a time.\r\n\r\nIt's possible to reproduce this logic through something like the code below, but I find that it is bottlenecking my tf.data pipeline, and I have to use `tf.image.extract_patches` instead.\r\n\r\n```\r\n@tf.function\r\ndef get_patches(image, num_patches=100, patch_size=16):\r\n    patches = []\r\n    for i in range(num_patches):\r\n        patch = tf.image.random_crop(image, [patch_size, patch_size, 3])\r\n        patches.append(patch)\r\n\r\n    return tf.stack(patches)\r\n```\r\n", "comments": ["OK I WILL LOOK FOR THAT\r\n", "@lminer,\r\nSorry for the delayed response. As per [this comment](https://github.com/tensorflow/tensorflow/pull/37952#pullrequestreview-382996086), this functionality can be achieved by vectorizing **`tf.vectorized_map`**. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 37873, "title": "Move training_op_helpers to framework", "body": "Continuation of #29703 \r\n\r\nSolves #27899\r\n\r\ncc: Original reviewers @alextp @jhseu  \r\ncc: Original authors @vcarpani @jhseu for CLAs", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37873) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37873) for more info**.\n\n<!-- ok -->", "Most the of CI jobs fail with the same error:\r\n```\r\nMultiple OpKernel registrations match NodeDef at the same priority '{{node Variable}}': 'op: \"VariableV2\" device_type: \"CPU\"' and 'op: \"VariableV2\" device_type: \"CPU\"'\r\n```\r\n\r\nDon't think this would be caused by my change. ", "@Squadrick this error means we're violating [C++'s One Definition Rule](https://en.wikipedia.org/wiki/One_Definition_Rule). This is likely happening because two binaries are compiling the same kernel registration. It's likely something to do with the dependency structure of the BUILD files.\r\n\r\nCan you try to fix this? I", "@Squadrick Can you please check @alextp's comments and keep us posted. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@tensorflowbutler Still being worked on. ", "@Squadrick Any update on this PR? and please resolve conflicts Thanks!", "@Squadrick There is a double inclusion with this PR. I can fix it if you give me write access or I can open a new PR based on this and with fixes. @alextp @jhseu, What do you prefer?", "@alextp @gbaned Sorry about the delay; fixed the errors. There was a small change from your last review, pointed out by @spidyDev.", "@Squadrick  I was trying to use this PR (use the header file in addons) . I keep getting undefined symbol error at runtime. I am not sure if this change is complete .\r\n\r\nI just include the header file (#include \"tensorflow/core/framework/training_op_helpers.h)  in my /kernels/xxx_ops.cc file and used the function \"GetInputTensorFromVariable\" \r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.6/dist-packages/tensorflow_addons/custom_ops/optimizers/_optimizer_ops.so: undefined symbol: _ZN10tensorflow7functor11DenseUpdateIN5Eigen9GpuDeviceEdLNS_15DenseUpdateTypeE2EEclERKS3_NS2_9TensorMapINS2_6TensorIdLi1ELi1ElEELi16ENS2_11MakePointerEEENS8_INS9_IKdLi1ELi1ElEELi16ESB_EE", "@spidyDev Have you included the target as a dep in your bazel build file? ", "@Squadrick  No , i have not included any target in my bazel file (https://github.com/tensorflow/addons/pull/1334/files).\r\nBut custom_op_library() would add  libtensorflow_framework as deps by default .\r\n        \"@local_config_tf//:libtensorflow_framework\",\r\n        \"@local_config_tf//:tf_header_lib\",\r\nPlease correct me , if I am missing something here.\r\nAlso, could you suggest what needs to be added as target. You can add a comment on [PR](https://github.com/tensorflow/addons/pull/1334/files) if that is easier. Thanks !!! ", "@Squadrick, not all custom ops are part of TF tree. TF-Addons for example link against TF library and can't include bazel targets from TF since it is used as external binary. As you proposed above before you closed this PR, I prepared another version which builds fine with TF-Addons custom ops. I will be opening PR now.", "@samikama thanks so much for taking this up and fixing this. I'll close this PR. "]}, {"number": 37872, "title": "Keras model for sentiment analysis is not learning anything!", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n\r\n- Google Colab\r\n\r\n**Describe the current behavior**\r\n\r\nI have tried to build a Keras model for sentiment analysis using ``tf.GradientTape`` and ``tf.function`` instead of using keras's ``model.compile`` and ``model.fit``. With the latter, the accuracy starts off at around ``0.50`` and raises to ``0.95`` on the training set and ``0.86`` on the test set. While the former just wanders around ``0.50`` accuracy.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt is expected that the accuracy goes up and not just oscillate around ``0.5``.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nThe full notebook: https://colab.research.google.com/drive/1DESzPRktTkYzZ0nnOo9ofNMPaVg-0UHd\r\n\r\nThe Model:\r\n\r\n```python\r\nclass ANNForSentimentAnalysis(tf.keras.Model):\r\n    def __init__(self, embedding = \"https://tfhub.dev/google/nnlm-en-dim128/1\", name=\"ANNForSentimentAnalysis\", **kwargs):\r\n        super(ANNForSentimentAnalysis, self).__init__(name=name, **kwargs)\r\n        self._layers = [\r\n            hub.KerasLayer(embedding, trainable=True, dtype=tf.string),\r\n            Dense(16, activation='relu'),\r\n            Dense(1, activation='sigmoid')\r\n        ]\r\n        # self._model = Sequential(self._layers)\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        # return self._model(inputs)\r\n        for layer in self._layers:\r\n            inputs = layer(inputs)\r\n        return inputs\r\n\r\ndef train_step(train_data, model, optimizer, loss_func, metric):\r\n    for i, batch in enumerate(train_data):\r\n        x_train, y_train = batch\r\n        with tf.GradientTape() as tape:\r\n            preds = model(x_train)\r\n            loss = loss_func(y_train, preds)\r\n        grads = tape.gradient(loss, model.trainable_variables)\r\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n        metric_eval = metric(y_train, preds)\r\n        sys.stdout.write(f\"\\rStep {i}: [\" + i*\"*\" + f\"]\\tloss: {loss:.4f}\\taccuracy: {metric_eval:.4f}\")\r\n    print(\"\")\r\n\r\ndef accuracy(y_train, y_pred):\r\n    return tf.reduce_mean(tf.cast(tf.cast(y_train, tf.float32) == tf.cast(y_pred > 0.5, tf.float32), tf.float32))\r\n```\r\n\r\n**Training Log**\r\n\r\n```none\r\nStep 29: [*****************************]\tloss: 0.6937\taccuracy: 0.5776\r\nStep 29: [*****************************]\tloss: 0.6667\taccuracy: 0.4945\r\nStep 29: [*****************************]\tloss: 0.6421\taccuracy: 0.4564\r\nStep 29: [*****************************]\tloss: 0.6559\taccuracy: 0.5151\r\nStep 29: [*****************************]\tloss: 0.6455\taccuracy: 0.5210\r\nStep 29: [*****************************]\tloss: 0.6347\taccuracy: 0.5201\r\nStep 29: [*****************************]\tloss: 0.6236\taccuracy: 0.5031\r\nStep 29: [*****************************]\tloss: 0.6119\taccuracy: 0.5059\r\nStep 29: [*****************************]\tloss: 0.5719\taccuracy: 0.5007\r\nStep 29: [*****************************]\tloss: 0.5685\taccuracy: 0.4990\r\nStep 29: [*****************************]\tloss: 0.5626\taccuracy: 0.4990\r\nStep 29: [*****************************]\tloss: 0.5764\taccuracy: 0.5074\r\nStep 29: [*****************************]\tloss: 0.5735\taccuracy: 0.4994\r\nStep 29: [*****************************]\tloss: 0.5386\taccuracy: 0.4995\r\nStep 29: [*****************************]\tloss: 0.5384\taccuracy: 0.4995\r\nStep 29: [*****************************]\tloss: 0.5517\taccuracy: 0.5000\r\nStep 29: [*****************************]\tloss: 0.5328\taccuracy: 0.4997\r\nStep 29: [*****************************]\tloss: 0.5351\taccuracy: 0.4979\r\nStep 29: [*****************************]\tloss: 0.5574\taccuracy: 0.5052\r\nStep 29: [*****************************]\tloss: 0.5166\taccuracy: 0.5010\r\n```\r\n", "comments": ["Tensorflow V2.2\n\nOn Wed, 1 Apr, 2020, 10:47 AM Saduf2019, <notifications@github.com> wrote:\n\n> @tirthasheshpatel <https://github.com/tirthasheshpatel>\n> could you please let us know what version of tensorflow are you facing\n> this issue in\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37872#issuecomment-607037397>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AKJOJRCZOBW3JHEY24E2A63RKLE47ANCNFSM4LSXZL7Q>\n> .\n>\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 37871, "title": "Argmax error on deeplab quantized model with tflite hexagon delegate", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version:  Build from: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 2.0.0, 1.14\r\n- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- Device: Redmi Note 7 Pro (Hexagon 685 DSP),  Android 10.0; MIUI 11\r\n\r\n**Describe the current behavior**\r\nWhen i try to run the official **deeplab model** with quantization aware training in tflite benchmark  using **hexagon** delegate, it fails with the following error:-\r\n\r\n`adb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/frozen_inference_graph_dm05_5.tflite --use_hexagon=true hexagon_profiling=true\r\nadb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)\r\nSTARTING!\r\nMin num runs: [50]\r\nMin runs duration (seconds): [1]\r\nMax runs duration (seconds): [150]\r\nInter-run delay (seconds): [-1]\r\nNum threads: [1]\r\nBenchmark name: []\r\nOutput prefix: []\r\nMin warmup runs: [1]\r\nMin warmup runs duration (seconds): [0.5]\r\nGraph: [/data/local/tmp/frozen_inference_graph_dm05_5.tflite]\r\nInput layers: []\r\nInput shapes: []\r\nInput value ranges: []\r\nInput layer values files: []\r\nUse legacy nnapi : [0]\r\nAllow fp16 : [0]\r\nRequire full delegation : [0]\r\nEnable op profiling: [0]\r\nMax profiling buffer entries: [1024]\r\nCSV File to export profiling data to: []\r\nMax number of delegated partitions : [0]\r\nEnable platform-wide tracing: [0]\r\nUse gpu : [0]\r\nAllow lower precision in gpu : [1]\r\nUse Hexagon : [1]\r\nHexagon lib path : [/data/local/tmp]\r\nHexagon Profiling : [0]\r\nExternal delegate path : []\r\nExternal delegate options : []\r\nUse nnapi : [0]\r\nUse xnnpack : [0]\r\nLoaded model /data/local/tmp/frozen_inference_graph_dm05_5.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nloaded libcdsprpc.so\r\nINFO: Created TensorFlow Lite delegate for Hexagon.\r\nINFO: Hexagon delegate: 71 nodes delegated out of 71 nodes.\r\n\r\nApplied Hexagon delegate, and the model graph will be completely executed w/ the delegate.\r\nThe input model file size (MB): 0.746232\r\nInitialized session in 315.521ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:02 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:02 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:02 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:02 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:03 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:03 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\n----------------\r\nTimestamp: Tue Mar 24 18:13:03 2020\r\n\r\n\r\nLog\r\nhexagon/ops/src/op_argminmax_8_d32.c:119:argminmax_8_d32 out too small\r\nhexagon/src/execute.c:142:execute() failed on node id=37b err=-1\r\nhexagon/src/interface.c:1174:fail in execute_inner()\r\n\r\n----------------\r\nERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH\r\nERROR: Node number 71 (TfLiteHexagonDelegate) failed to invoke.\r\n\r\ncount=7 first=84641 curr=81095 min=79276 max=84641 avg=80591 std=1766\r\n\r\nBenchmarking failed.`\r\n\r\nI removed argmax and model worked with nearest neighbor resizing.The model does not seem to work with int32/int64 argmax as the final layer; even though the operator is supported by [hexagon delegate](https://www.tensorflow.org/lite/performance/hexagon_delegate?hl=fr#faq). The final resize has output shape [513,513], so i tried replacing bilinear resize with  nearest neighbor resizing; but the benchmark still failed . I also verified the setup by  correctly running mobienet_v2 quantized model. Both models with **int32 and int64 argmax** seems to give same error: **argminmax_8_d32 out too small**\r\n\r\nHexagon library: [v1.14](https://storage.cloud.google.com/download.tensorflow.org/tflite/hexagon_nn_skel_v1.14.run)\r\n\r\n**Describe the expected behavior**\r\nThe benchmark model should run the quantized deeplab model without any problems.\r\n\r\n**Other info / logs**\r\nAndroid NDK: 20, Benchmark tool built from latest source with bazel 2.0\r\n\r\nHere are the three models that i've tried :-\r\n[quant_aware_deeplab_dm05_513.zip](https://github.com/tensorflow/tensorflow/files/4378780/quant_aware_deeplab_dm05_513.zip)\r\n\r\n\r\n", "comments": ["What does this error mean: argminmax_8_d32 out too small?\r\nIs there any way by which i can make it work, like changing shape, operator type etc? ", "I have a fix for the issue. Sorry for the trouble. Will be pushed soon.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37871\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37871\">No</a>\n"]}, {"number": 37870, "title": "run_eagerly model option doesn't work in Keras loss", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10, x64\r\n- TensorFlow installed from (source or\r\nbinary): Binary (pip)\r\n- TensorFlow version (use command below): TF 2.2.0 (2.2.0.dev20200323)\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.1 / 7.6\r\n- GPU model and memory: Bug appears on several computers with different GPU\r\n\r\n**Describe the current behavior**\r\n\r\nWhen fitting a Keras model in eager mode, by compiling it with the option run_eagerly=True, the loss is not run eagerly, even though the rest of the model is.\r\n\r\nThis bug does not appear when using  tf.config.experimental_run_functions_eagerly(True) instead of the run_eagerly option to run the model eagerly, in which case the loss is run eagerly.\r\n\r\n**Describe the expected behavior**\r\n\r\nBoth tf.config.experimental_run_functions_eagerly(True) and run_eagerly=True should have the same behaviour when fitting a model: run all of the model, including its loss, eagerly.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\n# Custom loss\r\nclass CustomLoss(keras.losses.Loss):\r\n\tdef call(self, y_true, y_pred):\r\n\t\tprint(tf.executing_eagerly())\r\n\t\t\r\n\t\tx = y_true + y_pred\r\n\t\treturn tf.reduce_mean(x)\r\n\r\nif __name__ == \"__main__\" :\r\n\tdata = np.random.random((16, 1000, 3)).astype(np.float32)\r\n\t\r\n\tinputs = tf.keras.Input(shape=(1000,3))\r\n\toutputs = tf.keras.layers.Dense(3)(inputs)\r\n\tmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\t\r\n\t# tf.config.experimental_run_functions_eagerly(True) # runs custom loss eagerly\r\n\t# model.compile(loss=CustomLoss())\r\n\t\r\n\tmodel.compile(loss=CustomLoss(), run_eagerly = True) # does not run custom loss eagerly\r\n\t\r\n\tmodel.fit(x=data, y=data)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n[logCompileEagerly.txt](https://github.com/tensorflow/tensorflow/files/4375802/logCompileEagerly.txt)\r\n[logExperimentalRunEagerly.txt](https://github.com/tensorflow/tensorflow/files/4375804/logExperimentalRunEagerly.txt)\r\n\r\n", "comments": ["@Lillypucien , to run model eagerly first you need to enable eager execution with `tf.enable_eager_execution()`\r\nComplete code is:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\ntf.enable_eager_execution()\r\n\r\n# Custom loss\r\nclass CustomLoss(keras.losses.Loss):\r\n\tdef call(self, y_true, y_pred):\r\n\t\tprint(tf.executing_eagerly())\r\n\r\n\t\tx = y_true + y_pred\r\n\t\treturn tf.reduce_mean(x)\r\n\r\nif __name__ == \"__main__\" :\r\n\tdata = np.random.random((16, 1000, 3)).astype(np.float32)\r\n\t\r\n\tinputs = tf.keras.Input(shape=(1000,3))\r\n\toutputs = tf.keras.layers.Dense(3)(inputs)\r\n\tmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\t\r\n\t# tf.config.experimental_run_functions_eagerly(True) # runs custom loss eagerly\r\n\t# model.compile(loss=CustomLoss())\r\n\t\r\n\tmodel.compile(loss=CustomLoss(), run_eagerly = True) # does not run custom loss eagerly\r\n\t\r\n\tmodel.fit(x=data, y=data)\r\n```", "Calling tf.enable_eager_execution() indeed does run all of the model eagerly, including its loss, as described in my post (and shown in logExperimentalRunEagerly.txt). \r\n\r\nHowever, tf.Keras models also have an attribute run_eagerly which, when set to True, allows a specific model to be run eagerly, whithout interfering with the rest of the code. Setting this attribute to True used to run the whole model eagerly, including the loss (tested with tf version 2.2.0.dev20200304). However, with the last tf nightly version (2.2.0.dev20200323), the loss is no longer run eagerly when run_eagerly is set to True, even though the rest of the model is, as shown in logCompileEagerly.txt.", "This issue seems to be a direct consequence of issue #37895", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37870\">No</a>\n"]}, {"number": 37869, "title": "Build tensorflow for  c++", "body": "Hello,\r\n\r\nI try to build tensorflow for cpp API. I use a docker to compile and generate a package.\r\n\r\nHere is the docker : \r\n```\r\n`\r\nFROM tensorflow/tensorflow\r\n\r\nRUN apt-get install -y git\r\nRUN DEBIAN_FRONTEND=noninteractive  apt-get install -y tzdata \r\n\r\n# Install object detection api dependencies\r\nRUN apt-get install -y protobuf-compiler python-pil python-lxml python-tk zip unzip && \\\r\n    pip install Cython && \\\r\n    pip install contextlib2 && \\\r\n    pip install jupyter && \\\r\n    pip install matplotlib \r\n\r\n# Get tensorflow source\r\nRUN cd /home/xxxx && git clone https://github.com/tensorflow/tensorflow\r\n\r\n# Install bazel\r\nRUN apt install curl \r\nRUN curl https://bazel.build/bazel-release.pub.gpg | apt-key add -\r\nRUN echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" |  tee /etc/apt/sources.list.d/bazel.list\r\nRUN apt update && apt install -y  bazel && apt install -y  bazel-1.0.0\r\nRUN apt install bazel-2.0.0\r\nRUN pip install future\r\n\r\nRUN cd /home/xxxx/tensorflow/ && /home/xxxx/tensorflow/ && bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both //tensorflow:libtensorflow_cc.so \\\r\n                //tensorflow:libtensorflow_framework.so \\\r\n                //tensorflow:install_headers\r\n\r\n`\r\n\r\n```\r\nI try with and without HW optimisation:\r\nWithout:\r\n```\r\nbazel build -c opt //tensorflow:libtensorflow_cc.so \\\r\n                //tensorflow:libtensorflow_framework.so \\\r\n                //tensorflow:install_headers\r\n\r\n```\r\n\r\nWith:\r\n```\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both //tensorflow:libtensorflow_cc.so \\\r\n                //tensorflow:libtensorflow_framework.so \\\r\n                //tensorflow:install_headers\"\r\n```\r\n\r\nWhen I use the optimize or the standard package the execution time is the same. \r\nWhen I use the optimize version the following message dissapear:   \r\n\r\n```\r\n2020-03-24 `14:48:16.411418: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\n\r\n```\r\nThe message dissapears but the excecution time is equivalent ~200ms. \r\n\r\n\r\n\r\n", "comments": ["That message is just an information log, not an error, does not have any effect.", "@xav12358, as @mihaimaruseac mentioned that message is just an information log its not an error. Can we close this issue. Thanks ", "@xav12358, Please update for the above comment. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37869\">No</a>\n", "> That message is just an information log, not an error, does not have any effect.\r\n\r\nc++  windows tensorflow.dll (1.8) \r\nit can run succ on release, but on debug model , it can not run succ\r\n[https://github.com/fo40225/tensorflow-windows-wheel/issues/145](url)\r\n\r\ncan you tell me how to solve this when on debug model?"]}, {"number": 37868, "title": "Train time multi crop augmentation", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@colt18\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n\r\nplease share the error log,code for which this feature implementation is required\r\nWe ask for this, because it is really difficult to help without that information. Thanks!\r\n", "@colt18\r\nPlease update on the above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 37867, "title": "tables_initializer", "body": "`sess_id.run(graph_id.get_operation_by_name(\"MyGraphID/init_all_tables\")) `\r\n\r\nI did not find a way to achieve this in C ++. what should I do\uff1f", "comments": ["@tianhongbao \r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "I am closing the issue as this issue not related to bug/performance.Please, ask this question in StackOverflow. Thanks!"]}, {"number": 37866, "title": "unable to generate train.record file", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@0unstoppable,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "@0unstoppable,\r\nAny updates regarding the reproducible code? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37865, "title": "Migrate TF1 to TF2", "body": "Hi, Im newbie on tensorflow. \r\nHow to use embedding_rnn_seq2seq on tensorflow v2? On tensorflow v1, it is in contrib.legacy_seq2seq class.", "comments": ["@Khanifsaleh,\r\nFollow the instructions mentioned in the [Tensorflow](https://www.tensorflow.org/guide/migrate) guide to migrate from tf1 to tf2", "Yes, I have read the documentation. I have tried implementing tf_upgrade_v2, but the tf.contrib.legcy_seq2seq.embedding_rnn_seq2seq has not changed. I also read [contrib_sunset](https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md) which states that legacy_seq2seq was replaced by seq2seq on the tensorflow_addons module. But that doesn't work, it works for the sequence_loss method which is in v1, that method is in the same module as embedding_rnn_seq2seq.", "See basic decoder and encoder [example](https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq) usages for TF1 and TF2\r\nAlso see [tfa.seq2seq](https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq) module.\r\nYou may also try this question on [tensorflow/addons](https://github.com/tensorflow/addons/issues) repo.  Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "was this figured out? I am stuck on same problem", "@ammeitzler not yet. I give up. ", "lol ugh. im trying still"]}, {"number": 37864, "title": "protobuf.bzl outdated making build with TF_SYSTEM_LIBS=com_google_protobuf fail", "body": "**Describe the current behavior**\r\n\r\nWhen using `TF_SYSTEM_LIBS=com_google_protobuf` to configure TensorFlow 2.1 the build fails with \r\n\r\n```\r\nERROR: /dev/shm/s3248973-EasyBuild/TensorFlow/2.1.0/foss-2019b-Python-3.7.4/TensorFlow/tensorflow-2.1.0/tensorflow/core/profiler/BUILD:51:1: in proto_gen rule //tensorflow/core/profiler:profiler_service_proto_py_genproto: \r\nTraceback (most recent call last):\r\n        File \"/dev/shm/s3248973-EasyBuild/TensorFlow/2.1.0/foss-2019b-Python-3.7.4/TensorFlow/tensorflow-2.1.0/tensorflow/core/profiler/BUILD\", line 51\r\n                proto_gen(name = 'profiler_service_proto_py_genproto')\r\n        File \"/tmp/easybuild-tmp/eb-NQjKjm/tmp8LJdGE-bazel-build/external/com_google_protobuf/protobuf.bzl\", line 110, in _proto_gen_impl\r\n                ctx.actions.run(inputs = inputs, outputs = ctx.out..., <4 more arguments>)\r\nFound tool(s) 'bazel-out/k8-opt/bin/external/grpc/grpc_python_plugin' in inputs. A tool is an input with executable=True set. All tools should be passed using the 'tools' argument instead of 'inputs' in order to make their runfiles availa\r\nble to the action. This safety check will not be performed once the action is modified to take a 'tools' argument. To temporarily disable this check, set --incompatible_no_support_tools_in_action_inputs=false.\r\n```\r\n\r\nReason is seemingly a very outdated protobuf.bzl which is used with system_libs. It might be enough to update it from the current protobuf repo. Maybe even download that single file only when using system libs", "comments": ["@Flamefire \r\n please share simple stand alone code before which this error was encountered", "Sure:\r\n\r\n- Compile and install protobuf into /usr (or install system package where available)\r\n- `TF_SYSTEM_LIBS=com_google_protobuf ./configure`\r\n- `bazel build //tensorflow/tools/pip_package:build_pip_package`", "@Flamefire\r\ncan you please let us know what OS are you facing this issue in", "Linux Mint 19.1, but this is a Bazel (code) issue, not dependent on the system. The error is\r\n\r\n> Found tool(s) 'bazel-out/k8-opt/bin/external/grpc/grpc_python_plugin' in inputs.\r\n\r\nThe code mentioned is:\r\nhttps://github.com/tensorflow/tensorflow/blob/6609461732729e9e60567b13d5345bc19fead5d1/third_party/systemlibs/protobuf.bzl#L112-L119\r\n\r\nNo mention of a \"tools\" parameter, only \"inputs\". Upstream code has \"tools\": https://github.com/protocolbuffers/protobuf/blob/dec4939439d9ca2adf2bb14edccf876c2587faf2/protobuf.bzl#L141-L149\r\n\r\nHence my suggestion to update it in the initial post.", "This seems to be fixed in 2.3.0 by https://github.com/tensorflow/tensorflow/commit/9cee90ac957f2575da2415242c5c127c0dd61430", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37864\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37864\">No</a>\n"]}, {"number": 37863, "title": "Win10: ImportError: DLL load failed: The specified module could not be found.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7 (Anaconda 2019.10, conda 4.8.3)\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA, not NVIDIA\r\n- GPU model and memory:Intel(R) HD Graphics 620\r\n\r\n\r\n\r\n**Describe the problem**\r\nCannot import tensorflow\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI created Anaconda environment using Anaconda Navigator. Environment name is tensorflow_env. In Anaconda Prompt, I first checked pip version\r\n>> pip -V\r\n\r\nwhich is 20 (greater than requirement for tensorflow), and version for Python, which falls in the required versions. I then activated the environment\r\n>> activate tensorflow_env\r\n\r\nwhich worked: the environment name appeared in the command line. Then, I did \r\n>> pip install tensorflow\r\n\r\nInstallation seemed to work just fine. Then I checked if the package was added to the environment \r\n>> conda list\r\n\r\nTensorflow is visible in this Anaconda environment. Then, I switched to python \r\n>> python\r\n\r\nand try to import tensorflow\r\n>> import tensorflow as tf\r\n\r\nI get error, copypasted below.\r\n\r\n\r\n**Any other info / logs**\r\n(tensorflow_env) C:\\DA_AI\\3_ML>python\r\n\r\nPython 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\jugi\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "What is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!", "> What is make/model of your cpu?\r\n> I suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\n> Make sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n> .Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows)\r\n> \r\n> Please, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!\r\n\r\nThanks for your response. My CPU is Intel Core i5-7200u. According to Intel's specs ([here](https://ark.intel.com/content/www/us/en/ark/products/95443/intel-core-i5-7200u-processor-3m-cache-up-to-3-10-ghz.html)), it should support AVX.\r\n\r\nCPU is **64bit**. Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 **64 bit** (AMD64)] :: Anaconda, Inc. on **win32**. Do you think the bitness of Anaconda is causing this? No: apparently ([here](https://stackoverflow.com/questions/29745275/entry-message-msc-v-1500-64-bit-amd64-on-win32)) this is as it should be.\r\n\r\nI didn't install from the source, instead I installed according to the steps mentioned in my original question.\r\n>> pip install tensorflow\r\n\r\nIf I understand correctly, installation from source requires Bazel, which I did not use. Also, do I need Microsoft Visual C++ when installing pip package, or only if I install from source? Apparently, ([here](https://www.tensorflow.org/install/pip)), I need in as part of the system requirements. Referring to [this](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-581091080), I try again with Visual C++.\r\n\r\nAfter installing Visual C++, importing tensorflow seems to work! At least, the errorcode is different. Now I get\r\n>W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n\r\nHowever, this seems to address missing CUDA installation, which I am missing anyways because of not using CUDA/NVIDIA/GPU-setup, instead am using Intel/CPU-setup. Is this expected behaviour, when I have done the CPU installation?", "I also have same kind of error. I was following some tutorials which he was using the older version.\r\nPython 3.6.6\r\nTensorflow-gpu 1.2.0\r\nCUDA v.8\r\ncuDNN v5.1\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.1\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.1\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.1\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.1\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.1\\helpers\\pydev\\_pydev_bundle\\pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\BMSSA\\PycharmProjects\\Tensorflow_GPU_programming\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nSo this is basically the import error\r\nAny recommendations or previous commits?", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37863\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37863\">No</a>\n"]}, {"number": 37862, "title": "Learning Rate scheduler with custom training using \"tf.GradientTape\"", "body": "Hello, I am using a learning rate scheduler to reduce the learning rate which is defined in the function as follows:\r\n\r\n```\r\ndef scheduler(epoch):\r\n    learning_rate = 0.0012\r\n    if epoch >= 9 and epoch == 19:\r\n        return learning_rate / 10\r\n    elif epoch > 19:\r\n        return learning_rate / 100\r\n    else:\r\n        return learning_rate\r\n```\r\n\r\nHow can I use this defined scheduler() function with custom training loop using \"tf.GradientTape\"?\r\n\r\nThe way I know is to use the scheduler as a callback:\r\n\r\n```\r\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)\r\n\r\nmodel.fit(\r\n\tx = data, y = labels,\r\n\tepochs=100, callbacks=[callback],\r\n\tvalidation_data=(val_data, val_labels))\r\n\r\n```\r\n\r\nThanks", "comments": ["Hi,\r\n\r\nIn TF 2.1, I would advise you to write your custom learning rate scheduler as a `tf.keras.optimizers.schedules.LearningRateSchedule` instance and pass it as `learning_rate` argument to your model's optimizer - this way you do not have to worry about it further.\r\n\r\nIn TF 2.2 (currently in RC1), this issue will be fixed by implementing a `tf.keras.Model` subclass and overriding its `train_step` method - this way you can still use `model.fit` and pass callbacks, although you are using a custom train step behaviour.\r\n\r\nIn your specific case, a hack can be to call `model.fit` multiple times, specifying both `epochs` and `initial_epoch` to ensure continuity, and changing manually the learning rate of `model.optimizer` in-between.\r\n\r\nI hope this helps :)", "If I use the following code:\r\n\r\n```\r\nboundaries = [9, 19]\r\nvalues = [0.1, 0.01, 0.001]\r\n\r\nlearning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\r\noptimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_fn)\r\n\r\n```\r\nAnd then during training using \"tf.GradientTape\", if I want to get the current learning rate being used by the optimizer, I am using the following code:\r\n\r\n`optimizer.learning_rate.numpy()`\r\n\r\nwhich throws the error:\r\nAttributeError: 'PiecewiseConstantDecay' object has no attribute 'numpy'\r\n\r\nHow can I get the current learning rate used by the optimizer?\r\n\r\nThanks!", "Here, `optimizer.learning_rate` it the `PiecewiseConstantDecay` you instantiated, thus to get its value at a given step, you should call it with the step number - _e.g._ to know the value at step 1000, `optimizer.learning_rate(1000)`. Note that you can gather the current step value from the optimizer itself: `optimizer.iterations`; thus you can run `optimizer.learning_rate(optimizer.iterations)`.\r\n\r\nNote that this is only valid when the learning rate is indeed a Scheduler instance :)", "Thanks!", "You are welcome!", "> tf.keras.optimizers.schedules.LearningRateSchedule\r\n\r\nHi, and how would I use that class? The documentation isn't saying much:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule\r\nIs it working as [here](https://www.tensorflow.org/tensorboard/scalars_and_keras)?\r\n\r\nand regarding the mentioned `PiecewiseConstantDecay`, how do I update the step? I want it to get updated every epoch, not every each iteration, is it possible?", "I'm trying to run this line optimizer.learning_rate(optimizer.iterations) but it is not  callable ", "You can call `optimizer._decayed_lr(tf.float32)` which should return the current learning rate"]}, {"number": 37861, "title": "Debundled protobuf broken", "body": "\r\n**System information** \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0 but most likely all affected\r\n- Bazel version (if compiling from source): 0.26.1\r\n\r\n**Describe the current behavior**\r\n\r\nUsing TF_SYSTEM_LIBS=com_google_protobuf leads to \r\n\r\n> In file included from bazel-out/k8-opt/bin/tensorflow/compiler/xla/xla_data.pb.cc:4:\r\nbazel-out/k8-opt/bin/tensorflow/compiler/xla/xla_data.pb.h:10:10: fatal error: google/protobuf/port_def.inc: No such file or directory\r\n #include <google/protobuf/port_def.inc>\r\n\r\nFull compiler invocation:\r\n\r\n> /sw/installed/OpenMPI/3.1.3-GCC-8.2.0-2.31.1/bin/mpicc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/xla_data_proto/xla_data.pb.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/xla_data_proto/xla_data.pb.pic.o' -fPIC -iquote . -iquote bazel-out/k8-opt/bin -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -O2 -ftree-vectorize '-march=native' -fno-math-errno -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c bazel-out/k8-opt/bin/tensorflow/compiler/xla/xla_data.pb.cc -o bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/xla_data_proto/xla_data.pb.pic.o\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nUsing TF_SYSTEM_LIBS=com_google_protobuf works\r\n\r\n**Standalone code to reproduce the issue** \r\nConfigure with  TF_SYSTEM_LIBS=com_google_protobuf then build\r\n\r\n**Other info / logs**\r\nThere are 2 issues with that:\r\n\r\n1. E.g. for 2.0.0 the directory containing the symlinked headers is passed as `-iquote bazel-out/k8-opt/bin/external/com_google_protobuf` but incuded with ` #include <google/protobuf/port_def.inc>` which by definition of `-iquote` will not be found\r\n2. After manually changing the `-iquote` to `-I` it shows that not all headers are copied. The list for 2.0.0 is at https://github.com/tensorflow/tensorflow/blob/v2.0.0/third_party/systemlibs/protobuf.BUILD#L15-L43 and is missing `port_undef.inc` hence the command fails with \r\n> In file included from bazel-out/k8-opt/bin/tensorflow/compiler/xla/xla_data.pb.cc:4:\r\nbazel-out/k8-opt/bin/tensorflow/compiler/xla/xla_data.pb.h:22:10: fatal error: google/protobuf/port_undef.inc: No such file or directory\r\n #include <google/protobuf/port_undef.inc>\r\n\r\nA possible solution was suggested in https://github.com/tensorflow/tensorflow/issues/37835: Allow usage of explicit prefixes and do NOT try to copy/symlink headers (or at least test that)", "comments": ["Sorry for the accidental locking", "@perfinion PTAL", "@perfinion As you introduced that debundled protobuf in https://github.com/tensorflow/tensorflow/pull/24004:\r\n\r\nAny reason for copying the headers at all? Could we simply not do that which avoids the problem of incomplete list of headers and include style. Also: How did you assemble the list of headers? That's not everything from the installed `include/google/protobuf` folder, so how did you choose?", "Pinging this again as this occurred in 2.3.0 now while I was able to get it to work in 2.1.0. Likely 2.2.0 is broken too with a commit made by @cbalint13 in #34792: https://github.com/tensorflow/tensorflow/commit/610a78b98569e2908809645626b4bd6afd2a22d8 where port_def.inc was removed from the list of headers to copy.\r\n\r\nMay I again ask why the copying of the headers is required at all?\r\n\r\nMy current approach for supporting existing installations of some dependencies is to use `--action_env` setting up a CPATH with the required include folders (e.g. `/opt/foo-1.2.3/include`)\r\n\r\nHowever in 2.3.0 this seemingly fails for some protobuf compilation:\r\n```\r\nERROR: /tmp/s3248973-EasyBuild/TensorFlow/2.3.0/fosscuda-2019b-Python-3.7.4/TensorFlow/tensorflow-2.3.0/tensorflow/stream_executor/BUILD:425:17: C++ compilation of rule '//tensorflow/stream_executor:dnn_proto_cc_impl' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /tmp/easybuild-tmp/eb-LzGAtl/tmptEWw5S-bazel-build/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=<...> \\\r\n    PATH=<...> \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/_objs/dnn_proto_cc_impl/dnn.pb.pic.d '-frandom-seed=bazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/_objs/dnn_proto_cc_impl/dnn.pb.pic.o' -iquote . -iquote bazel-out/ppc-opt-exec-50AE0418/bin -iquote external/com_google_protobuf -iquote bazel-out/ppc-opt-exec-50AE0418/bin/external/com_google_protobuf -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 -g0 '-std=c++14' -Wno-unknown-warning-option -Wno-unused-but-set-variable -Wno-sign-compare -c bazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/dnn.pb.cc -o bazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/_objs/dnn_proto_cc_impl/dnn.pb.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from bazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/dnn.pb.cc:4:\r\nbazel-out/ppc-opt-exec-50AE0418/bin/tensorflow/stream_executor/dnn.pb.h:10:10: fatal error: google/protobuf/port_def.inc: No such file or directory\r\n #include <google/protobuf/port_def.inc>\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n```\r\n\r\nIt might be the `tf_proto_library` rule and then likely the `tf_proto_library_cc` but I find that bazel code hard to follow and understand. Again note the use of the (to my understanding) wrong `-iquote` so a file included as `<google/protobuf/port_def.inc>` cannot possibly be found. Also note the lack of `CPATH` although I gave that as an action_env to bazel and other invocations show it which is usually a missing `use_default_shell_env = True,` but I don't know where it would need to be put here as I can't tell the exact bazel rule invoked for this. It seems it is ultimately calling `native.cc_library` but I don't know why that would discard the action_env CPATH I've set\r\n\r\nAnd maybe solution: If that list of headers is required, isn't it possible to just glob the folder?", "FTR:\r\n- Replacing `exec_tools` by  `tools` solves the include issue: #43156\r\n- Symlinking the `*.proto` files only solves the include issue (most symlinked includes weren't used anyway): #43153\r\n\r\nWith those 2 PRs I can build TF with custom protobuf\r\n", "@Flamefire \r\nAs we have the latest stable version 2.6.0, Can you try building TF 2.6.0 and let us know if the issue still persists?", "Yes fixed after the mentioned PRs have been merged", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37861\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37861\">No</a>\n"]}, {"number": 37860, "title": "freezing tensorflow model", "body": "The model I use is meta graph and win 10 ver 1903\r\nMy model clone :\r\nhttps://github.com/ZJULearning/pixel_link\r\n\r\nI am trying to freeze a flow pattern\r\n\r\nIn tenorflow, training from scratch is created after 4 files:\r\n\r\n1. model.ckpt-38055.data-00000-of-00001\r\n2. model.ckpt-38055.index\r\n3. model.ckpt-38055.meta\r\n4. checkpoint\r\n\r\nI would like to convert them (or only the needed ones) into one file  graph.pb\r\n\r\nI use src :\r\n\r\n> `import tensorflow as tf\r\n> \r\n> meta_path = 'model.ckpt-38055.meta'  # Your .meta file\r\n> \r\n> \r\n> config = tf.ConfigProto()\r\n> \r\n> \r\n> with tf.Session(config=config) as sess:\r\n> \r\n>     with tf.device(\"/cpu:0\"): \r\n> \r\n>     # Restore the graph\r\n>         saver = tf.train.import_meta_graph(meta_path)\r\n> \r\n>         # Load weights\r\n>         saver.restore(sess, tf.train.latest_checkpoint('./'))\r\n>         # saver.restore(sess, \"model.ckpt-38055\")\r\n> \r\n>         output_node_names = [n.name for n in tf.get_default_graph().as_graph_def().node]\r\n>         # output_node_names = \"reconstruction_layer\"\r\n> \r\n>         # Freeze the graph\r\n>         frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n>             sess,\r\n>             sess.graph_def,\r\n>             output_node_names)\r\n> \r\n>         # Save the frozen graph\r\n>         with open('output_graph.pb', 'wb') as f:\r\n>             f.write(frozen_graph_def.SerializeToString())`\r\n\r\n I encountered an error :\r\n\r\n> 2020-03-24 15:00:30.107728: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\nTraceback (most recent call last):\r\n  File \"freeze_graph.py\", line 5, in <module>\r\n    sess, sess.graph_def, [\"out\"])\r\n  File \"C:\\Users\\Lerror\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py\", line 227, in convert_variables_to_constants\r\n    inference_graph = extract_sub_graph(input_graph_def, output_node_names)\r\n  File \"C:\\Users\\Lerror\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py\", line 171, in extract_sub_graph\r\n    _assert_nodes_are_present(name_to_node, dest_nodes)\r\n  File \"C:\\Users\\Lerror\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py\", line 131, in _assert_nodes_are_present\r\n    assert d in name_to_node, \"%s is not in graph\" % d\r\nAssertionError: out is not in graph\r\n\r\n\r\nHope you can help me\r\n\r\nthank you", "comments": ["@DucLong06 \r\nplease update tensorflow version and simple stand alone code for us to replicate the issue faced.\r\nAs per error please refer to similar [issues](https://github.com/tensorflow/tensorflow/issues/19455), [link1](https://github.com/tensorflow/tensorflow/issues/15783) , [link2](https://github.com/tensorflow/tensorflow/issues/15426) [link3](https://github.com/tensorflow/tensorflow/issues/16293)\r\n\r\n#37139 #35703 ", "Hi @Saduf2019 \r\nI think I have to downgrade tensorflow version ?\r\nSo can you tell me which version is appropriate ?", "@DucLong06\r\nplease update tensorflow version and simple stand alone code for us to replicate the issue faced.", "I tried versions> 1.1 <1.8 and encountered the same error", "@DucLong06 \r\nplease confirm if you faced the error with 1.15, if you haven tried please try and let us know", "@DucLong06 \r\nplease update on the above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 37859, "title": "tf.keras.losses.SparseCategoricalCrossentropy  Documentation Issue", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nOn the third line of the second code box, origin probability is [.9, .05, .05], [.5, .89, .6], [.05, .01, .94], it should be [.9, .05, .05], [.05, .89, .06], [.05, .01, .94]. ", "comments": ["@UesugiErii , The example is removed in the [nightly version](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy?version=nightly). I think this will solve your issue."]}]