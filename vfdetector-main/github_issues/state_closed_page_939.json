[{"number": 25268, "title": "Cherrypick fixes related to estimator dependency", "body": "", "comments": []}, {"number": 25267, "title": "<release 13>-<rc1> cherry-pick request: Removing spurious warning in tf.data.", "body": "[tf.data] Avoid printing a spurious warning for `tf.compat.v1.data.make_one_shot_iterator` and `tf.compat.v1.data.make_initializable_iterator`.\r\n\r\nPiperOrigin-RevId: 231281365", "comments": ["I apologize, but this breaks compatibility with distribution strategy, so I will not be able to include it in 1.13. I'm reverting in #25497"]}, {"number": 25266, "title": "Fix TransposeConv op kernel in TensorFlow Lite", "body": "Use the proper filter height/width dimensions.\r\n\r\nPiperOrigin-RevId: 229294726", "comments": []}, {"number": 25265, "title": "Broken Link", "body": "fix broken link to post training quantization doc", "comments": ["Nagging Reviewer @MarkDaoust: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 25264, "title": "Broken link", "body": "fix broken link to post quant info", "comments": ["Whoopsi"]}, {"number": 25263, "title": "tf.data performance slow when returning many tensors from a dataset op", "body": "\r\n**System information**\r\n- Linux Ubuntu 16.04\r\n- i7-7800X CPU @ 3.50GHz x 8\r\n- Tensorflow binary, r1.12\r\n- TensorFlow version (use command below): ('v1.12.0-0-ga6d8ffae09', '1.12.0')\r\n- Python version: Python 2.7.12\r\n\r\n**Describe the current behavior**\r\n\r\nWe load tabular data from a database to a training script, and this tabular data contains quite a many columns (30 - 40), most of them scalar. We observe performance that seems slow, given the simplicity of the data. To demonstrate and isolate the performance bottleneck, I created a simple C++ dataset op that returns just a specified number of int scalar tensors, and we get only about 1000 - 1500 entries / second  (calls of get_next) with this fake data.  These overheads lead to high CPU utilization and limit the throughput of our training.\r\n\r\nMy code with more results can be seen here:\r\nhttps://github.com/akyrola/tf_data_repro\r\n\r\nThe key code is simply:\r\n```\r\n        for (int i = 0; i < dataset()->n_; ++i) {\r\n                    tensorflow::Tensor tensor(ctx->allocator({}), tensorflow::DT_INT32, shape);\r\n                    tensor.scalar<tensorflow::int32>()() = row;\r\n                    out_tensors->emplace_back(std::move(tensor));\r\n                }\r\n```\r\n\r\nThe C++ op is compiled with -O2 optimizations.\r\n\r\nI am suspecting the overhead is due to the tensor allocations, because the throughput changes almost linearly with the number of tensors (when n sufficiently large). I am looking for advice if using different allocator would help, for example.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect at least 10x better performance on fake data generation.\r\n\r\n**Code to reproduce the issue**\r\n\r\nSee code checked here for a benchmark:\r\nhttps://github.com/akyrola/tf_data_repro\r\n\r\n**Other info / logs**\r\nBenchmark results (approximate), where n = number of scalar tensors:\r\n- n=1:   8300 rows/sec\r\n- n=2:   6800 rows/sec\r\n- n=5:   4800 rows/sec\r\n- n=10:  3200 rows/sec\r\n- n=20:  2000 rows/sec\r\n- n=40:  1100 rows/sec\r\n\r\n", "comments": ["Hey Aapo,\r\n\r\nTLDR: You are not benchmarking TensorFlow's ability to allocate tensors, your are benchmarking TensorFlow's ability to execute a graph with n outputs.\r\n\r\nIf you would like to measure the performance of the inner loop of your dummy dataset, try the following:\r\n\r\n```\r\ndef benchmark(n):\r\n    num_rows = 1000 * 1000\r\n    dataset = dummy_dataset.DummyDataset(n).skip(num_rows - 1)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    get_next = iterator.get_next()\r\n\r\n    with tf.Session() as sess:\r\n      start_time = time.time()\r\n      row = sess.run(get_next)\r\n\r\n    print(row)\r\n    print(\"Finished (n={}): read {} rows, {} rows / sec\".format(\r\n        n, num_rows, num_rows / (time.time() - start_time)))\r\n```\r\n\r\nUsing the `skip` transformation will result in running the `GetNext` call of your dummy dataset in a tight loop `num_rows` number of times.\r\n\r\nWhen I do this on my workstation, I see throughput upwards of 300K rows/sec (compared to 1K rows/sec reported by your benchmarking code).\r\n\r\nEDIT: The original version of my benchmarking code had a measurement error. This has been fixed.", "Hi Jiri,\r\n\r\nthanks for your reply, this was indeed very clear way to isolate the overhead to the tensorflow graph execution. I guess we need to reduce the number of tensors we use and also limit the depth of the tf.data pipeline as each processing step adds a lot of overhead due to the number of tensors involved.", "Hi Aapo, note that you do not need to reduce the tf.data input pipeline depth as it does not contribute to the graph size -- fetching of an element from an arbitrary tf.data input pipeline corresponds to executing a single graph node.\r\n\r\nPerhaps you could batch your data to amortize the cost of executing the graph?"]}, {"number": 25262, "title": "Usage of tf_stack.extract_stack in registry.py breaks TensorFlow R client", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 29\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): nightly\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nHi,\r\n\r\nthis usage of `tf_stack` in registry.py\r\n\r\n```\r\nstack = tf_stack.extract_stack()\r\nuser_function = stack[2]\r\n```\r\n\r\nbreaks the TensorFlow for R client, because at that point, when called from R `stack` is of length 2, with both elements being of length 6.\r\n\r\nThis is analogous to the recently fixed https://github.com/tensorflow/tensorflow/issues/25067\r\n(thank you @jtkeeling)\r\n\r\nIt would be awesome if this could still be fixed for the 1.13 release, as I'm aware of no workaround and we have users that want to register a custom gradient.\r\n\r\nMany thanks!\r\n\r\n\r\n\r\n", "comments": ["Yes, this is entirely analogous to #25067. I've authored a fix and sent for review.", "Great thank you for the quick fix!!!", "This is fixed right (cf other issue)?", "@martinwicke This is another piece of code that uses tf_stack. I've sent you another change that fixes this one.", "Thanks! We'll wait for that to close."]}, {"number": 25261, "title": "Replace deprecated usage of np.asscalar with np.ndarray.item()", "body": "[`numpy.asscalar()` is deprecated since version 1.16](https://github.com/numpy/numpy/blob/master/numpy/lib/type_check.py#L519-L548).\r\n\r\nThis PR replaces its usage with [`numpy.ndarray.item()`](https://www.numpy.org/devdocs/reference/generated/numpy.ndarray.item.html)\r\n\r\nReopening #25169\r\n\r\nCloses #25225", "comments": ["Handing back to @alextp as I lack context on this.", "Revan, you were the one who found the issue with the original PR. Can you\nmake sure this one doesn't have the same issue?\n\n(otherwise you have as much context as I do)\n\nOn Mon, Jan 28, 2019 at 3:14 PM Revan Sopher <notifications@github.com>\nwrote:\n\n> Handing back to @alextp <https://github.com/alextp> as I lack context on\n> this.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/25261#issuecomment-458339673>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxQBbaxRFdGJyZtXekHyRZFfcBKKTks5vH4RlgaJpZM4aWka_>\n> .\n>\n\n\n-- \n - Alex\n", "I don't know why, but `tensorflow/python/kernel_tests:control_flow_ops_py_test` which was broken (and caught) in the presubmits for the last PR (https://source.cloud.google.com/results/invocations/4d268ca3-db35-4b0b-aec9-291ef137cf62/targets/%2F%2Ftensorflow%2Ftools%2Fci_build%2Fbuilds:gen_win_out/log) works on this one (https://source.cloud.google.com/results/invocations/1eb34f0a-9b01-4914-a89a-af5a58d91000/targets/%2F%2Ftensorflow%2Ftools%2Fci_build%2Fbuilds:gen_win_out/log) so LGTM I guess."]}, {"number": 25260, "title": "TypeError: Failed to convert object of type <class 'tensorlayer.layers.PReluLayer'> to Tensor. Contents:   Last layer is: PReluLayer. Consider casting elements to a supported type.", "body": "I am using tensorflow to construct CNN model. However, I got two errors when using tf.image.resize_images function:\r\n\r\n1st error: TypeError: Expected binary or unicode string, got <tensorlayer.layers.PReluLayer object at 0x0000000031962D68>\r\n\r\n2nd error: TypeError: Failed to convert object of type <class 'tensorlayer.layers.PReluLayer'> to Tensor. Contents:   Last layer is: PReluLayer. Consider casting elements to a supported type.\r\n\r\n\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: 9.0.167 (CUDA)\r\n- GPU model and memory: P6000\r\n\r\n**Describe the current behavior**\r\nThe part of the code is:\r\n\r\n'conv4 = Conv2d(conv3_bn_relu_pool, 256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, name='conv4')\r\n        conv4_bn = BatchNormLayer(conv4, act=tf.identity, is_train=is_train, gamma_init=g_init, name='conv4_bn')\r\n        conv4_bn_relu = PReluLayer(conv4_bn, name='conv4_bn_relu')\r\n    \r\n    ################################Deconvolution (up-sample + Conv)#########################\r\n        \r\n        deconv1_upsample = tf.image.resize_images(conv4_bn_relu, size=[64, 64], method=1)'\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Hi ymodak,\n\n\nThanks for your help. The problem has been solved and I have closed the issue.\n\n\n________________________________\nFrom: ymodak <notifications@github.com>\nSent: 28 January 2019 19:35:29\nTo: tensorflow/tensorflow\nCc: Di Ma; Author\nSubject: Re: [tensorflow/tensorflow] TypeError: Failed to convert object of type <class 'tensorlayer.layers.PReluLayer'> to Tensor. Contents: Last layer is: PReluLayer. Consider casting elements to a supported type. (#25260)\n\n\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/25260#issuecomment-458269324>, or mute the thread<https://github.com/notifications/unsubscribe-auth/Aj8nNORlP5oHN6d7A8X7xISMG9BQ132tks5vH1EAgaJpZM4aWZzb>.\n", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 25259, "title": "Keras & Estimator: 'MeanMetricWrapper' object has no attribute '__name__'", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary, using pip\r\n- TensorFlow version (use command below): b'v1.12.0-4728-ga8e5c41c5b' 1.13.0-rc0\r\n- Python version: 3.6.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nBuid a simple Sequencial model using Keras. It works well with Keras `model.fit()`. Now converting this model to be used with estimator` tf.keras.estimator.model_to_estimator(keras_model=model)`. Then using `train()` then the code crashed with:\r\n 'MeanMetricWrapper' object has no attribute '__name__'\r\n\r\n**Describe the expected behavior**\r\nThe same code was runing with tf 1.12 and I could train the model using estimator\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe code can be find in the following notebook:\r\nhttps://github.com/tarrade/proj_DL_models_and_pipelines_with_GCP/blob/master/notebook/08_Example_mnist_keras_estimator_tf_1_13.ipynb\r\n\r\n```\r\ndef baseline_model():\r\n    # create model\r\n    model = tf.keras.Sequential()\r\n \r\n    # hidden layer\r\n    model.add(tf.keras.layers.Dense(dim_input, \r\n                    input_dim=dim_input, \r\n                    kernel_initializer=tf.keras.initializers.he_normal(),\r\n                    bias_initializer=tf.keras.initializers.Zeros(),\r\n                    activation='relu'))\r\n    # last layer\r\n    model.add(tf.keras.layers.Dense(num_classes, \r\n                    kernel_initializer=tf.keras.initializers.he_normal(),\r\n                    bias_initializer=tf.keras.initializers.Zeros(),\r\n                    activation='softmax'))\r\n\r\n    optimiser=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9)\r\n    # Compile model\r\n    model.compile(loss='categorical_crossentropy', \r\n                  optimizer=optimiser, \r\n                  metrics=['accuracy'])\r\n    return model\r\n```\r\n\r\n`model = baseline_model()`\r\n\r\n```\r\ndef input_dataset_fn(x_data, y_data, batch_size=128, mode=tf.estimator.ModeKeys.TRAIN):\r\n    \r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        tf.logging.info(\"input_dataset_fn: PREDICT, {}\".format(mode))\r\n    elif mode == tf.estimator.ModeKeys.EVAL:\r\n        tf.logging.info(\"input_dataset_fn: EVAL, {}\".format(mode))\r\n    elif mode == tf.estimator.ModeKeys.TRAIN:\r\n        tf.logging.info(\"input_dataset_fn: TRAIN, {}\".format(mode))\r\n    \r\n    dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\r\n   \r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        num_epochs = FLAGS.epoch\r\n        dataset = dataset.shuffle(buffer_size=FLAGS.shuffle_buffer_size, seed=2)# depends on sample size\r\n    else:\r\n        num_epochs = FLAGS.epoch # to use validation data with keras\r\n    dataset = dataset.repeat(num_epochs)\r\n    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\r\n    dataset = dataset.prefetch(FLAGS.prefetch_buffer_size)\r\n\r\n    return dataset\r\n```\r\n\r\n`estimator_train_model = tf.keras.estimator.model_to_estimator(keras_model=model)`\r\n\r\n```\r\nestimator_train_model.train(input_fn=lambda: input_dataset_fn(x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN, batch_size=FLAGS.batch_size),\r\n                            steps=10)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nINFO:tensorflow:Calling model_fn.\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-123-a7db13f8b1dd> in <module>\r\n      1 # Fit the model (using estimator.train and data.Dataset)\r\n      2 estimator_train_model.train(input_fn=lambda: input_dataset_fn(x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN, batch_size=FLAGS.batch_size),\r\n----> 3                             steps=10)\r\n      4 \r\n      5 #estimator_train_model.train(input_fn=get_train_input_fn,\r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    352 \r\n    353       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 354       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    355       logging.info('Loss for final step: %s.', loss)\r\n    356       return self\r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1181       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1182     else:\r\n-> 1183       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1184 \r\n   1185   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1211       worker_hooks.extend(input_hooks)\r\n   1212       estimator_spec = self._call_model_fn(\r\n-> 1213           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n   1214       global_step_tensor = training_util.get_global_step(g)\r\n   1215       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n   1169 \r\n   1170     logging.info('Calling model_fn.')\r\n-> 1171     model_fn_results = self._model_fn(features=features, **kwargs)\r\n   1172     logging.info('Done calling model_fn.')\r\n   1173 \r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in model_fn(features, labels, mode)\r\n    286       loss = model.total_loss\r\n    287 \r\n--> 288       eval_metric_ops = _convert_keras_metrics_to_estimator(model)\r\n    289 \r\n    290     # Set train_op only during train.\r\n\r\n~/anaconda3/envs/env_gcp_dl_1_13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in _convert_keras_metrics_to_estimator(model)\r\n    231     for i, metric_name in enumerate(model.metrics):\r\n    232       if callable(metric_name):\r\n--> 233         metric_name = metric_name.__name__\r\n    234       eval_metric_ops[metric_name] = metrics_module.mean(\r\n    235           model.metrics_tensors[i])\r\n\r\nAttributeError: 'MeanMetricWrapper' object has no attribute '__name__'\r\n\r\n", "comments": ["could it be an installation issue ? I installed it using pip. Before (1.12 installed with conda), I didn't have a  separate package tensorflow-estimator \r\n```\r\ntensorboard               1.12.2                    <pip>\r\ntensorflow                1.13.0rc0                 <pip>\r\ntensorflow-estimator      1.10.12                   <pip>\r\n```", "A known bug in the RC0 is that it doesn't force the upgrade of estimator to the correct version. Can you try forcing an upgrade of tensorflow-estimator to 1.13.0rc0 i.e.\r\n\r\npip install --upgrade tensorflow==1.13.0rc0 tensorflow-estimator==1.13.0rc0\r\n\r\nThis matches more what we will be doing in the RC1.", "Thanks, this solve my issue. How can I find such info next time ? Is there a page with all the know isues and tricks ?", "tensorboard               2.2.2                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.7.0                    pypi_0    pypi\r\ntensorflow                2.2.0                    pypi_0    pypi\r\ntensorflow-estimator      2.2.0                    pypi_0    pypi\r\ntensorflow-probability    0.10.0                   pypi_0    pypi\r\n\r\nCan anyone help me out, what is the issue here?\r\n\r\n"]}, {"number": 25258, "title": "tf.nn.bias_add and tf.add as checkpointable", "body": "Please consider adding operation to checkpointable such as add, multiply, etc. Checkpointable does not work with any operands tf.keras.layers.add, tf.nn.bias_add, tf.add, +", "comments": ["@agniszczotka Could you provide more details about the features you are looking and the context of usage of those features. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 25257, "title": "TF 2.0 Conversion Script does not have a replacement for tf.contrib.eager.defun(train_step).", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nSubmitting on behalf of @victordibia. Thanks, Victor! \ud83d\ude0a\r\n\r\n**Describe the expected behavior**\r\n\r\nI used the TF 2.0 conversion script to convert my DCGAN sample from tf1.x to tf2.0.\r\n\r\nIt suggested use of tf.compat.v1.losses.sigmoid_cross_entropy  (previously in contrib), but am unclear if this has same behaviour as tf.nn.softmax_cross_entropy_with_logits. The script did not recommend a replacement for tf.contrib.eager.defun(train_step).\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/victordibia/tf2/blob/master/dcgan/dcgan.py\r\n\r\n**Other info / logs**\r\nFriction log: https://docs.google.com/document/d/1Sv6INZzqLUUChy46jeawX1FdO1rG5aAjjGde7wOSBb8/edit?usp=sharing", "comments": ["softmax_cross_entropy_with_logits and sigmoid_cross_entropy definitely do not have the same behavior. Can you link me to a message suggesting one for the other? It's a bug.\r\n\r\ntf.contrib.eager.defun can usually be replaced with tf.function but variable creation semantics are slightly different, so we can't make the transition automatically.", "Hi @alextp \r\nThanks for the note. There is no official message that says both are equivalent, luckily. \r\nI was asking given similar names. That being said, is there a specific equivalent for `tf.contrib.losses.softmax_cross_entropy` in `tf2.0`?  \r\n\r\n-V.\r\n", "the direct replacement for `tf.contrib.losses.softmax_cross_entropy` is `tf.compat.v1.losses.tf.losses.softmax_cross_entropy`.\r\n\r\nI would welcome a PR adding this to `tf_upgrade_v2.py`.", "I confirm that the `tf_upgrade_v2` script **already** does this replacement. \r\nI (incorrectly) assumed that `losses.softmax_cross_entropy` may have moved to some other location in the tf2.0 api. Thanks Martin.\r\nI think this issue can be closed now."]}, {"number": 25256, "title": "Use efficient squared_difference instead of square(diff)", "body": "", "comments": []}, {"number": 25255, "title": "Add jupyter_http_over_ws as part of jupyter install in Dockerfile", "body": "This fix tries to address the issue raised in #25247 to add jupyter_http_over_ws as part of jupyter install in Dockerfile.\r\n\r\nThis fix fixes #25247.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Well, this was a very pleasant experience, thanks very much to everyone involved! \\o/"]}, {"number": 25254, "title": "Keras & data.Dataset : \"Your dataset iterator ran out of data\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): Colab\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nKeras model.fit() does not reset validation dataset iterator between epochs. Thus, when specifying `validation_steps` < `validation_dataset_size / batch_size`, then every evaluation will be performed on a different set of examples.\r\n\r\n**Describe the expected behavior**\r\nI would expect that `model.fit()` restarts from the beginning in the validation dataset after every epoch of training. This way the validation dataset could be used without `.repeat()` and the evaluation would be performed on the same set of examples.\r\n\r\n**Code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1UjKNbX38UC4EG6EPm6xLzQ1AmFV8HWe5\r\n\r\n**Other info / logs**\r\n```\r\nWARNING:tensorflow:Your dataset iterator ran out of data interrupting testing. Make sure that your dataset can generate at least `steps` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\r\n```", "comments": ["I think it would be nice to have tf.keras consider one epoch when the dataset runs out of data, it would make the steps_per_epoch and validation_steps undeeded.", "As a quick workaround the validation dataset could be trimmed to  validation_steps * batch_size using .take() before .repeat().", "Reassigning this to @omalleyt12, since I think he has been improving the validation path lately, and I believe this feature would need to be implemented at the Keras level (but feel free to reassign, Tom!).", "We now allow users to not pass in validation_steps or steps_per_epoch for datasets, like in @cassianocasagrande 's suggestion", "System information\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13 / 2.0-alpha\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 10.0/7.5\r\n- GPU model and memory: 1080 Ti / 32 GB\r\n\r\nI still encounter similar problems with TF 2.0 alpha and TF 1.13.\r\n\r\n**TF 1.13**\r\n\r\n```python3\r\ngen_train = # ... generator function ...\r\ngen_test = # ... generator function ...\r\n# creation of datasets\r\ntypes = (tf.float32, tf.int32)\r\nshapes = ((512, 512, 3), (2,))\r\nds_train = tf.data.Dataset.from_generator(lambda: gen_train, types, shapes).shuffle(1000).repeat().batch(32)\r\nds_test = tf.data.Dataset.from_generator(lambda: gen_test, types, shapes).shuffle(100).repeat().batch(32)\r\n\r\n# usage in model\r\nmodel.fit(ds_train, steps_per_epoch=188, validation_data=ds_test, validation_steps=20, epochs=10, verbose=True, callbacks=[visualize, tensorboard])\r\n```\r\n\r\n`gen_train` provide a tuple of an image and a one_hot vector. `steps_per_epoch` are set to the exact number of batches in the dataset.\r\nHowever once I reach batch 156 (the one where the dataset would be required to load the next iteration for shuffling) the system stops. I have medium CPU usage from python (25-35%) and no progress at all in the learning.\r\n\r\n**TF 2.0**\r\n\r\n```python3\r\ngen_train = # ... generator function ...\r\ngen_test = # ... generator function ...\r\n# creation of datasets\r\ntypes = (tf.float32, tf.int32)\r\nshapes = ((512, 512, 3), (2,))\r\nds_train = tf.data.Dataset.from_generator(lambda: gen_train, types, shapes).shuffle(1000).batch(32)\r\nds_test = tf.data.Dataset.from_generator(lambda: gen_test, types, shapes).shuffle(100).batch(32)\r\n\r\n# usage in model\r\nmodel.fit(ds_train, validation_data=ds_test, epochs=10, verbose=True, callbacks=[visualize, tensorboard])\r\n```\r\n\r\nIn this case the system completes the first epoch and the evaluation. However beginning of the second epoch I get the following error:\r\n\r\n```\r\nW0322 18:36:04.919457 140678915827456 training_generator.py:228] Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 1880 batches). You may need to use the repeat() function when building your dataset.\r\n```\r\n\r\nIf I am using `.repeat()` on the datasets (and provide `steps_per_epoch` and `validation_steps` args) I run into the same problem as with TF 1.13.\r\n\r\n@omalleyt12 Am I right in the assumption that the change is already included in the tf-2.0-alpha release? (As TF 1.13 would raise an error if I do not provide `steps_per_epoch` and `validation_steps`, while TF2 does not)", "I'm guessing the generator runs out of Data, I don't think repeat works with generators", "Thanks for the note.\r\nIt actually does work, but the lambda function has to create the generator. So the code would look like this:\r\n\r\n```python\r\n# creation of datasets\r\ntypes = (tf.float32, tf.int32)\r\nshapes = ((512, 512, 3), (2,))\r\nds_train = tf.data.Dataset.from_generator(lambda: fct_to_create_train_gen(), types, shapes).shuffle(1000).batch(32)\r\nds_test = tf.data.Dataset.from_generator(lambda: fct_to_create_test_gen(), types, shapes).shuffle(100).batch(32)\r\n\r\n# usage in model\r\nmodel.fit(ds_train, validation_data=ds_test, epochs=10, verbose=True, callbacks=[visualize, tensorboard])\r\n```\r\n\r\nAlternative option would be to create a generator that loops infinitely over the data, but that would require to provide `steps_per_epoch` and `validation_steps`.", "I think this bug still exists when it is used in multiworkerdistributed mode, \r\ni launched workers using kubernetes, first epoch ran correctly then I got this error message, if I used steps_per_epoch, and repeat() everything works fine\r\n\r\ntfversion: 2.0.0-beta1\r\n\r\n```\r\n2019-07-07 06:48:48.821000: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 28884 of 100000000\r\n2019-07-07 06:48:49.144075: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\r\n2019-07-07 06:48:49.161736: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.161820: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.162250: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.162329: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.163848: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at collective_ops.cc:223 : Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.163910: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[metrics/accuracy/div_no_nan/allreduce_1/CollectiveReduce]]\r\n2019-07-07 06:48:49.164582: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at collective_ops.cc:223 : Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.169979: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.170069: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.170203: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at collective_ops.cc:223 : Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.179226: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.179355: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-07-07 06:48:49.179457: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at collective_ops.cc:223 : Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\nW0707 06:48:49.193020 140662389356352 training_arrays.py:309] Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 1404 batches). You may need to use the repeat() function when building your dataset.\r\n```\r\n\r\n<details><summary> train.py </summary>\r\n<p>\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nimport argparse\r\nimport json\r\nimport os\r\ntfds.disable_progress_bar()\r\n\r\n\r\nparser = argparse.ArgumentParser(description='Welcome')\r\nparser.add_argument('-workers', type=str, default='dummy')\r\nparser.add_argument('-type', type=str, default='dummy')\r\nparser.add_argument('-index', type=str, default='dummy')\r\n\r\nargs = parser.parse_args()\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': args.workers.split(','),\r\n    },\r\n    'task': {'type': args.type, 'index': int(args.index)}\r\n})\r\n\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\nBUFFER_SIZE = 10000\r\n\r\n# Scaling MNIST data from (0, 255] to (0., 1.]\r\ndef scale(image, label):\r\n  image = tf.cast(image, tf.float32)\r\n  image /= 255\r\n  return image, label\r\n\r\ndatasets, info = tfds.load(name='mnist',\r\n                           with_info=True,\r\n                           as_supervised=True)\r\n\r\ntrain_datasets_unbatched = datasets['train'].map(scale).shuffle(BUFFER_SIZE)\r\n#train_datasets = train_datasets_unbatched.batch(BATCH_SIZE)\r\n\r\ndef build_and_compile_cnn_model():\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n      tf.keras.layers.MaxPooling2D(),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(10, activation='softmax')\r\n  ])\r\n  model.compile(\r\n      loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n  return model\r\n\r\n\r\n\r\nNUM_WORKERS = 2\r\n# Here the batch size scales up by number of workers since \r\n# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \r\n# and now this becomes 128.\r\nGLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\r\ntrain_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\r\nwith strategy.scope():\r\n  multi_worker_model = build_and_compile_cnn_model()\r\nmulti_worker_model.fit(train_datasets, epochs=3)\r\n```\r\n\r\n</p>\r\n</details>", "Yes, even running the Multi-worker distributed training with Keras code example on the official TensorFlow Documentation website has this error. How do you get this to work over data loaded in from MNIST for example? This is the code example I was talking about, and it's identical to the one shown by ahmedanis03: https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_keras.", "same issue", "same for me.", "I am having the same issue as @ahmedanis03 and @benhe2011, but even for one machine two GPU setup. I modified the old code from the multi_gpu_model documentation and used the required MirroredStrategy.\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18362 Build 18362\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 10.0/7.6.1\r\n- GPU model and memory: 2x MSI GeForce RTX 2080 Ti GAMING X TRIO (no NVlink)\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications import Xception\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \r\n                                          cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\nwith strategy.scope():\r\n    parallel_model = Xception(weights=None,\r\n                              input_shape=(height, width, 3),\r\n                              classes=num_classes)\r\n    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.summary()\r\n# This `fit` call will be distributed on 2 GPUs.\r\n# Since the batch size is 64, each GPU will process 32 samples.\r\nparallel_model.fit(x, y, epochs=10, batch_size=64)\r\n```\r\n\r\nIt runs perfectly until the final epoch. It always ends with:\r\n\r\n```\r\nEpoch 8/10\r\n16/16 [==============================] - 5s 334ms/step - loss: 3590.6503\r\nEpoch 9/10\r\n16/16 [==============================] - 5s 332ms/step - loss: 3597.1092\r\nEpoch 10/10\r\n12/16 [=====================>........] - ETA: 1s - loss: 3603.6067\r\nW0723 14:30:47.582621   232 training_arrays.py:309] Your dataset ran out of data; \r\ninterrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` \r\nbatches (in this case, 160 batches). You may need to use the repeat() function when \r\nbuilding your dataset.\r\n12/16 [=====================>........] - ETA: 1s - loss: 3603.6067\r\n```\r\n\r\nThis is only an issue with MirroredStrategy. When I train on a single GPU, there is no issue.\r\n\r\nEdit: I'm also getting this output too!\r\n\r\n```\r\n2019-07-23 16:52:04.173982: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n         [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/update_0/Const/_355]]\r\n2019-07-23 16:52:04.183310: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n         [[Identity_1/_376]]\r\n2019-07-23 16:52:04.189139: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n```\r\n\r\n**TEMPORARY SOLUTION:** I converted the numpy arrays to a tf Dataset and used .repeat() while providing the proper number of steps per epoch within fit:\r\n\r\n```\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n\r\nBATCH_SIZE = 64\r\nBUFFER_SIZE = 10000\r\n\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\r\n\r\nif BUFFER_SIZE % BATCH_SIZE != 0:\r\n    parallel_steps = BUFFER_SIZE // BATCH_SIZE + 1\r\nelse:\r\n    parallel_steps = BUFFER_SIZE // BATCH_SIZE\r\n\r\n# This `fit` call will be distributed on 2 GPUs.\r\n# Since the batch size is 64, each GPU will process 32 samples.\r\nparallel_model.fit(train_dataset, epochs=10, steps_per_epoch = parallel_steps)\r\n```", "Any news on this topic?\r\nHave the same issues", "I am having similar issue. @Path-A 's solution works like charm ! Thanks. I tried it and I confirm it works.", "I had a similar issue and setting `drop_remainder=True` in the tf.Dataset `batch` method worked for me.", "Any updates? I experience the same with MultiWorkerMirroredStrategy.\r\n\r\n.repeat() + setting the correct number of samples works as a workaround. Nevertheless, it'd be nicer if one can just use the entire validation set without providing the correct number of samples.", "I get the same issue when using tensorflow.keras.preprocessing.image.ImageDataGenerator with model.fit() when trying to specify a steps_per_epoch greater than the length of the generator.", "Got the same issue on TF 2.1.0", "This still occurs in 2.2 (tf-nightly) if your epochs have varying lengths. I accept this is a rare occurance, but e.g. for graph neural networks, computation / memory requirements are generally dependent on the number of nodes, so batches can have dynamic sizes to accomodate this, which can lead to slightly varying numbers of batches per epoch. If epochs beyond the first are even one step shorter than the first epoch, this issue still arises.", "![image](https://user-images.githubusercontent.com/36342491/93561018-69263400-f951-11ea-8c04-e803e3e578bc.png)\r\n\r\n![image](https://user-images.githubusercontent.com/36342491/93560653-ad650480-f950-11ea-9b65-104ee2e98a16.png)\r\n\r\nSolution: Put the repeat(epochs) in the front of batch( batch_size ) \r\n![image](https://user-images.githubusercontent.com/36342491/93561319-f2d60180-f951-11ea-9d2e-6111a8fc88fd.png)\r\n\r\n![image](https://user-images.githubusercontent.com/36342491/93561376-0d0fdf80-f952-11ea-9637-3153517c74cf.png)\r\n\r\nhttps://blog.csdn.net/Linli522362242/article/details/108396485", "```\r\ndef gen():\r\n    df = read_csv(train_file_path,\r\n                  dtype=data_types, chunksize=2048)\r\n    for d in df:\r\n        y = d['like_gt']\r\n        d.drop(['tweet_id', 'engaging_id', 'reply_gt', 'retweet_gt',\r\n                'quote_gt', 'like_gt'], axis=1, inplace=True)\r\n\r\n        yield np.asarray(d), np.asarray(y)\r\n\r\nmodel.fit(gen(), batch_size=64, epochs=5)\r\n```\r\nWhat's the problem with this code that skips all epochs greater than 1?", "`tf.data.Dataset.from_generator ` has a big problem when using funcational api .\r\nIt force convert a list of tensors to tensor . \r\nFor example , I have a multi-input models\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ndata = pd.DataFrame(np.random.uniform(size=(1000,3)), columns=['Sales', 'SalesDiff7', 'SalesAggMean7'])\r\n\r\nmulti_inputs = []\r\nmulti_outputs = []\r\nwindow_size = 1\r\n\r\nfor i in range(data.shape[1]):\r\n    ti = keras.Input(shape=(window_size, 1), name=f't{i}')\r\n    tlstm = layers.LSTM(32)(ti)\r\n    tp = keras.layers.Dense(units=1)(tlstm)\r\n    multi_inputs.append(ti)\r\n    multi_outputs.append(tp)\r\n    \r\nr = tf.concat(multi_outputs, -1)\r\nc = keras.layers.Flatten()(r)\r\nresult = keras.layers.Dense(units=1)(c)\r\n\r\nmodel = keras.Model(\r\n    inputs=multi_inputs,\r\n    outputs=result,\r\n)\r\n```\r\nHere, the model need  input of  a list of  3 tensor .\r\n\r\n\r\nBut `Dataset.map` return only tensor\r\n```\r\ndef split_multi_window(features):\r\n  inputs = features[:, slice(0, 1, None), :]\r\n  inputs = tf.split(inputs, num_or_size_splits=features.shape[-1], axis=len(features.shape)-1)\r\n    \r\n  labels = features[:, slice(1, None, None), slice(0,1, None) ]\r\n  return inputs, labels\r\n\r\ndata = pd.DataFrame(np.random.uniform(size=(1000,3)), columns=['Sales', 'SalesDiff7', 'SalesAggMean7']).to_numpy()\r\nds = tf.keras.preprocessing.timeseries_dataset_from_array(\r\n  data=data,\r\n  targets=None,\r\n  sequence_length=1,\r\n  sequence_stride=1,\r\n  shuffle=True,\r\n  batch_size=32,)\r\n\r\nds2  = ds.map(split_multi_window)\r\nds2\r\n#  <MapDataset shapes: ((3, None, None, 1), (None, None, 1)), types: (tf.float64, tf.float64)>\r\n```\r\n\r\nTry to reformat the dataset  \r\n```\r\nds2 = tf.data.Dataset.from_generator(lambda : ((list(x), y) for x, y in ds2), (list, tf.float32))\r\n```\r\nwould get error  :  TypeError: Cannot convert value <class 'list'> to a TensorFlow DType. \r\n\r\n\r\n\r\n\r\n\r\n", "I think the issue with not having enough data in the last batch still exists. For me it happens when running model.predict() as my data is passed in through a generator. Here my problem:\r\n\r\nlen(X_test) = 567\r\nbatch_size = 5\r\nnumber of steps = 567 / 5 = 113.4\r\n\r\nWhen using this calculation I have 113 steps, as 0.4 or the last two samples are being ignored. This causes the warning below, which is correct:\r\n\r\n113/113 [============================>.] - ETA: 0sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 113.4 batches). You may need to use the repeat() function when building your dataset.\r\n113/113 [============================>.] - 7s 59ms/step\r\n\r\nWhen increasing the step size to 114 by applying \"steps=math.ceil(len(X_test) / batch_size)\"\r\nthe new step size is still ignored and only 113 of 114 steps are executed. See warning below:\r\n\r\n113/114 [============================>.] - ETA: 0sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 114 batches). You may need to use the repeat() function when building your dataset.\r\n113/114 [============================>.] - 7s 60ms/step\r\n\r\nI don't see these problems when running model.fit() and setting \"steps_per_epoch\" and \"validation_steps\"\r\n\r\nI am using Singularity container: tensorflow_2.3.2-gpu-jupyter.sif", "I got the same isssue in training with retinanet. I resolved it by using repeat inside \"fit\"\r\n\r\n`train_steps_per_epoch = dataset_info.splits[\"train[:95%]\"].num_examples // batch_size\r\nvalid_steps_per_epoch = dataset_info.splits[\"train[95%:]\"].num_examples // batch_size\r\n\r\ntrain_steps = 4*100000\r\nepochs = train_steps // train_steps_per_epoch\r\nprint (valid_steps_per_epoch)\r\n\r\n\r\nimport random\r\n\r\nrandom.seed(10)\r\nhistory = model.fit(\r\n    train_dataset.repeat(),\r\n    batch_size=batch_size,\r\n    validation_data=val_dataset.repeat(),\r\n    steps_per_epoch=train_steps_per_epoch,\r\n    validation_steps=valid_steps_per_epoch,\r\n    epochs=epochs,\r\n    callbacks=callbacks_list,\r\n    verbose=1,\r\n)_`", "I encountered the same issue.\r\nI had a python generator: gen\r\ntf.data.Dataset.from_generator(lambda: gen, ....) \r\nIt does not support repeat. But if I define a lambda generator outside of tf.data.from_generator(gen_lambda, ...) as follows\r\n\r\ngen_lambda = lambda: gen\r\ntf.data.Dataset.from_generator(gen_lambda,  ....) solved the issue. \r\nIt supports repeat method.", "The issue was resolved in my case. The porblem was in my dataset that contain some image with no labels. the number of generated samples < size of the set, so the generator will try to generate data that don't exist! \r\n\r\n", "Providing a case may help somebody.\r\n\r\nI create a dataset with `image_dataset_from_directory `, initialized with `batch_size`. \r\nThen I passed `steps_per_epoch `and `validation_steps` into `model.fit` , and what I get is early stopping.\r\n\r\nThe right way is removing  `steps_per_epoch `and `validation_steps` parameters in `model.fit`, because the steps was initiated when `batch_size` passed into `image_dataset_from_directory`\r\n\r\nChaos......"]}, {"number": 25253, "title": "[XLA] BNs - Create the epsilon with the right type", "body": "Use the `FloatLiteral` call rather than assuming it is FP32.", "comments": ["@hawkinsp fixed the merge conflict "]}, {"number": 25252, "title": "windows c_api error with tensorflow.dll", "body": "I tried to compile on windows c program with tenserflow c api and tenserflow.dll from https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.12.0.zip founded on https://www.tensorflow.org/install/lang_c. \r\nThis example:\r\n#include <stdio.h>\r\n#include <tensorflow/c/c_api.h>\r\n\r\nint main() {\r\n  printf(\"Hello from TensorFlow C library version %s\\n\", TF_Version());\r\n  return 0;\r\n}\r\n\r\nCompiling is success, but when i have run it, i recieved a mistake that libtenserflow.so not found. Its look like that tensorfow,dll from https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.12.0.zip was builded with some mistakes for windows sistem, becaurse libtensorflow.so is a target for Linux.\r\n\r\nCan you explain or fix this?  \r\n", "comments": ["@gunan @MarkDaoust is this something that should be covered in our docs?\r\n\r\n@supermanxxx you might also try posting on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow).", "CC @meteorcloudy \r\n", "This would be fixed when https://github.com/tensorflow/tensorflow/pull/24963 is merged.", "@supermanxxx libtensorflow is missing a .lib file which you have to generate on your own. I've written a guide on how to setup libtensorflow on windows here: http://iamsurya.com/using-libtensorflow-dlls-in-a-visual-studio-project/\r\n\r\n@meteorcloudy was #24963 merged? I see it as being rejected in the PR queue, which is unfortunate because the missing .lib makes it so hard to setup libtensorflow the first time.", "@iamsurya Yes, it is merged, please see https://github.com/tensorflow/tensorflow/pull/24963#issuecomment-468187880", "@XDRiVE888 Could you please let us know if you still need help on this ? if it is resolved then please feel free to move this issue to close status ? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25252\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25252\">No</a>\n"]}, {"number": 25251, "title": "Added note for the translate function for clarity", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@gavinlive  Could you please commit to the Master branch instead of Release branch. Thanks !", "@gavinlive  please push your changes to master branch , closing this PR"]}, {"number": 25250, "title": "Added 2 missing testcases for Keras switch backend", "body": "There was no test cases for the keras backend switch added the same", "comments": ["@fchollet , thanks for the review, i have updated the code as per the review comments, kindly check and merge.", "@fchollet & @hgadig , can you pls review the PR", "> @fchollet & @hgadig , can you pls review the PR\r\n\r\n@fchollet  PTAL", "@fchollet & @hgadig , all the code is updated as per your comments, can you pls review the PR", "Nagging Reviewer @fchollet, @fchollet: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@qlzh727 , i have updated the code as per your suggestion, kindly review.\r\n\r\nRegards\r\nAmit", "@qlzh727 , i have updated the code as per your suggestion, kindly review.\r\n\r\nRegards\r\nAmit"]}, {"number": 25249, "title": "TF Framework error_test missing test case add", "body": "1-error_code_from_exception_type api test case", "comments": ["@penpornk \r\n\r\nThanks for quick review. I added test case here to make sure both api is consistent and shouldn't be inconsistent. So additional changes is added with try catch block in error_code_from_exception_type similiar to _make_specific_exception api. \r\n\r\nWelcome for review comments and suggestion.", "@penpornk \r\n\r\nPlease review the updated changes, thanks."]}, {"number": 25248, "title": "TF Framework ops_eager_test missing test case add", "body": "1-disable_eager_execution api test case", "comments": ["@qlzh727 \r\n\r\nHelp to review the changes. Thanks....", "@pragyaak  Please help proceeding with the next steps as I've some access issues(I'm trying to resolve).", "@Dayananda-V seems one of the file has been moved or deleted `\r\n        tensorflow/tensorflow/python/framework/ops_eager_test.py\r\n      `  can you please check", "@rthadur \r\n\r\nThis change is closing and update PR #26379 can be find here."]}, {"number": 25247, "title": "[Docker] include jupyter_http_over_ws in Jupyter Docker images", "body": "**System information**\r\n- TensorFlow version (you are using): `tensorflow/tensorflow:nightly-gpu-py3-jupyter`\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nFollowing [these instructions](https://research.google.com/colaboratory/local-runtimes.html), it requires to have `jupyter_http_over_ws` Jupyter extension to work. The current Docker image doesn't seem to have it (or I'm mistaken, please correct if so).\r\n\r\nHaving the Docker Jupyter images have this preinstalled would allow for this integration to be made more straightforward.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAny Docker Jupyter users using Google's Colaboratory (or other frontend using the interface).\r\n\r\n**Any Other info.**\r\n\r\nN/A.", "comments": ["Added a PR #25255, Will let the docker file maintainers to decide if it will be merged or not.", "Just wanted to follow up for anybody using the images with Colab, this is how I did it:\r\n\r\n```\r\n# create a home for your config and your notebooks on your host (these will be accessible to TF from the container)\r\n$ mkdir - p ${HOME}/.config/jupyter ${HOME}/Development/Notebooks\r\n\r\n# enable the extension in our mounted configuration folder\r\n# this is required since we'll be running with a mounted configuration folder so any changes survive container restarts\r\n$ docker run -ti --rm -u `id -u`:`id -g` -v \"${HOME}/.config/jupyter:/.jupyter\" tensorflow/tensorflow:nightly-gpu-py3-jupyter bash -c \"source /etc/bash.bashrc && jupyter serverextension enable --py jupyter_http_over_ws\"\r\n\r\n# run the container (will keep it running each time you restart the computer)\r\n$ docker run --restart=always --detach --name jupyter --rm --runtime=nvidia -u `id -u`:`id -g` -p 8888:8888 -v \"${HOME}/.config/jupyter:/.jupyter\" -v \"${HOME}/Development/Notebooks:/tf\" tensorflow/tensorflow:nightly-gpu-py3-jupyter bash -c \"source /etc/bash.bashrc && jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --NotebookApp.allow_origin='https://colab.research.google.com'\"\r\n\r\n# check the token in Docker logs\r\n$ docker logs jupyter\r\n```\r\n\r\nThis will run the container as your current user (which needs to have permissions to run Docker) and will create a detached, always running process which will start with the Docker daemon, basically making it a \"service\".\r\n\r\nOpen http://localhost:8888/, login with the token to get the cookie stored in the browser. Once you do, open Colab and connect to your local runtime, it should work."]}, {"number": 25246, "title": "Go Binding: Use runtime.KeepAlive", "body": "Please ensure to call runtime.KeepAlive, because the go bindings use finalizers which they shouldn't...\r\nReference: https://github.com/golang/go/issues/13347\r\n\r\nAlso ensure to call runtime.KeepAlive on every:\r\n\r\n```go\r\nvar buf []byte\r\n//...\r\nunsafe.Pointer(&buf[0])\r\n// C call here\r\nruntime.KeepAlive(buf)\r\n```", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 25245, "title": "Error while training the 1D CNN in keras with tensorflow backend ", "body": "Hello Everyone!!\r\nI want to make a 1D CNN model using keras.\r\nConsider that I've got a dataset X which is (2015930,13) where 13 is the number of features of audio where I want to do the 1d convolution on My Y is (2015930, 7) and I'm working with keras with tensorflow backend.\r\n\r\nWhile training I am getting the following error. I am very new in this area. So I am unable to find the exact solution. The code of model is :\r\nmodel = Sequential()\r\nmodel.add(layers.Conv1D(40,2, activation='relu', input_shape=(13,1)))\r\nmodel.add(layers.Conv1D(26,1, activation='relu'))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(10, activation='relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(layers.Dense(y_train.shape[1],activation='softmax'))\r\n\r\nUnknownError : Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n[[{{node conv1d_12/convolution/Conv2D}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...propFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_3/Adam/gradients/conv1d_12/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1d_12/convolution/ExpandDims_1)]]\r\n[[{{node loss_6/mul/_525}} = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_770_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\r\nMy system specification are:\r\nGPU system with NVIDIA graphics QuadroK2200.\r\nOS: Ubuntu 16.04.1\r\nprint(tf.version) : 1.12.0(tensor flow)\r\n\r\nActually all the software were already installed by someone else so I am not sure CUDA and CUDNN are present or not.\r\nSo I used these command to check it.\r\ncat /usr/local/cuda/version.txt : CUDA Version 9.0.176\r\ncat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 :\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 0\r\n#define CUDNN_PATCHLEVEL 5\r\n\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 +CUDNN_PATCHLEVEL)\r\n#include \"driver_types.h\"\r\n\r\nCan anyone help me why this error is coming ?\r\nPlease reply I am struggling since one week.\r\nIf any additional information require I can share it.\r\n\r\nThanks in advance", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\n"]}, {"number": 25244, "title": "fix build wheel parse error", "body": "Mon Jan 28 13:12:17 IST 2019 : === Building wheel\r\nerror in tensorflow setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Invalid requirement, parse error at < 1.14.0'\r\n\r\nCould not find a version that satisfies the requirement tensorflow-estimator>=1.13 (from tensorflow==1.12.0) (from versions: 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12, 1.13.0rc0)\r\nNo matching distribution found for tensorflow-estimator>=1.13 (from tensorflow==1.12.0)", "comments": ["This fix already merged with PR [970](https://github.com/Rachelmorrell/tensorflow/pull/970) [commit](https://github.com/Rachelmorrell/tensorflow/pull/970/commits/59cf62cc475651e75fc8d2948daf2444cc0e8c15). So closing duplicate bug fix PR. Thanks"]}, {"number": 25243, "title": "A question about tflite inference", "body": "Hello, i use aware training method get a quantize model ,so in the tflite inference implementation, which part processes \"zero_point\"(Such as input and filter data should be combined with offset)  in the convolution code of tflite? Could you please give me a link\uff1f thanks ", "comments": ["Hello, the zero_point gets set to the filter_offset here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/conv.cc#L414\r\n\r\nThen it gets used in the kernel here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/reference/reference_ops.h#L383"]}, {"number": 25242, "title": "how to test data stream in speech_commands project?", "body": "Dear,\r\nI have a question,in the [project](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands)\r\nwhen I test the wave data decode by [librosa.load](https://github.com/librosa/librosa/blob/master/librosa/core/audio.py) not read by open in the row of 96 from the [script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/label_wav.py)\r\nit ups bug,\r\n`Traceback (most recent call last):\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: Unable to get element as bytes.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:/python/speechtf/label_wav4_6.py\", line 41, in <module>\r\n    y_pred,_=run_graph(graph,y)\r\n  File \"D:/python/speechtf/label_wav4_6.py\", line 14, in run_graph\r\n    predictions, = sess.run(softmax_tensor, {'wav_data:0': wav_data})\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Unable to get element as bytes.`\r\n\r\nSo how do I test data stream after decode by librosa.load but not wav file read by open ?\r\nCould U help me,Please?\r\nAny advice or suggestion will be great!\r\nThx\r\n", "comments": ["@ucasiggcas Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. Github is mainly for addressing bugs in installation and performance. Thanks!\r\n\r\nIf you think it is not a support question, then please fill system [template](https://github.com/tensorflow/tensorflow/issues/new?template=00-bug-performance-issue.md) and provide steps and a code to reproduce the error. Thanks"]}, {"number": 25241, "title": "Add include_batch_in_index for CPU kernel of max_pool_with_argmax", "body": "Related issue: #24067, PR: #23993 \r\n\r\nNote include_batch_in_index attribute defaults to False, which breaks CPU behavior.", "comments": ["@alextp @reedwm Hi, I think all comments have been resolved. Could you take a look again? Thanks :-)", "@facaiy  Could you please look into the merge conflicts. ", "@hgadig Hi, thanks for reminding me. I'll fix it tomorrow because I'm on the train today.", "@facaiy  Any update on the changes requested ?", "@reedwm Could you take a look again?", "@hgadig Hi, has the change been merged in Google inner repository?", "> @hgadig Hi, has the change been merged in Google inner repository?\r\n\r\nI'm having access issues and unable to look into the internal CL. \r\n@alextp  Could you please help ?", "Because #23993 depends on the PR, that would be helpful if we could merge the PR soon :-)", "@pragyaak  I've some access issues and could you PTAL and proceed with next steps ?", "@hgadig sure. Working on this now. Will update this PR. ", "Hi @facaiy.\r\n\r\nI apologize for the delay. It seems the test `//tensorflow/tools/api/tests:api_compatibility_test` is failing. Can you take a look? You can see the failure by looking at the \"Some checks were not successful\" section, and clicking \"Details\" next to the \"Ubuntu Python2\" row.\r\n\r\nYou can follow the instructions [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/api/tests) to update the golden files to make the test pass.\r\n", "Hi, I have updated the golden files.", "Hi, any update? ", "@reedwm gently ping. Would you mind taking a look?"]}, {"number": 25240, "title": "Tensor vs _EagerTensorBase in 2.0 preview with eager execution", "body": "Playing around with tensorlfow 2.0 preview (`tf_nightly_2.0_preview-2.0.0.dev20190126`) I noticed something that I found weird\r\n\r\nTensorflow version : tf_nightly_2.0_preview-2.0.0.dev20190126\r\nOS : Mac OS 10.14.1\r\nInstalled via `pip install tf-nightly-2.0-preview`\r\n\r\nusing a simple model \r\n\r\n    from tensorflow.keras.layers import *\r\n\r\n    class CNN(tf.keras.model.Model):\r\n    \r\n    def __init__(self, num_classes=10):\r\n        super(CNN, self).__init__()\r\n        self.conv1 = Conv2D(32, (3, 3), padding='same',input_shape=valid_features.shape[1:])\r\n        \r\n        self.softmax = Activation('softmax')\r\n        \r\n    def call(self, inputs):\r\n        \r\n        x = self.conv1(inputs)\r\n        ipdb.set_trace()\r\n        return self.softmax(x)\r\n\r\n\r\nevaluating `type(inputs)` in the debugger yields `<class 'tensorflow.python.framework.ops.Tensor'>` which has no way ( that I know) to actually get the contents of.\r\n\r\nHowever, after searching through tensorflow code I found `class _EagerTensorBase(Tensor):`\r\nwhich has a `numpy()` property the gives you the actual content.\r\n\r\n``` python \r\nx = np.array([1,2,3])\r\ny = tf.nn.relu(x)\r\ntype(y)\r\ntensorflow.python.framework.ops.EagerTensor\r\ny.numpy() works!\r\n```\r\n\r\n I couldn't find a place online that actually tells the difference between these two. Also shouldn't `_EagerTensorBase` be the default when using eager execution with keras?\r\n\r\nEDIT : \r\n\r\nIf i ran `tf.executing_eagerly()` in the debugger it returns `False` however running it in a cell returns `True`", "comments": ["Keras uses internally a mix of eager execution and graph building, and you're seeing this.\r\n\r\nIf you use a keras InputLayer you get a graph tensor, which has no static value. This tensor can be passed to layers, which run in graph mode. This allows you to build a model using keras's functional API.\r\n\r\nThe same layers, however, work if you pass eager tensors into them, executing eagerly.\r\n\r\nSo I think this is working as intended, but I'll let @fchollet close the bug if this is indeed the case.", "> The same layers, however, work if you pass eager tensors into them, executing eagerly.\r\n\r\nHow Can i pass an eager tensor to the model ? by using tf.data ?\r\n\r\n", "model(tf.constant(...)) works just fine.\n\nOn Tue, Jan 29, 2019 at 1:11 AM Wassim Seifeddine <notifications@github.com>\nwrote:\n\n> The same layers, however, work if you pass eager tensors into them,\n> executing eagerly.\n> How Can i pass an eager tensor to the model ? by using tf.data ?\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25240#issuecomment-458461649>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxeGXu6ertaTU9nyVMF-PqK2sFDABks5vIBAogaJpZM4aVOX1>\n> .\n>\n\n\n-- \n - Alex\n", "> model(tf.constant(...)) works just fine.\r\n> [\u2026](#)\r\n> On Tue, Jan 29, 2019 at 1:11 AM Wassim Seifeddine ***@***.***> wrote: The same layers, however, work if you pass eager tensors into them, executing eagerly. How Can i pass an eager tensor to the model ? by using tf.data ? \u2014 You are receiving this because you were assigned. Reply to this email directly, view it on GitHub <[#25240 (comment)](https://github.com/tensorflow/tensorflow/issues/25240#issuecomment-458461649)>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AAATxeGXu6ertaTU9nyVMF-PqK2sFDABks5vIBAogaJpZM4aVOX1> .\r\n> -- - Alex\r\n\r\nCould you answer @wassimseif 's question? How to make tf.data API generate eager tensor? ", "In eager mode that's what always happens, just do `for t in dataset:` and t\nis an eager tensor.\n\nOn Wed, Aug 28, 2019 at 3:24 PM hankcs <notifications@github.com> wrote:\n\n> model(tf.constant(...)) works just fine.\n> \u2026 <#m_3133106851875109259_>\n> On Tue, Jan 29, 2019 at 1:11 AM Wassim Seifeddine *@*.***> wrote: The\n> same layers, however, work if you pass eager tensors into them, executing\n> eagerly. How Can i pass an eager tensor to the model ? by using tf.data ? \u2014\n> You are receiving this because you were assigned. Reply to this email\n> directly, view it on GitHub <#25240 (comment)\n> <https://github.com/tensorflow/tensorflow/issues/25240#issuecomment-458461649>>,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAATxeGXu6ertaTU9nyVMF-PqK2sFDABks5vIBAogaJpZM4aVOX1\n> .\n> -- - Alex\n>\n> Could you answer @wassimseif <https://github.com/wassimseif> 's question?\n> How to make tf.data API generate eager tensor?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25240?email_source=notifications&email_token=AAABHRNQQEKVLVKXKDM6X5TQG33LNA5CNFSM4GSU4X22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5MUG6I#issuecomment-525943673>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRPMBFDNCVH3WLUGNO3QG33LNANCNFSM4GSU4X2Q>\n> .\n>\n\n\n-- \n - Alex\n", "> In eager mode that's what always happens, just do `for t in dataset:` and t is an eager tensor.\r\n> [\u2026](#)\r\n> On Wed, Aug 28, 2019 at 3:24 PM hankcs ***@***.***> wrote: model(tf.constant(...)) works just fine. \u2026 <#m_3133106851875109259_> On Tue, Jan 29, 2019 at 1:11 AM Wassim Seifeddine *@*.***> wrote: The same layers, however, work if you pass eager tensors into them, executing eagerly. How Can i pass an eager tensor to the model ? by using tf.data ? \u2014 You are receiving this because you were assigned. Reply to this email directly, view it on GitHub <#25240 (comment) <[#25240 (comment)](https://github.com/tensorflow/tensorflow/issues/25240#issuecomment-458461649)>>, or mute the thread https://github.com/notifications/unsubscribe-auth/AAATxeGXu6ertaTU9nyVMF-PqK2sFDABks5vIBAogaJpZM4aVOX1 . -- - Alex Could you answer @wassimseif <https://github.com/wassimseif> 's question? How to make tf.data API generate eager tensor? \u2014 You are receiving this because you modified the open/close state. Reply to this email directly, view it on GitHub <#25240?email_source=notifications&email_token=AAABHRNQQEKVLVKXKDM6X5TQG33LNA5CNFSM4GSU4X22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5MUG6I#issuecomment-525943673>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AAABHRPMBFDNCVH3WLUGNO3QG33LNANCNFSM4GSU4X2Q> .\r\n> -- - Alex\r\n\r\nThanks, that's true for `for t in dataset:`. But if dataset is passed into Model.fit of keras, it still produces non-eager tensor."]}, {"number": 25239, "title": "Build issue of \"cannot find symbol class Fill where T is a type-variable: T extends Object declared in class Zeros\" still persists, when building Bazel. ", "body": "**System information**\r\n- Ubuntu 16.04 LTS:\r\n- TensorFlow installed from source:\r\n- TensorFlow version 1.12:\r\n- Python version 2.7:\r\n- Bazel version 0.21.0:\r\n\r\n**Describe the problem**\r\nI am going to build Tensorflow Object Detection API Android demo using Bazel which is **def nativeBuildSystem = 'bazel'** But got the following error _**error: cannot find symbol class Fill where T is a type-variable: T extends Object declared in class Zeros **_\r\nI followed the instruction given [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md](url). All steps were completed, except this [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md#android-studio-with-bazel](url), which is building the demo using Android Studio and Bazel. This step is important for my project since Object tracking option requires Bazel. \r\n\r\n**Any other info / logs**\r\n _**Android Studio Version: 3.3**_\r\n_**Gradle version: 3.3.0**_\r\nAny of the instructions and suggestions in either [https://github.com/tensorflow/tensorflow/issues/21431](url), or [https://github.com/tensorflow/tensorflow/issues/23457](url) **DID NOT HELP**, however issues were closed. \r\n\r\n", "comments": ["I got the same issue.", "@akshayudnur do you have any news so far?", "Routing to @jdduke as this looks like an android build issue.", "Just to confirm, this is a *build* error, not a runtime error? Can you provide the full dump of the error and surrounding output?", "@jdduke Sorry for late reply. This is a BUILD ERROR. \r\nThe problem is when I build tensorflow demo using bazel with following command **bazel build --cxxopt='--std=c++11' -c opt //tensorflow/examples/android:tensorflow_demo** in terminal, it succeed, but when I try to build using Android Studio it shows following error in tensorflow/tensorflow/java/src/main/java/org/tensorflow/op/core/Zeros.java file:\r\n_**error: cannot find symbol class Fill\r\nwhere T is a type-variable:\r\nT extends Object declared in class Zeros\r\n**_;\r\n_**error: cannot find symbol class Fill\r\nwhere T is a type-variable:\r\nT extends Object declared in class Zeros\r\n**_;\r\n_**error: cannot find symbol variable Fill\r\nwhere T is a type-variable:\r\nT extends Object declared in class Zeros\r\n**_.\r\n\r\n", "As mentioned in the TensorFlow Dev Summit today, TensorFlow Mobile is being deprecated. It's highly unlikely that we'll continue supporting the gradle-based builds for the TFMobile samples. Is there a reason you cannot use TensorFlow Lite?\r\n\r\nThat said, it looks like this is an issue with the codegen dependency, as the Fill class is dynamically generated. Maybe there have been some more recent changes in how these classes are generated, but I haven't really followed the TensorFlow Java efforts.", "@jdduke The main reason why I am using TFMobile with Basel build option is object tracking function. With TFMobile I was able to build (on terminal) Android Demo with Object tracking option. However, I could not make Object tracking work with TensorFlow Lite so far", "> However, I could not Object tracking work with TensorFlow Lite so far\r\n\r\nCould you be more specific? Are you not able to use https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android?", "> Are you not able to use https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android?\r\n\r\nExactly. When the application starts toast with \"Object tracking support not found\" text comes out. \r\nAs I mentioned earlier, with TFMobile and Bazel I was I able to build the app (only on terminal) with Object tracking support. \r\nIn conclusion, I want  **Object tracking** support to work. ", "The object tracking is really just a clever way of masking the latency of the actual SSD inference. There's no reason you can't use the object tracking code in your own project with TFLite. The reason it doesn't work in that sample is 1) latency is now much lower, and approaching real-time, allowing independent detection, and 2) the TFLite detection sample was a fork of the TF detection sample, but it was decided not to pull in the [extra, more complicated object tracking code](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android/jni/object_tracking). ", "Hi, I see the same error in current r2.0 branch.\r\n\r\n> As mentioned in the TensorFlow Dev Summit today, TensorFlow Mobile is being deprecated\r\n\r\nI would suggest to highlight the fact that `examples/android` is related to deprecated TensorFlow Mobile project. It is not clear from the documentation.\r\n\r\nCould you please specify where can I find TFLite examples in v2.0 ?", "> Hi, I see the same error in current r2.0 branch.\r\n> \r\n> > As mentioned in the TensorFlow Dev Summit today, TensorFlow Mobile is being deprecated\r\n> \r\n> I would suggest to highlight the fact that `examples/android` is related to deprecated TensorFlow Mobile project. It is not clear from the documentation.\r\n> \r\n> Could you please specify where can I find TFLite examples in v2.0 ?\r\n\r\nAnswering to myself:  TF 2.0 compatible demos live in https://github.com/tensorflow/examples", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25239\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25239\">No</a>\n"]}]