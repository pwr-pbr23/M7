[{"number": 27743, "title": "import tensorflow failed after installing tensorflow CPU-only on Windows", "body": "After installing tensorflow CPU-only on Windows, the import tensorflow command fails as below:\r\n\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u52a8\u6001\u94fe\u63a5\u5e93(DLL)\u521d\u59cb\u5316\u4f8b\u7a0b\u5931\u8d25\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u52a8\u6001\u94fe\u63a5\u5e93(DLL)\u521d\u59cb\u5316\u4f8b\u7a0b\u5931\u8d25\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nThere are related issues, but it seems there has no resolution for the issue until now.", "comments": ["@mxx2016  Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27743\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27743\">No</a>\n"]}, {"number": 27742, "title": "Invalid value in tensor used for shape: -1879048192", "body": "When I  try to reshape a tensor with high dimension, it causes the error as follows:\r\n\r\nInvalid value in tensor used for shape: -1879048192\r\n\r\nThe code is : tf.reshape(scores, shape=[-1, nb_features*nb_features]), where scores is a matrix whose shape is 45192*45192 and nb_features is 45192.\r\n\r\nWHy I get this error? Is the dimension too high?\r\n\r\nThank you.", "comments": ["tf.reshape(scores, shape=[-1, nb_featuresnb_features]) should be \r\ntf.reshape(scores, shape=[-1, nb_features, nb_features])\r\nAlso nb_feature * nb_feature is 2042316864 but you are passing a tensor of shape 1879048192.\r\n\r\nThe new tensor after reshape has shape [-1, x, x] so the original tensor passed should of shape [x * x]", "> tf.reshape(scores, shape=[-1, nb_featuresnb_features]) should be\r\n> tf.reshape(scores, shape=[-1, nb_features, nb_features])\r\n> Also nb_feature * nb_feature is 2042316864 but you are passing a tensor of shape 1879048192.\r\n> \r\n> The new tensor after reshape has shape [-1, x, x] so the original tensor passed should of shape [x * x]\r\n \r\n\r\nSorry, the right code is tf.reshape(scores, shape=[-1, nb_features * nb_features]). I want to reshape the matrix from [nb_features, nb_features] to [-1,  nb_features * nb_features].\r\n", "I hope this will be helpful to you.\r\n```import tensorflow as tf\r\na = [[2.6, 3.25, 4.32, 12], [1, 2, 3, 4], [1, 2, 3, 4],[1, 2, 3, 4]]\r\nvar = tf.placeholder(tf.float32, shape=[4, 4], name=\"x\")\r\nans = tf.reshape(var, shape=[-1, 4 * 4])\r\nwith tf.Session() as sess:\r\n    print(sess.run(ans, feed_dict={t:a}))\r\n```\r\n\r\n### Output:\r\n[[ 2.6   3.25  4.32 12.    1.    2.    3.    4.    1.    2.    3.    4. 1.    2.    3.    4.  ]]\r\n\r\nThe problem might be that the tensor passed in the reshape is not of shape [nb_feature, nb_feature], make sure the input value has the correct shape. ", "Thank you for your help. I try later. @bipinkc19 ", " We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!\r\n"]}, {"number": 27741, "title": "Implementation of class weights with tf.nn.softmax_cross_entropy_with_logits_v2", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes, if my skills are enough.\r\n\r\n\r\n__Requested Feature__\r\nCurrently while implementing weighted loss there is tf.nn.weighted_cross_entropy_with_logits which uses sigmoid so it is restricted to binary classification. For multiclass classification using softmax categorical cross entropy, there isn't any feature.\r\n\r\nAlso in many forums, while implementing the class weights people often suggest something like this:\r\n```python\r\nweighted_logits = tf.multiply(weights, logits)\r\nloss = tf.nn.softmax_cross_entropy_with_logits_v2\r\n```\r\nIs this the correct method? Because we are messing around with the output of the model, while we should have been messing around with the calculated [batch_size, num_class] shape loss tensor.\r\n\r\nI think this is the correct way:\r\n```python\r\n        y_hat_softmax = tf.nn.softmax(logits)\r\n        y_cross = y * tf.log(y_hat_softmax)\r\n        weighted_cross = tf.multiply(class_weight, y_cross)\r\n        weighted_cross_reduced = - tf.reduce_sum(weighted_cross, 1)\r\n        loss = tf.reduce_mean(weighted_cross_reduced)\r\n```\r\nHere we are changing the y_cross which should be actually changed, which then changes the gradient flow. But changing logits (by multiplying with weight) will make the model understand that the correct output is different thus biasing result.\r\n\r\neg. If a model has three classes and the output logit is [1, 4, 2] then it is making the correct decision if the actual class is the second one. But multiplying with weight [1, 1, 4] will make the result [1, 4, 8] thus saying that the third logit should have been high to the loss function, thus completely changing the supervision in supervised learning. But actually, we should have been messing around with the loss by scaling the loss according to the weights. \r\n\r\n**Will this change the current api? How?**\r\nDon't know.\r\n\r\n**Who will benefit with this feature?**\r\nWhoever is implementing this incorrectly will benefit from this, democratizing Machine Learning.\r\n\r\n", "comments": ["@bipinkc19,\r\nSorry for the delayed response. Can you please let us know if [weighted_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits) is the functionality that you are looking for? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 27740, "title": "Add trailing $$", "body": "Add trailing $$", "comments": []}, {"number": 27739, "title": "[Tensorflow 2.0] AttributeError: Tensor.op is meaningless when eager execution is enabled.", "body": "**System information**\r\n- Enviroment : Google Colaboratory\r\n- TensorFlow installed from (source or binary):  !pip install tensorflow-gpu==2.0.0-alpha\r\n- TensorFlow version (use command below): 2.0-alpha\r\n\r\nMy code is followed,\r\n\r\n```shell\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import initializers\r\nfrom tensorflow.keras import backend as K\r\nprint(tf.__version__)\r\n\r\nclass CustomLayer(tf.keras.layers.Layer):\r\n  def __init__(self, \r\n               momentum=0.9, \r\n               epsilon=1e-4,\r\n               axis = -1,\r\n               moving_mean_initializer='zeros',\r\n               **kwargs):\r\n    \r\n    super(CustomLayer, self).__init__(**kwargs)\r\n    self.momentum = momentum\r\n    self.epsilon = epsilon\r\n    self.axis = axis\r\n    self.moving_mean_initializer = initializers.get(moving_mean_initializer)\r\n\r\n  def build(self, input_shape):\r\n    param_shape = input_shape[-1]\r\n    \r\n    self.moving_mean = self.add_weight(shape=param_shape,\r\n                                       name='moving_mean',\r\n                                       initializer=self.moving_mean_initializer,\r\n                                       trainable=False)\r\n    \r\n  def call(self, inputs, training=None):\r\n    input_shape = K.int_shape(inputs)\r\n    boundary_axis = 1\r\n    ndim = len(input_shape)\r\n    \r\n    reduction_axes = list(range(ndim))\r\n    for i in range(1): del reduction_axes[self.axis]\r\n    \r\n    broadcast_shape = [1] * ndim\r\n    broadcast_shape[self.axis] = input_shape[self.axis]\r\n    \r\n    mean = K.reshape(K.mean(inputs, axis=reduction_axes), broadcast_shape)\r\n    \r\n    \r\n    update_list = []\r\n    update_list.append(K.moving_average_update(K.reshape(self.moving_mean, broadcast_shape), mean, self.momentum))\r\n    self.add_update(update_list, inputs)\r\n    \r\n    return K.in_train_phase(1,\r\n                            0,\r\n                            training=training) \r\n\r\na = tf.constant(np.random.randn(128,224,224,3), dtype=tf.float32)\r\ncustom_layer_1 = CustomLayer()(a)\r\n\r\nprint(custom_layer_1)\r\n```\r\n\r\nThen I got this Error,\r\n\r\n```shell\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-26a5ee86fab6> in <module>()\r\n      4 #inputs_data = tf.stack([a,b], axis=1)\r\n      5 \r\n----> 6 custom_layer_1 = CustomLayer()(a)\r\n      7 \r\n      8 print(custom_layer_1)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    658           with base_layer_utils.autocast_context_manager(\r\n    659               input_list, self._mixed_precision_policy.should_cast_variables):\r\n--> 660             outputs = self.call(inputs, *args, **kwargs)\r\n    661           self._handle_activity_regularization(inputs, outputs)\r\n    662           self._set_mask_metadata(inputs, outputs, previous_mask)\r\n\r\n<ipython-input-2-1f5e23b011a1> in call(self, inputs, training)\r\n     42 \r\n     43     update_list = []\r\n---> 44     update_list.append(K.moving_average_update(K.reshape(self.moving_mean, broadcast_shape), mean, self.momentum))\r\n     45     self.add_update(update_list, inputs)\r\n     46 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in moving_average_update(x, value, momentum)\r\n   1399   from tensorflow.python.training import moving_averages  # pylint: disable=g-import-not-at-top\r\n   1400   return moving_averages.assign_moving_average(\r\n-> 1401       x, value, momentum, zero_debias=True)\r\n   1402 \r\n   1403 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\r\n    101         return strategy.extended.update(v, update_fn, args=(value,))\r\n    102 \r\n--> 103       return replica_context.merge_call(merge_fn, args=(variable, value))\r\n    104     else:\r\n    105       strategy = distribution_strategy_context.get_cross_replica_context()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in merge_call(self, merge_fn, args, kwargs)\r\n   1373     if kwargs is None:\r\n   1374       kwargs = {}\r\n-> 1375     return self._merge_call(merge_fn, args, kwargs)\r\n   1376 \r\n   1377   def _merge_call(self, merge_fn, args, kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _merge_call(self, merge_fn, args, kwargs)\r\n   1380         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\r\n   1381     try:\r\n-> 1382       return merge_fn(self._strategy, *args, **kwargs)\r\n   1383     finally:\r\n   1384       _pop_per_thread_mode()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py in merge_fn(strategy, v, value)\r\n     99         value = strategy.extended.reduce_to(\r\n    100             ds_reduce_util.ReduceOp.MEAN, value, v)\r\n--> 101         return strategy.extended.update(v, update_fn, args=(value,))\r\n    102 \r\n    103       return replica_context.merge_call(merge_fn, args=(variable, value))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in update(self, var, fn, args, kwargs, group)\r\n   1173     if kwargs is None:\r\n   1174       kwargs = {}\r\n-> 1175     return self._update(var, fn, args, kwargs, group)\r\n   1176 \r\n   1177   def _update(self, var, fn, args, kwargs, group):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _update(self, var, fn, args, kwargs, group)\r\n   1544     # The implementations of _update() and _update_non_slot() are identical\r\n   1545     # except _update() passes `var` as the first argument to `fn()`.\r\n-> 1546     return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\r\n   1547 \r\n   1548   def _update_non_slot(self, colocate_with, fn, args, kwargs, should_group):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _update_non_slot(self, colocate_with, fn, args, kwargs, should_group)\r\n   1550     # once that value is used for something.\r\n   1551     with ops.colocate_with(colocate_with), UpdateContext(colocate_with):\r\n-> 1552       result = fn(*args, **kwargs)\r\n   1553       if should_group:\r\n   1554         return result\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py in update_fn(v, value, decay)\r\n     85       decay = math_ops.cast(decay, v.dtype.base_dtype)\r\n     86     if zero_debias:\r\n---> 87       update_delta = _zero_debias(v, value, decay)\r\n     88     else:\r\n     89       update_delta = (v - value) * decay\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py in _zero_debias(unbiased_var, value, decay)\r\n    204   \"\"\"\r\n    205   with variable_scope.variable_scope(\r\n--> 206       unbiased_var.op.name, values=[unbiased_var, value, decay]) as scope:\r\n    207     with ops.colocate_with(unbiased_var):\r\n    208       with ops.init_scope():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in op(self)\r\n    932   def op(self):\r\n    933     raise AttributeError(\r\n--> 934         \"Tensor.op is meaningless when eager execution is enabled.\")\r\n    935 \r\n    936   @property\r\n\r\nAttributeError: Tensor.op is meaningless when eager execution is enabled.\r\n```\r\n\r\nMy purpose is to customize the batch normalization layer. And I refer to this document : https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py#L16\r\n\r\nI think that this error is caused by K.moving_average_update. Tensorflow 2.0 is not allowed K.moving_average_update api? I found this api in tf 2.0 docs. \r\n\r\nHow can I solve this error?", "comments": ["tf.keras Backend Uses TF Variables to perform the Moving Average. However in eager mode, A lot of functionalties are either not implemented or are avoided, in EagerTensor Class. As shown Here.\r\nhttps://github.com/tensorflow/tensorflow/blob/9b0656f8ac36124ffe928d295be2c8b9d080c643/tensorflow/python/framework/ops.py#L956-L996\r\nSo, the following error is being raised.\r\n", "Should I costumize only this api to customize the batchnormalization layer on tensorflow 2.0?https://github.com/tensorflow/tensorflow/blob/8d24f6ae5cffbb1e23e02e5ac14f15b5f3ab6414/tensorflow/python/keras/layers/normalization.py#L42\r\n\r\nI think that this api is difficult.\r\n", "This API is Still in Alpha Stage. So, it is supposed to have tons of Bugs. All of these are supposed to get fixed by the community and the tensorflow team before the final release.", "If I use my custom batch normalization right now, do you think that I should use this api?\r\n\r\n```shell\r\ntf.compat.v1.disable_eager_execution()\r\n```", "> If I use my custom batch normalization right now, do you think that I should use this api?\r\n> \r\n> ```shell\r\n> tf.compat.v1.disable_eager_execution()\r\n> ```\r\n\r\nI did some more digging. and found that yes you can do it. But you, missed a very important part.\r\n`moving_average_update` asks for `Mutable Tensors`, also known as *variables*.\r\nSo, you need to type cast the mean\r\n```python3\r\nmoving_mean = tf.Variable(K.reshape(self.moving_mean, broadcast_shape)) \r\nmean = tf.Variable(K.reshape(K.mean(inputs, axis=reduction_axes), broadcast_shape))\r\nupdate_list = []\r\nupdate_list.append(K.moving_average_update(moving_mean, mean, self.momentum))\r\n```\r\n\r\nthis does the job, but you need to disable eager by the above stated method at first. I'm looking into the issue why it is not supported in Eager. But for the time being, this is your work around.\r\n\r\n\r\n\r\n-------------------------------------------\r\n**EDIT**:\r\nThis issue is already resolved in the master branch. The error is caused when a call was being made to variable.op.name (in r2.0.0a). However in the master branch, I saw the same file, with the bug fixed.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2c2d508aa2947ede05cfa195139b176d6cdc9056/tensorflow/python/training/moving_averages.py#L206\r\n\r\nVS\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/71eb168f453bd035df4d8ba27383ef53527e3aaa/tensorflow/python/training/moving_averages.py#L206", "@captain-pool  Thank you for your kindness. \r\n\r\nAll arguments(ex. mean, var, moving_mean_or_var) of ```moving_average_update()``` are should be mutable Tensor, so I must use tf.Variable to them, right?  And gamma, beta etc... they be just 'tensor' (like tf.Tensor).\r\n\r\n---------------------------------------------------------------------\r\nYou said 2.0.0-alpha has this issue, but master branch is already fixed it.  I also found this. Thank you. I'm just waiting to be updated.\r\n ", "> @captain-pool Thank you for your kindness.\r\n> \r\n> All arguments(ex. mean, var, moving_mean_or_var) of `moving_average_update()` are should be mutable Tensor, so I must use tf.Variable to them, right? And gamma, beta etc... they be just 'tensor' (like tf.Tensor).\r\n> \r\n> You said 2.0.0-alpha has this issue, but master branch is already fixed it. I also found this. Thank you. I'm just waiting to be updated.\r\n\r\n\r\n\r\n@DevKiHyun , Yep, Rest of the things like Gamma, Beta can be Tensor or Just simply numpy arrays. I'ld suggest you to edit that specific line in your installed package folder. That should fix your issue.\r\nPRO Tip: Follow the Traceback, when the error occurs. The 2nd Last Error, has the file name in it. Open Up that file, go to Line 206 and replace `unbiased_var.op.name` with the line from above. That will solve the issue for you.\r\n", "I followed your advice.\r\n\r\n```shell\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import initializers\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.python.ops import variables as tf_variables\r\nprint(tf.__version__)\r\n\r\n\r\nclass CustomLayer(tf.keras.layers.Layer):\r\n  def __init__(self, \r\n               momentum=0.9, \r\n               epsilon=1e-4,\r\n               axis = -1,\r\n               beta_initializer='zeros',\r\n               gamma_initializer='ones',\r\n               moving_mean_initializer='zeros',\r\n               **kwargs):\r\n    \r\n    super(CustomLayer, self).__init__(**kwargs)\r\n    self.momentum = momentum\r\n    self.epsilon = epsilon\r\n    self.axis = axis\r\n    self.beta_initializer = initializers.get(beta_initializer)\r\n    self.gamma_initializer = initializers.get(gamma_initializer)\r\n    self.moving_mean_initializer = initializers.get(moving_mean_initializer)\r\n\r\n  def build(self, input_shape):\r\n    param_shape = input_shape[-1]\r\n\r\n    self.beta = self.add_weight(shape=param_shape,\r\n                                name='beta',\r\n                                initializer=self.beta_initializer)\r\n\r\n    self.gamma  = self.add_weight(shape=param_shape,\r\n                                      name='gamma',\r\n                                      initializer=self.gamma_initializer)\r\n                                                      \r\n    self.moving_mean = self.add_weight(shape=param_shape,\r\n                                            name='moving_mean',\r\n                                            initializer=self.moving_mean_initializer,\r\n                                            synchronization=tf_variables.VariableSynchronization.ON_READ,\r\n                                            aggregation=tf_variables.VariableAggregation.MEAN,\r\n                                            trainable=False)\r\n    \r\n  def call(self, inputs, training=None):\r\n    input_shape = K.int_shape(inputs)\r\n    boundary_axis = 1\r\n    ndim = len(input_shape)\r\n    \r\n    reduction_axes = list(range(ndim))\r\n    for i in range(1): del reduction_axes[self.axis]\r\n    \r\n    broadcast_shape = [1] * ndim\r\n    broadcast_shape[self.axis] = input_shape[self.axis]\r\n    \r\n    mean = tf.Variable(K.reshape(K.mean(inputs, axis=reduction_axes), broadcast_shape))\r\n    \r\n\r\n    update_list = []\r\n    update_list.append(K.moving_average_update(K.reshape(self.moving_mean, broadcast_shape), mean, self.momentum))\r\n    self.add_update(update_list, inputs)\r\n    \r\n    return K.in_train_phase(1, 0,\r\n                                          training=training) \r\n\r\na = tf.constant(np.random.randn(128,224,224,3), dtype=tf.float32)\r\ncustom_layer_1 = CustomLayer()(a)\r\n\r\nprint(custom_layer_1)\r\n```\r\n\r\nI refer to this code to make ```mutable variable```.\r\nhttps://github.com/tensorflow/tensorflow/blob/8d24f6ae5cffbb1e23e02e5ac14f15b5f3ab6414/tensorflow/python/keras/layers/normalization.py#L377-L385\r\n\r\nIt's okay? \r\nIf this code is incorrect, I will use the tf.Variable function.\r\n\r\n-------------------------------------------------------------------\r\nI want to edit the package code, but I use 'Colab'. So, I can't edit package. But, I found solution to this issue('Eager Mode'), now this issue is no problem. ", "Closing this issue, since we have found a work around. Feel free to reopen if have any further problems. Thanks!"]}, {"number": 27738, "title": "change format of references", "body": "change format of references, add link to paper in descriptive text, set italic for quote.", "comments": ["@mosesmarin can you please fix ubuntu sanity build failures.", "fixed ubuntu sanity build failures.", "Added commit to split long line"]}, {"number": 27737, "title": "Disable one more macos test for python35", "body": "Only py2 and wingpus left after this", "comments": []}, {"number": 27736, "title": "fix indent for python formatting", "body": "fix indent for python formatting", "comments": []}, {"number": 27735, "title": "TF utils_test additional test cases covers", "body": "1- constant_value api test case\r\n2- get_reachable_from_inputs api test case", "comments": ["@alextp \r\nthanks for help to reproduce build error case.\r\n\r\n@fchollet \r\ncompilation error is fixed here."]}, {"number": 27734, "title": "Update README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27734) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27734) for more info**.\n\n<!-- ok -->"]}, {"number": 27733, "title": "Remove numerics check from clip_by_global_norm", "body": "This changes clip_by_global_norm to return all NaNs instead of throwing an error when global_norm == infinity.\r\n\r\nThis is the only op in TF that throws an error like this, and it is problematic for (at least) a couple of reasons:\r\na) it breaks the TF-Debugger workflow, and\r\nb) it breaks automatic loss scaling.\r\n\r\nIt appears that this was in fact the original plan in https://github.com/tensorflow/tensorflow/pull/21428, but it was changed at the last minute to throw an error instead of returning NaNs.\r\n\r\nFYI @reedwm @tfboyd ", "comments": ["Thanks for the change!\r\n\r\nFYI @danijar @facaiy", "If I remember correctly, we think tf.where might hurt performance in most cases (`use_norm != inf`). That's why we replace it by assertion. ", "tf.where may have less overhead than verify_tensor_all_finite. Do you know of any benchmarks to verify?", "At worst this will be one additional op acting on a scalar value, which I imagine (if any slower at all) is well worth the usability improvements.", "> tf.where may have less overhead than verify_tensor_all_finite. Do you know of any benchmarks to verify?\r\n\r\nI'm afraid that we didn't test it on any benchmarks. Anyway, I have no object about the change. Thanks, Ben, Reed."]}, {"number": 27732, "title": "When test\uff0c An exception has occurred, use %tb to see the full traceback.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I download code from https://github.com/tegg89/SRCNN-Tensorflow\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 64 bits\r\n- TensorFlow installed from (source or binary): anaconda3 64bits  conda install\r\n- TensorFlow version (use command below): tensorflow-gpu 1.13.1\r\n\r\n- Python version: 3.6.8  spyder 3.3.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0.130  cudnn 7.3.1 installed via conda with tensorflow together\r\n- GPU model and memory: notebook gtx1060 3GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n![image](https://user-images.githubusercontent.com/41459859/55927092-bd9e8d80-5c4e-11e9-9b88-afa87c4d1717.png)\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nrunfile('F:/F_coding/other/SRCNN-Tensorflow-master/main.py', wdir='F:/F_coding/other/SRCNN-Tensorflow-master')\r\nC:\\Users\\myaccount\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n{'batch_size': <absl.flags._flag.Flag object at 0x000001A7E0DF4518>,\r\n 'c_dim': <absl.flags._flag.Flag object at 0x000001A7E6D0C390>,\r\n 'checkpoint_dir': <absl.flags._flag.Flag object at 0x000001A7E6D0C588>,\r\n 'epoch': <absl.flags._flag.Flag object at 0x000001A7E0DDEC18>,\r\n 'h': <tensorflow.python.platform.app._HelpFlag object at 0x000001A7E6D0C710>,\r\n 'help': <tensorflow.python.platform.app._HelpFlag object at 0x000001A7E6D0C710>,\r\n 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x000001A7E6D0C780>,\r\n 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x000001A7E6D0C7F0>,\r\n 'image_size': <absl.flags._flag.Flag object at 0x000001A7E0DF4908>,\r\n 'is_train': <absl.flags._flag.BooleanFlag object at 0x000001A7E6D0C630>,\r\n 'label_size': <absl.flags._flag.Flag object at 0x000001A7E175F6D8>,\r\n 'learning_rate': <absl.flags._flag.Flag object at 0x000001A7E6AABBE0>,\r\n 'sample_dir': <absl.flags._flag.Flag object at 0x000001A7E6D0C5F8>,\r\n 'scale': <absl.flags._flag.Flag object at 0x000001A7E6D0C438>,\r\n 'stride': <absl.flags._flag.Flag object at 0x000001A7E6D0C4E0>}\r\nWARNING:tensorflow:From D:\\scholarship\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From D:\\scholarship\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\n [*] Reading checkpoints...\r\nWARNING:tensorflow:From D:\\scholarship\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from checkpoint\\srcnn_21\\SRCNN.model-2550000\r\n [*] Load SUCCESS\r\nTesting...\r\nAn exception has occurred, use %tb to see the full traceback.\r\n![image](https://user-images.githubusercontent.com/41459859/55927114-d1e28a80-5c4e-11e9-8537-53bf878702d3.png)\r\n\r\n\r\nSystemExit\r\n\r\n**Describe the expected behavior**\r\nidk\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. \r\n\r\nThis is more related to an issue with another repository. So please post in that [repo](https://github.com/tegg89/SRCNN-Tensorflow/issues) or in Stackoverflow. Thanks!", "I am closing this issue as it is a support questions more suited for Stackoverflow. Thanks!"]}, {"number": 27731, "title": "Implement unidirectional sequence GRU kernel.", "body": "Implement unidirectional sequence GRU kernel supporting float eval, and add basic unit tests.", "comments": ["> lgtm, but wait for Jian's review as well\r\n\r\n@jianlijianli gentle ping  "]}, {"number": 27730, "title": "freezed pb Convert to tflite, ValueError: NodeDef mentions attr 'half_pixel_centers' not in Op<name=ResizeBilinear ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13,1.14\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.2, cudnn7\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nwhen convert freezed pb to tflite, the following problem happened:\r\n\r\nValueError: NodeDef mentions attr 'half_pixel_centers' not in Op<name=ResizeBilinear; signature=images:T, size:int32 -> resized_images:float; attr=T:type,allowed=[DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=align_corners:bool,default=false>; NodeDef: {{node ResizeBilinear}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\r\nAnyone has any ideas to solve it ?\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I already tried TF slim and tf layers, both of them have this issue? anyone can help?\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 27729, "title": "Make sure the executor type same when recursively creating items for a function", "body": "This PR makes sure the executor types are the same when multiple items are recursively created for a function. \r\n\r\nIt fixes a timeout issue in the `ParallelMapDatasetOp` tests. I'm not sure my understanding is correct. \r\n\r\nTaken [TestCase7](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/parallel_map_dataset_op_test.cc#L220) as an example, it sets `num_parallel_calls` as same as `thread_num` of `thread_pool_` while `use_inter_op_parallelism = false`. Two items with different types of executor are created for the function `XTimesFour` and `XTimesTwo`, where `XTimesFour` call `XTimesTwo` internally. The executor type of `XTimesFour` is `SINGLE_THREADED_EXECUTOR` and that of `XTimesTwo` is `Default`. This inconsistency causes a timeout issue when running the `XTimesFour` function inside `SingleThreadedExecutorImpl::RunAsync` which calls `ExecutorImpl::RunAsync` to run `XTimesTwo`, because there is no more availale resournce in `thread_pool_` to run `XTimesTwo` in `ExecutorImpl::RunAsync`. \r\n\r\ncc: @jsimsa ", "comments": ["@mrry do you have thoughts on this CL?", "To be clear, I am asking about whether the fact we are not propagating the executor type through recursive kernel creation is a bug.\r\n\r\nIf so, I will take care of reviewing this PR.", "Yes, I think it makes sense to have this as the default behavior.", "@feihugis I synced with @mrry offline and the conclusion we arrived at is that the behavior you are seeing is expected (single threaded executor has only one thread of execution, which means that it will hang if you are trying execute a graph that requires a multiple threads (e.g. because some ops block on other ops).\r\n\r\nIn other words, your test is expected to hang and you should instead use a different test function (for which the execution does not hang).", "@jsimsa and @mrry Thanks for your explanation! Yeah, when debugging, I saw the ops in the single threaded executor are blocked on the other ops running in the default executor (class ExecutorImpl). The test_case_7 hangs with the parameters `num_parallel_calls = 2, thread_num = 2, use_inter_op_parallelism = false, MapFunc = XTimesFour`. After increasing `thread_num` to be 3, the [test_case_7](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/parallel_map_dataset_op_test.cc#L220) can work. It looks like that the single threaded executor can call the default executor to run some ops, but whether it hangs will depend on the available resource in the thread_pool.\r\n\r\nAnother thing is that whether it is on purpose that the executor type is not propagated through recursive kernel creation?", "Can one of the admins verify this patch?", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27728, "title": "Decoupling preprocessing and training", "body": "**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, TensorFlow performs preprocessing and training on the same host. In situations where the data preprocessing is efficient and yet the CPU resources available on the host are not sufficient to keep up with the training workload on the accelerator, the preprocessing becomes a bottleneck. \r\n\r\nThe proposed feature is to extend the tf.data / tf.distribute APIs to make it possible to decouple the preprocessing from training.\r\n\r\n**Will this change the current api? How?**\r\n\r\nYes. In the least, the users will need to specify the set of \"input\" hosts that should perform the preprocessing and the set of \"training\" hosts to perform the training. \r\n\r\nThe preferred solution would allow users to express their input pipeline in tf.data as if it was executing on the same host as training and through the means of tf.data / tf.distribute configuration express how it should be distributed.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nUsers that execute preprocessing intensive training jobs.", "comments": ["As per tf's doc, users cannot perform any transformations after using tf.strategy.experimental_distribute_dataset() to transfer a normal tf dataset into a dataset for distributed training [https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#experimental_distribute_dataset](url). Moreover, what is often in my case is that I need to perform data augmentation in each global minibatch, rather than the entire training set, of the data. \r\nFor example in medical image segmentation, I need to randomly distort one 4D CT/MRI images in each global minibatch before feeding them into a model for forward propagation. The pesudo code is like this\r\n```\r\n    for ep in np.arange(0, epoch):\r\n        # Each step crosses one minibatch\r\n        for rawDataperGlbMB in enumerate(dsTrain):\r\n            # Augment data from a minibatch of raw data in reshuffled dsTrain\r\n            data = dataAugmentation(rawDataperGlbMB, ...)\r\n\t    prediction = myModel(data)\r\n\r\n```\r\nTherefore, when using tf.distribute.MirroredStrategy(), how to achieve that? Also, how to do reshuffling prior to each epoch?\r\nFurthermore, if operations in my data augmentation function cannot be performed by using tf functions, but by using numpy and scipy functions (since tf functions are not sufficiently rich), can I transform rawDataperGlbMB back into numpy arrays, do the augmentations, then transform the result back into tensors, in the distributed context as I did in the non-distributed training?\r\nThanks.", "From tf's Youtube tutorial, I became aware that tf.py_function can be used for data augmentation for each replica, yet if I write code as follows:\r\n```\r\n            for dataPerReplica in ds:\r\n\t\ttf.py_function(dataAugFuncPython, dataPerReplica, augdataPerReplica )\r\n                lossPerReplica, accPerReplic = strategy.run(trainOneReplica, args=(augdataPerReplica,,))\r\n                totalLoss += strategy.reduce(tf.distribute.ReduceOp.SUM, lossPerReplica, axis=None)\r\n                totalAcc += strategy.reduce(tf.distribute.ReduceOp.SUM, accPerReplic, axis=None)\r\n```\r\nwhere dataAugFuncPython is the name of my augmentation function in python, and trainOneReplica is the name of function for one training step. \r\nMy question is: \r\n1) if dataAugFuncPython contains random variable generator, which is often the case for data augmentation, can @tf.function be decorated for the function to train the replica?\r\n2) will the SAME augmented data (augdataPerReplica) in one replica be passed to all GPU's? If so, the data augmentation will become meaningless. Or will data in each replica will be augmented differently automatically? ", "@yourtheron your question is better suited to be posted on Stack Overflow. Github is meant to be used for reporting bugs or requesting functionality. I am also going to close this feature request as it has been addressed by [tf.data service](https://github.com/tensorflow/community/pull/195), which was released in TF 2.3."]}, {"number": 27727, "title": "Disable 3 tests which fail on tf 1.12.1.", "body": "", "comments": []}, {"number": 27723, "title": "Title of paper as clickable link", "body": "", "comments": ["added commit to fix ubuntu sanity failure (line-too-long)"]}, {"number": 27722, "title": "Edit source as clickable link", "body": "", "comments": []}, {"number": 27721, "title": "Title of paper as clickable link", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27721) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27721) for more info**.\n\n<!-- ok -->"]}, {"number": 27720, "title": "How i upgrade tensorflow 1.13.1 to 1.4.0 in window(without GPU)", "body": "i want to upgrade tensroflow 1.13.1 to 1.4.0 in window 10 without GPU \r\ni upgrade it but it stop 1.13.1. \r\nis this possible for me to reach 1.4.0 tensorflow version,\r\n if it is then hoW?", "comments": ["You can try building the TensorFlow package from source for windows using the link [https://www.tensorflow.org/install/source_windows]. \r\nThe build is tested for tensorflow-1.4.0 on CPU:\r\n\r\n<img width=\"740\" alt=\"Screen Shot 2019-04-11 at 5 49 18 PM\" src=\"https://user-images.githubusercontent.com/43215312/55995373-54387200-5c82-11e9-8fcf-68e72ab30611.png\">\r\n", "Is this still an issue ? Please let us know. Thanks!", "> Is this still an issue? Please let us know. Thanks!\r\n\r\nyes, still there is an issue.\r\nI am not able to update tensorflow.", "Clarification, you want to **downgrade** from 1.13 to 1.4 ?  Why move to so old of a version?\r\n\r\n1.14 is not finished yet. 1.13.1 is the latest version. \r\n\r\nThe way to do it would be:\r\n```\r\npip uninstall tensorflow\r\npip install tensorflow==1.4.0\r\n```", "Moving to older versions might lead to compatibility issues. We recommend to stay with the latest version unless and until it is required. You can try above solution provided and let us know on the update. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 27719, "title": "tf-nightly-2.0-preview's tf.summary doesn't work with tensorboard", "body": "**System information**\r\n- Have I written custom code: no\r\n- OS: macOS 10.14.4\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.0.0-dev20190410 (latest nightly)\r\n- Python version: 3.6.7 (miniconda)\r\n\r\n**Current behavior & code to reproduce the issue**\r\n\r\nThe following code\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\nsummary_writer = tf.summary.create_file_writer(\"tmp\")\r\n\r\nwith summary_writer.as_default():\r\n    for i in range(100):\r\n        tf.summary.scalar(\"index\", i, step=i)\r\nsummary_writer.close()\r\n```\r\n\r\noutputs an events file to `/tmp` but trying to view it with `tensorboard --logdir ./tmp`  throws\r\n```\r\nException in thread Reloader:\r\nAttributeError: module 'tensorflow._api.v2.compat.v1' has no attribute 'pywrap_tensorflow'\r\n```\r\nfollowed by\r\n```\r\nW0410 17:26:13.712886 123145489154048 core_plugin.py:172] Unable to get first event timestamp for run .: No event timestamp could be found\r\n```\r\nand an empty TB dashboard. I'm running the latest `tb-nightly`. Any ideas what's causing this?\r\n\r\n**Perhaps related:**\r\n- #27713", "comments": ["Closing this in favor of the tensorboard issue, https://github.com/tensorflow/tensorboard/issues/2106", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27719\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27719\">No</a>\n"]}, {"number": 27718, "title": "Update optimized_ops.h", "body": "Use GetReciprocal to replace the 1/(1+x) logic.", "comments": ["I don't understand how these two implementations are equivalent", "Thanks for the comment. The logic is given in the link below:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/reference/softmax.h#L105-L107\r\n"]}, {"number": 27717, "title": "Fix link to TF-TRT docs", "body": "", "comments": []}, {"number": 27716, "title": "Distribution strategies and conditional parameters update fails with \"Operation has been marked as not fetchable\"", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: `2.0.0a0`\r\n- Python version: 3.5.2\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using conditional parameters update and a distribution strategy in graph mode, the first `sess.run` fails with the error:\r\n\r\n> \"Operation '*' has been marked as not fetchable.\"\r\n\r\n**Describe the expected behavior**\r\n\r\nDistribution strategies should support conditional parameters update.\r\n\r\n**Code to reproduce the issue**\r\n\r\nI tried to compile a small and representative snippet that is the base logic for gradient accumulation:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef train_op(accum_steps=None):\r\n    step = tf.Variable(initial_value=0, dtype=tf.int32, trainable=False)\r\n    optimizer = tf.optimizers.SGD(learning_rate=0.1)\r\n    variables = [tf.Variable(tf.zeros([4, 5], dtype=tf.float32))]\r\n    gradients = [tf.Variable(tf.ones([4, 5], dtype=tf.float32), trainable=False)]\r\n    if accum_steps is None:\r\n        return optimizer.apply_gradients(zip(gradients, variables))\r\n    else:\r\n        return tf.cond(\r\n            tf.equal((step + 1) % accum_steps, 0),\r\n            true_fn=lambda: optimizer.apply_gradients(zip(gradients, variables)),\r\n            false_fn=tf.no_op)\r\n\r\ndevices = [\"/gpu:2\", \"/gpu:3\"]\r\nstrategy = tf.distribute.MirroredStrategy(devices=devices)\r\n#strategy = tf.distribute.OneDeviceStrategy(device=devices[0])\r\naccum_count = 8\r\n\r\nwith tf.Graph().as_default():\r\n    with strategy.scope():\r\n        train_op = strategy.extended.call_for_each_replica(train_op, args=(accum_count,))\r\n\r\n    config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\r\n    with tf.compat.v1.Session(config=config) as sess:\r\n        sess.run(tf.compat.v1.global_variables_initializer())\r\n        _ = sess.run(train_op)\r\n```\r\n\r\nThe above code does not fail if `OneDeviceStrategy` is used or `accum_count` is set to `None`.\r\n\r\n**Other info / logs**\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"cond_apply.py\", line 27, in <module>\r\n    sess.run(tf.compat.v1.global_variables_initializer())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 930, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1138, in _run\r\n    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 480, in __init__\r\n    self._assert_fetchable(graph, fetch)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 497, in _assert_fetchable\r\n    'Operation %r has been marked as not fetchable.' % op.name)\r\nValueError: Operation 'init' has been marked as not fetchable.\r\n```\r\n\r\n---\r\n\r\nFor an additional context, I'm porting a code from V1 `tf.estimator` and manual graph replication to V2 `tf.estimator` and distribution strategies. I'm struggling to port the gradient accumulation code that [we have working in V1](https://github.com/OpenNMT/OpenNMT-tf/blob/v1.22.0/opennmt/utils/optim.py#L199-L261). ", "comments": ["So this is not straightforward. Here is the adapted code to run within a distribution strategy:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef train_op():\r\n    step = tf.Variable(\r\n        0,\r\n        dtype=tf.int32,\r\n        trainable=False,\r\n        aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\r\n    optimizer = tf.optimizers.SGD(learning_rate=1)\r\n    variables = [tf.Variable(tf.zeros([], dtype=tf.float32))]\r\n    gradients = [tf.ones_like(var) for var in variables]\r\n    with tf.init_scope():\r\n        train_op = tf.cond(\r\n            tf.equal((step + 1) % 4, 0),\r\n            true_fn=lambda: optimizer.apply_gradients(zip(gradients, variables)),\r\n            false_fn=tf.no_op)\r\n        with tf.control_dependencies([train_op]):\r\n            train_op = tf.group(train_op, step.assign_add(1))\r\n    return train_op, variables\r\n\r\ndevices = [\"/gpu:1\", \"/gpu:2\"]\r\nstrategy = tf.distribute.MirroredStrategy(devices=devices)\r\n#strategy = tf.distribute.OneDeviceStrategy(device=devices[-1])\r\n\r\nwith tf.Graph().as_default():\r\n    with strategy.scope():\r\n        train_op, variables = strategy.extended.call_for_each_replica(train_op)\r\n\r\n    with tf.init_scope():\r\n        train_op = strategy.unwrap(train_op)\r\n        init_op = tf.compat.v1.global_variables_initializer()\r\n    config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\r\n    with tf.compat.v1.Session(config=config) as sess:\r\n        sess.run(init_op)\r\n        for _ in range(10):\r\n            _, var = sess.run((train_op, variables[0]))\r\n            print(var)\r\n```\r\n\r\nNotes:\r\n\r\n* the variable initializer op has to be defined under `tf.init_scope`\r\n* the conditional training op has to be defined under `tf.init_scope`\r\n* the training op has to be `unwrap` before calling `sess.run`\r\n\r\nI'm interested in hearing some feedback from a TensorFlow member regarding the code above.\r\n\r\nI would also like to know if this approach is expected to be supported by `tf.estimator`. If not, this could make the transition to TF2.0 more painful.", "The error in your original code is arising due to the fact that you have an `apply_gradients` call inside the tf.cond. `apply_gradients` when in a distribution strategy context would call a method called `merge_call` on the strategy object, which tries to execute some synchronization code, in this case it would be reducing the gradients across replicas, and updating the variables.\r\nPutting this code inside a merge_call is not very well supported. An alternative for this is to move the entire tf.cond inside a merge_call. Here is some code to illustrate this. \r\n\r\nIf you currently have some something like:\r\n```\r\ndef f():\r\n  return optimizer.apply_gradients(a, ...)  # can execute merge_call\r\n\r\ndef g():\r\n  return tf.no_op\r\n\r\ndef h():  # executed once per replica in a replica context\r\n  return tf.cond(..., f, g)\r\n```\r\n\r\nthen you would rewrite it to evaluate the condition once across all replicas:\r\n\r\n```\r\ndef f():  # as before\r\n  return optimizer.apply_gradients(a, ...)\r\n\r\ndef g():  # as before\r\n  return tf.no_op\r\n\r\n# f1/g1 switch from cross-replica context to replica context and call f/g\r\ndef f1():\r\n  return strategy.extended.call_for_each_replica(f)\r\n\r\ndef g1():\r\n  return strategy.extended.call_for_each_replica(g)\r\n\r\n# gets evaluated once in a cross-replica context\r\ndef h1():\r\n  return tf.cond(..., f1, g1)\r\n\r\n# called in a replica context once per replica, uses merge_call to call h1 once\r\ndef h():\r\n  return tf.distribute.get_replica_context.merge_call(h1)\r\n```\r\n\r\nThanks @josh11b for this code snippet.\r\n\r\nHope this helps. \r\n\r\n\r\n", "Awesome explanation @guptapriya.  Please re-open if you'd like more help.  We are looking internally on improving the error message. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27716\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27716\">No</a>\n"]}, {"number": 27715, "title": "Tensorflow Docker: Failed to get a convolutional algorithm. This is probably because cuDNN failed to initialize. ", "body": "Hey all, \r\n\r\nI saw that there are already some issues regarding` Failed to get convolutional algorithm. This is probably because cuDNN failed to initialize, so try look to see if a warning log message was printed above. ` Probably this error is caused by an incompatibility of cuDNN or so. However, I am working within an Docker image. I run `nvidia-docker run -it -v home_Path:container_path --rm tensorflow/tensorflow:latest-gpu-py3 ` and inside this image i run a Faster R-CNN code. The first two/three times everything worked well but afterwards every time this error is printed and the programm stops running. Even if I restart the container (by exiting and executing the same command another time), this error appear.  \r\n\r\nI hope you guys can help me. I am struggling since days with this problem and I have really no clue what's the problem or how to solve it. \r\n\r\n\r\nThanks a lot in advance. \r\n------------------------------------------------------------------------------------------------------\r\nOutput: \r\n\r\n\r\n`../Lib/faster_rcnn_config.py:313: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n  yaml_cfg = edict(yaml.load(f))\r\nRestoring from Cityscapes.yml file\r\n{'seed': 1234, 'restore_slim_file': '/root/OD/tf-Faster-RCNN/Data/ResNet50/resnet_v1_50.ckpt', 'num_epochs': 5, 'file_epoch': 1, 'run_num': 31, 'restore': False, 'restore_num': 1, 'batch_size': 1, 'data_directory': '/root/OD/tf-Faster-RCNN/Data/Cityscapes_for_FasterRCNN_REDUCED_REDUCED_imagesize/', 'save_directory': '../Logs/', 'gpu': 0, 'vis': False, 'display_step': 1000, 'learning_rate': 0.003, 'model_directory': 'Cityscapes/'}\r\nUsing GPU 0\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nTensor(\"model/resnet_v1_50/block3/unit_6/bottleneck_v1/Relu:0\", shape=(1, ?, ?, 1024), dtype=float32)\r\nconv_1 output: (1, ?, ?, 512)\r\nconv_1 output: (1, ?, ?, 18)\r\nWARNING:tensorflow:From ../Networks/anchor_target_layer.py:40: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, use\r\n    tf.py_function, which takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means 'tf.py_function's can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    \r\nconv_1 output: (1, ?, ?, 36)\r\nWARNING:tensorflow:From ../Lib/roi_pool.py:31: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nDeprecated in favor of operator or tf.math.divide.\r\nflat_1 output: (?, 50176)\r\nWARNING:tensorflow:From ../Lib/TensorBase/tensorbase/base.py:274: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use 'rate' instead of 'keep_prob'. Rate should be set to 'rate = 1 - keep_prob'.\r\nfc_1 output: (?, 4096)\r\nfc_2 output: (?, 4096)\r\nfc_1 output: (?, 4)\r\nfc_1 output: (?, 16)\r\nTensor(\"model_1/resnet_v1_50/block3/unit_6/bottleneck_v1/Relu:0\", shape=(1, ?, ?, 1024), dtype=float32)\r\nconv_1 output: (1, ?, ?, 512)\r\nconv_1 output: (1, ?, ?, 18)\r\nconv_1 output: (1, ?, ?, 36)\r\nflat_1 output: (?, 50176)\r\nfc_1 output: (?, 4096)\r\nfc_2 output: (?, 4096)\r\nfc_1 output: (?, 4)\r\nfc_1 output: (?, 16)\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.cast instead.\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n2019-04-10 15:29:35.327116: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7d5c080 executing computations on platform CUDA. Devices:\r\n2019-04-10 15:29:35.327156: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5\r\n2019-04-10 15:29:35.329004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3700305000 Hz\r\n2019-04-10 15:29:35.329289: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7dc5f20 executing computations on platform Host. Devices:\r\n2019-04-10 15:29:35.329312: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-04-10 15:29:35.329518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 7.76GiB freeMemory: 6.97GiB\r\n2019-04-10 15:29:35.329541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-04-10 15:29:35.493916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-04-10 15:29:35.493961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-04-10 15:29:35.493975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-04-10 15:29:35.494236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7871 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:04:00.0, compute capability: 7.5)\r\n2019-04-10 15:29:36.902368: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 7.69G (8253855488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\nRestoring TF-Slim Model.\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from /root/OD/tf-Faster-RCNN/Data/ResNet50/resnet_v1_50.ckpt\r\n2019-04-10 15:29:38.656957: W tensorflow/core/framework/allocator.cc:124] Allocation of 822083584 exceeds 10% of system memory.\r\n2019-04-10 15:29:38.879858: W tensorflow/core/framework/allocator.cc:124] Allocation of 822083584 exceeds 10% of system memory.\r\n2019-04-10 15:29:39.126316: W tensorflow/core/framework/allocator.cc:124] Allocation of 822083584 exceeds 10% of system memory.\r\n2019-04-10 15:29:39.343851: W tensorflow/core/framework/allocator.cc:124] Allocation of 822083584 exceeds 10% of system memory.\r\n2019-04-10 15:29:39.831089: W tensorflow/core/framework/allocator.cc:124] Allocation of 822083584 exceeds 10% of system memory.\r\nLearning Rate: 0.003000\r\nEpochs: 5\r\nNone\r\n{'seed': 1234, 'restore_slim_file': '/root/OD/tf-Faster-RCNN/Data/ResNet50/resnet_v1_50.ckpt', 'num_epochs': 5, 'file_epoch': 1, 'run_num': 31, 'restore_directory': '../Logs/Cityscapes/Model1/', 'restore': False, 'restore_num': 1, 'batch_size': 1, 'data_directory': '/root/OD/tf-Faster-RCNN/Data/Cityscapes_for_FasterRCNN_REDUCED_REDUCED_imagesize/', 'save_directory': '../Logs/', 'gpu': 0, 'vis': False, 'display_step': 1000, 'logging_directory': '../Logs/Cityscapes/Model31/', 'learning_rate': 0.003, 'model_directory': 'Cityscapes/'}\r\nTraining for 5 epochs\r\nepochs:   0%|                                                                                                                                                                                                                                                | 0/5 [00:00<?, ?it/s2019-04-10 15:29:41.114390: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally                                                                                                                     | 0/2096 [00:00<?, ?it/s]\r\n2019-04-10 15:29:41.140134: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.141836: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.143191: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.144476: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.154047: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.155242: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.157620: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.158772: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.161637: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.162776: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.165628: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.166792: E tensorflow/stream_executor/cuda/cuda_blas.cc:510] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-04-10 15:29:41.195178: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-04-10 15:29:41.197679: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node model/resnet_v1_50/conv1/Conv2D}}]]\r\n\t [[{{node model/roi_proposal/rpn_softmax/transpose_3}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"faster_rcnn_resnet50ish.py\", line 300, in <module>\r\n    main()\r\n  File \"faster_rcnn_resnet50ish.py\", line 293, in main\r\n    model.train()\r\n  File \"faster_rcnn_resnet50ish.py\", line 169, in train\r\n    summary = self._run_train_iter(feed_dict)\r\n  File \"faster_rcnn_resnet50ish.py\", line 137, in _run_train_iter\r\n    summary, _ = self.sess.run([self.merged, self.optimizer], feed_dict=feed_dict)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node model/resnet_v1_50/conv1/Conv2D (defined at ../Networks/resnet50_reduced.py:79) ]]\r\n\t [[node model/roi_proposal/rpn_softmax/transpose_3 (defined at ../Lib/rpn_softmax.py:46) ]]\r\n\r\nCaused by op 'model/resnet_v1_50/conv1/Conv2D', defined at:\r\n  File \"faster_rcnn_resnet50ish.py\", line 300, in <module>\r\n    main()\r\n  File \"faster_rcnn_resnet50ish.py\", line 291, in main\r\n    model = FasterRcnnRes50(flags, dictionary)\r\n  File \"faster_rcnn_resnet50ish.py\", line 44, in __init__\r\n    super().__init__(flags_input, flags_input['run_num'], vram=cfg.VRAM, restore=flags_input['restore_num'], restore_slim=flags_input['restore_slim_file'])\r\n  File \"../Lib/TensorBase/tensorbase/base.py\", line 676, in __init__\r\n    self._network()\r\n  File \"faster_rcnn_resnet50ish.py\", line 82, in _network\r\n    self._faster_rcnn(self.x['TRAIN'], self.gt_boxes['TRAIN'], self.im_dims['TRAIN'], 'TRAIN')\r\n  File \"faster_rcnn_resnet50ish.py\", line 93, in _faster_rcnn\r\n    feature_maps = resnet50_reduced(x)\r\n  File \"../Networks/resnet50_reduced.py\", line 79, in resnet50_reduced\r\n    net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py\", line 146, in conv2d_same\r\n    scope=scope)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1155, in convolution2d\r\n    conv_dims=2)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1058, in convolution\r\n    outputs = layer.apply(inputs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node model/resnet_v1_50/conv1/Conv2D (defined at ../Networks/resnet50_reduced.py:79) ]]\r\n\t [[node model/roi_proposal/rpn_softmax/transpose_3 (defined at ../Lib/rpn_softmax.py:46) ]]\r\n`\r\n", "comments": ["If it helps it generally occurs due to unreleased GPU memory form the previous session of training or GPU memory isn't sufficient for the network weights. As your code ran a few times then stopped it is probably the GPU memory is hogged. I would suggest checking the task manager to see GPU consumption before running the code and after. Also, try searching for how to release GPU memory.", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@bipinkc19 Thanks. How should I release GPU memory in case it is full? I added the code as mentioned here (https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-464910864) and it worked as expected. However, I tried it only once. Is this the solution, even for running the code in an docker container? \r\n\r\n@achandraa I see your point however, I mentioned I work with Docker and therefore, it should be independent from outer resources, or? \r\nI am working on a Linux machine (16.04) and I pull the latest Tensorflow-Docker image with the mentioned command `nvidia-docker run -it -v home_Path:container_path --rm tensorflow/tensorflow:latest-gpu-py3` - latest TF is 1.13.1 \r\nEverything that I have done happened inside this Nvidia-Docker container. ", "https://github.com/tensorflow/tensorflow/issues/24828#issuecomment-464960819. I think this one is good as it allows growth too. It shouldn't matter if you run it on docker or not. Also are you closing the session after running the code? Generally even when using ```with tf.Session() as sess:``` in jupyter notebooks, the memory isn't released. ", "Hello @bipinkc19 No i think i missed to close the session. The next time, this error occurs, I will try to add the line. Thanks a lot!", "@paviddavid : Are you still stuck in the issue ? Can you please let us know if the same is resolved ?", "@achandraa By adding the code I mentioned in previous comment helped me to not re-obtained the issue. For the moment, it works. ", "CUDA : 10.0.130\r\nTensorflow : 1.13.1\r\nIssue is solved by adding the codes below into the file.\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction=0.5\r\nsess = tf.Session(config=config)\r\n\r\nAnd the reason why the issue came out is that tensorflow will use nearlly all the memory of GPU in default, so, when other processes use some of the memory , it may cause that there is not enough memory for tensorflow to use. In my case, my GPU memory only has 7952M, and build a tensorflow device takes 7438M, only 514M memory left, and 500M memory is easy to run out. To limit memory for tensorflow, I use \"config.gpu_options.per_process_gpu_memory_fraction=0.5\" allocate 50% of memory to tf, then the tf device will only takes about 4611M memory and the issue is solved.\r\n", "I have the same issue. \r\nNothing like above solves it.\r\nTF 2.0 alpha0\r\nCUDA : 10.0.130\r\nCudnn 7.3.1\r\nFor some reason, Conv2D doesn't work", "I am getting the same error for tf.conv2d that never worked. So, it's not related to the memory. My dev env is also a docker (built according to https://www.tensorflow.org/install/docker) as follows:\r\n    Host OS: Ubuntu 18.04\r\n    GPU: RTX 2070\r\n    NVidia driver: 418.56\r\n    cuda ver: 10.1\r\n    Nvidia cuda docker image: nvidia/cuda:latest\r\n    The custom docker built based on tensorflow/tensorflow:latest-gpu-py3-jupyter.\r\n    tensorflow version: 1.13.1\r\n    running from jupyter notebook inside the docker container\r\n\r\nI couldn't find cuDNN library and its header file neither from my host OS env nor from Nvidia cuda docker container and the tensorflow:latest-gpu-py3-jupyter docker container. It seems that the docker images are missing the cudnn installation. Any help will be appreciated.\r\n\r\nChris", "@chris-opendata Sounds weird.. I am working under Ubuntu 16.04 and I used the docker image tensorflow/tensorflow:latest-gpu-py3 and it worked for me as expected. My Cuda is 10.0. Have you tried to verify cudnn in your image? nvcc --version could maybe help "]}, {"number": 27714, "title": "Convert freezed pb graph to tensorflow lite failed, problems:\"Check failed: dim_x == dim_y (8 vs. 48)Dimensions must match\"", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.2, cudnn7\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nwhen convert tofreezed pb to tflite, following problem happened:\r\n\r\nConverterError: TOCO failed. See console for info.\r\n2019-04-10 22:06:36.005315: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 473 operators, 617 arrays (0 quantized)\r\n2019-04-10 22:06:36.021194: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 473 operators, 617 arrays (0 quantized)\r\n2019-04-10 22:06:36.021657: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:118] Check failed: dim_x == dim_y (8 vs. 48)Dimensions must match\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fb89fd9c740 (most recent call first):\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/lib/python3.7/site-packages/absl/app.py\", line 300 in run\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/syshang/anaconda3/envs/tfnightly0410/bin/toco_from_protos\", line 10 in <module>\r\nAborted (core dumped)\r\n\r\n\r\n**Describe the expected behavior**\r\n", "comments": ["Anyone ideas to solve this problems? Thanks", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 27713, "title": "Tensorboard file writer not working any more after nightly build tf-nightly 1.14.1.dev20190410", "body": "I had to restart my script this morning and it automatically installs the latest nightly build of tensorflow (no other changes)\r\n\r\nUnfortunately the file write doesn't produce any output anymore.\r\nYesterday with build 2.0.0-dev20190405 it worked just fine.\r\n\r\n**System information**\r\n- Colab with tf-nightly 1.14.1.dev20190410 and w.o. HW acceleration\r\n- installed with !pip install tf-nightly-2.0-preview\r\n\r\n**Describe the current behavior**\r\nTensorboard File Writer does not create any output files. The folder itself is still created.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nwriter = tf.summary.create_file_writer(TENSORBOARD_LOG)               \r\nwith writer.as_default():\r\n    tf.summary.scalar('running_reward', running_reward,current_run)\r\n    for w in self.model.trainable_variables:\r\n        tf.summary.histogram(name=w.name, data=w, step=current_run)\r\n\r\n```\r\n\r\n", "comments": ["@markste-in Thanks for the report.  I'm not able to reproduce this with `tf-nightly-2.0-preview==2.0.0.dev20190416`.\r\n\r\nIf you're still experiencing the issue, could you provide the contents of `pip freeze` in the environment where you are running the code?  I'm not totally clear from your description whether you installed `tf-nightly`, `tf-nightly-2.0-preview`, or both (and which versions).  If you're using the 2.0 preview, it's best to `pip uninstall tf-nightly` first, and also make sure you're using an up-to-date tensorboard nightly (via `pip install -U tb-nightly`).", "Sorry for the late answer. It seems fixed with the latest version (2.0.0-dev20190516)", "Closing based on https://github.com/tensorflow/tensorflow/issues/27713#issuecomment-493163593", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27713\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27713\">No</a>\n"]}, {"number": 27712, "title": "Fixed cond with group and summaries, issue #24815", "body": "", "comments": ["> Can you write a test which fails before this PR and passes after?\r\n> \r\n> I'd like to prevent this issue from regressing in future changes to TF.\r\n\r\nThank You @alextp, I added test You asked for.", "I updated files, added whitespaces and removed unnecessary import, because //tensorflow/tools/ci_build:gen_ci_sanity_out failed.", "@ila96 can you please check ubuntu sanity errors ?", "> @ila96 can you please check ubuntu sanity errors ?\r\n\r\nHi, I run tensorflow/tools/ci_build/ci_sanity.sh and got errors that don't contain the files I changed. Also, ubuntu sanity error log doesn't list files I changed. Here's a snippet of a log:\r\n\"tensorflow/contrib/gan/python/train.py:543: [C0301(line-too-long), ] Line too long (94/80)\"\r\nI'm not sure what to do?", "@ila96 please resolve conflicts.", "@ila96 gentle ping to resolve conflicts. Thanks!", "I rebased and solved conflicts, and run ci_sanity.sh but it didn't show files i changed.", "@ila96 Can you please resolve the conflicts? Thanks!", "Hi @alextp, @gbaned, can You please merge this pull request?", "Hi @alextp, @gbaned, please feel free to let me know if changes are needed.", "Can one of the admins verify this patch?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27711, "title": "error save keras model have Conv2D and dilation_rate=2 use tf.saved_model.save()", "body": "install tensorflow2.0: pip install tf-nightly-2.0-preview==2.0.0.dev20190405\r\n\r\nkeras model have use Conv2D with dilation_rate=2.\r\ntf.saved_model.save(model, OUTPUT_DIR) out error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"convert_h5_to_tflite.py\", line 146, in <module>\r\n    tf.saved_model.save(model, OUTPUT_DIR)\r\n  File \"/docker_environment/home/docker/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 798, in save\r\n    meta_graph_def, saveable_view, signatures)\r\n  File \"/docker_environment/home/docker/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 529, in _fill_meta_graph_def\r\n    signatures = _generate_signatures(signature_functions, resource_map)\r\n  File \"/docker_environment/home/docker/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 407, in _generate_signatures\r\n    function, mapped_inputs, resource_map)\r\n  File \"/docker_environment/home/docker/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 358, in _call_function_with_mapped_captures\r\n    function.graph.captures, resource_map)\r\n  File \"/docker_environment/home/docker/anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py\", line 280, in _map_captures_to_created_tensors\r\n    .format(interior))\r\nAssertionError: Tried to export a function which references untracked object Tensor(\"StatefulPartitionedCall/forward_6_1b_conv2D/stack:0\", shape=(2, 2), dtype=int32).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\n```\r\ndilation_rate=1 not error", "comments": ["Could you put together code to reproduce? I tried exporting a Sequential that has a Conv2D with dilation_rate=2 and didn't run into the error:\r\n\r\n```\r\nroot = tf.keras.Sequential([tf.keras.layers.Conv2D(filters=3, kernel_size=2, dilation_rate=2)])\r\ninitial_output = root.predict(tf.ones((1, 5, 5, 1)))\r\ntf.saved_model.save(root, \"/tmp/sm\")\r\n```\r\n\r\nThis was with 2.0.0-dev20190402 and at head.", "code out error:\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ninput_data = tf.keras.layers.Input(name='fts_input', shape=(None,None,3), dtype='float32')\r\ninner = tf.keras.layers.Conv2D(filters=3, kernel_size=3, dilation_rate=2)(input_data)\r\nmodel = tf.keras.models.Model(inputs=[input_data], outputs=inner)\r\n\r\ninitial_output = model.predict([tf.ones((2, 300, 300, 3))])\r\ntf.saved_model.save(model, './')\r\n```", "Thanks, that does reproduce nicely. I'll take a look.", "Ooo, I accidentally fixed this in https://github.com/tensorflow/tensorflow/commit/0d4d88c0514a6026fd90efc06e1adb5f8aa9255c\r\n\r\nThis is working for me in 2.0.0-dev20190416. I'll add a test to make sure it doesn't break in the future. Thanks for the report!"]}]