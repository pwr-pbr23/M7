[{"number": 29630, "title": "TF 2.0 Beta CPU version not working", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): beta\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: I'm using CPU version\r\n- GPU model and memory: not relevant\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIt throws this error\r\n2019-06-11 17:55:04.982068: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0611 17:55:05.086806 23064 ag_logging.py:145] Entity <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>>: ValueError: Unable to locate the source code of <bound method FE.call of <__main__.FE object at 0x0000027010557DA0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nW0611 17:55:05.133668 23064 ag_logging.py:145] Entity <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>>: ValueError: Unable to locate the source code of <bound method LP.call of <__main__.LP object at 0x00000270184E6CF8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nW0611 17:55:05.149287 23064 ag_logging.py:145] Entity <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>>: ValueError: Unable to locate the source code of <bound method DC.call of <__main__.DC object at 0x00000270184E64E0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nW0611 17:55:05.149287 23064 ag_logging.py:145] Entity <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>>: ValueError: Unable to locate the source code of <bound method GRL.call of <__main__.GRL object at 0x00000270184E6128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\n\r\n**Describe the expected behavior**\r\nIt should work! it works in GPU version seemlessly\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nThe code is massive and I cannot tell where the error is. Any way, it works well in GPU version of TF.\r\nPS: when in CPU version, I'm not even using tf.function decorator. But it seems from the error that it is related to graphs.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 29629, "title": "`Check failed` error in Keras distributed (MultiWorkerMirroredStrategy) training.", "body": "Hello, in attempt to train simple keras model in distributed environment with TF 2.0 MultiWorkerMirroredStrategy I have encoutered an error `Check failed: size >= 0 ... Aborted` that appears only when the number of workers in TF_CONFIG is greater than 1. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nTrue\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nCentOS Linux release 7.4.1708 (Core)\r\n\r\n- TensorFlow installed from (source or binary):\r\npip install\r\n\r\n- TensorFlow version (use command below):\r\nv1.12.1-3259-gf59745a381 2.0.0-beta0\r\n\r\n- Python version:\r\n3.6.7\r\n\r\n**Describe the current behavior**\r\n\r\nWhen run with more then one worker it fails:\r\n\r\n```\r\nTrain on 2781 steps\r\nEpoch 1/100\r\n2019-06-11 10:54:04.220333: F tensorflow/core/framework/tensor_shape.cc:324] Check failed: size >= 0 (-19 vs. 0)\r\nAborted\r\n```\r\n\r\nThe negative value in check seems to depend only on `drop_remainder` argument to `padded_batch` method and not on: `num_inputs`, `batch_size`, length of dataset, `epochs`. It equals to `-19` when `drop_remainder=False` and to `-16` when `drop_remainder=True`.\r\n\r\n```\r\nCheck failed: size >= 0 (-19 vs. 0) <-> drop_remainder=False\r\nCheck failed: size >= 0 (-16 vs. 0) <-> drop_remainder=True\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nShould work\r\n\r\n**Code to reproduce the issue**\r\nSave this script as `tensorflow_issues_29629.py` and run on each node with fully qualified domain names `master` and `slave1`:\r\n```\r\npython tensorflow_issues_29629.py `hostname -f` \r\n```\r\nor set different index of worker in TF_CONFIG in `tensorflow_issues_29629.py` on different nodes.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport types\r\nimport numpy as np\r\nimport json\r\nimport os\r\nimport sys\r\n\r\nhostname_idx = {\r\n    \"master\": 0,\r\n    \"slave1\": 1\r\n}\r\nworker_index = hostname_idx[sys.argv[1]]\r\n\r\n\r\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_cpu_global_jit'\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': [\"master:1531\",\r\n                   \"slave1:1531\"\r\n                  ]\r\n    },\r\n    'task': {'type': 'worker', 'index': worker_index}\r\n})\r\n\r\nmirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\noptions_distribute = tf.data.Options()\r\noptions_distribute.experimental_distribute.auto_shard = True\r\n\r\ndef sliding_window(values, window_size=2, stride=1, start=0):\r\n    i = start\r\n    r = None\r\n    if i+window_size <= len(values):\r\n        yield values[i:i+window_size]\r\n    while True:\r\n        i = i+stride\r\n        if (i+window_size-1) < len(values):\r\n            yield values[i:i+window_size]\r\n        else:\r\n            break\r\n            \r\nnum_timesteps = 100\r\nnum_timesteps_to_predict = 1000\r\nnum_signals = 2\r\nnum_inputs = num_signals*num_timesteps_to_predict\r\nbatch_size = 2**5\r\nepochs = 100\r\n\r\ndataset = types.SimpleNamespace()\r\ndataset.xmin = 0\r\ndataset.xmax = 50\r\ndataset.size = 100000\r\ndataset.split_train_ratio = 0.9\r\n\r\ndataset.x = np.linspace(dataset.xmin, dataset.xmax, dataset.size)\r\ndataset.y = np.array([np.sin(dataset.x*(i+1)) for i in range(num_signals)])\r\ndataset.input = np.array([list(sliding_window(y,\r\n                                    window_size=num_timesteps,\r\n                                    stride=1,\r\n                                    start=0))[:-num_timesteps_to_predict] for y in dataset.y])\r\ndataset.target = np.array([list(sliding_window(y,\r\n                                     window_size=num_timesteps_to_predict,\r\n                                     stride=1,\r\n                                     start=num_timesteps)) for y in dataset.y])\r\n\r\ndataset.input = np.transpose(dataset.input, axes=[1,2,0])\r\ndataset.target = np.transpose(dataset.target, axes=[1,2,0])\r\n\r\ndataset.target = dataset.target.reshape((dataset.target.shape[0], dataset.target.shape[1]*dataset.target.shape[2]))\r\n\r\nsplit_point = int(len(dataset.input)*dataset.split_train_ratio)\r\nsplit_point = (split_point//batch_size)*batch_size\r\ndataset.train_input = dataset.input[:split_point]\r\ndataset.train_target = dataset.target[:split_point]\r\n\r\n\r\ninput_dataset = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(dataset.train_input), \r\n                                     tf.data.Dataset.from_tensor_slices(dataset.train_target)))\r\ninput_dataset = input_dataset.padded_batch(batch_size, \r\n                                           ((num_timesteps, num_signals), \r\n                                            (num_timesteps_to_predict*num_signals)),\r\n                                           drop_remainder=False)\r\n# Check failed: size >= 0 (-19 vs. 0) <-> drop_remainder=False\r\n# Check failed: size >= 0 (-16 vs. 0) <-> drop_remainder=True\r\n# num_inputs, batch_size, length of dataset, epochs do not change this value\r\n\r\ninput_dataset = input_dataset.shuffle(dataset.size)\r\ninput_dataset = input_dataset.with_options(options_distribute)\r\n\r\nprint('Train dataset shape', dataset.train_input.shape)\r\nprint('MultiWorkerMirroredStrategy: ', mirrored_strategy)\r\n\r\n\r\nwith mirrored_strategy.scope():\r\n    inputs = keras.Input(shape=(num_timesteps, num_signals), name='input')\r\n    lstm = keras.layers.LSTM(num_inputs)(inputs)\r\n    model = keras.Model(inputs=inputs, outputs=lstm)\r\n    optimizer = keras.optimizers.RMSprop(lr=1e-3)\r\n    model.compile(loss=keras.losses.mean_squared_error,\r\n                  optimizer=optimizer,\r\n                  metrics=['accuracy'])\r\n    \r\nmodel.fit(input_dataset, epochs=epochs)\r\nmodel.save('past_100_pred_1000_model.h5') \r\n```\r\n\r\n**Other info / logs**\r\n\r\nOne guess is that protobuf or python->cpp marshalling is broken.. Python, tensorflow, protobuf version are the same across machines.\r\n\r\n```\r\nlibprotobuf               3.8.0                h8b12597_0    conda-forge\r\nprotobuf                  3.8.0            py36he1b5a44_0    conda-forge\r\n```\r\n\r\n", "comments": ["Hello protsenkovi, thanks for reporting the issue. Can you provide a stack trace so there's more information for us to look into it?", "@rchao Excuse me, rchao, I thought about your request several times and do not understand how to do that. The only message I get now on error is from CHECK_GE in tensorflow/core/framework/tensor_shape.cc:324. Should I get C++ stacktrace? Can I do it without recompilation?", "No problem. Can you do me a favor and check if you'd still get the same error without using tf.distribute.Strategy? That is, removing `with mirrored_strategy.scope():` and see what happens. Thanks.", "@rchao I have removed this line and it is training as expected. \r\n\r\n```\r\nEpoch 1/100\r\n  71/2781 [..............................] - ETA: 2:28:00 - loss: 0.4671 - accuracy: 0.0000e+00\r\n```", "Thanks! That's useful to know. Will post here once there's some update.", "@protsenkovi I tried a few times but never successfully reproduced this issue (with python 3 and TF 2 enabled). Are you able to repro the issue consistently?", "@rchao Unfortunately, yes. I've checked it again with `envs_dirs` and `pkgs_dirs` pointing to the same nfs folders now and got the same behaviour.", "@protsenkovi Is this still an issue? Can you please check with `TF2.0` and let us know whether the issue persists with latest TF version. Thanks!", "@jvishnuvardhan With latest stable release of TF 2.0 the issue is gone.", "I am closing the issue as it was resolved in `TF2.0`. Please feel free to open it if the issue persists again. Thanks!"]}, {"number": 29628, "title": "TF 2.0 tf.image.non_max_suppression always output the length of max_output_size", "body": "tensorflow version: tensorflow-2.0.0-beta0\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nbbox = [[0,0,0,0],[0,0,0,0],[0.71619,0.3128575,0.7752377,0.37428612],[0.71619,0.3128575,0.7752377,0.37428612]]\r\nscores = [2.4719129,1.701416,0.89775455,4.354542]\r\n\r\nselected_index = tf.image.non_max_suppression(bbox,scores,3000,0.99)\r\n\r\nprint(selected_index)\r\n```\r\n\r\nand the output is\r\n```\r\n2.0.0-beta0\r\ntf.Tensor([3 0 0 ... 0 0 0], shape=(3000,), dtype=int32)\r\n```\r\n\r\nI also tried `tf.image.non_max_suppression_padded` function with parameter `pad_to_max_output_size=False` and `pad_to_max_output_size=True`, the output shape is the same", "comments": ["I have tried on Colab with TF CPU version 2.0.0-beta and was able to reproduce the issue.", "@JoelTsui \r\nCan you please try with nightly version (`!pip install tf-nightly`) and let us know the whether the issue persists.I have tried and please find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/26b4d9836f53dc6a3032888d77804266/untitled616.ipynb). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29628\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29628\">No</a>\n"]}, {"number": 29627, "title": "iPhone 6 crash: EXC_BAD_INSTRUCTION in v1.14.0-rc1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nCompiled on MacOS 10.14.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n[iPhone6](https://en.wikipedia.org/wiki/IPhone_6), iOS 11.4\r\n- TensorFlow installed from (source or binary):\r\nSource\r\niOS tensorflow lib built with the script: `tensorflow/contrib/makefile/build_all_ios.sh`\r\n- TensorFlow version (use command below):\r\nv1.14.0-rc1\r\n- GCC/Compiler version (if compiling from source):\r\nXCode 10.2.1\r\n```\r\ngcc --version\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.1 (clang-1001.0.46.4)\r\nTarget: x86_64-apple-darwin18.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```\r\n\r\n**Describe the current behavior**\r\nI have written an iOS app that uses TensorFlow from C++.\r\nThe app crashes on Session::Run() with `Thread 6: EXC_BAD_INSTRUCTION (code=1, subcode=0xd53be053)`\r\nXCode breaks and highlights an assembler line 329: ->  ```0x1014e7f30 <+1308>: mrs    x19, CNTVCT_EL0```\r\n\r\n**Describe the expected behavior**\r\nNo crash. The same app built with TensorFlow v1.13.1 runs successfully.\r\n\r\n**Other info / logs**\r\nThis appears to have been introduced with commit [9a486811ca07b5ca3f60f6fd96e69fc1df889818](https://github.com/tensorflow/tensorflow/commit/9a486811ca07b5ca3f60f6fd96e69fc1df889818) which was not in 1.13.1 but is in 1.14.0-rc0.\r\nIt introduces the struct `KernelTimer`, which calls `profile_utils::CpuUtils::GetCurrentClockCycle()` in [cpu_utils.h](https://github.com/tensorflow/tensorflow/blob/v1.14.0-rc1/tensorflow/core/platform/profile_utils/cpu_utils.h#L58) on initialization. On aarch64, this calls `asm volatile(\"mrs %0, cntvct_el0\" : \"=r\"(virtual_timer_value));` which is the line XCode breaks on.\r\nIf I [exit that function with an early return](https://github.com/travbid/tensorflow/commit/8b6b0d2ddb7fb3262c41f471e5f299b9ee377560#diff-5f82d595cba7425ac17d71e7615343d9) then the session runs without crashing.\r\nAfter consulting the [armv8 reference guide](https://developer.arm.com/docs/ddi0487/latest/arm-architecture-reference-manual-armv8-for-armv8-a-architecture-profile) the instruction in question looks right to me and can be found in other code samples with a google search.\r\n\r\nUnfortunately, I don't have any other iOS devices to test on currently.\r\n\r\nI know little about assembler or ARM architectures and have reached the limits of my debugging ability here. Could this be a hardware bug in iPhone 6? Any insight appreciated.\r\n\r\n", "comments": ["I have the same problem when I try to use my iPhone 6s plus or my iPad Pro 11\" A1980 with Tensorflow 2.0.0-beta. When I test my application using the simulator (any of them), I can execute the method Session::Run() correctly. @travbid, did you find out a solution for this problem?", "@fbobital I worked around this by editing cpu_utils.h as in https://github.com/travbid/tensorflow/commit/8b6b0d2ddb7fb3262c41f471e5f299b9ee377560#diff-5f82d595cba7425ac17d71e7615343d9 and re-compiling TensorFlow.", "@travbid It also worked for me. Thanks.", "@mihaimaruseac , can we get this fixed? @ymodak ", "1.14 is old and unsupported. contrib is no longer maintained. Makefile build is only community supported.", "@mihaimaruseac , I understand, but the issue is fundamentally one about `CPU_utils.h` library file. Apparently, `asm volatile(\"mrs %0, cntvct_el0\" : \"=r\"(virtual_timer_value));` is a privileged instruction on Apple devices.\r\n\r\nMoreover, it still occurs in 1.15 (which is still supposed to be supported for a few more months)", "Can you send a patch to 1.15  branch please? Mention me in the PR.", "Patch landed, we can close this now. Patch release will come today/tomorrow", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29627\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29627\">No</a>\n"]}, {"number": 29626, "title": "Tensor flow lite stable release for Linux on ARM 64 bit", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\r\n**Describe the problem**\r\nHave we have any version(or tag) for tensor flow lite which can build successfully (or stable release) for ARM64 ?\r\n I have try many tag version, but sometimes script build was deleted, what's happend?\r\nIf it is not stable now, please tell me and I think I will try it later.\r\n\r\nSome bug Im facing now:\r\nhttps://www.gitmemory.com/issue/tensorflow/tensorflow/28863/496775232\r\nhttps://github.com/tensorflow/tensorflow/issues/25120", "comments": ["@TrungLM13 Just to verify, Did you get a chance to go through the [Build TensorFlow Lite for ARM64](https://www.tensorflow.org/lite/guide/build_arm64) official website. Let us know if that solves your problem. Thanks!", "Hello @gadagashwini , I followed by official website step by step. And I faced the same problem I post before.\r\nI try to v1.12.1 and it can help me to pass #28863 bug I had to face with #25120.\r\nFinally I pass all issue by disable NNAPI. and it work,\r\nBut when I try to use new version v1.13... or v1.14....\r\nit is still bug #28863 .\r\n\r\nAnother thing, it seem likes that script build arm at some version was deleted and added again??? What happened for it?", "> Hello @gadagashwini , I followed by official website step by step. And I faced the same problem I post before.\r\n> I try to v1.12.2 and it can help me to pass #28863 bug I had to face with #25120.\r\n> Finally I pass all issue by disable NNAPI. and it work,\r\n> But when I try to use new version v1.13... or v1.14....\r\n> it is still bug #28863 .\r\n> \r\n> Another thing, it seem likes that script build arm at some version was deleted and added again??? What happened for it?\r\n\r\n@TrungLM13 Thanks for updating. ", "@TrungLM13,\r\n\r\nYou can use latest tensorflow (i.e 2.8) which also supports for Linux on ARM 64 bit.\r\n\r\nPlease refer [Build TensorFlow Lite for ARM boards](https://www.tensorflow.org/lite/guide/build_arm) may help you. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29626\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29626\">No</a>\n"]}, {"number": 29625, "title": "Switching default model with tf.keras", "body": "## URL(s) with the issue:\r\n\r\nI don't think it's documented so no link available.\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere doesn't seem to be any documentation on how to change the default model for the `tf.keras.backend.get_session`. I need to do this to properly save my model (I think).\r\n\r\n### Clear description\r\n\r\nI have an RNN that I'm training in batches with TBTT using tf.keras. Since my model is stateful I have to be explicit about the batch size when I create the model. However, at predict time I want to be able to do predictions on arbitrary length sequences and to have a batch size of 1. So I create a new, nearly identical model,  and then copy the weights via `predict_model.set_weights(train_model.get_weights())`. This all works as expected.\r\n\r\nNow I want to save my prediction model so I can do inference from C++. If I follow the directions one finds on the internet (e.g. on [this page](https://medium.com/@pipidog/how-to-convert-your-keras-models-to-tensorflow-e471400b886a)) I need to do something like:\r\n\r\n```\r\nsession = tf.keras.backend.get_session()\r\ngraph = session.graph\r\nwith graph.as_default_graph():\r\n    # Do things to serialize the GraphDef to protobuf\r\n```\r\n\r\nBut if I do this the `session.graph` is the graph I used for training, not my prediction model. It seems `tf.keras` does some \"magic\" to switch sessions or default graph (not sure which) and I can't find any documentation about what it does or when. I believe I could make one \"dummy prediction\" with my `predict_model` to make it current but that seems super hacky.\r\n\r\nIs there any way to get the `Graph` that corresponds to a `tf.keras.Model`? If not, is there any way to make a `Model` be the current graph without doing something super hacky like making a prediction for data I don't care about?\r\n\r\nI tried tracing through the `model.predict` code to see where the session is used but didn't find it quickly and figured this should be documented so I decided to ask here.\r\n\r\n", "comments": ["Probably this issue https://github.com/keras-team/keras/issues/3223 can point you in the right direction. ", "@ymodak that bug appears to be about saving the *single* Keras model to TF. I know how to do that. What's tricky is if you have multiple models so the `K.get_session().graph` isn't the graph you want to save.", "BTW: the answer seems to be that it just works. As far as I can tell Keras has only one graph even if you have mutliple models - it's just that not all the inputs/outputs in that one graph are connected. As long as you specify the correct outputs in the graph saving code it seems to work. this but was really just about the lack of documentation around this.", "@oliverdain \r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999"]}, {"number": 29624, "title": "on_epoch_end not triggered when workers=0 in fit_generator", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.14\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta0 (issue also happens on TF 1.12 and 1.13)\r\n- Python version: Python 3.6.7\r\n- Bazel version (if compiling from source):  N/A\r\n- GCC/Compiler version (if compiling from source):  N/A\r\n- CUDA/cuDNN version:  N/A\r\n- GPU model and memory:  N/A\r\n\r\n**Describe the current behavior**\r\nWhen running `fit_generator` on the main thread (i.e. with `use_multiprocessing=False` and `workers=0`), `on_epoch_end` doesn't get triggered\r\n\r\n**Describe the expected behavior**\r\nHaving looked at the source code, I would expect `on_epoch_end` to be triggered at the end of each epoch\r\n\r\n**Code to reproduce the issue**\r\nI create a simple generator by subclassing from tf.keras.utils.Sequence:\r\n```\r\nclass DataGenerator(Sequence):\r\n    def __init__(self, split):\r\n        self.split = split\r\n        \r\n    def __len__(self):\r\n        return 2\r\n\r\n    def __getitem__(self, index):\r\n\r\n        print (f'\\n split: {self.split} generator, index: {index}', flush=True)\r\n        y = np.random.uniform(low=0, high=1, size=(2_000, 1))\r\n        y = (y > 0.5).astype(np.int32)\r\n        X = np.random.normal(loc=0, scale=1, size=(2_000, 10))\r\n        X = X.astype(np.float32)\r\n        return X, y\r\n\r\n    def on_epoch_end(self):\r\n        print (f'on epoch end: {self.split}', flush=True)\r\n```\r\n\r\nI then create a simple model\r\n```\r\nmodel = Sequential()\r\nmodel.add(Dense(20, activation='relu', input_shape=(10,)))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\noptimizer = Adam(lr=0.001)\r\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\r\n```\r\n\r\nI set up my training and validation generators and run fit_generator\r\n```\r\ntraining_generator = DataGenerator(\r\n    split='training')\r\n\r\nvalidation_generator = DataGenerator(\r\n    split='validation')\r\n\r\nmodel.fit_generator(\r\n    generator=training_generator,\r\n    validation_data=validation_generator,\r\n    use_multiprocessing=False,\r\n    max_queue_size=10,\r\n    epochs=4,\r\n    shuffle=False,\r\n    workers=0,\r\n    verbose=0)\r\n```\r\n\r\nI get the following output:\r\n```\r\n split: training generator, index: 0\r\n\r\n split: training generator, index: 1\r\n\r\n split: validation generator, index: 0\r\n\r\n split: validation generator, index: 1\r\n\r\n split: training generator, index: 0\r\n\r\n split: training generator, index: 1\r\n\r\n split: validation generator, index: 0\r\n\r\n split: validation generator, index: 1\r\n\r\n split: training generator, index: 0\r\n\r\n split: training generator, index: 1\r\n\r\n split: validation generator, index: 0\r\n\r\n split: validation generator, index: 1\r\n\r\n split: training generator, index: 0\r\n\r\n split: training generator, index: 1\r\n\r\n split: validation generator, index: 0\r\n\r\n split: validation generator, index: 1\r\n```\r\n\r\nIf I change workers from 0 to 1, then `on_epoch_end` is triggered (i.e. `'on epoch end: {}'` print statements) appear.", "comments": ["@marwan116,\r\nI was able to reproduce the issue with TF v2.1. However, it seems to be fixed with the latest nightly TF v2.2.0-dev20200327. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/2fceed384fd9cfb8966ba9b507b8fcde/tf-nightly.ipynb). Thanks!", "@amahendrakar thanks for taking the time to check this. Ok cool so this looks like it is working now - what about TF1 (1.15 ..)?  ", "@marwan116,\r\nSeems like the issue still persists with TF 1.15.2. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/a338353b2125128441160f36acd0cd49/29624-1-15.ipynb). Thanks!", "Hi @marwan116. We usually don't patch old releases when we fix bugs. We only do patch releases for security issues. When do those, we investigate other PRs opened against the corresponding release branch and cherry-pick additional fixes, but this is limited. Our recommendation is to always use the latest version.\r\n\r\nIf someone identifies the fix commit for this and makes a cherrypick against the `r1.15` branch, we would be able to apply it when we do the release. Otherwise, unfortunately, we don't have enough cycles to cherry-pick all fix commits on all live branches", "I am closing this issue as it was resolved in recent `tf-nightly`. This will be available in stable `TF2.2` which will be released in near future. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29624\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29624\">No</a>\n"]}, {"number": 29623, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 76800 values, but the requested shape has 768", "body": "The shape of the intermediate tensor is as follows\uff1a\r\nlad_tensor: (1, 17, 17, 768)\r\nAvgPool_1a_5x5: (1, 5, 5, 768)\r\nConv2d_1b_1x1: (1, 5, 5, 128)\r\nConv2d_2a_5x5 (1, 1, 1, 768)\r\nfor example: aux_logits --> Tensor(\"\u00d7\u00d7\u00d7\u00d7\", shape=(1, 1, 1, 768), dtype=float32)\r\nand I want to convert a four-dimensional tensor into a two-dimensional tensor, I use the following method\uff1a\r\nbottleneck_tensor=tf.squeeze(aux_logits,[1,2],name='SpatialSqueeze')\r\nor\uff1a\r\nbottleneck_tensor=tf.reshape(aux_logits,(-1,768),name='SpatialSqueeze')\r\nSo the result is\uff1a\r\nbottleneck_tensor: Tensor(\"\u00d7\u00d7\u00d7\u00d7\u00d7\", shape=(1, 768), dtype=float32)\r\n\r\nBut I use the following statement \uff1a\r\nbottleneck_input = tf.placeholder_with_default(\r\nbottleneck_tensor, shape=[None, 768],\r\nname='BottleneckInputPlaceholder')\r\n\r\nThe program reported the following error\uff1a\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 76800 values, but the requested shape has 768\r\n[[Node: train/gradients/AuxLogits/SpatialSqueeze_grad/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](train/gradients/final_training_ops/Wx_plus_b/MatMul_grad/tuple/control_dependency, train/gradients/AuxLogits/SpatialSqueeze_grad/Shape)]]\r\nand 76800=768\u00d7100\uff0ctrain_batch_size=100\r\n\r\nBut if I use the following statement, the program does not report errors\uff1a\r\nbottleneck_input = tf.placeholder_with_default(\r\ns, shape=[None, 768],\r\nname='BottleneckInputPlaceholder')\r\nand s is the type of array\r\n\r\nbut I find in TensorBoard, the nodes in the graph are disconnected\r\n\r\nI'm very confused about it !", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 29622, "title": "How to change the LSTMCell weight format from tensorflow to tf.keras", "body": "\r\n\r\nI I have some old code from tensorflow that I want to make work for tensorflow2/tf.keras. I would like to keep the same LSTM weights, but cannot figure out how to convert the format.\r\n\r\nI have the old weights saved in a checkpoint file, and also have them saved in csv files.\r\n\r\nMy old code looks something like this:\r\n```\r\ninput_placeholder = tf.placeholder(tf.float32, [None, None, input_units])\r\nlstm_layers = [tf.nn.rnn_cell.LSTMCell(layer_size), tf.nn.rnn_cell.LSTMCell(layer_size)]\r\nstacked = tf.contrib.rnn.MultiRNNCell(lstm_layers)\r\nfeatures, state = tf.nn.dynamic_rnn(stacked, input_placeholder, dtype=tf.float32)\r\n```\r\n\r\nAnd my new code looks something like this:\r\n```\r\ninput_placeholder = tf.placeholder(tf.float32, [None, None, input_units])\r\nlstm_layers = [tf.keras.layers.LSTMCell(layer_size),tf.keras.layers.LSTMCell(layer_size)]\r\nstacked = tf.keras.layers.StackedRNNCells(lstm_layers)\r\nfeatures = stacked(input_placeholder)\r\n... #later in the code\r\nfeatures.set_weights(previous_weights)\r\n```\r\n\r\nThe old bias seems to match the new bias. The old kernel seems to be the concatenation of the kernel and recurrent kernel. I am able to load the previous_weights into the model (have explicitly checked the weights loaded correctly), however tests I have fail to produce the same result. Digging into the source code, the kernels seem to have a different format under the hood.\r\n\r\nIs it possible to calculate the kernel and recurrent_kernel (tf.keras) using these old saved kernel weights?\r\n\r\nLinks if they're helpful:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/ops/rnn_cell_impl.py\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/layers/recurrent.py\r\n", "comments": ["@5M7k0R5tTe Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. Thanks!", "Update. My original message was wrong, and the gate order is actually opposite. The actual order of Keras weights is IFCO, and TF is ICFO.\r\n\r\nCode for keras: https://github.com/keras-team/keras/blob/353cb10af7c0c7d435b31129c5970fcabe3fc961/keras/layers/recurrent.py#L2468\r\n\r\nCode for TF: https://github.com/tensorflow/tensorflow/blob/04256c89d8783c5cfd7e550f9512e9478beb6454/tensorflow/python/ops/rnn_cell_impl.py#L752\r\n\r\n+++++++++++++++++++++++++++++++++++++++\r\nOriginal message:\r\n@5M7k0R5tTe, the tf lstm cell has two weights: kernel, bias. and keras cell has 3 weights: kernel, recurrent_kernel, bias. The tf kernel should be the concat of keras kernel and recurrent kernel. \r\n\r\nFormat wise, tf lstm cell was using IFCO (input, forget, carry, output) gate order, and Keras cell was using ICFO (input, carry, forget, output). So to convert the weights, assume each gates has size U, it will be:\r\n\r\ni, f, c, o = np.split(tf_weights, 4, axis=1)\r\nkeras_weights = np.concatenate([i, c, f, o], axis=1)", "@qlzh727 , thanks for the clarification. However, it almost looks like TF LSTMCell uses **icfo**, and keras LSTM uses **ifco**, as opposite to what you described?\r\n\r\nThe source is: current tf2onnx handles TF LSTMCell (see code [here](https://github.com/onnx/tensorflow-onnx/blob/master/tests/test_lstm.py#L20)) but [not keras LSTM as of now](https://github.com/onnx/tensorflow-onnx/issues/1546). Under this case, the lstm rewriter treats that the [weights](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L222) and [bias](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L224) as in **icfo** format. Only then, it's converted to ONNX format which is [**iofc**](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L235). \r\n\r\nTherefore, my understanding on default gate order is:\r\nTF LSTM: ICFO\r\nkeras LSTM: IFCO\r\nONNX LSTM: IOFC\r\n\r\nPlease correct me if wrong. I am confused after reading tf2onnx code and this thread. Thanks.", "oh, yes. Thanks for spotting the error in my previous message. The keras weight format is IFCO, and TF format was ICFO. \r\n\r\nYou can find the keras logic for weights in https://github.com/keras-team/keras/blob/353cb10af7c0c7d435b31129c5970fcabe3fc961/keras/layers/recurrent.py#L2468\r\n\r\n> @qlzh727 , thanks for the clarification. However, it almost looks like TF LSTMCell uses **icfo**, and keras LSTM uses **ifco**, as opposite to what you described?\r\n> \r\n> The source is: current tf2onnx handles TF LSTMCell (see code [here](https://github.com/onnx/tensorflow-onnx/blob/master/tests/test_lstm.py#L20)) but [not keras LSTM as of now](https://github.com/onnx/tensorflow-onnx/issues/1546). Under this case, the lstm rewriter treats that the [weights](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L222) and [bias](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L224) as in **icfo** format. Only then, it's converted to ONNX format which is [**iofc**](https://github.com/onnx/tensorflow-onnx/blob/master/tf2onnx/rewriter/lstm_rewriter.py#L235).\r\n> \r\n> Therefore, my understanding on default gate order is: TF LSTM: ICFO keras LSTM: IFCO ONNX LSTM: IOFC\r\n> \r\n> Please correct me if wrong. I am confused after reading tf2onnx code and this thread. Thanks.\r\n\r\n"]}, {"number": 29621, "title": "How to change the protobuf version compiled in the tensorflow\uff1f", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Master source\r\n- TensorFlow version (use command below): 1.13.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.26\r\n- GCC/Compiler version (if compiling from source): 7.4\r\n- CUDA/cuDNN version: 10 7.5\r\n- GPU model and memory: 11G\r\n\r\nI met this problem for tensorflow c++ application.\r\n/home/wjl/github/tensorflow/bazel-genfiles/tensorflow/core/protobuf/verifier_config.pb.h:18:2: error: #error incompatible with your Protocol Buffer headers. \r\nMy system is protobuf 3.8. Tensorflow uses 3.7.\r\nHow can I change it?\r\n\r\n", "comments": ["GRPC now cannot compile for 3.7 protobuf.", "Just to verify did you follow the steps to change the protobuf version using pip install protobuf==3.7.Let us know if it resolves your issue.Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29620, "title": "TensorBoard in SageMaker notebook doesn't work with an S3 location on AL", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 27 and 36\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\n`tensorboard --logdir \"s3://[bucket]\" --inspect`\r\n\r\nError log: \r\n`No event files found within logdir s3://[bucket]`\r\n`2019-05-29 00:03:04.879182: I tensorflow/core/platform/retrying_utils.cc:70] The operation failed and will be automatically retried in 0.459992 seconds (attempt 1 out of 10), caused by: Failed precondition: Not a directory`\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n`sudo cp /etc/ssl/certs/ca-bundle.crt /etc/ssl/certs/ca-certificates.crt` fixes the issue\r\n\r\n\r\n----\r\n\r\nAmazon Linux:\r\n[ec2-user@ip-172-31-28-240 certs]$ pwd\r\n/etc/ssl/certs\r\n[ec2-user@ip-172-31-28-240 certs]$ ls -alL *.crt\r\n-r--r--r-- 1 root root 211658 Mar  8 19:58 ca-bundle.crt\r\n\r\n[ec2-user@ip-172-31-28-240 certs]$ ls -al *.crt\r\nlrwxrwxrwx 1 root root 49 Mar  8 19:58 ca-bundle.crt -> /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\r\nlrwxrwxrwx 1 root root 55 Mar  8 19:58 ca-bundle.trust.crt -> /etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt\r\n\r\n----\r\n\r\nUbuntu:\r\nubuntu@ip-172-31-76-35:/etc/ssl/certs$  ls -alL *.crt\r\n-rw-r--r-- 1 root root 233394 Mar 19 07:23 ca-certificates.crt\r\n\r\n---\r\n\r\n\r\nCan Tensorflow move the required /etc/ssl/certs/ca-certificates in the right location for tensorboard to work with Amazon Linux?", "comments": ["@kalyc. Can you please create an issue in the [TesorBoard section](https://github.com/tensorflow/tensorboard/issues) as its related to TensorBoard. Thanks!"]}, {"number": 29619, "title": "Explicitly disable XLA for AMP test", "body": "This test checks for certain graph nodes to verify AMP correctness,\r\nbut XLA changes the graph in ways that make these checks fail.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29619) for more info**.\n\n<!-- need_sender_cla -->", "@bas-aarts Please sign CLA in order to proceed with next steps. Thank you!", "I signed the NVidia CLA!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29619) for more info**.\n\n<!-- ok -->"]}, {"number": 29618, "title": "Tflite opengles delegate gives inaccurate result", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Internal Android 8.1 board\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.22.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Mali-T864 GPU\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI wrote a simple demo using tflite opengles delegate to run deeplab models from [model zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md).\r\n\r\nI have tried your hosted model [deeplabv3_mv2_257_gpu.tflite](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite), It works perfect on my device on CPU and Opengles delegate.\r\n\r\nHowever, when I tried the [deeplab mode with xception65 ](http://download.tensorflow.org/models/deeplabv3_xception_ade20k_train_2018_05_29.tar.gz), The tflite perform differently on CPU and Opengles delegate. My input layer is sub_7, output layer is ResizeBilinear_3.\r\n\r\n\r\nHere is my result:\r\ntest image:\r\n![two_human](https://user-images.githubusercontent.com/43549654/59234008-b852b600-8b9f-11e9-8ce2-703664cadcf4.png)\r\n\r\nresult from CPU (correct):\r\n![hp_nonflatten_cpu](https://user-images.githubusercontent.com/43549654/59234023-d02a3a00-8b9f-11e9-98f0-f17874fca671.png)\r\n\r\nresult from opengles delegate:\r\n![hp_flatten2_gpu](https://user-images.githubusercontent.com/43549654/59234034-dc15fc00-8b9f-11e9-9982-008d9f5064fa.png)\r\n\r\nI believed that this issue is related to the operations(BATCH_TO_SPACE_ND, SPACE_TO_BATCH_ND)  that opengles not supporting thus fallback to CPU. Another [issue](https://github.com/tensorflow/tensorflow/issues/29509) of mine described more detail.\r\n\r\nFlatten the unsupported ops using graph_transforms also failed. It gives me the same inaccurate result or shows message like:\r\n`INFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: TfLiteGpuDelegate Prepare: Program is not properly linked: L0005 The number of compute uniform components (1261) is greater than the maximum number allowed (1024).\r\nERROR: Node number 199 (TfLiteGpuDelegate) failed to prepare.\r\nERROR: Node number 199 (TfLiteGpuDelegate) failed to prepare.\r\n`\r\n\r\n**Describe the expected behavior**\r\nall models work as good as your hosted model\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["> I wrote a simple demo using tflite opengles delegate to run deeplab models from model zoo.\r\n\r\nPlease attach your code.", "Demo code (some less important functions are omitted):\r\n`int main(int argc, char** argv)\r\n{\r\n\r\n  std::cout << \"tflite_opengl_demo Start!\" << std::endl;\r\n\r\n  std::string path_model;\r\n  std::string path_img;\r\n  std::string path_label;\r\n  std::string mode;\r\n\r\n  if (argc != 10)\r\n  {\r\n    LOG(ERROR) << \"Invalid arguments. Exactly 9 arguments required.\";\r\n    LOG(ERROR) << \"path to model\";\r\n    LOG(ERROR) << \"path to image\";\r\n    LOG(ERROR) << \"path to label\";\r\n    LOG(ERROR) << \"mode(opengl/nnapi/cpu)\";\r\n    LOG(ERROR) << \"graph image mean\";\r\n    LOG(ERROR) << \"graph image std\";\r\n    LOG(ERROR) << \"input width\";\r\n    LOG(ERROR) << \"input height\";\r\n    LOG(ERROR) << \"num of class\";\r\n  return 1;\r\n  }\r\n  path_model = argv[1];\r\n  path_img = argv[2];\r\n  path_label = argv[3];\r\n  mode = argv[4];\r\n\r\n\r\n  float graph_image_mean = std::stof(argv[5]);\r\n  float graph_image_std = std::stof(argv[6]);;\r\n  int input_tensor_width = std::stoi(argv[7]);;\r\n  int input_tensor_height = std::stoi(argv[8]);;\r\n  const int input_tensor_channels = 3;\r\n  int graph_num_class = std::stoi(argv[9]);;\r\n  const cv::Size net_input_image_size = cv::Size(input_tensor_width,input_tensor_height);\r\n\r\n\r\n  cv::Mat image = cv::imread( path_img, cv::IMREAD_COLOR);\r\n  if (image.empty()){\r\n    LOG(ERROR) << \"Load image file failed\";\r\n    return -1;\r\n  }\r\n  cv::Mat target_image = image.clone();//input\r\n  int img_width = image.size().width;\r\n  int img_height = image.size().height;\r\n  float ratio_x = 1.0 * img_width / net_input_image_size.width;\r\n  float ratio_y = 1.0 * img_height / net_input_image_size.height;\r\n  float max_ratio = std::max(ratio_x, ratio_y);\r\n  cv::Size input_tensor_size = cv::Size( int(img_width / max_ratio), int(img_height / max_ratio));\r\n\r\n  std::cout << \"Original image size: \" << image.size() << \" resize to:\" << input_tensor_size << std::endl;\r\n  cv::resize(target_image, target_image, input_tensor_size, 0, 0, CV_INTER_NN);\r\n  cv::cvtColor(target_image, target_image, cv::COLOR_BGR2RGB);\r\n  cv::Mat segmentation_img;\r\n\r\n  ////////\r\n  // Set up interpreter.\r\n  model = tflite::FlatBufferModel::BuildFromFile(path_model.c_str());\r\n  tflite::ops::builtin::BuiltinOpResolver op_resolver;\r\n\r\n  tflite::InterpreterBuilder(*model, op_resolver)(&interpreter);\r\n  interpreter->SetAllowFp16PrecisionForFp32(true);\r\n\r\n  if ( mode == \"opengl\"){\r\n    auto* delegate = TfLiteGpuDelegateCreate(/*options=*/nullptr);\r\n    if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) return 0;\r\n\r\n  }\r\n\r\n  if ( mode == \"nnapi\"){\r\n    auto* delegate = tflite::NnApiDelegate();\r\n    if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) return 0;\r\n  }\r\n\r\n\r\n  if ( interpreter->AllocateTensors() != kTfLiteOk) {\r\n    LOG(ERROR) << \"Failed to allocate tensors!\";\r\n  }\r\n\r\n  WriteToInputTensor(target_image,interpreter->typed_input_tensor<float>(0));\r\n  if (interpreter->Invoke() != kTfLiteOk) return 0;\r\n  ReadFromOutputTensor(segmentation_img,interpreter->typed_output_tensor<float>(0));\r\n  DumpImage(segmentation_img);\r\n\t\r\n  return 0;\r\n}`", "@lwu025 : Is this a duplicate of earlier issue you have mentioned #29509 . If so, can we track with that issue and close this one. It will help us to follow easily. Please let us know. Thanks!", "Sure,. You can close this issue", "@lwu025 : Thanks for the response. Closing the issue since its a duplicate of #29509 .", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29618\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29618\">No</a>\n", "@lwu025 Please attach the other functions. Sometimes, the GPU delegates can produce different outputs on different hardwares. I could try running it on my Mali."]}, {"number": 29617, "title": "tensorflow/contrib module still tries to import cloud even when TF is compiled without GCP support", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): 6.3.1\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nIt seems `tensorflow.contrib` will try to `import cloud` on an x86 machine even when TF is compiled without GCP support:\r\n\r\n```\r\nif os.name != \"nt\" and platform.machine() != \"s390x\":\r\n  from tensorflow.contrib import cloud\r\n```\r\n\r\nI build TF with `--config=nogcp` which causes the `cloud` module NOT to be included in the pip package. But then when `tensorflow.contrib` is importing, you get `ImportError: cannot import name 'cloud' from 'tensorflow.contrib'`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild TF with `--config=nogcp`:\r\n\r\n```\r\nbazel build --config=nogcp //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nInstall the pip package, start Python, and run `import tensorflow.contrib`.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Can you try with 1.14 which was just released yesterday?", "Hi @mihaimaruseac,\r\n\r\nI haven't tried with 1.14 but I imagine the problem still exists looking at the code: https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/contrib/__init__.py#L30-L31\r\n\r\nI worked around the issue by changing those lines to:\r\n```\r\nif os.name != \"nt\" and platform.machine() != \"s390x\" and platform.machine() != \"x86_64\":\r\n  from tensorflow.contrib import cloud\r\n```\r\n\r\nas I'm building and running on an x86_64 machine.", "@mihaimaruseac 1.14 still has this issue. I used @erwa 's workaround to get tensorflow working.", "I'm running in the same issue, building TF r1.14 with the following flags:\r\n```\r\n--config=xla --config=mkl --config=noaws --config=nogcp --config=nohdfs --config=nokafka --config=noignite --config=numa\r\n```\r\n\r\n@gunan ", "![Screen Shot 2019-08-27 at 10 37 49 AM](https://user-images.githubusercontent.com/36496141/63794408-cc60a680-c8b6-11e9-8bc9-9ff2a0a4253c.png)\r\nI too face the same issue with tensorflow1.14 version .Can someone please help", "Same problem here for mac. I think for mac, os.name = 'posix'. Do I need to import cloud to run tensorflow on mac? I built tensorflow 1.13 with --config=nogcp. "]}, {"number": 29616, "title": "Point tpu_cluster_resolver.py to the v1 TPU API.", "body": "The v1 API is available. It might be good to consider allowing customers to pick which API version they want, but for now use the v1 API.", "comments": []}, {"number": 29615, "title": "Fix FusedBatchNormV3 conversion", "body": "PiperOrigin-RevId: 252495581", "comments": []}, {"number": 29614, "title": "Get global batch size for MirroredStrategy when using bucket_by_sequence_length", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14-rc1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI'm using [bucket_by_sequence_length](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/data/experimental/bucket_by_sequence_length) to batch sequences based on the maximum tokens allowed in a batch. This makes the batch size dynamic and not pre-determined. \r\n\r\nWhen I want to use distributed training using MirroredStrategy, I have to average the loss based on the global batch size or in other words the total examples I'm training in parallel in a single step across my GPUs. But since each GPU will have each own dynamic batch based on max tokens it's impossible for me to compute the total number of examples running in parallel since I only have access to a single GPU processing using the defined step_fn to run on [experimental_run](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/distribute/MirroredStrategy#experimental_run) function. \r\n\r\nIt would be very helpful to be able to have access to global information as input to step_fn with details about all the batches running in parallel.\r\n\r\n", "comments": ["It might be possible to do this but I am not sure if the cost of synchronization to know the exact global batch size would be acceptable?\r\nInstead of averaging over the exact global batch size, would it work to instead sum the loss, and then scale it by some \"Appx global batch size\" which is constant each step? Wouldn't that be a better way to weight your examples? Or do you necessarily want to have extra weight for examples when there are less examples per batch? \r\n\r\n", "That's an interesting question. Ping @lukaszkaiser if you have any comments or suggestions.", "Okay, so the way that I'm solving this for now is as follows:\r\n\r\n1) replace `experimental_run` with `experimental_run_v2` and  from TF1.14. This allows me to instead of giving the data iterator to the function and leave the `experimental_run` to fetch data, I will fetch them at each step and `experimental_run_v2` will take them as inputs to the `step_fn`.\r\n\r\n2) By having the flexibility to give each distributed batch myself, I can now use `strategy.experimental_local_results` to the fetched batch, compute the total batch size across all GPUs and then give it as an extra parameters to the `step_fn`.\r\n\r\nOf course, as @guptapriya said this has an extra cost that I have to pay due to synchronization of each GPU batch to be collected back to the master GPU in order to be computed. For now, it's not really a big problem for me as I don't see much latency (although I'm pretty sure it exists).\r\n\r\nI think it would be easier to solve this problem if we had the option to choose instead of accumulating all the gradients from the GPUs, averaging them so that each can compute the the local gradients (based on the local batch). Of course, in the case of dynamic batch size it's still not exact but I think it's a better approximation that making a fixed approximation myself about the global batch size. I don't know though if this can be implemented with the Ring-AllReduce method that MirroredStrategy is using right now.\r\n\r\nDisclaimer: I don't have much experience with distributed learning approaches so excuse me if some of my proposals don't make sense. \r\n", "Could you share the skeleton code for your solution? I am not quite sure I completely followed it and want to make sure it would do what you expect.\r\n\r\nRe: \"option to choose instead of accumulating all the gradients from the GPUs, averaging them so that each can compute the the local gradients (based on the local batch)\" -> I didn't understand this either. Currently : each replica computes it's gradients and then we add them. What are you proposing? ", "@guptapriya I can't share a full working example but what I did is basically the following:\r\n\r\n```\r\nwith strategy.scope():\r\n    def train_step(inputs, total_batch_size):\r\n        inp, tar = inputs\r\n        with tf.GradientTape() as tape:\r\n            predictions = model(inp, tar)\r\n            cross_entropy = padded_cross_entropy(predictions, tar)\r\n            loss = tf.reduce_sum(cross_entropy) * (1.0 / tf.cast(total_batch_size, dtype=tf.float32))\r\n            \r\n        gradients = tape.gradient(loss, model.variables)\r\n        update_vars = optimizer.apply_gradients(zip(gradients, model.variables))\r\n        \r\n        with tf.control_dependencies([update_vars]):\r\n            return tf.identity(loss)\r\n    \r\n    def dist_train_step(dist_inputs):\r\n        \"\"\"\r\n        dist_inputs will be a list of all the features (x, y) and each feature will be PerReplica object \r\n        \"\"\"\r\n        x_per_gpu_as_list = strategy.experimental_local_results(dist_inputs[0])\r\n        batch_sizes = [tf.shape(x_gpu)[0] for x_gpu in x_per_gpu_as_list]\r\n        total_batch_size = tf.reduce_sum(tf.stack(batch_sizes))\r\n        \r\n        per_replica_losses = strategy.experimental_run_v2(train_step, args=(dist_inputs, total_batch_size))\r\n        \r\n        mean_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\r\n        \r\n        return mean_loss\r\n    \r\n    train_iterator = train_dataset.make_initializable_iterator()\r\n    train_iterator_init = train_iterator.initialize()\r\n    \r\n    dist_train = dist_train_step(train_iterator.get_next())\r\n    \r\n    with tf.Session(config=config) as sess:\r\n        sess.run([v.initializer for v in all_variables])\r\n        sess.run(train_iterator_init)\r\n        \r\n        step = 0\r\n        loss_sum = 0\r\n        while True:\r\n            try:\r\n                loss = sess.run([dist_train])\r\n                loss_sum += loss\r\n                \r\n                if step % 100 == 0:\r\n                    print(step, loss_sum/(step+1))\r\n            \r\n                step += 1\r\n            except tf.errors.OutOfRangeError:\r\n                print(\"Done!\")\r\n                break\r\n```", "Ah i see. Your code looks right to me, thanks for sharing! \r\n\r\nwhat would be a concrete API change to make this type of use case easy? It doesn't seem obvious given that we don't have a lot of insight into the user's inputs in experimental_run_v2. They may or may not have a batch dimension, for instance.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 29613, "title": "[ROCm] Adding ROCm support for the gather_nd op", "body": "This PR adds ROCm support for the gather_nd ops.\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n--------------------------------------------------------\r\n\r\n@tatianashp @whchung", "comments": []}, {"number": 29612, "title": "[ROCm][XLA:GPU] support for device math calls", "body": "-  Support for rocm device calls for math \r\n-  Provide APIs so both Rocm and PTX can be supported ", "comments": ["@thomasjoerg  Thanks for the review! I have incorporated the suggestions. "]}, {"number": 29611, "title": "[ROCm] Adding ROCm support for the dynamic_stitch op", "body": "This PR adds ROCm support for the dynamic_stitch op.\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------------------------------------------------\r\n\r\n@tatianashp @whchung", "comments": []}, {"number": 29610, "title": "added an example for tf.image.rot90", "body": "Example was requested in https://github.com/tensorflow/tensorflow/issues/29243", "comments": ["@alextp Made changes to use single channel. Please let me know what you think. Thanks!", "@alextp In order to be easy for the reader, I thought of adding images and show them on the TF website. I got your point. I have updated. As we need `ndims`=>3, I added third dimension. Thanks!"]}, {"number": 29609, "title": "Added a note about AutoTrackable", "body": "#29541", "comments": []}, {"number": 29608, "title": "Cannot `import tensorflow.summary` since 2019-06-08 nightly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `('v1.12.1-3679-g3040de1372', '2.0.0-dev20190608')`\r\n- Python version: 2.7 or 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nImporting `tensorflow.summary` raises `ModuleNotFoundError`:\r\n\r\n```\r\n$ python -c 'import tensorflow.summary'; echo $?\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow.summary'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nImporting that module should succeed:\r\n\r\n```\r\n$ python -c 'import tensorflow.summary'; echo $?\r\n0\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\n$ activate ~/virtualenv/tf-nightly-2.0-preview-20190606-py2.7\r\n$ python -c 'import tensorflow.summary'; echo $?\r\n0\r\n$ activate ~/virtualenv/tf-nightly-2.0-preview-20190607-py2.7\r\n$ python -c 'import tensorflow.summary'; echo $?\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/buildtools/current/sitecustomize/sitecustomize.py\", line 152, in SetupPathsAndImport\r\n    return real_import(name, globals, locals, fromlist, level)\r\n  File \"/HOMEDIR/virtualenv/tf-nightly-2.0-preview-20190607-py2.7/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 93, in <module>\r\n    from tensorflow_core import *\r\nAttributeError: 'module' object has no attribute 'compiler'\r\n1\r\n$ activate ~/virtualenv/tf-nightly-2.0-preview-20190608-py2.7\r\n$ python -c 'import tensorflow.summary'; echo $?\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/buildtools/current/sitecustomize/sitecustomize.py\", line 152, in SetupPathsAndImport\r\n    return real_import(name, globals, locals, fromlist, level)\r\nImportError: No module named summary\r\n1\r\n```\r\n\r\n**Other info / logs**\r\n\r\ncc @mihaimaruseac; is this related to recent Pip changes?\r\n", "comments": ["I think it is, sorry about that. Will get to look into this in around 1 hour", "Cool, nothing pressing; we\u2019ll just stay pinned to 2019-06-06 for now.\r\n", "@mihaimaruseac the `tf.summary` import mechanism is pretty arcane - let me know if I can be helpful with any debugging/fixing here.", "It seems I cannot reproduce with a simple virtualenv, maybe I'm missing something\r\n\r\n```bash\r\nmihaimaruseac@ankh:/tmp/virtual_pip$ mkdir tf2.0\r\nmihaimaruseac@ankh:/tmp/virtual_pip$ cd tf2.0\r\nmihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ virtualenv .\r\nRunning virtualenv with interpreter /usr/bin/python2\r\nNew python executable in /tmp/virtual_pip/tf2.0/bin/python2\r\nAlso creating executable in /tmp/virtual_pip/tf2.0/bin/python\r\nInstalling setuptools, pkg_resources, pip, wheel...sdone.\r\nomihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ source bin/activate\r\n(tf2.0) mihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ pip install tf-nightly-2.0-preview\r\nDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\r\nCollecting tf-nightly-2.0-preview\r\n  Using cached https://files.pythonhosted.org/packages/5c/aa/92b2a8d290cffe1f195b055ffb5ea66e99cec2c532cc867f440baa9328e0/tf_nightly_2.0_preview-2.0.0.dev20190608-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/8a/44/6c99eee8359af17ae32deeabb4ab3660e2bf1fa1f10f9947225915a00eec/tb_nightly-1.14.0a20190610-py2-none-any.whl\r\nCollecting backports.weakref>=1.0rc1 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\r\nCollecting mock>=2.0.0 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\r\nRequirement already satisfied: wheel in ./lib/python2.7/site-packages (from tf-nightly-2.0-preview) (0.33.4)\r\nCollecting absl-py>=0.7.0 (from tf-nightly-2.0-preview)\r\nCollecting numpy<2.0,>=1.14.5 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/1f/c7/198496417c9c2f6226616cff7dedf2115a4f4d0276613bab842ec8ac1e23/numpy-1.16.4-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting termcolor>=1.1.0 (from tf-nightly-2.0-preview)\r\nCollecting protobuf>=3.6.1 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/b2/a8/ad407cd2a56a052d92f602e164a9e16bede22079252af0db3838f375b6a8/protobuf-3.8.0-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting google-pasta>=0.1.6 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/35/95/d41cd87d147742ef72d5d1dc317318486e3fbffdadf24a60e70dedf01d56/google_pasta-0.1.7-py2-none-any.whl\r\nCollecting gast>=0.2.0 (from tf-nightly-2.0-preview)\r\nCollecting enum34>=1.1.6 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\r\nCollecting grpcio>=1.8.6 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/8e/62/448199c50e05526f7fd336d8a87bd83a0c7d92188ae51ebea23aa5f3c37e/grpcio-1.21.1-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting six>=1.10.0 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\r\nCollecting keras-applications>=1.0.6 (from tf-nightly-2.0-preview)\r\nCollecting wrapt>=1.11.1 (from tf-nightly-2.0-preview)\r\nCollecting astor>=0.6.0 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\r\nCollecting keras-preprocessing>=1.0.5 (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\r\nCollecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/fc/25/2c861149cf7b97ed85b837a38822307d61a3e4418cf06b12c9187d462460/tensorflow_estimator_2.0_preview-1.14.0.dev2019060900-py2.py3-none-any.whl\r\nRequirement already satisfied: setuptools>=41.0.0 in ./lib/python2.7/site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (41.0.1)\r\nCollecting futures>=3.1.1; python_version < \"3\" (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/2d/99/b2c4e9d5a30f6471e410a146232b4118e697fa3ffc06d6a65efde84debd0/futures-3.2.0-py2-none-any.whl\r\nCollecting werkzeug>=0.11.15 (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl\r\nCollecting markdown>=2.6.8 (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\r\nCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\r\nCollecting h5py (from keras-applications>=1.0.6->tf-nightly-2.0-preview)\r\n  Using cached https://files.pythonhosted.org/packages/53/08/27e4e9a369321862ffdce80ff1770553e9daec65d98befb2e14e7478b698/h5py-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl\r\nInstalling collected packages: six, protobuf, enum34, absl-py, futures, werkzeug, markdown, grpcio, numpy, tb-nightly, backports.weakref, funcsigs, mock, termcolor, google-pasta, gast, h5py, keras-applications, wrapt, astor, keras-preprocessing, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview\r\nSuccessfully installed absl-py-0.7.1 astor-0.8.0 backports.weakref-1.0.post1 enum34-1.1.6 funcsigs-1.0.2 futures-3.2.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.21.1 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 mock-3.0.5 numpy-1.16.4 protobuf-3.8.0 six-1.12.0 tb-nightly-1.14.0a20190610 tensorflow-estimator-2.0-preview-1.14.0.dev2019060900 termcolor-1.1.0 tf-nightly-2.0-preview-2.0.0.dev20190608 werkzeug-0.15.4 wrapt-1.11.1\r\n(tf2.0) mihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ python\r\nPython 2.7.16 (default, Apr  6 2019, 01:42:57) \r\n[GCC 7.3.0] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.summary\r\n<module 'tensorboard.summary._tf.summary' from '/tmp/virtual_pip/tf2.0/local/lib/python2.7/site-packages/tensorboard/summary/_tf/summary/__init__.pyc'>\r\n>>> \r\n(tf2.0) mihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ python -c \"import tensorflow as tf; tf.summary\"; echo $?\r\n0\r\n```", "Got it, was able to reproduce the exact example you gave\r\n\r\n```bash\r\n(tf2.0) mihaimaruseac@ankh:/tmp/virtual_pip/tf2.0$ python -c \"import tensorflow.summary\"; echo $?\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/buildtools/current/sitecustomize/sitecustomize.py\", line 152, in SetupPathsAndImport\r\n    return real_import(name, globals, locals, fromlist, level)\r\nImportError: No module named summary\r\n1\r\n```", "@mihaimaruseac: Right. Those discrepancies are exactly why we test so\r\nmany import permutations in our smoke test:\r\n\r\nhttps://github.com/tensorflow/tensorboard/blob/7a4ef58a4e8e6a9db24b7b72ac2102e832dd590b/tensorboard/pip_package/build_pip_package.sh#L181-L193\r\n\r\nCurrently, `import_attr` and `import_from` work, but `import_as` fails.\r\n", "I have a fix, testing against tf1.* and tf.2* and on both pythons to make sure it works properly.", "Fix is in 2f0e7e39109ff7f40021425494f3c9d84a29b59c, sorry it took so long.", "Fixed in `tf-nightly-2.0-preview==2.0.0.dev20190613`. Thank you!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29608\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29608\">No</a>\n"]}, {"number": 29607, "title": "How do I extract information (consistently) such as Accuracy etc,.. from the distributed example/context ?", "body": "I was using your distribute example: https://www.tensorflow.org/tutorials/distribute/training_loops\r\n\r\nI wanted to know how to properly extract some properties such as accuracy in this custom training loop example.\r\n\r\nI have tried a couple of things but the documentation regarding this is not too specific.\r\n\r\nSomething I was initially looking at was:\r\n  - passing in or returning a tf.Keras.metrics object, taking the logits and labels within the step_fn and getting predictions and then accuracy. But I am running into issues of tensor parsing. Should I be using tf.Summary.scalar in some way then?\r\n\r\nA concrete reply would help.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and can provide better help to such issues. Thanks!\r\n"]}, {"number": 29606, "title": "[ROCm] Adding ROCm support for the eye functor", "body": "This PR adds ROCm support for the eye functor.\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------------------------------------------\r\n\r\n@tatianashp @whchung", "comments": []}, {"number": 29605, "title": "[ROCm] Adding ROCm support for the matrix_band_part op", "body": "This PR adds ROCm support for the matrix_band_part op. \r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.  \r\n\r\n------------------------------\r\n\r\n@tatianashp @whchung\r\n\r\n\r\n", "comments": []}, {"number": 29604, "title": "[ROCm] Adding ROCm support for the matrix_set_diag op", "body": "This PR adds ROCm support for the matrix_set_diag op.\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------------------------------------------------------\r\n\r\n@tatianashp @whchung", "comments": ["@deven-amd could you please resolve conflicts", "@rthadur I have rebased this PR to resolve the merge conflict....thanks"]}, {"number": 29603, "title": "[ROCm] Adding ROCm support for the parameterized_truncated_normal op", "body": "This PR adds ROCm support for the  parameterized_truncated_normal op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n----------------------------------------\r\n\r\n@tatianashp @whchung", "comments": []}, {"number": 29602, "title": "[ROCm] Adding ROCM support for the population_count op", "body": "This PR adds ROCm support for the population_count op\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n----------------------------------------------------\r\n\r\n@tatianashp @whchung ", "comments": []}, {"number": 29600, "title": "[ROCm] Adding ROCm support for slice and strided_slice ops", "body": "This PR adds ROCm support for the slice and strided_slice ops\r\n\r\nThe changes in this PR are trivial, please review and merge...thanks.\r\n\r\n------------------------------------------\r\n\r\n@tatianashp @whchung ", "comments": []}]