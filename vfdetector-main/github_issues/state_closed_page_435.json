[{"number": 40816, "title": "tensorflow 2.0 got following messages", "body": "tensorflow 2.0 \r\n\r\n\r\n2.2.0\r\n\r\n```\r\n2020-06-26 12:33:16.881206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-26 12:33:16.915893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:0b:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-26 12:33:16.916635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \r\npciBusID: 0000:42:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-26 12:33:16.916743: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.916777: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.916811: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.916842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.916874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.916904: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\r\n2020-06-26 12:33:16.918834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-26 12:33:16.918850: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-06-26 12:33:16.919060: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-26 12:33:16.942414: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3493110000 Hz\r\n2020-06-26 12:33:16.943646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf28000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-26 12:33:16.943667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-26 12:33:16.945443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-26 12:33:16.945458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \r\nFound 2000 images belonging to 2 classes.\r\n\r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n```", "comments": ["@SlowMonk,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso if you are using TensorFlow 2.0, please upgrade to the latest version of TensorFlow v2.2 and check if you are facing the same issue. Thanks!", "Also, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/32491#issuecomment-531219851) from a similar issue and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@SlowMonk the segmentation fault is not caused by the warnings you offered. Please provide fully filled issue template and minimal code to reproduce.", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40815, "title": "Segmentation fault when using my own tflite-model for example projects during tests", "body": "@tensorflow/micro\r\n\r\n**Short version of the question:**\r\nMy problem is, that when I try to run a test from **any example project with my own tflite-model, than I always get a segmentation fault**. I'm training the tflite-model in Google colab. After that, I download the tflite-model convert it to a ...model.cc and run \"test_example_project_test\". And like I said, for my own tflite-models I get a segmentation fault if I use other tflite-models (from other projects, just for testing) than I don't get a segmentation fault. I don't know what causes this problem as I'm using exactly the same model-structure than in the hello_world_example Google Colab script, but with my own dataset.\r\n\r\n\r\n\r\n**Long version of the question:**\r\n**System information**\r\n- Host OS Platform and Distribution: **Linux Ubuntu 18.04**\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version: **2.2.0**\r\n- Target platform: **Arm Mbed OS**\r\n- Launch pad: **Disco-F746NG + CAM-Shield**\r\n\r\n**Describe the problem**\r\n\r\nHi. After following the tutorials with success, I'm trying now to build my own small TensorFlow Lite project.\r\nFor achieving this, I use the \"image_recognition_experimental\" example as template.\r\nI renamed the copied template folder to my own project as \"image_recognition\" and changed all source files, header files and the Makefile.inc accordingly.\r\nThe problem is now, that when I want to run the test by entering: \"sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test\" **with my own tflite-model** then I always get a segmentation fault.\r\nI tried a lot of different things (as described below) to find out what causes this problem, but I wasn't able to find it out.\r\nThat's why I'm asking you guys if you can help me identifying the problem?\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n**1. Step:**\r\nI copied the folder \"image_recognition_experimental\" in the path \"/home/tensorflow/tensorflow/lite/micro/examples\" and gave it the name \"image_recognition\"\r\n\r\n**2. Step:**\r\nI changed the #include directives in the source and header files accordingly. For example:\r\nThis: `#include \"tensorflow/lite/micro/examples/image_recognition_experimental/util.h\"`\r\nwas changed to this: `#include \"tensorflow/lite/micro/examples/image_recognition/util.h\"`\r\nWhat was of course pretty straightforward.\r\n\r\n**3. Step:**\r\nI changed the Makefile.inc similar to before by adapting the paths, but I also deleted the \"download model\" instruction and inserted the path to the model instead.\r\nHere is the resulting content of Makefile.inc:\r\n```\r\n\r\n\r\nIMAGE_RECOGNITION_HDRS := \\\r\ntensorflow/lite/micro/examples/image_recognition/image_recognition_model.h \\\r\ntensorflow/lite/micro/examples/image_recognition/image_provider.h \\\r\ntensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_util.h \\\r\ntensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/display_util.h \\\r\ntensorflow/lite/micro/examples/image_recognition/util.h\r\n\r\nIMAGE_RECOGNITION_SRCS := \\\r\ntensorflow/lite/micro/examples/image_recognition/image_recognition_model.cc \\\r\ntensorflow/lite/micro/examples/image_recognition/main.cc \\\r\ntensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_provider.cc \\\r\ntensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/image_util.cc \\\r\ntensorflow/lite/micro/examples/image_recognition/stm32f746_discovery/display_util.cc\r\n\r\nIMAGE_RECOGNITION_TEST_SRCS := \\\r\ntensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc \\\r\ntensorflow/lite/micro/examples/image_recognition/image_recognition_model.cc\r\n\r\nIMAGE_RECOGNITION_TEST_HDRS := \\\r\ntensorflow/lite/micro/examples/image_recognition/image_recognition_model.h \\\r\ntensorflow/lite/micro/examples/image_recognition/util.h\r\n\r\ninclude $(wildcard tensorflow/lite/micro/examples/image_recognition/*/Makefile.inc)\r\n\r\nifneq ($(filter disco_f746ng,$(ALL_TAGS)),)\r\n  MBED_PROJECT_FILES += \\\r\n    BSP_DISCO_F746NG.lib \\\r\n    LCD_DISCO_F746NG.lib\r\nendif\r\n\r\n$(eval $(call microlite_test,image_recognition,\\\r\n$(IMAGE_RECOGNITION_SRCS),$(IMAGE_RECOGNITION_HDRS)))\r\n\r\n$(eval $(call microlite_test,image_recognition_test,\\\r\n$(IMAGE_RECOGNITION_TEST_SRCS),$(IMAGE_RECOGNITION_TEST_HDRS)))\r\n```\r\n\r\n**4. Step:**\r\nI copied the model with the filename \"image_recognition_model.cc\" (which was downloaded before) from \"tensorflow/lite/micro/tools/make/downloads/image_recognition_model/\" into the project path \"tensorflow/lite/micro/examples/image_recognition\".\r\n \r\n**5. Step:**\r\nI ran the test by entering: \"sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test\".\r\nIt worked.\r\n\r\n**6. Step**\r\nNow I used my own model (which is not really useful for solving a task, I only wanted to load it into the interpreter). For making it usable, I deleted the old image_recognition_model.cc and gave my model this name. Then I inserted the header-file and adapted the data-types and so on. But when I now enter: \"sudo make -f tensorflow/lite/micro/tools/make/Makefile test_image_recognition_test\", \r\nI always get the following result:\r\n```\r\ntensorflow/lite/micro/tools/make/Makefile:297: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'\r\ntensorflow/lite/micro/tools/make/Makefile:297: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/ruy'\r\ntensorflow/lite/micro/tools/make/Makefile:297: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'\r\ntensorflow/lite/micro/tools/make/Makefile:297: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'\r\ntensorflow/lite/micro/testing/test_linux_binary.sh tensorflow/lite/micro/tools/make/gen/linux_x86_64/bin/image_recognition_test '~~~ALL TESTS PASSED~~~'\r\nSegmentation fault (core dumped)\r\ntensorflow/lite/micro/examples/image_recognition/Makefile.inc:34: recipe for target 'test_image_recognition_test' failed\r\nmake: *** [test_image_recognition_test] Error 139\r\n```\r\n\r\n**7. Step:**\r\nNow I played around and tried several things:\r\n- I increased `const int tensor_arena_size = 50 * 1024;` in image_recognition_test.cc to 500 * 1024 -> still segmentation fault\r\n- I used all_ops_resolver instead of micro_ops_resolver -> still segmentation fault\r\n- I copied the model from the hello_world example and renamed it to \"image_recogniton_model\" and adapted it -> it worked, **no** segmentation fault\r\n- So I thought maybe it's my TensorFlow Python code and I copied the code for the hello_world-model from: https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb#scrollTo=cr1VLfotanf6 and build a similar model with the same instructions but for my own data -> still segmentation fault\r\n- So I thought maybe I do something wrong by converting the tf-model to a tf-lite model. So I ran the colab research hello_world model training, downloaded the tf-lite model, converted it to a cc-file by xxd and ran again the test. -> it worked, **no** segmentation fault.\r\n\r\n--> So here I am, totally confused and not knowing why I always get segmentation faults for my own models. The only difference between my code and the example code for the hello-world-model-training is that my datasets are arranged differently.\r\nBelow is my Python code for creating the tf-lite model (I'm not only a TensorFlow Lite noob, I'm also a TensorFlow noob as well, learned everything from the official tutorials and the TinyML book)\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers, models\r\nfrom tensorflow import keras\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\nimport IPython.display as display\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nfrom os import walk\r\n\r\n\r\nimport pathlib\r\ntf.__version__\r\n\r\nfrom google.colab import drive\r\ndrive.mount('/content/gdrive')\r\n\r\n# here is some code for getting the file names and creating labels. It's long and messy so I censored it\r\n# there are only two labels, a 1 means object and a 0 means not an object\r\n# ...\r\n\r\nobjectDataset = tf.data.Dataset.from_tensor_slices((objectFilenames, objectLabels))\r\nnotObjectDataset = tf.data.Dataset.from_tensor_slices((notObjectFilenames, notObjectLabels))\r\n\r\ndataset = objectDataset.concatenate(notObjectDataset)\r\n\r\ndataset = dataset.shuffle(18138)\r\n\r\ndef _parse_function(filename, label):\r\n    image_string = tf.io.read_file(filename)\r\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\r\n    image = tf.cast(image_decoded, tf.float32)\r\n    resized_image = tf.image.resize(image, [32, 32])\r\n    grayscale_image = tf.image.rgb_to_grayscale(resized_image)\r\n    return grayscale_image, label\r\n\r\n\r\ndataset = dataset.map(_parse_function)\r\ndataset = dataset.batch(1)\r\n\r\ndatasetSize = tf.data.experimental.cardinality(dataset).numpy()\r\n\r\ntrainSize = int(0.7 * datasetSize)\r\ntestSize = int(0.15 * datasetSize)\r\nvalSize = int(0.15 * datasetSize)\r\n\r\ntrainDataset = dataset.take(trainSize)\r\ntestDataset = dataset.skip(trainSize)\r\nvalDataset = dataset.skip(trainSize)\r\n\r\ntestDataset = dataset.take(testSize)\r\nvalDataset = dataset.skip(testSize)\r\nvalDataset = dataset.take(valSize) \r\n\r\n\r\nprint(tf.data.experimental.cardinality(trainDataset).numpy())\r\nprint(tf.data.experimental.cardinality(testDataset).numpy())\r\nprint(tf.data.experimental.cardinality(valDataset).numpy())\r\n\r\n\r\n\r\n# The following code is copied from train_hello_world_model \r\n# I know that it doesn't make sense like this with my dataset now, I only want a proof-of-concept)\r\n\r\nmodel = tf.keras.Sequential()\r\n\r\n# First layer takes a scalar input and feeds it through 16 \"neurons\". The\r\n# neurons decide whether to activate based on the 'relu' activation function.\r\nmodel.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(32,32,1)))\r\n\r\n# The new second layer may help the network learn more complex representations\r\nmodel.add(tf.keras.layers.Dense(2, activation='relu'))\r\n\r\n# Final layer is a single neuron, since we want to output a single value\r\nmodel.add(tf.keras.layers.Dense(2))\r\n\r\n# Compile the model using a standard optimizer and loss function for regression\r\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\r\n\r\nmodel.summary()\r\n\r\nhistory = model.fit(trainDataset, epochs=1, batch_size=64,\r\n                    validation_data=(ValDataset))\r\n\r\n\r\nmodel.save(\"my_model\")\r\n\r\n%cd /content/gdrive/My\\ Drive\r\n%pwd\r\n\r\n\r\n# Convert the model to the TensorFlow Lite format without quantization\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the model to disk\r\nopen(\"model.tflite\", \"wb\").write(tflite_model)\r\n\r\n!dir\r\n\r\nfrom google.colab import files\r\nfiles.download('model.tflite') \r\n```\r\n\r\n", "comments": ["@asolyou \r\nI ran the code shared on colab and face a different issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/0f1434d7224919cc1e9b163233c44fb9/untitled243.ipynb).\r\nCan you please confirm your cuda version and refer to [this link](https://github.com/tensorflow/tensorflow/issues/40558)", "@Saduf2019 \r\nMany thanks for you answer.\r\n\r\n> I ran the code shared on colab and face a different issue\r\n\r\nDo you mean that the data files are not there? This is because I used my own private pictures which I've uploaded on Google My Drive. That's why I skipped the part of the code in which the names and labels are deduced from the raw images.\r\n\r\nBut I just realised now that I could tell my question much shorter, than this big wall of text. Sry for that. \r\n\r\nSo my problem is, that when I try to run a test from any example with my own model, than I always get a segmentation fault. I don't have cuda on my laptop, I'm training the model in Google colab. After that, I download the model convert it to a ...model.cc and run \"test_example_project_test\". I don't know what causes this problem as I'm using exactly the same model-structure than in the hello_world_example Google Colab script.", "@Saduf2019 \r\nI created now a new tf-lite model with dummy data. So that you can fully run the code without having the effort to change something. You should be able to copy the code into a notebook and just run it and download the resulting model. The model doesn't make sense, of course, I just use it for testing if I'm able to load it into the tflite-interpreter during the tests.\r\n\r\nAfter running this code, I download the tflite-model, convert it by \"xxd -i model.tflite > model.cc\" and copy it to the example project folder and replace the old model file with this one.\r\nThan I run the test by: \"test_example_project_test\" and receive a segmentation fault.\r\n\r\nSo here is the code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers, models\r\nfrom tensorflow import keras\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\nimport IPython.display as display\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nfrom os import walk\r\n\r\n\r\nimport pathlib\r\ntf.__version__\r\n\r\n\r\n\r\n# create a dummy test-dataset\r\n\r\n# create dummy image data\r\ndummy_object_image = []\r\nfor i in range(0, 50):\r\n  tensor = tf.random.uniform(\r\n    (32,32,1), minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None\r\n  )\r\n  dummy_object_image.append(tensor)\r\n\r\ndummy_not_object_image = []\r\nfor i in range(0, 50):\r\n  tensor = tf.random.uniform(\r\n    (32,32,1), minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None\r\n  )\r\n  dummy_not_object_image.append(tensor)\r\n\r\n\r\n# create dummy labels\r\ndummy_object_label = []\r\nfor i in range(0, 50):\r\n  # object\r\n  dummy_object_label.append(1)\r\n\r\ndummy_not_object_label = []  \r\nfor i in range(0, 50):\r\n  # object\r\n  dummy_not_object_label.append(0)\r\n\r\n\r\nobjectDataset = tf.data.Dataset.from_tensor_slices((dummy_object_image, dummy_object_label))\r\nnotObjectDataset = tf.data.Dataset.from_tensor_slices((dummy_not_object_image, dummy_not_object_label))\r\n\r\ndataset = objectDataset.concatenate(notObjectDataset)\r\n\r\ndataset = dataset.shuffle(100)\r\n\r\n\r\ndataset = dataset.batch(1)\r\n\r\ndatasetSize = tf.data.experimental.cardinality(dataset).numpy()\r\n\r\ntrainSize = int(0.7 * datasetSize)\r\ntestSize = int(0.15 * datasetSize)\r\nvalSize = int(0.15 * datasetSize)\r\n\r\ntrainDataset = dataset.take(trainSize)\r\ntestDataset = dataset.skip(trainSize)\r\nvalDataset = dataset.skip(trainSize)\r\n\r\ntestDataset = dataset.take(testSize)\r\nvalDataset = dataset.skip(testSize)\r\nvalDataset = dataset.take(valSize) \r\n\r\n\r\nprint(tf.data.experimental.cardinality(trainDataset).numpy())\r\nprint(tf.data.experimental.cardinality(testDataset).numpy())\r\nprint(tf.data.experimental.cardinality(valDataset).numpy())\r\n\r\n\r\n\r\n# The following code is copied from train_hello_world_model \r\n# I know that it doesn't make sense like this with my dataset now, I only want a proof-of-concept)\r\n\r\nmodel = tf.keras.Sequential()\r\n\r\n# First layer takes a scalar input and feeds it through 16 \"neurons\". The\r\n# neurons decide whether to activate based on the 'relu' activation function.\r\nmodel.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(32,32,1)))\r\n\r\n# The new second layer may help the network learn more complex representations\r\nmodel.add(tf.keras.layers.Dense(2, activation='relu'))\r\n\r\n# Final layer is a single neuron, since we want to output a single value\r\nmodel.add(tf.keras.layers.Dense(2))\r\n\r\n# Compile the model using a standard optimizer and loss function for regression\r\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\r\n\r\nmodel.summary()\r\n\r\nhistory = model.fit(trainDataset, epochs=1, batch_size=64,\r\n                    validation_data=(valDataset))\r\n\r\n\r\nmodel.save(\"my_model\")\r\n\r\n%cd /content/gdrive/My\\ Drive\r\n%pwd\r\n\r\n\r\n# Convert the model to the TensorFlow Lite format without quantization\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the model to disk\r\nopen(\"model.tflite\", \"wb\").write(tflite_model)\r\n\r\n!dir\r\n\r\nfrom google.colab import files\r\nfiles.download('model.tflite') \r\n```", "I figured now out what causes the problem: It is the way in which I created the dataset and how it is ordered. If I use python lists / 2 dimensional arrays for the data, **then the resulting tflite-model is not causing a segmentation fault**.\r\nThen I finally get the result I was looking for by entering \"test_image_recognition_test\", which is:\r\n\r\n```\r\n...\r\ntensorflow/lite/micro/testing/test_linux_binary.sh tensorflow/lite/micro/tools/make/gen/linux_x86_64/bin/image_recognition_test\r\n~~~ALL TESTS PASSED~~~\r\ntensorflow/lite/micro/tools/make/gen/linux_x86_64/bin/image_recognition_test: FAIL - '~~~ALL TESTS PASSED~~~' not found in logs.\r\nTesting TestImageRecognitionInvoke\r\n4 == input->dims->size failed at tensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc:69 (4 vs 3)\r\n3 == input->dims->data[3] failed at tensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc:73 (3 vs 14)\r\nkTfLiteUInt8 == input->type failed at tensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc:74 (3 vs 1)\r\n6 == num_correct failed at tensorflow/lite/micro/examples/image_recognition/image_recognition_test.cc:106 (6 vs 2)\r\n0/1 tests passed\r\n~~~SOME TESTS FAILED~~~\r\n```\r\n\r\nSo some function-calls like the following: `tf.data.Dataset.from_tensor_slices((dummy_object_image, dummy_object_label)) `or the way in which the tf-tensor has been structured caused the problem.\r\nFor me as a tflite-newbie thats strange, because the resulting model.cc content looks very similar. From now on I will only use numpy functions whenever possible, because it seems like some tensorflow functions for preprocessing the data are not supported by TensorFlow Lite.\r\n\r\n\r\n**Here is the code for the dummy tflite-model that works:**\r\n\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers, models\r\nfrom tensorflow import keras\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\nimport IPython.display as display\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nfrom os import walk\r\n\r\n\r\nimport pathlib\r\ntf.__version__\r\n\r\n\r\n# create a dummy test-dataset\r\n\r\n# create dummy image data\r\ndummy_object_image = []\r\nfor i in range(0, 50):\r\n  single_image = np.random.rand(32,32)\r\n  dummy_object_image.append(single_image)\r\n\r\ndummy_not_object_image = []\r\nfor i in range(0, 50):\r\n  single_image = np.random.rand(32,32)\r\n  dummy_not_object_image.append(single_image)\r\n\r\nprint(len(x_values))\r\n\r\n\r\n# create dummy labels\r\ndummy_object_label = []\r\nfor i in range(0, 50):\r\n  # object\r\n  dummy_object_label.append(1)\r\n\r\ndummy_not_object_label = []  \r\nfor i in range(0, 50):\r\n  # object\r\n  dummy_not_object_label.append(0)\r\n\r\ny_values = dummy_object_label + dummy_not_object_label\r\n\r\nnp.random.shuffle(y_values)\r\n\r\n\r\nTRAIN_SPLIT = 60\r\nTEST_SPLIT = 80\r\n\r\nx_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\r\ny_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\r\n\r\n\r\n# The following code is copied from train_hello_world_model \r\n# I know that it doesn't make sense like this with my dataset now, I only want a proof-of-concept)\r\n# We'll use Keras to create a simple model architecture\r\nmodel = tf.keras.Sequential()\r\n\r\n# First layer takes a scalar input and feeds it through 8 \"neurons\". The\r\n# neurons decide whether to activate based on the 'relu' activation function.\r\nmodel.add(keras.layers.Dense(8, activation='relu', input_shape=(32,32)))\r\n\r\n# Final layer is a single neuron, since we want to output a single value\r\nmodel.add(keras.layers.Dense(1))\r\n\r\n# Compile the model using a standard optimizer and loss function for regression\r\nmodel.compile(optimizer='adam', loss='mse', metrics=['mae'])\r\n\r\n# Compile the model using a standard optimizer and loss function for regression\r\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\r\n\r\nmodel.summary()\r\n\r\n# Train the model on our training data while validating on our validation set\r\nhistory_1 = model.fit(x_train, y_train, epochs=10, batch_size=64,\r\n                    validation_data=(x_validate, y_validate))\r\n\r\n\r\nmodel.save(\"my_model\")\r\n\r\n%cd /content/gdrive/My\\ Drive\r\n%pwd\r\n\r\n\r\n# Convert the model to the TensorFlow Lite format without quantization\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the model to disk\r\nopen(\"model.tflite\", \"wb\").write(tflite_model)\r\n\r\n!dir\r\n\r\nfrom google.colab import files\r\nfiles.download('model.tflite') \r\n```\r\n\r\n", "@asolyou can you send the complete code for training tflite."]}, {"number": 40814, "title": "CUDA illegal error access error when running distributed mixed precision", "body": "Whenever I try to train a model using MirroredStrategy and mixed precision, at an indeterminate time, I get the following error:\r\n\r\n```\r\n./tensorflow/core/kernels/conv_2d_gpu.h:970] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, kNumThreads, kTileSize, kTileSize, conjugate>, total_tiles_count, kNumThreads, 0, d.stream(), input, input_dims, output) status: Internal: an illegal memory access was encountered\r\n2020-06-25 00:45:27.788127: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-06-25 00:45:27.788208: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\n```\r\n\r\nUnfortunately, I don't have a simply example to reproduce this and can't include my entire code. But maybe other people are having similar issues and can produce a better example.\r\n\r\nI'm running tensorflow 2.2.0 on ubuntu 18.04. CUDA 10.1.243, CuDNN 7.6.5 using two RTX 2080 ti cards. I get the same error on a V100.\r\n", "comments": ["@lminer \r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "I can't give you all the code, but I use the basic approach below:\r\n```python\r\npolicy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\r\ntf.keras.mixed_precision.experimental.set_policy(policy)\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    logits = get_logits()\r\n    model = tf.keras.Model(inputs, logits)\r\n\r\n\r\nmodel.fit(X, y)  # X and y are datasets read from tfrecords\r\n```\r\nI run this from the official tensorflow docker container.", "Is there a flag I can use to get a more detailed stack trace?", "I ran this with cuda-memcheck and the error occured at an earlier point:\r\n\r\n```\r\n========= Internal Memcheck Error: Initialization failed\r\n=========     Saved host backtrace up to driver entry point at error\r\n=========     Host Frame:/usr/lib/x86_64-linux-gnu/libcuda.so.1 [0x1403fc]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3d7e4a]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3caf70]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3d719a]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3dae9f]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3db60a]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3cec3c]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3bed7e]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x3f022c]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x379a2]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x37fa6]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x39af2]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x37fa6][48/2973]=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 [0x39af2]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 (cufftXtMakePlanMany + 0x63a) [0x4d0ca]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 (cufftMakePlanMany64 + 0x157) [0x4e087]\r\n=========     Host Frame:/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcufft.so.10 (cufftMakePlanMany + 0x193) [0x4aaf3]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2 (_ZN15stream_executor3gpu11CUDAFftPlan10InitializeEPNS0_11GpuExecutorEPNS_6StreamEiPyS6_yyS6_yyNS_3fft4TypeEiPNS_16ScratchAllocatorE + 0x1e6) [0x15949b6]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2 (_ZN15stream_executor3gpu7CUDAFft37CreateBatchedPlanWithScratchAllocatorEPNS_6StreamEiPyS4_yyS4_yyNS_3fft4TypeEbiPNS_16ScratchAllocatorE + 0xca) [0x159614a]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow10FFTGPUBase5DoFFTEPNS_15OpKernelContextERKNS_6TensorEPyPS3_ + 0x3bf) [0x5157bff]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow7FFTBase7ComputeEPNS_15OpKernelContextE + 0x453) [0x50f2fa3]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2 (_ZN10tensorflow13BaseGPUDevice7ComputeEPNS_8OpKernelEPNS_15OpKernelContextE + 0xe6) [0xf385f6]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow17KernelAndDeviceOp3RunEPNS_19ScopedStepContainerERKNS_15EagerKernelArgsEPSt6vectorINS_6TensorESaIS7_EEPNS_19CancellationManagerERKN4absl8optionalINS_25EagerRemoteFunctionParamsEEE + 0x64f) [0x378dd3f]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow17KernelAndDeviceOp3RunERKNS_15EagerKernelArgsEPSt6vectorINS_6TensorESaIS5_EEPNS_19CancellationManagerERKN4absl8optionalINS_25EagerRemoteFunctionParamsEEE + 0x2f) [0x378e23f]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow18EagerKernelExecuteEPNS_12EagerContextERKN4absl13InlinedVectorIPNS_12TensorHandleELm4ESaIS5_EEERKNS2_8optionalINS_25EagerRemoteFunctionParamsEEERKSt10unique_ptrINS_15KernelAndDeviceENS_4core15RefCountDeleterEEPNS_14GraphCollectorEPNS_19CancellationManagerENS2_4SpanIS5_EE + 0x60b) [0x376100b]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow11ExecuteNode3RunEv + 0x170) [0x3761be0]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow13EagerExecutor11SyncExecuteEPNS_9EagerNodeE + 0x1b$) [0x3789684]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so [0x375bb8c]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow12EagerExecuteEPNS_14EagerOperationEPPNS_12TensorHandleEPi + 0x2d2) [0x375f1a2]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_ZN10tensorflow18OperationInterface7ExecuteEPN4absl10FixedArrayISt10unique_ptrI29AbstractTensorHandleInterfaceSt14default_deleteIS4_EELm18446744073709551615ESaIS7_EEEPi +\r\n0x6b) [0x332917b]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (TFE_Execute + 0x91) [0x3317e91]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (_Z24TFE_Py_FastPathExecute_CP7_object + 0x1af1) [0x2fc9931]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so [0x20ef7]\r\n=========     Host Frame:/home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so [0x42c09]\r\n=========     Host Frame:python (_PyMethodDef_RawFastCallKeywords + 0x264) [0x163c34]\r\n=========     Host Frame:python (_PyCFunction_FastCallKeywords + 0x21) [0x163d51]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x4ebc) [0x1d00ac]\r\n=========     Host Frame:python (_PyEval_EvalCodeWithName + 0x2f9) [0x1131b9]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0x387) [0x163437]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x14eb) [0x1cc6db]\r\n=========     Host Frame:python (_PyEval_EvalCodeWithName + 0xab8) [0x113978]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0x387) [0x163437]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x4b29) [0x1cfd19]\r\n=========     Host Frame:python (_PyEval_EvalCodeWithName + 0x2f9) [0x1131b9]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0x387) [0x163437]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x14eb) [0x1cc6db]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0xfb) [0x1631ab]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x416) [0x1cb606]\r\n=========     Host Frame:python (_PyEval_EvalCodeWithName + 0x2f9) [0x1131b9]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0x387) [0x163437]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x14eb) [0x1cc6db]\r\n=========     Host Frame:python (_PyEval_EvalCodeWithName + 0x2f9) [0x1131b9]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0x325) [0x1633d5]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x416) [0x1cb606]\r\n=========     Host Frame:python (_PyFunction_FastCallKeywords + 0xfb) [0x1631ab]\r\n=========     Host Frame:python (_PyEval_EvalFrameDefault + 0x6a3) [0x1cb893]\r\n=========\r\n2020-06-27 16:22:40.585959: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event\r\nstatus: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered\r\n2020-06-27 16:22:40.586021: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event\r\nstatus: 1\r\n```", "@lminer Can you please provide us the full reproducible code for us to reproduce this issue. We can't reproduce the issue currently as the code you provided is not enough. Thanks!", "@lminer did you figure what causes this error?", "@ben0it8 no, and I'm having trouble creating a reproducible example that isn't just my entire code base. Do you have one?", "@gowthamkpr, I have a reproducible example. This will crash if I run: `TF_FORCE_GPU_ALLOW_GROWTH=true python fail.py`.\r\n\r\nWhere `fail.py` is as below. Interestingly, it does not crash with I don't set TF_FORCE_GPU_ALLOW_GROWTH to true. I'm running tensorflow 2.2.0 on ubuntu 18.04. CUDA 10.1.243, CuDNN 7.6.5 using two RTX 2080 ti cards. I get the same error on a V100. This only happens if I enable mixed precision and Mirrored distribute strategy.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\nclass Conv2dLayer(tf.keras.layers.Layer):\r\n    def __init__(self, filters, kernel_size, strides=1, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.activation = tf.keras.layers.LeakyReLU()\r\n        self.conv = tf.keras.layers.Conv2D(\r\n            filters, kernel_size, strides=strides, padding=\"same\", kernel_initializer=\"he_normal\",\r\n        )\r\n        self.batch_norm = tf.keras.layers.BatchNormalization()\r\n        self.filters = filters\r\n        self.kernel_size = kernel_size\r\n        self.strides = strides\r\n\r\n    def call(self, inputs, **kwargs):\r\n        x = self.conv(inputs)\r\n        x = self.activation(x)\r\n        x = self.batch_norm(x)\r\n        return x\r\n\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config[\"filters\"] = self.filters\r\n        config[\"kernel_size\"] = self.kernel_size\r\n        config[\"strides\"] = self.strides\r\n        return config\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return self.conv.compute_output_shape(input_shape)\r\n\r\n\r\nclass UpSampleLayer(tf.keras.layers.Layer):\r\n    def __init__(self, filters, strides=2, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dropout = tf.keras.layers.Dropout(0.5)\r\n        self.activation = tf.keras.layers.LeakyReLU()\r\n        self.upconv = tf.keras.layers.Conv2DTranspose(\r\n            filters, 4, strides=strides, padding=\"same\", kernel_initializer=\"he_normal\"\r\n        )\r\n        self.batch_norm = tf.keras.layers.BatchNormalization()\r\n        self.filters = filters\r\n        self.strides = strides\r\n\r\n    def call(self, inputs, **kwargs):\r\n        x = self.upconv(inputs)\r\n        x = self.batch_norm(x)\r\n        x = self.dropout(x)\r\n        return self.activation(x)\r\n\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config[\"filters\"] = self.filters\r\n        config[\"strides\"] = self.strides\r\n        return config\r\n\r\n\r\nclass DownsampleBlock(tf.keras.layers.Layer):\r\n    def __init__(self, filters, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.filters = filters\r\n\r\n        self.conv1 = Conv2dLayer(filters, 4)\r\n        self.conv2 = Conv2dLayer(filters, 4)\r\n        self.downsample_conv = Conv2dLayer(filters, 4, strides=2)\r\n        self.dropout = tf.keras.layers.Dropout(0.5)\r\n\r\n    def call(self, inputs, **kwargs):\r\n        x = self.conv1(inputs)\r\n        x = self.conv2(x)\r\n        x = self.downsample_conv(x)\r\n        x = self.dropout(x)\r\n        return x\r\n\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config[\"filters\"] = self.filters\r\n        return config\r\n\r\n\r\nclass Unet(tf.keras.models.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.mask = tf.keras.layers.Activation(\"relu\")\r\n        self.axis = -1\r\n        self.downsample_blocks = []\r\n        self.upsample_blocks = []\r\n\r\n        n_maps_list = []\r\n\r\n        for i in range(6):\r\n            n_maps = 16 * 2 ** i\r\n            n_maps_list.insert(0, n_maps)\r\n            self.downsample_blocks.append(DownsampleBlock(n_maps))\r\n\r\n        for i, n_maps in enumerate(n_maps_list[1:]):\r\n            self.upsample_blocks.append(UpSampleLayer(n_maps, strides=2))\r\n        self.upsample_blocks.append(UpSampleLayer(2, strides=2))\r\n\r\n    def call(self, inputs, training=None, mask=None):\r\n        skip_connections = []\r\n        x = inputs\r\n        for downsample_block in self.downsample_blocks:\r\n            x = downsample_block(x)\r\n            skip_connections.insert(0, x)\r\n\r\n        x = self.upsample_blocks[0](x)  # no skip connection used for first block\r\n        for upsample_block, h in zip(self.upsample_blocks[1:], skip_connections[1:]):\r\n            x = upsample_block(tf.keras.layers.concatenate([x, h], axis=self.axis))\r\n        return self.mask(x)\r\n\r\n\r\ndef train():\r\n    BATCH_SIZE = 16\r\n    WIDTH = 256\r\n    HEIGHT = 512\r\n    CHANNELS = 2\r\n    policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\r\n    tf.keras.mixed_precision.experimental.set_policy(policy)\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    with strategy.scope():\r\n        model = Unet()\r\n        model.build(input_shape=(None, WIDTH, HEIGHT, CHANNELS))\r\n        model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\r\n\r\n    examples = np.random.rand(BATCH_SIZE * 20, WIDTH, HEIGHT, CHANNELS)\r\n    target = np.random.rand(BATCH_SIZE * 20, WIDTH, HEIGHT, CHANNELS)\r\n\r\n    ds = tf.data.Dataset.from_tensor_slices((examples, target))\r\n    ds = ds.repeat()\r\n    ds = ds.batch(BATCH_SIZE)\r\n    model.fit(ds, steps_per_epoch=1875, epochs=10)\r\n\r\n\r\ntrain()\r\n```\r\nThe error is as follows:\r\n\r\n```\r\n2020-07-09 12:29:38.319163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-09 12:29:39.314182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1                                                           \r\n[96/108]2020-07-09 12:29:39.348856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:0a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-07-09 12:29:39.349533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:42:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-07-09 12:29:39.349555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-09 12:29:39.350837: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-09 12:29:39.351923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-07-09 12:29:39.352101: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-09 12:29:39.353272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-09 12:29:39.353937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-09 12:29:39.356280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-09 12:29:39.358938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu\r\ndevices: 0, 1\r\n2020-07-09 12:29:39.359275: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary\r\nis optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-07-09 12:29:39.383097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3499590000 Hz\r\n2020-07-09 12:29:39.384148: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d32e968bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-07-09 12:29:39.384186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-07-09 12:29:39.566332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:\r\npciBusID: 0000:0a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-07-09 12:29:39.566949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:\r\npciBusID: 0000:42:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-07-09 12:29:39.566982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-09 12:29:39.567005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-07-09 12:29:39.567016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully\r\n opened dynamic library libcufft.so.10                                                          [48/108]2020-07-09 12:29:39.567027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-07-09 12:29:39.567036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-07-09 12:29:39.567045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-07-09 12:29:39.567057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-09 12:29:39.569326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu\r\ndevices: 0, 1\r\n2020-07-09 12:29:39.569507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-07-09 12:29:40.324951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-07-09 12:29:40.324995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1\r\n2020-07-09 12:29:40.325002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N\r\n2020-07-09 12:29:40.325007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N\r\n2020-07-09 12:29:40.327546: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-07-09 12:29:40.327582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow\r\ndevice (/job:localhost/replica:0/task:0/device:GPU:0 with 10066 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:0a:00.0, compute capability: 7.5)\r\n2020-07-09 12:29:40.329152: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-07-09 12:29:40.329169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow\r\ndevice (/job:localhost/replica:0/task:0/device:GPU:1 with 10064 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5)\r\n2020-07-09 12:29:40.330787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d35311c4c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-07-09 12:29:40.330807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-07-09 12:29:40.330814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\r\nEpoch 1/10\r\nWARNING:tensorflow:From /home/lminer/anaconda3/envs/separate2/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\n2020-07-09 12:30:03.105866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-07-09 12:30:04.367518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\ntensor1:73142:73386 [1] NCCL INFO Bootstrap : Using [0]enp8s0:10.10.2.159<0>\r\ntensor1:73142:73386 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\r\ntensor1:73142:73386 [1] NCCL INFO NET/IB : No device found.\r\ntensor1:73142:73386 [1] NCCL INFO NET/Socket : Using [0]enp8s0:10.10.2.159<0>\r\ntensor1:73142:73386 [1] NCCL INFO Using network Socket\r\nNCCL version 2.7.3+cudaCUDA_MAJOR.CUDA_MINOR\r\ntensor1:73142:73601 [0] NCCL INFO Channel 00/02 :    0   1\r\ntensor1:73142:73601 [0] NCCL INFO Channel 01/02 :    0   1\r\ntensor1:73142:73601 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\r\ntensor1:73142:73601 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1\r\ntensor1:73142:73601 [0] NCCL INFO Setting affinity for GPU 0 to ffff\r\ntensor1:73142:73602 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\r\ntensor1:73142:73602 [1] NCCL INFO Trees [0] -1/-1/-1->1->0|0->1->-1/-1/-1 [1] -1/-1/-1->1->0|0->1->-1/-1/-1\r\ntensor1:73142:73602 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000\r\ntensor1:73142:73602 [1] NCCL INFO Could not enable P2P between dev 1(=42000) and dev 0(=a000)\r\ntensor1:73142:73601 [0] NCCL INFO Could not enable P2P between dev 0(=a000) and dev 1(=42000)\r\ntensor1:73142:73601 [0] NCCL INFO Could not enable P2P between dev 0(=a000) and dev 1(=42000)\r\ntensor1:73142:73602 [1] NCCL INFO Could not enable P2P between dev 1(=42000) and dev 0(=a000)\r\ntensor1:73142:73601 [0] NCCL INFO Channel 00 : 0[a000] -> 1[42000] via direct shared memory\r\ntensor1:73142:73602 [1] NCCL INFO Channel 00 : 1[42000] -> 0[a000] via direct shared memory\r\ntensor1:73142:73601 [0] NCCL INFO Could not enable P2P between dev 0(=a000) and dev 1(=42000)\r\ntensor1:73142:73602 [1] NCCL INFO Could not enable P2P between dev 1(=42000) and dev 0(=a000)\r\ntensor1:73142:73601 [0] NCCL INFO Could not enable P2P between dev 0(=a000) and dev 1(=42000)\r\ntensor1:73142:73602 [1] NCCL INFO Could not enable P2P between dev 1(=42000) and dev 0(=a000)\r\ntensor1:73142:73601 [0] NCCL INFO Channel 01 : 0[a000] -> 1[42000] via direct shared memory\r\ntensor1:73142:73602 [1] NCCL INFO Channel 01 : 1[42000] -> 0[a000] via direct shared memory\r\ntensor1:73142:73601 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\ntensor1:73142:73601 [0] NCCL INFO comm 0x55d409f64000 rank 0 nranks 2 cudaDev 0 busId a000 - Init COMPLETE\r\ntensor1:73142:73602 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\r\ntensor1:73142:73602 [1] NCCL INFO comm 0x55d3fee0e000 rank 1 nranks 2 cudaDev 1 busId 42000 - Init COMPLETE\r\ntensor1:73142:73598 [0] NCCL INFO Launch mode Group/CGMD\r\n 256/1875 [===>..........................] - ETA: 2:30 - loss: 0.45892020-07-09 12:30:29.803542: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-07-09 12:30:29.803584: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event\r\nstatus: 1\r\n2020-07-09 12:30:29.803545: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event\r\nstatus: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-07-09 12:30:29.803665: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event\r\nstatus: 1\r\n./fail.sh: line 7: 73142 Aborted                 (core dumped) NCCL_DEBUG=INFO TF_FORCE_GPU_ALLOW_GROWTH=true LD_LIBRARY_PATH=/usr/local/cuda-10.1/extras/CUPTI/lib64/:$LD_LIBRARY_PATH TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD=99999999999999999999999999999999 LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4 /home/lminer/anaconda3/envs/separate2/bin/python fail.py\r\n```\r\n", "Unfortunately I was not able to reproduce this on P100 or Titan-V.  Can you try running with `CUDA_LAUNCH_BLOCKING=1`?  That will tell us which kernel cause the crash.", "@sanjoy when I run it with that option, the model is loaded into the memory of both GPUs, but only one GPU actually sees any utilization and there is no crash.", "@dubey Have you seen similar issues before?", "I get the same error when running multi-gpu training with 2 or 3 RTX 2080Tis. My code is very similar to yours, with the exception that I do not use mixed precision.", "@sanjoy No I haven't seen this issue before.  ", "Ok guys, I think I've found a solution, which seems to work for me. \r\n\r\nI followed the instructions here: https://github.com/NVIDIA/framework-determinism - I enabled ```os.environ['TF_CUDNN_DETERMINISTIC']='1'```\r\n\r\nThen I fixed all the random seeds:\r\n\r\n```\r\nrandom.seed(42)\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)\r\n```\r\n\r\nThe model has been running without a hitch for many epochs now. Seems that the non-determinism of some operations might cause these multi-gpu issues. Keep in mind - I don't fully understand WHY this works, just know that it does work for a similar problem. Do let me know if this helps.\r\n\r\nAlso, keep in mind the instructions here: https://github.com/NVIDIA/framework-determinism are a bit different from the ones I originally used (here; https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu/62712389#62712389). Might be worth trying both sets.\r\n", "I get the same error when running multi-gpu mixed precision training with 2  RTX 2080Ti . Any solutions ?", "@dolhasz can you confirm that  enforcing determinism indeed solved your issue? also, which layer/op do you suspect to cause the error?", "I have a very similar setup as @lminer, and Luke's solution of NOT setting `TF_FORCE_GPU_ALLOW_GROWTH` works for me too. Thanks, @lminer!", "> Ok guys, I think I've found a solution, which seems to work for me.\r\n> \r\n> I followed the instructions here: https://github.com/NVIDIA/framework-determinism - I enabled `os.environ['TF_CUDNN_DETERMINISTIC']='1'`\r\n> \r\n> Then I fixed all the random seeds:\r\n> \r\n> ```\r\n> random.seed(42)\r\n> np.random.seed(42)\r\n> tf.random.set_seed(42)\r\n> ```\r\n> \r\n> The model has been running without a hitch for many epochs now. Seems that the non-determinism of some operations might cause these multi-gpu issues. Keep in mind - I don't fully understand WHY this works, just know that it does work for a similar problem. Do let me know if this helps.\r\n> \r\n> Also, keep in mind the instructions here: https://github.com/NVIDIA/framework-determinism are a bit different from the ones I originally used (here; https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu/62712389#62712389). Might be worth trying both sets.\r\n\r\nThis works for me. Thanks @dolhasz !\r\nMy set up is CUDA10.1, tensorflow 2.4.1, GTX1080Ti x2. Previously, I ran into this error whenever I use my newly added GPU to train. Interestingly, the newly added GPU has GPU id 0", "I faced a very similar issue.\r\nI was loading the Tensorflow pretrained model at every function call.\r\nI am not sure but for me this was the problem as the GPU was running out of memory.\r\n\r\nLoading the model just once solved the issue.", "@lminer ,\r\nCan you please try this [comment](https://github.com/tensorflow/tensorflow/issues/40814#issuecomment-663838196) with the latest stable version v2.7 and let us know the issue still persists.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40814\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40814\">No</a>\n"]}, {"number": 40813, "title": "[CherryPick:r2.3] Fix docker for numpy", "body": null, "comments": []}, {"number": 40812, "title": "Add \"align_corners\" and \"half_pixel_centers\" as argument to tf.image.resize ", "body": "tf.compat.v1.image.resize_nearest_neighbor, tf.compat.v1.image.resize_bilinear and tf.compat.v1.image.resize_bicubic all have \"align_corners\" and \"half_pixel_centers\" as argument for user to set or unset.\r\nCan tf.image.resize provides \"align_corners\" and \"half_pixel_centers\" as argument for user to use too? \r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.2.0\r\n\r\n**Who will benefit with this feature?**\r\nFor user who is currently using \"align_corners\" and \"half_pixel_centers\" in tf.compat.v1.image.resize_nearest_neighbor, tf.compat.v1.image.resize_bilinear and tf.compat.v1.image.resize_bicubic, want to migrate to use tf.image.resize \r\n\r\n", "comments": ["@winnietsang Sorry for the late response. Are you still interested in contributing this feature?\r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue or raise a PR in [keras-team/keras repo.](https://github.com/keras-team/keras/issues). Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40811, "title": "Fix docs for model_from_config", "body": "- Change model name\r\n- Provide correct model usage\r\n\r\nRefer to this issue: https://github.com/tensorflow/tensorflow/issues/40725\r\ncc: @ymodak ", "comments": ["Hi, is anyone reviewing this PR? @k-w-w @ymodak ", "@yil532 Can you please check @k-w-w's comments and keep us posted ? Thanks!", "@gbaned @k-w-w Could you plz check again?", "@k-w-w Just made changes"]}, {"number": 40810, "title": "segmentation fault in ctc_decode function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nSegmentation fault occurs in `tf.keras.backend.ctc_decode` when passing a large value for `top_paths` and setting `greedy` to `False`. If it is far large enough to be out of range of `int32`, the function handles the error properly by throwing an exception in python, but when it is around the boundary of the range, the function produces a segfault.\r\n\r\n**Describe the expected behavior**\r\nNo segfault. \r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\ny_pred = [[[4.7, 3.2, 2.8],\r\n        [4.9, 1.0, 3.0]],\r\n\r\n       [[3.9, 3.8, 1.4],\r\n        [1.0, 1.6, 3.8]],\r\n\r\n       [[4.0 , 4.5, 3.9],\r\n        [2.2, 2.2, 4.5]]]\r\ninput_length = [3, 2, 2]\r\ntop_paths = 2147483697\r\n\r\ntf.keras.backend.ctc_decode(y_pred, input_length, False, 100, top_paths)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nSegmentation fault (core dumped)\r\n```\r\n", "comments": ["Colab session crashes after using all available RAM. Tested with TF version 2.2.0", "Fixed https://github.com/tensorflow/tensorflow/commit/23693102bf820cbed93b7be0cf43f44db9faca02", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40810\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40810\">No</a>\n"]}, {"number": 40809, "title": "[CherryPick:r2.3] Fix the api docstrings for `on_*_batch_begin` methods in `callbacks.Callback` class.", "body": "PiperOrigin-RevId: 318203984\nChange-Id: I85e2aa5d4c498b67f3e9130fa45a38173f84b35b", "comments": []}, {"number": 40808, "title": "[CherryPick:r2.3] Allow tf.distribute.TPUStrategy to be used with TPUEmbedding API and ensure that LossScaleOptimizer properly rejects it.", "body": "PiperOrigin-RevId: 318186211\nChange-Id: Id3b9cb8288e5d28ddbaec97d5b35627ab35bc08d", "comments": []}, {"number": 40807, "title": "[CherryPick r2.3] Fix a critical breakage in `training` argument default value in inference for layers with a default of `training=True` called in e.g. a Sequential container.", "body": "PiperOrigin-RevId: 318145694\nChange-Id: I1af5286824e3a45e1a7d1b8a4fadd7ec223895dc", "comments": []}, {"number": 40806, "title": "[TFTRT] Possible issue with Conv2D converter without `is_dynamic_op= True`", "body": "@tfeher @bixia1 FYI\r\n\r\nAs discussed yesterday, here are the steps to reproduce:\r\n\r\n```python\r\nimport os\r\nimport numpy as np\r\nimport shutil\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\nfrom tensorflow.python.saved_model import tag_constants\r\n\r\nfrom distutils.version import LooseVersion\r\n\r\nIS_DYNAMIC_OP = True\r\n\r\nif LooseVersion(tf.__version__) >= LooseVersion(\"2.0.0\"):\r\n    import tensorflow.compat.v1 as tf\r\n\r\ntf.logging.set_verbosity(tf.logging.ERROR)\r\n\r\nwith tf.Graph().as_default() as _g:\r\n    with tf.Session(graph=_g) as sess:\r\n\r\n        saved_model_loaded = tf.saved_model.load(\r\n            export_dir=\"model-export/1591942827/\",\r\n            tags=[tag_constants.SERVING],\r\n            sess=sess\r\n        )\r\n\r\n        # Get tensors (input and output) by name\r\n        input_tensor = _g.get_tensor_by_name(\"input_tensor:0\")  # [None, 224, 224, 3]\r\n        output_probs = _g.get_tensor_by_name(\"resnext101-32x4d/output/softmax:0\")\r\n        output_class_id = _g.get_tensor_by_name(\"ArgMax:0\")\r\n\r\n        print(\"Bottleneck Block 0 0:\")\r\n        for layer in tf.global_variables():\r\n            if \"btlnck_block_0_0\" in layer.name:\r\n                print(\"\\t[*]\", layer.name, layer.get_shape())\r\n\r\n        print(\"\\nRunning Raw Saved Model - No TF-TRT:\\n\")\r\n\r\n        for idx in range(10):\r\n            probs, class_id = sess.run(\r\n                [output_probs, output_class_id],\r\n                feed_dict={input_tensor: np.random.random((10, 224, 224, 3))}\r\n            )\r\n            print(\"[{}] - {}\".format(idx, class_id))\r\n\r\n        default_graph_def = _g.as_graph_def()\r\n\r\n        output_node_names = [\r\n            'resnext101-32x4d/output/softmax',\r\n            'ArgMax',\r\n        ]\r\n        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess,\r\n            tf.get_default_graph().as_graph_def(),\r\n            output_node_names=output_node_names\r\n        )\r\n        frozen_graph_def = tf.graph_util.remove_training_nodes(frozen_graph_def)\r\n\r\nwith tf.Graph().as_default() as _g:\r\n    with tf.Session(graph=_g) as sess:\r\n\r\n        converter = trt.TrtGraphConverter(\r\n            input_saved_model_dir='model-export/1591942827/',\r\n            is_dynamic_op=IS_DYNAMIC_OP,\r\n        )\r\n        converter.convert()\r\n\r\n        tftrt_savedir=\"model-export/tftrt_model/\"\r\n\r\n        if os.path.exists(tftrt_savedir):\r\n            shutil.rmtree(tftrt_savedir)\r\n\r\n        converter.save(output_saved_model_dir=tftrt_savedir)\r\n\r\n        tf.saved_model.loader.load(\r\n             sess,\r\n             [tf.saved_model.tag_constants.SERVING],\r\n             export_dir='model-export/tftrt_model/'\r\n        )\r\n        input_tensor = _g.get_tensor_by_name(\"input_tensor:0\")  # [None, 224, 224, 3]\r\n        output_probs = _g.get_tensor_by_name(\"resnext101-32x4d/output/softmax:0\")\r\n        output_class_id = _g.get_tensor_by_name(\"ArgMax:0\")\r\n\r\n        print(\"\\nRunning TF-TRT Saved Model:\\n\")\r\n        for idx in range(10):\r\n            # Inference on single image\r\n            probs, class_id = sess.run(\r\n                [output_probs, output_class_id],\r\n                feed_dict={input_tensor: np.random.random((10, 224, 224, 3))}\r\n            )\r\n            print(\"[{}] - {}\".format(idx, class_id))\r\n```\r\n\r\nThe output to expect when `IS_DYNAMIC_OP = True`:\r\n\r\n```bash\r\nBottleneck Block 0 0:\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/conv2d/kernel:0 (1, 1, 64, 256)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/gamma:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/beta:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/moving_mean:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/shortcut/conv2d/BatchNorm/moving_variance:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/conv2d/kernel:0 (1, 1, 64, 128)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/gamma:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/beta:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/moving_mean:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_1/BatchNorm/moving_variance:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/bottleneck_2group_filter:0 (3, 3, 4, 128)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/gamma:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/beta:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/moving_mean:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_2/BatchNorm/moving_variance:0 (128,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/conv2d/kernel:0 (1, 1, 128, 256)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/gamma:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/beta:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/moving_mean:0 (256,)\r\n\t[*] resnext101-32x4d/btlnck_block_0_0/bottleneck_3/BatchNorm/moving_variance:0 (256,)\r\n\r\nRunning Raw Saved Model - No TF-TRT:\r\n\r\n[0] - [644 644 644 644 644 644 644 644 644 644]\r\n[1] - [644 644 644 644 644 644 644 644 644 644]\r\n[2] - [644 644 644 644 644 644 644 644 644 644]\r\n[3] - [644 644 644 644 644 644 644 644 644 644]\r\n[4] - [644 644 644 644 644 644 644 644 644 644]\r\n[5] - [644 644 644 644 644 644 644 644 644 644]\r\n[6] - [644 644 644 644 644 644 644 644 644 644]\r\n[7] - [644 644 644 644 644 644 644 644 644 644]\r\n[8] - [644 644 644 644 644 644 644 644 644 644]\r\n[9] - [644 644 644 644 644 644 644 644 644 644]\r\n\r\nRunning TF-TRT Saved Model:\r\n\r\n[0] - [644 644 644 644 644 644 644 644 644 644]\r\n[1] - [644 644 644 644 644 644 644 644 644 644]\r\n[2] - [644 644 644 644 644 644 644 644 644 644]\r\n[3] - [644 644 644 644 644 644 644 644 644 644]\r\n[4] - [644 644 644 644 644 644 644 644 644 644]\r\n[5] - [644 644 644 644 644 644 644 644 644 644]\r\n[6] - [644 644 644 644 644 644 644 644 644 644]\r\n[7] - [644 644 644 644 644 644 644 644 644 644]\r\n[8] - [644 644 644 644 644 644 644 644 644 644]\r\n[9] - [644 644 644 644 644 644 644 644 644 644]\r\n```\r\n\r\nHowever if you switch `IS_DYNAMIC_OP = False`, you will get the following error:\r\n\r\n```bash\r\n2020-06-25 20:00:30.873406: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:654] Number of TensorRT candidate segments: 1\r\n2020-06-25 20:00:31.110705: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1153] Linked TensorRT version: 7.1.2\r\n2020-06-25 20:00:31.110856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\r\n2020-06-25 20:00:31.110866: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1154] Loaded TensorRT version: 7.1.2\r\n2020-06-25 20:00:31.111660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7\r\n2020-06-25 20:00:41.767166: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected\r\n2020-06-25 20:00:41.767218: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456\r\n2020-06-25 20:00:41.767790: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected\r\n2020-06-25 20:00:41.767807: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456\r\n2020-06-25 20:00:41.767817: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected\r\n2020-06-25 20:00:41.767827: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456\r\n2020-06-25 20:00:41.767836: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected\r\n2020-06-25 20:00:41.767845: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nAttached you will find the SavedModel you need to reproduce: https://drive.google.com/file/d/1b0AdSFDTKnOP7SXJqNbUUWsNCgfXzETU/view?usp=sharing\r\n\r\n------------------\r\n\r\nSomething is definitely wrong here because: `kernel weights has count 4608 but 147456 was expected` and 4608 (what is inside the SavedModel) is the correct value. TF-TRT is just doing a bad assertion here. TF-TRT is wrong. Should be 4608 and be \"all green\".\r\n\r\n", "comments": ["@DEKHTIARJonathan \r\n\r\nRequest you to fill issue [template.](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version\r\n\r\nThanks!", "I am able to reproduce the good and bad cases.", "@ravikyram could you assign the bug to @bixia1. This issue came from a discussion between Google & NVIDIA. No need for following the template here.\r\n\r\nThanks", "Hi @DEKHTIARJonathan, thanks for reporting this. This is likely due to a problem in TensorRT. When is_dynamic_op == True,  the TF-TRT conversion stops with this error message before hitting the problem:\r\ntrt_engine_op.cc:756] TF-TRT Warning: Engine creation for TRTEngineOp_0_0 failed. The native segment will be used instead. Reason: Unimplemented: No converter registered for op: _FusedBatchNormEx\r\n\r\nWhen is_dynamic_op == False, the order of the graph nodes seen by segment.cc is different and the bridge crashed before converting op _FusedBatchNormEx. The reason for the crash is related to the warning message you showed about the discrepancy between the actual and the expected  size of the \"weights\" from trt_loger.cc. The warning message causes the TensorRT layer produces a result TensorRT tensor with unknown rank (that is, the  number of dimensions is unknown), which later on causes tensorflow::tensorrt::convert::GetTrtBroadcastShape() to crash when the bridge converts AddV2 op that uses the result.\r\n\r\n```\r\nI0630 15:20:17.657490 2805697 convert_nodes.cc:6012] Converting node resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D, op=Conv2D{{node resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/device:GPU:0\"](resnext101-32x4d/btlnck_block_0_0/bottleneck_1/relu, resnext101-32x4d/btlnck_block_0_0/bottleneck_2/bottleneck_2group_filter/read)\r\nI0630 15:20:17.657500 2805697 convert_nodes.cc:1914] Retrieved input resnext101-32x4d/btlnck_block_0_0/bottleneck_1/relu: TRT_TensorOrWeights(type=tensor=nvinfer1::ITensor(@40315869646352, name=resnext101-32x4d/btlnck_block_0_0/bottleneck_1/relu, dtype=kFLOAT, dims=nvinfer1::Dims(nbDims=3, d=128[9387=unknown],56[1904683784=unknown],56[32764=unknown],)), batch_size=-1)\r\nI0630 15:20:17.657503 2805697 convert_nodes.cc:1914] Retrieved input resnext101-32x4d/btlnck_block_0_0/bottleneck_2/bottleneck_2group_filter/read: TRT_TensorOrWeights(type=weights=TRT_ShapedWeights(shape=nvinfer1::Dims(nbDims=4, d=3[kSPATIAL],3[544913368=unknown],4[9387=unknown],128[1904678288=unknown],), type=kFLOAT, values=40318657290240))\r\nI0630 15:20:17.657517 2805697 log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: \"Unknown\" tensor { dtype: DT_FLOAT shape { dim { size: 3 } dim { size: 3 } dim { size: 4 } dim { size: 128 } } allocation_description { requested_bytes: 18432 allocated_bytes: 20480 allocator_name: \"cpu\" allocation_id: 8424 has_single_reference: true ptr: 40320748187648 } } }\r\nI0630 15:20:17.657527 2805697 convert_nodes.cc:956] num_groups: 1c4 then 4k128 then 128r3 then 3s3 then 3\r\nI0630 15:20:17.657556 2805697 trt_logger.cc:34] DefaultLogger Bias weights are not set yet. Bias weights can be set using setInput(2, bias_tensor) API call.\r\nE0630 15:20:17.657571 2805697 trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: kernel weights has count 4608 but 147456 was expected\r\nE0630 15:20:17.657589 2805697 trt_logger.cc:42] DefaultLogger resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: count of 4608 weights in kernel, but kernel dimensions (3,3) with 128 input channels, 128 output channels and 1 groups were specified. Expected Weights count is 128 * 3*3 * 128 / 1 = 147456\r\nI0630 15:20:17.657565 2805697 convert_nodes.cc:1311] Adding out tensor resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D: TRT_TensorOrWeights(type=tensor=nvinfer1::ITensor(@40317367670688, name=resnext101-32x4d/btlnck_block_0_0/bottleneck_2/Conv2D, dtype=kFLOAT, dims=nvinfer1::Dims(nbDims=-1, d=)), batch_size=-1)\r\n\r\n```\r\nWe may add a work around in the TF-TRT bridge, to abort the conversion when it sees a Layer with unknown rank tensors as results. On the other hand, it would be nice if you can talk to the NVIDIA TensorRT people to understand why the resulting tensor has an unknown rank.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40806\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40806\">No</a>\n", "@bixia1 shall we reopen the issue? I don't think it was fixed"]}, {"number": 40805, "title": "LSTM loss and accuracy values differ greatly between GPU and CPU implementation", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from: conda\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: CUDA Version 10.1.243\r\n- GPU model and memory: Nvidia GeForce 920M\r\n\r\n**Describe the current behavior**\r\nI've attached a <code>main.py</code> that should be able to replicate the error. When training a LSTM model the results differ by an order of magnitude (in the log sense) between GPU and CPU implementations.\r\n\r\n(I've also attached the <code>dataset.txt</code> file that I quickly parsed because I cannot share the corpus\r\nI am currently utilizing.)\r\n\r\nI've tested over multiple runs and this effect doesn't occur on the GRU RNN, only LSTM.\r\n\r\nIts rather hacky but I've used\r\n<code> os.environ['CUDA_VISIBLE_DEVICES'] = '-1' </code>\r\nto switch between GPU and CPU implementations and there is on <code>line 12</code> in <code>main.py</code>\r\n\r\nGPU:\r\n    Epoch 1 Train Loss 7.8753 Train Accuracy 46.6 Time 17.16\r\n    Epoch 2 Train Loss 7.1481 Train Accuracy 49.0 Time 11.74 \r\n    Epoch 3 Train Loss 6.9079 Train Accuracy 49.0 Time 13.47 \r\n\r\nCPU:\r\n    Epoch 1 Train Loss 6.6438 Train Accuracy 39.8 Time 16.51\r\n    Epoch 2 Train Loss 4.6425 Train Accuracy 40.4 Time 11.57\r\n    Epoch 3 Train Loss 4.4195 Train Accuracy 40.4 Time 11.73\r\n\r\n**Describe the expected behavior**\r\nI understand there should be small floating point error difference, as well as difference between random initialization, but the\r\nloss values should at least be similar.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem.\r\n\r\nApologies, this may not be exact minimum:\r\n\r\n[dataset.txt](https://github.com/tensorflow/tensorflow/files/4833424/dataset.txt)\r\n\r\n```\r\nimport os\r\nimport sys\r\nimport time\r\nfrom datetime import datetime\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\nimport math\r\nimport random\r\nimport numpy as np\r\n\r\n# the important bit \r\n#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\nclass LSTM_generator(tf.keras.Model):\r\n    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz):\r\n        super(LSTM_generator, self).__init__()\r\n        self.batch_sz = batch_sz\r\n        self.hidden_units = hidden_units\r\n        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\r\n                                                   output_dim=embedding_dim,\r\n                                                   mask_zero=True)\r\n        self.LSTM = tf.keras.layers.LSTM(self.hidden_units,\r\n                                        return_sequences=True,\r\n                                        return_state=True)\r\n        self.fc = tf.keras.layers.Dense(vocab_size)\r\n\r\n    def call(self, inp, states):\r\n        mask = self.embedding.compute_mask(inp)\r\n        \r\n        x = self.embedding(inp)\r\n\r\n        output, hidden, cell = self.LSTM(x,initial_state=states,mask=mask)\r\n\r\n        x = self.fc(output)\r\n\r\n        return x, (hidden, cell)\r\n\r\n    def initialize_hidden_state(self):\r\n        return tf.zeros((self.batch_sz,self.hidden_units)), tf.zeros((self.batch_sz,self.hidden_units))\r\n\r\n# Converts str to list of str word 'tokens'\r\n\r\ndef tokenize(inp):\r\n    words = []\r\n    buffer = \"\"\r\n    for let in inp:\r\n        if chr(let) == \" \":\r\n            words.append(buffer)\r\n            buffer = \"\"\r\n        else:\r\n            buffer = buffer + chr(let)\r\n\r\n    words.append(buffer)\r\n\r\n    return words\r\n\r\ndef split_input_target(sequence):   \r\n    input_text = sequence[:-1]\r\n    target_text = sequence[1:]\r\n    return input_text, target_text\r\n\r\ndataset_path = 'dataset.txt'\r\naug_dataset_path = 'aug.txt'\r\nvocabulary_set = set()\r\n\r\ndataset = tf.data.TextLineDataset(dataset_path)\r\n\r\n# get vocab\r\nfor text_tensor in dataset:\r\n    some_tokens = tokenize(text_tensor.numpy())\r\n    vocabulary_set.update(some_tokens)\r\n\r\nencoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\r\n\r\ndef encode(text_tensor):\r\n    encoded_text = encoder.encode(text_tensor.numpy())\r\n\r\n    return tf.cast(encoded_text,tf.int64)\r\n\r\ndef encode_map_fn(text):\r\n    encoded_text = tf.py_function(encode,inp=[text],Tout=tf.int64)\r\n\r\n    encoded_text.set_shape([None])\r\n\r\n    return encoded_text\r\n\r\nraw_dataset = dataset.map(encode_map_fn)\r\n\r\n# split dataset into sources and targets\r\ndataset_split = raw_dataset.map(split_input_target)\r\n\r\n# model parameters \r\nembedding_dim = 8\r\nrnn_units = 64\r\nbatch_size = 64\r\nepochs = 60\r\nsens_to_generate = 8000\r\ntemperature = 1.0\r\nvocab_size = encoder.vocab_size\r\nmax_seq_len_to_generate = 30\r\nBUFFER_SIZE = 10000\r\n\r\n# pad and batch the training datasets\r\ndataset_batched_padded = dataset_split.padded_batch(batch_size,\r\n                                        padded_shapes=([None,],[None,]),\r\n                                        drop_remainder=True).shuffle(BUFFER_SIZE)\r\n\r\ngenerator = LSTM_generator(vocab_size, embedding_dim, rnn_units, batch_size)\r\n\r\n# signatures help tf run faster - tracing or something\r\ntrain_step_signature = [\r\n    tf.TensorSpec(shape=(batch_size, None), dtype=tf.int64),\r\n    tf.TensorSpec(shape=(batch_size, None), dtype=tf.int64),\r\n    (tf.TensorSpec(shape=(batch_size, rnn_units), dtype=tf.float32),\r\n    tf.TensorSpec(shape=(batch_size, rnn_units), dtype=tf.float32))]\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\n\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n                        from_logits=True, reduction='none')           \r\n\r\ndef loss_function(real, pred):\r\n    return tf.reduce_mean(loss_object(real, pred))\r\n\r\n# Define metrics\r\ntrain_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\r\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\r\n\r\n# define a single training step\r\n@tf.function(input_signature=train_step_signature)\r\ndef train_step(inp, tar, hidden):\r\n    with tf.GradientTape() as tape:\r\n        predictions, hidden = generator(inp,hidden)\r\n\r\n        loss = loss_function(tar, predictions)\r\n\r\n    gradients = tape.gradient(loss, generator.trainable_variables)\r\n\r\n    optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\r\n\r\n    train_loss(loss)\r\n    train_accuracy(tar, predictions)\r\n\r\nfor epoch in range(epochs):\r\n    start = time.time()\r\n    \r\n    # initializing the hidden state at the start of every epoch\r\n    hidden = generator.initialize_hidden_state()\r\n    \r\n    # loop through training set\r\n    steps_per_epoch = 0\r\n    for (batch, (inp, tar)) in enumerate(dataset_batched_padded):\r\n        train_step(inp, tar, hidden)\r\n\r\n        if batch % 1 == 0:\r\n            sys.stdout.write(\"Epoch %d Batch %d Loss %.4f \\r\" % (\r\n                epoch + 1, batch, train_loss.result()\r\n            ) )\r\n            sys.stdout.flush()\r\n        \r\n        steps_per_epoch += 1\r\n            \r\n    print('-' * 89)\r\n    print ('Epoch {} Train Loss {:.4f} Train Accuracy {:.1f} Time {:.2f}'.format(epoch + 1, \r\n                                                    train_loss.result(),\r\n                                                    train_accuracy.result()*100,\r\n                                                    (time.time() - start)))\r\n\r\n    # Reset metrics every epoch\r\n    train_loss.reset_states()\r\n    train_accuracy.reset_states()\r\n```\r\n", "comments": ["Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it below\r\n \r\n- using [CPU](https://colab.research.google.com/gist/amahendrakar/26baf21ddc0a48520870e5984b4437d9/40805-cpu.ipynb)\r\n\r\n- using [GPU](https://colab.research.google.com/gist/amahendrakar/346729476adc2d38e0b11feb66af1854/40805-gpu.ipynb)\r\n\r\nThanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40805\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40805\">No</a>\n"]}, {"number": 40804, "title": "Could not load dynamic library 'cudart64_101.dll'", "body": "**System information**\r\n- Windows 10\r\n- Laptop: Asus gl553vw\r\n- TensorFlow installed with pip\r\n- tensorflow-gpu 2.2.0\r\n- Python 3.8.3\r\n- CUDA version 10.1 (update2)\r\n- cudnn-10.1-windows10-x64-v7.6.5.32\r\n- Nvidia GTX 960M\r\n\r\nI want to use tensorflow with GPU but I keep receiving this error Could not load dynamic library 'cudart64_101.dll' when I import Tensorflow.\r\n\r\n<details><summary>the output of `pip list`:</summary>\r\n\r\n```\r\nPackage                  Version\r\n------------------------ -----------\r\nabsl-py                  0.9.0\r\nastunparse               1.6.3\r\ncachetools               4.1.0\r\ncertifi                  2020.6.20\r\nchardet                  3.0.4\r\ngast                     0.3.3\r\ngoogle-auth              1.18.0\r\ngoogle-auth-oauthlib     0.4.1\r\ngoogle-pasta             0.2.0\r\ngrpcio                   1.30.0\r\nh5py                     2.10.0\r\nidna                     2.9\r\nKeras-Preprocessing      1.1.2\r\nMarkdown                 3.2.2\r\nnumpy                    1.19.0\r\noauthlib                 3.1.0\r\nopt-einsum               3.2.1\r\npip                      19.2.3\r\nprotobuf                 3.12.2\r\npyasn1                   0.4.8\r\npyasn1-modules           0.2.8\r\nrequests                 2.24.0\r\nrequests-oauthlib        1.3.0\r\nrsa                      4.6\r\nscipy                    1.4.1\r\nsetuptools               41.2.0\r\nsix                      1.15.0\r\ntensorboard              2.2.2\r\ntensorboard-plugin-wit   1.6.0.post3\r\ntensorflow-gpu           2.2.0\r\ntensorflow-gpu-estimator 2.2.0\r\ntermcolor                1.1.0\r\nurllib3                  1.25.9\r\nWerkzeug                 1.0.1\r\nwheel                    0.34.2\r\nwrapt                    1.12.1\r\n```\r\n</details>\r\n\r\n<details><summary>the output of `pip debug --verbose`:</summary>\r\n\r\n```\r\npip version: pip 19.2.3 from c:\\users\\ghassen\\downloads\\lisadetection\\lisadetection\\venv2\\lib\\site-packages\\pip (python 3.8)\r\nsys.version: 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)]\r\nsys.executable: c:\\users\\ghassen\\downloads\\lisadetection\\lisadetection\\venv2\\scripts\\python.exe\r\nsys.getdefaultencoding: utf-8\r\nsys.getfilesystemencoding: utf-8\r\nlocale.getpreferredencoding: cp1252\r\nsys.platform: win32\r\nsys.implementation:\r\n  name: cpython\r\nConfig variable 'Py_DEBUG' is unset, Python ABI tag may be incorrect\r\nCompatible tags: 15\r\n  cp38-cp38-win_amd64\r\n  cp38-none-win_amd64\r\n  py3-none-win_amd64\r\n  cp38-none-any\r\n  cp3-none-any\r\n  py38-none-any\r\n  py3-none-any\r\n  py37-none-any\r\n  py36-none-any\r\n  py35-none-any\r\n  py34-none-any\r\n  py33-none-any\r\n  py32-none-any\r\n  py31-none-any\r\n  py30-none-any\r\n```\r\n\r\n</details>\r\n\r\nFor `import tensorflow as tf` this is the output:\r\n\r\n```\r\n2020-06-24 14:50:11.230153: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-06-24 14:50:11.236957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n```\r\n\r\n<details>\r\n<summary>and for `tf.test.is_gpu_available()` the output is:</summary>\r\n```\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2020-06-24 14:51:00.146205: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-06-24 14:51:00.171655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21868deee70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 14:51:00.182635: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-24 14:51:00.190956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-06-24 14:51:01.031439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-06-24 14:51:01.045344: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-06-24 14:51:01.051842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found\r\n2020-06-24 14:51:01.058515: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\r\n2020-06-24 14:51:01.065241: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\r\n2020-06-24 14:51:01.072266: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2020-06-24 14:51:01.080353: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found\r\n2020-06-24 14:51:01.087954: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\r\n2020-06-24 14:51:01.095638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-06-24 14:51:01.186835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-24 14:51:01.194906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-06-24 14:51:01.198498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-06-24 14:51:01.206694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21876e35be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 14:51:01.214517: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0\r\nFalse\r\n```\r\n</details>\r\n\r\n\r\n", "comments": ["@chsigg any ideas?", "I solve this problem by cd into the folder of anaconda,and find cudart64_101.dll, copy it into c:/window/system32", "For me also, it worked after I copied the `dll` file to the System32 folder. Every CUDA related directory is in the PATH but still didn't work until I copy it to the System32.\r\n\r\nBut is there any way of doing that without copying every `dll` file..?\r\n\r\nI'm using Python3.8 from Windows Store. \r\nCUDA 10.1 Update 2. \r\nTensorflow was installed using `pip` inside a `virtualenv`.", "For me, the problem was the `python` installation. \r\nDon't use the python from the windows. Download the python installation file from the [official site](https://www.python.org/downloads/windows/).\r\n\r\nAfter that I configured my python environment again, now it is working like a charm.. \u263a\ufe0f ", "@GhassenBenMakhlouf \r\nIs this still an issue.", "@Saduf2019 \r\nYes, when I copy it into c:/window/system32, it solves the problem.\r\nActually I had to copy all these files into c:/window/system32, otherwise my script won't use GPU:\r\n\r\n- cublas64_10.dll\r\n- cublasLt64_10.dll\r\n- cudart64_101.dll\r\n- cudnn64_7.dll\r\n- cufft64_10.dll\r\n- curand64_10.dll\r\n- cusolver64_10.dll\r\n- cusparse64_10.dll\r\n- nvcuda.dll\r\n\r\nThis is a dirty solution, I hope you find a better one.", "@GhassenBenMakhlouf \r\nAs confirmed this solves the problem, please feel free to move this issue to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40804\">No</a>\n", "> @Saduf2019\r\n> Yes, when I copy it into c:/window/system32, it solves the problem.\r\n> Actually I had to copy all these files into c:/window/system32, otherwise my script won't use GPU:\r\n> \r\n> * cublas64_10.dll\r\n> * cublasLt64_10.dll\r\n> * cudart64_101.dll\r\n> * cudnn64_7.dll\r\n> * cufft64_10.dll\r\n> * curand64_10.dll\r\n> * cusolver64_10.dll\r\n> * cusparse64_10.dll\r\n> * nvcuda.dll\r\n> \r\n> This is a dirty solution, I hope you find a better one.\r\n\r\nDownload CUDA and cuDNN from NVIDIA, and try again.", "I've installed CUDA Toolkit 11.2.135 already, but I'm having the same issue. I've tried downloading an other version, but NVIDIA driver says the installed is newer than the downloaded - so?!", "> \r\n> \r\n> I solve this problem by cd into the folder of anaconda,and find cudart64_101.dll, copy it into c:/window/system32\r\n\r\nThis worked for me, thank you!"]}, {"number": 40803, "title": "[CherryPick 2.3] change the size of input to remedy OOM issue.", "body": "PiperOrigin-RevId: 317995769\nChange-Id: I1358449e989a41c5621e6a4d56e603387be0490d", "comments": []}, {"number": 40802, "title": "ModuleNotFoundError: No module named 'tensorflow.contrib'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:conda\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n  File \"main.py\", line 6, in <module>\r\n    import tflearn\r\n  File \"C:\\Users\\V\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\__init__.py\", line 4, in <module>\r\n    from . import config\r\n  File \"C:\\Users\\V\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\config.py\", line 5, in <module>\r\n    from .variables import variable\r\n  File \"C:\\Users\\V\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\tflearn\\variables.py\", line 7, in <module>\r\n    from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope\r\nModuleNotFoundError: No module named 'tensorflow.contrib'\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython main.py is only command I ran\r\n\r\nfull code:\r\nimport nltk\r\nfrom nltk.stem.lancaster import LancasterStemmer  #for stemming\r\nstemmer  = LancasterStemmer()\r\n\r\nimport numpy\r\nimport tflearn\r\nimport tensorflow\r\nimport random\r\nimport json\r\n\r\n#file import\r\nwith open(\"intents.json\") as file:\r\n\tdata = json.load(file)\r\n\tprint(data)\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@vgkakade \r\n\r\nWhich version of tensorflow you are using?.\r\ntensorflow.contrib is being removed in version TF 2.x and it works in only TF 1.x. For more info see this https://www.tensorflow.org/guide/migrate#a_note_on_slim_contriblayers\r\nThanks!", "I am \r\n\r\n> \r\n> \r\n> @vgkakade\r\n> \r\n> Which version of tensorflow you are using?.\r\n> tensorflow.contrib is being removed in version TF 2.x and it works in only TF 1.x. For more info see this https://www.tensorflow.org/guide/migrate#a_note_on_slim_contriblayers\r\n> Thanks!\r\n\r\nI am using 2.0.0.\r\n\r\nAnd if i want to continue with how can resolve this issue?", "The only way to use `contrib` functionality is to use TF 1.X version.\r\nFor TF 2.X you may try following: \r\nA subset of contrib functions are part of [`TF Addons`](https://github.com/tensorflow/addons).\r\nYou have to install `addons` package separately to use them.\r\nYou can also raise a FR on the `addons` to repo to add feature not already available.\r\nThanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 40800, "title": "Is it possible to use TensorFlow 2.2 with Cuda 10.0?", "body": "**System information**\r\nLinux Ubuntu 18.04\r\nTensorFlow 2.2.0 (installed using pip)\r\nPython 3.6.9\r\nCuda 10.0/ cuDNN 7.6.5\r\nGPU: nVIDIA GTX 1080 Ti\r\n\r\n**Describe the problem**\r\nI have a working setup with the above system configuration and TF 2.0. I would like to check out TF 2.2 (and also use some packages which only support TF >=2.2). However, I do not want to touch my cuda setup as I am afraid it could cause other unintended issues.\r\n\r\nQuestion: Is it possible to run TF 2.2 on top of Cuda 10.0? For example, by editing symlinks, recompiling etc.? If yes, can you direct me to any documentation with the steps (or explain here)? If not possible, is there any TF confirmed way of upgrading cuda 10.0 to cuda 10.2?\r\n\r\nI have tried running TF 2.2 with cuda 10.0 but it does not seem to be able to detect cuda packages (although it detects GPU)\r\n\r\n```\r\n>>> tf.config.list_physical_devices('GPU')\r\n2020-06-25 23:20:36.860274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-25 23:20:36.865225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-25 23:20:36.866048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.7085GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2020-06-25 23:20:36.866331: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.866444: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.866550: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.866653: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.866757: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.866878: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\r\n2020-06-25 23:20:36.872785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-25 23:20:36.872828: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\n\r\nCUDA Version Check:\r\n```\r\n/usr/local/cuda/bin/nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:01_CDT_2018\r\nCuda compilation tools, release 10.0, V10.0.130\r\n```\r\n\r\nNVIDIA Driver: 430.50\r\n\r\n\r\nIt works fine with TF 2.0.0\r\n\r\n```\r\n2020-06-25 23:25:12.242640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.7085\r\npciBusID: 0000:01:00.0\r\n2020-06-25 23:25:12.242832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-25 23:25:12.243852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-25 23:25:12.244711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-25 23:25:12.244930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-25 23:25:12.246136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-25 23:25:12.247112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-25 23:25:12.249902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n```\r\n\r\n\r\nThanks!", "comments": ["@SivamPillai \r\nCan you please refer to these links and let us know if it helps:\r\n#38194 [link](https://www.pytorials.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-ubuntu/) [link1](https://medium.com/@katnoria/installing-tensorflow-2-0-nightly-and-cuda-10-0-on-ubuntu-18-04-e880db22d2ee)", "I am not sure on how to do a safe symlink. I do not want the current setup to be affected in the process. I believe building TensorFlow from source (using Bazel) and specifying the cuda version as 10.0 might be the best option here. I need to adjust my storage to do this. I will get back on that.\r\n\r\nOne interesting alternative I have found is to use a docker container. I create a docker with Nvidia and ran TensorFlow on top of that. This is based on [TF instructions](https://www.tensorflow.org/install/docker) for docker based installation. My initial testings show that it works. I need to do some more tests to confirm.", "@SivamPillai \r\nPlease confirm of we may move this to closed status, if it resolves your issue.", "@Saduf2019 unfortunately I do not have a system to test this currently. I am now using a Docker container with Cuda 10.2 and TF 2.2.0. However, I can confirm that building from source with the option of CUDA 10.0 works. I have tried something similar in the past. \r\n\r\nThe question is whether there is a prebuilt package for TF 2.2.0 that works out-of-the-box with CUDA 10.0?", "As shown in this page [here](https://www.tensorflow.org/install/source#gpu) please try using CUDA 10.1 not 10.2. Thanks!", "@gowthamkpr thanks but the issue is not CUDA 10.2. TF 2.2.0 works fine with Cuda 10.2 in Docker environment. The question was about support for Cuda 10.0 and if there are any pre-built Tf2.2 package that supports it.", "@SivamPillai Thanks for your issue. We do not have pre built TF 2.2 packages supporting cuda 10.0\r\nIn future as we progress we generally add later cuda support to later TF versions and these are not back propagated to earlier versions of TF and later versions of cuda as in your case.\r\nFor your case you may try to [build TF from sources](https://www.tensorflow.org/install/source#setup_for_linux_and_macos) with appropriate cuda optimization flags.\r\nHope this helps!\r\n", "@ymodak the problem I see here is the large part of the community which may not be in a situation to update cuda to the latest version every time. In such cases, it makes sense to have newer versions of TF support older versions of CUDA (maybe something like LTS for specific major versions of CUDA?). As per my understanding, there are no breaking changes in TF that won't support such versions of cuda.\r\n\r\nBig fan of TF, so happy to be educated, if there are challenges in doing this which are not worthwhile to the core group!", "Unfortunately, we can only test with a single CUDA version as the internal CI infrastructure is shared across multiple Google products. Hence, it is very easy for code to tie in to a certain CUDA version and it is not feasible for us to claim that we support other versions except the one we built with.\r\n\r\nIt is always possible to recompile against a different CUDA version, fixing the potential build breakages (should be minimal, but see above paragraph). It could also be possible to symlink one CUDA library to act as another one, but beware of ABI breakages if you do that.\r\n\r\nAnother reason why we won't be able to offer a pip that contains support for multiple CUDA versions is the fact that our pip sizes are huge. We cannot include all the needed stubs on the pip and it would be a user degradation if we use a different deployment platform for the pips instead of PyPI.", "Closing this issue now. Thanks all. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40800\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40800\">No</a>\n", "Did anyone succeed in compiling Tensorflow 2.2 with CUDA 10.0? The HPC cluster of my research institute has not yet updated the GPU drivers needed to support CUDA 10.1, and we are trying to use some software that needs TensorFlow 2.2!"]}, {"number": 40799, "title": "ValueError: Shapes (1, 107, 3) and (1, 107, 2) are incompatible", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab system(Linux version 4.19.104+ )\r\n- TensorFlow installed from (source or binary):colab system installed it \r\n- TensorFlow version (use command below): tf2.2.0\r\n- Python version: 3.6\r\n\r\n\r\n**Describe the current behavior**\r\nI am doing some work about tensor train decomposition.\r\n      \r\n\r\n- Firstly, I represent a video with tensor. The tensor  dimension is 4 which shape can be see with [ frames, width, heights,channels]. And the tensor shape is [107, 60, 80, 3]. \r\n- Secondly, I convert the tf tensor to TT tensor via t3f library. \r\n- Thirdly, I write a Riemann dimension reduction function for the TT tensor. \r\n- In the end, I reduce  the TT tensor dimension via my function. But the bug come out in the end step.\r\n\r\nWhat I want to say is that the bug didn't come out when I represent another data with tensor which shape is [107, 60, 80, 2] .In that situtation code runned very good.\r\n\r\nThe exit:\r\n\r\n>  ---------------------------------------------------------------------------\r\n> ValueError                                Traceback (most recent call last)\r\n> ipython-input-34-e5f2500494ee in module()\r\n>       1 log = []\r\n>       2 for i in range(1000):\r\n> ----> 3     F = step()\r\n>       4     if i % 10 == 0:\r\n>       5         print(F)\r\n> \r\n> 4 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)\r\n>    1115     \"\"\"\r\n>    1116     if not self.is_compatible_with(other):\r\n> -> 1117       raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n>    1118 \r\n>    1119   def most_specific_compatible_shape(self, other):\r\n> \r\n> ValueError: Shapes (1, 107, 3) and (1, 107, 2) are incompatible\r\n\r\n**Describe the expected behavior**\r\nI expect the video convert to TT tensor can also be reduced dimension by my function been mentioned above without any error just as the shape [107, 60, 80, 2] data.  \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is the bug code colab address [Link](https://colab.research.google.com/drive/1Qz-TBBAbnflKioPn-YxxFwl59K3DVlWb?usp=sharing)\r\nHere is the video data address which shape is [107, 60, 80, 3] [Link](https://drive.google.com/file/d/1DVB7ReloEKTkqRBFyj8Uop6_FKf-oBYe/view?usp=sharing)\r\nHere is the another data address which shape is [107, 60, 80, 2] [Link](https://drive.google.com/file/d/1DNS5xCMikgsvye1NZRmdDl3ebcG10ves/view?usp=sharing)\r\n\r\n#33948 \r\n@jvishnuvardhan    ", "comments": ["Can you provide a **minimal** code to reproduce the issue? The error message makes sense, the last dimension in the shape does not match.", "@mihaimaruseac I have put a minimal code in the [cell](https://colab.research.google.com/drive/1bZiaDNQqpJjMFSQOhpXEgfMy-fwrhC8d?usp=sharing). But I can't provide the input data directly on the cell. If you need reproduce the issue, can download the data from my Google Drive link which is [video data](https://drive.google.com/file/d/1DVB7ReloEKTkqRBFyj8Uop6_FKf-oBYe/view?usp=sharing) and [another data](https://drive.google.com/file/d/1DNS5xCMikgsvye1NZRmdDl3ebcG10ves/view?usp=sharing).", "I know the error message makes sense, but I don't think my two tensor have a different shape. And the another data I have shared can identify the code is well.", "@mihaimaruseac I have find the reason the bug have been caused. I ignored a detail that a rank value need be modify in myself function. What a primary mistake. Thanks for all your patience! And I will close the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40799\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40799\">No</a>\n"]}, {"number": 40798, "title": "Simplify calls to .executing_eagerly()", "body": "This PR cleansup some calls to `context.executing_eagerly()`", "comments": []}, {"number": 40796, "title": "tf.debugging.enable_check_numerics() doesn't work on TPUs", "body": "Adding that line produces this traceback:\r\n```\r\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 644, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 140, in execute_with_callbacks\r\n    callback(op_name, tuple(inputs), attrs, tensors, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/debug/lib/check_numerics_callback.py\", line 294, in callback\r\n    path_length_limit=self._path_length_limit))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/debug/lib/check_numerics_callback.py\", line 164, in get_check_numerics_error_message\r\n    message += \"  shape: %s\\n\" % (tensor.shape,)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1067, in shape\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Compilation failure: Detected unsupported operations when trying to compile graph cluster_train_function_12198995384642658803[] on XLA_TPU_JIT: DebugNumericSummaryV2 (No registered 'DebugNumericSummaryV2' OpKernel for XLA_TPU_JIT devices compatible with node node my_model/embedding/embedding_lookup/ReadVariableOp/DebugNumericSummaryV2 (defined at tools/model-trainer.py:268) )node my_model/embedding/embedding_lookup/ReadVariableOp/DebugNumericSummaryV2 (defined at tools/model-trainer.py:268) \r\n        TPU compilation failed\r\n         [[tpu_compile_succeeded_assert/_449904103826306356/_3]]\r\n```", "comments": ["@bjourne \r\nPlease share tensor flow version and stand alone code to replicate the issue faced.", "In this case it's really easy. Just write `tf.debugging.enable_check_numerics()` and then try to run any model on a TPU.", "@bjourne \r\nI ran the code shared , please find the [gist here](https://colab.research.google.com/gist/Saduf2019/f34090b9b9468196ae0ce2f2188174d1/untitled246.ipynb), please let us know if it confirms your issue", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The code you wrote works. But you also have to begin training a model while numerics are being check. That is when TensorFlow crashes.", "@bjourne Can you please modify the code, so that we can reproduce the issue on colab. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for 2 weeks. Please add additional comments for us  to open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40796\">No</a>\n", "Please note that in order to use `tf.debugging.enable_check_numerics()` on TPUs, currently you need to call\r\n\r\n  `tf.config.set_soft_device_placement(True)`\r\n\r\nbefore calling `tf.debugging.enable_check_numerics()`\r\n\r\nas this API uses automatic outside compilation on TPUs.\r\n\r\nThis is in the documentation in the source code at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/debug/lib/check_numerics_callback.py#L415, but isn't reflected at the official documentation at https://www.tensorflow.org/api_docs/python/tf/debugging/enable_check_numerics yet because it's pending the next version update (2.3.0). Sorry for the confusion."]}, {"number": 40795, "title": "Error when computing gradients of a reloaded SavedModel containing an if clause", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2.0, 2.3.0-dev20200622\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: CUDA 10.1.243 - cuDNN 7.6.4\r\n- GPU model and memory: Tesla K80, 12GB\r\n\r\n**Describe the current behavior**\r\n\r\nComputing gradients of a reloaded SavedModel containing an if clause raises an error.\r\n\r\nWhen I save a model containing an if clause as follows:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass CondModel(tf.keras.models.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.dense_layer = tf.keras.layers.Dense(units=1)\r\n\r\n    def call(self, inputs, training=None):\r\n        if training:\r\n            return self.dense_layer(inputs)\r\n        else:\r\n            return self.dense_layer(inputs)\r\n\r\n\r\nm = CondModel()\r\nm.__call__ = tf.function(m.__call__)\r\nm.__call__.get_concrete_function(\r\n    inputs=tf.TensorSpec(shape=[1, 1]), \r\n    training=tf.TensorSpec(shape=None, dtype=tf.bool)\r\n)\r\ntf.saved_model.save(m, 'saved_model')\r\n```\r\n\r\nand I try to load it back and get gradients **in a new process** as:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nreloaded = tf.saved_model.load('saved_model')\r\n\r\nwith tf.GradientTape() as tape:\r\n    reloaded(inputs=[[1]], training=False)\r\n```\r\n\r\nthen error message below happens. If however I execute the following code it works all right:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# --- HACK ---\r\ndef f(x):\r\n    if x:\r\n        pass \r\n    \r\ntf.function(f).get_concrete_function(\r\n    x=tf.TensorSpec(shape=None)\r\n)\r\n# -------------\r\n\r\nreloaded = tf.saved_model.load('saved_model')\r\n\r\nwith tf.GradientTape() as tape:\r\n    reloaded(inputs=[[1]], training=False)\r\n```\r\n\r\nAlso if I reload in the same process in which I did the saving no error happens (so to reproduce the error the above snippets should be excuted in different processes).\r\n\r\n**Error message:**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\r\n   2485       with c_api_util.tf_buffer() as buf:\r\n-> 2486         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)\r\n   2487         data = pywrap_tf_session.TF_GetBuffer(buf)\r\n\r\nInvalidArgumentError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    330     try:\r\n--> 331       xla_compile = op.get_attr(\"_XlaCompile\")\r\n    332       xla_separate_compiled_gradients = op.get_attr(\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_attr(self, name)\r\n   2489       # Convert to ValueError for backwards compatibility.\r\n-> 2490       raise ValueError(str(e))\r\n   2491     x = attr_value_pb2.AttrValue()\r\n\r\nValueError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nLookupError                               Traceback (most recent call last)\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    606           try:\r\n--> 607             grad_fn = ops.get_gradient_function(op)\r\n    608           except LookupError:\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in get_gradient_function(op)\r\n   2654     op_type = op.type\r\n-> 2655   return _gradient_registry.lookup(op_type)\r\n   2656 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/registry.py in lookup(self, name)\r\n     96       raise LookupError(\r\n---> 97           \"%s registry has no entry for: %s\" % (self._name, name))\r\n\r\nLookupError: gradient registry has no entry for: If\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nLookupError                               Traceback (most recent call last)\r\n<ipython-input-1-c7239ff2b139> in <module>\r\n      4 \r\n      5 with tf.GradientTape() as tape:\r\n----> 6     reloaded(inputs=[[1]], training=False)\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in _call_attribute(instance, *args, **kwargs)\r\n    494 \r\n    495 def _call_attribute(instance, *args, **kwargs):\r\n--> 496   return instance.__call__(*args, **kwargs)\r\n    497 \r\n    498 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    844               *args, **kwds)\r\n    845       # If we did not create any variables the trace we have is good enough.\r\n--> 846       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n    847 \r\n    848     def fn_with_cond(*inner_args, **inner_kwds):\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)\r\n   1840                            resource_variable_ops.BaseResourceVariable))],\r\n   1841         captured_inputs=self.captured_inputs,\r\n-> 1842         cancellation_manager=cancellation_manager)\r\n   1843 \r\n   1844   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1921         possible_gradient_type,\r\n   1922         executing_eagerly)\r\n-> 1923     forward_function, args_with_tangents = forward_backward.forward()\r\n   1924     if executing_eagerly:\r\n   1925       flat_outputs = forward_function.call(\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward(self)\r\n   1431     \"\"\"Builds or retrieves a forward function for this call.\"\"\"\r\n   1432     forward_function = self._functions.forward(\r\n-> 1433         self._inference_args, self._input_tangents)\r\n   1434     return forward_function, self._inference_args + self._input_tangents\r\n   1435 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward(self, inference_args, input_tangents)\r\n   1187       (self._forward, self._forward_graph, self._backward,\r\n   1188        self._forwardprop_output_indices, self._num_forwardprop_outputs) = (\r\n-> 1189            self._forward_and_backward_functions(inference_args, input_tangents))\r\n   1190     return self._forward\r\n   1191 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _forward_and_backward_functions(self, inference_args, input_tangents)\r\n   1339     outputs = self._func_graph.outputs[:self._num_inference_outputs]\r\n   1340     return self._build_functions_for_outputs(\r\n-> 1341         outputs, inference_args, input_tangents)\r\n   1342 \r\n   1343 \r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _build_functions_for_outputs(self, outputs, inference_args, input_tangents)\r\n    897             self._func_graph.inputs,\r\n    898             grad_ys=gradients_wrt_outputs,\r\n--> 899             src_graph=self._func_graph)\r\n    900 \r\n    901       captures_from_forward = [\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    667                 # functions.\r\n    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,\r\n--> 669                                          lambda: grad_fn(op, *out_grads))\r\n    670               else:\r\n    671                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)\r\n    334       xla_scope = op.get_attr(\"_XlaScope\").decode()\r\n    335     except ValueError:\r\n--> 336       return grad_fn()  # Exit early\r\n    337 \r\n    338   if not xla_compile:\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in <lambda>()\r\n    667                 # functions.\r\n    668                 in_grads = _MaybeCompile(grad_scope, op, func_call,\r\n--> 669                                          lambda: grad_fn(op, *out_grads))\r\n    670               else:\r\n    671                 # For function call ops, we add a 'SymbolicGradient'\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _rewrite_forward_and_call_backward(self, op, *doutputs)\r\n    710   def _rewrite_forward_and_call_backward(self, op, *doutputs):\r\n    711     \"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\r\n--> 712     forward_function, backwards_function = self.forward_backward(len(doutputs))\r\n    713     if not backwards_function.outputs:\r\n    714       return backwards_function.structured_outputs\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in forward_backward(self, num_doutputs)\r\n    619     if forward_backward is not None:\r\n    620       return forward_backward\r\n--> 621     forward, backward = self._construct_forward_backward(num_doutputs)\r\n    622     self._cached_function_pairs[num_doutputs] = (forward, backward)\r\n    623     return forward, backward\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _construct_forward_backward(self, num_doutputs)\r\n    667           args=[], kwargs={},\r\n    668           signature=signature,\r\n--> 669           func_graph=backwards_graph)\r\n    670       backwards_graph_captures = backwards_graph.external_captures\r\n    671       captures_from_forward = [\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    977         _, original_func = tf_decorator.unwrap(python_func)\r\n    978 \r\n--> 979       func_outputs = python_func(*func_args, **func_kwargs)\r\n    980 \r\n    981       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _backprop_function(*grad_ys)\r\n    657             self._func_graph.inputs,\r\n    658             grad_ys=grad_ys,\r\n--> 659             src_graph=self._func_graph)\r\n    660 \r\n    661     with self._func_graph.as_default():\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\r\n    621               raise LookupError(\r\n    622                   \"No gradient defined for operation '%s' (op type: %s)\" %\r\n--> 623                   (op.name, op.type))\r\n    624         if loop_state:\r\n    625           loop_state.EnterGradWhileContext(op, before=False)\r\n\r\nLookupError: No gradient defined for operation 'cond_model/cond' (op type: If)\r\n```", "comments": ["@jdonier \r\n\r\nI have tried in colab with TF version 2.2 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/a929d95732c51e3c2bde8ba17b4e3de3/untitled70.ipynb).Thanks!", "@ravikyram I have just tried and it does fail. You need to restart the runtime after saving the model and then execute the cell:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nreloaded = tf.saved_model.load('saved_model')\r\n\r\nwith tf.GradientTape() as tape:\r\n    reloaded(inputs=[[1]], training=False)\r\n```\r\n\r\nand you will get \r\n\r\n```\r\nLookupError: No gradient defined for operation 'cond_model/cond' (op type: If)\r\n```", "Restarting the runtime after saving the model I could reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/341f427659e4ff5aae7d55481631ca7f/untitled73.ipynb).Thanks!", "For a workaround, setting the `training` to a Python constant, rather than a Tensor, avoids the error:\r\n\r\n```\r\nm.__call__.get_concrete_function(\r\n    inputs=tf.TensorSpec(shape=[1, 1]), \r\n    training=False\r\n)\r\n```\r\n", "@jdonier \r\n\r\nAny update on this issue please. Thanks!", "@mdanatg interesting, however this won't work for us as we don't want to set the training flag to a constant. Can you tell if this will be fixed in a near future?", "@omalleyt12 @fchollet would have the best answer for this question.", "I don't have full context on this issue, but it seems like the error is caused bc `training` is specified as a `Tensor` in the `concrete_function`, but then passed as a constant? Maybe passing `training` as a boolean `tf.Tensor` would fix this?", "No I get the same error if I run `reloaded(inputs=[[1]], training=tf.convert_to_tensor(False, dtype=tf.bool))` .", "Hm ok, thanks for the info I'll take a look", "This is fixed with latest tf-nightly version 2.4.0-dev20200916\r\nSee the [gist](https://colab.research.google.com/gist/ymodak/c1f02bba476ca5b6b302c8ada8d58676/untitled70.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Indeed it works, thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40795\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40795\">No</a>\n"]}, {"number": 40794, "title": "Error when computing gradients of a reloaded SavedModel containing an if clause", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): only the snippet below.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2.0, 2.3.0-dev20200622\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: CUDA 10.1.243 - cuDNN 7.6.4\r\n- GPU model and memory: Tesla K80, 12GB\r\n\r\n**Describe the current behavior**\r\n\r\nComputing gradients of a reloaded SavedModel containing an if clause raises an error.\r\n\r\nIf I save a model containing an if clause as follows:\r\n\r\n``````\r\n\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40794\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40794\">No</a>\n"]}, {"number": 40792, "title": "Custom ops env setup", "body": "added submodule", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40792) for more info**.\n\n<!-- need_sender_cla -->", "@JonathanGoorBlink Thank you for your contribution. Can you please sign CLA? Thanks!", "@JonathanGoorBlink  Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 40791, "title": "Documentation Error: padded_shapes isn't provided in padded_batch method.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/tutorials/keras/text_classification\r\n\r\n## Description of issue (what needs changing): Under heading 'Prepare the data for training'  in first code snippet \r\nBUFFER_SIZE = 1000\r\n\r\ntrain_batches = (\r\n    train_data\r\n    .shuffle(BUFFER_SIZE)\r\n    .padded_batch(32))\r\n\r\ntest_batches = (\r\n    test_data\r\n    .padded_batch(32))\r\n\r\npadded_shape isn't provided while it is mandatory i guess. Also when i was following this tutorial i got the error: \"TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'\"\r\n\r\nSo please update the documentation. And also please help me out what should be the padded_shapes for this example. \r\nI've read the documentation for padded_batch but i still got different errors. Thank You\r\n\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@devspartan \r\n\r\nI have tried executing tutorial in colab with TF 2.2 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/e09d0a0e89ac7cbbbbcb2f40472fd88a/untitled67.ipynb)..Can you please help me to understand where exactly you are facing the issue.If possible please share colab link or simple standalone code to reproduce the issue.It helps us in localizing the issue faster.Thanks!", "I've been using TF 2.1. After upgraded to TF 2.2 it works fine. Thank you for your quick response"]}, {"number": 40790, "title": "Could not detect op for DEPTHWISE_CONV_2D", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10, Mbed Studio\r\n- TensorFlow installed from (source or binary):\r\nSource\r\n- Tensorflow version (commit SHA if source):\r\n2.1.0, 896c9220929e85fec93c6587330f19815f71e589\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\nArm Mbed OS\r\n\r\n**Describe the problem**\r\nPerson detection example does not work out of the box and gives runtime errors on STM DISCO-F746NG. \r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n1. Clone tensorflow source. \r\n2. Make projects: `make -f tensorflow/lite/micro/tools/make/Makefile generate_projects`\r\n3. Try to run person_detection example. \r\n\r\nOutput: \r\n\"Could not detect op for builtin op code DEPTHWISE_CONV_2D\" \r\n\r\nI couldn't find any documentation on which commit of the Tensorflow source I should use. I have tried a few commits of the tensorflow/lite/micro repo with varying degrees of failure, Please suggest one that will compile cleanly and run with no errors. \r\n\r\n\r\n", "comments": ["Can you attempt this with tip of tree?", "Repeated process above for new pull from source. \r\n```\r\n~/tensorflow$ git rev-parse HEAD\r\n527f6835c3d980cf3379f6e6c0f5029af3f8a460\r\n```\r\n\r\nMake projects, etc. \r\nAttempt to compile with Mbed Studio. \r\nResult: \r\n\r\n```\r\n[Error] all_ops_resolver.h@22,31: expected class name\r\n[Error] all_ops_resolver.cc@24,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@25,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@26,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@27,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@28,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@29,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@30,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@31,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@33,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@34,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@35,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@36,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@37,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@38,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@39,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@40,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@41,3: use of undeclared identifier 'AddBuiltin'\r\n[Error] all_ops_resolver.cc@42,3: use of undeclared identifier 'AddBuiltin'\r\n[ERROR] In file included from .\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:13:\r\n./lib/tflite_person_detection\\tensorflow/lite/micro/kernels/all_ops_resolver.h:22:31: error: expected class name\r\nclass AllOpsResolver : public MicroMutableOpResolver {\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:24:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_FULLY_CONNECTED, Register_FULLY_CONNECTED(), 1, 4);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:25:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_MAX_POOL_2D, Register_MAX_POOL_2D(), 1, 2);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:26:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_SOFTMAX, Register_SOFTMAX(), 1, 2);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:27:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_LOGISTIC, Register_LOGISTIC(), 1, 2);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:28:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_SVDF, Register_SVDF(), 1, 3);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:29:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_CONV_2D, Register_CONV_2D(), 1, 3);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:30:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_CONCATENATION, Register_CONCATENATION(), 1, 3);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:31:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_DEPTHWISE_CONV_2D, Register_DEPTHWISE_CONV_2D(), 1,\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:33:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_AVERAGE_POOL_2D, Register_AVERAGE_POOL_2D(), 1, 2);\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:34:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_ABS, Register_ABS());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:35:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_SIN, Register_SIN());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:36:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_COS, Register_COS());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:37:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_LOG, Register_LOG());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:38:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_SQRT, Register_SQRT());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:39:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_RSQRT, Register_RSQRT());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:40:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_SQUARE, Register_SQUARE());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:41:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_PRELU, Register_PRELU());\r\n^\r\n.\\lib\\tflite_person_detection\\tensorflow\\lite\\micro\\kernels\\all_ops_resolver.cc:42:3: error: use of undeclared identifier 'AddBuiltin'\r\nAddBuiltin(BuiltinOperator_FLOOR, Register_FLOOR());\r\n^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\n```", "I also tried running the unit tests and all of them passed. \r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile test\r\n```", "Build fails when compiling with GCC_ARM on a Linux host as well. Error message is identical to the one given above. ", "The AddBuiltin API was removed with 34b4fab30\r\n\r\nThere is some inconsistency between the all_ops_resolver.cc in mbed studio with what we have in tip of tree. I think @petewarden  will have to help here.\r\n\r\n", "Thanks for the responses thus far. I would greatly appreciate continued support as this issue is blocking development of a component in an upcoming deployment. Please let me know if there's anything else I can do to expedite the process. ", "Bumping this issue as I still haven't found a good solution. Any advice is appreciated. ", "@advaitjain @petewarden do you have any suggestions to help fix the errors I encountered? E.g. \"Use version XX of TF source\" or \"include header YY in your source file\". I am very new to this so I'd appreciate even the most basic advice on whether I've missed some important step in using TFLiteMicro. ", "@dtch1997 \r\nIs this till an issue, could you please try is later tf versions and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40790\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40790\">No</a>\n"]}, {"number": 40789, "title": "Relax SciPy pip requirement to >= 1.4.1", "body": "SciPy 1.5.0 is out now https://docs.scipy.org/doc/scipy/reference/release.1.5.0.html and I'd like to use it. As an interim, quick to apply solution, I've relaxed the constraint. Probably a better solution would be to remove the dependency altogether and handle the version conflict some other way: https://github.com/tensorflow/tensorflow/issues/35709", "comments": ["Let's remove the `scipy` dependency. I think it is no longer needed.", "@frankier Can you please check @mihaimaruseac's comments and keep us posted. Thanks!", "the dependancy \"scipy==1.4.2\"  seems not removed in tensorflow_cpu_2.3.0rc2. is it normal ?", "The `r2.3` branch used for the 2.3 release has https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/tools/pip_package/setup.py#L72-L73\r\n\r\nThe relaxation only occurred on master."]}, {"number": 40788, "title": "TPU UnimplementedError: ", "body": "In [1]: # TPU detection \r\n   ...: import tensorflow as tf \r\n   ...: try: \r\n   ...:     tpu = tf.distribute.cluster_resolver.TPUClusterResolver(zone=\"asia-east1-c\", tpu='node-1') \r\n   ...:     print(\"Well done TPU\") \r\n   ...: except ValueError: \r\n   ...:     tpu = None \r\n   ...:  \r\n   ...: # TPUStrategy for distributed training \r\n   ...: if tpu: \r\n   ...:     tf.config.experimental_connect_to_cluster(tpu) \r\n   ...:     tf.tpu.experimental.initialize_tpu_system(tpu) \r\n   ...:     strategy = tf.distribute.experimental.TPUStrategy(tpu) \r\n   ...: else:  # default strategy that works on CPU and single GPU \r\n   ...:     strategy = tf.distribute.get_strategy() \r\n   ...:                                                                                                                                                                                                                                                                                                                                               \r\nWell done TPU\r\n2020-06-25 05:14:29.750280: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-06-25 05:14:29.756093: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\r\n2020-06-25 05:14:29.756581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a41541e180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-25 05:14:29.756623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-25 05:14:29.756743: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nE0625 05:14:29.759021301   24154 socket_utils_common_posix.cc:222] check for SO_REUSEPORT: {\"created\":\"@1593062069.759011126\",\"description\":\"SO_REUSEPORT unavailable on compiling system\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":190}\r\n2020-06-25 05:14:29.762198: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.164.19.178:8470}\r\n2020-06-25 05:14:29.762229: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54154}\r\n2020-06-25 05:14:29.773350: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.164.19.178:8470}\r\n2020-06-25 05:14:29.773386: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54154}\r\n2020-06-25 05:14:29.773901: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:54154\r\nINFO:tensorflow:Initializing the TPU system: node-1\r\nINFO:tensorflow:Initializing the TPU system: node-1\r\n2020-06-25 05:14:29.848183: E tensorflow/core/common_runtime/eager/context.cc:556] Failed to register function remotely due to \r\nThis shouldn't happen, please file a bug to tensorflow team.\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\n<ipython-input-1-f4a150040101> in <module>\r\n     10 if tpu:\r\n     11     tf.config.experimental_connect_to_cluster(tpu)\r\n---> 12     tf.tpu.experimental.initialize_tpu_system(tpu)\r\n     13     strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n     14 else:  # default strategy that works on CPU and single GPU\r\n\r\n~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py in initialize_tpu_system(cluster_resolver)\r\n    101     context.context()._clear_caches()  # pylint: disable=protected-access\r\n    102 \r\n--> 103     serialized_topology = output.numpy()\r\n    104 \r\n    105     # TODO(b/134094971): Remove this when lazy tensor copy in multi-device\r\n\r\n~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in numpy(self)\r\n    959     \"\"\"\r\n    960     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\r\n--> 961     maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n    962     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr\r\n    963 \r\n\r\n~/miniconda3/envs/mccb/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in _numpy(self)\r\n    927       return self._numpy_internal()\r\n    928     except core._NotOkStatusException as e:\r\n--> 929       six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n    930 \r\n    931   @property\r\n\r\n~/miniconda3/envs/mccb/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nUnimplementedError: \r\n", "comments": ["This shouldn't happen, so I file a bug to tensorflow team.", "# TPU detection\r\nimport tensorflow as tf\r\ntry:\r\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(zone=\"asia-east1-c\", tpu='node-1')\r\n    print(\"Well done TPU\")\r\nexcept ValueError:\r\n    tpu = None\r\n\r\n# TPUStrategy for distributed training\r\nif tpu:\r\n    tf.config.experimental_connect_to_cluster(tpu)\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\nelse:  # default strategy that works on CPU and single GPU\r\n    strategy = tf.distribute.get_strategy()\r\n", "@YankeeMarco \r\nPlease share the code after which you face this error along with tensorflow version.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40788\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40788\">No</a>\n"]}, {"number": 40787, "title": "tf.image.random_flip_left_right should be also to apply to a list of tsor", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2.0\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAdd support to randomly flip image for a list o tensor images instead a single tensor. tf.image.random_flip_left_right, random_flip_top_bottom..\r\nThe problem is that for segmentation training, we wants to use data augment to randomly flip the input left or right. But there is no way the flip the ground true (the labels) together. \r\nSince  we don't know which direction the random flip api is flipping to. Batching make it worse since each image will flip randomly. We need to  modify the api to take  either a single tensor or a list of tensors and flip the images together in the same direction. which is required  for  image segmentation.\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo. We can detect the input argument is a list or single tensor\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@ek9852 \r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "@ravikyram  I already state the use case.\r\nI want to train a network  with image segmentation.\r\nHow can I randomly flip input image and  ground true label (which is another image) to the same direction randomly for data augmentation ?", "You could feed the multiple images for `random_flip_left_right`, see the example [here](https://www.tensorflow.org/api_docs/python/tf/image/random_flip_left_right#example_usage). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40786, "title": "It seems be issues to tflite model", "body": "#https://github.com/google/mediapipe/issues/845", "comments": ["@weinixuehao,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code, the TensorFlow version and the supporting files you are using. Thanks!", "@amahendrakar \r\nThe complete code is #https://github.com/google/mediapipe, the tflite inference code in tflite_inference_calculator.cc. i used other models which provided by mediapipe(/mediapipe/models/*.tflite)  has not this issues. I suspect it is a problem with my model but used tensorflow_lite_gpu.framework to inference no problem. So it may be a version problem or do I need to use the same tensorflow version to convert model.pb to model.tflite?\r\n\r\ntensorflow version:\r\n```\r\n# 2020-04-01\r\n_TENSORFLOW_GIT_COMMIT = \"805e47cea96c7e8c6fccf494d40a2392dc99fdd8\"\r\n_TENSORFLOW_SHA256= \"9ee3ae604c2e1345ac60345becee6d659364721513f9cb8652eb2e7138320ca5\"\r\nhttp_archive(\r\n    name = \"org_tensorflow\",\r\n    urls = [\r\n      \"https://mirror.bazel.build/github.com/tensorflow/tensorflow/archive/%s.tar.gz\" % _TENSORFLOW_GIT_COMMIT,\r\n      \"https://github.com/tensorflow/tensorflow/archive/%s.tar.gz\" % _TENSORFLOW_GIT_COMMIT,\r\n    ],\r\n    patches = [\r\n        \"@//third_party:org_tensorflow_compatibility_fixes.diff\",\r\n        \"@//third_party:org_tensorflow_protobuf_updates.diff\",\r\n    ],\r\n    patch_args = [\r\n        \"-p1\",\r\n    ],\r\n    strip_prefix = \"tensorflow-%s\" % _TENSORFLOW_GIT_COMMIT,\r\n    sha256 = _TENSORFLOW_SHA256,\r\n)\r\n```\r\ntflite model: \r\n[my_model.tflite.zip](https://github.com/tensorflow/tensorflow/files/4834826/my_model.tflite.zip)\r\nmediepipe: master branch commit --> 024f7bf0f1e74149ea92b942cf168ccddf317073\r\n", "@amahendrakar \r\nI have confirmed that it is not a problem with mediapipe using tflite as I directly used TensorFlowLiteC.framework to verify with following code.\r\n```\r\n//\r\n//  ViewController.m\r\n//  tflite\r\n//\r\n//  Created by chenlong on 6/27/20.\r\n//  Copyright \u00a9 2020 Tom. All rights reserved.\r\n//\r\n\r\n#import \"ViewController.h\"\r\n#include <TensorFlowLiteC/TensorFlowLiteC.h>\r\n#include <vector>\r\n\r\n@interface ViewController ()\r\n\r\n@end\r\n\r\n@implementation ViewController\r\n\r\n- (void)run {\r\n    \r\n}\r\n\r\n- (void)viewDidLoad {\r\n    [super viewDidLoad];\r\n    // Do any additional setup after loading the view.\r\n    NSString *modelPath = [[NSBundle mainBundle] pathForResource:@\"hed_graph\" ofType:@\"tflite\"];\r\n    TfLiteModel* model = TfLiteModelCreateFromFile([modelPath UTF8String]);\r\n    TfLiteInterpreterOptions* ti_options = TfLiteInterpreterOptionsCreate();\r\n    \r\n    TFLGpuDelegateOptions options;\r\n    options.allow_precision_loss = true;\r\n    options.wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive;\r\n\r\n    TfLiteDelegate *delegate = TFLGpuDelegateCreate(&options);\r\n    TfLiteInterpreterOptionsAddDelegate(ti_options, delegate);\r\n    // Create the interpreter.\r\n    TfLiteInterpreter* interpreter = TfLiteInterpreterCreate(model, ti_options);\r\n    TfLiteInterpreterAllocateTensors(interpreter);\r\n    TfLiteTensor* input_tensor =\r\n    TfLiteInterpreterGetInputTensor(interpreter, 0);\r\n    \r\n    size_t inputDataSize = 256 * 256 * 3 * sizeof(float);\r\n    std::vector<float> input(inputDataSize);\r\n    // Allocate tensors and populate the input tensor data.\r\n    TfLiteTensorCopyFromBuffer(input_tensor, input.data(),\r\n                               inputDataSize);\r\n    // Execute inference.\r\n    TfLiteInterpreterInvoke(interpreter);\r\n\r\n    size_t outputDataSize = 256 * 256 * 1 * sizeof(float);\r\n    std::vector<float> output(inputDataSize);\r\n    // Extract the output tensor data.\r\n    const TfLiteTensor* output_tensor =\r\n          TfLiteInterpreterGetOutputTensor(interpreter, 0);\r\n    TfLiteTensorCopyToBuffer(output_tensor, output.data(),\r\n                             outputDataSize);\r\n\r\n    // Dispose of the model and interpreter objects.\r\n    TFLGpuDelegateDelete(delegate);\r\n    TfLiteInterpreterDelete(interpreter);\r\n    TfLiteInterpreterOptionsDelete(ti_options);\r\n    TfLiteModelDelete(model);\r\n}\r\n\r\n\r\n@end\r\n\r\n```\r\nThere is also such an error.\r\n![image](https://user-images.githubusercontent.com/17869361/85924304-18f48400-b8c4-11ea-97c1-6bd357cb046c.png)\r\n\r\n![image](https://user-images.githubusercontent.com/17869361/85924339-4e00d680-b8c4-11ea-8293-a4c87b0b5937.png)\r\nI have used the same version as mediapipe", "Any chance you can provide a link to the model? Or a minimal version of the .tflite model?", "The original issue google/mediapipe#845 is closed, so I think I can close this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40786\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40786\">No</a>\n"]}, {"number": 40785, "title": "the link to stable version of this codelab is broken ", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@navczydev \r\nPlease share the link mentioned in the issue.", "Here is the link : https://developer.android.com/codelabs/recognize-flowers-with-tensorflow-on-android/index.html?index=..%2F..index#0\r\nand it's. in this codelab  \ud83d\udc47\r\nhttps://developer.android.com/codelabs/recognize-flowers-with-tensorflow-on-android-beta#0", "Can you please point the page where this is hosted?\r\nWe have `Recognize flowers with TensorFlow` codelab tutorial on TF website on this [web page](https://www.tensorflow.org/lite/models/image_classification/overview)", "If you go to this link\r\nhttps://developer.android.com/codelabs/recognize-flowers-with-tensorflow-on-android-beta#0\r\nand there is a link to stable version of this codelab which is broken", "Do you mean `Colab` from this [web page](https://developer.android.com/codelabs/recognize-flowers-with-tensorflow-on-android-beta#0)?\r\n\r\n<img width=\"1371\" alt=\"Screen Shot 2020-07-04 at 11 18 16 AM\" src=\"https://user-images.githubusercontent.com/42785357/86518709-39eb3680-bde8-11ea-8b32-e8626d9e27b1.png\">\r\n\r\nClicking on `Colab` takes you to https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/lite/codelabs/flower_classification/ml/Flower_Classification_with_TFLite_Model_Maker.ipynb correctly.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40783, "title": "Define __slots__ for small classes", "body": "TensorFlow has many small classes that are used internally as wrappers or containers. Frequently used objects can benefit from defining [`__slots__`](https://docs.python.org/3/reference/datamodel.html#slots).\r\n\r\nFrom the Python docs:\r\n> `__slots__` allow us to explicitly declare data members (like properties) and deny the creation of `__dict__` and `__weakref__` (unless explicitly declared in `__slots__` or available in a parent.)\r\nThe space saved over using `__dict__` can be significant. Attribute lookup speed can be significantly improved as well.\r\n\r\nThis PR explicitely defines `__slots__` for a non exhaustive list of classes that have very few attributes, tend not to be inherited from and don't use dynamic assignment of new variables.", "comments": ["Sorry about the failing tests (it's a bit challenging to run all test locally without a proper bazel cache) af273bc57fd3920dbaae503629df63132d04f27f should fix it.", "aa41fec0487d05ee9607cdf4a82d656d5d1c0066 should fix the last CI breakage, sorry about that."]}]