[{"number": 23180, "title": "Fix comments to match usage", "body": "Fix comments of `sparse_softmax_cross_entropy_with_logits` to match usage.", "comments": ["Nagging Assignee @protoget: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23179, "title": "Introduce SamplingDatasetOp to TensorFlow", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (1.10):\r\n- Are you willing to contribute it (Yes):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI propose to introduce a SamplingDatasetOp to TensorFlow\r\n**Will this change the current api? How?**\r\nYes.\r\nUser would be able to create sampling dataset that output a subset of input dataset that is uniformed sampled from input dataset, with sample rate supplied as parameter.\r\n`dataset = dataset.sampling(rate)`\r\n**Who will benefit with this feature?**\r\nMinigo training have very slow filling rate. https://github.com/tensorflow/minigo/issues/520\r\nThis is due to Minigo use a FilterDatasetOp to filter out subset of input data, which has low efficiency.  With sampling dataset, we can implement the sample action inside the sampling dataset op, without call predicate and go through lambda function explicitly, which improves training performance by 1.7x.  More details can be seen in the issue for minigo above.\r\n**Any Other info.**\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hmm, it seems like some of the recent static optimizations for map/filter fusion and short-circuit maps should be able to take care of this without adding a new transformation.\r\n\r\nCan you please post a minimal reproduction, so we can test the optimizations?\r\n\r\nAssigning this to @jsimsa, since he added the short-circuit map support and can point you to the right optimizations.", "Here is a code snipet that reproduce this problem.\r\n```\r\nimport tensorflow as tf                                                     \r\ndataset = tf.data.Dataset.range(10000)                                      \r\ndataset = dataset.filter(lambda x: tf.less(tf.random_uniform([1]), 0.05)[0])\r\ndataset = dataset.repeat()                                                  \r\ndataset = dataset.shuffle(buffer_size=100000)                               \r\n                                                                            \r\nwith tf.Session() as sess:                                                  \r\n    value = dataset.make_one_shot_iterator().get_next()                     \r\n    sess.run(value)                                                         \r\n\r\n```\r\nThe time output of this program:\r\n```\r\n~/test/tf_dataset$ time python3 tf_dataset.py \r\n2018-10-25 15:01:57.602520: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2018-10-25 15:02:07.623575: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 22660 of 100000\r\n2018-10-25 15:02:17.623406: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 45551 of 100000\r\n2018-10-25 15:02:27.624088: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 68033 of 100000\r\n2018-10-25 15:02:37.624411: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 90821 of 100000\r\n2018-10-25 15:02:41.167028: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:135] Shuffle buffer filled.\r\n\r\nreal    0m45.482s\r\nuser    1m18.749s\r\nsys     0m15.244s\r\n\r\n```", "A more complete test case that use the sampling dataset I implemented locally.  I kinda of magnify the problem by set rate to 0.01, instead of 0.05\r\n```\r\nimport tensorflow as tf                                                           \r\nimport time                                                                       \r\n                                                                                  \r\nrate = 0.01                                                                       \r\n                                                                                  \r\ndatasetS = tf.data.Dataset.range(10000)                                           \r\ndatasetS = datasetS.repeat()                                                      \r\ndatasetS = datasetS.sampling(rate)                                                \r\ndatasetS = datasetS.shuffle(buffer_size=100000)                                   \r\n                                                                                  \r\ndatasetF = tf.data.Dataset.range(10000)                                           \r\ndatasetF = datasetF.repeat()                                                      \r\ndatasetF = datasetF.filter(lambda x: tf.less(tf.random_uniform([1]), rate)[0])    \r\ndatasetF = datasetF.shuffle(buffer_size=100000)                                   \r\n                                                                                  \r\nwith tf.Session() as sess:                                                        \r\n    valueS = datasetS.make_one_shot_iterator().get_next()                         \r\n    valueF = datasetF.make_one_shot_iterator().get_next()                         \r\n    print (\"run with sampling dataset\")                                           \r\n    start = time.time()                                                           \r\n    sess.run(valueS)                                                              \r\n    end = time.time()                                                             \r\n    print (\"%f seconds\"%(end-start))                                              \r\n    start = time.time()                                                           \r\n    print (\"run with filter dataset\")                                             \r\n    sess.run(valueF)                                                              \r\n    end = time.time()                                                             \r\n    print (\"%f seconds\"%(end-start))                                              \r\n\r\n```\r\nThe output shows sampling dataset op would be 47x faster than use a filter dataset op to do the job.\r\n```\r\n2018-10-25 15:20:41.554439: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.        \r\nrun with sampling dataset\r\n3.914848 seconds\r\nrun with filter dataset\r\n2018-10-25 15:20:55.497627: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 5451 of 100000                                                           \r\n2018-10-25 15:21:05.498753: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 10959 of 100000                                                          \r\n2018-10-25 15:21:15.498401: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 16433 of 100000                                                          \r\n2018-10-25 15:21:25.498502: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 21692 of 100000                                                          \r\n2018-10-25 15:21:35.497819: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 27089 of 100000                                                          \r\n2018-10-25 15:21:45.500435: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 32521 of 100000                                                          \r\n2018-10-25 15:21:55.500459: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 37949 of 100000                                                          \r\n2018-10-25 15:22:05.499758: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 43421 of 100000                                                          \r\n2018-10-25 15:22:15.497833: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 48904 of 100000                                                          \r\n2018-10-25 15:22:25.508743: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 54146 of 100000                                                          \r\n2018-10-25 15:22:35.500528: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 59416 of 100000                                                          \r\n2018-10-25 15:22:45.498792: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 64705 of 100000                                                          \r\n2018-10-25 15:22:55.500804: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 69902 of 100000                                                          \r\n2018-10-25 15:23:05.498479: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 75305 of 100000                                                          \r\n2018-10-25 15:23:15.498075: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 80657 of 100000                                                          \r\n2018-10-25 15:23:25.499887: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 86016 of 100000                                                          \r\n2018-10-25 15:23:35.500111: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 91404 of 100000                                                          \r\n2018-10-25 15:23:45.499380: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:97] Filling up shuffle buffer (this may take a while): 96791 of 100000                                                          \r\n2018-10-25 15:23:51.490890: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:135] Shuffle buffer filled.\r\n186.004482 seconds\r\n\r\n```", "Thank you for providing the example.\r\n\r\nWhen I run the filter-based pipeline on my workstation, it takes roughly 160 seconds.\r\n\r\nIIUC, the equivalent sampling logic can be implemented using the following pipeline:\r\n\r\n```\r\n  ds = tf.data.Dataset.range(10000).shuffle(10000)\r\n  ds = ds.repeat()\r\n  ds = ds.window(100).flat_map(lambda x: x.take(1))\r\n  ds = ds.shuffle(buffer_size=100000)\r\n```\r\n\r\nRunning this pipeline on my machine takes less than 10 seconds, so I am leaning towards not introducing new API for something that can be implemented within a factor of 2 using the existing API.\r\n\r\n", "Closing this issue, assuming it is resolved, but feel free to re-open if you have follow up.", "Hi, the first step (Dataset.range(10000)) is an artificial op to expose the performance bottleneck.  In real life scenario (https://github.com/mlperf/training/blob/master/reinforcement/tensorflow/minigo/preprocessing.py#L139), data is read from file and number of elements are not predefined.  It looks to me the method @jsimsa only works for fixed length dataset, and not working for variable length dataset or dataset that read from a stream.   How do I do something methematically equivalent or close when input data size is unknown?\r\n", "I don't have access to reopen.  Do you have suggestion for my scenario?", "I think the general pattern would be:\r\n\r\n```\r\ndataset # this is the dataset you wish to sample with ratio a/b\r\ndataset = dataset.shuffle(x) # x trades off mathematical accuracy and performance\r\ndataset = dataset.repeat()\r\ndataset = dataset.window(b).flat_map(lambda x: x.take(a))\r\n```\r\n\r\nDoes that make sense?", "I think the hard part is find out 'x' that balance between mathematical accuracy and performance.  i.e.  In the lab log of minigo, I read 'move shuffle buffer to 1M from 200k', then some later logs to move it back to 200k again, etc.  That I saw struggling between performance and accuracy.  While sampling op is both mathematical accurate and fast, which is the whole point.", "I am opposed to adding `sample` to the public tf.data API. It does not add any new functionality.\r\n\r\nAs far as I can tell, you want to introduce the transformation because of performance. If that's the case, let me suggest an alternative route. You implement the C++ `SampleDataset` kernel, but instead of surfacing it in the public API, you also implement  a static optimization that replaces instances of `FilterDataset` with a \"sampling\" predicate (e.g. `lambda x: tf.less(tf.random_uniform([1]), rate)[0])`) with `SampleDataset`. This way, the optimization happens automatically and we do not clutter the API with endpoints that do not provide new functionality.\r\n\r\nFor an example of tf.data static optimization, see https://github.com/tensorflow/tensorflow/blob/00ae12ad8bf5c348e4c31448e3922cbaab54cc03/tensorflow/core/grappler/optimizers/data/map_and_batch_fusion.cc (this optimization replaces `map(...).batch(...)` with `map_and_batch(...)`, also for the sake of performance).", "Hi @jsimsa , thanks for the suggestion.  I'm thinking this option over.  Technically it is possible, and with this the model code does not need to be changed.  There is but one doubt that might need clarification.  The use of `FilterDataset` for this purpose is little bit strange.  From the design of `FilterDataset`, it is designed to pick out the data according to whether its value meet predicate.   The use of random_uniform in this case, however, is independent of its value.   It seems a strange way of exploit the semantic of `FilterDataset` in lack of a `SamplingDataset`.  If we look at `TakeDataset` and `SkipDataset`, they all can be implemented by `FilterDataset` with proper lambda function.  However they are separate API rather than lambda function with proper optimization.\r\n\r\nIf say we implement the optimization and make it convert to an internal `SamplingDataset` automatically, is it align with the intent use of this API?  In another word, if we submit a PR for an optimization rather than a new API, will it be considered?", "`skip` and `take` are separate API because they can only be implemented using a *stateful* function and stateful functions have many limitations (e.g. do not support checkpointing and preclude many static optimizations).\r\n\r\nIf you implement my suggestion, I will be happy to review the PR.", "Hi @jsimsa \r\nI'm optimizing the pattern as you suggested.  However I met one problem. The `tf.random_uniform` op itself is stateful, which will be blocked by `tensorflow/core/framework/dataset.cc:AddFunction`.\r\n\r\nIt is tricky here, from definition in TensorFlow, random_uniform is stateful because two call with same input will generate different output, which is the nature of _random_.   The pseudo random number generator also requires a internal state to generate random number sequence.  On the other hand, if `random_uniform` is implemented to imitate true random number generator, each time we call `random_uniform`, we expect the output to be independent to previous outputs, make it actually stateless in another sense.  The final result is in practice this pattern cannot be statically optimized, but in spirit, this pattern should be able to be statically optimized (replaced by a `SamplingDataset`).\r\n\r\nWhat's your suggestion here?  It looks like either we need to remove some restriction on optimization in TensorFlow, or we have to introduce new API for same performance purpose.", "I am not sure what do you mean \"will be blocked by ...\". When we use `AddFunction` to build the graph for the sake of optimization, then stateful actions are allowed (see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/dataset.cc#L143)).\r\n\r\nYour optimization should check whether the FilterDataset function matches a certain pattern and if so, replace it with SamplingDataset.", "Oh, I'm experimenting with r1.10.1 branch, the allow optimization part is not present on r1.10.1.  I'll try the line in master and see how it goes.\r\n> I am not sure what do you mean \"will be blocked by ...\". When we use `AddFunction` to build the graph for the sake of optimization, then stateful actions are allowed (see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/dataset.cc#L143)).\r\n> \r\n> Your optimization should check whether the FilterDataset function matches a certain pattern and if so, replace it with SamplingDataset.\r\n\r\nYes, that's exactly I'm doing, it works well for the filter function, and get the performance expected, thanks for the suggestion!\r\n", "> `skip` and `take` are separate API because they can only be implemented using a _stateful_ function and stateful functions have many limitations (e.g. do not support checkpointing and preclude many static optimizations).\r\n> \r\n> If you implement my suggestion, I will be happy to review the PR.\r\n\r\nHi @jsimsa , PR 25384 is opened following your suggestion.  Can you review this PR?  Thanks!\r\nhttps://github.com/tensorflow/tensorflow/pull/25384"]}, {"number": 23178, "title": "Cannot build tensorflow from source, Ubuntu 16.04", "body": "uname\r\nLinux olympus 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nCUDA 10\r\n\r\nTrying to run ./configure to build tensorflow for cuda 10 but it doesn't work. bazel is complaining about many things..\r\n\r\nThe function 'set' has been removed in favor of 'depset', please use the latter. You can temporarily refer to the old 'set' constructor from unexecuted code by using --incompatible_disallow_uncalled_set_constructor=false\r\n\r\nERROR: error loading package '': Extension 'closure/filegroup_external.bzl' has errors\r\n\r\nWhat are the exact steps to build successfully from source for linux?", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).(From your case I think you can select Build/Installation Issue) Please provide all the information it asks. Thank you."]}, {"number": 23177, "title": "in mnist_with_summaries.py,the function act(), what mean,,where define", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py#L97\r\n      activations = act(preactivate, name='activation')\r\n\r\n", "comments": ["  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):  \r\nact is  a  formal parameter"]}, {"number": 23176, "title": "keras.layers.Concatenate could support list inputs with length 1", "body": "**System information**\r\n- TensorFlow version (you are using):\r\n```\r\n$ pip freeze | grep tensorflow\r\ntensorflow==1.12.0rc1\r\ntensorflow-estimator==1.10.12\r\n```\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, the `tf.keras.layers.Concatenate` only supports [list inputs with length >= 2](https://github.com/tensorflow/tensorflow/blob/e5c17aef836f8b85591cdcae31fbb66ddcf8185a/tensorflow/python/keras/layers/merge.py#L378).\r\n\r\nConsidering that the vanilla `tf.concat` works with inputs of length 1, it would be nice if the keras layers implemented the same behavior.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef test_tensorflow_concatenate(inputs):\r\n    tf.concat(inputs, axis=-1)\r\n\r\n    print(\"tf.concat works with {} inputs\".format(len(inputs)))\r\n\r\n\r\ndef test_concatenate_layer_with_inputs(inputs):\r\n    model = tf.keras.Sequential((\r\n        tf.keras.layers.Concatenate(axis=-1),\r\n        tf.keras.layers.Dense(32)))\r\n\r\n    feed_dict = {\r\n        input_: np.random.uniform(\r\n            0, 1, (3, *input_.shape[1:].as_list()))\r\n        for input_ in inputs\r\n    }\r\n    output = model(inputs)\r\n    output_eval = tf.keras.backend.get_session().run(\r\n        output, feed_dict=feed_dict)\r\n    output_np = model.predict([feed_dict[key] for key in inputs])\r\n\r\n    assert np.allclose(output_eval, output_np)\r\n\r\n    print(\"tf.keras.layers.Concatenate with {} inputs\".format(len(inputs)))\r\n\r\n\r\ndef main():\r\n    input1 = tf.keras.layers.Input((1, ))\r\n    input2 = tf.keras.layers.Input((2, ))\r\n\r\n    test_tensorflow_concatenate([input1, input2])\r\n    test_tensorflow_concatenate([input1])\r\n\r\n    test_concatenate_layer_with_inputs([input1, input2])\r\n    test_concatenate_layer_with_inputs([input1])\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo ValueErrors would be raised when calling the `tf.keras.layers.Concatenate` with input list of length 1.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone who dynamically creates multi-input/-output keras models.\r\n\r\n**Any Other info.**\r\nn/a", "comments": []}, {"number": 23175, "title": "[INTEL MKL] Register matmul kernel to use Eigen based implementation for int64", "body": "Recently, int64 has been enabled for matmul in TensorFlow (https://github.com/tensorflow/tensorflow/commit/2d0c8127d76b9a56c8e264cc98e902b257fb64b2). Since MKL does not support int64 for matmul, I have registered the matmul kernel to fallback to the default Eigen based implementation in such cases.\r\n\r\nThis PR would also cause `//tensorflow/python/kernel_tests:matmul_op_test` to pass with MKL-DNN.", "comments": ["Pinging @penpornk for a review.", "@penpornk I have removed the extra space per your suggestion.", "Hi @penpornk, I see that this PR is still not merged into the master. I was wondering if there's anything needed from my side to expedite this merge process. Thanks.", "@bhavani-subramanian Some of the checks failed. For example, GPU CC has 100 tests failed to build. Are you able to see the logs? ", "@penpornk Yes, I am able to see the logs. I'll look into these unit test failures. Thanks", "@penpornk It looks like these failures are caused by internal commit to the master:  \r\n![image](https://user-images.githubusercontent.com/28113241/47742376-ba33be80-dc39-11e8-9de5-b56a2a9b6032.png)\r\nAs you can see, in `2c164ed`, all unit tests pass. However, starting from `fc6cd33`, XLA and GPU tests start to fail.\r\nAm I missing something here?", "@bhavani-subramanian I'm not sure what is happening either. I don't think your changes would affect anything. I re-ran the tests again. Now GPU CC passed but Ubuntu CC that used to pass failed -- and it doesn't show the logs either. A recent commit (around the same time I re-ran the tests) passed all the tests. I also forced-run kokoro on this [typo PR](https://github.com/tensorflow/tensorflow/pull/23217) and it's passing all the completed tests so far. I'm thinking of pulling the PR in and see what happens directly.\r\n\r\n@wt-huang Could you please help pull the PR in?", "@penpornk just did, thanks."]}, {"number": 23174, "title": "1.12.0-rc2 cherry-pick request: Removing tf.train.confusion_matrix endpoint.", "body": "tf.train.confusion_matrix was added in 1.12.0rc0. Removal should be cherrypicked into 1.12.0rc2 so that compatibility breakage is only between rc's.", "comments": []}, {"number": 23173, "title": "[Intel-MKL] Fold subdivmul based batchnorms onto convlution and biasadd", "body": "This PR folds BatchNorms that are of form Sub-RealDiv-Mul format into the Conv2d present before and BiasAdd node present after.\r\n\r\n<pre>\r\nBefore:\r\n--->Conv2D ---> Sub ---> RealDiv ---> Mul ---> BiasAdd --->\r\n      ^          ^         ^           ^          ^\r\n    Const      Const      Const      Const      Const\r\n\r\nAfter:\r\n--->Conv2D ---------------------------------> BiasAdd --->\r\n      ^                                          ^\r\n  Const(New)                                 Const(New)\r\n</pre>\r\nThis optimization can be used in models such as Yolov2, Yolov3 where we see a  12 to 14% FP32 performance improvement while preserving the same mAP accuracy.\r\n\r\nNote: The input bias for the convolution2D node is set to zero in our calculation of Const(New) to Conv2D. ", "comments": ["Can you add unit tests for this change, similar to the other graph transform examples? Thanks!", "@petewarden @wt-huang Done. Unit test added as requested.", "@wt-huang I do not see any errors and unable to click any link to check what failed. Yet I ran cpplint and just fixed some formatting such as long lines. Let me know if anything needs to be done for this PR for it to be merged", "@petewarden @wt-huang Can you Merge this PR please.", "Any update on this PR?"]}, {"number": 23172, "title": "Error using cohen_kappa metric with tf.contrib.distribute.MirroredStrategy configured estimator", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): ('v1.11.0-0-gc19e29306c', '1.11.0')\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.0.176/7.2.1.38\r\n- GPU model and memory: 4x Nvidia V100 16GB\r\n\r\n**Describe the current behavior**\r\nWhen using the `tf.contrib.metrics.cohen_kappa` metric with an estimator, a `TypeError` is raised when calling the `evaluate` method on the estimator if the evaluation is configured to be distributed with `tf.contrib.distribute.MirroredStrategy`. The evaluation is successful if the estimator is not configured for distributed evaluation.\r\n\r\n**Describe the expected behavior**\r\nThe metric `tf.contrib.metrics.cohen_kappa` should be calculated successfully in both distributed and non-distributed evaluations.\r\n\r\n**Code to reproduce the issue**\r\ntest.py:\r\n```python\r\nimport tensorflow as tf\r\n\r\nDO_EVAL_DIST = True\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\ndef model_fn(features, labels, mode):\r\n    layer = tf.layers.Dense(2)\r\n    logits = layer(features)\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\"logits\": logits}\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n    loss = tf.losses.mean_squared_error(\r\n        labels=labels, predictions=tf.reshape(logits, [-1]))\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        class_targets = tf.reshape(tf.argmax(labels, axis=-1, name='class_targets'), [-1])\r\n        preds = tf.reshape(tf.argmax(logits, axis=-1, name='preds'), [-1])\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={\r\n            'cohen_k': tf.contrib.metrics.cohen_kappa(class_targets, preds, 2),\r\n        })\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\ndef input_fn():\r\n    features = tf.data.Dataset.from_tensors([[1.]]).repeat()\r\n    labels = tf.data.Dataset.from_tensors([1., 0.]).repeat()\r\n    return tf.data.Dataset.zip((features, labels))\r\n\r\n# Configured the estimator for either distributed or non-distributed evaluation\r\n# Training is always distributed\r\nif DO_EVAL_DIST:\r\n    distribution = tf.contrib.distribute.DistributeConfig(\r\n        train_distribute=tf.contrib.distribute.MirroredStrategy(),\r\n        eval_distribute=tf.contrib.distribute.MirroredStrategy()\r\n    )\r\n    config = tf.estimator.RunConfig(experimental_distribute=distribution)\r\nelse:\r\n    distribution = tf.contrib.distribute.MirroredStrategy()\r\n    config = tf.estimator.RunConfig(train_distribute=distribution)\r\n\r\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config, model_dir='out_test')\r\n\r\nprint('********* start train **********')\r\nclassifier.train(input_fn=input_fn, steps=1000)\r\nprint('********* end train/start eval **********')\r\nclassifier.evaluate(input_fn=input_fn, steps=1000)\r\nprint('********* end eval **********')\r\n```\r\n\r\n**Other info / logs**\r\nError thrown when using distributed evaluation, when `DO_EVAL_DIST = True`:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 49, in <module>\r\n    classifier.evaluate(input_fn=input_fn, steps=1000)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 474, in evaluate\r\n    return _evaluate()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 469, in _evaluate\r\n    output_dir=self.eval_dir(name))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1528, in _evaluate_run\r\n    config=self._session_config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/evaluation.py\", line 212, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 783, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 816, in _close_internal\r\n    h.end(self._coordinated_creator.tf_sess)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 941, in end\r\n    self._final_ops, feed_dict=self._final_ops_feed_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1095, in _run\r\n    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 429, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 249, in for_fetch\r\n    return _DictFetchMapper(fetch)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 387, in __init__\r\n    _FetchMapper.for_fetch(fetch) for fetch in fetches.values()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 255, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 288, in __init__\r\n    (fetch, type(fetch), str(e)))\r\nTypeError: Fetch argument PerDevice({'/replica:0/task:0/device:GPU:0': <tf.Tensor 'cohen_kappa/value/Merge:0' shape=() dtype=float64>, '/replica:0/task:0/device:GPU:1': <tf.Tensor 'tower_1/cohen_kappa/value/Merge:0' shape=() dtype=float64>, '/replica:0/task:0/device:GPU:2': <tf.Tensor 'tower_2/cohen_kappa/value/Merge:0' shape=() dtype=float64>, '/replica:0/task:0/device:GPU:3': <tf.Tensor 'tower_3/cohen_kappa/value/Merge:0' shape=() dtype=float64>}) has invalid type <class 'tensorflow.contrib.distribute.python.values.PerDevice'>, must be a string or Tensor. (Can not convert a PerDevice into a Tensor or Operation.)\r\n```", "comments": ["I was able to execute your code successfully with DO_EVAL_DIST = True. Tagging priya to get more insights on this.", "@ymodak are you running this on a machine with multiple GPUs?\r\n\r\nThe VM I am testing with has 4x V100 GPUs, and I have updated the issue report to reflect this. I am not seeing this error on a VM with only a single V100 GPU. I have also confirmed that the code will execute successfully on the 4x V100 GPU VM if the eval distribute configuration is changed to the following:\r\n```python\r\neval_distribute=tf.contrib.distribute.MirroredStrategy(num_gpus=1)\r\n```\r\n\r\nThe issue still remains for me when trying to distribute over multiple GPUs.", "@Matt-Hicks-Bose Yes you are right about that. I have tested against single GPU and it completed successfully. This issue is likely to occur for multiple GPUs.", "I think the issue here is the metric was never updated to use the _aggregate_across_towers() wrapper that the non contrib tf.metrics use such as tf.mean_per_class_accuracy.", "See https://github.com/tensorflow/tensorflow/blob/748435b8ef55a554e011e97a9f893304e737775a/tensorflow/python/ops/metrics_impl.py#L304 for what @Brian-Hetherman-Bose is refering to. I am not sure if any of the tf.contrib.metrics will work with distributed eval until this is updated.", "@guptapriya Have you had a chance to take a look at this? Would be nice if this was fixed in the TF 1.12 stable release", "Sorry just looking at this now. You guys are right that this is not working because contrib.metrics haven't been modified to be distribution strategy aware. \r\n\r\nAFAIK, (and [according to this RFC](https://github.com/tensorflow/community/blob/5c805774c8b45a3a0ce1337ada4a3f1fc3307983/rfcs/20180907-contrib-sunset.md)), contrib.metrics is not being migrated to core TF. As such, we don't think we will be making an effort to make them distribution aware. \r\n\r\nIf you guys are interested in the fate of these metrics, please join addons@tensorflow.org for the Addons SIG, where metrics like this may end up (assuming there is someone who wants to migrate and maintain them). \r\n", "Nagging Assignee @guptapriya: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23171, "title": "Updates to documentation for root package and tf.a*", "body": "This PR contains miscellaneous API documentation updates that cover the root package `tf` and all the API functions whose names start with `tf.a`. Some of the changes correct typos, while others document aspects of these functions that weren't obvious to me without reading the source code.\r\n\r\nNote that the functions `tf.abs`, `tf.add_n`, `tf.accumulate_n`, and `tf.angle` moved to the `tf.math` package while I was making these edits.\r\n\r\nI've generated and reviewed the Markdown files for the documentation after these changes.", "comments": ["It looks like there was a hiccup somewhere in the CI infrastructure. The build and tests are all working on this branch on my test machine. Would someone with access mind rerunning the CI checks for this PR?", "@frreiss Can you please resolve the conflicts? Thanks!", "Merge conflicts fixed. Currently rerunning regression tests on my test machine.", "@frreiss There are branch conflicts. Can you please rebase? Thanks!", "Merged in changes from master, including manually moving some of my documentation edits from `gradients_impl.py` to `gradients_util.py`. The branch conflicts should be fixed now.", "@MarkDaoust Can you PTAL? Thanks!", "Hi @MarkDaoust and @ymodak , this PR appears to be ready to merge. Is there anything still holding it up?", "@frreiss can you please resolve conflicts", "Conflicts resolved."]}, {"number": 23170, "title": "Switch from Deprecated to Current Docker Images on Docker Hub", "body": "Tensorflow Dockerfiles are [currently located](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles) at `tensorflow/tensorflow/tools/dockerfiles/dockerfiles/`. The parent directory (`tensorflow/tensorflow/tools/dockerfiles/`) includes instructions to build the images from that directory. This is done so the Dockerfiles have the `bashrc` file in their build context to `COPY` into containers at runtime. \r\n\r\nThere are another set of Dockerfiles at `tensorflow/tensorflow/tools/docker/` which are marked deprecated/for-deletion. These deprecated Dockerfiles are the ones currently hosted on [Docker Hub](https://hub.docker.com/r/tensorflow/tensorflow/).\r\n\r\nI propose Tensorflow switch their publicly available Docker images from the deprecated set to current ones. With minimal upfront effort, all eight current images could be hosted on Docker Hub and automatically rebuilt with each repo update.\r\n\r\nThis transition could be achieved in two main steps:\r\n\r\n1 Move `tensorflow/tensorflow/tools/dockerfiles/bashrc` into the `dockerfiles` child directory at `tensorflow/tensorflow/tools/dockerfiles/dockerfiles/` to give the Dockerfiles access to the file in their default build context.\r\n - This will require a few minor relative path updates, such as changing the `COPY` path in `tensorflow/tensorflow/tools/dockerfiles/assembler.Dockerfile`\r\n\r\n```diff\r\n- COPY  bashrc /etc/bash.bashrc\r\n+ COPY dockerfiles/bashrc /etc/bash.bashrc\r\n```\r\n\r\n2 Now, Docker Hub can be easily configured to link to the Tensorflow account, host the current Docker images and rebuild them whenever they're changed. Using this Docker Hub Build Setting image for context:\r\n\r\n![graph_nets_dockerhub_build_settings](https://user-images.githubusercontent.com/21133719/47311058-03f72600-d5f6-11e8-8827-8411c2fb641b.png)\r\n\r\nI recommend Tensorflow set up Docker Hub automatic build settings to the `tensorflow/tensorflow` repo with the following location:tag pairs:\r\n\r\n| Dockerfile Location                                                                          |  Docker Tag Name          |\r\n|----------------------------------------------------------------------------------------|----------------------------------|\r\n| `tools/dockerfiles/dockerfiles/cpu.Dockerfile`                                  | latest                               |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel.Dockerfile`                        | latest-devel                      |\r\n| `tools/dockerfiles/dockerfiles/cpu-jupyter.Dockerfile`                      | latest-jupyter                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel-jupyter.Dockerfile`            | latest-devel-jupyter          |\r\n| `tools/dockerfiles/dockerfiles/nvidia.Dockerfile`                              | latest-gpu                        |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel.Dockerfile`                    | latest-gpu-devel               |\r\n| `tools/dockerfiles/dockerfiles/nvidia-jupyter.Dockerfile`                  | latest-gpu-jupyter             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel-jupyter.Dockerfile`        | latest-gpu-devel-jupyter   |\r\n\r\nI have already signed the individual CLA for a previous commit and would be happy to implement these code changes -- someone with access to Tensorflow's Docker Hub account would have to enter the automated build settings.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hi, I would be happy to add anything. But I'm not sure what more would be helpful for the proposal above.\r\n\r\nThis is a proposal that is environment-agnostic.", "I made the proposed changes in a [forked branch](https://github.com/IMBurbank/tensorflow/tree/host_new_dockerfiles) and pushed the images to [Docker Hub](https://hub.docker.com/r/imburbank/tensorflow/ 'imburbank/tensorflow'). I'll show finish fleshing this out for your consideration in a PR this evening.", "Thanks for bringing this up. Unfortunately, there is a lot of hidden complexity to how we deploy our images -- the reason we haven't already updated our images, actually, is because I've been trying to simplify the internal process. For example, our test infrastructure for these images is very simple, and we don't have a way yet to prove that the images work for what we want them to do (and suddenly breaking everyone that depends on these images would be very bad).\r\n\r\nI am currently planning to work on this in November. In the meantime, I'll update the docs you mentioned to better describe the real situation. I'll also keep this issue open, since we don't have any other issues that better reflect this need.", "Alright, thank you very much for the reply. I hope you don't mind if I propose intermediate solutions in light of your concerns about the fragile build workflow.\r\n\r\nIt seems there may be an intermediate way to maintain the current function of all Dockerfiles and older hosted images while also making the current Dockerfile images available. \r\n\r\nOne alternative to achieve this would be as follows:\r\n\r\nCopy `tensorflow/tools/dockerfiles/bashrc` to `tensorflow/tools/dockerfiles/dockerfiles/bashrc`\r\n\r\nSince the `bashrc` file is very small and remains largely unchanging, a copy of the file could be placed in the `dockerfiles` child directory with the rest of the Dockerfiles. Nothing would change in any Dockerfiles, images could be built from the `tensorflow/tools/dockerfiles/` or `tensorflow/tools/dockerfiles/dockerfiles/` context with the exact same access to `bashrc` and the current images could immediately be hosted on Docker Hub. The only change would be to `assembler.py` to copy `bashrc` when creating the directory.\r\n\r\nThe Dockerfile images could be hosted with the proposed tags `latest` and `latest-gpu` changed to avoid a naming collision with the two older images already hosted on Docker Hub.\r\n\r\n| Dockerfile Location                                                                          |  Docker Tag Name          |\r\n|----------------------------------------------------------------------------------------|----------------------------------|\r\n| `tools/dockerfiles/dockerfiles/cpu.Dockerfile`                                  | latest-current                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel.Dockerfile`                        | latest-devel                      |\r\n| `tools/dockerfiles/dockerfiles/cpu-jupyter.Dockerfile`                      | latest-jupyter                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel-jupyter.Dockerfile`            | latest-devel-jupyter          |\r\n| `tools/dockerfiles/dockerfiles/nvidia.Dockerfile`                              | latest-current-gpu             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel.Dockerfile`                    | latest-gpu-devel               |\r\n| `tools/dockerfiles/dockerfiles/nvidia-jupyter.Dockerfile`                  | latest-gpu-jupyter             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel-jupyter.Dockerfile`        | latest-gpu-devel-jupyter   |\r\n\r\nThis option could be a simple stop-gap to make all images available without risking any breaking changes - or creating significant rework.", "Since you'll be looking at this over the new few weeks, I modified my [`host_new_dockerfiles`](https://github.com/IMBurbank/tensorflow/tree/host_new_dockerfiles) branch to demonstrate this new proposed change. It only slightly modifies `assembler.py` to copy `bashrc` into the `dockerfiles` directory when created.\r\n \r\nI moved the undid the previous changes, and changed the following in `assembler.py`\r\n\r\n- Add `FLAG.bashrc_file`\r\n```python\r\nflags.DEFINE_string(\r\n    'bashrc_file',\r\n    './bashrc',\r\n    'Path to image bashrc file',\r\n    short_name='b')\r\n```\r\n\r\n- Add test to ensure `FLAG.bashrc_file` path exists\r\n```python\r\n  # Abort if bashrc path is invalid\r\n  if not os.path.exists(FLAGS.bashrc_file):\r\n    print('>> ERROR: {} is an invalid bashrc path!'.format(FLAGS.bashrc_file))\r\n    exit(1)\r\n```\r\n\r\n- Copy `bashrc` to `dockerfiles` directory when created\r\n```diff\r\n  # Write each completed Dockerfile\r\n  if not FLAGS.dry_run:\r\n    print('>> Emptying destination dir \"{}\"'.format(FLAGS.output_dir))\r\n    shutil.rmtree(FLAGS.output_dir, ignore_errors=True)\r\n    mkdir_p(FLAGS.output_dir)\r\n+   shutil.copy(FLAGS.bashrc_file, FLAGS.output_dir)\r\n  else:\r\n```\r\n\r\nThen I followed instructions and ran `assembler.py` to recreate the `dockerfiles` directory with `bashrc` included.\r\n\r\nThe forked branch is up to date and the images are available at [`imburbank/tensorflow`](https://hub.docker.com/r/imburbank/tensorflow/). I'll keep the branch updated with upsteam/master for current image builds at least through November.\r\n\r\nThe images are available with my original proposed tag scheme:\r\n\r\n| Dockerfile Location                                                                          |  Docker Tag Name          |\r\n|----------------------------------------------------------------------------------------|----------------------------------|\r\n| `tools/dockerfiles/dockerfiles/cpu.Dockerfile`                                  | latest                               |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel.Dockerfile`                        | latest-devel                      |\r\n| `tools/dockerfiles/dockerfiles/cpu-jupyter.Dockerfile`                      | latest-jupyter                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel-jupyter.Dockerfile`            | latest-devel-jupyter          |\r\n| `tools/dockerfiles/dockerfiles/nvidia.Dockerfile`                              | latest-gpu                        |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel.Dockerfile`                    | latest-gpu-devel               |\r\n| `tools/dockerfiles/dockerfiles/nvidia-jupyter.Dockerfile`                  | latest-gpu-jupyter             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel-jupyter.Dockerfile`        | latest-gpu-devel-jupyter   |\r\n\r\nAnd can be used as proposed:\r\n\r\n```bash\r\ndocker run --user $(id -u):$(id -g) -p 8888:8888 -v $(pwd):/notebooks -it imburbank/tensorflow:latest-jupyter\r\n```", "Disregard the previous proposal (even more so). There is a way to host all of these images without any changes. \r\n\r\n[Docker Cloud](https://cloud.docker.com/) integrates directly with your Docker Hub account and provides the option to add build context and args to their automated build workflow.\r\n\r\n![screenshot from 2018-10-26 14-06-03](https://user-images.githubusercontent.com/21133719/47590144-ae3db900-d928-11e8-8fd4-a9cd1d821fae.png)\r\n\r\nNo code changes are needed for Tensorflow to host these images. Just set the build-context to `tools/dockerfiles` \r\n\r\nAnd use a tag system like the one I proposed that doesn't collide with your currently hosted images\r\n\r\n| Dockerfile Location                                                                          |  Docker Tag Name          |\r\n|----------------------------------------------------------------------------------------|----------------------------------|\r\n| `tools/dockerfiles/dockerfiles/cpu.Dockerfile`                                  | latest-current                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel.Dockerfile`                        | latest-devel                      |\r\n| `tools/dockerfiles/dockerfiles/cpu-jupyter.Dockerfile`                      | latest-jupyter                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel-jupyter.Dockerfile`            | latest-devel-jupyter          |\r\n| `tools/dockerfiles/dockerfiles/nvidia.Dockerfile`                              | latest-current-gpu             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel.Dockerfile`                    | latest-gpu-devel               |\r\n| `tools/dockerfiles/dockerfiles/nvidia-jupyter.Dockerfile`                  | latest-gpu-jupyter             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel-jupyter.Dockerfile`        | latest-gpu-devel-jupyter   |\r\n\r\nThe images could all be officially hosted with no risk and little effort.", "Thanks for the suggestions. I'll consider them while I'm working on the images.", "Nagging Assignee @angersson: It has been 31 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "As of today, the `nightly` Docker images use the new Dockerfiles. The rest are WIP. ", "This is now complete."]}, {"number": 23169, "title": "Document undocumented ops in check_ops.py", "body": "This PR adds API documentation for two public functions in `check_ops.py` that were previously undocumented.\r\n\r\nI've generated and reviewed the Markdown files for the documentation after these changes.", "comments": ["Hmm, something appears to have gone wrong with the CI server. @MarkDaoust, would you mind triggering the CI builds again?", "@frreiss  Can you please run clang-format on your code.", "> @frreiss Can you please run clang-format on your code.\r\n\r\n`clang-format` doesn't seem to have settings for Python. I tried running my modified copy of `check_ops.py` through `yapf`, but the formatter didn't change any of the lines that I modified in this PR. Can you provide more information about the formatting issue?", "@frreiss  Please rebase the PR to resolve the merge conflict, so that I can run the test for this PR again.", "Pulled changes from master into this branch. Please let me know if there are any additional problems.", "@MarkDaoust -  The merging conflicts have been resolved and could you please approve or suggest changes(if required)."]}, {"number": 23168, "title": "[Intel MKL] MKL DNN: cleaning mkl softamx kernel", "body": "[Intel MKL] Cleaned up Intel MKL ML related code. The intention is to stop supporting MKL ML (closed source library) code and have the MKL DNN code (Open sourced library) to be the default code path.", "comments": ["Hi, if possible, can you please take a look at this PR. It is a very small change to one file to clean up the MKL ML code.", "Hi, if possible, can you please take a look at this PR. It is a very small change to one file to clean up the MKL ML code.", "sorry, did not notice it was assigned to me. I am not familiar with this code. Can you find another reviewer? thanks", "I will wait a few days to commit this PR, since another PR also changing the file.", "@ashraf-bhuiyan Can you please resolve the conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It will be worked on. Need to fix a conflicted file.", "I merged the softmax file with the master, and removed the conflict, and thus, it seems lots of changes. But, it has actually fewer changes comparing to master, about 6 to 7 lines.", "@tatianashp if possible please have a look in this PR. Only few line changes in this PR.", "Looks good. Thanks for fixing the typos.", "@ymodak most of the relevant checks are successful. The ones failed here, are not related to this PR. If possible, please have a look.", "code has been merged to master."]}, {"number": 23167, "title": "MKL DNN: cleaning up MKL ML code in LRN kernel", "body": "Cleaned up Intel MKL ML related code. The intention is to stop supporting MKL ML (closed source library) code and have the MKL DNN code (Open sourced library) to be the default code path.", "comments": ["If possible, can you please review this PR. ", "If possible, can you please review this PR", "sorry for the delay. I have applied clang format check, and found some other format issues. Fixed all the issues."]}, {"number": 23166, "title": "\"Invalid loop structure. Mismatched parent frames\"", "body": "Computing the gradient through a batch normalization layer as implemented in keras with a batch size of None while in a tf.while loop can cause the following error:\r\n\r\n\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid loop structure: Mismatched parent frames for \"while/while_context\": \"while/while_context\" vs \"\". This is an internal bug, please file a bug report with instructions on how to reproduce the error\"\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): Reproducible using the latest release [v1.12.0-rc1-0-g7b08198113 1.12.0-rc1] through back to at least 1.10.0.\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: Reproducible without CUDA.\r\n- GPU model and memory: Reproducible without any GPUs.\r\n\r\nCurrent Behavior: running the below script throws a really bad error.\r\n\r\nExpected Behavior: it crashes, but not with this error.\r\n\r\n**Code to reproduce the issue**\r\n\r\nThis is the minimal example that I can get to cause a crash. It isn't \"correct\" code in that it shouldn't work, but it shouldn't crash because of mismatched parent frames. Code that I believe is actually correct also causes the crash, but is much longer.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n### MUST be keras, not from tensorflow import keras\r\nimport keras\r\n\r\nif __name__ == \"__main__\":\r\n  sess = keras.backend.get_session()\r\n\r\n  ### I can't reproduce this with tf.layers.batch_normalization\r\n  model = keras.models.Sequential([keras.layers.BatchNormalization(input_shape=(1,))])\r\n  ### This next line MUST have the None, otherwise it doesn't crash\r\n  x = tf.placeholder(tf.float32, (None, 1))\r\n\r\n  eta = tf.zeros(tf.shape(x))\r\n  def cond(i, _):\r\n    return tf.less(i, 10)\r\n  def body(i, e):\r\n    preds = model(x+e)\r\n    return i + 1, tf.gradients(preds, x)[0]\r\n\r\n  _, eta = tf.while_loop(cond, body, [tf.zeros([]), eta])\r\n\r\n  sess.run(eta, {x: np.zeros((128,1))})\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\n2018-10-22 17:21:30.132455: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InternalError: Invalid loop structure: Mismatched parent frames for \"while/while_context\": \"while/while_context\" vs \"\". The node giving this error: {{node while/gradients/while/sequential_1/batch_normalization_1/cond/batchnorm/mul_1_grad/Shape/Enter}}This is an internal bug, please file a bug report with instructions on how to reproduce the error.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"bug.py\", line 26, in <module>\r\n    sess.run(eta, {x: np.zeros((128,1))})\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/home/ncarlini/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Invalid loop structure: Mismatched parent frames for \"while/while_context\": \"while/while_context\" vs \"\". The node giving this error: node while/gradients/while/sequential_1/batch_normalization_1/cond/batchnorm/mul_1_grad/Shape/Enter (defined at bug.py:22) This is an internal bug, please file a bug report with instructions on how to reproduce the error.\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce\nMobile device", "I removed the N/A cases because they were ... not applicable.\r\n\r\nExact command to reproduce\r\n\r\n`python3 bug.py`", "@carlini If you change the input shape in the model like so: \r\n\r\n`model = keras.models.Sequential([keras.layers.BatchNormalization(input_shape=(None,))])`\r\n \r\nThen there is no mismatched parent frames crash.\r\n\r\n\r\n", "In my original code that won't work -- it takes inputs as images of shape NxNx3.", "Maybe to provide additional context on this if it's helpful. I encountered the same bug as the issue that @npapernot referenced. The library there is several thousand lines, so I reduced the reproduction to just this one short script that I expect to return a simple TF python-land error (saying that I have a type mismatch), but instead raises this error from C++-land.\r\n\r\nIf it would be helpful, I can try to create a reproduction script that's not supposed to crash at all, but it will be somewhat longer than this one.", "Is there something I can do to help diagnose the bug to make it easier to fix? I (and others, it seems) have been running into this reasonably often recently.", "[I don't know why it says I unassigned @wt-huang -- I didn't intend to do that if I did somehow]", "I have the same issue when experimenting around with nested while-loops and imported graphs (trying to connect frozen graphs). Esp. I use an imported graph containing a while-loop inside a while body:\r\n\r\nCompletely standalone example:\r\nin short (pseudocode):\r\n```\r\nwith innerGraph:\r\n    inner_results = tf.while(...)\r\n\r\nwith outerGraph:\r\n    def outer_body():\r\n        tf.import_graph_def(innerGraph.as_graph_def(), ...)\r\n        ...\r\n   def outer_condition(): ...\r\n   outer_results = tf.while( outer_condition, outer_body, ...)\r\n\r\n   with sess:\r\n        sess.run(outer_results)\r\n```\r\n\r\nand in python:\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\nmyInnerGraph = tf.Graph()\r\nwith myInnerGraph.as_default():\r\n\r\n    limit_inner = tf.placeholder(dtype=tf.float32, name=\"inner_limit\")\r\n    def body_inner(counter_inner, my_sum_inner):\r\n        return (counter_inner + 1, my_sum_inner + counter_inner)\r\n    \r\n    def cond_inner(counter_inner, my_sum_inner):\r\n        return counter_inner <= limit_inner\r\n\r\n    counter_inner = tf.constant(0, dtype=tf.float32, name=\"inner_initialCounter\")\r\n    my_sum_inner = tf.constant(0, dtype=tf.float32, name=\"inner_initialSum\")\r\n    \r\n    [_, result_inner] = tf.while_loop( \r\n        cond_inner, \r\n        body_inner, \r\n        [counter_inner, my_sum_inner],\r\n        back_prop=False, parallel_iterations=1)\r\n    result_inner = tf.identity(result_inner, name=\"inner_result\")\r\n    \r\n\r\nouterGraph = tf.Graph()\r\nwith outerGraph.as_default():\r\n\r\n    limit = tf.placeholder(dtype=tf.float32, name=\"limit\")\r\n    \r\n    tempVar = tf.Variable(0.0, dtype = tf.float32)\r\n    tempVar.assign(0.0, name='assigner')\r\n    def body(counter, my_sum):\r\n        \r\n        [inner_sum_result] = tf.import_graph_def(myInnerGraph.as_graph_def(),\r\n                            input_map={\"inner_limit:0\" : counter},\r\n                            return_elements=['inner_result:0'],\r\n                            name=\"importedGraph\",\r\n                            producer_op_list=None\r\n                            )\r\n        assigned = tempVar.assign(inner_sum_result)\r\n        return (counter + 1, my_sum + assigned)\r\n\r\n    def cond(counter, my_sum):\r\n        return counter <= limit\r\n    \r\n    my_sum = tf.constant(0, dtype=tf.float32, name=\"initialSum\")\r\n    counter = tf.constant(0, dtype=tf.float32, name=\"initialCounter\")\r\n    [counter_result, my_sum_result] = tf.while_loop( \r\n            cond, \r\n            body, \r\n            [counter, my_sum],\r\n            back_prop=False, parallel_iterations=1)\r\n\r\n    my_sum_result = tf.identity(my_sum_result, name = \"sum_result\")\r\n\r\n    #writeBlub = tf.summary.FileWriter('/tmp/', outerGraph); # for tensorBoard\r\n    #tf.train.write_graph(outerGraph.as_graph_def(), '/tmp/', 'example.pbtxt', as_text=True) # for human readable\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(my_assigner)\r\n        sum_value = sess.run(my_sum_result,\r\n                              feed_dict={limit : 5})\r\n\r\n```\r\nThis throws the mentioned exception. In contrast: Defining the inner loop directly inside the outer_body works fine and produces the expected result (35.0 = sum_{i=0..5}(  i * (i+1) / 2 )\r\n\r\nThe example code generates a \"while/importedGraph/while\" namespace. (uncomment and see the exported  `/tmp/exampleGraph.pbtxt`) But while the name of those inner nodes is correct, their `frame_name` attribute (if set - seems to be something `while`-related) is still set to `while/while_context` where `while/importedGraph/while/while_context` was expected. \r\n\r\nAdjusting this frame_name and reimporting the graphdef fixes the problem. But that's only a dirty workaround and probably only works well with frozen graphs (which contains only a few variables).\r\n\r\nhope that helps\r\n", "here is even a short script which -- when inserted in the example above right before the Session -- replaces the bogus-`frame_name` on the fly:\r\n\r\n```python\r\ndef fix_frame_name(op):\r\n    attr_list = list(op.attr.keys())\r\n    if 'frame_name' in attr_list:\r\n        frame_name = op.attr['frame_name']\r\n        if (str(frame_name.s) == \"b'while/while_context'\" and op.name.count(\"while\") > 1 ):\r\n            idx = op.name.rfind(\"while\")\r\n            prefix = op.name[:idx]\r\n            frame_name.s = bytes(prefix + \"while/while_context\", 'utf-8')\r\n            print(op.name, frame_name.s) \r\n    \r\nouterGraphDef = outerGraph.as_graph_def()\r\nfor op in outerGraphDef.node:\r\n    fix_frame_name(op)\r\n    \r\nwith tf.Graph().as_default():\r\n\r\n    [my_sum_result, limit, my_assigner] = tf.import_graph_def(outerGraphDef,\r\n                                input_map=None,\r\n                                return_elements=['sum_result:0', 'limit:0', 'assigner:0'],\r\n                                name=\"\",\r\n                                producer_op_list=None\r\n                                )    \r\n```\r\nBut **Warning**: it\r\n* completely exports and reimports the whole graph. \r\n* probably does not work well with variables/trained model data. \r\n* has a somewhat handmade bug-recognition\r\n* is only a workaround.", "I encountered the same problem when using Dropout layers rather than BatchNorm. I was able to solve the problem by `K.set_learning_phase(0)`. However, this doesn't work with BatchNorm. ", "@azaks2 is there something we can do to help this move along?", "@azaks2  is there any workaround we can use?  blocking here for days", "Could you try setting the environment flag `TF_ENABLE_CONTROL_FLOW_V2=\"1\"` and see if the issue remains?", "I still get the same error when setting that environment variable.", "Did this issue solved now? I'm suffering from the same error with dropout and batch normalization.", "Last I checked it's still an issue with the same crash.", "Can we get some attention on this bug? It is consistently a problem with our usecase on tensorflow/cleverhans and has been present for a year and a half.", "To the best of our knowledge this does not reproduce on any recent TF release. And the code patterns that give it rise are not idiomatic TF2. Closing as stale. Please open again if you have a repro on a recent TF release.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23166\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23166\">No</a>\n", "It is somewhat amusing the ultimate resolution to a bug with a crash that literally says \"This is an internal bug, please file a bug report with instructions on how to reproduce the error\" is to wait 2.5 years without fixing the issue, and then close as \"not idiomatic\".", "The irony is not lost on us either, believe me.\r\nBut under limited time and resources, we must prioritize. Is this still crashing with more recent version of TF? IS there a particular functionality that you are unable to implement because of this? If either is true (esp. if both) we'll try to prioritize it."]}, {"number": 23165, "title": "TensorRT engine binding error", "body": "*System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Jetson TX2, Linux4Tegra Xenial 16.04\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.8.0\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source): gcc5\r\n- CUDA/cuDNN version: 9.0/7.1.5\r\n- GPU model and memory: Jetson tx2 8GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**:\r\n\r\nI have frozen a graph that contains the following operations:\r\n\r\n* tf.layers.conv2d(*args, **kwargs)\r\n* tf.layers.batch_normalization(net, **batch_norm)\r\n\r\nI will try to provide a minimal graph that have this problem.\r\n**Describe the expected behavior**:\r\nI create a trt_graph by using the function trt.create_inference_graph and it creates a graph successfully  but whenever I try to make an inference I encounter:\r\n\r\n```\r\n2018-10-22 15:29:17.537843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with\u2502\r\n 363 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)                                            \u2502\r\n2018-10-22 15:29:20.426303: F tensorflow/contrib/tensorrt/shape_fn/trt_shfn.cc:76] TensorRT engine cannot find binding: ModelBase/Conv2dBatchNorm/Relu     \r\nAborted (core dumped)\r\n```\r\nAny guideline on how to provide a better log issue?\r\n\r\nThanks\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce\nMobile device", "In order to expedite the trouble-shooting process, please provide a minimum example to reproduce the issue reported here so that we can quickly identify the source. Thanks!\r\n", "Hi @ymodak I've attached a small minimal module that reproduces the problem in the Jetson TX2, let me know if I can be of help.\r\n\r\nThere are two python modules one that creates the tensorrt graph and serializes it. the other try to run inference on an image. .\r\n\r\n[tensorrt_problem.tar.gz](https://github.com/tensorflow/tensorflow/files/2516567/tensorrt_problem.tar.gz)\r\n", "@davidnet any chance of using a more recent version of TF such as 1.10 or 1.11?", "We have encounter other issues with performance on jetson tx2 while using (on house compiling) tensorflow 1.10 or 1.11, do you provide wheels for python2.7 for the jetson tx2.\r\n\r\n", "Any updates?", "Hi @Davidnet,\r\nDid you check\r\nhttps://docs.nvidia.com/deeplearning/dgx/install-tf-jetsontx2/index.html ?", "We are working on producing the packages.", "Nagging Assignee @samikama: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I am closing this since the update will come with the next pip package for TX2."]}, {"number": 23164, "title": "Error exporting to TFlite", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.10.1\r\n- Python version: \r\n- Bazel version (if compiling from source):0.16.1\r\n- GCC/Compiler version (if compiling from source):.3.0\r\n- CUDA/cuDNN version: 9.1/7.1.2\r\n- GPU model and memory: AWS EC2 g2.2 K520\r\n\r\n**Describe the current behavior**\r\nI want to reuse one of the classification checkpoints in mobilenet v2 as feature extractor in the object detection pipeline.\r\n\r\nI started with a classification checkpoint mobilenet_v2_1.0_224 for object detection retraining.\r\nI made modifications to ssd_mobilenet_v2_coco pipeline.config. Specifically changed `fine_tune_checkpoint_type` from `detection` to `classification` \r\nI uploaded the modified [pipeline.config](https://github.com/tensorflow/tensorflow/files/2502108/pipeline.config.txt) file.\r\n\r\nI am able to retrain and I see the inference images in Tensorboard during the training process. The loss values converge.\r\n\r\nThe problem is when exporting to TFLite using `object_detection/export_tflite_ssd_graph.py` script.\r\n\r\nCommand to export to TFlite:\r\n`python object_detection/export_tflite_ssd_graph.py \r\n                  --pipeline_config_path=$CONFIG_FILE \r\n--trained_checkpoint_prefix=$CHECKPOINT_PATH \r\n--output_directory=$OUTPUT_DIR \r\n--add_postprocessing_op=true`\r\n\r\nError:\r\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nAssign requires shapes of both tensors to match. lhs shape= [3,3,256,24] rhs shape= [3,3,1280,24]\r\n     [[Node: save/Assign_15 = Assign[T=DT_FLOAT, _class=[\"loc:@BoxPredictor_1/BoxEncodingPredictor/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](BoxPredictor_1/BoxEncodingPredictor/weights, save/RestoreV2:15)]]\r\n\r\n**Describe the expected behavior**\r\nThe retraining was successful, so I should get a tflite file successfully after exporting.\r\n\r\n**Code to reproduce the issue**\r\nN/A\r\n\r\n**Other info / logs**\r\nI am able to start with a detection checkpoint like ssd_mobilenet_v2_coco, retrrain it, export to TFLite and run inferece on Android.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "@tensorflowbutler  @harshini-gadige Updated the original issue comment.", "It looks like there is mismatch between model training configuration and model loading configuration.\r\nPlease refer [this](https://www.tensorflow.org/api_guides/python/meta_graph) and try using, Import a graph with preset devices as mentioned in the manual.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23163, "title": "ModuleNotFoundError: No module named 'tensorflow_estimator', and other import errors on TFE side", "body": "Hello,\r\n\r\nI think there's a bug in the master branch of TF, where it's trying to import a module `tensorflow_estimator` which doesn't seem to exist? I can load TF as-is all good, but when I try to load TFP, I get this error (posted below my System specs):\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution: Debian Stretch\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): Master branch\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source):0.18.0\r\n- GCC/Compiler version (if compiling from source): 8.2.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n- Mobile device: No\r\n- Exact command to reproduce:\r\n\r\n```bash \r\necho \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list && \\\r\n    curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add - && \\\r\n    apt-get update && apt-get install -y bazel  && rm -rf /var/lib/apt/lists/* && \\\r\n    ldconfig && \\\r\n    pip uninstall -y tensorflow-tensorboard tb-nightly tf-nightly tensorflow && \\\r\n    cd /opt && \\\r\n    git clone https://github.com/tensorflow/tensorflow.git && \\\r\n    cd /opt/tensorflow && \\\r\n    # sed -i 's/2018\\.0\\.3\\.20180406/2019\\.0\\.20180710/g' tensorflow/contrib/cmake/external/mkl.cmake && \\\r\n    /bin/bash ./configure \\\r\n    && \\\r\n    bazel build \\\r\n    --config=mkl --config=opt --config=verbs \\\r\n    --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n    --copt=-msse4.2 --copt=-msse4.1 --copt=-mavx --copt=-msse2 --copt=-msse3  \\\r\n    --copt=-O3 --copt=-mfpmath=both \\\r\n    --copt=\"-DMKL_LP64\" \\\r\n    --copt=\"-fPIC\" \\\r\n    --linkopt=\"-lmkl_gf_lp64\" \\\r\n    --linkopt=\"-lmkl_gnu_thread\" \\\r\n    --linkopt=\"-dl\" \\\r\n    --linkopt=\"-lpthread\" \\\r\n    --linkopt=\"-lmkl_core\" \\\r\n    --linkopt=\"-lm\" \\\r\n    --linkopt=\"-lmkl_rt\" \\\r\n    --linkopt=\"-lmkldnn\" \\\r\n    tensorflow/tools/pip_package:build_pip_package && \\\r\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\r\n    pip install --no-deps /tmp/pip/tensorflow-*.whl && \\\r\n    cd /opt && rm -rf /opt/tensorflow /tmp/* \r\n\r\ncd /opt && \\\r\n    pip uninstall -y tfp-nightly && \\\r\n    git clone https://github.com/tensorflow/probability.git && \\\r\n    cd /opt/probability && \\\r\n    echo \"\" >> /opt/probability/tensorflow_probability/python/sts/internal/__init__.py && \\\r\n    bazel build \\\r\n    --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n    --copt=-mavx --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 \\\r\n    --copt=-O3 --copt=-mfpmath=both \\\r\n    --copt=\"-DMKL_LP64\" \\\r\n    --copt=\"-fPIC\" \\\r\n    --linkopt=\"-lmkl_gf_lp64\" \\\r\n    --linkopt=\"-lmkl_gnu_thread\" \\\r\n    --linkopt=\"-dl\" \\\r\n    --linkopt=\"-lpthread\" \\\r\n    --linkopt=\"-lmkl_core\" \\\r\n    --linkopt=\"-lm\" \\\r\n    --linkopt=\"-lmkl_rt\" \\\r\n    --linkopt=\"-lmkldnn\" \\\r\n    :pip_pkg && \\\r\n    PKGDIR=$(mktemp -d) && \\\r\n    ./bazel-bin/pip_pkg $PKGDIR && \\\r\n    pip install --no-deps $PKGDIR/*.whl && \\\r\n    cd /opt && rm -rf /opt/probability /tmp/* && \\\r\n    python -c \"import tensorflow_probability\"\r\n```\r\n\r\n## Error trace:\r\n\r\n```python\r\n\r\nIn [1]: import tensorflow_probability as tfp\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-1-41494c8c96ff> in <module>\r\n----> 1 import tensorflow_probability as tfp\r\n\r\n/opt/probability/tensorflow_probability/__init__.py in <module>\r\n     19\r\n     20 # from tensorflow_probability.google import staging  # DisableOnExport\r\n---> 21 from tensorflow_probability.python import *  # pylint: disable=wildcard-import\r\n     22 from tensorflow_probability.python.version import __version__\r\n\r\n/opt/probability/tensorflow_probability/python/__init__.py in <module>\r\n     19 from __future__ import print_function\r\n     20\r\n---> 21 from tensorflow_probability.python import bijectors\r\n     22 from tensorflow_probability.python import distributions\r\n     23 from tensorflow_probability.python import edward2\r\n\r\n/opt/probability/tensorflow_probability/python/bijectors/__init__.py in <module>\r\n     21 # pylint: disable=unused-import,wildcard-import,line-too-long,g-importing-member\r\n     22\r\n---> 23 from tensorflow_probability.python.bijectors.absolute_value import AbsoluteValue\r\n     24 from tensorflow_probability.python.bijectors.affine import Affine\r\n     25 from tensorflow_probability.python.bijectors.affine_linear_operator import AffineLinearOperator\r\n\r\n/opt/probability/tensorflow_probability/python/bijectors/absolute_value.py in <module>\r\n     20\r\n     21 import tensorflow as tf\r\n---> 22 from tensorflow_probability.python.bijectors import bijector\r\n     23 from tensorflow.python.ops import control_flow_ops\r\n     24\r\n\r\n/opt/probability/tensorflow_probability/python/bijectors/bijector.py in <module>\r\n     29 import tensorflow as tf\r\n     30\r\n---> 31 from tensorflow_probability.python.internal import distribution_util\r\n     32 from tensorflow.python.framework import tensor_util\r\n     33\r\n\r\n/opt/probability/tensorflow_probability/python/internal/distribution_util.py in <module>\r\n     24 import tensorflow as tf\r\n     25\r\n---> 26 from tensorflow_probability.python.internal import dtype_util\r\n     27 from tensorflow_probability.python.internal import reparameterization\r\n     28 from tensorflow.python.framework import smart_cond\r\n\r\n/opt/probability/tensorflow_probability/python/internal/dtype_util.py in <module>\r\n     22 import tensorflow as tf\r\n     23\r\n---> 24 from tensorflow.contrib import framework as contrib_framework\r\n     25\r\n     26\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/__init__.py in <module>\r\n     38 from tensorflow.contrib import data\r\n     39 from tensorflow.contrib import deprecated\r\n---> 40 from tensorflow.contrib import distribute\r\n     41 from tensorflow.contrib import distributions\r\n     42 from tensorflow.contrib import estimator\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/distribute/__init__.py in <module>\r\n     32 from tensorflow.contrib.distribute.python.parameter_server_strategy import ParameterServerStrategy\r\n     33 from tensorflow.contrib.distribute.python.step_fn import *\r\n---> 34 from tensorflow.contrib.distribute.python.tpu_strategy import TPUStrategy\r\n     35 from tensorflow.python.distribute.distribute_config import DistributeConfig\r\n     36 from tensorflow.python.distribute.distribute_coordinator import run_standard_tensorflow_server\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/tpu_strategy.py in <module>\r\n     25 from tensorflow.contrib.distribute.python import one_device_strategy\r\n     26 from tensorflow.contrib.distribute.python import values\r\n---> 27 from tensorflow.contrib.tpu.python.ops import tpu_ops\r\n     28 from tensorflow.contrib.tpu.python.tpu import tpu\r\n     29 from tensorflow.contrib.tpu.python.tpu import tpu_system_metadata as tpu_system_metadata_lib\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/tpu/__init__.py in <module>\r\n     71 from tensorflow.contrib.tpu.python.tpu.bfloat16 import *\r\n     72 from tensorflow.contrib.tpu.python.tpu.device_assignment import *\r\n---> 73 from tensorflow.contrib.tpu.python.tpu.keras_support import tpu_model as keras_to_tpu_model\r\n     74 from tensorflow.contrib.tpu.python.tpu.keras_support import TPUDistributionStrategy\r\n     75 from tensorflow.contrib.tpu.python.tpu.topology import *\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in <module>\r\n     60 from tensorflow.contrib.tpu.python.ops import tpu_ops\r\n     61 from tensorflow.contrib.tpu.python.tpu import keras_tpu_variables\r\n---> 62 from tensorflow.contrib.tpu.python.tpu import tpu\r\n     63 from tensorflow.contrib.tpu.python.tpu import tpu_function\r\n     64 from tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py in <module>\r\n     22 from six.moves import xrange  # pylint: disable=redefined-builtin\r\n     23\r\n---> 24 from tensorflow.contrib.compiler import xla\r\n     25 from tensorflow.contrib.framework.python.framework import experimental\r\n     26 from tensorflow.contrib.tpu.python.ops import tpu_ops\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/compiler/xla.py in <module>\r\n     25 from tensorflow.compiler.jit.ops import xla_ops\r\n     26 from tensorflow.core.framework import attr_value_pb2\r\n---> 27 from tensorflow.python.estimator import model_fn as model_fn_lib\r\n     28 from tensorflow.python.framework import ops\r\n     29 from tensorflow.python.ops import array_ops\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/estimator/__init__.py in <module>\r\n     24 from __future__ import print_function\r\n     25\r\n---> 26 from tensorflow_estimator.python import estimator\r\n     27\r\n     28 # Include attrs that start with single underscore.\r\n\r\nModuleNotFoundError: No module named 'tensorflow_estimator'\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated.", "I can avert this by manually building `tensorflow_estimator` with Bazel. I thought this would've been including with core TF", "Another error that probably comes from the TFE side:\r\nhttps://github.com/tensorflow/estimator/issues/5", "> I can avert this by manually building `tensorflow_estimator` with Bazel. I thought this would've been including with core TF\r\n\r\n@sadatnfs How could you achieve the above?", "I just built TFE like I did with base TF (clone, configure and Bazel build) ", "Just pip install worked for me:\r\n`pip install -U tensorflow_estimator`", "Just reinstall `tensorflow-estimator` with the command below:\r\n\r\n`pip install 'tensorflow-estimator<1.15.0rc0,>=1.14.0rc0' --force-reinstall`\r\n\r\n---\r\nThis is because `tensorflow-gpu 1.14.0` requires `tensorflow-estimator<1.15.0rc0,>=1.14.0rc0`.\r\n\r\nThe stable version (which is installed by default)  `tensorflow-estimator 1.13.0` is incompatible with TF 1.14.0.\r\n"]}, {"number": 23162, "title": "Can not run traing comand Object Detectioon API", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n\r\n- TensorFlow installed from (source or binary):conda\r\n- TensorFlow version (use command below):1.9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- Python version:3.6.6\r\n Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: CUDA 9/ cuDNN 7.\r\n- GPU model and memory: Tesla K80 , 11GB\r\n\r\n**Describe the current behavior**\r\nI trying to train a model(Faster R-CNN with Inception v2) but there is an error massage \"TypeError: merge_external_params_with_configs() got an unexpected keyword argument 'train_steps'\" while tracing the issue i have print the train_steps and is't equal to 200,000.\r\n**The Output**\r\n```\r\nTrain steps\r\n200000\r\n<class 'int'>\r\n```\r\n\r\n**My command is :**\r\n```\r\nPIPELINE_CONFIG_PATH=/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/pipeline_od.config\r\nMODEL_DIR=/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/models/model\r\nNUM_TRAIN_STEPS=200000\r\nSAMPLE_1_OF_N_EVAL_EXAMPLES=1\r\npython object_detection/model_main.py \\\r\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\r\n    --model_dir=${MODEL_DIR} \\\r\n    --num_train_steps=${NUM_TRAIN_STEPS} \\\r\n    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\r\n    --alsologtostderr\r\n\r\n```\r\n\r\n**The error message:**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"object_detection/model_main.py\", line 101, in <module>\r\n    tf.app.run()\r\n  File \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"object_detection/model_main.py\", line 62, in main\r\n    eval_steps=FLAGS.num_eval_steps)\r\n  File \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/model_lib.py\", line 509, in create_estimator_and_inputs\r\n    retain_original_images_in_eval=False if use_tpu else True)\r\nTypeError: merge_external_params_with_configs() got an unexpected keyword argument 'train_steps'\r\n```\r\n\r\n**My configuration File:**\r\n ```\r\nFaster R-CNN with Inception v2, configuration for MSCOCO Dataset.\r\n Users should configure the fine_tune_checkpoint field in the train config as\r\n well as the label_map_path and input_path fields in the train_input_reader and\r\n eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\nshould be configured.\r\n\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    num_classes: 9\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 600\r\n        max_dimension: 1024\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'faster_rcnn_inception_v2'\r\n      first_stage_features_stride: 16\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 14\r\n    maxpool_kernel_size: 2\r\n    maxpool_stride: 2\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 300\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 32\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        manual_step_learning_rate {\r\n          initial_learning_rate: 0.0002\r\n          schedule {\r\n            step: 900000\r\n            learning_rate: .00002\r\n          }\r\n          schedule {\r\n            step: 1200000\r\n            learning_rate: .000002\r\n          }\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  gradient_clipping_by_norm: 10.0\r\n  fine_tune_checkpoint: \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n   Note: The below line limits the training process to 200K steps, which we\r\n   empirically found to be sufficient enough to train the COCO dataset. This\r\n   effectively bypasses the learning rate schedule (the learning rate will\r\n   never decay). Remove the below line to train indefinitely.\r\n  num_steps: 200000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/data/train.record\"\r\n  }\r\n  label_map_path: \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/data/mscoco_label_map_dataturk.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 83\r\n   Note: The below line limits the evaluation process to 10 evaluations.\r\n   Remove the below line to evaluate indefinitely.\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/data/eval.record\"\r\n  }\r\n  label_map_path: \"/home/dabastany_gmail_com/miniconda3/envs/od/lib/python3.6/site-packages/tensorflow/models/research/object_detection/train/data/mscoco_label_map_dataturk.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n\r\n\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce\nMobile device", "Nagging Assignee @ymodak: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issue is better asked on [TensorFlow Models](https://github.com/tensorflow/models/issues/new) repo. Closing this issue since it's not related to TensorFlow Core. Please post it on TensorFlow Models repo. Thanks!"]}, {"number": 23161, "title": "Fix build on macOS", "body": "<iostream> is needed before <Python.h> to avoid issues with toupper.\r\nAlso, switch to using unsigned long long for trt_allocator_test.cc.", "comments": ["Closing this PR, refer to #22961 "]}, {"number": 23160, "title": "tf.layers.dense activity_regularizer= tf.contrib.layers.l2_regularizer(0.0) causes error.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 1.10\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0 / 7\r\n- GPU model and memory: Tesla k80\r\n\r\n**Describe the current behavior**\r\nSetting the activity regularizer of a tf.layers.dense layer to tf.contrib.layers.l2_regularizer(0.0) gives the error:\r\nValueError: None values not supported.\r\n\r\n**Describe the expected behavior**\r\nNo error should be thrown - the regularizer should be disabled.\r\n**Code to reproduce the issue**\r\nx = tf.placeholder(tf.float32, (64,100))\r\nlayer = tf.layers.dense(\r\n    x,\r\n    100,\r\n    activation=None,\r\n    kernel_initializer=tf.contrib.layers.xavier_initializer(),\r\n    activity_regularizer=tf.contrib.layers.l2_regularizer(scale=0.0)\r\n)\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTrace:\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 7, in <module>\r\n  File \"/tensorflow/python/layers/core.py\", line 189, in dense\r\n    return layer.apply(inputs)\r\n  File \"/tensorflow/python/keras/engine/base_layer.py\", line 805, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/tensorflow/python/layers/base.py\", line 362, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/tensorflow/python/keras/engine/base_layer.py\", line 758, in __call__\r\n    self._handle_activity_regularization(inputs, outputs)\r\n  File \"/tensorflow/python/keras/engine/base_layer.py\", line 640, in _handle_activity_regularization\r\n    self.add_loss(activity_regularization, inputs=inputs)\r\n  File \"/tensorflow/python/layers/base.py\", line 134, in add_loss\r\n    super(Layer, self).add_loss(losses, inputs=inputs)\r\n  File \"/tensorflow/python/keras/engine/base_layer.py\", line 411, in add_loss\r\n    if not tensor_util.is_tensor(loss) else loss for loss in losses]\r\n  File \"/tensorflow/python/keras/engine/base_layer.py\", line 411, in <listcomp>\r\n    if not tensor_util.is_tensor(loss) else loss for loss in losses]\r\n  File \"/tensorflow/python/framework/ops.py\", line 998, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/tensorflow/python/framework/ops.py\", line 1094, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/tensorflow/python/framework/constant_op.py\", line 217, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/tensorflow/python/framework/constant_op.py\", line 196, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/tensorflow/python/framework/tensor_util.py\", line 424, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\n", "comments": ["@corynezin I can reproduce the issue with 1.10 but not with tf-nightly. Can you check the latest version of tf-nightly and see if the issue has been resolved?", "@yongtang is correct, this issue is not in the latest TensorFlow version either.\r\n\r\n\r\n", "Closing as this is resolved, free to reopen if problem persists\r\n\r\n\r\n", "I have this issue in 1.13.1\r\n\r\nCode to reproduce:\r\n```\r\n#!/usr/bin/env python\r\nimport numpy as np\r\nimport tensorflow\r\nfrom tensorflow import keras\r\n\r\ntensorflow.enable_eager_execution()\r\n\r\ndense = keras.layers.Dense(8, activity_regularizer=keras.regularizers.l1(0.0))\r\nout = dense(np.random.randn(1,16))\r\nprint(out)\r\n```\r\n\r\nThe error I get:\r\n```\r\nTraceback (most recent call last):\r\n  File \"./test.py\", line 9, in <module>\r\n    out = dense(np.random.randn(1,16))\r\n  File \"/home/pmitrano/.local/opt/anaconda3/envs/ros1py3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 593, in __call__\r\n    self._handle_activity_regularization(inputs, outputs)\r\n  File \"/home/pmitrano/.local/opt/anaconda3/envs/ros1py3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1345, in _handle_activity_regularization\r\n    array_ops.shape(output)[0], activity_loss.dtype)\r\nAttributeError: 'float' object has no attribute 'dtype'\r\n```"]}, {"number": 23159, "title": "Infinite run or optimizer fail", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.9.0\r\n- Python version: 3.6.0\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:9.1\r\n- GPU model and memory: P100 16GB\r\n\r\n**Describe the current behavior**\r\nsess.run() executes infinitely and will never return\r\nIn the alternative version, sess.run() produces expected results but error is produced by the optimizer (see log).\r\n\r\nThe bug only occurs when \r\n1. On GPU. The code executes properly on CPU.\r\n2. The condition of tf.cond holds False, i.e. when tf.gradients is not to be executed. Otherwise correct gradients could be calculated.\r\n3. There're loop structures, e.g. RNN.  \r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\n> X = tf.placeholder(shape=[None, None, 10], dtype=tf.float32)\r\n> Y, _ = tf.nn.bidirectional_dynamic_rnn(LSTMCell(20), LSTMCell(20), X, dtype=tf.float32)\r\n> \r\n> loss = tf.reduce_mean(Y)\r\n> vars = tf.trainable_variables()\r\n> grads = tf.cond(tf.shape(X)[0] < 3, lambda :tf.gradients(loss, vars), lambda :[np.nan] * len(vars))\r\n> \r\n> sess = tf.Session()\r\n> sess.run(tf.global_variables_initializer())\r\n> print(sess.run(grads, feed_dict={X: np.random.random([30, 10, 10])}))\r\n\r\n\r\nAlternative version:\r\n\r\n> X = tf.constant(np.random.random([30, 10, 10]), dtype=tf.float32)\r\n> Y, _ = tf.nn.bidirectional_dynamic_rnn(LSTMCell(20), LSTMCell(20), X, dtype=tf.float32)\r\n> \r\n> loss = tf.reduce_mean(Y)\r\n> vars = tf.trainable_variables()\r\n> grads = tf.cond(tf.shape(X)[0] < 3, lambda :tf.gradients(loss, vars), lambda :[np.nan] * len(vars))\r\n> \r\n> sess = tf.Session()\r\n> sess.run(tf.global_variables_initializer())\r\n> print(sess.run(grads))\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n> 2018-10-22 17:32:36.399614: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:581] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n> 2018-10-22 17:32:36.401378: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:581] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.\r\n> ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "@dy-octa I run the above alternate version using latest TensorFlow version and didn't receive any error.\r\nTensorFlow nightly works as well. There was no error produced by the optimizer.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 23158, "title": "Mysterious infinite run", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.9.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.1.85\r\n- GPU model and memory: P100 16GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Update: I've managed to make a minimal example here: https://github.com/tensorflow/tensorflow/issues/23159**\r\nPlease close this issue.\r\n\r\n\r\n        check_vars = model.trainable_variables()  \r\n\r\n        check_grad = tf.cond(cond,  \r\n\r\n                                  lambda :[g if isinstance(g, tf.Tensor) else 0.0 for g in  \r\n\r\n                                           tf.gradients(model.loss, check_vars)],  \r\n\r\n                                  lambda : [0.0] * len(check_vars))  \r\n\r\n        sess.run(check_grad)  \r\nIn my own model (a Tacotron2 implementation), the last line will fall into infinite run and never return when tf is run on GPU and cond holds False, i.e. it should directly return a tensor of zeros, while the results will be correct when tf is run on CPU, or cond holds True.\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nI didn't manage to reproduce the case on a model simple enough.\r\n**Other info / logs**\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "I've managed to make a minimal example here: #23159\r\nPlease close this issue."]}, {"number": 23157, "title": "Supported input types for tf.nn.quantized_conv2d", "body": "**System information**\r\n- TensorFlow version: 1.11.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/nn/quantized_conv2d\r\n- Have I written custom code: Check [this question](https://stackoverflow.com/questions/52922980/error-when-using-quantized-conv2d-with-tf-qint8-inputs).\r\n- OS Platform and Distribution: macOS Mojave\r\n- TensorFlow installed from: pip binary\r\n- Bazel version: N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n- Exact command to reproduce: N/A\r\n- Mobile device: N/A\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nThe documentation for [tf.nn.quantized_conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/quantized_conv2d) says that `input` and `filter` must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.\r\n\r\nHowever, the only registered type for these arguments is `tf.quint8`. See also [this question](https://stackoverflow.com/questions/52922980/error-when-using-quantized-conv2d-with-tf-qint8-inputs).\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@rvinas It is true that tf.quint8 is the only registered type for input and filter as it covers most cases in conv2d.\r\nWe will certainly look into other types as well.\r\n\r\n\r\n", "Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@wt-huang, if I want to create custom op for `tf.nn.quantized_conv2d` where I register the data types I want, is there a way to do so? What I am thinking is registering my own kernels only like this\r\n\r\n```\r\nREGISTER_KERNEL_BUILDER(\r\n    Name(\"QuantizedConv2D\")\r\n        .Device(DEVICE_CPU)\r\n        .TypeConstraint<quint8>(\"Tinput\")\r\n        .TypeConstraint<quint8>(\"Tfilter\")\r\n        .TypeConstraint<qint32>(\"out_type\"),\r\n    QuantizedConv2DOp< <qint16, qint16, qint32, Im2ColConvFunctor>);\r\n```"]}, {"number": 23155, "title": "Support for Truncated Backpropagation Through Time with tf.data.TFRecordDataset API", "body": "I am aware that there is support on Tensorflow for truncated backpropagation through time with the tf.contrib.training.batch_sequences_with_states method and the state saving RNN. However this requires the conventional method using the queue runners. I am using the new tf.data.TFRecordDataset API for my my work which does not require the developer to explicitly call queue runners. But apparently there is no support for truncated backpropagation through time when I use this API.\r\n\r\nTensorflow Version: 1.11.0  ", "comments": []}, {"number": 23154, "title": "Support for Truncated Backpropagation Through Time with tf.data.TFRecordDataset API", "body": "I am aware that there is support on Tensorflow for truncated backpropagation through time with the tf.contrib.training.batch_sequences_with_states method and the state saving RNN. However this requires the conventional method using the queue runners. I am using the new tf.data.TFRecordDataset API for my my work which does not require the developer to explicitly call queue runners. But apparently there is no support for truncated backpropagation through time when I use this API.\r\n\r\nTensorflow Version: 1.11.0  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "In the meanwhile. It is okay to run session to get the value parsed with `tf.data` and then split it and use `batch_sequences_with_states` for TBPTT later like this:\r\n\r\n```\r\nbatch = iterator.get_next()\r\nnumpy_batch = sess.run(batch)\r\ntrain_with_batch_sequences_with_states(numpy_batch)\r\n```\r\n\r\nOr is there are a better approach? I don't want to rewrite my whole pipeline built with tf.data just for TBPTT.\r\n\r\nThanks in advance.  ", "Adding @mrry to route to the right person within `tf.data`", "Thanks Ryan. Passing this over to @ebrevdo, who added some `tf.data`-based training utilities that could be helpful here.", "We had some approaches that allowed a variant of batch_sequences_with_states this with tf.data, which we [decided to remove recently](https://github.com/tensorflow/tensorflow/commit/1221a9f8ea7583646a0e5d664d6111d9be2e12d8).  No one used them and I wasn't a huge fan of that API.\r\n\r\nIf you have exactly one trainer thread (worker) going, you can store intermediate activations in a tf.Variable: read the final RNN state from the RNN layer, and perform an assign to state Variables.  on the next session.run, read from those variables again as the initial state.  You may need to be careful about reinitializing an all zero state for those batch entries starting a new sequence.  I believe [Keras RNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN) has some magic that does this for you.  See the 'stateful' init kwarg of tf.keras.layers.{RNN,LSTM,GRU}; but I don't think that Keras intelligently resets to a zero state for new sequences the way that batch_sequences_with_states does.", "Thanks for the response @ebrevdo. I have tried doing exactly the thing that you have mentioned. But the process seems to be quite slow. That is why I wanted to know if there is some internally optimised method of doing that.", "@ghost,\r\nSorry for the delayed response. **`RNNs`** now support **`tf.data`**. Please refer [this code in the documentation](https://www.tensorflow.org/text/tutorials/text_generation#create_training_batches) and let us know if this is what you are looking for. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23153, "title": "rasa core", "body": "while running rasa core in ubuntu im getting thiss error\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\nfrom tensorflow.python.keras._impl.keras.backend import abs\r\nImportError: cannot import name abs\r\n\r\ntried  uninstalling and installing the tensorflow and also tensorflow-gpu\r\n\r\n------------------------\r\n\r\nrasa core version : \r\nVersion: 0.11.12\r\n\r\npython version: 2.7.14\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new/choose). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 23152, "title": "[Intel-Mkl] Redundant transpose removal: transpose(to \"NHWC\")+ conv2d(NHWC) + transpose(back to \"NCHW\") -> conv2d.", "body": "This is a pattern found in Keras-based models. When using \"NCHW\" format dataset, Keras will insert 2 extra \"Transpose\" ops before/after every CNN ops, because only \"NHWC\" format is supported in CPU mode. \r\n\r\nThese \"Transpose\" overhead are significant in typical CNN models, we observed it contributes ~35% of total inference time in 3D-UNet. This PR is aimed to remove these overhead completely, by:\r\n1. detect the \"transpose + conv2d + transpose\" pattern;\r\n2. delete those 2 \"transpose\" ops, and make \"conv2d\"'s format \"NCHW\";\r\n3. replace \"conv2d\" with \"_MklConv2D\", which support both \"NCHW\" and \"NHWC\" format.\r\n\r\n", "comments": ["@wt-huang is the CLA ok?", "@wenxizhu have you signed the CLA? Github's been malfunctioning lately so I think our CLA checked ignored this PR.", "@martinwicke Thanks for the reminder!\r\n\r\n@wenxizhu Please make sure CLA is signed so that we can proceed with this PR.", "@martinwicke @wt-huang I'm pretty sure I have my CLA signed. What shall I do now?", "@wt-huang seems it doesn't pass your \"clang-format\" test? I'm wondering how to run it on m local device. \"//tensorflow/tools/ci_build:gen_ci_clang_format_out\" is not a valid bazel so I could not run it directly. Any suggestions?", "@wt-huang \"no such package 'tensorflow/tools/ci_build': BUILD file not found on package path\"", "@wenxizhu You can use [clang-format](https://clang.llvm.org/docs/ClangFormat.html) given with the [LLVM toolchain](http://releases.llvm.org/download.html) to format the source files to pass the `clang-format` test.", "@penpornk I've applied \"clang-format-3.8\" to fix the problem. Can we move on now?", "@wenxizhu Yes, I've been meaning to review this today but didn't get to. Sorry for the delay! I'll do it tomorrow. ", "@penpornk thanks for your comments! I've replied all your comments and hope I didn't miss any of them. For the greedy matching code, I've already introduced a stack-based algorithm to replace it, I think it won't be a problem now. ", "@penpornk thanks for your comments! Changes have been applied, especially for the `CheckForNodeFusion`. And again, please let me know if I missed any of your comments.", "@penpornk Sorry for the late response! Please see my comments for detailed updates.", "@penpornk Your modifications adopted, and also clang-format-3.8 applied. \r\n\r\nAnd about the test cases, I'm afraid there is no way to add such test cases, because:\r\n1. As you know, \"transpose-removal\" is a very constrained pattern, those 3 test cases won't take effect on this pattern;\r\n2. What we need is actually some \"dummy\" patterns, which have \"multiple input\" and \"multiple output\", and don't exist in our existing \"mlk_layout_pass.cc \" code. Any attempt to add these kind of \"dummy\" patterns through testing code will be destructive to existing \"mkl_layout_pass.cc\" code, at least a bunch of interfaces have to be added and implemented.\r\n\r\nSo can we leave these test cases to be added when some day a real-world pattern is met? That does make more sense I think.", "@wenxizhu \r\n> So can we leave these test cases to be added when some day a real-world pattern is met? That does make more sense I think.\r\n\r\nI agree. Thank you! \r\n", "@penpornk those 2 wired comment lines fixed now.", "@penpornk Thank you!", "Please fix the `clang-format` error. Thank you!", "@penpornk Hmm... already fixed I think. Did I miss any conversation?", "It's the `Experimental clang-format Check` at the bottom of this PR. Can you see the `details` link? If not, I can copy the error message to here.", "@penpornk OK, now I see the log, fixed now. However I'm not sure I use the same clang-format version with yours. Please let me know if there is still problems.", "@wenxizhu I'm seeing a lot of changes from `type* variable` to `type *variable` (which aren't right) in your new commits. \r\n\r\nI think your original format was very close already. It's just that the new merged comment line was longer than 80 characters again. Could you please go back to your original formatter? \r\n\r\nAlso, it would be great if you could eliminate the new orphan comment lines clang-format generates, like\r\n```c++\r\n// Something that is too long to fit in one line and clang-format wraps around\r\n// like this.\r\n// Something in the next line.\r\n```\r\nto\r\n```c++\r\n// Something that is too long to fit in one line and clang-format wraps around\r\n// like this. Something in the next line.\r\n```\r\nwhile also making sure that the new merged line is not too long.", "@penpornk I tried fix it by hand. Let's see if it can pass format-check this time.", "Note: Tagging `ready-to-pull` because the 5 failing tests also failed in the recent commits.", "@wt-huang Could you please help pull this PR? (The Windows Bazel GPU failure is expected.) Thank you!", "@penpornk hi, these failed checks are in-relevant with my code, right?", "@wenxizhu I think so. I think our tests are acting funny right now. It keeps asking me to re-apply the test tag.", "@penpornk OK, thank you. And BTW, do you know when this PR will be merged?", "@wenxizhu Unfortunately, I don't. It depends on @wt-huang now.", "@penpornk OK, that's fine.", "> @penpornk OK, thank you. And BTW, do you know when this PR will be merged?\r\n\r\nHelping to merge this as @wt-huang is OOO. Will keep you posted. Thanks !", "@wenxizhu  Could you please get these changes done ?", "@penpornk @harshini-gadige changes done!", "@penpornk Sure. Changes done, let's see if it can pass the check now."]}, {"number": 23151, "title": "Pull", "body": "", "comments": []}, {"number": 23150, "title": "TPU model doesn't work with tensorflow.python.keras learning rate scheduler.", "body": "When I convert Keras model into TPU model using `tensorflow.contrib.tpu.keras_to_tpu_model` and try to fit it with learning rate scheduler callback, the training crashes with error `ValueError: Optimizer must have a \"lr\" attribute.`. I guess the problem is that the keras and tensorflow optimizers use different learning rate variable name, which makes the keras callback fail. The callback in `tensorflow.python.keras` should be therefore corrected to use the proper variable.\r\n\r\n**System information**\r\n- Google Colab TPU runtime\r\n- TF 1.12.0rc1\r\n\r\n**Code fragment**\r\n```\r\n    strategy = tensorflow.contrib.tpu.TPUDistributionStrategy(\r\n        tensorflow.contrib.cluster_resolver.TPUClusterResolver(tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n    )\r\n    model = tensorflow.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\r\n    model.compile(\r\n        loss=tensorflow.keras.losses.categorical_crossentropy,\r\n        optimizer=tensorflow.train.GradientDescentOptimizer(learning_rate=lr_schedule(0)),\r\n        metrics=['accuracy']\r\n    )\r\n    (...)\r\n   callbacks = [tensorflow.python.keras.callbacks.LearningRateScheduler(lr_schedule_function)]\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\nTraceback (most recent call last)\r\n<ipython-input-12-b6a9470abb3b> in <module>()\r\n    441                         validation_data=(x_test, y_test),\r\n    442                         epochs=epochs, verbose=1, workers=4,\r\n--> 443                         callbacks=callbacks)\r\n    444 \r\n    445 # Score trained model.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   2175         use_multiprocessing=use_multiprocessing,\r\n   2176         shuffle=shuffle,\r\n-> 2177         initial_epoch=initial_epoch)\r\n   2178 \r\n   2179   def evaluate_generator(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n    141       for m in model.stateful_metric_functions:\r\n    142         m.reset_states()\r\n--> 143       callbacks.on_epoch_begin(epoch)\r\n    144       steps_done = 0\r\n    145       batch_index = 0\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_begin(self, epoch, logs)\r\n    198     logs = logs or {}\r\n    199     for callback in self.callbacks:\r\n--> 200       callback.on_epoch_begin(epoch, logs)\r\n    201     self._delta_t_batch = 0.\r\n    202     self._delta_ts_batch_begin = deque([], maxlen=self.queue_length)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_begin(self, epoch, logs)\r\n    768   def on_epoch_begin(self, epoch, logs=None):\r\n    769     if not hasattr(self.model.optimizer, 'lr'):\r\n--> 770       raise ValueError('Optimizer must have a \"lr\" attribute.')\r\n    771     try:  # new API\r\n    772       lr = float(K.get_value(self.model.optimizer.lr))\r\n\r\nValueError: Optimizer must have a \"lr\" attribute.\r\n```", "comments": ["Use a native Keras optimizer.\r\n\r\nTensorFlow optimizers do not place nicely with LearningRateSchedulers/ReduceLROnPlateau.", "@brge17 is correct that keras optimizer should work. Post your code here if you need further help.\r\n\r\n\r\n", "I have tried doing this and it does not work. Specifically, I have tried the following:\r\n\r\n`from keras.optimizers import Adam`\r\n`from tensorflow.keras.optimizers import Adam`\r\n`from tensorflow.python.keras.optimizers import Adam`\r\n\r\nIn the first case, the model will not compile. With the latter two, it compiles but during the fit, I get the message \"ValueError: Operation 'tpu_140522079557168/VarIsInitializedOp' has been marked as not fetchable.\"", "Facing the same issue!!\r\nFound any solution to it yet?", "Any Answer?", "Any attempt to mix keras and tf.keras classes fail on TPU. You probably need to induce TF devs to fix their optimisers rather.."]}]