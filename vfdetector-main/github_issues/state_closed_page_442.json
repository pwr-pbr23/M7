[{"number": 40596, "title": "Add MKL supoprt to auto_mixed_precision.", "body": "This extends the auto mixed precision grappler pass to support converting nodes to bfloat16 on MKL-supported CPUs. This functionality is exposed as the `auto_mixed_precision_mkl` grappler pass.\r\n\r\nSome Python tests are disabled with MKL because they crash. These crashes are likely not due to the grappler pass itself, but instead due to bugs in MKL-DNN or TensorFlow's MKL integration. Intel has confirmed these crashes do not occur when training real models, so we will fix these after this PR is submitted in followup PRs. Since TensorFlow is not built with MKL by default, the auto_mixed_precision_mkl grappler pass cannot be used except in Intel builds and so these issues do not appear in official TensorFlow releases.\r\n\r\nSince TensorFlow is not built with MKL by default, the auto_mixed_precision_mkl grappler pass is not documented.\r\n\r\n/CC @nhasabni @nluehr @benbarsdell\r\n\r\nCo-authored-by: Niranjan Hasabnis <niranjan.hasabnis@intel.com>", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40596) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "@reedwm Maybe you have to post `@googlebot I consent.` too? The bot wants both authors to do this.", "@googlebot I consent.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40596) for more info**.\n\n<!-- cla_yes -->", "Both me and @nhasabni clearly consented, so I'm switching the label to cla:yes. Not sure why @googlebot didn't switch it"]}, {"number": 40595, "title": "tf.signal.rfft(2d/3d) documentation refers `Tcomplex` and `input` as arguments.", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft2d\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/rfft3d\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the `Args` section, there are inputs `input` and `Tcomplex`. `Treal` no longer exist, and `input` should be `input_tensor`.\r\n\r\nRunning code\r\n\r\n~~~python\r\ntf.signal.rfft(1, Tcomplex=tf.complex64)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _rfft() got an unexpected keyword argument 'Tcomplex'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n\r\n\r\n## Related Issue:\r\n#39520", "comments": ["@DNXie Looks like this was resolved in recent TF docs. \r\n\r\nCan you please verify once and close the issue if this was resolved. Thanks!", "@jvishnuvardhan Looks like it has been fixed. Closing the issue. Thanks."]}, {"number": 40593, "title": "Unclear rank/dimension dependency of `weights` in  `sigmoid_cross_entropy` documentation", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/sigmoid_cross_entropy\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nUnclear rank dependency of input `weights`. According to the document, `weights` could have the same rank as `labels`, and must be broadcastable to `labels`, but it is unclear what `labels` is. \r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nYes\r\n\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2", "comments": []}, {"number": 40592, "title": "`tf.nn.swish` documentation refers `name` as an argument", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/swish\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the \"Args\" section, there is an input ` name`, but it is not in the signature, and the function doesn't accept the argument.\r\n\r\nRunning code:\r\n\r\n~~~python\r\ntf.nn.swish(1, name=None)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: swish() got an unexpected keyword argument 'name'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n", "comments": ["I would like to work on this issue", "It looks like all it needs is for someone to add the name argument, and an [ops.name_scope](https://github.com/tensorflow/tensorflow/blob/r2.2/tensorflow/python/framework/ops.py#L6189)", "Moving the issue to closed status as the pr is merged and the change is reflecting."]}, {"number": 40591, "title": "bazel mirror tar gz 404 warning, and build fails", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version: 2.2.0, installed by mediapipe\r\n- Python version: 3.8.3\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 3.3.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nTrying to build a mediapipe target:\r\n```bash\r\nbazel run mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu \r\n```\r\n\r\nI get:\r\n\r\n ```\r\nLoading: \r\nLoading: 0 packages loaded  \r\nWARNING: Download from https://mirror.bazel.build/github.com/tensorflow/tensorflow/archive/7c09d15f9fcc14343343c247ebf5b8e0afe3e4aa.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found     \r\nWARNING: Download from http://mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/cf1e44edb908e9616030cc83d085989b8e6cd6df.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found   \r\n\r\nAnalyzing: target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu (0 packages loaded, 0 targets configured)  \r\nINFO: Repository local_execution_config_python instantiated at:  \r\nno stack (--record_rule_instantiation_callstack not enabled)     \r\nRepository rule local_python_configure defined at:        \r\nC:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/py/python_configure.bzl:275:41: in                                                                                                                                  \r\nERROR: An error occurred during the fetch of repository 'local_execution_config_python':          Traceback (most recent call last):                     \r\nFile \"C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/py/python_configure.bzl\", \r\nline 208                                                                                              \r\nget_python_bin(repository_ctx)                                                              \r\nFile \"C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl\", line 44, in \r\nget_python_bin                                                                                                    \r\nwhich(repository_ctx, \"python\")           \r\nFile \"C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl\", line 27, in which  execute(repository_ctx, <1 more arguments>)            \r\nFile \"C:/users/amit/_bazel_amit/j6xr7hh5/external/org_tensorflow/third_party/remote_config/common.bzl\", line 208, in execute \r\n                                  fail(<1 more arguments>)`\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nconda create --name=test python=3\r\nconda activate test\r\ngit clone https://github.com/google/mediapipe.git\r\ncd mediapipe\r\nbazel run mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu\r\n```", "comments": ["@AmitMY \r\n\r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Please, let us know which TF version you are using?\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Sorry, added the sequence of commands + tf version", "@AmitMY I guess this is more relevant to the Mediapipe repo. Can you please post this issue in Mediapipe repo? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40591\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40591\">No</a>\n"]}, {"number": 40590, "title": "Cant install tensorflow with gpu ", "body": "ImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\mahmo\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\mahmo\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\mahmo\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\mahmo\\Anaconda3\\envs\\deeplearning\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\mahmo\\Anaconda3\\envs\\deeplearning\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@sarab2811,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it helps. \r\n\r\nSimilar issues for reference #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nAlso, please make sure you fill in the issue template and the TensorFlow version you are trying to install.\r\n\r\nThanks!", "@sarab2811 You can use https://puzl.ee to save time on tf deployment", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40590\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40590\">No</a>\n"]}, {"number": 40589, "title": "AutoGraph \"could not transform\" warning when code contains a multi-line string with backslashes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: 10.1/7\r\n- GPU model and memory: Nvidia GeForce RTX 2080Ti\r\n\r\n**Describe the current behavior**\r\nAutoGraph warning appears if a custom keras layer's `call` method code contains a multiline string joined by the backslash. If a multiline string is joined using brackets, however, no warning appears. Does not seem to influence calculations in any way, but a fun bug to encounter\r\n\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method MyLayer.call of <__main__.MyLayer object at 0x0000XXXXXXXXXXXX>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]\r\nWARNING: AutoGraph could not transform <bound method MyLayer.call of <__main__.MyLayer object at 0x0000XXXXXXXXXXXX>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]\r\n```\r\n\r\n**Describe the expected behavior**\r\nNo warnings appears\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ntf.autograph.set_verbosity(10, alsologtostdout = True)\r\n\r\nfrom tensorflow.keras.layers import Layer, Input\r\n\r\nclass SlashPhobic(Layer):\r\n\r\n    def call(self, inputs):\r\n        s = \"foo\" \\\r\n            \"bar\"\r\n        print(s)\r\n        return inputs\r\n\r\nx = Input(shape = (1,))\r\ny = SlashPhobic()(x)\r\n```\r\n\r\nAutograph log:\r\n\r\n```\r\nConverted call: <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>\r\n    args: (<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nNot whitelisted: <method-wrapper '__call__' of method object at 0x0000XXXXXXXXXXXX>: default rule\r\nNot whitelisted: <class '__main__.SlashPhobic'>: default rule\r\nNot whitelisted: <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>: default rule\r\nEntity <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> is not cached for key <code object call at 0x0000XXXXXXXXXXXX, file \".\\phobic.py\", line 8> subkey (<tensorfl\r\now.python.autograph.core.converter.ConversionOptions object at 0x0000XXXXXXXXXXXX>, frozenset())\r\nConverting <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>\r\nError transforming entity <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>>\r\nTraceback (most recent call last):\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 526, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 326, in convert\r\n    free_nonglobal_var_names)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 240, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 475, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 634, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\parser.py\", line 207, in parse_entity\r\n    return _attempt_to_parse_normal_source(source, future_features)\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\parser.py\", line 111, in _attempt_to_parse_normal_source\r\n    return parse_str(source, preamble_len=len(future_features)), source\r\n  File \"D:\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\parser.py\", line 230, in parse_str\r\n    raise ValueError('expected exactly one node node, found {}'.format(nodes))\r\nValueError: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]\r\nWARNING:tensorflow:AutoGraph could not transform <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]\r\nWARNING: AutoGraph could not transform <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x0000XXXXXXXXXXXX>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x0000XXXXXXXXXXXX>, <gast.gast.Return object at 0x0000XXXXXXXXXXXX>]\r\n```", "comments": ["@dmtlvn \r\nI ran the code shared on tf 2.1,2.2 and tf nightly and see this error, can you please confirm if [this is the issue](https://colab.research.google.com/gist/Saduf2019/7c6cbdb1a4b0bf8d749b4590c0f462ac/untitled238.ipynb) faced.", "@Saduf2019 \r\nThe code in the colab seems to work fine, so I am not sure what issue you are talking about. Looks like colab has some preprocessor, which changes the code to compile and removes the backslash:\r\n```\r\nINFO:tensorflow:Source code of <bound method SlashPhobic.call of <__main__.SlashPhobic object at 0x7f074ff23b38>>:\r\n\r\ndef call(self, inputs):\r\n    s = \"foo\"             \"bar\"\r\n    print(s)\r\n    return inputs\r\n```\r\n\r\nHowever, I am able to reproduce this warning in a separate environment by running a script with the code above, as well as running a jupyter notebook.\r\n", "This looks the same as #35765. It should be fixed in TF 2.2.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40589\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40589\">No</a>\n"]}, {"number": 40588, "title": "Iterator.make_initializer returns None", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.2 / 7.6\r\n- GPU model and memory: GeForce RTX 2080 / 12 Gb\r\n\r\n\r\n**Describe the current behavior**\r\nI'm trying to run a code written in tensorflow 1.1 using tensorflow 2.2. I already run the `tf_upgrade_v2` which changed most of the unsupported things. However, while creating an iterator\r\n```\r\ntrain_data = tf.data.Dataset.from_generator(gen_function, gen_types, gen_shapes)\r\ntrain_data = train_data.map(map_func=map_func, num_parallel_calls=self.num_threads)\r\n# Prefetch data\r\ntrain_data = train_data.prefetch(10)\r\n# create a iterator of the correct shape and type\r\niterator = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(train_data), tf.compat.v1.data.get_output_shapes(train_data))\r\n```\r\nand when I initialize it:\r\n```\r\ntrain_init_op = iter.make_initializer(train_data)\r\n```\r\nThe initalization operator `train_init_op` is `None`. and I got the following error when i run `sess.run(train_init_op)`\r\n:\r\n```\r\nFile \"/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 958, in run\r\n    run_metadata_ptr)\r\n  File \"/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1166, in _run\r\n    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\r\n  File \"/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 477, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/home/pvnieo/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 263, in for_fetch\r\n    (fetch, type(fetch)))\r\nTypeError: Fetch argument None has invalid type <class 'NoneType'>\r\n```\r\n\r\nHow can I solve this issue?", "comments": ["@pvnieo \r\nCan you please share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "Actually, I don't have a small reproducing example, but what I wan't to do is to run the code provided in this github repo: https://github.com/HuguesTHOMAS/KPConv\r\nYou can set up a quick example using the following commands:\r\n**NB**: before running `sh compile_op.sh`, you should comment the flag `-D_GLIBCXX_USE_CXX11_ABI=0` if you are running the code on tf v2.\r\n```\r\ngit clone https://github.com/HuguesTHOMAS/KPConv.git\r\nwget https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_segmentation_benchmark_v0.zip\r\ntf_upgrade_v2 --intree KPConv/ --outtree KPConv_v2/ --reportfile report2.txt\r\nmkdir KPConv_v2/Data\r\nmkdir KPConv_v2/Data/ShapeNetPart\r\nunzip shapenetcore_partanno_segmentation_benchmark_v0.zip\r\ncp shapenetcore_partanno_segmentation_benchmark_v0 KPConv_v2/Data/ShapeNetPart/shapenetcore_partanno_segmentation_benchmark_v0\r\ncd KpConv_v2/tf_custom_ops\r\nsh compile_op.sh\r\ncd ../cpp_wrappers\r\nsh compile_wrappers.sh\r\ncd ..\r\npython3 training_ShapeNetPart.py\r\n```", "@pvnieo I tried running the suggested commands but encountered build errors in my environment. If you can isolate the issue to something reproducible in colab, it will help a lot with figuring out the root problem.", "Hi, Thank you for your response.\r\n\r\nwhat is the error you getting?", "/usr/bin/ld: cannot find -ltensorflow_framework\r\ncollect2: error: ld returned 1 exit status", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40588\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40588\">No</a>\n", "@pvnieo since you closed the issue, were you able to solve the issue? If so how?\r\n(I am having a similar issue porting the code from KPConv from tf1.12 to tf2.4)", "Hi @heujnd \r\nYes, I solved the issue by moving from tensorflow to pytorch!"]}, {"number": 40587, "title": "Test branch", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40587) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 40586, "title": "Distributed training problem", "body": "I am studying the principle of distributed training of TensorFlow, but I cannot find the source code related to gradient communication. I want to know where can I find the source code of uploaded gradient to PS.", "comments": ["Hi @Mrhs121, if I understand correctly it sounds like you are wondering how the gradients are updated and synchronized across devices/workers. Is there a specific distribution strategy you are curious about? ", "yes", "There are different ways to manage the gradients in tf.distribute, depending on what strategy you are using and the arguments you configure. \r\n\r\nI would recommend first taking a look at the [overview page in the documentation](https://www.tensorflow.org/guide/distributed_training) to get a sense for the different options available. This [deep dive presentation](https://www.youtube.com/watch?v=jKV53r9-H14) might also be of use.\r\n\r\nYou can easily see the source code in the documentation as well. For example, if you were interested in learning about the tf.distribute implementation of [NcclAllReduce](https://www.tensorflow.org/api_docs/python/tf/distribute/NcclAllReduce), you can select the \"view source on github\" option to see the [source code](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/distribute/cross_device_ops.py#L743-L765).\r\n\r\nI will close this issue now since it is not a bug, and Stack Overflow is a better place to get support help with a larger community. But feel free to file a new issue if you run into bugs/issues in the future implementing any of these strategies."]}, {"number": 40585, "title": "Add complex64 and complex128 gpu support for tensor_scatter_nd_add", "body": "This PR adds complex64 and complex128 gpu support for tensor_scatter_nd_add,\r\nas was raised in #40577.\r\n\r\nThis PR fixes #40577.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 40584, "title": "Tensorflow 2.2.0 and Tensorflow Probability 0.10.0 import error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.8.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):  3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: n.a.\r\n- GPU model and memory: n.a.\r\n\r\n\r\n\r\nTensorflow version 2.2.0 compiled from source following the steps detailed in the [official documentation](https://www.tensorflow.org/install/source#cpu-only_2) doesn't work with any version of Tensorflow Probability higher than 0.7.  \r\nTensorflow (CPU ONLY) is compiled using the Docker environment and works just fine by itself but when importing Tensorflow Probability I get the following error:  \r\n~~~\r\n>>> import tensorflow_probability as tfp\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/__init__.py\", line 76, in <module>\r\n    from tensorflow_probability.python import *  # pylint: disable=wildcard-import\r\n  File \"/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/__init__.py\", line 24, in <module>\r\n    from tensorflow_probability.python import experimental\r\n  File \"/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/__init__.py\", line 34, in <module>\r\n    from tensorflow_probability.python.experimental import auto_batching\r\n  File \"/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/__init__.py\", line 24, in <module>\r\n    from tensorflow_probability.python.experimental.auto_batching import frontend\r\n  File \"/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/frontend.py\", line 45, in <module>\r\n    from tensorflow.python.autograph.core import naming\r\nImportError: cannot import name 'naming' from 'tensorflow.python.autograph.core' (/home/fabio/Downloads/tf-prob/.pyenv/lib64/python3.8/site-packages/tensorflow/python/autograph/core/__init__.py)\r\n~~~\r\nI am not sure if it is a bug in Tensorflow Probability or if there is something wrong with my build of Tensorflow.", "comments": ["I'm having the same problem\r\n\r\nSystem information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 2.3.0-rc0\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): n.a\r\n- GCC/Compiler version (if compiling from source): n.a\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GTX 1070 8GB\r\n", "Use this build\r\n`pip install tfp-nightly 0.11.0.dev20200708`", "@cfabio @TalhaAsmal \r\nPlease update as per above comment.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Tensorflow 2.3.0rc1 and  tfp-nightly 0.11.0.dev20200716 resolves this issue for me.\r\n\r\nThanks!", "Moving this issue to closed status as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40584\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40584\">No</a>\n", "I just tried `pip install tfp-nightly 0.11.0.dev20200708` and I got back \r\n\r\n```console\r\nRequirement already satisfied: tfp-nightly in /net/vast-storage/scratch/vast/fiete/armas/anaconda/lib/python3.7/site-packages (0.11.0.dev20200715)\r\nERROR: Could not find a version that satisfies the requirement 0.11.0.dev20200708 (from versions: none)\r\nERROR: No matching distribution found for 0.11.0.dev20200708\r\n\r\n```\r\n\r\nbut the original issue remains `ImportError: cannot import name 'naming' from 'tensorflow.python.autograph.core'`. ", "@cfabio @TalhaAsmal @alejandroarmas \r\n\r\nI have tried in colab with [TF 2.3](https://colab.research.google.com/gist/ravikyram/058427903f3806e66361d290a1749187/untitled207.ipynb) and was able to reproduce the issue.But the issue got resolved in [TF nightly version](https://colab.research.google.com/gist/ravikyram/de6c83519abd26da4454f7f7999fc163/untitled206.ipynb)(`2.4.0-dev20200730`).Please, verify once and close the issue.Thanks!", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40584\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40584\">No</a>\n", "Having this issue with TF 2.3 on Colab. Any resolutions?\r\n\r\n\r\n```\r\n2020-10-08 04:27:25.844475: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2020-10-08 04:27:25.844527: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"tapas/tapas/run_task_main.py\", line 29, in <module>\r\n    from tapas.experiments import prediction_utils as exp_prediction_utils\r\n  File \"/usr/local/lib/python3.6/dist-packages/tapas/experiments/prediction_utils.py\", line 25, in <module>\r\n    from tapas.models import tapas_classifier_model\r\n  File \"/usr/local/lib/python3.6/dist-packages/tapas/models/tapas_classifier_model.py\", line 33, in <module>\r\n    import tensorflow_probability as tfp\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_probability/__init__.py\", line 76, in <module>\r\n    from tensorflow_probability.python import *  # pylint: disable=wildcard-import\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/__init__.py\", line 24, in <module>\r\n    from tensorflow_probability.python import experimental\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/experimental/__init__.py\", line 34, in <module>\r\n    from tensorflow_probability.python.experimental import auto_batching\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/experimental/auto_batching/__init__.py\", line 24, in <module>\r\n    from tensorflow_probability.python.experimental.auto_batching import frontend\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/experimental/auto_batching/frontend.py\", line 45, in <module>\r\n    from tensorflow.python.autograph.core import naming\r\nImportError: cannot import name 'naming'\r\n```", "For anyone else that stumbles upon this while using a later version of Tensorflow (I'm running 2.5), I was able to resolve the issue by installing `tensorflow-probability` 0.11.0:\r\n\r\n```\r\npip install tensorflow-probability==0.11.0\r\n```"]}, {"number": 40583, "title": "Add PropagateWhiteFwdThroughClearAndGray in AMP", "body": "This pass is to add gray/clear ops to white_set which are downstream of white ops, because the gray ops are considered numerically-safe(may be made unsafe by an upstream blacklist op).", "comments": ["Thank you for the PR. However, it is not necessarily safe to turn graylist nodes to fp16 even if they are next to whitelist nodes. We only want to convert graylist nodes to fp16 if they are between two whitelist nodes, which is what `AddClearAndGrayToWhiteIfBetweenWhite` does. So I'm closing this PR.\r\n\r\nAlso note we recommend using the `tf.keras.mixed_precision` API over the auto_mixed_precision grappler pass. In the future, auto_mixed_precision will be deprecarated, so I'm hesitant to make algorithmic changes to auto_mixed_precision.\r\n\r\nLet me know if you have a specific use case for converting nodes to fp16 on a numerically-safe path from a whitelist node. Maybe we can find a solution for that specific use case. "]}, {"number": 40582, "title": "Add NewWritableFile", "body": "@mihaimaruseac \r\nThis PR add support for NewWritableFile for GCS", "comments": ["Internal code seems to fail to build. I'm looking into this now and should fix soon."]}, {"number": 40581, "title": "Make the XLA_FLAGS=--xla_gpu_asm_extra_flags works with replay_computation", "body": "Mostly, replay_computation have call to ptxas during the generation of the fake input. But it doesn't use the XLA_FLAGS. So this patch this specific case.\r\n\r\nThis is a follow up from #39734\r\n@timshen91  that reviewed it.", "comments": []}, {"number": 40580, "title": "tf.image.flip_left_right and tf.image.flip_up_down incorrectly assumes rank-3 image and flips along the wrong axis", "body": "## System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7\r\n\r\nYou can also obtain the TensorFlow version with:\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n`unknown 2.0.0`\r\n\r\n## Describe the current behavior\r\n\r\n**Setup:** Under some circumstances (in my case, when a `tf.Tensor` is inside a `tf.data.Dataset` and it is being conditionally transformed inside a `tf.data.Dataset.map()` call), the shape of a `Tensor` becomes unknown (this may be expected behavior still).\r\n\r\n**Behavior**: When `tf.image.flip_left_right` is applied to this `tf.Tensor`, the function incorrectly assumes a rank-3 shape and flips the image along the wrong axis.\r\n\r\n## Describe the expected behavior\r\n\r\nWhen `tf.image.flip_left_right` is applied to the `tf.Tensor`, the function does not assume a rank-3 shape and flips the image along the correct axis.\r\n\r\n## Standalone code to reproduce the issue\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\ndef correct_image_flip_left_right(image):\r\n    return tf.reverse(image, axis=[-2])\r\n\r\nPATCH_TF = False  # Change this to True to fix the bug\r\nif PATCH_TF:\r\n    tf.image.flip_left_right = correct_image_flip_left_right\r\n\r\nimage_input = tf.convert_to_tensor([\r\n    # batch: 0\r\n    [\r\n        # y: 0\r\n        [[0, 1, 2], [3, 4, 5]],  # x=0,1 channels=0,1,2\r\n        # y: 1\r\n        [[6, 7, 8], [9, 10, 11]],  # x=0,1 channels=0,1,2\r\n    ],\r\n])\r\n\r\nimage_flipped_directly = tf.image.flip_left_right(image_input)\r\n\r\nexpected_output = tf.convert_to_tensor([\r\n    # batch: 0\r\n    [\r\n        # y: 0\r\n        [[3, 4, 5], [0, 1, 2]],  # x=0,1 channels=0,1,2\r\n        # y: 1\r\n        [[9, 10, 11], [6, 7, 8]],  # x=0,1 channels=0,1,2\r\n    ],\r\n])\r\n\r\ntf.assert_equal(image_flipped_directly, expected_output)\r\nprint(\"Directly calling tf.image.flip_left_right works as exected.\")\r\n\r\ndef generator():  yield image_input\r\n\r\ndataset = tf.data.Dataset.from_generator(generator, output_types=tf.int32)\r\n\r\ndef flip_it(image, do_flip: bool):\r\n    if do_flip:\r\n        return tf.image.flip_left_right(image)\r\n    else:\r\n        return image\r\n\r\ndataset = dataset.map(lambda image: flip_it(image, tf.constant(True)))\r\n\r\nimage_flipped_via_dataset_map = next(iter(dataset))\r\n\r\nprint(\"image_flipped_via_dataset_map:\")\r\nprint(image_flipped_via_dataset_map)\r\nprint(\"expected_output:\")\r\nprint(expected_output)\r\n\r\ntf.assert_equal(image_flipped_via_dataset_map, expected_output)\r\n# This assertion fails even though it shouldn't unless PATCH_TF is True\r\n\r\nprint(\"If you can see this message, image_flipped_via_dataset_map == expected_output\")\r\n```\r\n\r\nOutput:\r\n```\r\n> python .\\tf_image_flip.py\r\n2020-06-18 17:10:08.875275: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\nDirectly calling tf.image.flip_left_right works as exected.\r\nimage_flipped_via_dataset_map:\r\ntf.Tensor(\r\n[[[[ 6  7  8]\r\n   [ 9 10 11]]\r\n\r\n  [[ 0  1  2]\r\n   [ 3  4  5]]]], shape=(1, 2, 2, 3), dtype=int32)\r\nexpected_output:\r\ntf.Tensor(\r\n[[[[ 3  4  5]\r\n   [ 0  1  2]]\r\n\r\n  [[ 9 10 11]\r\n   [ 6  7  8]]]], shape=(1, 2, 2, 3), dtype=int32)\r\nTraceback (most recent call last):\r\n  File \".\\tf_image_flip.py\", line 54, in <module>\r\n    tf.assert_equal(image_flipped_via_dataset_map, expected_output)\r\n  File \"C:\\Users\\uib58003\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\check_ops.py\", line 456, in assert_equal_v2\r\n    return assert_equal(x=x, y=y, summarize=summarize, message=message, name=name)\r\n  File \"C:\\Users\\uib58003\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\check_ops.py\", line 546, in assert_equal\r\n    (message or '', index_and_values_str, summary_msg)))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:\r\nCondition x == y did not hold.\r\nIndices of first 3 different values:\r\n[[0 0 0 0]\r\n [0 0 0 1]\r\n [0 0 0 2]]\r\nCorresponding x values:\r\n[6 7 8]\r\nCorresponding y values:\r\n[3 4 5]\r\nFirst 3 elements of x:\r\n[6 7 8]\r\nFirst 3 elements of y:\r\n[3 4 5]\r\n```\r\n\r\n## Other info / logs\r\n\r\nThe bug is in `tensorflow_core.ops.image_ops_impl._flip`, called by `image_ops_impl.flip_left_right`:\r\nhttps://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L537-L546\r\n\r\nTensorflow should not assume based on `shape.ndims is None` that the image is 3-dimensional and it should not call `fix_image_flip_shape` which further builds on this incorrect assumption:\r\nhttps://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L315-L320\r\n\r\nThis causes the flipping to happen along the wrong axis.\r\n\r\nThe `flip_left_right` function should be implemented by `array_ops.reverse(image, axis=[-2])` which always flips along the correct axis for any number of ranks as long as the dimensions end in `..., HEIGHT, WIDTH, CHANNELS]`.\r\n\r\nThe same bug probably appears in `tf.image.flip_up_down` for the same reason based on looking at the source code, but I haven't tested this. That function should always apply `tf.reverse(image, axis=[-3])` for the same reason as before.", "comments": ["I have tried in colab with TF 2.0,2.1,2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/2df7914ebc51be2db05ffe646a4b4122/untitled38.ipynb).Thanks!", "Added a PR #40626 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40580\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40580\">No</a>\n"]}, {"number": 40579, "title": "[ROCm] Fix ROCm CSB build failure - 200618", "body": "The folllowing commit introduces build error on the ROCm platform\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/b6ff68822a59578f942e4fb8076757da8db278ae\r\n\r\nbuild error\r\n\r\n```\r\nIn file included from tensorflow/core/kernels/split_lib_gpu.cu.cc:27:\r\nIn file included from ./tensorflow/core/util/gpu_kernel_helper.h:25:\r\n./tensorflow/core/util/gpu_device_functions.h:824:25: error: redefinition of 'GpuAtomicMax'\r\n__device__ inline int64 GpuAtomicMax(int64* ptr, int64 value) {\r\n                        ^\r\n./tensorflow/core/util/gpu_device_functions.h:792:29: note: previous definition is here\r\n__device__ inline long long GpuAtomicMax(long long* ptr, long long value) {\r\n                            ^\r\n./tensorflow/core/util/gpu_device_functions.h:894:25: error: redefinition of 'GpuAtomicMin'\r\n__device__ inline int64 GpuAtomicMin(int64* ptr, int64 value) {\r\n                        ^\r\n./tensorflow/core/util/gpu_device_functions.h:862:29: note: previous definition is here\r\n__device__ inline long long GpuAtomicMin(long long* ptr, long long value) {\r\n                            ^\r\n2 errors generated.\r\n...\r\n...\r\n```\r\n\r\nThe cause is a combination of two things\r\n* The condition `#if __CUDA_ARCH__ < 320` will hold true for ROCm too!\r\n* The issue being addressed by (the build breaking commit, for CUDA) was already fixed by this commit (https://github.com/tensorflow/tensorflow/commit/307485737f46a76c97aefb51b0fc3cd264c2bb94) within a `#if TENSORFLOW_USE_ROCM` block\r\n\r\nThe fix being submitted in this PR, is to undo some of the changes introduced by the earlier ROCm commit, and combine that change with the change in the breaking commit.\r\n\r\n\r\n-----------------------------------\r\n\r\n/cc @chsigg @cheshire @nvining-work ", "comments": ["@gbaned gentle ping.\r\n\r\nwe need to this PR merged to get ROCm nightly CI runs to start passing again.  thanks.", "@deven-amd sorry for the delay , can you please check below error \r\n\r\n` \r\n  File \"tensorflow/python/framework/test_combinations.py\", line 315, in decorated\r\n    execute_test_method()\r\n  File \"/tensorflow/python/framework/test_combinations.py\", line 298, in execute_test_method\r\n    test_method(**kwargs_to_pass)\r\n  File \"tensorflow/python/distribute/combinations.py\", line 367, in decorator\r\n    test_method(self, **kwargs)\r\n  File \"/contrib/distribute/python/ps_strategy/single_client_multi_process_test.py\", line 73, in test_single_client\r\n    list_stdout=True).stdout\r\n  File \"//tensorflow/python/distribute/multi_process_runner.py\", line 763, in run\r\n    return runner.join(timeout)\r\n  File \"tensorflow/python/distribute/multi_process_runner.py\", line 498, in join\r\n    self._get_mpr_result(process_statuses))\r\ntensorflow.python.distribute.multi_process_runner.UnexpectedSubprocessExitError: Subprocess chief-0 exited with exit code 255`", "@rthadur that error does not seem to be related to the change in this PR.  \r\n\r\nWithout more details and/or the ability to reproduce the error locally on my end, it would be difficult to root cause it.", "@chsigg can you please help with these failures ?", "@rthadur where is this error coming from...all the CI runs seem to have passed for this PR", "> @rthadur where is this error coming from...all the CI runs seem to have passed for this PR\r\n\r\nI tried to submit it again and this time it went through , I guess above failures were flaky. Thank you "]}, {"number": 40578, "title": "[MLIR][XLA] Add GatherOp to LHLO/HLO emitters", "body": "This is a PR from JIZHI, the AI platform in Tencent.\r\n@sherhut @pifon2a\r\n\r\nWe work on TensorFlow/MLIR to make mlir_gpu enable. Could you tell me how to run the test? It seems need a new tool.", "comments": ["@timshen91 can you help providing guidance about where we want the HLO->LHLO conversion be handled right now?", "@xinan-jiang Can you please check @joker-eph's comments and keep us posted. Thanks!", "Unassigning myself since @pifon2a is more familiar with this code."]}, {"number": 40577, "title": "tensor scatter nd add doesn't support complex64 in tf 2.3-dev", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.3-dev\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Quadro P5000, 16Gb\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using `tf.tensor_scatter_nd_add` with complex data, I have the following error:\r\n\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-4-35a6b23ae93f> in <module>\r\n----> 1 tf.tensor_scatter_nd_add(tf.transpose(to_update), arr_ind, updates)\r\n\r\n~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in tensor_scatter_add(tensor, indices, updates, name)\r\n  10686       return _result\r\n  10687     except _core._NotOkStatusException as e:\r\n> 10688       _ops.raise_from_not_ok_status(e, name)\r\n  10689     except _core._FallbackException:\r\n  10690       pass\r\n\r\n~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   6841   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6842   # pylint: disable=protected-access\r\n-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6844   # pylint: enable=protected-access\r\n   6845 \r\n\r\n~/workspace/tfkbnufft/venv/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Unsupported dtype: complex64 [Op:TensorScatterAdd]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n`tf.tensor_scatter_nd_add` should work with complex data.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf \r\nto_update = tf.ones([1, 640000], dtype=tf.complex64)\r\narr_ind = tf.range(324000)[:, None]\r\nupdates = tf.cast(tf.random.normal([324000, 1], dtype=tf.float32), tf.complex64)\r\ntf.tensor_scatter_nd_add(tf.transpose(to_update), arr_ind, updates)\r\n```\r\n\r\n[Colab link](https://colab.research.google.com/drive/1omAKl8vcqd2TBVbXEnVGvey8Urmcp-kH?usp=sharing).\r\n\r\n**Other info / logs** \r\n\r\nThis problem only appears for tf-nightly and on GPU.\r\n", "comments": ["Added a PR #40585 for complex support", "Hi @yongtang , thanks for taking care of this.\r\n\r\nDo you know if by any chance there is a link between this issue (i.e. complex support not being straightfoward) and issue #40672 ?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40577\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40577\">No</a>\n"]}, {"number": 40575, "title": "TF2.2.0 model.train&evaluate may have a display bug ", "body": "Please make sure that this may be a bug. \r\n**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\nNo. This is the code from (https://www.tensorflow.org/beta/tutorials/quickstart/beginner)\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab and mac OS Mojave  10.14.4\r\n\r\n- TensorFlow version (use command below): pip install tensorflow==2.2.0\r\n\r\n- Python version: 3.6.9 \r\n\r\n**Describe the current behavior**\r\nThere is a difference of result between TF2.1.0 and TF2.20 version in model.train  & model.evaluate sections.  \r\nIn TF2.1.0, result of model.train show 60000/60000.it is normal.\r\nBut in TF2.2.0, this show 1875/1875  . Despite the same shape of train data.\r\n\r\nIn case of evaluate is same.\r\nIn TF2.1.0, result of model.evaluate show 10000/10000.\r\nBut in TF2.2.0, this show 313/313.\r\n\r\nThis is may be bug.But it's also may normal.\r\nSo please check the problem.\r\n\r\n**Source code / logs**\r\n\r\n```\r\n#install Tensorflow in Colab\r\n!pip install tensorflow==2.2.0\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\n#RUN the code \r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nprint(\"fit\") \r\nmodel.fit(x_train, y_train, epochs=1)\r\nprint(\"evaluate\")\r\nmodel.evaluate(x_test,  y_test)\r\n```\r\n\r\n[out]\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 0s 0us/step\r\nfit\r\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.2957 - accuracy: 0.9136\r\nevaluate\r\n313/313 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9594\r\n[0.13421817123889923, 0.9593999981880188]\r\n\r\n\r\n\r\nI uploaded to [Colab](https://colab.research.google.com/drive/1MxqnCskd43a9-cr3Gjv6Oaby04OzyDcc?usp=sharing )\r\nThis ipynb file uses the TF2.1.0 and TF2.2.0. You can see the bug on TF 2.2.0.", "comments": ["I have tried in colab with TF version 2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/2fc7cca38390186678550f8036c27a2a/untitled45.ipynb).Thanks!", "@kurikinton105  This is by design. The `batch_size` argument in `model.fit` if unspecified will default to `32`. You can validate this by simply looking at `number of samples (60000)/1875 = batch_size (32)` \r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit arguments documentation.\r\nThanks!\r\n", "Thank you for your answering!!!!!\r\nI checked the document and I understand this design changes.\r\n\r\nThis changes may be sudden change.\r\nSo users may be wondering may be wondering if they can learn from the data properly because there is no display.\r\nThanks!!!", "Glad to help. Closing now. Thanks for confirming. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40575\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40575\">No</a>\n"]}, {"number": 40574, "title": "LSTM example for GPU delegate ", "body": "Hello, \r\nI am trying to run my model in android GPU using TF lite and gpu delegate.\r\nBut I faced this \"UNIDIRECTIONAL SEQUENCE LSTM: Operation is not supported\".\r\nFrom the document \"https://www.tensorflow.org/lite/performance/gpu_advanced\", LSTM v2 is supported now. \r\nAll examples in tensorflow git are not using this LSTM.\r\nIs there any example for \"LSTM v2 (Basic LSTM only)\" ?\r\n  ", "comments": ["My model is \r\n```\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Input(shape=(1, input_dim), name='input'),\r\n    tf.keras.layers.LSTM(hidden_size, time_major=False, return_sequences=True)\r\n```\r\nAbove model has \"UNIDIRECTIONAL SEQUENCE LSTM\", so I changed like this\r\n```\r\nenc_inp = tf.keras.Input(shape=(input_dim))\r\nstates1 = [tf.keras.Input(shape=(hidden_size)),tf.keras.Input(shape=(hidden_size))]\r\ncell1 = tf.keras.layers.LSTMCell(hidden_size)\r\n[output, out_states1] = cell1(enc_inp,states=states1)\r\nmodel = tf.keras.Model(inputs=[enc_inp,states1], outputs=[output,out_states1])\r\n```\r\nThis model has no \"UNIDIRECTIONAL SEQUENCE LSTM\" operation. but error is occur at\r\n\"ModifyGraphWithDelegate\".\r\n", "@ymodak  Hello, Can you show me any document or example for LSTM gpu delegate ?", "TFLite GPU doesn't have a good story for RNNs.\r\n\r\nFirst of all, only the basic LSTM is supported.  Unidirectional, bidirectional, full LSTMs are not implemented and we don't have immediate priorities to add the missing ops.\r\n\r\nThen comes the problem around invoking the LSTM network with a for loop.  What we've seen in the past is the following pattern:\r\n```\r\nfor (int i = 0; i < n; ++i) {\r\n  // copy output state from i - 1 to input state to i\r\n  interpreter->Invoke();\r\n}\r\n```\r\nUnfortunately, this will take up a LOT of time in GPU/CPU synchronization, and at that point, you might as well just stay in the CPU land.\r\n\r\nNow a terrible workaround that I have done in one of the LSTM projects is the manual unrolling.  Instead doing the for loop programmatically 28 times at Invoke, I've replicated the graph structure 28 times in the TFLite model, so that it is a single Invoke call."]}, {"number": 40573, "title": "Keras Mixed Precision", "body": "\r\n**System information**\r\n- Linux Ubuntu 18\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0\r\n- GPU model and memory: 2080 Ti\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to run a simple cnn on Tensor Cores of 2080 Ti. Using the following\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\nRunning into this error\r\n![Screenshot from 2020-06-16 16-03-04](https://user-images.githubusercontent.com/66824777/85017922-e93dd180-b189-11ea-90bd-759f2021b451.png)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@agg-aditi \r\nPlease share the code for which this issue is faced.", "i followed these codes\r\nhttps://www.tensorflow.org/guide/mixed_precision\r\nhttps://developer.nvidia.com/automatic-mixed-precision", "@agg-aditi\r\nPlease share simple stand alone code for us tpo replicate or if possible share a colab gist for us to analyse.", "@Saduf2019 \r\nThis is the code :\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\n\r\n\r\n\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n\r\n\r\n\r\nprint('Compute dtype: %s' % policy.compute_dtype)\r\nprint('Variable dtype: %s' % policy.variable_dtype)\r\n\r\n\r\n\r\n\r\ninputs = keras.Input(shape=(784,), name='digits')\r\nif tf.config.list_physical_devices('GPU'):\r\n  print('The model will run with 4096 units on a GPU')\r\n  num_units = 4096\r\nelse:\r\n\r\n  print('The model will run with 64 units on a CPU')\r\n  num_units = 64\r\ndense1 = layers.Dense(num_units, activation='relu', name='dense_1')\r\nx = dense1(inputs)\r\ndense2 = layers.Dense(num_units, activation='relu', name='dense_2')\r\nx = dense2(x)\r\n\r\n\r\nprint('x.dtype: %s' % x.dtype.name)\r\n\r\nprint('dense1.kernel.dtype: %s' % dense1.kernel.dtype.name)\r\n\r\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\nprint('Outputs dtype: %s' % outputs.dtype.name)\r\n\r\n\r\n\r\nx = layers.Dense(10, name='dense_logits')(x)\r\noutputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)\r\nprint('Outputs dtype: %s' % outputs.dtype.name)\r\n\r\noutputs = layers.Activation('linear', dtype='float32')(outputs)\r\n\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\nmodel.compile(loss='sparse_categorical_crossentropy',\r\n              optimizer=keras.optimizers.RMSprop(),\r\n              metrics=['accuracy'])\r\n\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784).astype('float32') / 255\r\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\r\n\r\n\r\n\r\ninitial_weights = model.get_weights()\r\n\r\n\r\n\r\nhistory = model.fit(x_train, y_train,\r\n                    batch_size=8192,\r\n                    epochs=5,\r\n                    validation_split=0.2)\r\ntest_scores = model.evaluate(x_test, y_test, verbose=2)\r\nprint('Test loss:', test_scores[0])\r\nprint('Test accuracy:', test_scores[1])\r\n\r\n\r\n\r\n\r\n\r\nx = tf.constant(256, dtype='float16')\r\n(x ** 2).numpy()  \r\n\r\n\r\nx = tf.constant(1e-5, dtype='float16')\r\n(x ** 2).numpy()  \r\n\r\n\r\n\r\nloss_scale = policy.loss_scale\r\nprint('Loss scale: %s' % loss_scale)\r\n\r\n\r\n\r\n\r\nnew_policy = mixed_precision.Policy('mixed_float16', loss_scale=1024)\r\nprint(new_policy.loss_scale)\r\n\r\n\r\n\r\noptimizer = keras.optimizers.RMSprop()\r\noptimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\r\n\r\n\r\n\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\r\ntrain_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n                 .shuffle(10000).batch(8192))\r\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(8192)\r\n\r\n\r\n\r\n@tf.function\r\ndef train_step(x, y):\r\n  with tf.GradientTape() as tape:\r\n    predictions = model(x)\r\n    loss = loss_object(y, predictions)\r\n    scaled_loss = optimizer.get_scaled_loss(loss)\r\n  scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\r\n  gradients = optimizer.get_unscaled_gradients(scaled_gradients)\r\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n  return loss\r\n\r\n\r\n@tf.function\r\ndef test_step(x):\r\n  return model(x, training=False)\r\n\r\n\r\nmodel.set_weights(initial_weights)\r\n\r\n\r\nfor epoch in range(5):\r\n  epoch_loss_avg = tf.keras.metrics.Mean()\r\n  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\r\n      name='test_accuracy')\r\n  for x, y in train_dataset:\r\n    loss = train_step(x, y)\r\n    epoch_loss_avg(loss)\r\n  for x, y in test_dataset:\r\n    predictions = test_step(x)\r\n    test_accuracy.update_state(y, predictions)\r\n  print('Epoch {}: loss={}, test accuracy={}'.format(epoch, epoch_loss_avg.result(), test_accuracy.result()))\r\n\r\n\r\n", "@agg-aditi\r\nCode shared is not indented, i ran the code after fixing few lines the entire code is unindented, please find the [gits here](https://colab.research.google.com/gist/Saduf2019/a6e7b8bdcc0e5dd2e2ddacc6e1b8eb96/untitled238.ipynb)\r\nPlease share code (indented) such that we can replicate the issue faced or  please share colab gist with the error faced for us to analyse.", "> @\r\n> Code shared is not indented, i ran the code after fixing few lines the entire code is unindented, please find the [gits here](https://colab.research.google.com/gist/Saduf2019/a6e7b8bdcc0e5dd2e2ddacc6e1b8eb96/untitled238.ipynb)\r\n> Please share code (indented) such that we can replicate the issue faced or please share colab gist with the error faced for us to analyse.\r\n@Saduf2019 \r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb", "@agg-aditi\r\nBy colab gist i mean the code you have used, to reproduce the issue as shared in my gist, please remove indentation errors and share.", "> @agg-aditi\r\n> By colab gist i mean the code you have used, to reproduce the issue as shared in my gist, please remove indentation errors and share.\r\n\r\nhttps://gist.github.com/agg-aditi/5a3727eee3e052e1275bf95e7284a115\r\nthis is the exact code i have used", "i tried running the this tutorial which itself gave the error\r\n\r\n> > @\r\n> > Code shared is not indented, i ran the code after fixing few lines the entire code is unindented, please find the [gits here](https://colab.research.google.com/gist/Saduf2019/a6e7b8bdcc0e5dd2e2ddacc6e1b8eb96/untitled238.ipynb)\r\n> > Please share code (indented) such that we can replicate the issue faced or please share colab gist with the error faced for us to analyse.\r\n> > @Saduf2019\r\n> > https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/mixed_precision.ipynb\r\n\r\n", "@agg-aditi I ran the code but didn't run into any error. Heres my [gist](https://colab.research.google.com/gist/gowthamkpr/c9496350467bb22505443c62136827a5/mixed_precision.ipynb). You have to run it using tensorflow 2.2.0 not using 1.X. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive fr more than 2 weeks. Please add additional comments for us to open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40573\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40573\">No</a>\n"]}, {"number": 40572, "title": "Unable to create SavedModel from keras model", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.4\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.2.0rc3\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nRunning model.save(\"model\") creates a standalone file named \"model\"\r\n\r\n**Describe the expected behavior**\r\n\r\nRunning model.save(\"model\") creates a directory named model that contains assets, saved_model.pb, and variables\r\n\r\n**Standalone code to reproduce the issue**\r\nLink to model: https://www.dropbox.com/s/6ginejkhna1sic8/unet_70.h5?dl=0\r\n\r\n```\r\nimport segmentation_models as sm\r\nfrom keras.models import load_model\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\n\r\n\r\npath_to_model = \"models/unet_70.h5\"\r\nloss = sm.losses.binary_focal_dice_loss\r\nmodel = load_model(path_to_model, custom_objects={'binary_focal_loss_plus_dice_loss': loss})\r\n\r\nmodel.save('model')\r\n\r\n```\r\n", "comments": ["@MyJumperBroke23 \r\n\r\nI have tried in colab with TF version 2.2 and i am seeing the below error message.(`OSError: Unable to open file (truncated file: eof = 7340032, sblock->base_addr = 0, stored_eof = 122058928`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/15a8e1bfe466b7c38ec35b25e1db8c87/untitled46.ipynb).Thanks!", "@ravikyram Edited it so that the model loads\r\n\r\nhttps://colab.research.google.com/gist/MyJumperBroke23/84ce4dc78f109d582a2e0f983ee4ab33/untitled46.ipynb", "Hi @MyJumperBroke23, model.save only creates a directory with assets, saved_model.pb, and variables when you are saving to **TF SavedModel format**. As you are saving to the **H5 format**, all you will see is the standalone model file. See [this section of the docs](https://www.tensorflow.org/guide/keras/save_and_serialize#whole-model_saving_loading) for more detail.\r\n\r\nSince the TF SavedModel format is the default when using model.save(), you can try saving the model to a filename that does not end in .h5.\r\n\r\nAdditionally it looks like you are using a combination of keras and tf.keras? You probably want to change your second import so that everything is consistent:\r\n` from tensorflow.keras.models import load_model `", "@nikitamaia Hi, my model.save call doesn't end in .h5, the file I'm loading the model from is a h5 file. I'm using \r\n\r\n`model.save('model')`\r\n\r\nI use keras.models instead of tensorflow.keras.models, because when I use tensorflow.keras.models I get an error importing my model due to a custom layer", "Ahh I see, okay in that case I wonder if the custom layer is causing the problem and that would be the first thing to try and fix so you can import with tf.keras. Similar issue here [#26835](https://github.com/tensorflow/tensorflow/issues/26835). Is there a way you can import your custom layers as custom objects?\r\n\r\nWhere did you get the unet model from?", "@nikitamaia that fixed it. Thanks.", "Glad to hear it! Closing now since a fix was found."]}, {"number": 40571, "title": "The GPUs hang when split a log_prob and gradient computation across a number of GPU devices", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat - Enterprise Linux Server 7.5 (Maipo)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.2.0-0-g2b96f36 2.2.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: 10.1/7.6.4\r\n- GPU model and memory: 4 x GPU NVIDIA V100 (Volta) with 16GB HBM2.\r\n\r\n**Describe the current behavior**\r\n\r\nTrying to demonstrate how to split a log_prob and gradient computation across a number of GPU devices, the GPUs hang. \r\n\r\n**Describe the expected behavior**\r\n\r\n\r\nRun inference as expected in multi-GPU environment.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe attached files are based on the [notebook](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb#scrollTo=b4RG2YJQdHGA) shared by @brianwa84 We have not setup logical GPUs as he did, but we have tried to use the 4 physical GPUs in the machine.  \r\n\r\nThis file hangs\r\n\r\n```python \r\n#!/apps/PYTHON/3.7.4_ML/bin/python \r\n\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\n\r\n\r\ndef main():\r\n    tfb, tfd = tfp.bijectors, tfp.distributions\r\n\r\n    physical_gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    print(physical_gpus)\r\n\r\n#    tf.config.experimental.set_virtual_device_configuration(\r\n#        physical_gpus[0],\r\n#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)\r\n#    tf.config.experimental.set_virtual_device_configuration(\r\n#        physical_gpus[1],\r\n#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)\r\n#    gpus = tf.config.list_logical_devices('GPU')\r\n#    print(gpus)\r\n\r\n#st = tf.distribute.MirroredStrategy(devices=tf.config.list_logical_devices('GPU'))\r\n    st = tf.distribute.MirroredStrategy()\r\n    print(st.extended.worker_devices)\r\n    ndim = 3\r\n    \r\n    def model():\r\n      Root = tfd.JointDistributionCoroutine.Root\r\n      loc = yield Root(tfb.Shift(.5)(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim]))))\r\n      scale_tril = yield Root(tfb.FillScaleTriL()(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim * (ndim + 1) // 2]))))\r\n      yield tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril)\r\n    \r\n    dist = tfd.JointDistributionCoroutine(model)\r\n    tf.random.set_seed(1)\r\n    loc, scale_tril, _ = dist.sample(seed=2)\r\n    \r\n    samples = dist.sample(value=([loc] * 1024, scale_tril, None), seed=3)[2]\r\n    samples = tf.round(samples * 1000) / 1000\r\n    for dim in reversed(range(ndim)):\r\n      samples = tf.gather(samples, tf.argsort(samples[:,dim]))\r\n    \r\n    print(samples)\r\n    \r\n    def dataset_fn(ctx):\r\n      batch_size = ctx.get_per_replica_batch_size(len(samples))\r\n      d = tf.data.Dataset.from_tensor_slices(samples).batch(batch_size)\r\n      return d.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)\r\n    \r\n    ds = st.experimental_distribute_datasets_from_function(dataset_fn)\r\n    \r\n    observations = next(iter(ds))\r\n    print(observations)\r\n\r\n    def log_prob_and_grad(loc, scale_tril, observations):\r\n      ctx = tf.distribute.get_replica_context()\r\n      with tf.GradientTape() as tape:\r\n        tape.watch((loc, scale_tril))\r\n        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples)\r\n      grad = tape.gradient(lp, (loc, scale_tril))\r\n      return ctx.all_reduce('sum', lp), [ctx.all_reduce('sum', g) for g in grad]\r\n    \r\n    @tf.custom_gradient\r\n    def target_log_prob(loc, scale_tril):\r\n      lp, grads = st.experimental_run_v2(log_prob_and_grad, (loc, scale_tril, observations))\r\n      return lp.values[0], lambda grad_lp: [grad_lp * g.values[0] for g in grads]\r\n    \r\n    singleton_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril))\r\n    \r\n    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2)\r\n    kernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()])\r\n    \r\n    @tf.function(autograph=False)\r\n    def sample_chain():\r\n      return tfp.mcmc.sample_chain(\r\n          num_results=200, num_burnin_steps=100,\r\n          current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], \r\n          kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted)\r\n    samps, is_accepted = sample_chain()\r\n    \r\n    print(f'accept rate: {np.mean(is_accepted)}')\r\n    print(f'ess: {tfp.mcmc.effective_sample_size(samps)}')\r\n    \r\n    print(tf.reduce_mean(samps[0], axis=0))\r\n\r\nif __name__ == \"__main__\":\r\n    sys.exit(main())\r\n```\r\n\r\nIn order to run previous file in a machine with multiple GPUs we use the following batch job \r\n\r\n```\r\n#!/bin/bash \r\n#SBATCH --job-name='test2_cross_gpu' \r\n#SBATCH --qos=debug\r\n# \r\n#SBATCH --nodes=1 \r\n#SBATCH --ntasks=1 \r\n#SBATCH --cpus-per-task=80 \r\n#SBATCH --gres=gpu:2 \r\n#SBATCH --time=00:05:00 \r\n#------- I/O ------- \r\n#SBATCH -D . \r\n#SBATCH --output=test2_cross_gpu_%j.out \r\n#SBATCH --error=test2_cross_gpu_%j.err \r\n#------- modules ------- \r\nmodule purge \r\nmodule load gcc/8.3.0 cuda/10.1 cudnn/7.6.4 nccl/2.4.8 tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2 fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 python/3.7.4_ML \r\necho \"== Starting run at $(date)\" \r\necho \"== Job ID: ${SLURM_JOBID}\" \r\necho \"== Job NPROCS: ${SLURM_NPROCS}\" \r\necho \"== Job NNODES: ${SLURM_NNODES}\" \r\necho \"== Node list: ${SLURM_NODELIST}\" \r\necho \"== Submit dir. : ${SLURM_SUBMIT_DIR}\" \r\n#------- srun ------ \r\nsrun ./testHangs.py\r\n\r\necho \"Done\"\r\n```\r\n\r\nThis file works (second part of the notebook previously referred to)\r\n\r\n```python\r\n#!/apps/PYTHON/3.7.4_ML/bin/python \r\n\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\n\r\n\r\ndef main():\r\n    tfb, tfd = tfp.bijectors, tfp.distributions\r\n\r\n    physical_gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    print(physical_gpus)\r\n\r\n#    tf.config.experimental.set_virtual_device_configuration(\r\n#        physical_gpus[0],\r\n#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)\r\n#    tf.config.experimental.set_virtual_device_configuration(\r\n#        physical_gpus[1],\r\n#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)] * 2)\r\n#    gpus = tf.config.list_logical_devices('GPU')\r\n#    print(gpus)\r\n\r\n#st = tf.distribute.MirroredStrategy(devices=tf.config.list_logical_devices('GPU'))\r\n    st = tf.distribute.MirroredStrategy()\r\n    print(st.extended.worker_devices)\r\n    ndim = 3\r\n    \r\n    def model():\r\n      Root = tfd.JointDistributionCoroutine.Root\r\n      loc = yield Root(tfb.Shift(.5)(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim]))))\r\n      scale_tril = yield Root(tfb.FillScaleTriL()(tfd.MultivariateNormalDiag(loc=tf.zeros([ndim * (ndim + 1) // 2]))))\r\n      yield tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril)\r\n    \r\n    dist = tfd.JointDistributionCoroutine(model)\r\n    tf.random.set_seed(1)\r\n    loc, scale_tril, _ = dist.sample(seed=2)\r\n    \r\n    samples = dist.sample(value=([loc] * 1024, scale_tril, None), seed=3)[2]\r\n    samples = tf.round(samples * 1000) / 1000\r\n    for dim in reversed(range(ndim)):\r\n      samples = tf.gather(samples, tf.argsort(samples[:,dim]))\r\n    \r\n    print(samples)\r\n    \r\n    batches_per_eval = 2\r\n    \r\n    def dataset_fn(ctx):\r\n      batch_size = ctx.get_per_replica_batch_size(len(samples))\r\n      d = tf.data.Dataset.from_tensor_slices(samples).batch(batch_size // batches_per_eval)\r\n      return d.shard(ctx.num_input_pipelines, ctx.input_pipeline_id).prefetch(2)\r\n    \r\n    ds = st.experimental_distribute_datasets_from_function(dataset_fn)\r\n    \r\n    def log_prob_and_grad(loc, scale_tril, observations, prev_sum_lp, prev_sum_grads):\r\n      with tf.GradientTape() as tape:\r\n        tape.watch((loc, scale_tril))\r\n        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples)\r\n      grad = tape.gradient(lp, (loc, scale_tril))\r\n      return lp + prev_sum_lp, [g + pg for (g, pg) in zip(grad, prev_sum_grads)]\r\n\r\n    @tf.custom_gradient\r\n    def target_log_prob(loc, scale_tril):\r\n      sum_lp = tf.zeros([])\r\n      sum_grads = [tf.zeros_like(x) for x in (loc, scale_tril)]\r\n      sum_lp, sum_grads = st.experimental_run_v2(\r\n          lambda *x: tf.nest.map_structure(tf.identity, x), (sum_lp, sum_grads))\r\n      def reduce_fn(state, observations):\r\n        sum_lp, sum_grads = state\r\n        return st.experimental_run_v2(\r\n            log_prob_and_grad, (loc, scale_tril, observations, sum_lp, sum_grads))\r\n      sum_lp, sum_grads = ds.reduce((sum_lp, sum_grads), reduce_fn)\r\n      sum_lp = st.reduce('sum', sum_lp, None)\r\n      sum_grads = [st.reduce('sum', sg, None) for sg in sum_grads]\r\n      return sum_lp, lambda grad_lp: [grad_lp * sg for sg in sum_grads]\r\n    \r\n    multibatch_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril))\r\n    \r\n    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2)\r\n    kernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()])\r\n    \r\n    @tf.function(autograph=False)\r\n    def sample_chain():\r\n      return tfp.mcmc.sample_chain(\r\n          num_results=200, num_burnin_steps=100,\r\n          current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], \r\n          kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted)\r\n    samps, is_accepted = sample_chain()\r\n    \r\n    print(f'accept rate: {np.mean(is_accepted)}')\r\n    print(f'ess: {tfp.mcmc.effective_sample_size(samps)}')\r\n    \r\n    print(tf.reduce_mean(samps[0], axis=0))\r\n\r\nif __name__ == \"__main__\":\r\n    sys.exit(main())\r\n```\r\nAnd the batch job \r\n\r\n```\r\n#!/bin/bash \r\n#SBATCH --job-name='test2_cross_gpu' \r\n#SBATCH --qos=debug\r\n# \r\n#SBATCH --nodes=1 \r\n#SBATCH --ntasks=1 \r\n#SBATCH --cpus-per-task=80 \r\n#SBATCH --gres=gpu:2 \r\n#SBATCH --time=00:05:00 \r\n#------- I/O ------- \r\n#SBATCH -D . \r\n#SBATCH --output=test2_cross_gpu_%j.out \r\n#SBATCH --error=test2_cross_gpu_%j.err \r\n#------- modules ------- \r\nmodule purge \r\nmodule load gcc/8.3.0 cuda/10.1 cudnn/7.6.4 nccl/2.4.8 tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2 fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 python/3.7.4_ML \r\necho \"== Starting run at $(date)\" \r\necho \"== Job ID: ${SLURM_JOBID}\" \r\necho \"== Job NPROCS: ${SLURM_NPROCS}\" \r\necho \"== Job NNODES: ${SLURM_NNODES}\" \r\necho \"== Node list: ${SLURM_NODELIST}\" \r\necho \"== Submit dir. : ${SLURM_SUBMIT_DIR}\" \r\n#------- srun ------ \r\nsrun ./testWorks.py\r\n\r\necho \"Done\"\r\n```\r\n\r\n**Other info / logs**\r\n\r\nDoing ```strace -F -p [PID]``` we obtain \r\n\r\n```futex(0x4a896234, FUTEX_WAIT_PRIVATE, 1, NULL <unfinished ...> ```\r\n\r\nThen ```gdb -p [PID]```\r\n```\r\n#0  syscall () at ../sysdeps/unix/sysv/linux/powerpc/syscall.S:29\r\n#1  0x00007fff63fed144 in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fff63febd08 in nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fff63fe7414 in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fff63fe7aec in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fff63fe7b44 in nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fff63fe59c4 in tensorflow::condition_variable::wait(tensorflow::mutex_lock&) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fff59ae1f88 in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fff59ae242c in tensorflow::KernelAndDeviceFunc::Run(tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fff59a9dcd4 in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::Span<tensorflow::TensorHandle*>) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007fff59a9ef40 in tensorflow::ExecuteNode::Run() ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007fff59adb59c in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007fff59a96e34 in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#13 0x00007fff59a9b4c8 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()\r\n   from /apps/PYTHON/3.7.4_ML/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n---Type <return> to continue, or q <return> to quit---\r\n```", "comments": ["Dear @sanjoy, Any clue about this issue?", "Dear @Flamefire  and @crccw , due your experience with Slurm, maybe you have a solution to resolve this issue.", "I don't think this is Slurm related at all as there is only a single process on a single node being executed. I guess you can replicated this in an interactive job and maybe also locally or on Cloud resources.", "Thanks @Flamefire .\r\n\r\nYes It's possible to replicate it locally, and works perfectly, but not in Slurm. I've tested with different configurations (multiple nodes and MultiWorkerMirroredStrategy) but none has worked, that's the reason why I put in this issue the simplest one (single process on a single node). \r\n\r\nRemembering your [issue](https://github.com/tensorflow/tensorflow/issues/39417#start-of-content) I have tested also different configurations adding ```@tf.function``` on the code, but again, none progress.\r\n", "@Flamefire if it's not asking too much, please, could you test the code on your machines? I would be very grateful.", "@AngelBerihuete It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.4.1 or 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40571\">No</a>\n"]}, {"number": 40570, "title": "ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32", "body": "Hi, \r\nI am very new to Tensorflow. I am using TensorFlow 1.14.0, Anaconda Spyder 3.7 64 bit and windows 10 64 bit. In my DATASET I am having two folders with classification images (in png and jpeg format). \r\nI am trying to convert my Keras model.h5 into tflite model. For that, I am using the below-mentioned code. It gives me an error(full traceback can be found at the bottom): \r\n    ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32 for input 185, name: mobilenetv2_1.00_224_input \r\n\r\nI have tried to convert images into float 32 using the TensorFlow image converter and NumPy but the same error. \r\n\r\n    import tensorflow as tf\r\n    dataset_dir = \"C:\\\\Users\\\\Ravi\\\\dataset\"\r\n\r\n    IMAGE_SIZE = 224\r\n    BATCH_SIZE = 64\r\n\r\n    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n        rescale=1./255, \r\n        validation_split=0.2)\r\n\r\n    train_generator = datagen.flow_from_directory(\r\n    dataset_dir,\r\n    target_size=(IMAGE_SIZE, IMAGE_SIZE),\r\n    batch_size=BATCH_SIZE, \r\n    subset='training')\r\n\r\n    val_generator = datagen.flow_from_directory(\r\n    dataset_dir,\r\n    target_size=(IMAGE_SIZE, IMAGE_SIZE),\r\n    batch_size=BATCH_SIZE, \r\n    subset='validation')\r\n\r\n    image_batch, label_batch = next(val_generator)\r\n    image_batch.shape, label_batch.shape\r\n\r\n    print (train_generator.class_indices)\r\n\r\n    labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\r\n\r\n    with open('Mask_labels.txt', 'w') as f:\r\n      f.write(labels)\r\n  \r\n    IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\r\n\r\n    # Create the base model from the pre-trained MobileNet V2\r\n    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\r\n                                              include_top=False, \r\n                                              weights='imagenet')\r\n    base_model.trainable = False\r\n    model = tf.keras.Sequential([\r\n      base_model,\r\n      tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\r\n      tf.keras.layers.Dropout(0.2),\r\n      tf.keras.layers.GlobalAveragePooling2D(),\r\n      tf.keras.layers.Dense(units=2, activation='softmax')\r\n    ])\r\n\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(), \r\n              loss='categorical_crossentropy', \r\n              metrics=['accuracy'])\r\n\r\n    print(model.summary())\r\n    print('Number of trainable weights = {}'.format(len(model.trainable_weights)))\r\n\r\n    history = model.fit_generator(train_generator, \r\n                    epochs=2, \r\n                    validation_data=val_generator)\r\n\r\n    # A generator that provides a representative dataset\r\n    def representative_data_gen():\r\n      dataset_list = tf.data.Dataset.list_files(dataset_dir + '/*/*')\r\n      for i in range(100):\r\n        global image\r\n        image = next(iter(dataset_list))\r\n        image = tf.io.read_file(image)\r\n        image = tf.io.decode_jpeg(image, channels=3)\r\n        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\r\n        #image = np.array(image, dtype=\"float32\")\r\n        image = tf.image.convert_image_dtype(image, tf.float32)\r\n        #image = tf.expand_dims(image, 0)\r\n        yield [image]\r\n    \r\n    saved_keras_model = 'model.h5'\r\n    model.save(saved_keras_model)\r\n\r\n    converter =  tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(\"model.h5\")\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    # This ensures that if any ops can't be quantized, the converter throws an error\r\n    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    # These set the input and output tensors to uint8\r\n    converter.inference_input_type = tf.uint8\r\n    converter.inference_output_type = tf.uint8\r\n    # And this sets the representative dataset so we can quantize the activations\r\n    converter.representative_dataset = representative_data_gen\r\n    tflite_model = converter.convert()\r\n \r\n    with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:\r\n      f.write(tflite_model)\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n      File \"C:\\Users\\Ravi\\train_the_model.py\", line 120, in <module>\r\n        tflite_model = converter.convert()\r\n\r\n      File \"C:\\Users\\Ravi\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 908, in convert\r\n    inference_output_type)\r\n\r\n      File \"C:\\Users\\Ravi\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 200, in _calibrate_quantize_model\r\n    inference_output_type, allow_float)\r\n\r\n      File \"C:\\Users\\Ravi\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\", line 75, in calibrate_and_quantize\r\n    self._calibrator.FeedTensor(calibration_sample)\r\n\r\n      File \"C:\\Users\\Ravi\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\tensorflow_lite_wrap_calibration_wrapper.py\", line 112, in FeedTensor\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value)\r\n\r\n    ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32 for input 185, name: mobilenetv2_1.00_224_input \r\n\r\n\r\n\r\n\r\n\r\n ", "comments": ["@MevadaRavikumar \r\nPlease refer to below links for reference and let us know if it helps.\r\n[link](https://stackoverflow.com/questions/52530724/python-tensorflow-lite-error-cannot-set-tensor-got-tensor-of-type-1-but-expecte) [link1](https://github.com/tensorflow/tensorflow/issues/22409)", "I ran the code shared, please share all dependencies or a colab gist for us to analyse the issue faced.\r\nPlease find the [gist here](https://colab.research.google.com/gist/Saduf2019/d0c3679f8e5f543357633ba9b13fed58/untitled236.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "It got solved by running the code on google colab. "]}, {"number": 40569, "title": "AttributeError: 'Tensor' object has no attribute 'numpy'", "body": "System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution: Windows 10\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version: 2.0.0\r\nPython version: 3.6\r\nGPU model and memory: NVIDIA 4GB GTX970\r\n\r\nMy code is giving me the error 'AttributeError: 'Tensor' object has no attribute 'numpy'' in the bolded line, with the comments \"Error occurs here\".\r\n\r\nI want to perform selective search on the feature mappings generated by the convolutional layers in my CNN model. However, it appears that cv2 functions do not accept tensors, and thus I wish to convert the tensors to numpy arrays. However, when I attempt to do the conversion using the numpy() or tf.py_function() functions, I will get the attribute error as shown above. \r\n\r\nIs this error occuring because I am calling numpy() within the model which is using @tf.function? Is there any other way to perform this operation?\r\n\r\nThank you.\r\n\r\nHere is my code: \r\n\r\n```\r\nclass seq_model(object):\r\n    def __init__(self):\r\n        print(\"Using SEQUENTIAL model\")\r\n\r\n    def input(self):\r\n        #Create CNN model\r\n        input_size = (28, 28, 1)\r\n        inputs = Input(shape = input_size)\r\n        return inputs\r\n\r\n    def selective_search(self, input_stack):\r\n        cv2.setUseOptimized(True)\r\n        cv2.setNumThreads(4)\r\n        total_ROI = 0\r\n        ROI_img_list = []\r\n        select_search = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\r\n\r\n        input_shape = input_stack.get_shape().as_list()\r\n        print(\"input_shape = \", input_shape)\r\n        no_of_channel = input_shape[3]\r\n        for i in range(no_of_channel):\r\n            if input_shape[0] == None:\r\n                img_tensor = input_stack[-1,:,:,i]\r\n\r\n                **img = img_tensor.numpy()** #Error occurs at this line\r\n\r\n                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) #Ensure 3 channels\r\n            select_search.setBaseImage(img)\r\n            select_search.switchToSelectiveSearchQuality()\r\n            rects = select_search.process()\r\n            numShowRects = 100\r\n            img_copy = img.copy()\r\n            boundary_list = []\r\n            for j, rect in enumerate(rects):\r\n                if (j < numShowRects):\r\n                    x, y, w, h = rect\r\n                    cv2.rectangle(img_copy, (x,y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\r\n                    boundary = [x, x+w, y, y+h]\r\n                    boundary_list.append(boundary)\r\n                else:\r\n                    break\r\n            num_region = len(boundary_list)\r\n            label = label_stack[i]\r\n            for k in range(num_region):\r\n                corner = boundary_list[k]\r\n                x1 = corner[0]\r\n                x2 = corner[1]\r\n                y1 = corner[2]\r\n                y2 = corner[3]\r\n                ROI_img = img[y1:y2, x1:x2]\r\n                ROI_img = cv2.cvtColor(ROI_img, cv2.COLOR_RGB2GRAY)\r\n                ROI_img_reshaped = np.empty(CNN_input_shape)\r\n                ROI_img_reshaped = cv2.resize(ROI_img, (y2-y1, x2-x1))\r\n                ROI_img_list.append(ROI_img_reshaped)\r\n            total_ROI += num_region #Obtain total number of ROI images\r\n            ROI_stack = np.empty((total_ROI, 28, 28, 1))\r\n\r\n        return ROI_stack\r\n\r\n    def spatial_pyramid_pooling(self, input, levels):\r\n        #Levels refers to the list of pooling regions to use. \r\n        #The length of the list is the number of pooling regions.\r\n        #Each int in the list is the number of regions in that pool. \r\n        #For example [1,2,4] would be 3 regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\r\n        input_shape = input.get_shape().as_list()\r\n        pyramid = []\r\n        outputs = []\r\n        num_rows = input_shape[1]\r\n        num_cols = input_shape[2]\r\n        row_length = [K.cast(num_rows, 'float32') / i for i in levels] #Returns a Keras tensor of float32 type\r\n        col_length = [K.cast(num_cols, 'float32') / i for i in levels]\r\n        tf.print(row_length) #[4,8,16]\r\n        tf.print(col_length) #[4,8,16]\r\n\r\n        for pool_num, num_pool_regions in enumerate(levels): #pool_num is the index, num_pool_regions is the actual value\r\n            for jy in range(num_pool_regions):\r\n                for ix in range(num_pool_regions):\r\n                    x1 = ix * col_length[pool_num]\r\n                    x2 = ix * col_length[pool_num] + col_length[pool_num]\r\n                    y1 = jy * row_length[pool_num]\r\n                    y2 = jy * row_length[pool_num] + row_length[pool_num]\r\n\r\n                    x1 = K.cast(K.round(x1), 'int32')\r\n                    x2 = K.cast(K.round(x2), 'int32')\r\n                    y1 = K.cast(K.round(y1), 'int32')\r\n                    y2 = K.cast(K.round(y2), 'int32')\r\n\r\n                    if input_shape[0] == None:\r\n                        new_shape = [-1, y2 - y1, x2 - x1, input_shape[3]]\r\n\r\n                    x_crop = input[:, y1:y2, x1:x2, :]\r\n                    xm = Reshape(new_shape)(x_crop)\r\n                    pooled_val = K.max(xm, axis = (1, 2)) #Obtain maximum value from cropped image\r\n                    #print(\"pooled_val = \", np.shape(pooled_val))\r\n                    outputs.append(pooled_val)    \r\n\r\n        outputs = concatenate(outputs, axis = 1)\r\n        #print(\"SHAPE = \", np.shape(outputs)) #(None, 112, 64)\r\n        return outputs\r\n\r\n    def conv_model(self, no_of_class = 10):\r\n        kernel_size = (3,3)\r\n        pad = 'same'\r\n        activation = 'selu'\r\n        kernel = 'lecun_normal'\r\n        filters = 64\r\n\r\n        self.initial_input = self.input()\r\n\r\n        c1 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(self.initial_input)\r\n        b1 = BatchNormalization()(c1) \r\n        p1 = MaxPooling2D()(b1)\r\n\r\n        c2 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(p1)\r\n        b2 = BatchNormalization()(c2) \r\n\r\n        roi = self.selective_search(b2)\r\n        spp = self.spatial_pyramid_pooling(roi, levels = [3,2,1])\r\n\r\n        f = Flatten()(spp)\r\n        bf = BatchNormalization()(f)\r\n\r\n        bf_shape = bf.get_shape().as_list()\r\n        dense_num = bf_shape[1] #Changes the dense layer automatically\r\n\r\n        d1 = Dense(dense_num, activation = 'selu', kernel_initializer = kernel)(bf)\r\n        db1 = BatchNormalization()(d1)\r\n        d2 = Dense(10, activation = 'softmax')(db1)\r\n\r\n        model = Model(inputs = [self.initial_input], outputs = [d2])\r\n\r\n        return model\r\n\r\nget_model = seq_model()\r\nmodel = get_model.conv_model()\r\nprint(model.summary())\r\n\r\n```", "comments": ["@StriderDM35 \r\n\r\nI tried in colab and i am seeing the error message(`NameError: name 'Input' is not defined`).Request you to share colab link or simple standalone file sode with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "> @StriderDM35\r\n> \r\n> I tried in colab and i am seeing the error message(`NameError: name 'Input' is not defined`).Request you to share colab link or simple standalone file sode with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!\r\n\r\nMy apologies, @ravikyram. I had forgotten to include the libraries used for my code. Please include the libraries below:\r\n\r\n```\r\nimport os\r\nimport glob\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport cv2\r\n\r\nimport keras\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.models import Model, load_model, Sequential, model_from_json, load_model\r\nfrom tensorflow.keras.layers import Input, BatchNormalization, Activation, Flatten, Dense, LeakyReLU, Reshape\r\nfrom tensorflow.keras.layers import concatenate\r\nfrom tensorflow.python.keras.layers.core import Lambda, Dropout\r\nfrom tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\r\nfrom tensorflow.python.keras.layers.pooling import MaxPooling2D, AveragePooling2D\r\nfrom tensorflow.python.keras.layers.merge import Concatenate, Add\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\r\nfrom tensorflow.keras.optimizers import *\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\nclass seq_model(object):\r\n    def __init__(self):\r\n        print(\"Using SEQUENTIAL model\")\r\n\r\n    def input(self):\r\n        #Create CNN model\r\n        input_size = (28, 28, 1)\r\n        inputs = Input(shape = input_size)\r\n        return inputs\r\n\r\n    def selective_search(self, input_stack):\r\n        cv2.setUseOptimized(True)\r\n        cv2.setNumThreads(4)\r\n        total_ROI = 0\r\n        ROI_img_list = []\r\n        select_search = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\r\n\r\n        input_shape = input_stack.get_shape().as_list()\r\n        print(\"input_shape = \", input_shape)\r\n        no_of_channel = input_shape[3]\r\n        for i in range(no_of_channel):\r\n            if input_shape[0] == None:\r\n                img_tensor = input_stack[-1,:,:,i]\r\n\r\n                **img = img_tensor.numpy()** #Error occurs at this line\r\n\r\n                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) #Ensure 3 channels\r\n            select_search.setBaseImage(img)\r\n            select_search.switchToSelectiveSearchQuality()\r\n            rects = select_search.process()\r\n            numShowRects = 100\r\n            img_copy = img.copy()\r\n            boundary_list = []\r\n            for j, rect in enumerate(rects):\r\n                if (j < numShowRects):\r\n                    x, y, w, h = rect\r\n                    cv2.rectangle(img_copy, (x,y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\r\n                    boundary = [x, x+w, y, y+h]\r\n                    boundary_list.append(boundary)\r\n                else:\r\n                    break\r\n            num_region = len(boundary_list)\r\n            label = label_stack[i]\r\n            for k in range(num_region):\r\n                corner = boundary_list[k]\r\n                x1 = corner[0]\r\n                x2 = corner[1]\r\n                y1 = corner[2]\r\n                y2 = corner[3]\r\n                ROI_img = img[y1:y2, x1:x2]\r\n                ROI_img = cv2.cvtColor(ROI_img, cv2.COLOR_RGB2GRAY)\r\n                ROI_img_reshaped = np.empty(CNN_input_shape)\r\n                ROI_img_reshaped = cv2.resize(ROI_img, (y2-y1, x2-x1))\r\n                ROI_img_list.append(ROI_img_reshaped)\r\n            total_ROI += num_region #Obtain total number of ROI images\r\n            ROI_stack = np.empty((total_ROI, 28, 28, 1))\r\n\r\n        return ROI_stack\r\n\r\n    def spatial_pyramid_pooling(self, input, levels):\r\n        #Levels refers to the list of pooling regions to use. \r\n        #The length of the list is the number of pooling regions.\r\n        #Each int in the list is the number of regions in that pool. \r\n        #For example [1,2,4] would be 3 regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map\r\n        input_shape = input.get_shape().as_list()\r\n        pyramid = []\r\n        outputs = []\r\n        num_rows = input_shape[1]\r\n        num_cols = input_shape[2]\r\n        row_length = [K.cast(num_rows, 'float32') / i for i in levels] #Returns a Keras tensor of float32 type\r\n        col_length = [K.cast(num_cols, 'float32') / i for i in levels]\r\n        tf.print(row_length) #[4,8,16]\r\n        tf.print(col_length) #[4,8,16]\r\n\r\n        for pool_num, num_pool_regions in enumerate(levels): #pool_num is the index, num_pool_regions is the actual value\r\n            for jy in range(num_pool_regions):\r\n                for ix in range(num_pool_regions):\r\n                    x1 = ix * col_length[pool_num]\r\n                    x2 = ix * col_length[pool_num] + col_length[pool_num]\r\n                    y1 = jy * row_length[pool_num]\r\n                    y2 = jy * row_length[pool_num] + row_length[pool_num]\r\n\r\n                    x1 = K.cast(K.round(x1), 'int32')\r\n                    x2 = K.cast(K.round(x2), 'int32')\r\n                    y1 = K.cast(K.round(y1), 'int32')\r\n                    y2 = K.cast(K.round(y2), 'int32')\r\n\r\n                    if input_shape[0] == None:\r\n                        new_shape = [-1, y2 - y1, x2 - x1, input_shape[3]]\r\n\r\n                    x_crop = input[:, y1:y2, x1:x2, :]\r\n                    xm = Reshape(new_shape)(x_crop)\r\n                    pooled_val = K.max(xm, axis = (1, 2)) #Obtain maximum value from cropped image\r\n                    #print(\"pooled_val = \", np.shape(pooled_val))\r\n                    outputs.append(pooled_val)    \r\n\r\n        outputs = concatenate(outputs, axis = 1)\r\n        #print(\"SHAPE = \", np.shape(outputs)) #(None, 112, 64)\r\n        return outputs\r\n\r\n    def conv_model(self, no_of_class = 10):\r\n        kernel_size = (3,3)\r\n        pad = 'same'\r\n        activation = 'selu'\r\n        kernel = 'lecun_normal'\r\n        filters = 64\r\n\r\n        self.initial_input = self.input()\r\n\r\n        c1 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(self.initial_input)\r\n        b1 = BatchNormalization()(c1) \r\n        p1 = MaxPooling2D()(b1)\r\n\r\n        c2 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(p1)\r\n        b2 = BatchNormalization()(c2) \r\n\r\n        roi = self.selective_search(b2)\r\n        spp = self.spatial_pyramid_pooling(roi, levels = [3,2,1])\r\n\r\n        f = Flatten()(spp)\r\n        bf = BatchNormalization()(f)\r\n\r\n        bf_shape = bf.get_shape().as_list()\r\n        dense_num = bf_shape[1] #Changes the dense layer automatically\r\n\r\n        d1 = Dense(dense_num, activation = 'selu', kernel_initializer = kernel)(bf)\r\n        db1 = BatchNormalization()(d1)\r\n        d2 = Dense(10, activation = 'softmax')(db1)\r\n\r\n        model = Model(inputs = [self.initial_input], outputs = [d2])\r\n\r\n        return model\r\n\r\nget_model = seq_model()\r\nmodel = get_model.conv_model()\r\nprint(model.summary())\r\n\r\n```", "I have tried in colab with TF versions 2.2 ,nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/707519c3eb063d7973ca773bf70dbcf1/untitled47.ipynb).Thanks!", "@StriderDM35 Please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/27519)  especially this [comment](https://github.com/tensorflow/tensorflow/issues/27519#issuecomment-566528842) and let me know if it helps!", "Hi, @gowthamkpr. I have checked my code using the issue that you mentioned and noticed that the img that raised the error is also returning <class 'tensorflow.python.framework.ops.Tensor'>.\r\nHowever, neither \"model.run_eagerly = True\" nor \"tf.config.experimental_run_functions_eagerly(True)\" solved the issue. ", "@StriderDM35 The issue here is that you are trying to convert `img_tensor` to a numpy array which is called while a graph is executed i.e., eager execution disabled (img_tensor.numpy() only works when eager execution is enabled) and that is the reason why you are noticing this error.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40569\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40569\">No</a>\n"]}, {"number": 40568, "title": "Building Tensorflow for arm based linux systems.", "body": "System information\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.6\r\n- Bazel Version: 2.0.0\r\n\r\n\r\n**Describe the problem**\r\nI want to build tensorflow shared library from source for arm based 32 bit linux platform but nowhere i find the build command in documentation.\r\nIs it that some different toolchain is required for arm-linux-androideabi ?\r\nWhat bazel command shall i try to build it ?\r\n", "comments": ["Hi Yash,\r\n\r\nIf you are trying to build TensorFlow (both training and inference) on Arm based system, the cloest thing to checkout is the RasberryPi build. \r\n\r\nhttps://www.tensorflow.org/install/source_rpi\r\n\r\nIf you only care about inference, you might want to check out TensorFlow Lite which has pretty intensive Android (mostly Arm chips) support. \r\n\r\nhttps://www.tensorflow.org/lite/guide/build_arm64\r\n\r\nIn the past, we had TensorFlow mobile for Android, which is effectively building slimmed TensorFlow on Android for Arm chip. But that project has been deprecated by Tensorflow Lite.\r\n\r\nThx", "Hi @wangtz ,\r\nI was tryng to build inference only tflite for arm 32 bit linux OS which is not based on android.\r\nI have a static library libtensorflowlite.a which works but I  need libtensorflowlite.so shared library which runs on my hardware.\r\nThanks", "There is a way to build shared library using the Bazel.\r\n\r\n[ARM32]\r\n```\r\nbazel build --config=elinux_armhf tensorflow/lite:libtensorflowlite.so\r\n```\r\n\r\n[ARM64]\r\n```\r\nbazel build --config=elinux_aarch64 tensorflow/lite:libtensorflowlite.so\r\n```", "ohh, great! Thanks @terryheo :)\r\nI will try this and close the issue if it works.", "@terryheo \r\nThe above commands aren't working for me. \r\nIt says --config=elinux_aarch64/elinux_armhf not found in .bazelrc\r\nDo I have to downoad any dependencies for it ?", "@scocoyash, the configuration is available since TF2.3. You should use 2.3 or master branch.", "Built it, Thanks @terryheo ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40568\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40568\">No</a>\n"]}, {"number": 40567, "title": "d", "body": "d", "comments": ["@Lucysmith8 \r\nPlease share simple stand alone code for us to replicate the issue faced or share a colab gist with the error for us to analyse", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40567\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40567\">No</a>\n"]}, {"number": 40566, "title": "Use loss_weight in Model.compile() to compute total loss, but in real the total loss is more than the sum of losses", "body": "I test for the using of the loss_weight in Model.compile() ,which can weight losses. but In my test, I find the total loss is more than sum of losses.\r\nlike { 'loss': 3.4932688, 'output_1_loss': 1.107162, 'output_2_loss': 1.107162, 'output_3_loss': 1.107162}, where I made loss_weight is [1,1,1]\u30023.49 > 1.107*3\r\nmy version of tensorflow is 2.1.0\r\npython is 3.6\r\n", "comments": ["@jianrui1995 \r\n\r\nRequest you to fill [issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose).Please, share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "this is my model class and main().\r\n`class model(tf.keras.Model):\r\n    def __init__(self,):\r\n        super(model,self).__init__()\r\n        self.x1 = tf.keras.layers.Dense(10,activation=\"relu\")\r\n        self.x2 = tf.keras.layers.Dense(10,activation=\"relu\")\r\n        self.pre = tf.keras.layers.Dense(3,activation=\"softmax\")\r\n        \r\n    @tf.function\r\n    def call(self, inputs, training=None, mask=None):\r\n        out = self.x1(inputs)\r\n        out = self.x2(out)\r\n        out = self.pre(out)\r\n        return [out,out,out]\r\n\r\n\r\ndef train():\r\n    re = ra()  # a dataset.  (x,(y,y,y)) y is one-hot  in 3 dim\r\n    mo = model()\r\n    mo.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\r\n               loss=[MineLoss(from_logits=False),MineLoss(from_logits=False),MineLoss(from_logits=False)],\r\n               loss_weights=[1,1,1])\r\n    mo.fit(re().batch(4),\r\n           epochs=5,\r\n           validation_data=re().batch(4),\r\n           verbose=1)\r\n\r\nif __name__ == \"__main__\":\r\n    train()\r\n`\r\n\r\nbelow is my  loss class\r\n\r\n`\r\nclass MineLoss(tf.keras.losses.Loss):\r\n\r\ndef __init__(self,from_logits):\r\n\r\nsuper(MineLoss,self).__init__(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)self.from_logits = from_logits def call(self, y_true, y_pred):\r\n\r\nloss = tf.keras.losses.categorical_crossentropy(y_true,y_pred,from_logits=self.from_logits)return loss\r\n`", "@jianrui1995 \r\n\r\nWill it be possible to share colab link or simple standalone code with proper indentation.It will help us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40565, "title": "Prediciting the model with features on TPU (AssertionError: Could not compute output Tensor(\"dense_3/Identity:0\", shape=(None, 1), dtype=float32))", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Kaggle using TPU\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAfter succesful Training , prediction of the model was not happening even if the dataset was right \r\nAnd throwing this error\r\n`    AssertionError: Could not compute output Tensor(\"dense_3/Identity:0\", shape=(None, 1), dtype=float32)\r\n`\r\n**Describe the expected behavior**\r\nModel should sucessfully predict the dataset\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n[https://www.kaggle.com/prudhvi9999/image-and-metadata](url)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nLogs are \r\n[logs.txt](https://github.com/tensorflow/tensorflow/files/4797768/logs.txt)\r\n\r\n", "comments": ["@prudhvirajboddu,\r\nI was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1011a622c82d670157c10ff1ea1b96eb/40565.ipynb). Thanks!", "That was the latest version of changed code Not exactly I want the model to run.\r\nThis was the kernel version 2 . I was not able to run . Please take a look at it .\r\nThank you.\r\nhttps://www.kaggle.com/prudhvi9999/image-and-metadata?scriptVersionId=36605669", "> That was the latest version of changed code Not exactly I want the model to run.\r\n> This was the kernel version 2 . I was not able to run . Please take a look at it .\r\n> Thank you.\r\n> https://www.kaggle.com/prudhvi9999/image-and-metadata?scriptVersionId=36605669\r\n\r\n@amahendrakar  any update ?", "I'm having the same issue on Kaggle with TPU, model fit ran successfully, but I can't generate predictions.\r\n` AssertionError: Could not compute output Tensor(\"dense_7/Identity:0\", shape=(None, 1), dtype=float32)`\r\nTemporary fix:\r\nsince mode.predict() can accept the format of training data and ignores the label, you can leverage this using map() on test data:\r\n` def prepare_test_data(sample):`\r\n`----return sample, 0`\r\njust make sure to do it before batching.", "> I'm having the same issue on Kaggle with TPU, model fit ran successfully, but I can't generate predictions.\r\n> ` AssertionError: Could not compute output Tensor(\"dense_7/Identity:0\", shape=(None, 1), dtype=float32)`\r\n> Temporary fix:\r\n> since mode.predict() can accept the format of training data and ignores the label, you can leverage this using map() on test data:\r\n> ` def prepare_test_data(sample):`\r\n> `----return sample, 0`\r\n> just make sure to do it before batching.\r\n\r\nCan you share the code snippet for that ?", "This worked for me\r\n`def prepare_test_data(sample):`\r\n`----return sample, 0`\r\n\r\n`test_ds = get_test_dataset()`\r\n`test_images_ds = test_ds.map(prepare_test_data).batch(BATCH_SIZE)`\r\n`ouput = model.predict(test_images_ds)\r\n`\r\n", "Was able to reproduce the issue, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8381d48dfeba929a493d1bd1493b8117/40565.ipynb). Thanks!", "Got the solution for that issue. We've to get the test dataset without batching from that function and batch them after parsing with image and tabular data with '0' and batch them .Check this link for more . Thanks \r\nhttps://colab.research.google.com/drive/1F4enrsOUuxbXUlN4YWwQd9H2_Sy1eMGm?usp=sharing", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40565\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40565\">No</a>\n"]}]