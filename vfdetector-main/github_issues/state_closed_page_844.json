[{"number": 28200, "title": "Deprecation warning in ctc_batch_cost function (python/keras/backend.py)", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nOS: Arch linux\r\nTensorflow: 2.0.0alpha0\r\n\r\nWARNING: Logging before flag parsing goes to stderr. \r\nW0426 20:17:50.524740 140527476778624 deprecation.py:323] From /python3.7/site-packages/tensorflow/python/keras/backend.py:5151: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. \r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\n\r\nW0426 20:17:50.689021 140527476778624 deprecation.py:323] From /python3.7/site-packages/tensorflow/python/keras/backend.py:5130: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\n\r\n", "comments": ["@arthurflor23 : Please give us some more details on the issue you are facing. Thanks!", "Hi! Sorry, but It's more the prevention of the bug, considering that the functions to_int32 and to_int64 will be removed in a future version.", "Apologies but I am having trouble understanding your query. Are you asking to add deprecation warning to ```ctc_batch_cost``` function ? In that case its not required since we have included this function in TF 2.0 \r\nAlso deprecation warnings for ```to_int32``` and ```to_int64``` functions look correct. Please let me know if I am missing something. Thanks!", "That's right, will this be updated at some point? I think I made a mistake then, sorry"]}, {"number": 28199, "title": "Correct out-of-date docstring for StaticHashTable", "body": "The code snippet in documentation for the TensorFlow V2 version of `tf.lookup.StaticHashTable` hasn't been updated and no longer runs with TensorFlow 2.x. This PR updates the docstring for that class with code snippets that work on the latest master branch. I've included separate example code for both eager mode and graph mode.", "comments": ["Hmm, looking at this code again, I can see that the situation with StaticHashTable is a bit more complicated than I thought. I will withdraw this PR and submit a new one shortly."]}, {"number": 28198, "title": "Building 2.0 from master branch using --config=v2 creating 1.13.1 version", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: tried to \r\n- Python version: 3.5.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 6.2.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nTried to build and install tensorflow 2.0 from master branch using --config=v2. It is building but the build version is 1.13.1. After installing the version it also shows 1.13.1 while run: `tf.__version__`\r\n\r\nHow can I build tensorflow 2.0 from master branch? \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel --output_base=$tf_deps/ build \\ \r\n--config=v2 \\ \r\n--copt=\"-O3\" --copt=\"-g\" -s -c opt \\ \r\n//tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. \r\n```\r\nimport tensorflow as tf\r\ntf.__version__\r\n1.13.1\r\n```\r\n", "comments": ["With `--config=v2`, you get TensorFlow 2.0. The `tf.__version__` is not updated though.  Check something like `tf.version` to see if you are using `tensorflow._api.v2`", "Thanks. got it. \r\nSo when using --config=v2 on master branch it builds both v1 and v2 and v2 is enabled by default. "]}, {"number": 28197, "title": "while_loop inside @tf.contrib.eager.defun only loop once", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n`tf.while_loop` only loops once\r\n**Describe the expected behavior**\r\n`tf.while_loop` only loops more than once\r\n**Code to reproduce the issue**\r\n```\r\n@tf.contrib.eager.defun\r\ndef fn():\r\n    idx = 0\r\n    max_iter = 5\r\n    \r\n    def loop_body(idx):\r\n        print('loop once')\r\n        return idx + 1\r\n    \r\n    tf.while_loop(\r\n        lambda idx: idx < max_iter,\r\n        lambda idx: loop_body(idx),\r\n        [idx]\r\n        )\r\n    \r\n    \r\nfn() # -> only printed once\r\n```\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["You can use `tf.print` instead, which will print every time the loop body executes. `print` will only run while building the TensorFlow graph.", "but the value of `idx` remains `0` after the whole thing\r\n\r\n```\r\n@tf.contrib.eager.defun\r\ndef fn():\r\n    idx = 0\r\n    max_iter = 5\r\n    \r\n    def loop_body(idx):\r\n        tf.print('loop once')\r\n        return idx + 1\r\n    \r\n    tf.while_loop(\r\n        lambda idx: idx < max_iter,\r\n        lambda idx: loop_body(idx),\r\n        [idx]\r\n        )\r\n    \r\n    print(idx) # ==> 0\r\n    \r\n    \r\nfn()\r\n```", "`while_loop` returns the updated value as a Tensor. Or you can use AutoGraph and write this as a normal Python for loop; if you're looping over a Tensor value like `tf.range` it'll manage this stuff for you.", "thanks!\r\n\r\nwhat I provided above was a minimal working example. what I wanted to do was to use `tf.while_loop` to update several values in a matrix.\r\n\r\n```\r\n    idx = 0\r\n    max_iter = tf.shape(double_bond_idxs)[0]\r\n    \r\n    def loop_body(idx):\r\n        # get the double bond idx\r\n        chr_idx = double_bond_idxs[idx]\r\n\r\n        # change the bond order in the adjaceny map to 2\r\n        adjacency_map[chr_idx, chr_idx + 1].assign(\r\n            tf.constant(2, dtype=tf.float32))\r\n        \r\n        return idx + 1\r\n```\r\nI wanted to put `2` into the position `[chr_idx, chr_idx + 1]` of my `adjacency_map` Variable, based on the values in `double_bond_idxs`. Would `tf.while_loop` in this case be appropriate? Or to be more general, what would be the best way to put values in a matrix variable at certain positions?\r\n\r\nThanks!\r\n\r\nAlso, when I don't put my function under `@tf.contrib.eager.defun` it worked fine, and had my desired property, but just slower. ", "More efficient to use something like `scatter_nd_update`:\r\n\r\n```\r\nv = tf.Variable(tf.ones([5, 5]))\r\nindices = tf.tile(tf.range(tf.shape(v)[0])[:, tf.newaxis], [1, 2])\r\nvalues = tf.tile([2.], [tf.shape(v)[0]])\r\nv.scatter_nd_update(indices, values)\r\n```\r\n\r\nThat'd set the diagonal, but you can change `indices` to be whatever you want.\r\n", "Thanks! But is there a way to modify an object multiple times using a `tf.while_loop` under `@tf.distribution.eager.defun`?", "something like this:\r\n\r\n```\r\n@tf.contrib.eager.defun\r\ndef fn():\r\n    counter = tf.Variable(0, dtype=tf.int32)\r\n    \r\n    idx = 0\r\n    max_iter = 5\r\n    \r\n    def loop_body(idx):\r\n        counter = counter + 1\r\n        return idx + 1\r\n    \r\n    tf.while_loop(\r\n        lambda idx: idx < max_iter,\r\n        lambda idx: loop_body(idx),\r\n        [idx]\r\n        )\r\n    \r\n    print(counter)\r\n    \r\n    \r\nfn()\r\n```\r\n\r\nnote that this works fine if there's no `@tf.contrib.eager.defun`", "You can use `variable.assign` in the loop body, just add a control dependency to one of the loop outputs.", "@yuanqing-wang : Did you get chance to try @allenlavoie's suggestion. Please let us know. Thanks!", "@achandraa yes, it works, but control dependency is indeed needed.", "@yuanqing-wang : Good to know that it worked for you. We will be happy to help in case you get any other related issues. Thanks! "]}, {"number": 28196, "title": "Fix memory leak in gcs file cache under certain STL versions.", "body": "The memory leak results from using vector<T>::shrink_to_fit() to attempt to\r\nshrink the allocated space to the size used, however, the behavior of\r\nshrink_to_fit() is implemention defined and may not actually shrink the\r\nallocated space. This results in memory leak when Tensorflow is compiled under\r\ncertain compiler versions (e.g. g++ 5.4).\r\n\r\nPiperOrigin-RevId: 245458291", "comments": []}, {"number": 28194, "title": "Cuda driver version is inssufficient for CUDA runtime version", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE 13.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9/7\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\nlinux-xzga:~ # nvidia-smi\r\nWed Apr 10 17:49:28 2019\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.116 Driver Version: 390.116 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r\n|===============================+======================+======================|\r\n| 0 GeForce GT 720 Off | 00000000:02:00.0 N/A | N/A |\r\n| N/A 53C P0 N/A / N/A | 161MiB / 977MiB | N/A Default |\r\n+-------------------------------+----------------------+----------------------+\r\n| 1 Tesla K40c Off | 00000000:03:00.0 Off | 0 |\r\n| 29% 62C P0 65W / 235W | 220MiB / 11441MiB | 0% Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes: GPU Memory |\r\n| GPU PID Type Process name Usage |\r\n|=============================================================================|\r\n| 0 Not Supported |\r\n| 1 3389 C /opt/anaconda2/envs/tf-gpu/bin/python 69MiB |\r\n| 1 21633 C /opt/anaconda2/envs/tf-gpu/bin/python 69MiB |\r\n| 1 26550 C /opt/anaconda2/envs/tf-gpu/bin/python 69MiB |\r\n+-----------------------------------------------------------------------------+\r\n~ #", "comments": ["Please have a look on this [link](https://developer.nvidia.com/cuda-toolkit-archive) and let us know if that helps. Thanks!"]}, {"number": 28193, "title": "Use \"tf-estimator-nightly\" instead of \"tensorflow_estimator\"", "body": "", "comments": []}, {"number": 28192, "title": "tf.fft2d not working properly for complex64 data", "body": "**System information**\r\n- Windows 7\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): print(tensorflow.GIT_VERSION, tensorflow.VERSION)\r\nb'unknown' 1.13.1\r\n- Python version: 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\r\n- CUDA 10, cudnn 64_10\r\n- GPU model and memory: Titan X pascal\r\n\r\n**Describe the current behavior**\r\n\r\nfft2d produces non-sensical results on complex64 datatype. (also verified complex128 broken)\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\nimport numpy as np\r\nimport scipy as sp\r\nimport scipy.fftpack\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\n#===================================================================================================\r\n# Generate data\r\nslc = sp.misc.face(gray=True).astype('float32')\r\nslc = (slc + 1j*slc)[0:256, 0:256]\r\ntileSize = slc.shape[0]\r\n\r\n#===================================================================================================\r\nfreqImg = np.fft.fft2(slc)\r\n\r\n#===================================================================================================\r\n# Now do this in keras/tf\r\ninput1 = tf.keras.layers.Input(shape=(tileSize, tileSize, 1), dtype='complex128')\r\nout = tf.keras.layers.Lambda(lambda x:tf.spectral.fft2d(x))(input1)\r\nmodel = tf.keras.models.Model(input1, out)\r\nfreqImg_tf = model.predict(slc[None,:,:,None])\r\n\r\nplt.figure(); plt.imshow(np.log(np.abs(freqImg)+1)); plt.title('sp')\r\nplt.figure(); plt.imshow(np.log(np.abs(freqImg_tf[0,:,:,0])+1)); plt.title('keras'); plt.show()\r\n\r\n#===================================================================================================\r\n# Plots\r\n\r\n\r\n\r\n\r\nprint('done')\r\n```", "comments": ["I think fft2 might only be doing a column fft instead of a 2d fft (think batch fft on columns in CPU-land).  See the hack below for \"fix\" (I do fft2d then a transpose, then another fft2d, and then finally another tranpose:\r\n\r\n```\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\nimport numpy as np\r\nimport scipy as sp\r\nimport scipy.fftpack\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\n#===================================================================================================\r\n# Generate data\r\nslc = sp.misc.face(gray=True).astype('float32')\r\nslc = (slc + 1j*slc)[0:256, 0:256]\r\ntileSize = slc.shape[0]\r\n\r\n#===================================================================================================\r\nfreqImg = np.fft.fft2(slc)\r\n\r\n#===================================================================================================\r\n# Now do this in keras/tf\r\ninput1 = tf.keras.layers.Input(shape=(tileSize, tileSize, 1), dtype='complex128')\r\nprint(input1)\r\nout = tf.keras.layers.Lambda(lambda x:tf.transpose(tf.fft2d(tf.transpose(tf.fft2d(x), perm=(0,2,1,3))), perm=(0,2,1,3)))(input1)\r\nmodel = tf.keras.models.Model(input1, out)\r\nfreqImg_tf = model.predict(slc[None,:,:,None])\r\n\r\n# Check mag\r\nplt.figure(); plt.imshow(np.log(np.abs(freqImg)+1)); plt.title('np')\r\nplt.figure(); plt.imshow(np.log(np.abs(freqImg_tf[0,:,:,0])+1)); plt.title('keras'); \r\n\r\n# Check phase\r\nplt.figure(); plt.imshow(np.angle(freqImg)); plt.title('np - phase')\r\nplt.figure(); plt.imshow(np.angle(freqImg_tf[0,:,:,0])); plt.title('keras - phase'); \r\n\r\n\r\nplt.show()\r\n\r\n#===================================================================================================\r\n# Plots\r\n\r\n\r\n\r\n\r\nprint('done')\r\n\r\n```\r\n\r\nSpecial thank to John McKay for help with analyzing this bug.", "Thanks for the report and the code example! \r\n\r\n`tf.signal.fft2d` operates on the inner-most 2 dimensions of the provided tensor. It looks like the tensor you are providing is rank 4, with shape `[batch, tileSize, tileSize, 1]`, so the FFT is over`[tileSize, 1]` matrices, which there are `batch * tileSize` of. This explains why you're seeing only one axis being transformed. The FFT over the length 1 axis is a no-op, so it's effectively a 1D FFT.\r\n\r\nHere is a [Colab notebook](https://colab.research.google.com/drive/1vm3_GydusmRL5Y_7CeISunAqgLzmp0eK) with a fix to your code example (remove the inner-most dimension). I realize you're probably using the layout `[batch, height, width, channels]` because that's what the TF conv ops use (`NHWC` layout), and I'm sorry for the confusion, but the FFT ops don't assume that layout. We follow `numpy.fft` convention and operate on the inner-most N axes for an N-D FFT (and unfortunately we don't support an axis argument for FFTs yet).", "Hi @rryan, the documentation states the fft2 operates on the innermost dimensions, so wouldn't that be [tileSize, tileSize]?  I can only think that our definition of \"innermost\" is different.  \r\n\r\nThanks for the fix and explanation.  Perhaps the documentation should be updated?  (i found it hard to believe when I googled for this problem that no one else had this issue.)  I didnt think to cross check it with numpy.fft -- good idea.  In any case, I'll update my code tomorrow and ensure the fix works.  Thank you.", "@isaacgerg it sounds like we have a terminology difference then! TensorFlow shapes are generally described as `[outermost, outer, middle, inner, innermost]`, so innermost 2 dimensions refers to `[inner, innnermost]` for that example. It looks like you think of inner-most in terms of distance to `middle`? ", "@rryan  Correct."]}, {"number": 28191, "title": "[INTEL MKL] Added quint8 output type in RequantizePerChannelOp", "body": "A previous PR missed quint8 data-type registration for RequantizePerChannelOp. This is required for MobileNet and SSD-MobileNet.", "comments": []}, {"number": 28190, "title": "Three cherrypicks", "body": "- Add tf.compat.v1.all_v2_summary_ops() for TF 2.0 legacy graph users\r\n- Leave GPU options untouched on CPU only setups\r\n- Undo failed attempts at including kissfft\r\n", "comments": []}, {"number": 28189, "title": "[ROCm] Fix for the broken `--config=rocm` build.", "body": "The `--config=rocm` build was broken by the following commit.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/9b10284509bda0212e9d7eb7f797ad1b1ed63280\r\n\r\nThe changes made by the above commit were incomplete for the ROCm platform. This update fills in the missing gaps to complete the ROCm functionality associated with the commit above amd make the `--config=rocm` build working again.\r\n\r\n-----------------------------\r\n\r\n@tatianashp , @whchung just FYI\r\n\r\nPlease approve and merge. The changes here are trivial and only applicable for the `--config=rocm` build.\r\n\r\nthanks", "comments": []}, {"number": 28188, "title": "Three cherrypicks", "body": "- Add tf.compat.v1.all_v2_summary_ops() for TF 2.0 legacy graph users\r\n- Leave GPU options untouched on CPU only setups\r\n- Undo failed attempts at including kissfft\r\n", "comments": ["Merged the v2_summary_ops change differently since contrib_layers_layer_norm_comment is not available in the 1.14 branch. I was not able to update this PR, created another one (hopefully the last one): https://github.com/tensorflow/tensorflow/pull/28190"]}, {"number": 28187, "title": "Three cherrypicks", "body": "- Add tf.compat.v1.all_v2_summary_ops() for TF 2.0 legacy graph users\r\n- Leave GPU options untouched on CPU only setups\r\n- Undo failed attempts at including kissfft\r\n", "comments": ["Replaced by https://github.com/tensorflow/tensorflow/pull/28188"]}, {"number": 28186, "title": "padding causal with conv1d gives an error", "body": "\r\n**System information**\r\n- I wrote custom code\r\n- System : Linux\r\n- TensorFlow 1.11\r\n- Keras version(embedded in TF) '2.1.6-tf'\r\n\r\nIt seems keras Conv1D (embedded in Tensorflow) does not support 'causal' in Conv1D contrary to what is stated in the class doc string in the code. Here is a simple code to reproduce\r\n\r\n    from tensorflow.python.keras.models import Sequential\r\n    from tensorflow.python.keras.layers import InputLayer\r\n    from tensorflow.python.keras.layers.convolutional import Conv1D\r\n    model = Sequential()\r\n    model.add(InputLayer(name='input_layer', input_shape=(5,3,)))\r\n    model.add(Conv1D(1, kernel_size=1, padding='causal'))\r\n\r\nThis results in the error\r\n\r\n    ValueError: Attr 'padding' of 'Conv2D' Op passed string 'CAUSAL' not in: \"SAME\", \"VALID\".\r\n\r\nAny help please? (please notice I am trying to construct a `Conv1D` layer but the error mentions `Conv2D`", "comments": ["With tensorflow 1.13.1 I am not seeing the issue. Think the issue has been resolved?", " Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28185, "title": "PhasedLSTMCell only accepts 1-dimensional time input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nYes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\r\nDocker image, details below;\r\n```\r\nREPOSITORY              TAG                      IMAGE ID            CREATED             SIZE\r\ntensorflow/tensorflow   latest-gpu-py3-jupyter   8c77abe6b462        8 weeks ago         3.57GB\r\n```\r\n\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n\r\n- TensorFlow version (use command below):\r\nGit Version: v1.13.1-0-g6612da8951\r\nVersion: 1.13.1\r\n\r\n- Python version:\r\n3.5.2\r\n\r\n- CUDA/cuDNN version:\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:01_CDT_2018\r\nCuda compilation tools, release 10.0, V10.0.130\r\n```\r\n\r\n- GPU model and memory:\r\nNVIDIA GTX 1050 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nWhen passing multi-dimensional time input into a Phased LSTM Cell, I am presented with an arithmetic error;\r\n\r\n```\r\nValueError: Dimensions must be equal, but are 6 and 256 for 'test/rnn/sub' (op: 'Sub') with input shapes: [?,6], [256].\r\n```\r\n\r\nThis appears to be caused by the following line in `rnn_cell.py`, which seems to make the assumption that `time` has one dimension;\r\n\r\n```\r\n~usr/local/lib/python3.5/dist-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py in _get_cycle_ratio(self, time, phase, period)\r\n   1965     phase_casted = math_ops.cast(phase, dtype=time.dtype)\r\n   1966     period_casted = math_ops.cast(period, dtype=time.dtype)\r\n-> 1967     shifted_time = time - phase_casted\r\n   1968     cycle_ratio = self._mod(shifted_time, period_casted) / period_casted\r\n   1969     return math_ops.cast(cycle_ratio, dtype=dtypes.float32)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nLSTM computes phases and `shifted_time` for *each* parameter separately (in this case, this would require `shifted_time` and other relevant variables to be the same size as the number of features in the input - e.g. 6 input features implies that `shifted_time` should be a 6-dimensional vector)\r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.utils import Sequence\r\n\r\nfrom tensorflow.keras.layers import (\r\n    RNN,\r\n    Input,\r\n    Dense\r\n)\r\n\r\nfrom tensorflow.contrib.rnn import PhasedLSTMCell\r\n\r\nK.clear_session()\r\n\r\nwith tf.variable_scope('test', reuse=tf.AUTO_REUSE):\r\n    t_series_dim = 6\r\n    output_dim = 1\r\n\r\n    # Inputs here\r\n    timestamps = Input(shape=(None, t_series_dim,), name='t_input')\r\n    feature_signals = Input(shape=(None, t_series_dim,), name='ts_input')\r\n\r\n    # Layer configuration\r\n    ## Time-series input\r\n    time_input = (timestamps, feature_signals)\r\n    \r\n    cell = PhasedLSTMCell(256)\r\n    ts_x = RNN(cell, return_sequences=False)(time_input)\r\n    \r\n    # Output layer\r\n    logits = Dense(output_dim, name='logits', activation='sigmoid')(ts_x)\r\n\r\n    # Stick it all together inside a model...\r\n    model = Model(\r\n        inputs=[timestamps, feature_signals],\r\n        outputs=[logits]\r\n    )\r\n\r\n    # Define an optimiser and metrics, and compile the model\r\n    model.compile(\r\n        optimizer='adam',\r\n        loss=['binary_crossentropy'],\r\n        metrics=['binary_accuracy']\r\n    )\r\n```\r\n\r\n**Other info / logs**\r\n\r\nTo give you some context, I have several sensors generating signals at uneven sample rates. For example, \"sensor 1\" reports at a frequency of 2Hz, while others may range up to 16Hz. Each of these features has their own time stamps (e.g. the first 5 time stamps for \"sensor 1\" at 2Hz would be something like [0.0, 0.5, 1.0, 1.5, 2.0] - while \"sensor 2\" at 8Hz would be something like [0.0, 0.125, 0.25, 0.375, 0.5]) so it's more helpful to provide each individual feature's timestamps alongside the feature.\r\n\r\nI'm not sure if I am describing this adequately. Please ask for clarification if required!", "comments": ["@newey01c  I could reproduce the issue with TF1.13.1. Thanks!", "From the docstring in the call() method of PhasedLSTMCell, its quite clear that its expecting two tensor, and the shape are (batch, 1) and (batch, features_size). So the timestamps input in your code snippet is actually not correct. The shape of that should be\r\n```python\r\n timestamps = Input(shape=(None, 1), name='t_input')\r\n```", "@qlzh727 you are correct. However, in the case of several inputs with vastly different sample rates (e.g. imagine 2 sensors; one with 1000Hz sample rate, and the other with 2.5Hz) that doesn't seem a particularly efficient strategy. Obviously this is an exaggerated scenario but it's illustrative - to jointly train a Phased LSTM on outputs from these sensors, one would need to essentially stretch the 2.5Hz sample tensor to the same dimensions as the 1000Hz, so that the same time tensor can be used to represent both inputs.\r\n\r\nIf it's worthwhile, I'm happy to try and develop an alternative implementation (so that users can provide a time tensor for each input). What are your thoughts as to the performance implications of this?", "I haven't dig deep into the paper yet, but we are no long releasing contrib in Tensorflow 2.0, the change you are about to make will probably never get released anymore.\r\n\r\nHaving said that, if you would like to contribute the change, you can make the updated cell to tensorflow/addons repository, which is the new github repository for extended APIs.", "Contrib has been depreciated here in Tensorflow repo and moved to tensorflow/addons , please reopen the issue in https://github.com/tensorflow/addons/issues if this exists in latest version. Thank you"]}, {"number": 28184, "title": "Tensorflow v1.13.1 CUDA Compilation fails on Windows 10", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v1.13.1\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: 7.5.1\r\n- GPU model and memory: GeForce GTX1080 8Gb\r\n\r\n**Describe the problem**\r\n\r\nTensorflow fails to build when configured to use CUDA\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- Installed Python 3.7.0\r\n\t- With pip as optional feature\r\n\t- Adding Python to environment variables\r\n\r\n- Installed MSYS2\r\n\tpacman -Syu\r\n\tpacman -Su\r\n\tpacman -S git patch unzip\r\n\r\n- Installed Bazel 0.21.0\r\n\t- Downloaded bazel-0.21.0-windows-x86_64.exe\r\n\t- Renamed it to bazel.exe\r\n\t- Moved bazel.exe to C:\\bazel (C:\\bazel\\bazel.exe)\r\n\t- Added C:\\bazel to the user variables PATH\r\n\t- Added C:\\msys64\\usr\\bin to user variables PATH\r\n\t- Added C:\\msys64\\usr\\bin\\bash.exe to a new BAZEL_SH user variable\r\n\r\n- Installed CUDA 10.0\r\n\r\n\t- Downloaded and installed NVIDIA GeForce Experience to install NVIDIA GPU drivers v430.39 on GTX1080 card\r\n\t- Downloaded and installed CUDA Toolkit 10.0 from https://developer.nvidia.com/cuda-toolkit-archive\r\n\t- Downloaded and installed cuDNN SDK 7.5.1 for CUDA 10 from https://developer.nvidia.com/cudnn\r\n\t\t- Downloaded cudnn-10.0-windows10-x64-v7.5.1.10.zip from https://developer.nvidia.com/cudnn\r\n\t\t- Copied cuda\\bin\\cudnn64_7.dll to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\r\n\t\t- Copied cuda\\include\\cudnn.h to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include\r\n\t\t- Copied cuda\\lib\\x64\\cudnn.lib to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\lib\\x64\r\n\t\t- Checked CUDA_PATH was set to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\r\n\t\t- Added the following paths to the user environment variable PATH\r\n           \t\tC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin\r\n           \t\tC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64\r\n          \t\tC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include\r\n           \t\tC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\r\n\r\n- Installed Tensorflow dependencies\r\n\r\n\tpip3 install six numpy wheel\r\n\tpip3 install keras_applications==1.0.6 --no-deps\r\n\tpip3 install keras_preprocessing==1.0.5 --no-deps\r\n\r\n- Downloaded and configured Tensorflow v.1.13.1 for CUDA support\r\n\r\n\tgit clone https://github.com/tensorflow/tensorflow.git\r\n\tcd tensorflow\r\n    \tgit checkout r1.13\r\n\tcd tensorflow\r\n\tbazel clean\r\n\tpython ./configure.py\r\n\r\n\tWhen prompted \u201cDo you wish to build TensorFlow with CUDA support?\u201d selected \u201cy\u201d\r\n\tWhen prompted to specify the CUDA compute capabilitied, specified 3.5,6.1 (for GeForce GTX1080)\r\n\r\n- Build command that fails\r\n\r\n\tbazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\t\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nThe following file contains the configure step of Tensorflow and the console log of the build command that fails for me:\r\n\r\n[2019.04.26_tensorflow_1.13.1_cuda10_build_error_windows10.txt](https://github.com/tensorflow/tensorflow/files/3121627/2019.04.26_tensorflow_1.13.1_cuda10_build_error_windows10.txt)\r\n\r\n\r\n", "comments": ["@MiguelAlgaba As per the [link](https://www.tensorflow.org/install/source_windows#gpu) , TF 1.13.1 supports python 3.5 - 3.6 and try to install relevant Bazel,CUDA and cuDNN components. Please let us know how it progresses. Thanks!", "I have been having issues building this.  From github repo; and I'm not sure if it's exactly the same issue...\r\n\r\n```\r\nM:\\javascript\\tensorflow\\node_modules\\@tensorflow\\tfjs-node\\deps\\tensorflow>bazel build --config=opt tensorflow/tools/pip_package:build_pip_package\r\nWARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.\r\nINFO: Build options --action_env and --python_path have changed, discarding analysis cache.\r\nINFO: Repository 'cython' used the following cache hits instead of downloading the corresponding file.\r\n * Hash 'bccc9aa050ea02595b2440188813b936eaf345e85fb9692790cecfe095cf91aa' for http://mirror.tensorflow.org/github.com/cython/cython/archive/0.28.4.tar.gz\r\nIf the definition of 'cython' was updated, verify that the hashes were also updated.\r\nERROR: C:/general/work3/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Tracebac\r\nk (most recent call last):\r\n        File \"C:/general/work3/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/py/python_configure.bzl\", line 344\r\n                _create_local_python_repository(repository_ctx)\r\n        File \"C:/general/work3/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/py/python_configure.bzl\", line 292, in _create_local_python_repo\r\nsitory\r\n                _check_python_bin(repository_ctx, python_bin)\r\n        File \"C:/general/work3/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/py/python_configure.bzl\", line 234, in _check_python_bin\r\n                _fail((\"--define %s='%s' is not execut...)))\r\n        File \"C:/general/work3/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/py/python_configure.bzl\", line 27, in _fail\r\n                fail((\"%sPython Configuration Error:%...)))\r\nPython Configuration Error: --define PYTHON_BIN_PATH='C:/tools/Python27/python.exe' is not executable. Is it the python binary?\r\n and referenced by '//third_party/py/numpy:headers'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 7.875s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (267 packages loaded, 4593 targets configured)\r\n    currently loading: tensorflow/lite/schema\r\n```\r\n\r\nWhich is really just\r\n\r\n```\r\nPython Configuration Error: --define PYTHON_BIN_PATH='C:/tools/Python27/python.exe' is not executable. Is it the python binary?\r\n```\r\n\r\n\r\n``` py\r\ndef _check_python_bin(repository_ctx, python_bin):\r\n    \"\"\"Checks the python bin path.\"\"\"\r\n    cmd = '[[ -x \"%s\" ]] && [[ ! -d \"%s\" ]]' % (python_bin, python_bin)\r\n    result = repository_ctx.execute([_get_bash_bin(repository_ctx), \"-c\", cmd])\r\n    if result.return_code == 1:\r\n        _fail(\"--define %s='%s' is not executable. Is it the python binary?\" % (\r\n            _PYTHON_BIN_PATH,\r\n            python_bin,\r\n        ))\r\n```\r\n\r\nI don't think [[-x]] works in command prompt... was there some bash shell I missed having to use?\r\n\r\n\r\ntensorflow\\third_party\\py\\python_configure.bzl\r\n\r\n```\r\n    python_bin = _get_python_bin(repository_ctx)\r\n---    _check_python_bin(repository_ctx, python_bin)\r\n+++    #_check_python_bin(repository_ctx, python_bin)\r\n    python_lib = _get_python_lib(repository_ctx, python_bin)\r\n---    _check_python_lib(repository_ctx, python_lib)\r\n+++    #_check_python_lib(repository_ctx, python_lib)\r\n\r\n```\r\n\r\nNow I get up to it's truing to run patch with c:\\windows\\system32\\bash.exe which is a WSL image that can't change directory to ....\r\n\r\n```\r\nNon-zero return code(2) when executing 'C:\\WINDOWS\\system32\\bash.exe -l -c \"patch\" \"-p1\" \"-d\" \"C:/users/panther/_bazel_panther/7dujpcn3/external/png_archive\" \"-i\" \"C:/general/work3\r\n/javascript/tensorflow/node_modules/@tensorflow/tfjs-node/deps/tensorflow/third_party/png_fix_rpi.patch\"':\r\nStdout:\r\nStderr: patch: **** Can't change to directory C:/users/panther/_bazel_panther/7dujpcn3/external/png_archive : No such file or directory\r\n and referenced by '//tensorflow/tools/pip_package:licenses'\r\n```", "@MiguelAlgaba Were able to resolve the issue? Thanks!", "Also, note that there is now a Tensorflow 1.13.2 release which might have the build issue solved.", "(I was able to solve the `python.exe' is not executable. Is it the python binary?` issue by running the `bazel build` command from git Bash instead of Powershell.)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28183, "title": "Replacing keras by tensorflow.python.keras causes AttributeError: 'ThreadsafeIterator' object has no attribute 'shape'", "body": "System information\r\n- OS Platform and Distribution (Windows 10 64bit):\r\n- TensorFlow installed from (pip):\r\n- TensorFlow version (1.13.1):\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: RTX 2060 6GB\r\n- Keras 2.2.4\r\n\r\nUsing PyCharm.\r\n\r\n**Describe the problem.**\r\nWhen I try my model with keras and tensorflow.python.keras I found difference.\r\nThe model on keras works but when I use tensorflow.python.keras throwing errors:\r\n\r\n`File \"C:\\python36_ver\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1427, in fit_generator\r\n    initial_epoch=initial_epoch)`\r\n`File \"C:\\python36_ver\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 119, in model_iteration\r\n    shuffle=shuffle)`\r\n`File \"C:\\python36_ver\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 399, in convert_to_generator_like\r\n    num_samples = int(nest.flatten(data)[0].shape[0])`\r\n`AttributeError: 'ThreadsafeIterator' object has no attribute 'shape'`\r\n", "comments": ["@bwolfus  In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "I have the same issue. The `generator` passed to `model.fit_generator` is created with code\r\n\r\n```python\r\n@threadsafe_generator\r\ndef generator_x(image_ids, data_dir, batch_size, do_shuffle=True, name=None,\r\n                image_subdir='images', image_suffix='.png', mask_subdir='masks', mask_suffix='.png'):\r\n\r\n    while True:\r\n        # Shuffle the list of images from 'train_ids'\r\n        if do_shuffle:\r\n            ids = shuffle(image_ids)\r\n        else:\r\n            ids = image_ids\r\n\r\n        for start in range(0, len(ids), batch_size):\r\n            x_batch = []\r\n            y_batch = []\r\n            end = min(start + batch_size, len(ids))\r\n            ids_batch = ids[start:end]\r\n            for image_id in ids_batch:\r\n                image_path = os.path.join(data_dir, image_subdir, '%s%s' % (image_id, image_suffix))\r\n                img = imread(image_path)\r\n                # Convert color space, if needed\r\n                img = from_bgr(img, color_space)\r\n\r\n                mask_path = os.path.join(data_dir, mask_subdir, '%s%s' % (image_id, mask_suffix))\r\n                mask = imread(mask_path, cv2.IMREAD_GRAYSCALE)\r\n                mask = np.expand_dims(mask, axis=2)\r\n\r\n                x_batch.append(img)\r\n                y_batch.append(mask)\r\n\r\n            x_batch = np.array(x_batch, np.float32) / 255\r\n            y_batch = np.array(y_batch, np.float32) / 255\r\n            yield x_batch, y_batch\r\n```\r\n\r\nThat generator is passed in tf.keras code to `convert_to_generator_like` that is not able to use it (the error as above).", "Automatically closing due to lack of recent activity from the author. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n@jpsacha Please post a [new issue](https://github.com/tensorflow/tensorflow/issues/new/choose) by filling all the information asked by the template. Thanks!", "This problem still persists"]}, {"number": 28182, "title": "output shape not inferred for slicing operations", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nThis code does not work because slicing doesn't seem to make an attempt to infer output shape. I believe In most cases output shape could be inferred. \r\n\r\n```\r\nx = keras.Input(shape=(32, 32, 3))\r\nx = keras.layers.Conv2D(8, (3,3), padding='same')(x)\r\nslice1 = x[:, :, :, :4]\r\nslice2 = x[:, :, :, 4:]\r\n# slice1 = x[..., :4]  # or, even better, infer output shape with this slice notation\r\n# slice2 = x[..., 4:]  # also should be possible with no API impact\r\n# slice1.set_shape((None, 32, 32, 4))  # shape not inferred, manually set shape\r\n# slice2.set_shape((None, 32, 32, 4))\r\nx = keras.layers.concatenate([slice1, slice2], axis=3)\r\nx = keras.layers.Flatten()(x)\r\nout = keras.layers.Dense(10)(x)\r\n```\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis should be possible with no impact on API. \r\n\r\n**Who will benefit with this feature?**\r\n\r\nI would imagine fairly broad benefit, but probably more benefit to ML researchers and others that are building custom networks. I ran into this when doing my first port to TF2 keras API.\r\n\r\n**Any Other info.**\r\n\r\nHere is traceback for above code:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-10-579a9f498ccc> in <module>\r\n      5 # slice1.set_shape((None, 32, 32, 4))  # shape not inferred, manually set shape\r\n      6 # slice2.set_shape((None, 32, 32, 4))\r\n----> 7 x = keras.layers.concatenate([slice1, slice2], axis=3)\r\n      8 x = keras.layers.Flatten()(x)\r\n      9 out = keras.layers.Dense(10)(x)\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/layers/merge.py in concatenate(inputs, axis, **kwargs)\r\n    686       A tensor, the concatenation of the inputs alongside axis `axis`.\r\n    687   \"\"\"\r\n--> 688   return Concatenate(axis=axis, **kwargs)(inputs)\r\n    689 \r\n    690 \r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    592           # Build layer if applicable (if the `build` method has been\r\n    593           # overridden).\r\n--> 594           self._maybe_build(inputs)\r\n    595           # Explicitly pass the learning phase placeholder to `call` if\r\n    596           # the `training` argument was left unspecified by the user.\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   1711     # Only call `build` if the user has manually overridden the build method.\r\n   1712     if not hasattr(self.build, '_is_default'):\r\n-> 1713       self.build(input_shapes)\r\n   1714     # We must set self.built since user defined build functions are not\r\n   1715     # constrained to set self.built.\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)\r\n    287     # This preserves compatibility with external Keras.\r\n    288     if input_shape is not None:\r\n--> 289       input_shape = convert_shapes(input_shape, to_tuples=True)\r\n    290     output_shape = fn(instance, input_shape)\r\n    291     # Return shapes from `fn` as TensorShapes.\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in convert_shapes(input_shape, to_tuples)\r\n    220 \r\n    221   return map_structure_with_atomic(_is_atomic_shape, _convert_shape,\r\n--> 222                                    input_shape)\r\n    223 \r\n    224 \r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in map_structure_with_atomic(is_atomic_fn, map_fn, nested)\r\n    167     values = nested\r\n    168   mapped_values = [\r\n--> 169       map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\r\n    170   ]\r\n    171   return nest._sequence_like(nested, mapped_values)\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in <listcomp>(.0)\r\n    167     values = nested\r\n    168   mapped_values = [\r\n--> 169       map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\r\n    170   ]\r\n    171   return nest._sequence_like(nested, mapped_values)\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in map_structure_with_atomic(is_atomic_fn, map_fn, nested)\r\n    156   \"\"\"\r\n    157   if is_atomic_fn(nested):\r\n--> 158     return map_fn(nested)\r\n    159 \r\n    160   # Recursively convert.\r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/keras/utils/tf_utils.py in _convert_shape(input_shape)\r\n    216     input_shape = tensor_shape.TensorShape(input_shape)\r\n    217     if to_tuples:\r\n--> 218       input_shape = tuple(input_shape.as_list())\r\n    219     return input_shape\r\n    220 \r\n\r\n~/venvs/lidar_nnfusion/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in as_list(self)\r\n   1126     \"\"\"\r\n   1127     if self._dims is None:\r\n-> 1128       raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n   1129     return [dim.value for dim in self._dims]\r\n   1130 \r\n\r\nValueError: as_list() is not defined on an unknown TensorShape.\r\n```", "comments": ["@pat-coady : Will it be possible to provide a small code snippet which can give us more information on the feature we are discussing here. Thanks!", "@achandraa - I assume you saw the code snippet in my original request? It is self-contained. The issue is when you do any slicing, the shape information is lost. So you have to manually set the shape before applying additional layers.\r\n\r\nHappy to provide additional examples if there are aspects you'd like clarified.\r\n\r\nOr are you maybe looking for the code that would implement the improved behavior?", "Same issue for me.\r\nA way to overcome this issue is to use tf.slice (with a Lambda layer for instance). But I'm willing to have this feature directly with a classical \"numpy\" slice!", "@pat-coady -- this is a general shortfall of slicing, as we cannot retain static shape information after slicing. You can create a custom layer that does the slicing inside of its .call() method, and this should work-- can you try putting this inside a custom layer or Lambda layer?", "@karmel -- Could a StridedSlice class (subclass of Layer) be created? Then strided_slice would just be a functional interface to this. ", "Been using TF2 for another couple months. OK without this feature.", "Will TF2 not be adding the numpy style slicing feature then?"]}, {"number": 28181, "title": "TF 2.0 tf.summary.scalar claiming it sees a whole tensor when fed scalar", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): My script is included below.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16\r\n- TensorFlow installed from (source or binary): conda environment with pip install tensorflow==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0. I also, just to check, ran pip install --upgrade tb-nightly I believe on the 25th.\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: NO GPU USED\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I run the simple MNIST script below (with the tf.summary.scalar line commented out) it runs fine. When I try to log a scalar inside Model.call() I get an error message that seems to indicate tf.summary.scalar is seeing the original tensor--somehow--as opposed to the numpy-summed result that I am passing to tf.summary.scalar.\r\n\r\n**Describe the expected behavior**\r\n\r\nAccording to https://www.tensorflow.org/tensorboard/r2/scalars_and_keras, this would appear to be the way to log scalar values in Tensorboard 2.0. Am I incorrect?\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCode:\r\n\r\n`\r\n```\r\n\"\"\"\r\nLearn the very basics by running MNIST in TF 2.0\r\n\"\"\"\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers\r\nimport numpy as np\r\nimport datetime\r\nL2_REG = 0.0000001\r\nLEARN_RATE = 1e-5\r\nNUM_LABELS = 10\r\n\r\n\r\nclass MyFirstConvnet(tf.keras.Model):\r\n    def __init__(self):\r\n        super(MyFirstConvnet, self).__init__()\r\n        self.layer1 = layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2_REG))\r\n        self.layer2 = layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2_REG))\r\n        self.pool = layers.MaxPooling2D((2, 2))\r\n        self.layer3 = layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(L2_REG))\r\n        self.flatten = layers.Flatten()\r\n        self.classifier = layers.Dense(NUM_LABELS, activation='softmax')\r\n        self.batchnorm1 = layers.BatchNormalization(scale=False)\r\n        self.batchnorm2 = layers.BatchNormalization(scale=False)\r\n\r\n    def call(self, inputs):\r\n        x = self.batchnorm1(self.layer1(inputs))\r\n        x = self.layer2(x)\r\n        tf.summary.scalar('layer_2_activation_sum', data=np.sum(x, axis=None))  # ERROR THROWN HERE\r\n        x = self.batchnorm2(self.pool(x))\r\n        x = self.layer3(x)\r\n        x = self.flatten(x)\r\n        return self.classifier(x)\r\n\r\n\r\nif __name__ == '__main__':\r\n    # load up MNIST\r\n    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\r\n    train_images = train_images.reshape((60000, 28, 28, 1)).astype(np.float32)/255.0\r\n    test_images = test_images.reshape((10000, 28, 28, 1)).astype(np.float32)/255.0\r\n\r\n    # model must be 'compiled' which integrates information about training and stores it in the model structure\r\n    model = MyFirstConvnet()\r\n    optimizer = tf.keras.optimizers.Adam(lr=LEARN_RATE)\r\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n\r\n    # set up tensorboard\r\n    logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n    file_writer = tf.summary.create_file_writer(logdir)\r\n    file_writer.set_as_default()\r\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\r\n\r\n    # train\r\n    model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.05, shuffle=True,\r\n              callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\r\n                         tensorboard_callback])\r\n\r\n    # test\r\n    model.evaluate(test_images, test_labels, verbose=1)\r\n```\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nError message:\r\n\r\n> 2019-04-26 08:41:48.064844: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-04-26 08:41:48.089158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394490000 Hz\r\n2019-04-26 08:41:48.090339: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55b1385baf40 executing computations on platform Host. Devices:\r\n2019-04-26 08:41:48.090379: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\r\nTraceback (most recent call last):\r\n  File \"hello_mnist.py\", line 55, in <module>\r\n    tensorboard_callback])\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 806, in fit\r\n    shuffle=shuffle)\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2503, in _standardize_user_data\r\n    self._set_inputs(cast_inputs)\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\", line 456, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2775, in _set_inputs\r\n    outputs = self.call(inputs)\r\n  File \"hello_mnist.py\", line 28, in call\r\n    tf.summary.scalar('layer_2_activation_sum', data=np.sum(x, axis=None))  # ERROR THROWN HERE\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorboard/plugins/scalar/summary_v2.py\", line 61, in scalar\r\n    tf.debugging.assert_scalar(data)\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py\", line 1718, in assert_scalar_v2\r\n    assert_scalar(tensor=tensor, message=message, name=name)\r\n  File \"/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py\", line 1751, in assert_scalar\r\n    % (message or '', tensor.name, shape))\r\nValueError: Expected scalar shape for conv2d_1/Relu:0, saw shape: (None, 24, 24, 64).\r\n\r\n\r\n", "comments": ["@CJMenart Able to reproduce the issue with the code provided, attached the log.\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-4-241886290bee> in <module>()\r\n     50     model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.05, shuffle=True,\r\n     51               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\r\n---> 52                          tensorboard_callback])\r\n     53 \r\n     54     # test\r\n\r\n7 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py in assert_scalar(tensor, name, message)\r\n   1749       else:\r\n   1750         raise ValueError('%sExpected scalar shape for %s, saw shape: %s.'\r\n-> 1751                          % (message or '', tensor.name, shape))\r\n   1752     return tensor\r\n   1753 \r\n\r\nValueError: Expected scalar shape for conv2d_1/Relu:0, saw shape: (None, 24, 24, 64).\r\n\r\n\r\n Request you to reference stackoverflow similar issues [link1](https://stackoverflow.com/questions/49057149/expected-conv2d-1-input-to-have-shape-28-28-1-but-got-array-with-shape-1-2) and [link2](https://stackoverflow.com/questions/50860182/error-when-checking-input-expected-conv2d-1-input-to-have-shape-28-28-1-but/50860463). Hope these helps. This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "@muddham There is nothing wrong with the size of the tensors invovled.\r\n\r\nIf I add the following print statements to call:\r\n\r\n```    \r\ndef call(self, inputs):\r\n        x = self.batchnorm1(self.layer1(inputs))\r\n        x = self.layer2(x)\r\n        print(x)\r\n        print(np.sum(x))\r\n        tf.summary.scalar('layer_2_activation_sum', data=np.sum(x, axis=None))  # ERROR THROWN HERE\r\n        x = self.batchnorm2(self.pool(x))\r\n        x = self.layer3(x)\r\n        x = self.flatten(x)\r\n        return self.classifier(x)\r\n```\r\n\r\nThe same thing is printed twice: \r\n\r\n> Tensor(\"conv2d_1/Relu:0\", shape=(None, 24, 24, 64), dtype=float32)\r\nTensor(\"conv2d_1/Relu:0\", shape=(None, 24, 24, 64), dtype=float32)\r\n\r\nThat should not be possible. np.sum() should not be passing back a Tensor object. The issue is that tf.summary.scalar is talking about tensors by name at all when, supposedly, all it is being given is a numpy scalar.\r\n\r\nThe following snippet appears to show the correct behavior:\r\n\r\n```\r\nconst = tf.constant([3,3], dtype=tf.float32)\r\nnp.sum(const)\r\n```\r\n>6.0\r\n\r\nSo my only guess is that something is going wrong involving Model.call().", "@CJMenart Could reproduce the issue.Log shows as below.\r\n\r\nTensor(\"conv2d_1/Relu:0\", shape=(None, 24, 24, 64), dtype=float32)\r\nTensor(\"conv2d_1/Relu:0\", shape=(None, 24, 24, 64), dtype=float32)", "@CJMenart is correct; the model.call is incorrect.\r\n\r\nIn this line:\r\n```\r\n        tf.summary.scalar('layer_2_activation_sum', data=np.sum(x, axis=None))  # ERROR THROWN HERE\r\n```\r\nx is a symbolic Tensor. When you call `np.sum`, it retrieves the Tensor `__sum__` attr, which in the case of TensorFlow is the element wise sum. (And the sum of a single element is just an identity) And so `tf.summary.scalar` is correctly telling you that the value you passed is not a scalar. The function that you want is `tf.reduce_sum`. ", "So if I understand correctly what's happened here...model.call was supposed to do things in eager mode; that's what I initially assumed would be the case in 2.0. And in fact, it was supposed to do things in eager mode (in the default case, of course), but it was actually building a graph with symbolic tensors, a la the default method of model construction in 1.x. As such, the output which confused me came from the fact that np.sum is auto-cast to this Tensor attribute when called on a Tensor (which maybe should come with a warning message?). This would also explain why calls to print() only printed output once when my code snippet was run.\r\n\r\nIs that roughly correct? Sorry if this comment re-opens an issue that shouldn't be.", "This is intentional. Even though eager is the default execution mode in TF 2.0, keras defaults to symbolic computation because it is more efficient for the sorts of computation that keras is typically used for. (Namely, the same computation over different data.) You can enable eager execution inside of a layer's call method either on an individual basis (by passing `dynamic=True` to a Layer's constructor) or on a Model level by setting the `run_eagerly` attribute or passing `run_eagerly` to compile.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.enable_v2_behavior()\r\nprint(\"We're in eager mode:   \", tf.random.uniform(shape=(4,)))\r\n\r\nclass LoggingIdentityLayer(tf.keras.layers.Layer):\r\n  \"\"\"A keras layer that prints some stuff.\"\"\"\r\n  \r\n  def call(self, inputs):\r\n    print(\"Inputs to {}: {}\".format(self.name, tf.squeeze(inputs)))\r\n\r\n    return tf.identity(inputs)\r\n    # The base Layer is an identity layer\r\n    return super(LoggingIdentityLayer, self).call(inputs=inputs)\r\n\r\n  def compute_output_shape(self, input_shape):\r\n    return input_shape  # This is an identity layer\r\n\r\nx=np.random.random(size=(16, 1)),\r\ny=np.random.random(size=(16, 1))\r\n\r\ninp = tf.keras.layers.Input(shape=(1,))\r\ndense_results = tf.keras.layers.Dense(1)(inp)\r\nlog_layer = LoggingIdentityLayer()(dense_results)\r\nmodel = tf.keras.models.Model(inp, log_layer)\r\n\r\nmodel.compile(loss=\"mse\", optimizer=\"sgd\")\r\nmodel.fit(x=x, y=x, batch_size=4)\r\nprint()\r\n\r\n# Run the entire model in eager mode:\r\nmodel.compile(loss=\"mse\", optimizer=\"sgd\",\r\n              run_eagerly=True)\r\nmodel.fit(x=x, y=x, batch_size=4)\r\nprint()\r\n\r\n# Only make a certain layer dynamic\r\ndynamic_log_layer = LoggingIdentityLayer(dynamic=True)(dense_results)\r\nmodel_prime = tf.keras.models.Model(inp, dynamic_log_layer)\r\nmodel_prime.compile(loss=\"mse\", optimizer=\"sgd\")\r\nmodel_prime.fit(x=x, y=x, batch_size=4)\r\n```"]}, {"number": 28180, "title": "fix typo in contrib.quantize comments", "body": "", "comments": []}, {"number": 28179, "title": "Lite: Batch_to_space-ND support", "body": "Arbitrary dimension support added.\r\n\r\nAdd ref: #21526", "comments": ["See also https://github.com/tensorflow/tensorflow/pull/27867. Once we confirm these 2 PRs unblock the model execution, we can proceed.", "@ANSHUMAN87 Can you please resolve conflicts? Thanks!", "@gbaned : The conflict is resolved, would you please help get it reviewed and merged, Thanks!", "> See also #27867. Once we confirm these 2 PRs unblock the model execution, we can proceed.\r\n\r\nThanks for the contribution, @ANSHUMAN87 \r\nAny reply to jdduke's previous comment?\r\n", "> > See also #27867. Once we confirm these 2 PRs unblock the model execution, we can proceed.\r\n> \r\n> Thanks for the contribution, @ANSHUMAN87\r\n> Any reply to jdduke's previous comment?\r\n\r\n@miaout17 : I have verified, the solution works fine! Please refer #27867 also, both are done together as related. Thanks!", "Can one of the admins verify this patch?", "@ANSHUMAN87 Can you please resolve conflicts? Thanks!", "Resolved!", "@miaout17 Can you please take a look on this PR? Thanks!", "@ANSHUMAN87 Can you please resolve conflicts? Thanks!", "@gbaned : The conflicts are resolved now, Thanks!", "@ANSHUMAN87 Can you please resolve conflicts? Thanks!", "@gbaned : I will resolve the conflicts possibly by Saturday. Thanks!", "@gbaned : The conflicts are resolved now. Thanks!", "As a high-level comment, is it possible to define local variables of type NdArrayDesc<8> instead of introducing new temporary tensors? We are unlikely to support dimensions > 8.", "I found a performance regression with your PR on my Pixel 3.\r\nThe input size is [400,30,30,100 ] and batch_size is [20, 20], crops  is [[1,1],[1,1]].\r\nThe performance before and after your pr:\r\nbefore 57.826ms\r\nafter 99.597ms\r\nCould you double check on performance?", "> I found a performance regression with your PR on my Pixel 3.\r\n> The input size is [400,30,30,100 ] and batch_size is [20, 20], crops is [[1,1],[1,1]].\r\n> The performance before and after your pr:\r\n> before 57.826ms\r\n> after 99.597ms\r\n> Could you double check on performance?\r\n\r\n@thaink : Thanks! I will sure check on it and update you!", "Hey @ANSHUMAN87, we're working on an overhaul for >4D kernel support, so I think it's best if we table this PR for now (and 1 or 2 of the related PRs) as we work toward that end. Thanks for your patience in iterating on this and pushing for generalization, and apologies we couldn't land this more promptly. "]}, {"number": 28178, "title": "TfLite Multithreaded_Conv op don't works as expect", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm trying to compile Tensorflow Lite to WASM for machine learning on Web. But I found the TfLite MultiThread-Conv have some bugs. And my Conv2D test case can't pass when use the WASM version of this op.\r\n\r\nSee the code in [TFLite multithreaded_conv.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/optimized/multithreaded_conv.h):\r\n Since `(Const)EigenMatrix` is defined as `Eigen::RowMajor` Layout, should the code in [here](https://github.com/tensorflow/tensorflow/blob/55e854864fded7318c49daae0b634c5860f3e419/tensorflow/lite/kernels/internal/optimized/multithreaded_conv.h#L101) be\r\n```c\r\ndim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 1);\r\nEigenMatrix output(output_data, input_batches * conv_width, filter_count);\r\nConstEigenMatrix input(input_data, input_batches * conv_width, input_depth);\r\nConstEigenMatrix filter(filter_data, filter_count, input_depth);\r\n```\r\nrather than \r\n```c\r\ndim_pair[0] = Eigen::IndexPair<Eigen::DenseIndex>(1, 0);\r\nEigenMatrix output(output_data, input_batches * conv_width, filter_count);\r\nConstEigenMatrix input(input_data, input_batches * conv_width, input_depth);\r\nConstEigenMatrix filter(filter_data, input_depth, filter_count);\r\n```\r\n\r\nSame issues are in https://github.com/tensorflow/tensorflow/blob/55e854864fded7318c49daae0b634c5860f3e419/tensorflow/lite/kernels/internal/optimized/multithreaded_conv.h#L115 and https://github.com/tensorflow/tensorflow/blob/55e854864fded7318c49daae0b634c5860f3e419/tensorflow/core/kernels/eigen_spatial_convolutions-inl.h#L1482.\r\n\r\nAnd after correcting all the place, all my test case passed.\r\n\r\nIs this a TFLite ops bug?? Or just my test case is not compatible with this operation? \u3000\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n", "comments": ["@Wenzhao-Xiang  It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28177, "title": "no project building", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["@neharika11 Please provide the doc link and context. Thanks!", " Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28176, "title": "TPU + Keras doesn't support multiple input layers", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Google Colab\r\n\r\n**Describe the current behavior**\r\nWhen trying to train a model that has multiple input layers using Keras (eg. CTC) on a TPU, Tensorflow throws an InvalidArgumentError claiming that I didn't feed a value for a placeholder tensor. \r\n\r\n**Describe the expected behavior**\r\nIf I run the exact same model on a GPU, everything works as expected (eg. the model trains).\r\n\r\n**Code to reproduce the issue**\r\nAll code required to reproduce this but can be found on Google Colab:\r\nhttps://colab.research.google.com/drive/1rxKwCfDPS_2GPNN9yWAyQlQZy8Fg3deV\r\n\r\n**Other info / logs**\r\nPossibly related issue: https://github.com/tensorflow/tensorflow/issues/23659\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n13 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1318       return self._call_tf_sessionrun(\r\n-> 1319           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1320 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1406         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1407         run_metadata)\r\n   1408 \r\n\r\nInvalidArgumentError: Combined status information from 9 operations:\r\n\r\nStatus code: Invalid argument [2x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[{{node label}}]] [1x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[{{node label}}]]\r\n  \t [[{{node GroupCrossDeviceControlEdges_0/TPUReplicate/_compile/_11823778269055837323/_17}}]] [1x]\r\n(7 successful operations.)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-5-6495be1fe4ea> in <module>()\r\n      3     x = feed_dict_x,\r\n      4     y = feed_dict_y,\r\n----> 5     batch_size = BATCH_SIZE\r\n      6 )\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1530                                   validation_split, validation_data, shuffle,\r\n   1531                                   class_weight, sample_weight, initial_epoch,\r\n-> 1532                                   steps_per_epoch, validation_steps, **kwargs)\r\n   1533       finally:\r\n   1534         self._numpy_to_infeed_manager_list = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _pipeline_fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1631         initial_epoch=initial_epoch,\r\n   1632         steps_per_epoch=steps_per_epoch,\r\n-> 1633         validation_steps=validation_steps)\r\n   1634 \r\n   1635   def _pipeline_fit_loop(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _pipeline_fit_loop(self, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\r\n   1730             val_sample_weights=val_sample_weights,\r\n   1731             validation_steps=validation_steps,\r\n-> 1732             epoch_logs=epoch_logs)\r\n   1733 \r\n   1734       callbacks.on_epoch_end(epoch, epoch_logs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _pipeline_fit_loop_sample_wise(self, ins, callbacks, index_array, shuffle, batch_size, num_training_samples, indices_for_conversion_to_dense, do_validation, val_inputs, val_targets, val_sample_weights, validation_steps, epoch_logs)\r\n   1786 \r\n   1787       outs = f.pipeline_run(\r\n-> 1788           cur_step_inputs=ins_last_batch, next_step_inputs=ins_batch)\r\n   1789       ins_last_batch = ins_batch\r\n   1790 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in pipeline_run(***failed resolving arguments***)\r\n   1334           next_input_tensors)\r\n   1335       next_tpu_model_ops = self._tpu_model_ops_for_input_specs(\r\n-> 1336           next_input_specs, next_step_infeed_manager)\r\n   1337       infeed_dict = next_infeed_instance.make_feed_dict(next_tpu_model_ops)\r\n   1338 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _tpu_model_ops_for_input_specs(self, input_specs, infeed_manager)\r\n   1169                                                  infeed_manager)\r\n   1170       self._compilation_cache[shape_key] = new_tpu_model_ops\r\n-> 1171       self._test_model_compiles(new_tpu_model_ops)\r\n   1172 \r\n   1173     return self._compilation_cache[shape_key]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _test_model_compiles(self, tpu_model_ops)\r\n   1107     start_time = time.time()\r\n   1108 \r\n-> 1109     result = K.get_session().run(tpu_model_ops.compile_op)\r\n   1110     proto = tpu_compilation_result.CompilationResultProto()\r\n   1111     proto.ParseFromString(result)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    927     try:\r\n    928       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 929                          run_metadata_ptr)\r\n    930       if run_metadata:\r\n    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1150     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1151       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1152                              feed_dict_tensor, options, run_metadata)\r\n   1153     else:\r\n   1154       results = []\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1326     if handle is None:\r\n   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1328                            run_metadata)\r\n   1329     else:\r\n   1330       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1346           pass\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349 \r\n   1350   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Combined status information from 9 operations:\r\n\r\nStatus code: Invalid argument [2x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[node label (defined at <ipython-input-2-85a234430d50>:9) ]] [1x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[node label (defined at <ipython-input-2-85a234430d50>:9) ]]\r\n  \t [[{{node GroupCrossDeviceControlEdges_0/TPUReplicate/_compile/_11823778269055837323/_17}}]] [1x]\r\n(7 successful operations.)\r\n\r\nCaused by op 'label', defined at:\r\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 832, in start\r\n    self._run_callback(self._callbacks.popleft())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\r\n    ret = callback()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\r\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\r\n    self._handle_recv()\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-3-18d98e7a13ff>\", line 4, in <module>\r\n    model = build_training_model(graph)\r\n  File \"<ipython-input-2-85a234430d50>\", line 9, in build_training_model\r\n    label        = Input(name = 'label',        batch_shape = [BATCH_SIZE, MAX_LABEL_LENGTH], dtype = 'int32')\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 231, in Input\r\n    input_tensor=tensor)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 107, in __init__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\", line 876, in placeholder\r\n    x = array_ops.placeholder(dtype, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Combined status information from 9 operations:\r\n\r\nStatus code: Invalid argument [2x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[node label (defined at <ipython-input-2-85a234430d50>:9) ]] [1x]\r\n  You must feed a value for placeholder tensor 'label' with dtype int32 and shape [256,12]\r\n  \t [[node label (defined at <ipython-input-2-85a234430d50>:9) ]]\r\n  \t [[{{node GroupCrossDeviceControlEdges_0/TPUReplicate/_compile/_11823778269055837323/_17}}]] [1x]\r\n(7 successful operations.)\r\n```\r\n\r\nI also tried training the model using `model.fit_generator(...)` and `tf.keras.utils.Sequence`, but the same exception gets thrown.", "comments": ["I was able to reproduce the issue with TF1.13.1. No error when GPU was used but there is an `InvalidArgumentError` when TPU was used. Thanks!", "Is there any workaround for this issue? Really need TPU to save my life\ud83d\ude2d.", "We have improved Keras coverage in the when running a nightly version for your TPU (you'll have to also install tf-nightly in your VM). Also that API is deprecated, and the official usage is here:\r\nhttps://github.com/tensorflow/tpu/tree/master/models/experimental/resnet50_keras\r\n\r\nWe haven't tested everything, so you may run into other issues.", "has anyone solved this issue?", "Hi There,\r\n\r\nWe are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions.we will get you the right help.Thanks!", "@NMAC427 \r\n\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28176\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28176\">No</a>\n"]}, {"number": 28175, "title": "Quantization-aware training Fails", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: One plus 5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):bazel-0.24.0-installer-darwin-x86_64\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nI am referring to https://github.com/tensorflow/tensorflow/issues/20867. I am currently running [Quantization-aware training](https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize) and I have modified my deeplab->train.py file. When I start training using train.py :\r\n```\r\n\r\n# Copyright 2018 The TensorFlow Authors All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\n\"\"\"Training script for the DeepLab model.\r\n\r\nSee model.py for more details and usage.\r\n\"\"\"\r\n\r\nimport six\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import math_ops\r\nfrom deeplab import common\r\nfrom deeplab import model\r\nfrom deeplab.datasets import data_generator\r\nfrom deeplab.utils import train_utils\r\n\r\nflags = tf.app.flags\r\nFLAGS = flags.FLAGS\r\n\r\n# Settings for multi-GPUs/multi-replicas training.\r\n\r\nflags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy.')\r\n\r\nflags.DEFINE_boolean('clone_on_cpu', False, 'Use CPUs to deploy clones.')\r\n\r\nflags.DEFINE_integer('num_replicas', 1, 'Number of worker replicas.')\r\n\r\nflags.DEFINE_integer('startup_delay_steps', 15,\r\n                     'Number of training steps between replicas startup.')\r\n\r\nflags.DEFINE_integer(\r\n    'num_ps_tasks', 0,\r\n    'The number of parameter servers. If the value is 0, then '\r\n    'the parameters are handled locally by the worker.')\r\n\r\nflags.DEFINE_string('master', '', 'BNS name of the tensorflow server')\r\n\r\nflags.DEFINE_integer('task', 0, 'The task ID.')\r\n\r\n# Settings for logging.\r\n\r\nflags.DEFINE_string('train_logdir', None,\r\n                    'Where the checkpoint and logs are stored.')\r\n\r\nflags.DEFINE_integer('log_steps', 10,\r\n                     'Display logging information at every log_steps.')\r\n\r\nflags.DEFINE_integer('save_interval_secs', 1200,\r\n                     'How often, in seconds, we save the model to disk.')\r\n\r\nflags.DEFINE_integer('save_summaries_secs', 600,\r\n                     'How often, in seconds, we compute the summaries.')\r\n\r\nflags.DEFINE_boolean(\r\n    'save_summaries_images', False,\r\n    'Save sample inputs, labels, and semantic predictions as '\r\n    'images to summary.')\r\n\r\n# Settings for profiling.\r\n\r\nflags.DEFINE_string('profile_logdir', None,\r\n                    'Where the profile files are stored.')\r\n\r\n# Settings for training strategy.\r\n\r\nflags.DEFINE_enum('learning_policy', 'poly', ['poly', 'step'],\r\n                  'Learning rate policy for training.')\r\n\r\n# Use 0.007 when training on PASCAL augmented training set, train_aug. When\r\n# fine-tuning on PASCAL trainval set, use learning rate=0.0001.\r\nflags.DEFINE_float('base_learning_rate', .0001,\r\n                   'The base learning rate for model training.')\r\n\r\nflags.DEFINE_float('learning_rate_decay_factor', 0.1,\r\n                   'The rate to decay the base learning rate.')\r\n\r\nflags.DEFINE_integer('learning_rate_decay_step', 2000,\r\n                     'Decay the base learning rate at a fixed step.')\r\n\r\nflags.DEFINE_float('learning_power', 0.9,\r\n                   'The power value used in the poly learning policy.')\r\n\r\nflags.DEFINE_integer('training_number_of_steps', 30000,\r\n                     'The number of steps used for training')\r\n\r\nflags.DEFINE_float('momentum', 0.9, 'The momentum value to use')\r\n\r\n# When fine_tune_batch_norm=True, use at least batch size larger than 12\r\n# (batch size more than 16 is better). Otherwise, one could use smaller batch\r\n# size and set fine_tune_batch_norm=False.\r\nflags.DEFINE_integer('train_batch_size', 8,\r\n                     'The number of images in each batch during training.')\r\n\r\n# For weight_decay, use 0.00004 for MobileNet-V2 or Xcpetion model variants.\r\n# Use 0.0001 for ResNet model variants.\r\nflags.DEFINE_float('weight_decay', 0.00004,\r\n                   'The value of the weight decay for training.')\r\n\r\nflags.DEFINE_multi_integer('train_crop_size', [513, 513],\r\n                           'Image crop size [height, width] during training.')\r\n\r\nflags.DEFINE_float(\r\n    'last_layer_gradient_multiplier', 1.0,\r\n    'The gradient multiplier for last layers, which is used to '\r\n    'boost the gradient of last layers if the value > 1.')\r\n\r\nflags.DEFINE_boolean('upsample_logits', True,\r\n                     'Upsample logits during training.')\r\n\r\n# Hyper-parameters for NAS training strategy.\r\n\r\nflags.DEFINE_float(\r\n    'drop_path_keep_prob', 1.0,\r\n    'Probability to keep each path in the NAS cell when training.')\r\n\r\n# Settings for fine-tuning the network.\r\n\r\nflags.DEFINE_string('tf_initial_checkpoint', None,\r\n                    'The initial checkpoint in tensorflow format.')\r\n\r\n# Set to False if one does not want to re-use the trained classifier weights.\r\nflags.DEFINE_boolean('initialize_last_layer', True,\r\n                     'Initialize the last layer.')\r\n\r\nflags.DEFINE_boolean('last_layers_contain_logits_only', False,\r\n                     'Only consider logits as last layers or not.')\r\n\r\nflags.DEFINE_integer('slow_start_step', 0,\r\n                     'Training model with small learning rate for few steps.')\r\n\r\nflags.DEFINE_float('slow_start_learning_rate', 1e-4,\r\n                   'Learning rate employed during slow start.')\r\n\r\n# Set to True if one wants to fine-tune the batch norm parameters in DeepLabv3.\r\n# Set to False and use small batch size to save GPU memory.\r\nflags.DEFINE_boolean('fine_tune_batch_norm', True,\r\n                     'Fine tune the batch norm parameters or not.')\r\n\r\nflags.DEFINE_float('min_scale_factor', 0.5,\r\n                   'Mininum scale factor for data augmentation.')\r\n\r\nflags.DEFINE_float('max_scale_factor', 2.,\r\n                   'Maximum scale factor for data augmentation.')\r\n\r\nflags.DEFINE_float('scale_factor_step_size', 0.25,\r\n                   'Scale factor step size for data augmentation.')\r\n\r\n# For `xception_65`, use atrous_rates = [12, 24, 36] if output_stride = 8, or\r\n# rates = [6, 12, 18] if output_stride = 16. For `mobilenet_v2`, use None. Note\r\n# one could use different atrous_rates/output_stride during training/evaluation.\r\nflags.DEFINE_multi_integer('atrous_rates', None,\r\n                           'Atrous rates for atrous spatial pyramid pooling.')\r\n\r\nflags.DEFINE_integer('output_stride', 16,\r\n                     'The ratio of input to output spatial resolution.')\r\n\r\n# Hard example mining related flags.\r\n\r\nflags.DEFINE_integer(\r\n    'hard_example_mining_step', 0,\r\n    'The training step in which exact hard example mining kicks off. Note we '\r\n    'gradually reduce the mining percent to the specified '\r\n    'top_k_percent_pixels. For example, if hard_example_mining_step=100K and '\r\n    'top_k_percent_pixels=0.25, then mining percent will gradually reduce from '\r\n    '100% to 25% until 100K steps after which we only mine top 25% pixels.')\r\n\r\n\r\nflags.DEFINE_float(\r\n    'top_k_percent_pixels', 1.0,\r\n    'The top k percent pixels (in terms of the loss values) used to compute '\r\n    'loss during training. This is useful for hard pixel mining.')\r\n\r\n# Dataset settings.\r\nflags.DEFINE_string('dataset', 'pascal_voc_seg',\r\n                    'Name of the segmentation dataset.')\r\n\r\nflags.DEFINE_string('train_split', 'train',\r\n                    'Which split of the dataset to be used for training')\r\n\r\nflags.DEFINE_string('dataset_dir', None, 'Where the dataset reside.')\r\n\r\n\r\ndef _build_deeplab(iterator, outputs_to_num_classes, ignore_label):\r\n  \"\"\"Builds a clone of DeepLab.\r\n\r\n  Args:\r\n    iterator: An iterator of type tf.data.Iterator for images and labels.\r\n    outputs_to_num_classes: A map from output type to the number of classes. For\r\n      example, for the task of semantic segmentation with 21 semantic classes,\r\n      we would have outputs_to_num_classes['semantic'] = 21.\r\n    ignore_label: Ignore label.\r\n  \"\"\"\r\n  samples = iterator.get_next()\r\n\r\n  # Add name to input and label nodes so we can add to summary.\r\n  samples[common.IMAGE] = tf.identity(samples[common.IMAGE], name=common.IMAGE)\r\n  samples[common.LABEL] = tf.identity(samples[common.LABEL], name=common.LABEL)\r\n\r\n  model_options = common.ModelOptions(\r\n      outputs_to_num_classes=outputs_to_num_classes,\r\n      crop_size=FLAGS.train_crop_size,\r\n      atrous_rates=FLAGS.atrous_rates,\r\n      output_stride=FLAGS.output_stride)\r\n\r\n  outputs_to_scales_to_logits = model.multi_scale_logits(\r\n      samples[common.IMAGE],\r\n      model_options=model_options,\r\n      image_pyramid=FLAGS.image_pyramid,\r\n      weight_decay=FLAGS.weight_decay,\r\n      is_training=True,\r\n      fine_tune_batch_norm=FLAGS.fine_tune_batch_norm,\r\n      nas_training_hyper_parameters={\r\n          'drop_path_keep_prob': FLAGS.drop_path_keep_prob,\r\n          'total_training_steps': FLAGS.training_number_of_steps,\r\n      })\r\n\r\n  # Add name to graph node so we can add to summary.\r\n  output_type_dict = outputs_to_scales_to_logits[common.OUTPUT_TYPE]\r\n  output_type_dict[model.MERGED_LOGITS_SCOPE] = tf.identity(\r\n      output_type_dict[model.MERGED_LOGITS_SCOPE], name=common.OUTPUT_TYPE)\r\n\r\n  for output, num_classes in six.iteritems(outputs_to_num_classes):\r\n    train_utils.add_softmax_cross_entropy_loss_for_each_scale(\r\n        outputs_to_scales_to_logits[output],\r\n        samples[common.LABEL],\r\n        num_classes,\r\n        ignore_label,\r\n        loss_weight=1.0,\r\n        upsample_logits=FLAGS.upsample_logits,\r\n        hard_example_mining_step=FLAGS.hard_example_mining_step,\r\n        top_k_percent_pixels=FLAGS.top_k_percent_pixels,\r\n        scope=output)\r\n\r\n    # Log the summary\r\n    _log_summaries(samples[common.IMAGE], samples[common.LABEL], num_classes,\r\n                   output_type_dict[model.MERGED_LOGITS_SCOPE])\r\n\r\n\r\ndef _tower_loss(iterator, num_of_classes, ignore_label, scope, reuse_variable):\r\n  \"\"\"Calculates the total loss on a single tower running the deeplab model.\r\n\r\n  Args:\r\n    iterator: An iterator of type tf.data.Iterator for images and labels.\r\n    num_of_classes: Number of classes for the dataset.\r\n    ignore_label: Ignore label for the dataset.\r\n    scope: Unique prefix string identifying the deeplab tower.\r\n    reuse_variable: If the variable should be reused.\r\n\r\n  Returns:\r\n     The total loss for a batch of data.\r\n  \"\"\"\r\n  with tf.variable_scope(\r\n      tf.get_variable_scope(), reuse=True if reuse_variable else None):\r\n    _build_deeplab(iterator, {common.OUTPUT_TYPE: num_of_classes}, ignore_label)\r\n\r\n  losses = tf.losses.get_losses(scope=scope)\r\n  for loss in losses:\r\n    tf.summary.scalar('Losses/%s' % loss.op.name, loss)\r\n\r\n  regularization_loss = tf.losses.get_regularization_loss(scope=scope)\r\n  tf.summary.scalar('Losses/%s' % regularization_loss.op.name,\r\n                    regularization_loss)\r\n\r\n  total_loss = tf.add_n([tf.add_n(losses), regularization_loss])\r\n  return total_loss\r\n\r\n\r\ndef _average_gradients(tower_grads):\r\n  \"\"\"Calculates average of gradient for each shared variable across all towers.\r\n\r\n  Note that this function provides a synchronization point across all towers.\r\n\r\n  Args:\r\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list is\r\n      over individual gradients. The inner list is over the gradient calculation\r\n      for each tower.\r\n\r\n  Returns:\r\n     List of pairs of (gradient, variable) where the gradient has been summed\r\n       across all towers.\r\n  \"\"\"\r\n  average_grads = []\r\n  for grad_and_vars in zip(*tower_grads):\r\n    # Note that each grad_and_vars looks like the following:\r\n    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\r\n    grads, variables = zip(*grad_and_vars)\r\n    grad = tf.reduce_mean(tf.stack(grads, axis=0), axis=0)\r\n\r\n    # All vars are of the same value, using the first tower here.\r\n    average_grads.append((grad, variables[0]))\r\n\r\n  return average_grads\r\n\r\n\r\ndef _log_summaries(input_image, label, num_of_classes, output):\r\n  \"\"\"Logs the summaries for the model.\r\n\r\n  Args:\r\n    input_image: Input image of the model. Its shape is [batch_size, height,\r\n      width, channel].\r\n    label: Label of the image. Its shape is [batch_size, height, width].\r\n    num_of_classes: The number of classes of the dataset.\r\n    output: Output of the model. Its shape is [batch_size, height, width].\r\n  \"\"\"\r\n  # Add summaries for model variables.\r\n  for model_var in tf.model_variables():\r\n    tf.summary.histogram(model_var.op.name, model_var)\r\n\r\n  # Add summaries for images, labels, semantic predictions.\r\n  if FLAGS.save_summaries_images:\r\n    tf.summary.image('samples/%s' % common.IMAGE, input_image)\r\n\r\n    # Scale up summary image pixel values for better visualization.\r\n    pixel_scaling = max(1, 255 // num_of_classes)\r\n    summary_label = tf.cast(label * pixel_scaling, tf.uint8)\r\n    tf.summary.image('samples/%s' % common.LABEL, summary_label)\r\n\r\n    predictions = tf.expand_dims(tf.argmax(output, 3), -1)\r\n    summary_predictions = tf.cast(predictions * pixel_scaling, tf.uint8)\r\n    tf.summary.image('samples/%s' % common.OUTPUT_TYPE, summary_predictions)\r\n\r\n\r\ndef _train_deeplab_model(iterator, num_of_classes, ignore_label):\r\n  \"\"\"Trains the deeplab model.\r\n\r\n  Args:\r\n    iterator: An iterator of type tf.data.Iterator for images and labels.\r\n    num_of_classes: Number of classes for the dataset.\r\n    ignore_label: Ignore label for the dataset.\r\n\r\n  Returns:\r\n    train_tensor: A tensor to update the model variables.\r\n    summary_op: An operation to log the summaries.\r\n  \"\"\"\r\n  global_step = tf.train.get_or_create_global_step()\r\n  summaries = []\r\n\r\n  learning_rate = train_utils.get_model_learning_rate(\r\n      FLAGS.learning_policy, FLAGS.base_learning_rate,\r\n      FLAGS.learning_rate_decay_step, FLAGS.learning_rate_decay_factor,\r\n      FLAGS.training_number_of_steps, FLAGS.learning_power,\r\n      FLAGS.slow_start_step, FLAGS.slow_start_learning_rate)\r\n  summaries.append(tf.summary.scalar('learning_rate', learning_rate))\r\n # Build forward pass of model.\r\n  loss = tf.losses.get_total_loss()\r\n\r\n# Call the training rewrite which rewrites the graph in-place with\r\n# FakeQuantization nodes and folds batchnorm for training. It is\r\n# often needed to fine tune a floating point model for quantization\r\n# with this training tool. When training from scratch, quant_delay\r\n# can be used to activate quantization after training to converge\r\n# with the float graph, effectively fine-tuning the model.\r\n  g = tf.get_default_graph()\r\n  tf.contrib.quantize.create_training_graph(input_graph=g,\r\n                                          quant_delay=2000000)\r\n\r\n# Call backward pass optimizer as usual.\r\n  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n  optimizer.minimize(loss)\r\n  #optimizer = tf.train.MomentumOptimizer(learning_rate, FLAGS.momentum)\r\n\r\n  tower_grads = []\r\n  tower_summaries = None\r\n  for i in range(FLAGS.num_clones):\r\n    with tf.device('/gpu:%d' % i):\r\n      with tf.name_scope('clone_%d' % i) as scope:\r\n        loss = _tower_loss(\r\n            iterator=iterator,\r\n            num_of_classes=num_of_classes,\r\n            ignore_label=ignore_label,\r\n            scope=scope,\r\n            reuse_variable=(i != 0))\r\n        grads = optimizer.compute_gradients(loss)\r\n        tower_grads.append(grads)\r\n\r\n        # Retain the summaries from the first tower.\r\n        if not i:\r\n          tower_summaries = tf.summary.merge_all(scope=scope)\r\n\r\n  with tf.device('/cpu:0'):\r\n    grads_and_vars = _average_gradients(tower_grads)\r\n    if tower_summaries is not None:\r\n      summaries.append(tower_summaries)\r\n\r\n    # Modify the gradients for biases and last layer variables.\r\n    last_layers = model.get_extra_layer_scopes(\r\n        FLAGS.last_layers_contain_logits_only)\r\n    grad_mult = train_utils.get_model_gradient_multipliers(\r\n        last_layers, FLAGS.last_layer_gradient_multiplier)\r\n    if grad_mult:\r\n      grads_and_vars = tf.contrib.training.multiply_gradients(\r\n          grads_and_vars, grad_mult)\r\n\r\n    # Create gradient update op.\r\n    grad_updates = optimizer.apply_gradients(\r\n        grads_and_vars, global_step=global_step)\r\n\r\n    # Gather update_ops. These contain, for example,\r\n    # the updates for the batch_norm variables created by model_fn.\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    update_ops.append(grad_updates)\r\n    update_op = tf.group(*update_ops)\r\n\r\n    total_loss = tf.losses.get_total_loss(add_regularization_losses=True)\r\n\r\n    # Print total loss to the terminal.\r\n    # This implementation is mirrored from tf.slim.summaries.\r\n    should_log = math_ops.equal(math_ops.mod(global_step, FLAGS.log_steps), 0)\r\n    total_loss = tf.cond(\r\n        should_log,\r\n        lambda: tf.Print(total_loss, [total_loss], 'Total loss is :'),\r\n        lambda: total_loss)\r\n\r\n    summaries.append(tf.summary.scalar('total_loss', total_loss))\r\n\r\n    with tf.control_dependencies([update_op]):\r\n      train_tensor = tf.identity(total_loss, name='train_op')\r\n    summary_op = tf.summary.merge(summaries)\r\n\r\n  return train_tensor, summary_op\r\n\r\n\r\ndef main(unused_argv):\r\n  tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n  tf.gfile.MakeDirs(FLAGS.train_logdir)\r\n  tf.logging.info('Training on %s set', FLAGS.train_split)\r\n\r\n  graph = tf.Graph()\r\n  with graph.as_default():\r\n    with tf.device(tf.train.replica_device_setter(ps_tasks=FLAGS.num_ps_tasks)):\r\n      assert FLAGS.train_batch_size % FLAGS.num_clones == 0, (\r\n          'Training batch size not divisble by number of clones (GPUs).')\r\n      clone_batch_size = FLAGS.train_batch_size // FLAGS.num_clones\r\n\r\n      dataset = data_generator.Dataset(\r\n          dataset_name=FLAGS.dataset,\r\n          split_name=FLAGS.train_split,\r\n          dataset_dir=FLAGS.dataset_dir,\r\n          batch_size=clone_batch_size,\r\n          crop_size=FLAGS.train_crop_size,\r\n          min_resize_value=FLAGS.min_resize_value,\r\n          max_resize_value=FLAGS.max_resize_value,\r\n          resize_factor=FLAGS.resize_factor,\r\n          min_scale_factor=FLAGS.min_scale_factor,\r\n          max_scale_factor=FLAGS.max_scale_factor,\r\n          scale_factor_step_size=FLAGS.scale_factor_step_size,\r\n          model_variant=FLAGS.model_variant,\r\n          num_readers=2,\r\n          is_training=True,\r\n          should_shuffle=True,\r\n          should_repeat=True)\r\n\r\n      train_tensor, summary_op = _train_deeplab_model(\r\n          dataset.get_one_shot_iterator(), dataset.num_of_classes,\r\n          dataset.ignore_label)\r\n\r\n      # Soft placement allows placing on CPU ops without GPU implementation.\r\n      session_config = tf.ConfigProto(\r\n          allow_soft_placement=True, log_device_placement=False)\r\n\r\n      last_layers = model.get_extra_layer_scopes(\r\n          FLAGS.last_layers_contain_logits_only)\r\n      init_fn = None\r\n      if FLAGS.tf_initial_checkpoint:\r\n        init_fn = train_utils.get_model_init_fn(\r\n            FLAGS.train_logdir,\r\n            FLAGS.tf_initial_checkpoint,\r\n            FLAGS.initialize_last_layer,\r\n            last_layers,\r\n            ignore_missing_vars=True)\r\n\r\n      scaffold = tf.train.Scaffold(\r\n          init_fn=init_fn,\r\n          summary_op=summary_op,\r\n      )\r\n\r\n      stop_hook = tf.train.StopAtStepHook(FLAGS.training_number_of_steps)\r\n\r\n      profile_dir = FLAGS.profile_logdir\r\n      if profile_dir is not None:\r\n        tf.gfile.MakeDirs(profile_dir)\r\n\r\n      with tf.contrib.tfprof.ProfileContext(\r\n          enabled=profile_dir is not None, profile_dir=profile_dir):\r\n        with tf.train.MonitoredTrainingSession(\r\n            master=FLAGS.master,\r\n            is_chief=(FLAGS.task == 0),\r\n            config=session_config,\r\n            scaffold=scaffold,\r\n            checkpoint_dir=FLAGS.train_logdir,\r\n            summary_dir=FLAGS.train_logdir,\r\n            log_step_count_steps=FLAGS.log_steps,\r\n            save_summaries_steps=FLAGS.save_summaries_secs,\r\n            save_checkpoint_secs=FLAGS.save_interval_secs,\r\n            hooks=[stop_hook]) as sess:\r\n          while not sess.should_stop():\r\n            sess.run([train_tensor])\r\n\r\n\r\nif __name__ == '__main__':\r\n  flags.mark_flag_as_required('train_logdir')\r\n  flags.mark_flag_as_required('dataset_dir')\r\n  tf.app.run()\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n\r\n### I get the following error:\r\n\r\n> WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\n> For more information, please see:\r\n>   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n>   * https://github.com/tensorflow/addons\r\n> If you depend on functionality not listed there, please file an issue.\r\n> \r\n> INFO:tensorflow:Training on train set\r\n> WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Colocations handled automatically by placer.\r\n> WARNING:tensorflow:From /home/ubuntu/ajinkya/models/research/deeplab/core/preprocess_utils.py:203: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.cast instead.\r\n> Traceback (most recent call last):\r\n>   File \"deeplab/train2.py\", line 516, in <module>\r\n>     tf.app.run()\r\n>   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n>     _sys.exit(main(argv))\r\n>   File \"deeplab/train2.py\", line 468, in main\r\n>     dataset.ignore_label)\r\n>   File \"deeplab/train2.py\", line 348, in _train_deeplab_model\r\n>     loss = tf.losses.get_total_loss()\r\n>   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/losses/util.py\", line 112, in get_total_loss\r\n>     return math_ops.add_n(losses, name=name)\r\n>   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\r\n>     return target(*args, **kwargs)\r\n>   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2658, in add_n\r\n>     raise ValueError(\"inputs must be a list of at least one\"\r\n> ValueError: inputs must be a list of at least oneTensor/IndexedSlices with the same dtype and shape\r\n> \r\nHow do I resolve this error? Its extremely tough to debug whats happening here", "comments": ["@ajinkya933 This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "@ajinkya933 did you solved the issue ??"]}, {"number": 28174, "title": "Tensorflowlite build error for Raspberry pi", "body": "I am trying to build Tensorflow Lite using instructions https://www.tensorflow.org/lite/guide/build_rpi but getting following error.\r\n\r\n**Describe the problem**\r\n**benchmark_tflite_model.cc:(.text+0x53a0): undefined reference to `tflite::evaluation::CreateGPUDelegate(tflite::FlatBufferModel*)'\r\nbenchmark_tflite_model.cc:(.text+0x551e): undefined reference to `tflite::evaluation::CreateNNAPIDelegate()'**\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker image **tensorflow/tensorflow:nightly-devel**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Building for Raspberry Pi using Docker\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.0/Latest\r\n- Python version: Python 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): bazel release 0.15.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCommands defined on https://www.tensorflow.org/lite/guide/build_rpi\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["Passing over to @aselle as a TF Lite RPi issue.", "I verified that this now works after #26336. It worked for me in the docker container cross compiling approach. I then tested on a raspberry pi 4 and no loader error (undefined reference) occurred.", "@Kishwar,\r\nAs per @aselle's comment looks like the issue is fixed. Please feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28174\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28174\">No</a>\n"]}, {"number": 28173, "title": "Tensorflow.org display errors.", "body": "Hello there, something display error with **tensorflow.org** with a bunch of messy.\r\nJust like this.\r\n![image](https://user-images.githubusercontent.com/16497652/56794571-fdfe2e00-6840-11e9-8237-f03d8a8c4743.png)\r\n![image](https://user-images.githubusercontent.com/16497652/56794637-21c17400-6841-11e9-9a46-ea10b982ebf1.png)\r\n\r\n", "comments": ["@Whisht It is strange. I know you are trying to access tutorials page. Tutorials page should look like this https://screenshot.googleplex.com/DMWAtBAQvkx\r\n\r\n1. Could you tell from which region (Asia, Europe, America etc) your are accessing TF website? \r\n2. Are you using Chrome? Could you check the same page using others (IE,Firefox, Safari etc)\r\n3. Do you see similar things in other pages. Could you share a screenshot.\r\nThanks!", "@jvishnuvardhan \r\nAbsolutely.\r\n> 1. I access tensorflow.org from China.\r\n> 2. Yes, the browser is Chrome. And this page display the same error no matter browser I use.\r\n> 3.  The same error is happened in `https://developers.google.com/` and any sub-page of `tensorflow.org`.\r\nHere are the screenshots.\r\n![Snipaste_2019-05-01_12-54-10](https://user-images.githubusercontent.com/16497652/57006111-ac72ec00-6c10-11e9-9dcf-91f39a99a235.png)\r\n![Snipaste_2019-05-01_12-53-19](https://user-images.githubusercontent.com/16497652/57006112-ad0b8280-6c10-11e9-94ca-413e1abedd4a.png)\r\n![Snipaste_2019-05-01_12-55-52](https://user-images.githubusercontent.com/16497652/57006113-ad0b8280-6c10-11e9-94c1-5c8f6254d83d.png)\r\n![Snipaste_2019-05-01_12-52-53](https://user-images.githubusercontent.com/16497652/57006114-ada41900-6c10-11e9-8f5c-41ce02be46c1.png)\r\n", "@Whisht Does this happen when you access the site through tensorflow.google.cn ? Do you have any JavaScript blockers on?\r\n", "@lamberta No matter tensorflow.google.cn or tensorflow.org, I encountered the same error. And I have turned the  blockers off. For that I did't misjudge, I have tried to access these website through other browsers, such as Firefox and Microsoft Edge which have no type of plug-ins.", "This seems related to how webfonts from fonts.googleapis.com are blocked in China.\r\nTracking: b/134091451", "Hi @Whisht, can you try this again? Testing thinks you have a Chrome extension installed that is blocking Google web fonts.\r\n", "Hello, @lamberta .Sorry for not follwing up this issue.\r\nHere is my latest testing result.\r\nI test the display result throug 3 browsers. MS egde, Firefox as well as Chrome. There still exists the same problem.\r\n\r\n-  The common display error of top bar.\r\n\r\n![Snipaste_2019-06-29_13-16-06](https://user-images.githubusercontent.com/16497652/60380061-4cae8b00-9a71-11e9-85f3-878138fb185a.png)\r\n- Edge without angy extension installed.\r\n![edge](https://user-images.githubusercontent.com/16497652/60380062-546e2f80-9a71-11e9-972a-1a7a6efd6430.png)\r\n- Chrome with AD blocker.\r\n![chrome](https://user-images.githubusercontent.com/16497652/60380073-926b5380-9a71-11e9-8b2f-e2b61c78c3bb.png)\r\n- Chrome that turning off all extension.\r\n![chrome \u65e0\u75d5](https://user-images.githubusercontent.com/16497652/60380076-a616ba00-9a71-11e9-803e-4d0dc151cd84.png)\r\n- Firefox without any installed extension.\r\n![firefox](https://user-images.githubusercontent.com/16497652/60380123-79af6d80-9a72-11e9-8e4d-d8ac47ab1e69.png)\r\n\r\n\r\nBy the way, Whether I access `tensorflow.org` through a shadowsocks proxy or access `tensorflow.org.cn` directly. There are same display error.\r\n![Snipaste_2019-06-29_13-31-33](https://user-images.githubusercontent.com/16497652/60380105-4076fd80-9a72-11e9-9ab0-578cca99fef3.png)\r\n\r\n\r\n", "Thank you, @Whisht, for the follow up.\r\n\r\n", "Thanks, @Whisht.\r\n\r\nSeems to be an issue with Google Fonts getting blocked. Assuming you're using a VPN to access tensorflow.org or using tensorflow.google.cn, these resources should be available. There may be something at the ISP-level going on.\r\n\r\nSInce there doesn't seem like much we can do, closing this issue for now. We can re-examine if there are more reports.\r\n\r\nThank you for your help and will keep an eye on it.\r\n", "That's all right, thanks for your kindly help@lamberta "]}, {"number": 28172, "title": "why I didn't get the right fft results with tf.fft?", "body": "I tried a simple test to see the fft function in tensorflow. But I found the result was not correct obviously. I dont know if I use the function rightly. Thanks for your comments.\r\n\r\n`import numpy as np\r\nimport tensorflow as tf\r\nimport scipy.io as scio\r\nimport matplotlib.pyplot as plt\r\n\r\nif __name__ == '__main__':\r\n\tt_data = np.linspace(0, 5, 201)\r\n\tf = 50\r\n\tt_holder = tf.placeholder(tf.float32, shape=[None, 1], name='t')\r\n\tf_tf = tf.Variable(f, dtype=tf.float32, name='f_tf', trainable=False)\r\n\ty_tf = tf.cos(2 * np.pi * f_tf * t_holder)\r\n\tfft_inputs = tf.complex(y_tf, tf.zeros_like(y_tf))\r\n\toutputs_fft = tf.fft(fft_inputs)\r\n\toutputs_fft_abs = tf.abs(outputs_fft)\r\n\tinit = tf.global_variables_initializer()\r\n\twith tf.Session() as sess:\r\n\t\tinit.run()\r\n\t\tfft_abs_print = sess.run(outputs_fft_abs, feed_dict={t_holder: np.reshape(t_data, (201, 1))})\r\n\t\tplt.plot(fft_abs_print)\r\n\t\tplt.show()`", "comments": ["@Frankcht I made minor modifications and ran the code. here is the GitHub [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/d9140511287b016b8ad5a98a74a62901/untitled120.ipynb). \r\n\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}, {"number": 28171, "title": "nvidia-smi: command not found in docker container from tensorflow/tensorflow:latest-gpu", "body": "Following the instructions of this webpage, https://tensorflow.google.cn/install/docker#gpu_support\r\nJust as following:\r\n1. docker pull tensorflow/tensorflow:latest-gpu\r\n2. sudo nvidia-docker run --network=host -v /ssd1:/ssd1 -it 0de7f0bffd91 /bin/bash\r\n     where 0de7f0bffd91 is the image id of latest_gpu\r\nBut when started in the container and use nvidia-smi to check gpu status, got the following message:\r\nbash: nvidia-smi: command not found\r\n\r\nIs there anything  wrong?\r\n", "comments": ["@SunGaofeng Please run the nvidia-smi command outside the docker container. Thanks!", "Yes, when run outside, every thing is ok. I can built containers from other images and run cuda programs inside them. But for the image pulled from tensorflow/tensorflow:latest-gpu, it failed to work.\r\n\r\n```\r\nSun May  5 09:34:45 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P40           On   | 00000000:43:00.0 Off |                    0 |\r\n| N/A   21C    P8    10W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla P40           On   | 00000000:44:00.0 Off |                    0 |\r\n| N/A   22C    P8    10W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla P40           On   | 00000000:45:00.0 Off |                    0 |\r\n| N/A   21C    P8    10W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla P40           On   | 00000000:49:00.0 Off |                    2 |\r\n| N/A   22C    P8     9W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla P40           On   | 00000000:4A:00.0 Off |                    0 |\r\n| N/A   24C    P8     9W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla P40           On   | 00000000:4B:00.0 Off |                    0 |\r\n| N/A   21C    P8    10W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla P40           On   | 00000000:4C:00.0 Off |                    0 |\r\n| N/A   24C    P8     9W / 250W |     10MiB / 22919MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```", "Is there any suggestion? I pulled 1.2.0-devel-gpu, and it worked well. What happened to the latest-gpu docker image?", "@SunGaofeng, please try to replicate this:\r\n\r\n```\r\n> docker rmi tensorflow/tensorflow:latest-gpu\r\n> docker run -it --runtime=nvidia --rm tensorflow/tensorflow:latest-gpu nvidia-smi\r\nTue May 14 18:05:38 2019\r\n+-----------------------------------------------------------------------------+                                                                              \r\n| NVIDIA-SMI 410.78       Driver Version: 410.78       CUDA Version: 10.0     |                                                                              \r\n|-------------------------------+----------------------+----------------------+                                                                              \r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |                                                                              \r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |                                                                              \r\n|===============================+======================+======================|                                                                              \r\n|   0  Quadro P1000        Off  | 00000000:18:00.0  On |                  N/A |                                                                              \r\n| 34%   36C    P5    N/A /  N/A |    535MiB /  4037MiB |     25%      Default |                                                                              \r\n+-------------------------------+----------------------+----------------------+                                                                              \r\n                                                                                                                                                             \r\n+-----------------------------------------------------------------------------+                                                                              \r\n| Processes:                                                       GPU Memory |                                                                              \r\n|  GPU       PID   Type   Process name                             Usage      |                                                                              \r\n|=============================================================================|                                                                              \r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nYou'll need to be using the newer version of [nvidia-docker](https://github.com/NVIDIA/nvidia-docker), triggered with `docker --runtime=nvidia` rather than `$ nvidia-docker ...`. TensorFlow 1.2 still used the older method, which is probably why it works for you.", "Yes, I'll use the docker for tf 1.2.  The server I used is shared by many people and it's not convenient to update docker version for myself without conflicts  with other people's environment. \r\nThanks for your reply, I think this issue can be closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28171\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28171\">No</a>\n"]}, {"number": 28170, "title": "Implement an algsimp optimization for dot operation.", "body": "The basic idea is that dot(reshape(transpose(A)), constant) can be replaced by dot(reshape(A), reshape(transpose(reshape(constant)))) if the effect of lhs transpose and reshape is to reorder elements in lhs contracting dims. We apply inverse reordering on the constant side, and then the inverse reordering can be constant folded.", "comments": ["@jlebar This is previously PR [27160](https://github.com/tensorflow/tensorflow/pull/27160) for the dot + transpose algsimp optimization. Somehow I screwed up the git log of that PR and I did not find a way to fix it within the PR. So I create this new one. Sorry about the duplication.", "Huh, I am surprised a simple `git push -f` to your remote branch didn't fix the problem.  But oh well.  Would you be willing to give me a list of which if any comments are outstanding from the previous PR?\r\n\r\nOne is the question about the protobuf int64 class.  We have an AsInt64Slice helper for exactly this.", "> Huh, I am surprised a simple `git push -f` to your remote branch didn't fix the problem. But oh well. Would you be willing to give me a list of which if any comments are outstanding from the previous PR?\r\n> \r\n> One is the question about the protobuf int64 class. We have an AsInt64Slice helper for exactly this.\r\n\r\nAbout the RepeatedField and int64 type comment, in this push I copied lhs_contracting_dims and rhs_contracting_dims out to a std::vector at the beginning and manipulate the vector since then, as we do not actually modify the dnums of the dot anyway.\r\n\r\nBesides a few small typos here are the outstanding comments I can remember:\r\n1. In checking lhs reshape squishes some dims into one, change the for loop into std::find_if. Your original comment is to change it to absl::c_linear_search, but we need a custom comparison function here. Also add some comments about the check.\r\n2. In checking lhs transpose. Remove the unnecessary condition.\r\n3. In updating lhs contracting dims after \"pulling in\" lhs transpose, use ComposePermutation helper. I compute the permutation vector within contracting dims to workaround the check in the current ComposePermutation implementation.\r\n4. Simplify the comments before transforming rhs.\r\n5. In inverting reshape and transpose, simplify the implementation.", "Thanks for approving the PR. Just while you are reviewing it I made some changes to not copy out the lhs_contracting_dims before hand. If this looks better or equally well I can leave it this way. I will fix things you suggested as well.", "> I made some changes to not copy out the lhs_contracting_dims before hand. If this looks better or equally well I can leave it this way\r\n\r\nLooks even better to me!", "@jlebar My previous push seemed to overwrite your approval. I just update the PR to fix review comments. Basically this revision just changes absl::c_find_if to absl::c_any_of and fixes comment format. If this revision looks good to you, could you approve it again? Thanks!", "@jlebar sure. I'm taking care of this PR and helping to get it merged. Thanks you!", "I had to roll this back due to a test failure; one of the CHECKs added here was failing.\r\n\r\nOverall this is kind of a good thing, it means that a real model used in production is affected by this change.  :)  I will see if there's an easy fix that I can make, and if not I'll give you a testcase.", "Thanks! Let me know if there is anything I can do on my side.", "@BinFan would you be willing to check the following patch for me?  The first testcase in here is the one that was crashing for me.\r\n\r\n```\r\ndiff --git a/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier.cc b/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier.cc\r\n--- a/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier.cc\r\n+++ b/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier.cc\r\n@@ -1558,28 +1558,37 @@ AlgebraicSimplifierVisitor::OptimizeDotO\r\n       reshape->operand(0)->shape(), reshape->shape());\r\n   CHECK_EQ(lhs_contracting_dims.size(), 1);\r\n   if ((unmodified_dims.size() != reshape->shape().rank() - 1) ||\r\n       absl::c_any_of(unmodified_dims, [&](const std::pair<int64, int64>& p) {\r\n         return p.second == lhs_contracting_dims[0];\r\n       })) {\r\n     return nullptr;\r\n   }\r\n-  // Virtually pull the reshape into the dot. Now the dot is equivalent to a\r\n-  // new dot with \"unsquished\" lhs contracting dims. We don't need to actually\r\n-  // create a new dot instruction. We can just keep track of lhs and\r\n-  // lhs_contracting_dims.\r\n-  CHECK_GT(reshape->operand(0)->shape().rank(), reshape->shape().rank());\r\n-  lhs_contracting_dims.Resize(\r\n-      reshape->operand(0)->shape().rank() - reshape->shape().rank() + 1,\r\n-      lhs_contracting_dims[0]);\r\n-  absl::c_iota(lhs_contracting_dims, lhs_contracting_dims[0]);\r\n+\r\n+  // Virtually pull the reshape into the dot so the dot operates on the\r\n+  // transpose, with \"unsquished\" lhs contracting dims.  The new contracting\r\n+  // dims are all of the dims that are modified by the reshape -- that is, every\r\n+  // dimension that's not in `unmodified_dims[i].first`.\r\n+  //\r\n+  // (We don't need to actually create a new dot instruction. We can just keep\r\n+  // track of lhs and lhs_contracting_dims.)\r\n+  absl::flat_hash_set<int64> unmodified_transpose_dims;\r\n+  for (const auto& pair : unmodified_dims) {\r\n+    unmodified_transpose_dims.insert(pair.first);\r\n+  }\r\n+  lhs_contracting_dims.Clear();\r\n+  for (int64 i = 0; i < transpose->shape().dimensions_size(); ++i) {\r\n+    if (!unmodified_transpose_dims.contains(i)) {\r\n+      lhs_contracting_dims.Add(i);\r\n+    }\r\n+  }\r\n   lhs = lhs->mutable_operand(0);\r\n \r\n-  // Check if transpose only permutes the contracting dims.\r\n+  // Check that the transpose only permutes the contracting dims.\r\n   const auto& transpose_dims = transpose->dimensions();\r\n   for (int64 i = 0; i < transpose_dims.size(); ++i) {\r\n     if (transpose_dims[i] != i &&\r\n         !absl::c_linear_search(lhs_contracting_dims, i)) {\r\n       return nullptr;\r\n     }\r\n   }\r\n   // Virtually pull the transpose into the dot. Now the dot is equivalent to\r\ndiff --git a/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier_test.cc b/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier_test.cc\r\n--- a/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier_test.cc\r\n+++ b/google3/third_party/tensorflow/compiler/xla/service/algebraic_simplifier_test.cc\r\n@@ -5297,10 +5297,57 @@ TEST_F(AlgebraicSimplifierTest, DotContr\r\n       [](const Shape&, const Shape&) { return false; });\r\n   options.set_is_layout_sensitive(true);\r\n   // The transformation of moving transpose and reshape to the constant side is\r\n   // layout insensitive. It should not happen if AlgebraicSimplifier is set up\r\n   // to be layout sensitive.\r\n   ASSERT_FALSE(AlgebraicSimplifier(options).Run(m.get()).ValueOrDie());\r\n }\r\n \r\n+TEST_F(AlgebraicSimplifierTest, DotContractingReorder_SizeOneDimsNoChange) {\r\n+  // This isn't transformed (notice that the relative order of the `2` and `3`\r\n+  // dims doesn't change, so there's no opportunity here), but it's nonetheless\r\n+  // an interesting testcase because of the presence of the size-1 dimensions.\r\n+  const char* kModuleStr = R\"(\r\n+    HloModule m\r\n+    test {\r\n+     param = f32[1,2,5,3] parameter(0)\r\n+     transpose = f32[1,5,2,3] transpose(param), dimensions={0,2,1,3}\r\n+     reshape = f32[5,6] reshape(transpose)\r\n+     constant = f32[6,4] constant({{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4}})\r\n+     ROOT dot = f32[5,4] dot(reshape, constant),\r\n+       lhs_contracting_dims={1}, rhs_contracting_dims={0}\r\n+    }\r\n+  )\";\r\n+  TF_ASSERT_OK_AND_ASSIGN(auto m, ParseAndReturnVerifiedModule(kModuleStr));\r\n+  ASSERT_FALSE(AlgebraicSimplifier(default_options_).Run(m.get()).ValueOrDie());\r\n+}\r\n+\r\n+TEST_F(AlgebraicSimplifierTest, DotContractingReorder_SizeOneDims) {\r\n+  const char* kModuleStr = R\"(\r\n+    HloModule m\r\n+    test {\r\n+     param = f32[1,2,3,5] parameter(0)\r\n+     transpose = f32[1,3,2,5] transpose(param), dimensions={0,2,1,3}\r\n+     reshape = f32[6,5] reshape(transpose)\r\n+     constant = f32[6,4] constant({{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4}})\r\n+     ROOT dot = f32[5,4] dot(reshape, constant),\r\n+       lhs_contracting_dims={0}, rhs_contracting_dims={0}\r\n+    }\r\n+  )\";\r\n+  TF_ASSERT_OK_AND_ASSIGN(auto m, ParseAndReturnVerifiedModule(kModuleStr));\r\n+  ASSERT_TRUE(AlgebraicSimplifier(default_options_).Run(m.get()).ValueOrDie());\r\n+  auto shape1 = ShapeUtil::MakeShape(F32, {6, 5});\r\n+  auto shape2 = ShapeUtil::MakeShape(F32, {1, 3, 2, 4});\r\n+  auto shape3 = ShapeUtil::MakeShape(F32, {1, 2, 3, 4});\r\n+  const HloInstruction* transpose;\r\n+  ASSERT_THAT(m->entry_computation()->root_instruction(),\r\n+              GmockMatch(m::Dot(\r\n+                  m::Reshape(m::Parameter(0)).WithShapeCompatibleTo(&shape1),\r\n+                  m::Reshape(m::Transpose(&transpose,\r\n+                                          m::Reshape(m::Constant())\r\n+                                              .WithShapeCompatibleTo(&shape2))\r\n+                                 .WithShapeCompatibleTo(&shape3)))));\r\n+  EXPECT_THAT(transpose->dimensions(), ElementsAre(0, 2, 1, 3));\r\n+}\r\n+\r\n }  // namespace\r\n }  // namespace xla\r\n```", "@jlebar Thanks a lot for the patch! It looks good. And indeed I missed the size 1 dim case.\r\n\r\nI'm wondering if we should add check after filling in unmodified_transpose_dims something like\r\n```\r\nif (!is_iota(unmodified_transpose_dims)) { // I did not find an std or absl library for is_iota\r\n  return nullptr;\r\n}\r\n```\r\nbecause I'm thinking of this example\r\n```\r\n  param = f32[2,5,1,3] parameter(0)\r\n  transpose = f32[1,5,2,3] transpose(param), dimensions={2,1,0,3}\r\n  reshape = f32[5,6] reshape(transpose)\r\n  constant = f32[6,4] constant({{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4},{1,2,3,4}})\r\n  ROOT dot = f32[5,4] dot(reshape, constant),\r\n    lhs_contracting_dims={1}, rhs_contracting_dims={0}\r\n```\r\nI think this example would pass all the check: After pulling in reshape, lhs_contracting_dims={0,2,3}, and the transpose only permute dimensions 0 and 2. But the relative order of dim 2 and 3 does not change either, so should be no opportunity here.", "> I think this example would pass all the check\r\n\r\nThis one does not trigger the transformation.  I didn't step through in a debugger, but I think it's because the `1` dim is considered a contracting dim.\r\n\r\nI added this one as a testcase.", "Looks good to me. Thanks!"]}]