[{"number": 43765, "title": "LookupError: gradient registry has no entry for: TensorScatterMax", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Tesla P100-PCIE, 16280MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI'm making YOLACT and while creating semantic_segmentation_loss function, I've used `tensor_scatter_nd_max` function which was introduced in tf 2.3. The function is as follows:\r\n\r\n```\r\ndef _loss_semantic_segmentation(pred_seg, mask_gt, classes):\r\n    batch_size, mask_h, mask_w, num_classes = tf.shape(pred_seg)\r\n    loss_s = 0\r\n\r\n    for i in range(batch_size):\r\n        cur_segment = pred_seg[i]\r\n        cur_class_gt = classes[i]\r\n        masks = mask_gt[i]\r\n\r\n        masks = tf.expand_dims(masks, axis=-1)\r\n        masks = tf.image.resize(masks, [mask_h, mask_w], method=tf.image.ResizeMethod.BILINEAR)\r\n        masks = tf.cast(masks + 0.5, tf.int64)\r\n        masks = tf.squeeze(tf.cast(masks, tf.float32))\r\n\r\n        segment_gt = tf.zeros_like(cur_segment) # [height, width, num_cls]\r\n        segment_gt = tf.transpose(segment_gt, perm=(2, 0, 1))\r\n\r\n        obj_cls = tf.expand_dims(cur_class_gt, axis=-1)\r\n        segment_gt = tf.tensor_scatter_nd_max(segment_gt, indices=obj_cls, updates=masks)\r\n        segment_gt = tf.transpose(segment_gt, perm=(1, 2, 0))\r\n\r\n        loss_s += tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(segment_gt, cur_segment))\r\n\r\n    return loss_s / mask_h / mask_w\r\n```\r\n\r\nBut it throws me following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 300, in <module>\r\n    app.run(main)\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"train.py\", line 208, in main\r\n    labels)\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 761, in __call__\r\n    return self._python_function(*args, **kwds)\r\n  File \"train.py\", line 54, in train_step\r\n    grads = tape.gradient(total_loss, model.trainable_variables)\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1073, in gradient\r\n    unconnected_gradients=unconnected_gradients)\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\r\n    compat.as_str(unconnected_gradients.value))\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 151, in _gradient_function\r\n    grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\r\n  File \"/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/registry.py\", line 97, in lookup\r\n    \"%s registry has no entry for: %s\" % (self._name, name))\r\nLookupError: gradient registry has no entry for: TensorScatterMax\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nNo error should come\r\n\r\n**Standalone code to reproduce the issue**\r\nThe link to my repository is [this](https://github.com/anshkumar/yolact). \r\nTo run:\r\n\r\n> python3 train.py -tfrecord_dir '/home/deploy/ved/data' -weights '/home/deploy/ved/ckpt'  -train_iter '100000'  -batch_size '2' \r\n\r\nIf you need tfrecord let me know.\r\n", "comments": ["@anshkumar \r\nPlease provide with simple stand alone code such that we can replicate the issue faced or if possible share a colab gist with the error reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43765\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43765\">No</a>\n"]}, {"number": 43764, "title": "UnknownError: Failed to get convolution algorithm. ", "body": "**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\nTensorFlow installed from (source or binary): binary **(no errors during installation)**\r\nTensorFlow version: 2.3.1\r\nPython version: 3.7.5\r\nCUDA/cuDNN version: 10.1\r\nGPU model and memory: RTX 1660 Ti 6.00GB\r\n[full script output.txt](https://github.com/tensorflow/tensorflow/files/5322982/full.script.output.txt)\r\n\r\n\r\n**Describe the current behavior**\r\nThe code below throws the following exception \r\n\r\n`tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\r\n`\r\nFull script's output is attached.\r\nThe code is pretty standard, it's weird to get this error. In the script I also put code that trains model via Keras's model.fit() - and it works. **The error occurs when GradientTape-approach is used.**\r\nAlso the same code (version with training via Keras model.fit() and version with GradiantTape) works fine on GoogleColab https://colab.research.google.com/drive/1fjbvlpEEEm3yvyKhcGyel3vLguEkU9GN?usp=sharing\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\nx_train = x_train[..., tf.newaxis].astype(\"float32\")\r\nx_test = x_test[..., tf.newaxis].astype(\"float32\")\r\nnb_classes = 10\r\ny_train = tf.keras.utils.to_categorical(y_train, nb_classes)\r\ny_test = tf.keras.utils.to_categorical(y_test, nb_classes)\r\ndataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\r\n\r\n# oversimplified model just for example\r\ninputs = tf.keras.layers.Input(shape=(28, 28, 1))\r\nx = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\r\nx = tf.keras.layers.MaxPool2D(2)(x)\r\nx = tf.keras.layers.Flatten()(x)\r\noutputs = tf.keras.layers.Dense(nb_classes, activation='softmax')(x)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\r\nloss_func = tf.keras.losses.CategoricalCrossentropy()\r\noptimizer = tf.keras.optimizers.Adam()\r\n\r\nfor i, (xx, yy) in enumerate(dataset):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = model(xx)\r\n        loss = loss_func(yy, y_pred)\r\n    grad = tape.gradient(loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(grad, model.trainable_variables))\r\n    print('batch {} processed'.format(i))\r\n\r\n# if used this approach to train - everything works\r\n# model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam())\r\n# model.fit(x_train, y_train, batch_size=128, validation_data=(x_test, y_test))\r\n# model.evaluate(x_test, y_test, batch_size=128, verbose=1)\r\n```\r\n\r\n\r\n\r\n**Other info / logs** \r\nFull script output is attached.\r\n", "comments": ["That may be obvious from the description of the bug, but for more precise issue localization:  if Convolution and MaxPool layers are excluded from the model everything works.\r\nBut **usage tf.keras.layers.Conv2D and/or tf.keras.layers.MaxPool2D while training via GradientTape() causes described above bug.**\r\n", "@RomanGirin \r\n\r\nI have tried in colab with TF version 2.3.0 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/564e7bc08f0128fa8c084b68b2437227/untitled416.ipynb).Please, help us with reproducible code. It helps us in localizing the issue faster. Thanks!\r\n\r\n\r\n", "@ravikyram  Yes, I register the issue on my laptop only too. Both, in virtual environment and 'globally' in the system (also running as Administator).\r\nIs there any list what can be checked based on the script's output attached above?\r\n\r\nIt is likely environmental problem in my laptop, but I keep wonder why keras model.fit() works then?\r\n\r\nIs this part of the script's output gives us some clue?\r\n```\r\n2020-10-05 19:57:05.600720: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-10-05 19:57:05.601278: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n```\r\n", "@RomanGirin I don't think it is a Tensorflow bug. Double check your cudnn version and https://github.com/tensorflow/tensorflow/issues/39989", "@bhack thank you for the reply! \r\nmy cudnn version is cudnn-10.1-windows10-x64-v7.6.5.32\r\nI also tried cudnn-10.1-windows10-x64-v8.0.3.33 with no luck\r\n\r\nChecked environment vars: \r\nin particular i have in PATH\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\bin\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\libnvvp\r\n\r\nI also have var CUDA_PATH with value\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\r\nand CUDA_PATH_V10_1\r\nwith the same value\r\nThe paths in the var's values corresponds to the actual ones where I copied cudnn. \r\n\r\nAlso I tried to run this addition of vars with no luck\r\nhttps://www.tensorflow.org/install/gpu#windows_setup\r\n\r\nRun through \"check list\" here\r\nhttps://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261/2\r\nIn particular, I'm the only user in the system (this is laptop) no possible side effects from other training processes. And the error is consistent (not occurring from time to time)\r\n\r\nThe issue still remains\r\nAny help is very appreciated!\r\n", "Also, just in case, checked that I have installed CUDA 10.1 with the update 2\r\n\r\nCUDA Toolkit 10.1 update2 Archive https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal\r\n\r\nThe issue still remains\r\nAny help is very appreciated!\r\n", "@ravikyram @bhack  found a workaround. Set GPU memory growth setting to 'true' instead of default https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n\r\nLooks like a bug in memory allocation logic in TF or CUDA engine to me.\r\n\r\nI consider it as workaround. It would be cool if it wouldn't be necessary to use this settings. Because (quote from https://www.tensorflow.org/guide/gpu) \"By default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to CUDA_VISIBLE_DEVICES) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation.\" \r\n\r\nThese two comments may be relevant to this issue also:\r\nhttps://github.com/tensorflow/tensorflow/issues/6698#issuecomment-297179317 (this one relates to TF 1.X but root cause may be the same)\r\nhttps://github.com/tensorflow/tensorflow/issues/6698#issuecomment-613039907\r\n", "@RomanGirin \r\n\r\nPlease, close this thread if your issue was resolved. Thanks!", "@ravikyram I don't think it should be considered like a solution. It's just work around because it may lead to GPU memory fragmentation as noted in TF docs (https://www.tensorflow.org/guide/gpu)\r\n\r\nLooks like a bug in memory allocation logic in TF or CUDA engine to me.\r\n\r\nThanks for all the replies anyway!!", "@imintz is looking into possibly fixing this for good.", "Don't close the thread, because neither of the solution, worked for me. I installed Anaconda with Python 3.8, CUDA 10.1,cuDNN 8.0.3, and Tensorflow 2.3 on my Window 10 with GPU Configuration - GTX 1050 . Please Help me.", "@yashrajjain726 Does https://github.com/tensorflow/tensorflow/issues/43764#issuecomment-706560533 work for you?", "Nope.", "@yashrajjain726 take a look at this check list https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261/2 just in case if it's environmental problem", "Ohk, So My error is cleared when I used the cuDNN v7.6.5 with CUDA 10.1", "@RomanGirin \r\nCould you please provide access to the colab gist so we could verify if this is fixed in later tf versions or could you please confirm if this is still an issue on latest tf version.", "I had the error more than a half of year ago! \r\nI'm sorry but the only code I have left for the case is provided above in this issue", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43764\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43764\">No</a>\n"]}, {"number": 43763, "title": "Loss and metric calculated differently on validation", "body": "I'm using `keras.applications.vgg19` with some custom loss function (cross-entropy based). I'm using the loss function both as a loss and as a metric. While training, I've been getting the same values for both loss and metric, but for validation, those values are different.\r\n\r\n![image](https://user-images.githubusercontent.com/59140738/95012520-ecc66d00-0641-11eb-99e0-370ff41af92f.png)\r\n\r\nYou can see that for training, the loss and loss metric are the same (orange and blue lines that merge into one line), and for validation the loss and loss metric look different.\r\n\r\n\r\n```\r\nEpoch 1/7\r\n - 111s - loss: 3.3320 - loss_metric: 3.3320 - val_loss: 3.0186 - val_loss_metric: 3.0993 \r\nEpoch 2/7\r\n - 90s - loss: 3.0934 - loss_metric: 3.0934 - val_loss: 3.0394  - val_loss_metric: 3.0424 \r\nEpoch 3/7\r\n - 91s - loss: 3.0643 - loss_metric: 3.0643 - val_loss: 3.0139  - val_loss_metric: 3.0031 \r\nEpoch 4/7\r\n - 90s - loss: 3.0411 - loss_metric: 3.0411 - val_loss: 3.0588  - val_loss_metric: 2.9770 \r\nEpoch 5/7\r\n - 90s - loss: 3.0170 - loss_metric: 3.0170 - val_loss: 2.8466  - val_loss_metric: 2.9625 \r\nEpoch 6/7\r\n - 90s - loss: 2.9866 - loss_metric: 2.9866 - val_loss: 3.0236  - val_loss_metric: 2.9133 \r\nEpoch 7/7\r\n - 91s - loss: 2.9447 - loss_metric: 2.9447 - val_loss: 2.9063  - val_loss_metric: 3.0723\r\n```\r\n\r\nSome notes:\r\n\r\n- I know this might be due to the usage of regularization, however, I'm not finding any regularization in the  [Keras implementation of VGG19](https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg19.py)\r\n- I know there a was a [bug ](https://github.com/tensorflow/tensorflow/issues/25970#issuecomment-470210090)which has been fixed for TF2. I'm using TensorFlow GPU 2.1.0 and Keras 2.3.1\r\n\r\nCan anyone please tell me what am I missing?\r\n\r\n", "comments": ["@michalCyberfish,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@michalCyberfish Can you please share a simple standalone code to reproduce the issue? Thanks!", ">\n> train_datagen = ImageDataGenerator(rescale=1./255,)\n> train_generator= train_datagen .flow_from_dataframe(\n>\ndirectory=\"./train/\",\n\nx_col=\"id\",\n\ny_col=\"label\",\n\nbatch_size=32,\n\nshuffle=True,\n\nclass_mode=\"categorical\",\n\ntarget_size=(32,32))\n\ndataframe=train_df,\n\n\nthis prints this line for each flow_from_dataframe initialization:\n\n> Found 2000 images belonging to 2 classes\n\n\nwhich is really annoying when you use it inside another generator. and it\nprints it thousand of times.\n", "@michalCyberfish Generally you need to use `ImageDataGenerator` once to load generator. So  ` Found 2000 images belonging to 2 classes` this should be printed only one time. Please check [this tutorial](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#scrollTo=0p7iDOhIcqY2) where `ImageDataGenerator` was used.\r\n\r\nAnyway, how is this print out related to the title of this issue? Can you please update it so that other users will find it useful. \r\n\r\nIf there are any further questions, please provide a simple standalone code to reproduce the issue. Thanks!", "I\u2019m sorry, I thought you replied on the other issue I opened. I will\nprovide a standalone code for this issue shortly.\n\nOn Wed, 14 Oct 2020 at 1:23 Vishnuvardhan Janapati <notifications@github.com>\nwrote:\n\n> @michalCyberfish <https://github.com/michalCyberfish> Generally you need\n> to use ImageDataGenerator once to load generator. So Found 2000 images\n> belonging to 2 classes this should be printed only one time. Please check this\n> tutorial\n> <https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning_with_hub.ipynb#scrollTo=0p7iDOhIcqY2>\n> where ImageDataGenerator was used.\n>\n> Anyway, how is this print out related to the title of this issue? Can you\n> please update it so that other users will find it useful.\n>\n> If there are any further questions, please provide a simple standalone\n> code to reproduce the issue. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/43763#issuecomment-708041970>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AODGVAVA4LZUJUOIX6NDJR3SKTHPRANCNFSM4SDTH7AA>\n> .\n>\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@michalCyberfish I am closing this issue. I think the tutorial i mentioned in the last comment should help understanding usage of `ImageDataGenerator`.\r\n\r\nIf you still face any issue, Please feel free to reopen with a simple standalone code to reproduce the issue. Thanks!"]}, {"number": 43762, "title": "Minor grammar fix in docs", "body": "", "comments": []}, {"number": 43761, "title": "Error : Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : Ubuntu20.04\r\n- TensorFlow installed from (source or binary): conda install tensorflow-gpu\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: I installed necessary tool things [here](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html) and [here](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker)\r\n- GPU model and memory: RTX2060, 6GB\r\n\r\n**Describe the current behavior**\r\nI think I did everything to try to fix the bug that when I run model.fit_generator the error occurs saying as the tytle. Some information I need to add is I tried on windows, linux and finally docker environment, on each of which I got the same result. Below is my docker file to create a container;\r\n\r\n```\r\nFROM nvidia/cuda:11.1-base-ubuntu20.04\r\nRUN apt-get update && apt-get install -y\\\r\n    sudo\\\r\n    wget\\\r\n    vim\r\nWORKDIR /opt\r\nRUN wget https://repo.continuum.io/archive/Anaconda3-2020.07-Linux-x86_64.sh &&\\\r\n    sh Anaconda3-2020.07-Linux-x86_64.sh -b -p /opt/anaconda3 &&\\\r\n    rm -f Anaconda3-2020.07-Linux-x86_64.sh\r\n\r\nENV PATH /opt/anaconda3/bin:$PATH\r\n\r\nRUN conda upgrade conda && conda install \\\r\n    keras\\\r\n    tensorflow-gpu\r\n\r\nWORKDIR /\r\n\r\nCMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--allow-root\", \"--LabApp.tokenh=''\"]`\r\n\r\n```\r\n\r\nand after I built the file, I ran the image by;\r\n\r\n`docker run --gpus all -v ~:/work -p 8888:8888 <Image ID>`\r\n\r\nOne thing I finally couldn't get is... is it even possible to use tensorflow and GPU in Anaconda environment?\r\nI was able to run the same code as below for a few days on Windows, but one day the code suddenly did't work at all.\r\n\r\n---\r\n\r\n```python\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.optimizers import RMSprop\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\nbase_dir = 'cats_and_dogs_filtered'\r\ntrain_dir = os.path.join(base_dir, 'train')\r\nvalidation_dir = os.path.join(base_dir, 'validation')\r\n\r\ntrain_cats_dir = os.path.join(train_dir, 'cats')\r\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\r\n\r\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\r\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\r\n    tf.keras.layers.MaxPooling2D(2, 2),\r\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(512, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer=RMSprop(lr=1e-4),\r\n              metrics=['accuracy'])\r\n\r\ntrain_datagen = ImageDataGenerator(rescale=1./255)\r\ntest_datagen = ImageDataGenerator(rescale=1./255)\r\n\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        train_dir,  # This is the source directory for training images\r\n        target_size=(150, 150),  # All images will be resized to 150x150\r\n        batch_size=40,\r\n        # Since we use binary_crossentropy loss, we need binary labels\r\n        class_mode='binary')\r\n\r\nvalidation_generator = test_datagen.flow_from_directory(\r\n        validation_dir,\r\n        target_size=(150, 150),\r\n        batch_size=100,\r\n        class_mode='binary')\r\n\r\nhistory = model.fit_generator(\r\n      train_generator,\r\n      steps_per_epoch=50,  # 2000 images = batch_size * steps\r\n      epochs=100,\r\n      validation_data=validation_generator,\r\n      validation_steps=10,  # 1000 images = batch_size * steps\r\n      verbose=1)'\r\n\r\n```\r\n---\r\n\r\nand I've got same errors as below forever;\r\n```\r\nUnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node sequential/conv2d/Conv2D (defined at :60) ]] [Op:__inference_train_function_1187]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n```\r\n\r\nWithout docker environment, I should have installed CUDA Driver, CUDA toolkit and tf of proper version manually right?\r\nBut they came with tensorflow when I install it on conda. Honestly, I don't get this(If they comes with tf, do I even need to mind what I need?)\r\n\r\nAnyway, I checked tickets which mention this bug such as [#24828](https://github.com/tensorflow/tensorflow/issues/24828) but no answers were good medicine to my situation. So I issued this ticket again.\r\n\r\n**Describe the expected behavior**\r\nSuccessfully complete the process of learning.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nnouveau is ok, it doesn't work now. If there is any more information I should show, please let me know.", "comments": ["Were using 2 environments simultaneously for prototyping? I mean this usually happens when you run tensorflow model that initializes cuDNN in one environment and then you try to run another model in some other environment before deactivating the previous environment. I have faced it and in my case this was the issue. \r\nLet me know if it helps", "Thank you @AkshayRoyal for answering.According to what the interpreter says, it might be the case. \nIs it possible for one GPU being taken up by a process run on Windows and still so even after PC is shut down and apparently no software related to GPU(such ad CUDA or cudnn) is alive(not sure in backend), or even after Linux is installed in another SSD and conda environments are built where I try to run the Conv2D program and fail? I already checked the state of my GPU by \nNvidia-smi \nand saw some processes are active that I have no idea what it is about(I tried to deactivate them but it said no process is running). I'll check them throughly after I get back home, so could you tell me if it is possible for a process to be stuck only in the GPU and alive forever until I take some action.", "I tried different kinds of environments on which tensorflow runs, but still got the same error. So I suspect the GPU is in an abnormal state. Another possibility is that conda environment doesn't go along with tensorflow since it is installed automatically with some version of cudatoolkit and cudnn, and I cannot change the version of them. For example, on Ubuntu 20.04, conda install tensorflow 2.2, cudatoolkit 10.1, and cudnn 7.6 at the same time as a package.", "Here is my output from nvidia-smi command.\r\nI don't think these remaining process matter though.\r\n\r\n```\r\nmamo@mamo-MS-7B86:~$ nvidia-smi\r\nSun Oct  4 17:01:29 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 2060    On   | 00000000:26:00.0  On |                  N/A |\r\n|  0%   38C    P8     7W / 160W |    224MiB /  5926MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      1894      G   /usr/lib/xorg/Xorg                100MiB |\r\n|    0   N/A  N/A      2019      G   /usr/bin/gnome-shell               92MiB |\r\n|    0   N/A  N/A      6536      G   ...AAAAAAAAA= --shared-files       29MiB |\r\n+-----------------------------------------------------------------------------+\r\n```", "@MAMOMIMOMU It won't matter if you try different environments until you close the IDE or deactivate the environment that initialized cuDNN to run your model. Restarting should automatically do that for you and try running any convolutional neural net. You should be able to do it.\r\nAlso, were you able to run any CNN on the environment that has TensorFlow installed? If no, then it suggests that cuDNN is not present in your system or is not in the path", "@AkshayRoyal\r\nActually, I was able to run the same ipynb file on Windows, but one day suddenly the error came to occur. I didn't change my environment at all so I had no ideas about the unknown error. \r\n\r\nYou gave me a good insight that cudnn isn't working. So I tried nvidia/cuda:11.1-runtime-ubuntu20.04 since [this page](https://hub.docker.com/r/nvidia/cuda) implies that cudnn is not provided in the base image. But no, I've got the same error. \r\nCould you refer to [this page](https://hub.docker.com/layers/nvidia/cuda/11.1-runtime-ubuntu20.04/images/sha256-994b38c095b9fadacba22fda452094a719c8628f115a5897b01f16423eb34d4d?context=explore) and see if this image can make a container that meets requirements to run tensorflow using GPU(And I don't need to add a path to cudnn if I install like this right)?", "@MAMOMIMOMU  tensorflow 2.2 requires cuda 10.1 but you are using 11.1 \r\nInstall cuda 10.1 and also check this [link](https://www.tensorflow.org/install/source#linux)", "@AkshayRoyal \r\nThank you for giving me a possible solution, but no, it didn't work.\r\nI edited my Dockerfile as below; \r\n\r\n```\r\nFROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04\r\nRUN apt-get update && apt-get install -y\\\r\n    sudo\\\r\n    wget\\\r\n    vim\r\nWORKDIR /opt\r\nRUN wget https://repo.continuum.io/archive/Anaconda3-2020.07-Linux-x86_64.sh &&\\\r\n    sh Anaconda3-2020.07-Linux-x86_64.sh -b -p /opt/anaconda3 &&\\\r\n    rm -f Anaconda3-2020.07-Linux-x86_64.sh\r\n\r\nENV PATH /opt/anaconda3/bin:$PATH\r\n\r\nRUN conda update conda && conda install \\\r\n    keras\\\r\n    scipy\\\r\n    tensorflow-gpu\r\n\r\nWORKDIR /\r\n\r\nCMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--allow-root\", \"--LabApp.tokenh=''\"]\r\n```\r\nThough my OS is ubuntu20.04, there is no docker image like nvidia/cuda:10.1-devel-ubuntu20.04 (only for cuda11.0 or above)so I used nvidia/cuda:10.1-devel-ubuntu18.04 instead.\r\n\r\nNow my environment is as below;\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 2060    Off  | 00000000:26:00.0  On |                  N/A |\r\n|  0%   42C    P2    29W / 160W |    472MiB /  5926MiB |      1%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n```\r\nPlease note that nvidia-smi says I'm using CUDA 11.0, but I'm not. I reinstalled my ubuntu and didn't install CUDA 11.0, but installed 10.1 this time. So `nvcc -V` says\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:07:16_PDT_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n```\r\nPython version is 3.8.3\r\n\r\nBy running `cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2`\r\nI can see \r\n```\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 6\r\n#define CUDNN_PATCHLEVEL 5\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n\r\n#include \"driver_types.h\"\r\n```\r\n\r\nversion of tensorflow-gpu is 2.2.0\r\n\r\nThere seems to be no problems in the combination of the version of Python, CUDA and cudnn according to [this link](https://www.tensorflow.org/install/source#linux).\r\n\r\nFinally I have no idea what is the cause of this error... ", "@MAMOMIMOMU \r\nI ran the code shared and face a different issue as some dependencies are missing, please share all dependencies so we could replicate the issue faced.\r\nPlease find gist here for the code run on [colab with tf 2.2 gpu](https://colab.research.google.com/gist/Saduf2019/3180190c57df4143e432dd3753f88489/untitled424.ipynb), or if possible share a colab gist with the issue reported.", "Just to note the we don't directly support Anaconda here.", "@bhack \r\nWe do not officially support build/install issues but we do support code-bugs from anaconda for tf as in this case.", "@Saduf2019 are you sure that It Is a code bug? It seems to me an environment bug.", "@Saduf2019 @AkshayRoyal @bhack \r\nI am sorry for not replying for a day. I finally fixed the problem.\r\nThe dockerfile below is the one I showed to you before, and this was actually enough for building the environment to run the Conv2D algorithm.\r\n\r\n```\r\nFROM nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04\r\nRUN apt-get update && apt-get install -y\\\r\n    sudo\\\r\n    wget\\\r\n    vim\r\nWORKDIR /opt\r\nRUN wget https://repo.continuum.io/archive/Anaconda3-2020.07-Linux-x86_64.sh &&\\\r\n    sh Anaconda3-2020.07-Linux-x86_64.sh -b -p /opt/anaconda3 &&\\\r\n    rm -f Anaconda3-2020.07-Linux-x86_64.sh\r\n\r\nENV PATH /opt/anaconda3/bin:$PATH\r\n\r\nRUN conda update conda && conda install \\\r\n    keras\\\r\n    scipy\\\r\n    tensorflow-gpu\r\n\r\nWORKDIR /\r\n\r\nCMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--allow-root\", \"--LabApp.tokenh=''\"]\r\n\r\n```\r\nAt the time when I ran the code, I still got the unknownerror. However, I found some people on the web saying when you see this error, add \r\n```\r\nfrom tensorflow.compat.v1 import ConfigProto, InteractiveSession\r\n\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.6\r\nsess = InteractiveSession(config=config)\r\n```\r\nat the beginning. This fixed the problem, so the problem comes out of lack of GPU memory maybe?\r\nI don't know when I have to write this(maybe only when using Conv2D?), and also it limits the VRAM resource so it doesn't seem preferable, but for the moment, I report that I successfully managed the problem by adding some statements above. Also thank you very much for thinking about and dealing with the problem with me. That significantly helped me as well!", "@MAMOMIMOMU \r\nPlease move the issue to closed status as resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43761\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43761\">No</a>\n"]}, {"number": 43760, "title": "creating segmentation", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["The given doc link https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod is not working.\r\nCan you please update the issue with correct link?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 43759, "title": "- added missing argument docstrings for genbbox.", "body": "Addresses #43697 ", "comments": ["@ashwin-phadke can you please fix ubuntu sanity errors ?", "@rthadur , @mihaimaruseac can you take a look at the CPU logs? ."]}, {"number": 43758, "title": "[T.F 2.0 API Docs] Adds usage example for log_sigmoid", "body": "PR for issue #25802\r\n\r\nAdds usage example for `math.log_sigmoid`", "comments": ["Thanks for reviewing @Harsh188. Made the changes."]}, {"number": 43757, "title": "creating tf.data.Dataset object from generator gives error for incorrect file name", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10 **\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **conda**\r\n- TensorFlow version (use command below): **2.3.0**\r\n- Python version: **3.8 and 3.6**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **10.1.243/7.6.5**\r\n- GPU model and memory: **Nvidia RTX2070 8 GB**\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nOn trying to consume batches from the dataset `ds` I get InvalidArgumentError\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n[official tfdata colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data.ipynb)\r\nIn the above file. Go to Consuming Python Generators section and in the code cell\r\n```\r\nds = tf.data.Dataset.from_generator(\r\n    img_gen.flow_from_directory, args=[flowers], \r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,256,256,3], [32,5])\r\n)\r\n\r\nds\r\n```\r\nadd `next(iter(ds))` to consume a batch of `ds`\r\n**Other info / logs** \r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)\r\n   2101       ctx.executor = executor_new\r\n-> 2102       yield\r\n   2103     finally:\r\n\r\n10 frames\r\nInvalidArgumentError: TypeError: endswith first arg must be bytes or a tuple of bytes, not str\r\nTraceback (most recent call last):\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 711, in get_iterator\r\n    return self._iterators[iterator_id]\r\n\r\nKeyError: 1\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 713, in get_iterator\r\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\", line 959, in flow_from_directory\r\n    interpolation=interpolation)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\", line 397, in __init__\r\n    **kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\", line 135, in __init__\r\n    classes, filenames = res.get()\r\n\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 644, in get\r\n    raise self._value\r\n\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\r\n    result = (True, func(*args, **kwds))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 221, in _list_valid_filenames_in_directory\r\n    for root, fname in valid_files:\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 178, in _iter_valid_files\r\n    if fname.lower().endswith('.tiff'):\r\n\r\nTypeError: endswith first arg must be bytes or a tuple of bytes, not str\r\n\r\n\r\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py in wait(self)\r\n     65   def wait(self):\r\n     66     \"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\r\n---> 67     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\n     68 \r\n     69   def clear_error(self):\r\n\r\nInvalidArgumentError: TypeError: endswith first arg must be bytes or a tuple of bytes, not str\r\nTraceback (most recent call last):\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 711, in get_iterator\r\n    return self._iterators[iterator_id]\r\n\r\nKeyError: 1\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 713, in get_iterator\r\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\", line 959, in flow_from_directory\r\n    interpolation=interpolation)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\", line 397, in __init__\r\n    **kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\", line 135, in __init__\r\n    classes, filenames = res.get()\r\n\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 644, in get\r\n    raise self._value\r\n\r\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\r\n    result = (True, func(*args, **kwds))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 221, in _list_valid_filenames_in_directory\r\n    for root, fname in valid_files:\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 178, in _iter_valid_files\r\n    if fname.lower().endswith('.tiff'):\r\n\r\nTypeError: endswith first arg must be bytes or a tuple of bytes, not str\r\n\r\n\r\n\t [[{{node PyFunc}}]]\r\n```\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e111c8e4edca3eadedea8e791a45615a/43757.ipynb). Thanks!", "@AkshayRoyal can you give a run with\r\n```\r\nds = tf.data.Dataset.from_generator(\r\n    lambda: img_gen.flow_from_directory(flowers),\r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,256,256,3], [32,5])\r\n)\r\n```", "@bhack . Thanks for answering. Please fix the issue with the example too as it does not work the way it was expected and it should be removed from example as it is misleading\r\n\r\nWhat worked?\r\n```\r\nds = tf.data.Dataset.from_generator(\r\n    lambda: img_gen.flow_from_directory(flowers),\r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,256,256,3], [32,5])\r\n)\r\n```\r\nAND\r\n\r\n```\r\nfrom funtools import partial\r\nds = tf.data.Dataset.from_generator(\r\n    partial(img_gen.flow_from_directory,flowers),\r\n    output_types=(tf.float32, tf.float32), \r\n    output_shapes=([32,256,256,3], [32,5])\r\n)\r\n```\r\n", "/cc @MarkDaoust ", "Fix incoming.\r\n\r\nThanks @AkshayRoyal.\r\nThanks @bhack.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43757\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43757\">No</a>\n"]}, {"number": 43793, "title": "Fatal Exception: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found", "body": "**System information**\r\n\r\nMobile Device - Android - across multiple Android version (6, 7, 8)\r\n\r\n**Describe the current behavior**\r\n\r\nInvoking `org.tensorflow.lite.Interpreter` causes crash on some cases\r\n\r\n**Describe the expected behavior**\r\n\r\nShould not crash\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI am getting this on crash analysis tool. Since this is not reproducible on my devices I am not able to produce a standalone code.\r\n\r\n**Other info / logs** \r\n\r\n```\r\n\r\nFatal Exception: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found\r\nFalling back to OpenGL\r\nTfLiteGpuDelegate Init: No EGL error, but eglChooseConfig failed.\r\nTfLiteGpuDelegate Prepare: delegate is not initialized\r\nNode number 31 (TfLiteGpuDelegateV2) failed to prepare.\r\n\r\nRestored previous execution plan after delegate application failure.\r\n       at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(NativeInterpreterWrapper.java)\r\n       at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:85)\r\n       at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:61)\r\n       at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:224)\r\n       at a.b.c..data.Posenet.getInterpreter(Posenet.java:184)\r\n       at a.b.c..data.Posenet.estimateSinglePose(Posenet.java:293)\r\n       at a.b.c..call.ImageAnalyser.processImage(ImageAnalyser.java:157)\r\n       at a.b.c..call.ImageAnalyser.access$processImage(ImageAnalyser.java:26)\r\n       at a.b.c..call.ImageAnalyser$processImageForAnalysis$2.invokeSuspend(ImageAnalyser.java:127)\r\n       at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(BaseContinuationImpl.java:33)\r\n       at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.java:56)\r\n       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)\r\n       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)\r\n       at java.lang.Thread.run(Thread.java:764)\r\n\r\n```\r\n", "comments": ["Hello @jvishnuvardhan any update on this? Anything more I can help with here?", "@archie94 Can you provide a snippet of your inference code in Java? It might help us dig into whats happening.\r\n\r\nAlso adding @impjdi who might know more about the specific errors.", "Hi @srjoglekar246 \r\n\r\nIt is pretty much same as this sample https://github.com/tensorflow/examples/blob/master/lite/examples/posenet/android/posenet/src/main/java/org/tensorflow/lite/examples/posenet/lib/Posenet.kt", "@srjoglekar246 If it wasn't able to load the delegate with that error message, it should safely fallback to OpenGL, but I've never seen that \"No EGL error, but eglChooseConfig failed.\" in my last 3 years working on this project.  But then when that fails, we should safely fallback to CPU mode.\r\n\r\n@archie94 Rather than \"Mobile Device - Android - across multiple Android version (6, 7, 8)\", can you specifically name devices?  We'll see whether we can repro if we have the device...", "Hmm I agree. \"Restored previous execution plan after delegate application failure.\" indicates we did recover to CPU on the native side,  but we might be treating that as an error in the JNI layer.", "Thank you for your response! \r\n\r\nSure here are some devices on which we are facing this issue.\r\n\r\nSamsung\r\n- Galaxy J3(2016)\r\n- Galaxy J3(2016)\r\n- Galaxy Tab E 9.6\r\n\r\nLGE\r\n- LG Phoenix 4\r\n- LG K8(2018)\r\n- LG K8(2018)\r\n\r\nCherry_Mobile\r\n- Flare_S7_Prime\r\n\r\nThe one area where we differ from the above sample is we select `GpuDelegate` if the device supports OpenGL ES 2.0 API.", "Oh, our GPU delegate only supports OpenGL ES 3.1 and above, as we employ compute shaders which are not available in 3.0 or below.", "Oh! I thought they 3.x was backwards compatible!\r\n\r\nThat may have been the case? Allow me some time to make the change and get back to you on this.", "One week after the OpenGL ES 3.1 check there are no issues on the new release. I think this issue is resolved.\r\n\r\nThank you @impjdi @srjoglekar246 for you help :) ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43793\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43793\">No</a>\n"]}, {"number": 43756, "title": "Hi, am trying to visualize the loss function using tensorboard ", "body": "\r\nHi am trying to view loss function using tensorboard , am using google colab, i edit my code as following:\r\n`import tensorflow as tf\r\nimport datetime\r\n%load_ext tensorboard\r\n\r\nsess = tf.Session()\r\n\r\nfile_writer = tf.summary.FileWriter('/path/to/logs', sess.graph)\r\nlogdir = os.path.join(\r\n    \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)`\r\n\r\nand while calling train() i added \r\n\r\n`custom_callbacks=[tensorboard_callback]`\r\n\r\nit gives me the following error\r\n\r\n`\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)\r\n     59           \"allowed values: %s\" %\r\n     60           (param_name, dtypes.as_dtype(dtype).name,\r\n---> 61            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\n     62 \r\n     63 \r\n\r\nTypeError: Value passed to parameter 'values' has DataType bool not in list of allowed values: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, float16, uint32, uint64\r\n`\r\n", "comments": ["@Rimehdaoudi \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorboard/issues/1340#issuecomment-529612368) as per which this error does not exist in 2.x version, could you please upgrade your tf version as there is no support for 1.x and let us know if the issue exist.\r\nyou may also refer to issues with siilar error: [link](https://stackoverflow.com/questions/44417133/typeerror-value-passed-to-parameter-a-has-datatype-not-in-list-of-allowed-val/63300437#63300437), [link1](https://stackoverflow.com/questions/44822999/tensorflow-typeerror-value-passed-to-parameter-input-has-datatype-uint8-not-in).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43756\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43756\">No</a>\n"]}, {"number": 43754, "title": "Fix TFLite quantization example", "body": "The TFLite documentation at https://www.tensorflow.org/lite/guide/get_started#quantization contained a slight error. The name of the quantized model variable was `tflite_quant_model`, but on the line below it was used as `tflite_quantized_model`.\r\n\r\nAlso I think that the example could use the proper `with open(...)` pattern? I'll add it to this PR if you agree.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43754) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43754) for more info**.\n\n<!-- ok -->", "@av8ramit Can you check this flow? The bot call again a kokoro rebuilds after the 2nd approval (by @mihaimaruseac) without any intermediate commit between the two approvals.", "Looping in @rthadur who owns the bot now, I've moved on to another project.", "@bhack @av8ramit bot applies labels irrespective of commit.", "Don't we waste build cycles and increase waiting times?", "A 2nd approval on the same identical commit doesn't require another build I think.", "you are right , will try to fix this. Thank you"]}, {"number": 43753, "title": "Segmentation fault (core dumped)", "body": "**System information**\r\n- OS Platform and Distribution :CentOS Linux release 7.7.1908\r\n-TensorFlow version:2.3.0\r\n\r\nI try to convert [the tensorflow offical image caption model ](https://www.tensorflow.org/tutorials/text/image_captioning?hl=en)to TFLite model \r\n\r\nAnd Now I have successfully convert the model using ```tf.lite.TFLiteConverter.from_concrete_functions```\r\nas following:\r\n```\r\n@tf.function\r\ndef evaluate(img_tensor_val):\r\n    temp_input = tf.expand_dims(img_tensor_val, 0)\r\n    img_tensor_val = image_features_extract_model(temp_input)\r\n    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\r\n    hidden = decoder.reset_states(batch_size=1)\r\n\r\n    features = encoder(img_tensor_val)\r\n\r\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\r\n    result = []\r\n\r\n    for i in range(max_length):\r\n        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\r\n        print(predictions.shape)\r\n        # result.append(predictions)\r\n        predicted_id = tf.random.categorical(predictions, 1)[0][0]\r\n        #\r\n        #\r\n        result.append(predicted_id)\r\n        #\r\n        #\r\n        # if predicted_id == 3:\r\n        #     return result\r\n        # # result.append(tf.gather(tokenizer.index_word, predicted_id))\r\n        # #\r\n        # # if tf.gather(tokenizer.index_word, predicted_id) == '<end>':\r\n        # #     return result\r\n        #\r\n        dec_input = tf.expand_dims([predicted_id], 0)\r\n    return result\r\n\r\nexport_dir = \"./\"\r\ntflite_enc_input = ''\r\nckpt.f = evaluate\r\nto_save = evaluate.get_concrete_function(tf.TensorSpec(shape=(299, 299, 3),dtype=tf.dtypes.float32))\r\n\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nAnd I Visualize the converted_model.tflite by [Netorn:](https://drive.google.com/file/d/1CXCJHVauGiccFpW8itIPUX4kgbnpCgLj/view?usp=sharing)\r\nBut when I invoke the interpreter the problem came:\r\n**LOG:**\r\n\r\n```\r\n2020-10-03 12:11:24.049222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-03 12:11:30.184705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-10-03 12:11:30.213363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:af:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-10-03 12:11:30.213414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-03 12:11:30.219666: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-03 12:11:30.223018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-03 12:11:30.224419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-03 12:11:30.227861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-03 12:11:30.230195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-03 12:11:30.236320: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-03 12:11:30.239374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-03 12:11:30.239829: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-03 12:11:30.248265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz\r\n2020-10-03 12:11:30.249524: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615faa7fa90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-03 12:11:30.249552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-03 12:11:30.381691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615faaec0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-10-03 12:11:30.381734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\n2020-10-03 12:11:30.383860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:af:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-10-03 12:11:30.383900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-03 12:11:30.383930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-03 12:11:30.383944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-03 12:11:30.383959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-03 12:11:30.383973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-03 12:11:30.383987: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-03 12:11:30.384002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-03 12:11:30.387738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-03 12:11:30.387786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-03 12:11:31.156790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-03 12:11:31.156840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-10-03 12:11:31.156853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-10-03 12:11:31.160006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30098 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\r\n**(299, 299, 3)**\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n2020-10-03 12:11:31.760387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:af:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2020-10-03 12:11:31.760470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-03 12:11:31.760523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-03 12:11:31.760551: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-03 12:11:31.760577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-03 12:11:31.760601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-03 12:11:31.760625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-03 12:11:31.760647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-03 12:11:31.763282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-10-03 12:11:31.763329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-03 12:11:31.763346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-10-03 12:11:31.763360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-10-03 12:11:31.766083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30098 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\r\n**INFO: TfLiteFlexDelegate delegate: 51 nodes delegated out of 2014 nodes with 51 partitions.**\r\n\r\n**Segmentation fault (core dumped)**\r\n```\r\n\r\n**The invoke of Interpreter**\r\n```\r\ndef load_image(image_path):\r\n    img = tf.io.read_file(image_path)\r\n    img = tf.image.decode_jpeg(img, channels=3)\r\n    img = tf.image.resize(img, (299,299))\r\n    img = tf.keras.applications.inception_v3.preprocess_input(img)\r\n    return img, image_path\r\n\r\nimage = load_image('./test.jpg')[0]\r\nprint(image.shape)\r\n\r\n\r\ninterpreter = tf.lite.Interpreter(model_path='./converted_model.tflite')\r\ninput_details = interpreter.get_input_details()\r\ninterpreter.allocate_tensors()\r\ninterpreter.set_tensor(input_details[0]['index'], image)\r\ninterpreter.invoke()\r\n\r\nraw_prediction = interpreter.tensor(\r\n    interpreter.get_output_details()[0]['index'])()\r\nprint(raw_prediction)\r\n```\r\n\r\nPlease tell me what 's the problem of the program?What's the meaning of 'Segmentation fault (core dumped)' ?\r\n\r\n", "comments": ["@DavidInWuhanChina,\r\nOn trying to convert the model to TF Lite, I am facing an error stating `TypeError: reset_states() got an unexpected keyword argument 'batch_size'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8b910c4d8a0839068d1cbb07d0da049f/43753.ipynb#scrollTo=lbHLa1sxkGI0&line=3&uniqifier=1). \r\n\r\nCould you please share the SavedModel file or the .pb file you are using to convert the model, as well as the `converted_model.tflite`, so that we can reproduce the issue on our end. Thanks!", "> \r\n> \r\n> @DavidInWuhanChina,\r\n> On trying to convert the model to TF Lite, I am facing an error stating `TypeError: reset_states() got an unexpected keyword argument 'batch_size'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8b910c4d8a0839068d1cbb07d0da049f/43753.ipynb#scrollTo=lbHLa1sxkGI0&line=3&uniqifier=1).\r\n> \r\n> Could you please share the SavedModel file or the .pb file you are using to convert the model, as well as the `converted_model.tflite`, so that we can reproduce the issue on our end. Thanks!\r\n\r\nThe link of checkpoint is [here](https://drive.google.com/drive/folders/1FFSQPJ3Susgn47VIXGf3qOJBoyU4Db1a?usp=sharing).The link of `converted_model.tflite` is [here](https://drive.google.com/file/d/1vViD2qEyPVEzB6LQGQwDuczrK27LbJ6z/view?usp=sharing).After I switch the GPU to CPU, Now I can print the `raw_prediction = 293`.But it's different from the expected sequence List.Why?Can we figure out the correct concrete_functions?", "Was able to reproduce the issue.\r\n\r\nSession crashes on running the code with [GPU](https://colab.research.google.com/gist/amahendrakar/254044396b179ef50cbd5e9344e4c6b1/43753-gpu.ipynb). Whereas, with [CPU](https://colab.research.google.com/gist/amahendrakar/b3a25266fd1d0e40d04d6a266c3798d8/43753-cpu.ipynb#scrollTo=Hxcr3q3nDxYu) the `raw_prediction` output is printed. Please find the attached gist. Thanks!", "> \r\n> \r\n> Was able to reproduce the issue.\r\n> \r\n> Session crashes on running the code with [GPU](https://colab.research.google.com/gist/amahendrakar/254044396b179ef50cbd5e9344e4c6b1/43753-gpu.ipynb). Whereas, with [CPU](https://colab.research.google.com/gist/amahendrakar/b3a25266fd1d0e40d04d6a266c3798d8/43753-cpu.ipynb#scrollTo=Hxcr3q3nDxYu) the `raw_prediction` output is printed. Please find the attached gist. Thanks!\r\n\r\nI have edit the [gist](https://colab.research.google.com/gist/DavidInWuhanChina/f83e3e11009211f3469436bbc069b18a/43753.ipynb).Now the colab crashed when I try to interpreter  the TfLite model.Why? ", "@abattery any idea on this?", "Flex delegate enforces using CPU kernels not the GPU kernels in the TF core project since the mobile environment does not have equivalent capability of the training environment. When you need to convert your TF model for TFLite, please make sure use CPU kernels instead of GPU kernels.", "@abattery don't we need to mention this on https://www.tensorflow.org/lite/guide/ops_select ?", "@terryheo Good point. We should mention this in the above page.", "@abattery Is this the case even if the only conversion you're doing is to fp16? I'm not looking to deploy on a mobile device. I just wanted faster performance on a GPU server.", "@lminer Only Flex operators will work on CPU kernels and Flex portion will be small in the ordinary TFLite models. You can delegate most of TFLite builtin operators to the OpenCL backend for the server case via GPU delegate. +CCing @terryheo", "@terryheo  could you provide more details regarding GPU delegation on the server side?", "You can use OpenCL supports on x86 servers\r\nIt's experimental and only tested with NVidia CUDA OpenCL 1.2.\r\nIf you want to try, please check the following link.\r\nhttps://www.tensorflow.org/lite/guide/build_cmake#opencl_gpu_delegate", "@DavidInWuhanChina  It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version 2.5 or 2.4.1 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43753\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43753\">No</a>\n", "I believe I am still having this issue, even with TensorFlow 2.8.0. I created a simple example of a Keras model with a single Flex operation, converted it to TFLite and run inference on the TFLite model. Here are the exact same notebooks, except one runs on the CPU and the other runs on the GPU:\r\n- [CPU](https://colab.research.google.com/drive/1g8Aas8_ZjdxAZQD4-tz0lRBHF-2_zkqT?usp=sharing)\r\n- [GPU](https://colab.research.google.com/drive/1J9HhNcIFnJAKiQZ6DEDSjw7vrCEdSExb?usp=sharing)\r\n\r\nThe CPU session runs fine, but the GPU sessions crashes when running inference on the TFLite model.\r\n\r\n\r\n> Flex delegate enforces using CPU kernels not the GPU kernels in the TF core project since the mobile environment does not have equivalent capability of the training environment. When you need to convert your TF model for TFLite, please make sure use CPU kernels instead of GPU kernels.\r\n\r\nIf this is still the culprit, I am still not quite sure how to \"use CPU kernels instead of GPU kernels\". I don't think <https://www.tensorflow.org/lite/guide/ops_select> is updated to explain this issue.", "@[DavidInWuhanChina] Please can you confirm Image captioning with Tensorflow Lite worked or not ?", "[DavidInWuhanChina](https://github.com/DavidInWuhanChina), Please can you confirm Image captioning with Tensorflow Lite worked or not ?\r\n", "[DavidInWuhanChina](https://github.com/DavidInWuhanChina), If Tensorflow lite is working,Please can you share the working Code base with Fix...It is also failing for me."]}, {"number": 43752, "title": "Documentation example for tf.keras.utils.Sequence is incorrect;  'fencepost' error in example code", "body": "\r\non \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\r\n\r\nIn the example generator there is code to return a batch:\r\n\r\n    def __getitem__(self, idx):\r\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *self.batch_size]\r\n\r\nhowever this returns (batch_size + 1 ) results.   for example if batch_size = 1,  requesting idx 0 returns items of index  0, and 1, two items. \r\n\r\nThis will cause an array overrun when the batch_size is an even multiple of the data size.\r\n\r\nthe correct code is:\r\n\r\n    def __getitem__(self, idx):\r\n        batch_x = self.x[idx * self.batch_size:((idx + 1) *self.batch_size)-1]\r\n        batch_y = self.y[idx * self.batch_size:((idx + 1) *self.batch_size)-1]\r\n\r\n\r\nI see the incorrect code copied all over the place.", "comments": ["oops, was wrong about python behavior with indices."]}, {"number": 43751, "title": "Win10+CUDA11.1+cudnn8.0.4+rtx3090", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Amd 3900x+ nvidia rtx 3090\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:r2.3 v2.3 v2.3.1 v2.4\r\n- Python version:3.8.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.5.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:CUDA11.1+cudnn8.0.4\r\n- GPU model and memory:nvidia rtx 3090 24GB\r\n\r\n**Describe the problem**\r\n\r\nv2.3.1 error  below\r\nERROR: F:/tensorflow-2.3.1/tensorflow/core/kernels/BUILD:3180:18: C++ compilation of rule '//tensorflow/core/kernels:image_ops_gpu' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/itx/_bazel_itx/aorpfopj/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n\r\nv2.4 error below\r\nERROR: C:/users/itx/_bazel_itx/vne2u2k5/external/nsync/BUILD:467:11: C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/itx/_bazel_itx/vne2u2k5/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I have similar error\r\n```\r\nERROR: D:/developpython/tools/tensorflow/tensorflow-master/tensorflow/core/kernels/BUILD:258:1: \r\nC++ compilation of rule '//tensorflow/core/kernels:concat_lib' failed (Exit 2): \r\npython.exe failed: error executing command\r\n```", "also builder does not show exact error , just compilation failed", "@lpen027 \r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#gpu).Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43751\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43751\">No</a>\n"]}, {"number": 43750, "title": "Import issue with tensor flow Windows 10 python 3.7", "body": "Hi \r\n\r\nI am trying to make this tutorial work : https://github.com/ildoonet/tf-pose-estimation/blob/master/.\r\nI am having an error in file tf-pose-estimation-master\\tf_pose\\estimator.py\",\r\nThe import \"\"\"import tensorflow.contrib.tensorrt as trt\"\"\" was causing an error, after having read about this issue, using \r\nfrom tensorflow.python.compiler.tensorrt import trt didnt fix it either, what must i do ?\r\n\r\nBest regards\r\n", "comments": ["@andrejmz The link you provided is not working. I ran your code mentioned above wiithout any issue. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/45899b5ba07198f475b3ac04c85fe770/untitled.ipynb). Thanks!\r\n\r\nPlease also, fill the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose) so that we know your system details. Thanks!", "Hi \r\n\r\nHere is the link: https://github.com/ildoonet/tf-pose-estimation\r\nI've just uninstalled tensorflow, than installed tensorflow-1.15.3 as you recommended.\r\nI still have the error:\r\n\r\n  File \"run_webcam_picture.py\", line 8, in <module>\r\n    from tf_pose.estimator import TfPoseEstimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master\\tf_pose\\__init__.py\", line 5, in <module>\r\n    from tf_pose.runner import infer, Estimator, get_estimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master\\tf_pose\\runner.py\", line 8, in <module>\r\n    from tf_pose import eval\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master\\tf_pose\\eval.py\", line 13, in <module>\r\n    from tf_pose.estimator import TfPoseEstimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master\\tf_pose\\estimator.py\", line 14, in <module>\r\n    import tensorflow.contrib.tensorrt as trt\r\nModuleNotFoundError: No module named 'tensorflow.contrib.tensorrt'\r\n\r\nBut I have read about pip silently not removing the files correctly or caching stuff or something like that.\r\n\r\nBest regards", "@andrejmz  I would suggest you to use https://github.com/gsethi2409/tf-pose-estimation this version with the latest tensorflow version.", "So\r\n\r\nI have downloaded files from this link https://github.com/gsethi2409/tf-pose-estimation\r\nThan cd into the appropriate directory than pip install -r requirements.txt\r\nthan python run_webcam_picture.py\r\nand i have errors:\r\n\r\nC:\\Users\\mz\\Downloads\\tf-pose-estimation-master (3)\\tf-pose-estimation-master>python run_webcam.py\r\n2020-10-03 23:58:13.307125: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-10-03 23:58:13.309845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"run_webcam.py\", line 8, in <module>\r\n    from tf_pose.estimator import TfPoseEstimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master (3)\\tf-pose-estimation-master\\tf_pose\\__init__.py\", line 5, in <module>\r\n    from tf_pose.runner import infer, Estimator, get_estimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master (3)\\tf-pose-estimation-master\\tf_pose\\runner.py\", line 8, in <module>\r\n    from tf_pose import eval\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master (3)\\tf-pose-estimation-master\\tf_pose\\eval.py\", line 13, in <module>\r\n    from tf_pose.estimator import TfPoseEstimator\r\n  File \"C:\\Users\\mz\\Downloads\\tf-pose-estimation-master (3)\\tf-pose-estimation-master\\tf_pose\\estimator.py\", line 14, in <module>\r\n    from tensorflow.python.compiler.tensorrt import trt_convert as trt\r\nImportError: cannot import name 'trt_convert' from 'tensorflow.python.compiler.tensorrt' (C:\\Users\\mz\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\__init__.py)\r\n\r\nWhat did i do wrong ?\r\n\r\nBest regards", "Did you try going through numerous such cases already on stackoverflow and issue tab here , I guess https://github.com/tensorflow/tensorflow/issues/23692 is something that can help you maybe this too https://forums.developer.nvidia.com/t/importerror-cannot-import-name-tensorrt-from-tensorflow-python-compiler/80633/2. You need to look into searching for your errors. As i am using Linux I cannot trace your error here, It works fine for me in Linux, also did you compile the c++ library for post processing as mentioned here https://github.com/ildoonet/tf-pose-estimation/tree/master/tf_pose/pafprocess . ", "@andrejmz Please follow the guidance from @ashwin-phadke and also follow the instructions at https://github.com/ildoonet/tf-pose-estimation.\r\n\r\nI am closing this issue as this is not related to a bug or performance related to tensorflow. Please feel free to let me know if I am mistaken. Please post it in Stackoverflow where there is a large community to support this kind of questions. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43750\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43750\">No</a>\n"]}, {"number": 43749, "title": "Memory blowup converting from TFLite to C", "body": "I am observig a blowup of around 6-7x in memory size when converting a model from tflite flatBuffer to C source. \r\n\r\nFor easier reproducibility, I am reporting with the TFLite models obtained from the MNIST tutorial [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb)\r\n\r\nI use the following method for converting from tflite model to C source:\r\n\r\n`\r\n\r\n\tfrom tensorflow.lite.python.util import convert_bytes_to_c_source\r\n\t\r\n\tdef convert_to_c(tflite_model,file_name):\r\n\t\r\n\t    source_text, header_text = convert_bytes_to_c_source(tflite_model,  file_name)\r\n\t\r\n\t    with  open(file_name + '.h',  'w')  as  file:\r\n\t\r\n\t        file.write(header_text)\r\n\t\r\n\t    with  open(file_name + '.cc',  'w')  as  file:\r\n\t\r\n\t        file.write(source_text)\r\n `\r\n \r\nHere is a summary of the sizes before ('.tflite' file) and after converting to C source ('.cc' file):\r\n1. Integer-only quantized model: before - 24.7 KB, after - 156.6 KB, blowup ~ 6.340x\r\n2. Float fallback quantized model: before - 24.6 KB, after - 156.1 KB, blowup ~ 6.346x \r\n3. Dynamic range quantized model: before - 23.8 KB, after - 151.1 KB, blowup ~ 6.349x\r\n4. Normal model: before - 84.5 KB, after - 533.4 KB, blowup ~ 6.312x\r\n   \r\nThis blowup seems independent of the model architecture and parameters because I have tested with few other models and observed a similar trend there as well. \r\n\r\nI wanted to know what is possibly causing this blowup in memory size. In case of a small model (with initial flatbuffer size in kB) it is not a big issue, but for bigger models (with initial flatbuffer size in the order of MB) the final C source size is quite large and often exceeds the flash memory size of micro-controllers. ", "comments": ["Try compiling the .cc file, I think you'll find the object file is pretty similar to the tfilte one.\r\n", "@Rakeshpavan333 \r\nCan you please let us know the tf version on which the issue is faced as you have not filled the issue template.", "@Rakeshpavan333 \r\nPlease update the tf version on which the issue is faced as you have not filled the issue template.", "@Saduf2019  \r\nApologies, I didn't mention the TF version, as the tutorial I shared above ( [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb) ) is using TF 2.3.0. So I am using the same. (the code in the first cell automatically asserts tf version >= 2.3 )\r\n\r\n@yair-ehrenwald  \r\nThe documentation for TFLite [here](https://www.tensorflow.org/lite/microcontrollers) specified in the 'Workflow' section to convert to C byte array and store it in the read-only memory of the micro-controller. Also, most of the microcontroller IDEs available don't compile if the size exceeds the micro-controller flash. \r\n\r\nFor now, I am more interested in learning the cause for this size blowup (instead of fixing/hacking it). I also tried using MicroTensor ( [uTensor](https://utensor.github.io/website/) ) library, which actually makes use of TFLite in the backend. The blowup in this case is around 4.5X, which is slightly less than the 6X blowup using the TFLite  `convert_bytes_to_c_source` method. So, probably, the reason lies partly in the `convert_bytes_to_c_source` method, and partly in how the model information is represented in flatbuffers implementation. ", "@Rakeshpavan333 \r\nPlease share a colab gist with the issue reported for us to analyse.", "Hi @Saduf2019 \r\nHere is the colab link: \r\nhttps://colab.research.google.com/drive/1DAMoBlLijzRorc7HSwOOYDUZPm0ZBQ83?usp=sharing\r\n\r\n\r\n\r\n", "@Rakeshpavan333 \r\nPlease confirm if the [gist here](https://colab.research.google.com/gist/Saduf2019/6f686504cca6be37ec050184b6df225e/untitled431.ipynb) replicates the issue reported.", "Hi, I think I've understood why the source file size is larger. Each hex value would take around 5-6 characters to write in the source. Hence the source would be around 6x larger. So this is not any performance issue.\r\n\r\n The final compiled executable can be smaller depending on the deployment pipeline and IDE used. \r\n\r\nI will close the issue. Thank you for the help. "]}, {"number": 43748, "title": "Some cleanup of the Makefile", "body": "This is progress towards reducing duplicated flags.\r\n\r\nWhile this change directly touches bluepill, hifimini and\r\ncortex_m_gcc_generic, it also moves some flags into the common Makefile\r\nso it may have an impact on other targets too.\r\n\r\nManually confirmed that the size and cycles of the keyword_benchmark\r\ntest are identical before and after this change for xtensa_hifimini.\r\n\r\nRelying on CI for the other targets.\r\n\r\nChange to micro_frontend allows using -Wall and -Wextra for all the builds. These were previously restricted to bluepill and a few other targets.\r\n\r\nThis change is progress towards addressing b/169973190", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43747, "title": "Cannot import tensorflow", "body": "First time post on github.  trying to import tensorflow on local machine.  keep getting a runtime error.  please advise.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip install tensorflow on miniconda3\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cudnn-11.0-windows-x64-v8.0.3.33.zip   cuDNN8.0.4\r\n- GPU model and memory: NVIDIA Quadro K1100M.  This has compute capability 3.0 which is less than the minimum required... see https://www.tensorflow.org/install/gpu#hardware_requirements \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\ntensorflow is not imported.  instead i get a runtime warning... see warning below in Other info / logs\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nimport tensorflow as tf\r\n\r\n**Other info / logs** \r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\miniconda3\\envs\\quant\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\miniconda3\\envs\\quant\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-43-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "> First time post on github. trying to import tensorflow on local machine. keep getting a runtime error. please advise.\r\n> \r\n> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n> * TensorFlow installed from (source or binary): pip install tensorflow on miniconda3\r\n> * TensorFlow version (use command below): 2.2.0\r\n> * Python version: 3.8.5\r\n> * Bazel version (if compiling from source):\r\n> * GCC/Compiler version (if compiling from source):\r\n> * CUDA/cuDNN version: cudnn-11.0-windows-x64-v8.0.3.33.zip   cuDNN8.0.4\r\n> * GPU model and memory: NVIDIA Quadro K1100M.  This has compute capability 3.0 which is less than the minimum required... see https://www.tensorflow.org/install/gpu#hardware_requirements\r\n> \r\n> You can collect some of this information using our environment capture\r\n> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n> You can also obtain the TensorFlow version with:\r\n> \r\n> 1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> 2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n> \r\n> **Describe the current behavior**\r\n> \r\n> tensorflow is not imported. instead i get a runtime warning... see warning below in Other info / logs\r\n> \r\n> **Describe the expected behavior**\r\n> \r\n> **Standalone code to reproduce the issue**\r\n> \r\n> import tensorflow as tf\r\n> \r\n> ## **Other info / logs**\r\n> ImportError Traceback (most recent call last)\r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in\r\n> 57\r\n> ---> 58 from tensorflow.python.pywrap_tensorflow_internal import *\r\n> 59\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in\r\n> 27 return _mod\r\n> ---> 28 _pywrap_tensorflow_internal = swig_import_helper()\r\n> 29 del swig_import_helper\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n> 23 try:\r\n> ---> 24 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> 25 finally:\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\imp.py in load_module(name, file, filename, details)\r\n> 241 else:\r\n> --> 242 return load_dynamic(name, filename, file)\r\n> 243 elif type_ == PKG_DIRECTORY:\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\imp.py in load_dynamic(name, path, file)\r\n> 341 name=name, loader=loader, origin=path)\r\n> --> 342 return _load(spec)\r\n> 343\r\n> \r\n> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> ImportError Traceback (most recent call last)\r\n> in\r\n> ----> 1 import tensorflow as tf\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow__init__.py in\r\n> 39 import sys as _sys\r\n> 40\r\n> ---> 41 from tensorflow.python.tools import module_util as _module_util\r\n> 42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n> 43\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python__init__.py in\r\n> 48 import numpy as np\r\n> 49\r\n> ---> 50 from tensorflow.python import pywrap_tensorflow\r\n> 51\r\n> 52 # Protocol buffers\r\n> \r\n> ~\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in\r\n> 67 for some common reasons and solutions. Include the entire stack trace\r\n> 68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n> ---> 69 raise ImportError(msg)\r\n> 70\r\n> 71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n> \r\n> ImportError: Traceback (most recent call last):\r\n> File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n> _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\imp.py\", line 242, in load_module\r\n> return load_dynamic(name, filename, file)\r\n> File \"C:\\Users\\Jeff\\miniconda3\\envs\\quant\\lib\\imp.py\", line 342, in load_dynamic\r\n> return _load(spec)\r\n> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/errors\r\n> \r\n> for some common reasons and solutions. Include the entire stack trace\r\n> above this error message when asking for help.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43747\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43747\">No</a>\n", "@DJJD17 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download [the latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43747\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43747\">No</a>\n"]}, {"number": 43746, "title": "[XLA/GPU] clear operands for removed HLOs.", "body": "This avoids possible accesses to the Null operands.\r\n\r\nOperands of a removed instruction is not cleared but only set to NULL. A more sound behavior should be to also clear the operands for the removed instructions, so that we avoid potential accesses to the NULL operands.\r\n\r\nThis fixed a crash case encountered by https://github.com/tensorflow/tensorflow/pull/43051.\r\n", "comments": ["@thomasjoerg, the change ran through NV's internal CI tests well. Please help to take a look and let's see if it can also run through your CIs well.", "@thomasjoerg \r\nCould you help to take a look of this one liner? Thanks!"]}, {"number": 43745, "title": "Keras Backend ones_like with Lambda is not serializable", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Databricks Runtime 7.3\r\n- TensorFlow installed from (source or binary):  binary\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: 3\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: AWS p3.xlarge\r\n\r\n**Describe the current behavior**\r\nWrapping a `tf.keras.backend.ones_like` in a `tf.keras.layer.Lambda` fails serialization.\r\n\r\nThe following code creates the model that fails to serialize:\r\n```python\r\nx = keras.Input(shape=1, name=\"x\")\r\nones_like_layer = keras.layers.Lambda(K.ones_like, name=\"ones_like\")\r\nones_like_layer(x)\r\nlogits = keras.layers.Dense(1, activation=\"sigmoid\")\r\n\r\nmodel = keras.Sequential([x, ones_like_layer, logits], name=\"ones_like_model\")\r\n```\r\n\r\nErrors:\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\nTypeError: 'str' object is not callable\r\nDuring handling of the above exception, another exception occurred:\r\nTypeError                                 Traceback (most recent call last)\r\n11 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in wrapper(*args, **kwargs)\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    204       # TypeError, when given unexpected types.  So we need to catch both.\r\n--> 205       result = dispatch(wrapper, args, kwargs)\r\n    206       if result is not OpDispatcher.NOT_SUPPORTED:\r\n    207         return result\r\nTypeError: 'module' object is not callable\r\n````\r\n\r\nThis happens on TF 2.3 and TF Nightly.  See https://colab.research.google.com/drive/1ih41e5b6jw_3iSm9pKSOcW_Kf5y8ktU5?usp=sharing .\r\n\r\n**Describe the expected behavior**\r\nThe model should be serializable.\r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nWorkaround - instead of using the `Lambda`, just call `ones_like` directly.  This works but leads to the model being less interpretable.  This requires using the Functional model.\r\n\r\nSee also: https://github.com/tensorflow/tensorflow/issues/41244#issuecomment-698918718", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/4cb86c00223e42eab4fbbd7d7b4a3b70/43745.ipynb). Thanks!", "FYI - `tf.ones_like` also suffers from this serialization issues as well.\r\n\r\nA workaround is:\r\n```python\r\nclass OnesLike(keras.layers.Layer):\r\n  def call(self, x):\r\n    return K.ones_like(x)\r\n```", "Adding the `contributions welcome` label to this issue for further investigation by the community. If you are interested in working on this issue, please leave a comment and I will assign it to you. Thanks!", "@jeisinge When I update one line (Lambda layer), everything worked without any error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/00813ad0f5980624a1d6d1f937fa6022/43745.ipynb)\r\n\r\nline before \r\n\r\n`ones_like_layer = keras.layers.Lambda(K.ones_like, name=\"ones_like\")`\r\n\r\nline after updating\r\n\r\n`ones_like_layer = keras.layers.Lambda(lambda x:K.ones_like(x), name=\"ones_like\")`\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n\r\n", "Unfortunately, I am still seeing the error in my production on TF 2.3.1.\r\n\r\nWith that being said, I just tested on Colab.  This workaround works on 2.3.0+ just like the `OnesLike` workaround.\r\n\r\nThe original code still fails on tf-nightly.  Is it required to use a Python `lambda` in a Lambda layer?  I thought that any functions would work there?", "@nikitamaia With @tomerk commit https://github.com/tensorflow/tensorflow/commit/229cbce4caa531b9f9695e98b38909dfeed234aa on TF master/2.5.0x now we claim:\r\n```\r\nThe `Lambda` layer exists so that arbitrary expressions can be used\r\n  as a `Layer` when constructing `Sequential`\r\n  and Functional API models. `Lambda` layers are best suited for simple\r\n  operations or quick experimentation. For more advanced use cases, follow\r\n  [this guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\r\n  for subclassing `tf.keras.layers.Layer`.\r\n```\r\n```\r\n  WARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!\r\n```\r\n\r\nSo can we clarify with the team what we want to achieve here with a candidate PR?\r\n\r\n|  jeisinge: Is it required to use a Python lambda in a Lambda layer? I thought that any functions would work there?\r\n\r\nE.g. not all the lambda functions can be easy expressed inline (control flow etc..).\r\n", "@tomerk, the docstring was updated in https://github.com/tensorflow/tensorflow/commit/229cbce4caa531b9f9695e98b38909dfeed234aa. Could we make it bit explicit for what limitation it could have?", "It could be nice if we explain why we have this current limitation and if we want any contribution on this specific topic.", "After looking at the above comments, I analysed the code by going in depth function call trace.\r\n\r\nI compared below two scenarios:\r\nSerializability of model is affected based on previous layer.\r\n`model = keras.Sequential([ones_like_layer, logits], name=\"ones_like_model\")` is serializable but `model = keras.Sequential([x, ones_like_layer, logits], name=\"ones_like_model\")` is not.\r\n\r\nThe `Lambda` layer seems serializable but when `Input` layer is passed before `Lambda` . In that case, the FullArgSpec of `ones_like` before and after are as below:\r\n#### Before\r\n```\r\nFullArgSpec(args=['tensor', 'dtype', 'name', 'optimize'], varargs=None, varkw=None, defaults=(None, None, True), kwonlyargs=[], kwonlydefaults=None, annotations={})\r\n```\r\n#### After\r\n```\r\nFullArgSpec(args=[], varargs='args', varkw='kwargs', defaults=None, kwonlyargs=[], kwonlydefaults=None, annotations={})\r\n```\r\n\r\n### Observations\r\n- `generic_utils.func_dump()` and `generic_utils.func_load()` looks good and the error can't be there.\r\n- The closures are different in both the cases (before and after) for dumped function code. The closure before looks like `(<function ones_like at 0x7f9ea3d35290>, <function ones_like at 0x7f9ea3d35320>)` and closure after looks like `['ones_like', 'ones_like']`. This may be the problem but I am not sure yet why and how.\r\n\r\n@bhack , @qlzh727, @jvishnuvardhan - Can you point me to the direction where error can be?", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210528, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/0e2d302f2507a44ca3aa74062f8f3041/43745.ipynb). Thanks!", "I think that you need to use something like:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nx = keras.layers.Input(shape=(1), name=\"input_layer\")\r\nones_like_layer = keras.layers.Lambda(lambda x: tf.ones_like(x), name=\"ones_like\")\r\nones_like_layer(x)\r\nlogits = keras.layers.Dense(1, activation=\"sigmoid\")\r\nmodel = keras.Sequential([x, ones_like_layer, logits], name=\"ones_like_model\")\r\nkeras.models.model_from_json(model.to_json())\r\n```\r\n\r\nAlso from the documention:\r\n> Variables: While it is possible to use Variables with Lambda layers, this practice is discouraged as it can easily lead to bugs. For instance, consider the following layer:\r\npython scale = tf.Variable(1.) scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)\r\nBecause scale_layer does not directly track the scale variable, it will not appear in scale_layer.trainable_weights and will therefore not be trained if scale_layer is used in a Model.\r\nA better pattern is to write a subclassed Layer:\r\n```python \r\nclass ScaleLayer(tf.keras.layers.Layer): def init(self): super(ScaleLayer, self).init() self.scale = tf.Variable(1.)\r\n  def call(self, inputs):\r\n    return inputs * self.scale\r\n```\r\n\r\n> In general, Lambda layers can be convenient for simple stateless computation, but anything more complex should use a subclass Layer instead.", "FYI - still an issue in TF 2.6.  New exception:\r\n\r\n```python\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/backend.py in wrapper(*args, **kwargs)\r\n    205     try:\r\n--> 206       return target(*args, **kwargs)\r\n    207     except (TypeError, ValueError):\r\n\r\nTypeError: 'str' object is not callable\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNameError                                 Traceback (most recent call last)\r\n\r\n13 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/backend.py in wrapper(*args, **kwargs)\r\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    209       # TypeError, when given unexpected types.  So we need to catch both.\r\n--> 210       result = dispatch(wrapper, args, kwargs)\r\n    211       if result is not OpDispatcher.NOT_SUPPORTED:\r\n    212         return result\r\n\r\nNameError: name 'dispatch' is not defined\r\n```\r\n\r\nSee https://colab.research.google.com/gist/jeisinge/a08614cc802516327484d0ab9dbf03d9/43745.ipynb#scrollTo=x07lI1S5v6cC .", "Hi @jeisinge! I just made few changes according to this [thread](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda#variables)  in lambda layer as below. \r\n`ones_like_layer = keras.layers.Lambda(lambda x:K.ones_like(x), name=\"ones_like\")` and I was able resolve this issue in 2.7. Attaching [Gis](https://colab.research.google.com/gist/mohantym/c6adf0691b30d41ad1e6050a44838c49/43745.ipynb#scrollTo=1WYW-rQkfCuQ)t for reference .Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Correct.\r\n```python\r\nones_like_layer = keras.layers.Lambda(lambda x: K.ones_like(x), name=\"ones_like\")\r\n```\r\nSucceeds.\r\n\r\nHowever, the original issue,\r\n```python\r\nones_like_layer = keras.layers.Lambda(K.ones_like, name=\"ones_like\")\r\n```\r\nfails.  The workaround is fine for me.  Feel free to close out or add extra documentation!", "Ok @jeisinge ! Thanks for confirming the same! Closing this issue as it seems to be resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43745\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43745\">No</a>\n"]}, {"number": 43743, "title": "person_detection benchmarks do not build for STM32F4", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): #43509 \r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): STM32F4\r\n\r\nAfter #43509 is merged, remove the exclusion for the person_detection and person_deteciton_experimental benchmarks and then:\r\n\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=stm32f4 TAGS=cmsis-nn person_detection_benchmark\r\n```\r\nwill give the following error:\r\n```\r\n/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: tensorflow/lite/micro/tools/make/gen/stm32f4_cortex-m4/bin/person_detection_benchmark section `.rodata' will not fit in region `FLASH'\r\n/home/advaitjain/github/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: tensorflow/lite/micro/tools/make/gen/stm32f4_cortex-m4/bin/person_detection_benchmark section `.bss' will not fit in region `RAM'\r\n/home/advaitjain/github/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: region `RAM' overflowed by 72568 bytes\r\n/home/advaitjain/github/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: region `FLASH' overflowed by 158376 bytes\r\ncollect2: error: ld returned 1 exit status\r\nmake: *** [tensorflow/lite/micro/benchmarks/Makefile.inc:31: tensorflow/lite/micro/tools/make/gen/stm32f4_cortex-m4/bin/person_detection_benchmark] Error 1\r\n```\r\n\r\nThe easy fix is to increase the numbers here https://github.com/tensorflow/tensorflow/blob/27d26a8d86bceda282ad9ba3e3116a00759d4ebc/tensorflow/lite/micro/tools/make/targets/stm32f4/stm32f4.lds#L34-L37 but will let the CMSIS-NN team weigh in on this.\r\n", "comments": ["@mansnils @freddan80  what do you think?", "@advaitjain sounds like a good idea. I think the numbers were derived from the Bluepill target originally. The STM32M4 seem to support a wide range of memory configs: https://www.st.com/en/microcontrollers-microprocessors/stm32f4-series.html\r\n", "I think the .ld should map the settings here:\r\nhttps://github.com/renode/renode/blob/master/platforms/cpus/stm32f4.repl\r\n", "@mansnils can look at this next week. I think the only change needed is:\r\n\r\n```\r\nMEMORY { \r\n RAM (xrw) : ORIGIN = 0x20000000, LENGTH = 256K \r\n FLASH (rx) : ORIGIN = 0x8000000, LENGTH =  2048K\r\n } \r\n\r\n```\r\nAnd perhaps remove the outdated comments in the top of the file:\r\n\r\n```\r\n/* Copied and modified from: tensorflow/lite/micro/tools/make/targets/bluepill/bluepill.lds\r\n\r\n*/\r\n\r\n/*\r\n * 0x00000000 - 0x07ffffff - aliased to flash or sys memory depending on BOOT jumpers.\r\n * 0x08000000 - 0x0801ffff - Flash.\r\n * 0x1ffff000 - 0x1ffff7ff - Boot firmware in system memory.\r\n * 0x1ffff800 - 0x1fffffff - Option bytes.\r\n * 0x20000000 - 0x20004fff - SRAM.\r\n * 0x40000000 - 0x40023400 - Peripherals\r\n */\r\n```\r\n\r\n@advaitjain let us know if you prefer us to fix this.", "yes, a PR from you guys would be excellent.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43743\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43743\">No</a>\n"]}, {"number": 43742, "title": "Remove Unsupported gpu architecture compute_80", "body": "", "comments": []}, {"number": 43741, "title": "[INTEL MKL] Enable DNNL BatchMatMul support with broadcast and update oneDNN to v1.6.4.", "body": "This PR enables new features from DNNL to perform BatchMatMul with broadcast. Current support is up to rank 12 tensors. Earlier, the BatchMatMul op was using cblas api from Intel Math Kernel Library(MKL).", "comments": ["@penpornk Thanks for the review and great suggestions. I have addressed them. Please check."]}, {"number": 43740, "title": "Assertion error in Keras model with two string inputs and single output", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina 10.15.5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nI have created a simple test model to take two strings (base64 encoded images), convert those strings to\r\nimage-shaped tensors (299,299,3) and add the two image-shaped tensors (see Colab link below). The Add layer was\r\nchosen as a simple of demo combining two inputs.\r\n\r\nI am running into an assertion error when calling the model. Any ideas for how to fix this?\r\n\r\nReason for string conversion: when deployed, the model must accept string representations of images from a JSON payload.\r\n\r\nThank you!\r\n\r\n**Describe the expected behavior**\r\nI would expect the model to output a (1,299,299,3) float32 tensor\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1y7Z1W_DxigMYiYb4O4M2OVPScANXye_3?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```python\r\nAssertionError                            Traceback (most recent call last)\r\n~/tc/pixel-crunching/servitup.py in <module>\r\n     97     im2 = get_and_resize(ANOTHER_URL)\r\n     98     batch = tf.constant([im1, im2])\r\n---> 99     y = model(batch)\r\n    100 \r\n    101 \r\n\r\n~/tc/pixel-crunching/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    983 \r\n    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):\r\n--> 985           outputs = call_fn(inputs, *args, **kwargs)\r\n    986 \r\n    987         if self._activity_regularizer:\r\n\r\n~/tc/pixel-crunching/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)\r\n    384     \"\"\"\r\n    385     return self._run_internal_graph(\r\n--> 386         inputs, training=training, mask=mask)\r\n    387 \r\n    388   def compute_output_shape(self, input_shape):\r\n\r\n~/tc/pixel-crunching/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)\r\n    515     for x in self.outputs:\r\n    516       x_id = str(id(x))\r\n--> 517       assert x_id in tensor_dict, 'Could not compute output ' + str(x)\r\n    518       output_tensors.append(tensor_dict[x_id].pop())\r\n    519 \r\n\r\nAssertionError: Could not compute output Tensor(\"add/add:0\", shape=(None, 299, 299, 3), dtype=float32)\r\n```", "comments": ["I figured out my issue: was not shaping the input correctly. Sorry for the false alarm!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43740\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43740\">No</a>\n"]}, {"number": 43739, "title": "[INTEL MKL] Enable DNNL BatchMatMul support with broadcast.", "body": "This PR enables new features from DNNL to perform BatchMatMul with broadcast. Current support is up to rank 12 tensors. Earlier, the BatchMatMul op was using cblas api from Intel Math Kernel Library(MKL).", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43739) for more info**.\n\n<!-- need_author_cla -->", "Submitted from wrong email."]}, {"number": 43738, "title": "Evaluation produces OSError: [Errno 24] Too many open files", "body": "I have a dataset of around 40,000 images. I load them into memory using opencv and I put them in a long python list. Then I use a TimeseriesGenerator, like this:\r\n\r\n``\r\ngenerator = TimeseriesGenerator(allframes, allframes, length=75, sampling_rate=5, stride=2, batch_size=8)\r\n``\r\n\r\nWhere allframes is just a python list where each entry is an image as loaded with opencv.\r\n\r\nI then have a custom generator:\r\n```\r\ndef customGenerator(generator, indexes):\r\n\r\n    while True:\r\n        np.random.shuffle(indexes)\r\n        for i in indexes:\r\n            x,y = generator[i]\r\n            yield (x, y)\r\n```\r\n\r\nand then my train function, im removing some non important lines:\r\n```\r\ndef trainRNNmodel(model, generator):\r\n\r\n    randomize = np.arange( len(generator) - 1 )\r\n    np.random.shuffle(randomize)\r\n    trainLimit = int( 0.9*len(randomize) )\r\n    valsteps = int( 0.1*len(randomize) ) \r\n\r\n    workers = int(multiprocessing.cpu_count()/2)\r\n\r\n    model.fit( x= customGenerator(generator, randomize[:trainLimit]), y=None, \r\n            validation_data = customGenerator(generator, randomize[trainLimit:]), \r\n            epochs=1000, steps_per_epoch=trainLimit, validation_steps=valsteps,\r\n            use_multiprocessing = False, callbacks=callbacks_list)\r\n```\r\n\r\nit works ok, but around epoch 50 I get the same error 24 as the user says. and this happens during validation too.\r\n\r\nI can increase ulimit but this only delays the error.\r\n\r\nNo idea why is it happening because I reckon it's not loading any files during training.", "comments": ["@thephet \r\nPlease share complete stand alone indented code and data-set for us to replicate the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43738\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43738\">No</a>\n"]}, {"number": 43737, "title": "Peezoslug patch 1", "body": "", "comments": ["What is this supposed to do? Can you please describe it? Is there an issue that this solves?\r\n\r\nTo prevent Hacktoberfest abuse, will close and mark this as invalid but will reconsider if we have answers to the above questions."]}, {"number": 43736, "title": "Unable to train the model", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Manjaro 5.4.64 kernel\r\n- TensorFlow installed from (source or binary): Pycharm \r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- GPU model and memory: No GPU\r\n\r\n\r\n**Describe the problem**\r\nI have built a model architecture that takes in multimodal inputs i.e. visual and textual. For visual inputs, I am using the embeddings generated by second to last layer of VGG-19 of 4096 dimension and passing them here. When I do start training the model, the following error shows up:\r\n\r\n```\r\nEpoch 1/300\r\nTraceback (most recent call last):\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: z_log_var/BiasAdd:0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/mvae.py\", line 211, in <module>\r\n    train(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/mvae.py\", line 158, in train\r\n    model.autoencoder.fit(x=[text, im],\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 840, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1843, in _filtered_call\r\n    return self._call_flat(\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1923, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 545, in call\r\n    outputs = execute.execute(\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 72, in quick_execute\r\n    raise core._SymbolicException(\r\ntensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'z_log_var/BiasAdd:0' shape=(None, 64) dtype=float32>, <tf.Tensor 'z_mean/BiasAdd:0' shape=(None, 64) dtype=float32>]\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nimport pdb\r\n\r\nimport tensorflow\r\nfrom keras import regularizers\r\nfrom keras import objectives, backend as K\r\nfrom keras.layers import Dropout, Reshape, Concatenate, Flatten, Bidirectional, Dense, Embedding, Input, Lambda, LSTM, \\\r\n    RepeatVector, TimeDistributed\r\nfrom keras.models import Model\r\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint, TensorBoard\r\nfrom keras.optimizers import Adam, RMSprop\r\nimport keras\r\nimport numpy as np\r\nimport os\r\nfrom sklearn.metrics import precision_score, accuracy_score, precision_recall_fscore_support\r\n\r\n# tensorflow.config.experimental_run_functions_eagerly(True)\r\n\r\n\r\nclass MVAE(object):\r\n\r\n    def create(self, max_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix):\r\n        self.encoder = None\r\n        self.decoder = None\r\n        self.fnd = None\r\n        self.autoencoder = None\r\n        self.embedding_matrix = embed_matrix\r\n        self.vocab_size = self.embedding_matrix.shape[0]\r\n        self.max_length = max_length\r\n        self.latent_dim = latent_dim\r\n        self.reg_lambda = reg_lambda\r\n        self.fnd_lambda = fnd_lambda\r\n        self.image_embed_size = image_embed_size\r\n\r\n        input_txt = Input(shape=(self.max_length,), name='input_txt')\r\n        input_img = Input((image_embed_size,), name='input_img')\r\n\r\n        vae_ce_loss, vae_mse_loss, encoded = self._build_encoder(input_txt, input_img)\r\n        self.encoder = Model(inputs=[input_txt, input_img], outputs=encoded)\r\n\r\n        encoded_input = Input(shape=(self.latent_dim,))\r\n        predicted_outcome = self._build_fnd(encoded_input)\r\n        self.fnd = Model(encoded_input, predicted_outcome)\r\n\r\n        decoded_txt, decoded_img = self._build_decoder(encoded_input)\r\n        self.decoder = Model(encoded_input, [decoded_txt, decoded_img])\r\n\r\n        decoder_output = self._build_decoder(encoded)\r\n\r\n        self.autoencoder = Model(inputs=[input_txt, input_img],\r\n                                 outputs=[decoder_output[0], decoder_output[1], self._build_fnd(encoded)])\r\n        self.autoencoder.compile(optimizer=Adam(1e-5),\r\n                                 loss=['sparse_categorical_crossentropy', vae_mse_loss, 'binary_crossentropy'],\r\n                                 metrics=['accuracy'])\r\n        self.get_features = K.function([input_txt, input_img], [encoded])\r\n        print(self.autoencoder.summary())\r\n\r\n    def _build_encoder(self, input_txt, input_img, latent_dim=64):\r\n        txt_embed = Embedding(self.vocab_size, 32, input_length=self.max_length, name='txt_embed', trainable=False,\r\n                              weights=[self.embedding_matrix])(input_txt)\r\n        lstm_txt_1 = Bidirectional(LSTM(32, return_sequences=True, name='lstm_txt_1', activation='tanh',\r\n                                        kernel_regularizer=regularizers.l2(self.reg_lambda)), merge_mode='concat')(\r\n            txt_embed)\r\n        lstm_txt_2 = Bidirectional(LSTM(32, return_sequences=False, name='lstm_txt_2', activation='tanh',\r\n                                        kernel_regularizer=regularizers.l2(self.reg_lambda)), merge_mode='concat')(\r\n            lstm_txt_1)\r\n        fc_txt = Dense(32, activation='tanh', name='dense_txt', kernel_regularizer=regularizers.l2(self.reg_lambda))(\r\n            lstm_txt_2)\r\n\r\n        fc_img_1 = Dense(1024, name='fc_img_1', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(\r\n            input_img)\r\n        fc_img_2 = Dense(32, name='fc_img_2', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(\r\n            fc_img_1)\r\n\r\n        h = Concatenate(axis=-1, name='concat')([fc_txt, fc_img_2])\r\n        h = Dense(64, name='shared', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(h)\r\n\r\n        def sampling(args):\r\n            z_mean_, z_log_var_ = args\r\n            batch_size = K.shape(z_mean_)[0]\r\n            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=0.01)\r\n            return z_mean_ + K.exp(0.5 * z_log_var_) * epsilon\r\n\r\n        z_mean = Dense(latent_dim, name='z_mean', activation='linear')(h)\r\n        z_log_var = Dense(latent_dim, name='z_log_var', activation='linear')(h)\r\n\r\n        def vae_mse_loss(x, x_decoded_mean):\r\n            mse_loss = objectives.mse(x, x_decoded_mean)\r\n            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\r\n            return mse_loss + kl_loss\r\n\r\n        def vae_ce_loss(x, x_decoded_mean):\r\n            x = K.flatten(x)\r\n            x_decoded_mean = K.flatten(x_decoded_mean)\r\n            xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\r\n            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\r\n            return xent_loss + kl_loss\r\n\r\n        return (\r\n        vae_ce_loss, vae_mse_loss, Lambda(sampling, output_shape=(latent_dim,), name='lambda')([z_mean, z_log_var]))\r\n\r\n    def _build_decoder(self, encoded):\r\n        dec_fc_txt = Dense(32, name='dec_fc_txt', activation='tanh',\r\n                           kernel_regularizer=regularizers.l2(self.reg_lambda))(encoded)\r\n        repeated_context = RepeatVector(self.max_length)(dec_fc_txt)\r\n        dec_lstm_txt_1 = LSTM(32, return_sequences=True, activation='tanh', name='dec_lstm_txt_1',\r\n                              kernel_regularizer=regularizers.l2(self.reg_lambda))(repeated_context)\r\n        dec_lstm_txt_2 = LSTM(32, return_sequences=True, activation='tanh', name='dec_lstm_txt_2',\r\n                              kernel_regularizer=regularizers.l2(self.reg_lambda))(dec_lstm_txt_1)\r\n        decoded_txt = TimeDistributed(Dense(self.vocab_size, activation='softmax'), name='decoded_txt')(dec_lstm_txt_2)\r\n\r\n        dec_fc_img_1 = Dense(32, name='dec_fc_img_1', activation='tanh',\r\n                             kernel_regularizer=regularizers.l2(self.reg_lambda))(encoded)\r\n        dec_fc_img_2 = Dense(1024, name='dec_fc_img_2', activation='tanh',\r\n                             kernel_regularizer=regularizers.l2(self.reg_lambda))(dec_fc_img_1)\r\n        decoded_img = Dense(4096, name='decoded_img', activation='sigmoid')(dec_fc_img_2)\r\n\r\n        return decoded_txt, decoded_img\r\n\r\n    def _build_fnd(self, encoded):\r\n        h = Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(self.fnd_lambda))(encoded)\r\n        h = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(self.fnd_lambda))(h)\r\n        return Dense(1, activation='sigmoid', name='fnd_output')(h)\r\n\r\n\r\ndef train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\r\n    text = np.load('data/train_text.npy')\r\n    im = np.load('data/train_image_embed.npy')\r\n    label = np.load('data/train_label.npy')[:, 1]\r\n\r\n    test_text = np.load('data/test_text.npy')\r\n    test_im = np.load('data/test_image_embed.npy')\r\n    test_label = np.load('data/test_label.npy')[:, 1]\r\n\r\n    embed_matrix = np.load('data/embedding_matrix.npy')\r\n    vocab_size = embed_matrix.shape[0]\r\n\r\n    # temp = np.zeros((text.shape[0], sequence_length, vocab_size))\r\n    # temp[np.expand_dims(np.arange(text.shape[0]), axis=0).reshape(text.shape[0], 1), np.repeat(np.array([np.arange(sequence_length)]), text.shape[0], axis=0), text] = 1\r\n    # text_one_hot = temp\r\n    #\r\n    # temp = np.zeros((test_text.shape[0], sequence_length, vocab_size))\r\n    # temp[np.expand_dims(np.arange(test_text.shape[0]), axis=0).reshape(test_text.shape[0], 1), np.repeat(np.array([np.arange(sequence_length)]), test_text.shape[0], axis=0), test_text] = 1\r\n    # test_text_one_hot = temp\r\n\r\n    if not os.path.exists(path):\r\n        os.makedirs(path)\r\n    if not os.path.exists(path + '/tb'):\r\n        os.makedirs(path + '/tb')\r\n    if not os.path.exists(path + '/weights'):\r\n        os.makedirs(path + '/weights')\r\n    tensorboard = TensorBoard(log_dir=path + '/tb', write_graph=True, write_images=True)\r\n    checkpoint = ModelCheckpoint(path + '/weights/{epoch:02d}.hdf5', monitor='loss', verbose=1, save_best_only=True,\r\n                                 mode='auto')\r\n    reduce_lr = ReduceLROnPlateau(monitor='fnd_output_loss', factor=0.2, patience=6, min_lr=1e-7)\r\n\r\n    model = MVAE()\r\n    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\r\n    model.autoencoder.fit(x=[text, im],\r\n                          y={'decoded_txt': np.expand_dims(text, -1), 'decoded_img': im, 'fnd_output': label},\r\n                          batch_size=128, epochs=300, callbacks=[checkpoint, tensorboard, reduce_lr], shuffle=True,\r\n                          validation_data=([test_text, test_im],\r\n                                           {'decoded_txt': np.expand_dims(test_text, -1), 'decoded_img': test_im,\r\n                                            'fnd_output': test_label}))\r\n\r\n\r\ndef save_features(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\r\n    test_text = np.load('../data/test_text.npy')\r\n    test_im = np.load('../data/test_image_embed.npy')\r\n\r\n    embed_matrix = np.load('../data/embedding_matrix.npy')\r\n    vocab_size = embed_matrix.shape[0]\r\n\r\n    model = MVAE()\r\n    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\r\n    model.autoencoder.load_weights(path + '/weights/286.hdf5')\r\n\r\n    if not os.path.exists(path + '/features'):\r\n        os.makedirs(path + '/features')\r\n\r\n    learnt_features = np.array([]).reshape(0, 64)\r\n    for i in range(test_text.shape[0]):\r\n        text_batch = test_text[i:i + 1]\r\n        im_batch = test_im[i:i + 1]\r\n        batch = model.get_features([text_batch, im_batch])[0]\r\n        learnt_features = np.concatenate([learnt_features, batch])\r\n    np.save(path + '/features/vae_fnd', learnt_features)\r\n\r\n\r\ndef test(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\r\n    test_text = np.load('data/test_text.npy')\r\n    test_im = np.load('data/test_image_embed.npy')\r\n    test_label = np.load('data/test_label.npy')[:, 1]\r\n\r\n    embed_matrix = np.load('data/embedding_matrix.npy')\r\n    vocab_size = embed_matrix.shape[0]\r\n\r\n    model = MVAE()\r\n    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\r\n    model.autoencoder.load_weights(path + '/weights/224.hdf5')\r\n    for i in range(10):\r\n        pred = model.autoencoder.predict([test_text, test_im])[-1]\r\n        pred[pred > 0.5] = 1\r\n        pred[pred <= 0.5] = 0\r\n        print(accuracy_score(test_label, pred))\r\n        print(precision_recall_fscore_support(test_label, pred))\r\n\r\n    pdb.set_trace()\r\n\r\n\r\nif __name__ == '__main__':\r\n    train(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\r\n    test(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\r\n    save_features(20, 4096, 64, 0.05, 0.3, '../models/vae_fnd_0.05_0.3')\r\n\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nI tried adding `tensorflow.config.experimental_run_functions_eagerly(True)` to the code. This error went away but another error showed up later which I guess is because of adding this line only error - \r\n```\r\nEpoch 1/300\r\n2020-10-02 19:48:34.816657: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 130744320 exceeds 10% of free system memory.\r\n2020-10-02 19:48:35.015006: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 130744320 exceeds 10% of free system memory.\r\n2020-10-02 19:48:35.073321: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 130744320 exceeds 10% of free system memory.\r\nTraceback (most recent call last):\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/mvae.py\", line 211, in <module>\r\n    train(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/mvae.py\", line 158, in train\r\n    model.autoencoder.fit(x=[text, im],\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 806, in train_function\r\n    return step_function(self, iterator)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 796, in step_function\r\n    outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1211, in run\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2585, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2945, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 275, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 789, in run_step\r\n    outputs = model.train_step(data)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 756, in train_step\r\n    _minimize(self.distribute_strategy, tape, self.optimizer, loss,\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 2743, in _minimize\r\n    optimizer.apply_gradients(\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 545, in apply_gradients\r\n    return distribute_ctx.get_replica_context().merge_call(\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2715, in merge_call\r\n    return self._merge_call(merge_fn, args, kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2722, in _merge_call\r\n    return merge_fn(self._strategy, *args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 275, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 642, in _distributed_apply\r\n    with ops.control_dependencies(update_ops):\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 5359, in control_dependencies\r\n    return get_default_graph().control_dependencies(control_inputs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 360, in control_dependencies\r\n    return super(FuncGraph, self).control_dependencies(filtered_control_inputs)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 4749, in control_dependencies\r\n    c = self.as_graph_element(c)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3670, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/home/caesar/PycharmProjects/fake-news-detector/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3758, in _as_graph_element_locked\r\n    raise TypeError(\"Can not convert a %s into a %s.\" %\r\nTypeError: Can not convert a NoneType into a Tensor or Operation.\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\nIt is because of the some graph elements due to which previous error showed up. \r\nThank you for your time!\r\n", "comments": ["@DhruvAwasthi \r\n\r\nCan you please share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "Hey @ravikyram, thank you for your prompt response\r\n\r\nHere are the attached files.\r\nWhen you unzip this, the files in /data directory are the supporting files required and mvae.py contains the main code to build the architecture.\r\n\r\n\r\n[architecture.zip](https://github.com/tensorflow/tensorflow/files/5326971/architecture.zip)\r\n", "@DhruvAwasthi \r\n\r\nI am not seeing any files in data folder. Can you please recheck and share with me. Thanks!", "Hey, please unzip this into /data dir\r\n[data.zip](https://github.com/tensorflow/tensorflow/files/5332091/data.zip)\r\n\r\nThank you!", "@DhruvAwasthi \r\n\r\nI tried in colab with TF version 2.3 and i am seeing different error message(`IndexError: too many indices for array`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/4abcd0b094671bee05d80ced53626234/untitled426.ipynb#scrollTo=vJJJxMzFSnGL).Thanks!", "@ravikyram \r\n[Here](https://drive.google.com/file/d/1Wnj1TmUaOSlzDJx8LvyLVizrcm7QM0Kl/view?usp=sharing) is the updated zip, you can use this...\r\nThank you for the patience!\r\n", "@DhruvAwasthi \r\n\r\nI tried in colab with TF version 2.3 and i am seeing the error message (\r\n`ValueError: cannot reshape array of size 1572832 into shape (12957,4096)`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/eb1e1b3f163c017ee07cd0ca950d7f8c/untitled431.ipynb).Thanks!\r\n\r\n", "@ravikyram \r\n\r\nI am sharing a [colab](https://colab.research.google.com/drive/165C3QYuXOp8AQt796JN2_3loXay_GMd1?usp=sharing) with TF version 2.3.1\r\nPlease upload the data.zip file before running.\r\nThank you!\r\n", "I have ran your codein tf-nightly and this is a user error. Please find the gist [here](https://colab.research.google.com/gist/gowthamkpr/95740bdaac8bb5f5ce473ff8e4cd1b55/untitled5.ipynb). Also inorder to understand about symbolic tensors you can look at this [issue](https://stackoverflow.com/questions/59707065/what-are-symbolic-tensors-in-tensorflow-and-keras)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43736\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43736\">No</a>\n"]}, {"number": 43735, "title": "Finalize hadoop filesystem plugins", "body": "@mihaimaruseac \r\nThis PR adds:\r\n- fix for #43647\r\n- fix for `JoinPath` on Windows\r\n- logging\r\n- `ProvideFilesystemSupportFor`", "comments": []}]