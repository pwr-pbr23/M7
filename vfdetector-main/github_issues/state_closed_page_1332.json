[{"number": 13139, "title": "Where can I get the pre-trained models in slim?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13138, "title": "fixed a typo in the documentation", "body": "fixed a typo in the documentation", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13137, "title": "RNN cells parameter naming inconsistency", "body": "In most RNN cells the size is spified by the `num_units` parameter.\r\nThis is true for LSTMCell, LSTMBlockCell and GRUCell.\r\nFor GRUBlockCell the same parameter is called `cell_size`.\r\nThis discrepancy could be problematic in some cases like this code I'm using to create a RNN cell depending on a string parameter passed by the user:\r\n\r\n```\r\ndef get_cell_fn(cell_type):\r\n    if cell_type == 'rnn':\r\n        cell_fn = tf.nn.rnn_cell.BasicRNNCell\r\n    elif cell_type == 'lstm_basic':\r\n        cell_fn = tf.nn.rnn_cell.BasicLSTMCell\r\n    elif cell_type == 'lstm_basic_ln':\r\n        cell_fn = tf.contrib.rnn.LayerNormBasicLSTMCell\r\n    elif cell_type == 'lstm_block':\r\n        cell_fn = tf.contrib.rnn.LSTMBlockCell\r\n    elif cell_type == 'lstm':\r\n        cell_fn = tf.nn.rnn_cell.LSTMCell\r\n    elif cell_type == 'gru':\r\n        cell_fn = tf.nn.rnn_cell.GRUCell\r\n    elif cell_type == 'gru_block':\r\n        # Faster version of GRU (25% faster in my tests)\r\n        cell_fn = tf.contrib.rnn.GRUBlockCell\r\n    else:\r\n        cell_fn = tf.nn.rnn_cell.BasicRNNCell\r\n    return cell_fn\r\n\r\ncell = get_cell_fn(cell_type)(num_units=256)\r\n```\r\n\r\nAs this will return an error in case of GRUBlockCell.\r\n\r\nThe solution is just renaming that parameter and possibly add **kwargs to all cell constructors,as right now only RNNCell has **kwargs.", "comments": ["Added a PR #13153 for `num_units` in `GRUBlockCell`."]}, {"number": 13136, "title": "Branch 169166848", "body": "", "comments": []}, {"number": 13135, "title": "MKL-DNN open source integration.", "body": "This is a modified version of tensorflow to integrate with MKL-DNN open source. This pull request has one op (convolution) and the build setup to build MKL-DNN as a third party library.", "comments": ["Can one of the admins verify this patch?", "@mahmoud-abuzaina, thanks for your PR! By analyzing the history of the files in this pull request, we identified @martinwicke, @keveman and @tensorflower-gardener to be potential reviewers.", "Did you have a particular reviewer in mind?", "Please add @andydavis1 as reviewer also", "@mahmoud-abuzaina if the PR is working, we can also consider merging it.\r\nAs long as it passes all tests, we should be OK.", "Jenkins, test this please.", "The change looks OK to me.\r\nThe only improvement I can think of is, we may want to add the copt to set to a config option in configure.py, so `--config=mkl_dnn` automatically builds with mkl_dnn support.", "@mahmoud-abuzaina also if you think the PR is ready for merge, please edit the PR title to remove DONOTMERGE and for comments only.", "@gunan I think this PR is still not ready to merge because of the bazel mirroring URL for MKL-DNN. I left a note for @jart about that.", "Jenkins, test this please.", "Looks like mkldnn is not off by default. @mahmoud-abuzaina Could you take another look?", "Right @gunan, we are looking at that.", "@gunan We have fixed the issue. Can you run the test again? ", "@mahmoud-abuzaina there is a merge conflict, can you address that and we can kick of the tests again.", "@sb2nov The conflicts were fixed. ", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please.", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "@gunan I see that the MAC tests fail because the compiler flag \"-fopenmp\" is not supported by clang. Currently, MKL-DNN does not support MAC, so I put -fopenmp inside a select statement. ", "CLAs look good, thanks!\n\n<!-- ok -->", "Let's see if it works.\r\nJenkins, test this please.", "Jenkins, test this please.", "@gunan I don't think that MacOS failure now are related to MKL-DNN, can you have a quick look?", "The time issue seems like it could have to do with compiler options:\r\n```\r\n[ RUN      ] TimeUtil.ParseRfc3339Time\r\ntensorflow/core/platform/cloud/time_util_test.cc:26: Failure\r\n      Expected: 1461971724896\r\nTo be equal to: mtime_nsec / 1000 / 1000\r\n      Which is: 1461971683186\r\n```\r\nThe GCS test appears to be non-hermetic :(\r\n\r\n```\r\n2017-09-28 17:14:25.170375: I tensorflow/core/platform/cloud/retrying_utils.cc:77] The operation failed and will be automatically retried in 0 seconds (attempt 1 out of 10), caused by: Unavailable: 503\r\n```\r\nand the exponential backoff seems to be too tight.", "@drpngx Do you know what compiler options we need to check? ", "The MacOS CPU test failure of platform/cloud tests are a known issue. They are flaky in the upgraded xcode compiler.\r\ncoordinator_test issue on windows is also potentially a flake. I will rerun tests just to be sure.\r\n\r\nJenkins, test this please.", "Thank you @gunan. It seems all tests have passed.", "@mahmoud-abuzaina When I look at the successful build logs, I still see mkl getting built for non-mkl builds.\r\n```\r\nINFO: From Compiling external/mkl_dnn/src/cpu/jit_avx512_common_conv_winograd_kernel_f32.cpp:\r\nexternal/mkl_dnn/src/cpu/jit_avx512_common_conv_winograd_kernel_f32.cpp: In static member function 'static mkldnn::impl::status_t mkldnn::impl::cpu::jit_avx512_common_conv_winograd_bwd_weights_kernel_f32::init_conf(mkldnn::impl::cpu::jit_conv_winograd_conf_t&, const convolution_desc_t&, const mkldnn::impl::memory_desc_wrapper&, const mkldnn::impl::memory_desc_wrapper&, const mkldnn::impl::memory_desc_wrapper&)':\r\nexternal/mkl_dnn/src/cpu/jit_avx512_common_conv_winograd_kernel_f32.cpp:648:9: warning: unused variable 'regs_transV' [-Wunused-variable]\r\n     int regs_transV = jcp.ver == ver_4fma ? 6 : 0;\r\n```\r\nI will take another look into this this weekend or monday.", "@gunan Made some changes so MKL-DNN does not get built for non-mkl build. Can you run the test again?", "Jenkins, test this please.", "Looks good. @mahmoud-abuzaina could you retrigger CLA check with the comment `I signed it!`", "I signed it!", "Jenkins, test this please"]}, {"number": 13134, "title": "Increasing the minor version of the nightly version by 1.", "body": "Expedited patch via github.", "comments": []}, {"number": 13133, "title": "Session.run with fetches = list apparently works incorrectly", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: The problem manifests in a standard tutorial and I wrote custom code to better understand it.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.3.0-rc2-20-g0787eee', '1.3.0')\r\n- **Python version**: Python 2.7.12 (default, Nov 19 2016, 06:48:10) [GCC 5.4.0 20160609] on linux2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: no GPU\r\n- **GPU model and memory**: none\r\n\r\n### Describe the problem\r\nThe [TensorFlow Mechanics 101 tutorial](https://tensorflow.rstudio.com/tensorflow/articles/tutorial_tensorflow_mechanics.html) code outputs value of the same Op, loss, in two ways: summary and console output.  The two values do not match.\r\n\r\nThe code is located [here](https://tensorflow.rstudio.com/tensorflow/articles/examples/mnist_fully_connected_feed.html).\r\nTo make the problem clear, I changed the console output format on line 305 to 8 decimals:\r\n\r\n      cat(sprintf('Step %d: loss = %.8f (%.3f sec)\\n',\r\n\r\nI compared the console output for loss with the results of the summary Op (the op is defined on lines 120 and 262, and run on line 308).  I obtained the results of the summary op from the csv file downloaded from tensorboard.\r\n\r\nThe console output is close to the csv file but different, often in the third decimal; they should be identical since the op is the same on the same step.\r\n\r\nI do not copy the output here since it is unstable, changes from one run to another.  (I have not been able to stabilize it with `use_session_with_seed` or with `tf$set_random_seed`.)\r\n\r\nI changed lines 297-298 from\r\n\r\n    values <- sess$run(list(train_op, loss), feed_dict = feed_dict)\r\n    loss_value <- values[[2]]\r\n\r\nto a supposedly equivalent code:\r\n\r\n    sess$run(train_op, feed_dict = feed_dict)\r\n    loss_value = sess$run(loss, feed_dict = feed_dict)\r\n \r\nAfter that the console output agreed fully with summary data obtained from csv.\r\n\r\nI take it that `sess$run(list(...` works incorrectly.\r\n\r\nI do not know whether the problem is in TensorFlow or in the R interface to it.\r\n\r\n", "comments": ["```\r\nvalues <- sess$run(list(train_op, loss), feed_dict = feed_dict)\r\nloss_value <- values[[2]]\r\n```\r\nis not equivalent to \r\n```\r\nsess$run(train_op, feed_dict = feed_dict)\r\nloss_value = sess$run(loss, feed_dict = feed_dict)\r\n```\r\n\r\nThis has been discussed many times, e.g. #12863 ,#10860\r\n", "Thanks!\r\n\r\nI see that if the `fetches` argument in `Session.run` is a list then its elements are executed in the random order.\r\n\r\nI think it is worthwhile to mention this in the [manual](https://www.tensorflow.org/api_docs/python/tf/Session#run).\r\n\r\nThus, there is no bug.\r\n\r\nHowever, I want to make this thread a suggestion to improve the above manual.", "I'm not sure that \"random order\" makes sense to add to the manual because it's an implementation detail. IE, maybe today it's random order, and tomorrow it becomes left to right. Leaving it unspecified gives freedom to change implementation around without violating API guarantees\r\n\r\nCurrently the order is determined by [this part](https://github.com/tensorflow/tensorflow/blob/5747ec38cf9ffaa586b854910af8b57e148e9543/tensorflow/core/common_runtime/executor.cc#L1414) in executor.cc. It schedules ready ops simultaneously which means the order is determined by how fast computations run for each fetch\r\n", "I think it is important to add to the manual that the fetches are run in \"unspecified order which may change from one run to another, possibly in parallel\" to dispel the natural assumption that they are run in the order they appear in the list.\r\n\r\nIn this way you guys will have less threads to answer and close, and we the beginners will have to spend less time breaking our heads figuring out why our code does not work.\r\n\r\nIn fact, I remember checking that manual a few times before submitting [a question to stackoverflow](https://stackoverflow.com/questions/46212821/tensorflow-using-tfsummary-in-tensorflow-mechanics-101-tutorial/46279588#46279588) but the idea that the fetches may run not in the specified order, did not come to my mind.", "This problem had bitten my butt badly at least twice in the past. \r\nThe worst part is that `session.run(ops)` does evaluate `ops` in order they are provided on cpu version tensorflow, but not gpu version of tensorflow.\r\n@yaroslavvb - A warning to user about undefined order in documentation would only be fair. If at some point order will become defined, then documentation can be updated. Until then you will have people scratching their heads whenever they test code along the lines of\r\n```python\r\n_, actual_weights = session.run([train_op, weights_op])\r\nassert expected_weights == actual_weights\r\n```\r\nthat works as expected with cpu-basedtensorflow, but fails with gpu-based tensorflow.", "@PuchatekwSzortach do you want to send a PR for this? Since you are the user, you are the best positioned to find the best place to encounter this in documentation.\r\n\r\n", "@yaroslavvb Alright, I'll send a PR :)", "@yaroslavvb https://github.com/tensorflow/tensorflow/pull/17727", "Sorry to post on this old issue again; however, shouldn't the information about the ```fetches``` execution order being undefined be put higher up in the documentation? [Currently](https://www.tensorflow.org/api_docs/python/tf/Session#run), it is in the \"Returns\" subsection, but there is an \"args\" subsection which seems to make more sense (to me at least).\r\n\r\nShould I open another issue for this?", "It seems natural to me that properties of return values are described in return section. I suppose it's best to ask others and see what's the majority's opinion."]}, {"number": 13132, "title": "Reverting the version back to 1.3. Sync rotation reverted the revert.", "body": "", "comments": []}, {"number": 13131, "title": "Added missing error check", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please"]}, {"number": 13130, "title": "Build fails at patch command - different line endings", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 8.1 64bit\r\n- **TensorFlow installed from (source or binary)**:\r\nI'm trying to build from source to use CPU optimizations\r\n- **TensorFlow version (use command below)**:\r\n1.3 cloned from master\r\n- **Python version**: \r\n3.6.1\r\n- **Bazel version (if compiling from source)**:\r\n0.5.4\r\n- **CUDA/cuDNN version**:\r\nCPU only\r\n### Describe the problem\r\nI'm trying to build TensorFlow from source to use CPU optimizations. I was getting `patch` error exactly as in [Issue #10435](https://github.com/tensorflow/tensorflow/issues/10435) so I used the [recommended solution](https://github.com/tensorflow/tensorflow/issues/10435#issuecomment-306422472) by adding `--binary` to `patch` call at _workspace.bzl_ function `_apply_patch()`. The _tensorflow/core_ is now loaded, bur I get another error with _tensorflow/contrib/session_bundle_ - see log.\r\n### Source code / logs\r\n```\r\n$ ./configure\r\nYou have bazel 0.5.4 installed.\r\nFound possible Python library paths:\r\n  D:\\anaconda\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [D:\\anaconda\\lib\\site-packages]\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with GDR support? [y/N]: n\r\nNo GDR support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\r\nNo VERBS support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\nAdd \"--config=mkl\" to your bazel command to build with MKL support.\r\nPlease note that MKL on MacOS or windows is still not supported.\r\nIf you would like to use a local MKL instead of downloading, please set the environment variable \"TF_MKL_ROOT\" every time before build.\r\nConfiguration finished\r\n\r\n$ ./bazel build --config=opt --cpu=x64_windows_msvc --host_cpu=x64_windows_msvc --copt=-w --host_copt=-w //tensorflow/tools/pip_package:build_pip_package\r\n.............\r\n____Loading package: tensorflow/tools/pip_package\r\n____Loading package: @bazel_tools//tools/cpp\r\n____Loading package: @bazel_tools//tools/jdk\r\n____Loading package: @local_config_xcode//\r\n____Loading package: @local_config_cc//\r\n____Loading package: @local_jdk//\r\n____Loading complete.  Analyzing...\r\n____Loading package: @bazel_tools//tools/launcher\r\n____Loading package: tensorflow/contrib/nn\r\n____Loading package: tensorflow/python/tools\r\n____Loading package: tensorflow/python/eager\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 1,500,767 bytes\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 3,866,533 bytes\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 1,351,924 bytes\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 3,602,866 bytes\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 1,223,337 bytes\r\n____Downloading http://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz: 3,589,997 bytes\r\nERROR: D:/tensorflow/tensorflow/tools/pip_package/BUILD:70:1: error loading package 'tensorflow/contrib/session_bundle': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': Traceback (most recent call last):\r\n        File \"D:/tensorflow/tensorflow/workspace.bzl\", line 123\r\n                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)\r\n        File \"D:/tensorflow/tensorflow/workspace.bzl\", line 114, in _apply_patch\r\n                _execute_and_check_ret_code(repo_ctx, cmd)\r\n        File \"D:/tensorflow/tensorflow/workspace.bzl\", line 94, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(1) when executing 'D:\\msys\\usr\\bin\\bash.exe -c patch --binary -p1 -d D:/msys/tmp/_bazel_admin/aeorbm85/external/protobuf_archive -i D:/tensorflow/third_party/protobuf/add_noinlines.patch':\r\nStdout: patching file src/google/protobuf/compiler/cpp/cpp_file.cc\r\nHunk #1 FAILED at 557 (different line endings).\r\nHunk #2 FAILED at 656 (different line endings).\r\nHunk #3 FAILED at 737 (different line endings).\r\n3 out of 3 hunks FAILED -- saving rejects to file src/google/protobuf/compiler/cpp/cpp_file.cc.rej\r\n\r\nStderr:  and referenced by '//tensorflow/tools/pip_package:simple_console_for_windows'.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\n____Elapsed time: 34,135s\r\n```", "comments": ["@gunan, have you seen anything like this? In the past cygwin and others had ways of configuring how to treat CRLF in apps. Is there somethings similar in msys  that might fix this? In any case you can also try cmake, which is currently working a little more reliably than bazel on windows.", "It is possible this is related to the github file hash issues. We may not have updated the r1.3 branch yet. But just to check @meteorcloudy have you seen this issue?", "@9k37 Maybe you want to add `--binary` flag [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl#L107).\r\nAccording to https://stackoverflow.com/questions/2076688/how-to-use-patches-created-in-windows-with-crlf-in-linuxi", "@meteorcloudy it was with `--binary` when I got the above error. After your response I tried couple of times with and without `--binary` and finally omit the patch error. My build is now crashing with another error - can you help me further? Note also the warning in the middle.\r\n```\r\n$ ./bazel build --config=opt --cpu=x64_windows --host_cpu=x64_windows --copt=-w --host_copt=-w //tensorflow/tools/pip_package:build_pip_package\r\n____Loading complete.  Analyzing...\r\n____Loading package: tensorflow/core/profiler\r\n____Loading package: tensorflow/contrib/saved_model\r\n____Loading package: tensorflow/core/util/tensor_bundle\r\n____Loading package: @fft2d//\r\n____Loading package: @lmdb//\r\n____Loading package: @highwayhash//\r\n____Loading package: @farmhash_archive//\r\n____Loading package: @com_googlesource_code_re2//\r\n____Loading package: @sqlite_archive//\r\n____Loading package: @gif_archive//\r\n____Loading package: @jsoncpp_git//\r\n____Loading package: @png_archive//\r\n____Loading package: @jpeg//\r\nWARNING: D:/tensorflow/tensorflow/core/BUILD:1652:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in D:/tensorflow/tensorflow/tensorflow.bzl:913:30.\r\n____Loading package: @swig//\r\n____Loading package: @grpc//\r\n____Loading package: @grpc//third_party/nanopb\r\n____Loading package: @boringssl//\r\n____Loading package: @pcre//\r\n____Found 1 target...\r\n____Building...\r\n____[0 / 5] Writing file tensorflow/tools/pip_package/build_pip_package.launch_info\r\n____[8 / 164] Writing file external/protobuf_archive/libprotoc_lib.a-2.params [for host]\r\n____[9 / 196] Executing genrule @protobuf_archive//:protos_python_genrule\r\n____[15 / 260] Expanding template external/jpeg/jconfigint_nowin.h\r\n____[40 / 457] Writing file external/snappy/libsnappy.a-2.params [for host]\r\n____[42 / 463] Writing file external/jpeg/libsimd_none.a-2.params [for host]\r\nERROR: D:/tensorflow/tensorflow/core/BUILD:1562:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 127).\r\n/usr/bin/env: 'python': No such file or directory\r\n____Building complete.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n____Elapsed time: 216,811s, Critical Path: 1,10s\r\n```\r\n[full_output.txt](https://github.com/tensorflow/tensorflow/files/1330723/full_output.txt)\r\n", "@9k37 Looks like you don't have python in your `PATH`?", "@meteorcloudy my python is in D:\\anaconda\\\r\n```\r\n$ printenv PATH\r\n/usr/local/bin:/usr/bin:/bin:/opt/bin:/c/Windows/System32:/c/Windows:/c/Windows/System32/Wbem:/c/Windows/System32/WindowsPowerShell/v1.0/:/d/anaconda\r\n$ printenv PYTHON_BIN_PATH\r\nD:\\anaconda\\python.exe\r\n```\r\nand I don't have anything like /usr/bin/env: I am using MSYS with all executables in /d/msys/usr/bin\r\nRedefining PYTHON_BIN_PATH to /d/anaconda or /d/anaconda/python doesn't help, same error.\r\nI even tried creating /d/msys/usr/bin/env and copying python there: this resulted in a bit different error:\r\n```\r\n____Building...\r\n____[0 / 8] Executing genrule @protobuf_archive//:protos_python_genrule\r\nERROR: D:/tensorflow/tensorflow/core/BUILD:1562:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 126).\r\n/usr/bin/bash: tensorflow/tools/git/gen_git_source.py: /usr/bin/env: bad interpreter: Permission denied\r\n```", "you could just try changing tensorflow/tools/git/gen_git_source.py first line (starts with #! to be \r\n```\r\n#!/d/msys/usr/bin/python\r\n```", "@aselle I did change it to my python location:\r\n```\r\n$ less /d/tensorflow/tensorflow/tools/git/gen_git_source.py | grep python\r\n#!/d/anaconda/python\r\n        # In python 3.5, symlink function exists even on Windows. But requires\r\n```\r\nAnd as I understood from gen_git_source.py I was running MSYS as administrator. Result is:\r\n```\r\nX@Y MSYS /d/tensorflow\r\n$ ./bazel build --config=opt --cpu=x64_windows --host_cpu=x64_windows --copt=-w --host_copt=-w //tensorflow/tools/pip_package:build_pip_package\r\n____Loading complete.  Analyzing...\r\nWARNING: D:/tensorflow/tensorflow/core/BUILD:1652:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in D:/tensorflow/tensorflow/tensorflow.bzl:913:30.\r\n____Found 1 target...\r\n____Building...\r\nERROR: D:/tensorflow/tensorflow/core/BUILD:1562:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1).\r\nTraceback (most recent call last):\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 264, in <module>\r\n    generate(args.generate)\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 216, in generate\r\n    git_version = get_git_version(data[\"path\"])\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 156, in get_git_version\r\n    str(\"--work-tree=\" + git_base_path), \"describe\", \"--long\", \"--tags\"\r\n  File \"D:\\anaconda\\lib\\subprocess.py\", line 336, in check_output\r\n    **kwargs).stdout\r\n  File \"D:\\anaconda\\lib\\subprocess.py\", line 403, in run\r\n    with Popen(*popenargs, **kwargs) as process:\r\n  File \"D:\\anaconda\\lib\\subprocess.py\", line 707, in __init__\r\n    restore_signals, start_new_session)\r\n  File \"D:\\anaconda\\lib\\subprocess.py\", line 990, in _execute_child\r\n    startupinfo)\r\nFileNotFoundError: [WinError 2] The system cannot find the file specified\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n____Elapsed time: 1,910s, Critical Path: 0,42s\r\n```", "This was resolved, before the build broke with another issue."]}, {"number": 13129, "title": "random crashes while serving multiple frozen models in parallel using go api", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nYes, I have written custom code\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux x86_64 SLES12\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nSource, latest master at the moment\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n('v1.3.0-rc1-2265-g6e7539b', '1.4.0-dev')\r\nI also tried r1.3 with similar result.\r\n\r\n- **Python version**: \r\n\r\nPython 2.7.9\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\nBuild label: 0.5.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Aug 25 10:00:00 2017 (1503655200)\r\nBuild timestamp: 1503655200\r\nBuild timestamp as int: 1503655200\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nNot used.\r\n\r\n- **GPU model and memory**:\r\n\r\nNot used.\r\n\r\n- **Exact command to reproduce**:\r\n\r\n$ ./tfcrash --n_models 16 --n_images 100\r\n\r\nAn output of this program can be different. The bug has random nature. In some cases the process just segfaults. Typical output is:\r\n\r\n$ ./tfcrash --n_models 16 --n_images 100\r\n2017/09/18 16:45:43 setting 8 cpu\r\n2017/09/18 16:45:43 launching 16 models\r\n2017/09/18 16:45:43 feeding 100 images\r\n2017/09/18 16:45:43 waiting\r\n2017/09/18 16:45:51 session.Run() failed: Expects arg[0] to be uint8 but INVALID is provided\r\n\r\nOr:\r\n\r\n$ ./tfcrash \r\n2017/09/18 16:57:54 setting 8 cpu\r\n2017/09/18 16:57:54 launching 16 models\r\n2017/09/18 16:57:54 feeding 100 images\r\n2017/09/18 16:57:54 waiting\r\nSegmentation fault (core dumped)\r\n\r\n\r\n### Describe the problem\r\n\r\nI'm trying to serve predictions from multiple frozen models that I have trained and generated previously using python script. My programming language for serving predictions is golang. I have found that sometimes my process crashes randomly. Exact conditions needed to reproduce this behaviour are unknown. It is also unknown if this bug related to golang bindings or tensorflow itself.\r\nI also tried different builds of tensorflow, all of them are affected so far, including one built with cuda support. I also noticed that setting lower numbers for --n_images and --n_models parameters decreases probability of bug reproduction. In my experience setting --n_models to 16 and up gives 100% probability of crash.\r\n\r\nI tried both go-1.8.3 and go-1.9 with similar result.\r\n\r\n### Source code / logs\r\n\r\nI wrote a short program (less than 100 lines in go) which is able to reproduce crash with >90% probability:\r\nhttps://gist.github.com/a33c892b17d9ec1da1e40e4fb68fdcf9\r\n\r\nThe model file (type: .frozen.pb, size: 34Mb): https://drive.google.com/file/d/0B9jZHp3Hh0s2MnAxekRGYlVTVHM/\r\n\r\n", "comments": ["Fixed in https://github.com/anight/tensorflow/commit/846454faae5a66fa430b03c82f571440919070f3"]}, {"number": 13128, "title": "Replace `WIN32` -> `PLATFORM_WINDOWS`", "body": "I was trying to make cmake build on Linux (#12018/#13061) but noticed that `WIN32` was used in `tensorflow/core/lib/jpeg/jpeg_mem.cc`.\r\n\r\nI don't know enough history with TensorFlow's code base though I assume `WIN32` should only be inside `tensorflow/core/platform`?\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @mingxingtan and @tensorflower-gardener to be potential reviewers.", "With #13145 merged this PR is not needed. Closing. "]}, {"number": 13127, "title": "Build Tensorflow on Windows with /MT option", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64-bit\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0 release\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: - (using CMake 3.9.1)\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nFirst: add /MT key to CMAKE_CXX_FLAGS_RELEASE in CMakeLists.txt\r\nset(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /MT /D_ITERATOR_DEBUG_LEVEL=0\")\r\n\r\nThen, CMake and build:\r\n\r\n$ cmake .. -G\"Visual Studio 15 2017 Win64\" -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF -Dtensorflow_BUILD_SHARED_LIB=ON\r\n$ MSBuild /m:2 /p:PreferredToolArchitecture=x64 /p:Configuration=Release tensorflow.vcxproj\r\n```\r\n\r\n### Describe the problem\r\nI am getting a lot of link errors of the following type for many 3rd party libraries tensorflow links against:\r\n\r\n```\r\n(Link target) ->\r\n         nsync.lib(mu.obj) : error LNK2038: mismatch detected for 'RuntimeLibrary': value 'MD_DynamicRelease' doesn't match value 'MT_StaticRelease' in gen_proto_text_functions.obj [C:\\all\\lib\\tensorflow\\tensorflow\\contrib\\cmake\\bu\r\n       ild\\proto_text.vcxproj]\r\n```\r\n\r\nI am not really sure if that's supposed to work, so it can be considered a feature request. I would really like to build tensorflow with /MT to make my application as portable as possible.\r\nCurrently, I build tensorflow.dll with Visual Studio 2017 and default switches (/MD), and therefore the resulting application requires Microsoft Redistributable C++ libraries for Visual Studio 2017.\r\n\r\nIf building with /MT is supposed to work, maybe someone could give me a hint how to get it right (and then we can close the issue)? I guess, digging into build options of every third-party library and adding /MT there?", "comments": ["If I remember correctly, we're using `/MD` by default in order to generate a DLL that's usable as a Python extension. I vaguely recall being able to build the example trainer program with `/MT` in the exploratory stages of the Windows port, but that was before most of the external dependencies were working.\r\n\r\nI believe it should be enough to thread the option through to each of the external projects. Since we only use the CMake build for TensorFlow-on-Windows-using-Python release, it's unlikely that anyone on the team is going to look into this, but we would encourage contributions if this would be useful for you.\r\n\r\n/cc @guschmue who might have encountered the same problem.", "@mrry Thank you for the reply! Okay, I will look into passing the option to the libraries.\r\nWill post here later how it went.", "Any updates @alex-petrenko ?", "It turns out you actually can do it; just like @mrry said you can pass /MT option to each and every 3rd party library tensorflow depends on. On Windows, all of them are built with CMake, so usually, you just need to add the flag to the CMake options.\r\n\r\nIn my case, I wanted to build a version with static runtime to simplify the deployment, to eliminate the dependency on the Microsoft C++ Runtime Libraries. However, I faced problems with other libraries that I use (namely, OpenCV) and I ended up just adding vcruntime140.dll (and a couple of other Microsoft dlls) to my distribution. I recommend this solution to anyone facing the same problem: it's easier to implement and is much less error-prone.\r\n\r\nIf you're building a standalone app for Windows and you have a separate installer, even better is to include the Microsoft C++ Redistributable Package into your installer. I didn't have an installer (because we build a [plugin](https://www.assetstore.unity3d.com/en/#!/content/100613), not a standalone app), so I just added Microsoft .dlls near the tensorflow.dll\r\n\r\nI think this issue can be closed. I don't think it's a good idea to mess with CMake build system of tensorflow to add the /MT build option.", "Thank you very much for the explanation!\r\nNow that we have possible workarounds and we confirmed that we can do this using the cmake build, I will mark this issue closed.", "Hi, @alex-petrenko \r\n\r\nI read your instructions, but it is not too clear for me. Could you be more precise about the instructions to build Tensorflow with /MT option, please?\r\n\r\nI mean, should I add\r\n\r\n```\r\nset(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /MT\")\r\n```\r\n\r\nto each **.cmake** file located in tensorflow\\contrib\\cmake\\external or each **.BUILD** file located in third_party folder?\r\n\r\nI had already passed flags like ```-DCMAKE_CXX_FLAGS_RELEASE=\"/MT\"``` in my cmake command (they appear in CMakeCache), but when I run build, the libraries continues being built with /MD option.", "@DiogoDantas sorry, I don't remember exactly how we did it, as I said, we ended up using a different solution which I recommend. But I think you should add this option to every *.cmake file in tensorflow\\contrib\\cmake\\external \r\n\r\nAll these dependencies are basically separate CMake projects, so you can just pass this option to every one of them. Some of them will have problems of their own handling the MT build.\r\n\r\nAs an example, you can take a look at the ExternalProject_Add command in protobuf.cmake file. It has both command line and CMakeCache arguments, I think at least one of the options should work. Feel free to post more detailed instructions if you manage to use this in production.", "For those who are interested, I wrote a [post on Medium](https://medium.com/@arnaldog12/how-to-build-tensorflow-on-windows-with-mt-42a8e4bea7e7) and created a [Github Repo](https://github.com/arnaldog12/Tensorflow-Build-MT) with detailed instruction about how to achieve this.\r\n\r\nI hope it helps!", "@arnaldog12 Will this repo work with tf v1.14?", "Hi, @jetjodh \r\nSorry for the late response. I tried it with the version you mentioned (v1.14) and I had problems with some operations not defined by v1.4. However, I tested with version v1.13 and everything went fine.\r\n\r\nIf you really need to run it on v1.14, I can help you build it. If you have already done it, please let me know.", "@arnaldog12 I found that c# was much better suited for my use case, so I used that instead. There are many bindings for TensorFlow in C# which surprisingly worked better than ones in C++.", "@jetjodh Nice! Can you please share the tutorials you followed our even your TensorFlow build for C# to help others as well? Thanks in advance."]}, {"number": 13126, "title": "installing tensorflow to a local folder results in import error with realtive paths", "body": "this is on linux with python 3.6.2 and tf 1.3\r\ni install tensorflow into a folder named 'site-packages' inside my project. i then add it to the path with a relative reference. works fine when path is absolute\r\n\r\npip install tensorflow -t site-packages\r\npython\r\nimport sys\r\nsys.path.insert(1,\"site-packages\") # will fail\r\n#sys.path.insert(1,\"/home/absolute_path/site-packages\") #works\r\nfrom tensorflow.contrib.framework.python.ops.checkpoint_ops import *\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"site-packages/tensorflow/contrib/framework/python/ops/__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.framework.python.ops.checkpoint_ops import *\r\n  File \"site-packages/tensorflow/contrib/framework/python/ops/checkpoint_ops.py\", line 32, in <module>\r\n    resource_loader.get_path_to_datafile(\"_checkpoint_ops.so\"))\r\n  File \"site-packages/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"site-packages/tensorflow/python/framework/load_library.py\", line 64, in load_op_library\r\n    None, None, error_msg, error_code)\r\ntensorflow.python.framework.errors_impl.NotFoundError: site-packages/tensorflow/contrib/util/site-packages/tensorflow/contrib/framework/python/ops/_checkpoint_ops.so: cannot open shared object file: No such file or directory\r\n", "comments": ["@eyaler I guess you have to mention absolute_path not the other way around? By the way,I couldn't understand your concern :)", "@printdhruv you understood correctly. this is a bug happening only with this module. see the created path: site-packages/tensorflow/contrib/util/site-packages/tensorflow/contrib/framework/python/ops/_checkpoint_ops.so", "@eyaler Can you try to `print sys.path` too see all path information?", "@printdhruv i checked the path and its fine. this contrived path name is created by tf", "I guess this [link](https://stackoverflow.com/questions/480764/linux-error-while-loading-shared-libraries-cannot-open-shared-object-file-no-s) will help you to understand the differences among using path in a linux.", "I believe this is working as intended. I don't see a compelling reason to add relative paths to sys.path or that it is supported by Python. If you want to make it agile to being moved around, just make a shell script to wrap python that sets up PYTHONPATH before it invokes python.\r\n", "this breaks the principal of least surprise. if relative paths are not supported, to the very least this should be documented. ", "Backtracking, it is probably possible to make this work, but it will require changing how .dso's are found to be more robust. (I.e. right now we use resource_loader.get_path_to_datafile which uses some absolute path).", "@allenlavoie, do you have any inkling to fix this problem?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Not sure how I missed this. I think you nailed it @aselle. Given that this is a rather niche use, I'd say this is contributions welcome.", "Hi @eyaler ! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more.  But I executed steps mentioned in the template, and was able to  execute this command `from tensorflow import  *`.  Closing this issue as it has been resolved now in 2.8 version. Thanks!  "]}, {"number": 13125, "title": "Tensorflow froze 2 variables & converted to const ops", "body": "Hi there, \r\nI'm new to Python & Tensorflow. Im using raspbian9 (stretch) & Python 2.7.13.\r\n\r\nWhen i run retrain.py from the examples provided using these code:\r\n\r\n`python retrain.py --bottleneck_dir=tf_files/bottlenecks --how_many_training_steps=50 model_dir=tf_files/inception output_graph=retrained_graph.pb output_labels=retrained_labels.txt --image_dir=img --input_binary=true`\r\n\r\nThere are no outputs for output_labels (retrained_labels.txt) & output_graph (retrained_graph.pb).\r\nThe codes below are the console outputs for the few last lines console output from the command above:\r\n\r\n`INFO:tensorflow:2017-09-18 12:50:07.148873: Step 49: Train accuracy = 95.0%\r\nINFO:tensorflow:2017-09-18 12:50:07.149888: Step 49: Cross entropy = 0.241774\r\nINFO:tensorflow:2017-09-18 12:50:08.259520: Step 49: Validation accuracy = 97.0% (N=100)\r\nINFO:tensorflow:Final test accuracy = 89.3% (N=28)\r\nINFO:tensorflow:Froze 2 variables.\r\nConverted 2 variables to const ops.`\r\n\r\nAny solutions? Thanks!\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13123, "title": "Fix argument name mismatch in FinalBeamSearchDecoderOutput docstring", "body": "", "comments": ["Jenkins, test this please.", "Flake\r\n\r\nJenkins, test this please."]}, {"number": 13122, "title": "R1.3", "body": "good", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "That seems like an invalid change. Please resubmit once fixed."]}, {"number": 13121, "title": "array_elementwise_ops_test_cpu_parallel test failure on ppc64le", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Rhel 7.3/ SLES 12 ppc64le\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7.4\r\n- **Bazel version (if compiling from source)**: 0.4.6\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nbazel test --test_output=errors //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nTest gives failure log as below. Root causing the issue, error lines are these:\r\n\r\nComputationBuilder builder(client_, TestName());\r\n  **auto result = builder.IsFinite(builder.ConstantR0<float>(NAN));**\r\n  ComputeAndCompareR0<bool>(&builder, false, {});\r\n\r\nIsFinite(..) on ppc64le incorrectly returning True instead of False when passed a NaN. Tracing the implemnetaion of IsFinite leads to code under XLA, from here: https://www.tensorflow.org/performance/xla/ seems like XLA does not support ppc64le as a backend. \r\n\r\nNeed some insight to help with further debugging, is this analysis correct that this test failure is due to XLA not supporting ppc64le? Any other pointers for this will help!\r\n \r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n==================== Test output for //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel:\r\nNote: This is test shard 5 of 25.\r\n[==========] Running 5 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 5 tests from ArrayElementwiseOpTest\r\n[ RUN      ] ArrayElementwiseOpTest.IsFiniteScalarF32\r\n2017-07-28 10:35:17.159242: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n2017-07-28 10:35:17.160204: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n2017-07-28 10:35:17.161041: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x1002d5b4cb0 executing computations on platform Host. Devices:\r\n2017-07-28 10:35:17.161051: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\r\ntensorflow/compiler/xla/tests/literal_test_util.cc:151: Failure\r\nValue of: Equal(expected, actual)\r\n  Actual: false (expected: false\r\nactual:   true)\r\nExpected: true\r\nexpected:\r\nfalse\r\n        vs actual:\r\ntrue\r\ntensorflow/compiler/xla/tests/literal_test_util.cc:151: Failure\r\nValue of: Equal(expected, actual)\r\n  Actual: false (expected: false\r\nactual:   true)\r\nExpected: true\r\nexpected: false vs actual: true\r\n[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32 (41 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.CompareEqZeroElementF32s\r\n2017-07-28 10:35:17.199474: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.CompareEqZeroElementF32s (6 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.MinZeroElementF32s\r\n2017-07-28 10:35:17.205103: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.MinZeroElementF32s (5 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.ClampF32ScalarVector\r\n2017-07-28 10:35:17.210559: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.ClampF32ScalarVector (15 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.3DBinaryOpF32s\r\n2017-07-28 10:35:17.225124: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.3DBinaryOpF32s (12 ms)\r\n[----------] 5 tests from ArrayElementwiseOpTest (79 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 5 tests from 1 test case ran. (79 ms total)\r\n[  PASSED  ] 4 tests.\r\n[  FAILED  ] 1 test, listed below:\r\n[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32\r\n\r\n1 FAILED TEST\r\n================================================================================\r\n==================== Test output for //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel:\r\nNote: This is test shard 6 of 25.\r\n[==========] Running 5 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 5 tests from ArrayElementwiseOpTest\r\n[ RUN      ] ArrayElementwiseOpTest.IsFiniteR1F32s\r\n2017-07-28 10:35:17.180614: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n2017-07-28 10:35:17.181740: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n2017-07-28 10:35:17.182605: I tensorflow/compiler/xla/service/service.cc:198] XLA service 0x100337e4cb0 executing computations on platform Host. Devices:\r\n2017-07-28 10:35:17.182614: I tensorflow/compiler/xla/service/service.cc:206]   StreamExecutor device (0): <undefined>, <undefined>\r\ntensorflow/compiler/xla/tests/literal_test_util.cc:151: Failure\r\nValue of: Equal(expected, actual)\r\n  Actual: false (expected: {010100}\r\nactual:   {111100})\r\nExpected: true\r\nexpected: {010100}   vs actual: {111100}\r\n[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s (15 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.CompareGeF32s\r\n2017-07-28 10:35:17.195704: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.CompareGeF32s (10 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.MinF64s\r\n2017-07-28 10:35:17.205905: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.MinF64s (10 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.AddTwoParametersF32s\r\n2017-07-28 10:35:17.215280: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.AddTwoParametersF32s (8 ms)\r\n[ RUN      ] ArrayElementwiseOpTest.Add1DTo3DTwoWaysOver2\r\n2017-07-28 10:35:17.223646: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n[       OK ] ArrayElementwiseOpTest.Add1DTo3DTwoWaysOver2 (20 ms)\r\n[----------] 5 tests from ArrayElementwiseOpTest (63 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 5 tests from 1 test case ran. (63 ms total)\r\n[  PASSED  ] 4 tests.\r\n[  FAILED  ] 1 test, listed below:\r\n[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s\r\n\r\n1 FAILED TEST\r\n================================================================================\r\n//tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel (23/25 cached) FAILED in 2", "comments": ["Maybe the problem is that ppc64le just isn't supported.  @hawkinsp ?", "Unfortunately we don't promise to support ppc64le. That said, contributions are very welcome if the community wants to add support."]}, {"number": 13120, "title": "PermissionDeniedError when save model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution: Win7\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: tensorflow-gpu 1.3.0\r\n- **Python version**: python 3.6 64bit\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: GTX 1050Ti 4GB\r\n### Describe the problem\r\ntry to load a model and then save it, same codes ran in three computers\uff0cone failed when saving (tensorflow-gpu 1.3.0 GTX 1050Ti 4GB), another two passed (tensorflow 1.3.0 and tensorflow-gpu 1.3.0 with GTX 780 Ti 4GB) .  And I ran it as Administrator, so should not lack of write permission\r\n\r\nhere is the code\r\n` def fit(self,\r\n            training_iters =1e2,\r\n            learning_rate = 1e-4,\r\n            optimizer_epsilon = 1e-10,\r\n            max_gard_norm = 50,\r\n            display_step = 5,\r\n            save_path = None,\r\n            restore_path = None):\r\n\r\n        self._sess.run(tf.global_variables_initializer())\r\n        self._variables_saver = tf.train.Saver()\r\n        if restore_path is not None and os.path.exists(restore_path):\r\n            self._variables_saver.restore(self._sess, restore_path)\r\n            print ('restore ok')\r\n\r\n        if self._batch_size == self._mini_batch_size:\r\n            for scope in range(np.int(training_iters)):\r\n                _, loss, acc, tp1, tp2 = \\\r\n                self._sess.run([self._train_step, self._cost, self._accuracy, self._pondering_cost, self._rnn_cost],\r\n                               feed_dict = {self._inputs:self._tmp_inputs, self._targets:self._tmp_targets})\r\n\r\n                if scope % display_step == 0:\r\n                    print (scope, '  loss--', loss, '  acc--', acc, '  pondering_cost--',tp1, '  rnn_cost--', tp2)\r\n                    if save_path is not None:\r\n                        self._variables_saver.save(self._sess, save_path)`\r\n\r\n and exception logs\r\n`---------------------------------------------------------------------------\r\nPermissionDeniedError                     Traceback (most recent call last)\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1326     try:\r\n-> 1327       return fn(*args)\r\n   1328     except errors.OpError as e:\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1305                                    feed_dict, fetch_list, target_list,\r\n-> 1306                                    status, run_metadata)\r\n   1307 \r\n\r\nd:\\anaconda3664\\lib\\contextlib.py in __exit__(self, type, value, traceback)\r\n     88             try:\r\n---> 89                 next(self.gen)\r\n     90             except StopIteration:\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in raise_exception_on_not_ok_status()\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n\r\nPermissionDeniedError: Failed to create a directory: e:.\r\n\t [[Node: save_5/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_5/Const_0_0, save_5/SaveV2/tensor_names, save_5/SaveV2/shape_and_slices, act_core/act_output_linear/b/_939, act_core/act_output_linear/b/RMSProp/_941, act_core/act_output_linear/b/RMSProp_1/_943, act_core/act_output_linear/w/_945, act_core/act_output_linear/w/RMSProp/_947, act_core/act_output_linear/w/RMSProp_1/_949, act_core/halting_linear/b/_951, act_core/halting_linear/b/RMSProp/_953, act_core/halting_linear/b/RMSProp_1/_955, act_core/halting_linear/w/_957, act_core/halting_linear/w/RMSProp/_959, act_core/halting_linear/w/RMSProp_1/_961, global_step, lstm/b_gates/_963, lstm/b_gates/RMSProp/_965, lstm/b_gates/RMSProp_1/_967, lstm/w_gates/_969, lstm/w_gates/RMSProp/_971, lstm/w_gates/RMSProp_1/_973, lstm_1/b_gates/_975, lstm_1/b_gates/RMSProp/_977, lstm_1/b_gates/RMSProp_1/_979, lstm_1/w_gates/_981, lstm_1/w_gates/RMSProp/_983, lstm_1/w_gates/RMSProp_1/_985, lstm_2/b_gates/_987, lstm_2/b_gates/RMSProp/_989, lstm_2/b_gates/RMSProp_1/_991, lstm_2/w_gates/_993, lstm_2/w_gates/RMSProp/_995, lstm_2/w_gates/RMSProp_1/_997)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nPermissionDeniedError                     Traceback (most recent call last)\r\n<ipython-input-16-2f0c74b77fe4> in <module>()\r\n      3               display_step = 1,\r\n      4               save_path=\"e:./dnc_model_171.ckpt\",\r\n----> 5               restore_path=\"e:./dnc_model_17.ckpt\"\r\n      6              )\r\n      7 \r\n\r\nD:\\PyTrade\\DNCore.py in fit(self, training_iters, learning_rate, optimizer_epsilon, max_gard_norm, display_step, save_path, restore_path)\r\n    135                     \r\n    136                     if save_path is not None:\r\n--> 137                         self._variables_saver.save(self._sess, save_path)\r\n    138 \r\n    139             \r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\r\n   1472         model_checkpoint_path = sess.run(\r\n   1473             self.saver_def.save_tensor_name,\r\n-> 1474             {self.saver_def.filename_tensor_name: checkpoint_file})\r\n   1475         model_checkpoint_path = compat.as_str(model_checkpoint_path)\r\n   1476         if write_state:\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    893     try:\r\n    894       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 895                          run_metadata_ptr)\r\n    896       if run_metadata:\r\n    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1122     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1123       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1124                              feed_dict_tensor, options, run_metadata)\r\n   1125     else:\r\n   1126       results = []\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1319     if handle is None:\r\n   1320       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n-> 1321                            options, run_metadata)\r\n   1322     else:\r\n   1323       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n\r\nd:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1338         except KeyError:\r\n   1339           pass\r\n-> 1340       raise type(e)(node_def, op, message)\r\n   1341 \r\n   1342   def _extend_graph(self):\r\n\r\nPermissionDeniedError: Failed to create a directory: e:.\r\n\t [[Node: save_5/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_5/Const_0_0, save_5/SaveV2/tensor_names, save_5/SaveV2/shape_and_slices, act_core/act_output_linear/b/_939, act_core/act_output_linear/b/RMSProp/_941, act_core/act_output_linear/b/RMSProp_1/_943, act_core/act_output_linear/w/_945, act_core/act_output_linear/w/RMSProp/_947, act_core/act_output_linear/w/RMSProp_1/_949, act_core/halting_linear/b/_951, act_core/halting_linear/b/RMSProp/_953, act_core/halting_linear/b/RMSProp_1/_955, act_core/halting_linear/w/_957, act_core/halting_linear/w/RMSProp/_959, act_core/halting_linear/w/RMSProp_1/_961, global_step, lstm/b_gates/_963, lstm/b_gates/RMSProp/_965, lstm/b_gates/RMSProp_1/_967, lstm/w_gates/_969, lstm/w_gates/RMSProp/_971, lstm/w_gates/RMSProp_1/_973, lstm_1/b_gates/_975, lstm_1/b_gates/RMSProp/_977, lstm_1/b_gates/RMSProp_1/_979, lstm_1/w_gates/_981, lstm_1/w_gates/RMSProp/_983, lstm_1/w_gates/RMSProp_1/_985, lstm_2/b_gates/_987, lstm_2/b_gates/RMSProp/_989, lstm_2/b_gates/RMSProp_1/_991, lstm_2/w_gates/_993, lstm_2/w_gates/RMSProp/_995, lstm_2/w_gates/RMSProp_1/_997)]]\r\n\r\nCaused by op 'save_5/SaveV2', defined at:\r\n  File \"d:\\anaconda3664\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\anaconda3664\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-16-2f0c74b77fe4>\", line 5, in <module>\r\n    restore_path=\"e:./dnc_model_17.ckpt\"\r\n  File \"D:\\PyTrade\\DNCore.py\", line 121, in fit\r\n    self._variables_saver = tf.train.Saver()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1140, in __init__\r\n    self.build()\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1172, in build\r\n    filename=self._filename)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 686, in build\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 276, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 219, in save_op\r\n    tensors)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 768, in save_v2\r\n    tensors=tensors, name=name)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"d:\\anaconda3664\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nPermissionDeniedError (see above for traceback): Failed to create a directory: e:.\r\n\t [[Node: save_5/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_5/Const_0_0, save_5/SaveV2/tensor_names, save_5/SaveV2/shape_and_slices, act_core/act_output_linear/b/_939, act_core/act_output_linear/b/RMSProp/_941, act_core/act_output_linear/b/RMSProp_1/_943, act_core/act_output_linear/w/_945, act_core/act_output_linear/w/RMSProp/_947, act_core/act_output_linear/w/RMSProp_1/_949, act_core/halting_linear/b/_951, act_core/halting_linear/b/RMSProp/_953, act_core/halting_linear/b/RMSProp_1/_955, act_core/halting_linear/w/_957, act_core/halting_linear/w/RMSProp/_959, act_core/halting_linear/w/RMSProp_1/_961, global_step, lstm/b_gates/_963, lstm/b_gates/RMSProp/_965, lstm/b_gates/RMSProp_1/_967, lstm/w_gates/_969, lstm/w_gates/RMSProp/_971, lstm/w_gates/RMSProp_1/_973, lstm_1/b_gates/_975, lstm_1/b_gates/RMSProp/_977, lstm_1/b_gates/RMSProp_1/_979, lstm_1/w_gates/_981, lstm_1/w_gates/RMSProp/_983, lstm_1/w_gates/RMSProp_1/_985, lstm_2/b_gates/_987, lstm_2/b_gates/RMSProp/_989, lstm_2/b_gates/RMSProp_1/_991, lstm_2/w_gates/_993, lstm_2/w_gates/RMSProp/_995, lstm_2/w_gates/RMSProp_1/_997)]]`\r\n", "comments": ["It looks like your save path is invalid \r\n```\r\n4 save_path=\"e:./dnc_model_171.ckpt\",\r\n```\r\ntry giving it one that isn't a mix of being relative and absolute.\r\n", "I have encountered the same problem\uff0cand the problem is caused by that I save the model file in the same path which I put the Python file. When I save the model file in a different path from the path of python file, the problem is solved.\r\nGood luck!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "> I have encountered the same problem\uff0cand the problem is caused by that I save the model file in the same path which I put the Python file. When I save the model file in a different path from the path of python file, the problem is solved.\r\n> Good luck!\r\n\r\nI have got the same problem: is there any working solution yet? The above solution is not working for me. ", "I use absolute paths for data and models, and the problem solved.", "> I use absolute paths for data and models, and the problem solved.\r\n\r\nYes, it works for me too     --->    tf.VERSION:    1.12.0"]}, {"number": 13119, "title": "Tensorflow installation ", "body": "I am installing tensorflow on window machine with the help of Python (version python-3.5.4-amd64).\r\n\r\nCommand use to install tensorflow  :- pip3 install --upgrade tensorflow\r\n\r\nBellow error getting in Import tensorflow command.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\eclipse\\WorkspavePython\\study\\test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["You have browse to the directory containing the tensorflow source code and install it using pip.\r\nAlternatively you can do it using Anaconda, refer the documentation for more details. ", "This is a duplicate of #13196. Please see that issue for more information.\r\n"]}, {"number": 13118, "title": "Can't freeze .pbtxt to .pb file :  Multiple OpKernel registrations match NodeDef after compiled android_arm .so", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**:  8.0.61\r\n- **GPU model and memory**: NVIDIA Corporation Device 1b06\r\n- **Exact command to reproduce**: \r\n\r\n```\r\nbazel-bin/tensorflow/python/tools/freeze_graph \\\r\n--input_graph=.../imagenet/train_logs/graph.pbtxt \\\r\n--input_checkpoint=.../imagenet/train_logs/model.ckpt-10000 \\\r\n--output_graph=.../imagenet/train_logs/frozen_graph.pb \\\r\n--output_node_names=MobilenetV1/Predictions/Reshape_1\r\n```\r\n\r\n### Describe the problem\r\nI am doing some fine-tune , but can't convert text file to binary file after training , the following error is what I got\r\n\r\n### Source code / logs\r\n```\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 329, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 242, in main\r\n    FLAGS.input_saved_model_dir, FLAGS.saved_model_tags)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 233, in freeze_graph\r\n    input_saved_model_dir, saved_model_tags.split(\",\"))\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 127, in freeze_graph_with_def_protos\r\n    saver.restore(sess, input_checkpoint)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1646, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1118, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1315, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'prefetch_queue/fifo_queue = FIFOQueueV2[capacity=2, component_types=[DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[10,224,224,3], [10,3]], shared_name=\"\"]()': 'op: \"FIFOQueueV2\" device_type: \"CPU\"' and 'op: \"FIFOQueueV2\" device_type: \"CPU\"'\r\n         [[Node: prefetch_queue/fifo_queue = FIFOQueueV2[capacity=2, component_types=[DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[10,224,224,3], [10,3]], shared_name=\"\"]()]]\r\n\r\nCaused by op u'prefetch_queue/fifo_queue', defined at:\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 329, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 242, in main\r\n    FLAGS.input_saved_model_dir, FLAGS.saved_model_tags)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 233, in freeze_graph\r\n    input_saved_model_dir, saved_model_tags.split(\",\"))\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 99, in freeze_graph_with_def_protos\r\n    _ = importer.import_graph_def(input_graph_def, name=\"\")\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 3077, in create_op\r\n    op_def=op_def)\r\n  File \"/home/simonlee/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1627, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Multiple OpKernel registrations match NodeDef 'prefetch_queue/fifo_queue = FIFOQueueV2[capacity=2, component_types=[DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[10,224,224,3], [10,3]], shared_name=\"\"]()': 'op: \"FIFOQueueV2\" device_type: \"CPU\"' and 'op: \"FIFOQueueV2\" device_type: \"CPU\"'\r\n         [[Node: prefetch_queue/fifo_queue = FIFOQueueV2[capacity=2, component_types=[DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[10,224,224,3], [10,3]], shared_name=\"\"]()]]\r\n```\r\n\r\n\r\nI know the op FIFOQueueV2 is not supported on Android , so I followed #8404 , recompiled my .so file before this occurred.\r\nBut does it result in this ? Does it only be used when model loaded on Android ? Or all bazel compilation ?", "comments": []}, {"number": 13117, "title": "'DNNClassifier' object has no attribute '_train_model'", "body": "I got an error saying \"'DNNClassifier' object has no attribute '_train_model'\" when I run this.\r\n\r\n```\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"/tmp/data/\")\r\nX_train = mnist.train.images\r\nX_test = mnist.test.images\r\ny_train = mnist.train.labels.astype(\"int\")\r\ny_test = mnist.test.labels.astype(\"int\")\r\nimport tensorflow as tf\r\n\r\nconfig = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\r\nfeature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\r\ndnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10, feature_columns=feature_cols, config=config)\r\ndnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\r\ndnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)\r\n```\r\n", "comments": ["I upgraded my tensoflow to 1.3 and it worked!"]}, {"number": 13116, "title": "tensorflow.python.debug.cli.offline_analyzer failed to read debug data from HDFS filesys", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.2 \r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0 from master branch\r\n- **Python version**: Python 2.7.12 (default, Nov 19 2016, 06:48:10)\r\n- **Bazel version (if compiling from source)**: 0.4.5\r\n- **CUDA/cuDNN version**: null\r\n- **GPU model and memory**: null\r\n- **Exact command to reproduce**: python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://<debug_data_dir>\r\n\r\n### Issue description\r\nI saved debug data by `DumpingDebugHook` into hdfs filesys and then it failed to read the data by `python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://<debug_data_path>`, but it works well with the local filesys by the same way.\r\n\r\n#### Error info:\r\n```\r\n# python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505721619237931_100\r\ntfdbg offline: FLAGS.dump_dir = hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505721619237931_100\r\nSLF4J: Class path contains multiple SLF4J bindings.\r\nSLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/kms/tomcat/webapps/kms/WEB-INF/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.3/share/hadoop/httpfs/tomcat/webapps/webhdfs/WEB-INF/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\nhdfsExists: invokeMethod((Lorg/apache/hadoop/fs/Path;)Z) error:\r\njava.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: \"G53.ad000000000427.et2/11.140.133.72\"; destination host is: \"ns1\":8020;\r\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1479)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\r\n\tat com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:771)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\r\n\tat com.sun.proxy.$Proxy11.getFileInfo(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2108)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)\r\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301)\r\n\tat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426)\r\nCaused by: java.net.SocketException: Network is unreachable\r\n\tat sun.nio.ch.Net.connect0(Native Method)\r\n\tat sun.nio.ch.Net.connect(Net.java:454)\r\n\tat sun.nio.ch.Net.connect(Net.java:446)\r\n\tat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)\r\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)\r\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\r\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\r\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:614)\r\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:712)\r\n\tat org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:375)\r\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1528)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1451)\r\n\t... 17 more\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/cli/offline_analyzer.py\", line 78, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/cli/offline_analyzer.py\", line 41, in main\r\n    FLAGS.dump_dir, validate=FLAGS.validate_graph)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py\", line 682, in __init__\r\n    raise IOError(\"Dump root directory %s does not exist\" % dump_root)\r\nIOError: Dump root directory hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505721619237931_100 does not exist\r\n```\r\n\r\nBe sure that the above hdfs dir exists, which including debug data by `DumpingDebugHook`, as below:\r\n\r\n```\r\n# hdfs dfs -ls -d hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505721619237931_100\r\ndrwxr-xr-x   - root supergroup          0 2017-09-18 08:01 hdfs://ns1/data/luchen.sk/tfdbg/tb_debug_data_dump/run_1505721619237931_100\r\n```", "comments": ["I will close the issue at first because I find another issue after replaced `ns1` with `hostname:port` in hdfs path, and then would file another issue if needed, thanks."]}, {"number": 13115, "title": "Build problem :Configurable attribute \"copts\" doesn't match this configuration", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux pine64 3.10.104-2-pine64-longsleep aarch64 aarch64 aarch64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:1.3.0-rc0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:0.4.5\r\n- **CUDA/cuDNN version**: no\r\n- **Exact command to reproduce**: `bazel build -c opt --copt=\"-funsafe-math-optimizations\" --copt=\"-ftree-vectorize\" --copt=\"-fomit-frame-pointer\" --verbose_failures tensorflow/tools/pip_package:build_pip_package`\r\n\r\n### Describe the problem\r\nAs  tensorflow supports ARM 64-bit CPU platform,so I build it on PINE64.But after I install bazel exactly, and try to install tensorflow,there is something wrong in building process.\r\n\r\n### Source code / logs\r\n```\r\nERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/nsync/BUILD:401:13: Configurable attribute \"copts\" doesn't match this configuration (would a default condition help?).\r\nConditions checked:\r\n @nsync//:android_arm\r\n @nsync//:android_arm64\r\n @nsync//:android_armeabi\r\n @nsync//:android_x86_32\r\n @nsync//:android_x86_64\r\n @nsync//:clang_macos_x86_64\r\n @nsync//:gcc_linux_aarch64\r\n @nsync//:gcc_linux_ppc64\r\n @nsync//:gcc_linux_x86_64_1\r\n @nsync//:gcc_linux_x86_64_2\r\n @nsync//:ios_x86_64\r\n @nsync//:msvc_windows_x86_64.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.\r\n```\r\nAs the logs errors indicate the file, so I looks the code ,and it indicates the cpp library configure as follow:\r\n ```\r\n# The library compiled in C++11, rather than C.\r\n397 cc_library(\r\n398     name = \"nsync_cpp\",\r\n399     srcs = NSYNC_SRC_GENERIC + NSYNC_SRC_PLATFORM_CPP,\r\n400     hdrs = NSYNC_HDR_GENERIC,\r\n401     copts = NSYNC_OPTS_CPP,\r\n402     includes = [\"public\"],\r\n403     textual_hdrs = NSYNC_INTERNAL_HEADERS + NSYNC_INTERNAL_HEADERS_PLATFORM,\r\n404 )\r\n```\r\nI try to annotation the number 401 code,the errer above seems disapperence but other errer happens.\r\nI appreciate ever help, thank you all very much.", "comments": ["hi, please refer to here:\r\njust add in NSYNC_OPTS_GENERIC, it might be OK.\r\n\"//conditions:default\": [],\r\nhttps://lengerrong.blogspot.com/2017/09/fix-up-configurable-attribute-copts.html\r\n", "I do reproduce the same while cross-compiling for RPi3, maybe @petewarden can be interested :)", "It seems like root issue was documented as https://github.com/tensorflow/tensorflow/issues/12524 and a fix landed for Windows there: https://github.com/tensorflow/tensorflow/pull/12603\r\n\r\nThat fix seems to imply nsync-side changes in https://github.com/google/nsync/commit/d3bc53d38bee13bf66354ca61694956c92ffe879 though.\r\n\r\n@m3bm3b Can you confirm that ?"]}, {"number": 13114, "title": "Extremely slow first epoch.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 LTS\r\n- **TensorFlow installed from (source or binary)**: PIP, tensorflow-gpu==1.2.1\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: Python 3.6.2\r\n- **CUDA/cuDNN version**: CUDA Version 8.0.61 / cuDNN Version 5.1.10\r\n- **GPU model and memory**: GTX 1080ti x 2, 11171MiB each.\r\n\r\n### Describe the problem\r\nWhen training model, \"**only First epoch after executing training script is extremely slow** (More specifically, It takes 12 hours while second and third epoch after executed takes 2.5 hours with my environment and dataset)\"\r\n\r\nI uploaded this issue because similar issue in stackoverflow is not handled long time.\r\n(https://stackoverflow.com/questions/44966831/tensorflow-first-epoch-is-extremely-slow-maybe-related-to-pool-allocator)\r\n\r\nIn more detail,\r\nmy code uses model with  **1d convolution layers** (tf.nn.conv1d - tf.bias_add - tf.nn.relu) as model.\r\n**tf.ctc_loss** as loss function.\r\nData is served with tf.PaddingFIFOQueue && tf.QueueBase.dequeue_many and \"**each data has different size**\".\r\n\r\nHere is what I tried,\r\nFirst I also assumed that pool allocator makes this problem like [above stackoverflow link](https://stackoverflow.com/questions/44966831/tensorflow-first-epoch-is-extremely-slow-maybe-related-to-pool-allocator) (**but now I think this issue is not from pool allocator**)\r\n1. Uses tcmalloc\r\n`LD_PRELOAD=\"/usr/lib/libtcmalloc.so\"` which is suggested in [here](https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/ja7FlGrvh-E)\r\n2. Uses BFC allocator type.\r\n- With `TF_CPU_ALLOCATOR_USE_BFC=true`\r\n- And I tried `tf.ConfigProto().gpu_options. allocator_type = 'BFC'` also.\r\n3. Build tensorflow from source with modified initial pool size limit (100 to 10000), (Which is hard coded in [here](https://github.com/tensorflow/tensorflow/blob/927f811b0303e51126531c135f8b093383de2d6d/tensorflow/core/common_runtime/gpu/process_state.cc#L187)) \r\n\r\nAnd all trying was ineffective.\r\n\r\nExcept extremely slow first epoch, everything was fine. Weights of model is trained well, save and load checkpoint and continuing training or inferencing is also fine without any warning and error.\r\n\r\nIs it one of avoidable characteristic of Tensorflow or bugs?\r\n\r\nThank you for your reading.\r\nIf you need any more information, please notify me.", "comments": ["If each data has different size, TF can spend a large amount of time running cudnn benchmarks for each data and store them in cache. This is probably the reason.\r\nYou can `export TF_CUDNN_USE_AUTOTUNE=0` to see if each epoch becomes the same (slower) speed.", "@w4-kang, does @ppwwyyxx's suggestion improve your performance?\r\n", "@aselle It still running first epoch. If I get result (if second epoch is done), I will reply ASAP.\r\nBut currently (50% steps of first epoch), with `export TF_CUDNN_USE_AUTOTUNE=0` it become 4x slower with first epoch. @ppwwyyxx is it expected result? After read your suggestion, I expected faster in first epoch and slower in second epoch.", "I would recommend trying to redefine your code in such a way that your data can be same size. That will likely be the best way to avoid performance problems. Make sure you are not modifying the graph continually on every loop of training (you can finalize your graph to get an error if yout ry to do this). Without you sharing your code in the issue (or a simplified version that still has the problem), it's very unlikely we will be able to help you effectively (we're just guessing).", "Even though second epoch is still running, I think elapse time of second epoch will be similar with first epoch(about 45h) with `export TF_CUDNN_USE_AUTOTUNE=0`. As ppwwyyxx 's expectation, two epoch takes same (slower) speed.\r\nIf I can't modify data (like zero padding) for like aselle's recomentation, no more options in there?\r\nRather than make same size data, if I arrange order of data and make each batch group's size similar, does it help this problem?\r\nI haven't tried make all data same size, but when I tried to train with large batch size, there is no significant difference between first & second epoch's elapse time.\r\nAnd more, When I train with size sorted data, Increment of first epoch's time elapse is significantly smaller than random ordered.", "Your best bet is probably to sort and to pad within discrete sets of sizes. i.e. one strategy would be to have powers of two sizes allowed with zero padding to the next biggest to bit your irregular sizes. This is edging on the side of a stack overflow question at this point. I think things are working as intended.   We could maybe consider it a feature request to make padding and sorting of input data to be easier (library functions to help). @mrry, do you have any other thoughts?", "Dealing with irregular shapes is quite common. I wish there is a way to use a reasonably good cudnn algorithm without wasting too much time in warm up, but I don't know how this can be done. Maybe allow users to dump/load the autotune cache? Following some heuristics when autotune is disabled?", "Thanks a lot for finding reason of problem. Now, I should find way to dataset reordering method that minimize data modification and  approximatively size sorted. And as person facing with this problem, saving autotune cache persistently might be great like above ppwwyyxx's idea!", "The NMT tutorial takes a similar approach to batch input data according to bucketed sequence length. You might try taking a look at [how it uses `tf.contrib.data.group_by_window()`](https://github.com/tensorflow/nmt/blob/d43f1a6371e446778d79da991115c68435be9dcd/nmt/utils/iterator_utils.py#L197) to achieve this.", "Thanks for information!"]}, {"number": 13113, "title": "More robust sed regex syntax in compile_nsync.sh", "body": "> The syntax \\t for a tab character in sed is not standard. That escape is a [GNU sed extension](http://www.gnu.org/software/sed//manual/html_node/Escapes.html). \r\n\r\n> But [OS X sed](https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/sed.1.html), like other *BSD sed, doesn't support `\\t` for tab and instead treats `\\t` as meaning `backslash` followed by `t`.\r\n\r\nSo currently, nsync Android build in MacOS fails with \r\n\r\n> ar cr nsync.a common.o counter.o cv.o debug.o dll.o mu.o mu_wait.o note.o once.o sem_wait.o time_internal.o wait.o \"nsync_semaphore_mutex.o per_thread_waiter.o yield.o **ime_rep_timespec.o** nsync_panic.o\"\r\nar: nsync_semaphore_mutex.o per_thread_waiter.o yield.o **ime_rep_timespec.o** nsync_panic.o: No such file or directory\r\nmake: *** [nsync.a] Error 1\r\n\r\nSo added a `$` to the seq syntax to enable [ANSI-C Quoting](http://www.gnu.org/software/bash/manual/bash.html#ANSI_002dC-Quoting), and problem resolved.\r\n\r\nReference: [Simple sed replacement of tabs mysteriously failing](https://unix.stackexchange.com/a/145385)", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Jenkins, test this please."]}, {"number": 13112, "title": "Feature Request: API for weights values conversion", "body": "It would be very nice if the TensorFlow developers can provide a simple API for converting the weight values, ported from other frameworks like `Theano, Torch, Caffe and Chainer`. A lot of researchers still use these frameworks. Most of the times when an individual convert weights values, obtained from some framework other than TF, the results are not reproducible which is not desirable. Providing such an API, can help the TF community to port the models from other frameworks to TF, proving that the same thing could have been done more easily in TF. The API can have a method that takes the following signature:\r\n\r\n```\r\ndef port_weights_to_tf(weights values, framework=[Caffe or theano or Torch or chainer]):\r\n       # Change the weight values for each layer and store in hdf5 with layer names\r\n       return modified_weights\r\n```\r\n", "comments": ["@AakashKumarNain, unfortunately, most TensorFlow developers are focused on developing Tensorflow, and we actually do not have the expertise to write such converters. Incidentally there is more to moving weights. It is also important to ensure that ops have exactly the same semantics and features, and we have been working on that. For example, explicit padding is not available in TensorFlow and so Caffe models that use it, cannot be necessarily matched. We are open to PRs that fix those types of incompatibilities, and we would consider linking to weight conversion tools that others write. Thanks!"]}, {"number": 13111, "title": "Add py3 support for speech commands example", "body": "* Add imports for xrange and cast iterable to list", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Transient windows failure. Jenkins, test this please.", "I manually fixed the import order, @daemon \r\n\r\n@tensorflow-jenkins test this please", "@caisq I think it's ready."]}, {"number": 13110, "title": "Fix typos", "body": "This PR fixes some typos: `Tenor`, `tenor`, and `varibles`.", "comments": ["Can one of the admins verify this patch?", "@taehoonlee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @fchollet, @benoitsteiner and @keveman to be potential reviewers.", "@tensorflow-jenkins test this please"]}, {"number": 13109, "title": "Remove multiple includes of gpu_tracer.cc in Makefile build", "body": "Currently the `tensorflow/core/platform/default/gpu_tracer.cc` is included by both https://github.com/tensorflow/tensorflow/blob/702d595822e9e5f5232b8140c6296683612c33a9/tensorflow/contrib/makefile/Makefile#L468 and https://github.com/tensorflow/tensorflow/blob/702d595822e9e5f5232b8140c6296683612c33a9/tensorflow/contrib/makefile/Makefile#L515 in the Makefile. \r\n\r\nLeading to multiple definition build failure when the built tensorflow static lib is linked by other project.\r\n\r\n> <ndk_root>/toolchains/x86_64-4.9/prebuilt/darwin-x86_64/lib/gcc/x86_64-linux-android/4.9.x/../../../../x86_64-linux-android/bin/ld: error: <tensorflow_root>/lib/x86_64/libtensorflow-core.a(gpu_tracer.o): multiple definition of 'tensorflow::CreateGPUTracer()'\r\n<ndk_root>/toolchains/x86_64-4.9/prebuilt/darwin-x86_64/lib/gcc/x86_64-linux-android/4.9.x/../../../../x86_64-linux-android/bin/ld: <tensorflow_root>/lib/x86_64/libtensorflow-core.a(gpu_tracer.o): previous definition here\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\nProblem should be introduced from 083f5433f65b92a406f41806e7bc8c5d0ae679ac\r\n\r\nSo removed the later include to resolve the problem.", "comments": ["Can one of the admins verify this patch?", "@resec, thanks for your PR! By analyzing the history of the files in this pull request, we identified @martinwicke, @tensorflower-gardener and @vrv to be potential reviewers.", "Jenkins, test this please.", "@caisq @gunan is that a new Windows problem? I am seeing this on another PR, where there is no error reported but the final build fails.", "I think the actual problem is eigen:\r\n```\r\nCMake Error at eigen-stamp/download-eigen.cmake:157 (message):\r\n17:44:45     Each download failed!\r\n17:44:45   \r\n17:44:45 CUSTOMBUILD : error : downloading 'https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz' failed [C:\\tf_jenkins\\home\\workspace\\tensorflow-pr-win-cmake-py\\cmake_build\\eigen.vcxproj]\r\n17:44:45            status_code: 52\r\n17:44:45            status_string: \"Server returned nothing (no headers, no data)\"\r\n17:44:45            log:\r\n```", "Ah, thank you! Some firewall problem? This seems to work for me:\r\n```\r\n curl https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz|gzip -tv\r\n```", "Jenkins, test this please.\r\n\r\n(Maybe it's transient)"]}]