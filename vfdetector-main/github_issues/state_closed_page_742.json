[{"number": 31310, "title": "[INTEL MKL] Enable MatMul in eager mode", "body": "This PR depends on https://github.com/tensorflow/tensorflow/pull/30402 and should be merged it.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31310) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it", "Closing PR"]}, {"number": 31309, "title": "Custom loss function fails with sample_weight and batch_size > 1", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Debian 9.9\r\n- TensorFlow installed from: conda (-c anaconda)\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.3\r\n- GPU model and memory: n/a - tested in CPU mode\r\n\r\n**Describe the current behavior**\r\n\r\nAn error occurs when training an LSTM with a custom loss function, using `sample_weight` and `batch_size > 1`. The error does not occur if `batch_size = 1`, or if `sample_weight = None`.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect custom loss functions to work irrespective of batch size and sample weights.\r\n\r\n**Code to reproduce the issue**\r\n\r\nHere\u2019s a minimal example:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nbatch_size = 32  # no problem if this is 1\r\nsequence_len = 1\r\nembedding_size = 100\r\n\r\nx_train = np.random.randn(batch_size, sequence_len, embedding_size)\r\ny_train = np.random.randn(batch_size, embedding_size)\r\nsample_weight = np.random.randn(batch_size)  # no problem if this is None\r\n\r\ntrain_input = tf.keras.Input(shape=(sequence_len, embedding_size),\r\n                             batch_size=batch_size)\r\n\r\nlstm_layer = tf.keras.layers.LSTM(200,\r\n                                  return_sequences=False,\r\n                                  )(train_input)\r\n\r\ndense_layer = tf.keras.layers.Dense(embedding_size,\r\n                                    )(lstm_layer)\r\n\r\nmodel = tf.keras.models.Model(inputs=train_input, outputs=dense_layer)\r\n\r\nmodel.summary()\r\n\r\n# Custom loss function. This function could of course be replaced with\r\n# tf.keras.losses.mean_squared_error, but I have a use case where I need a\r\n# custom loss function.\r\nclass customLoss(tf.keras.losses.Loss):\r\n    def call(self, y_true, y_pred):\r\n        return tf.reduce_mean(tf.math.squared_difference(y_true, y_pred))\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\r\n              loss=customLoss())\r\n\r\nloss = model.train_on_batch(x_train,\r\n                            y=y_train,\r\n                            sample_weight=sample_weight)\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\nIn #29026, @pavithrasv has pointed out that loss functions from `tf.losses` do not work with keras, and suggested to use loss functions from `tf.keras.losses` instead (thanks again!). Consequently, I thought that defining a custom loss function using the `tf.keras.losses.Loss` base class should be possible. (Please note that in my actual use case I have a more complex custom loss function for which I need some math operations from `tf.math`.)\r\n\r\nTraceback:\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/john/PhD/GitLab/literary_lstm/bug_minimal_example_03.py\", line 38, in <module>\r\n    sample_weight=sample_weight)\r\n  File \"/home/john/miniconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1175, in train_on_batch\r\n    outputs = self.train_function(ins)  # pylint: disable=not-callable\r\n  File \"/home/john/miniconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 3292, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"/home/john/miniconda3/envs/py_tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1458, in __call__\r\n    run_metadata_ptr)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 32\r\n\t [[{{node loss_1/dense_loss/weighted_loss/Squeeze}}]]\r\n```\r\n", "comments": ["I have exactly the same issue.\r\nI use tf.keras.loss but I still get this error, I don't know hot to fix that.", "Thank for reporting this @ingo-m . The issue is because of how the custom loss is expected to be implemented. The `call` in `Loss` class is expected to return per-sample loss values. \r\n\r\nPlease take a look at the documentation for `y_true`, `y_pred`, `sample_weight` here: https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss?version=nightly#__call__\r\n\r\n`call` basically reduces y_true and y_pred with shape [batch_size, d0, .. dN] to loss values of shape [batch_size, d0, .. dN-1]. The reduce_mean is along the last dimension. To this result sample_weight that is broadcastable to shape [batch_size, d0, .. dN-1] is applied.\r\n\r\nIn your code updating the loss function like: \r\n`return tf.reduce_mean(tf.math.squared_difference(y_true, y_pred), axis=-1)` will fix the issue.\r\n\r\nHope this helps :) Closing out the issue, please feel free to add comments if you have more questions.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31309\">No</a>\n", "I'm currently trying to extend the example here with sample weights: https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n\r\nUntil now I had no luck :(.\r\n\r\n@pavithrasv Could you please explain how the example can be modified to use sample weights?  (or class_weights)", "@oholimoli  You will have to provide the weights when calling the loss function in the custom training loop. here -> https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example"]}, {"number": 31308, "title": "TF 2.0 nigtly 190803 generates errors W0803 during prediction", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): !pip install tf-nightly-gpu-2.0-preview\r\n- TensorFlow version: 2.0.0-dev20190803\r\n- Python version: \r\n- Installed using virtualenv? pip? conda?: !pip install tf-nightly-gpu-2.0-preview\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen running predictions I receive a great number of errors with the same information thus impeding performance. No such problem for TF 2.0.0-beta1\r\nSample of error text:\r\nW0803 19:06:51.695915 140613664049024 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nforecast = []\r\nresults = []\r\nfor time in range(len(series) - window_size):\r\n  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\r\n\r\nforecast = forecast[split_time-window_size:]\r\nresults = np.array(forecast)[:, 0, 0]\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["same. ", "In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "`!pip install tf-nightly-2.0-preview\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nprint(tf.__version__)\r\n#generating artificial data\r\ndef plot_series(time, series, format=\"-\", start=0, end=None):\r\n    plt.plot(time[start:end], series[start:end], format)\r\n    plt.xlabel(\"Time\")\r\n    plt.ylabel(\"Value\")\r\n    plt.grid(False)\r\n\r\ndef trend(time, slope=0):\r\n    return slope * time\r\n\r\ndef seasonal_pattern(season_time):\r\n    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\r\n    return np.where(season_time < 0.1,\r\n                    np.cos(season_time * 6 * np.pi),\r\n                    2 / np.exp(9 * season_time))\r\n\r\ndef seasonality(time, period, amplitude=1, phase=0):\r\n    \"\"\"Repeats the same pattern at each period\"\"\"\r\n    season_time = ((time + phase) % period) / period\r\n    return amplitude * seasonal_pattern(season_time)\r\n\r\ndef noise(time, noise_level=1, seed=None):\r\n    rnd = np.random.RandomState(seed)\r\n    return rnd.randn(len(time)) * noise_level\r\n\r\ntime = np.arange(10 * 365 + 1, dtype=\"float32\")\r\nbaseline = 10\r\nseries = trend(time, 0.1)  \r\nbaseline = 10\r\namplitude = 40\r\nslope = 0.005\r\nnoise_level = 3\r\n\r\n# Create the series\r\nseries = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\r\n# Update with noise\r\nseries += noise(time, noise_level, seed=51)\r\n\r\nsplit_time = 3000\r\ntime_train = time[:split_time]\r\nx_train = series[:split_time]\r\ntime_valid = time[split_time:]\r\nx_valid = series[split_time:]\r\n\r\nwindow_size = 20\r\nbatch_size = 32\r\nshuffle_buffer_size = 1000\r\n\r\nplot_series(time, series)\r\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer):\r\n  dataset = tf.data.Dataset.from_tensor_slices(series)\r\n  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\r\n  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\r\n  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\r\n  dataset = dataset.batch(batch_size).prefetch(1)\r\n  return dataset\r\n#training model\r\ntf.keras.backend.clear_session()\r\ntf.random.set_seed(51)\r\nnp.random.seed(51)\r\n\r\ntf.keras.backend.clear_session()\r\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\r\n                      input_shape=[None]),\r\n   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\r\n  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n  tf.keras.layers.Dense(1),\r\n  tf.keras.layers.Lambda(lambda x: x * 100.0)\r\n])\r\n\r\n\r\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9),metrics=[\"mae\"])\r\nhistory = model.fit(dataset,epochs=50,verbose=1)\r\n#predicting results\r\nforecast = []\r\nresults = []\r\nfor time in range(len(series) - window_size):\r\n  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\r\n\r\nforecast = forecast[split_time-window_size:]\r\nresults = np.array(forecast)[:, 0, 0]\r\n\r\n\r\nplt.figure(figsize=(10, 6))\r\n\r\nplot_series(time_valid, x_valid)\r\nplot_series(time_valid, results)\r\n`", "@rmothukuru please find code that I run in Colab when experienced the issue. As for the moment 2.0.0-dev20190805 issue is still present. Issue actually pops when running model.predict but I have to provide all the stuff to generate data and train the model for a few epoch to get to the stage.", "If it will be more convenient please find the actual Colab code [https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%203%20Exercise%20Answer.ipynb](url) ", "[https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%203%20Exercise%20Answer.ipynb](url)", "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%203%20Exercise%20Answer.ipynb", "@Simaex ,\r\nThank you for sharing the Google Colab. I could reproduce the issue with tf-nightly-2.0-preview.", "Those are warning logs and not necessarily a degrading performance. \r\nYou can always suppress them from printing by using something like this,\r\n```python\r\nimport logging, os\r\nlogging.disable(logging.WARNING)\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \r\n```", "It is also possible to revert to TF 2.0-beta that do not generate this warning message. My point was that nightly version have some undesired side issues. ", "Alright. Those are warning messages and not errors. You can safely ignore them. Feel free to post a new issue if you come across any bug/performance issues with TF 2.0 Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31308\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31308\">No</a>\n"]}, {"number": 31307, "title": "Performance decline after updating from 1.13.1 to 1.14.0", "body": "I have observed an obvious performance decline after I update TF from 1.13.1 to 1.14.0, even if the code has never changed. \r\nI am using CUDA 10.0 and tf.contrib.opt.AdamWOptimizer", "comments": ["Please provide details about what platform you are using (operating system, architecture).  Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the Github new issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n"]}, {"number": 31306, "title": "A correct way to use tf.contrib.opt.AdamWOptimizer", "body": "tf.contrib.opt.AdamWOptimizer requires two arguments: weight_decay and learning_rate. Since learning_rate is usually decayed along with the training, should weight_decay also be decayed with the same schedule? Would you please provide an example? ", "comments": ["When using warm up, do we need to warm up weight_decay together with learning_rate?", "I can imagine implementing it either way. \r\n\r\n@mingxingtan appears to be the author, maybe they can help.", "Sorry, I just merged an external PR. The original PR that adds this optimizer should be this: https://github.com/tensorflow/addons/pull/164", "Cool.\r\n\r\nSo since `tf.contrib` is being deleted, and this lives in tensorflow/addons now Lets close this bug, and anyone who's interested can continue the conversation in tensorflow/addons/issues.\r\n\r\nRight?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31306\">No</a>\n"]}, {"number": 31305, "title": "Parallel sessions for Comp Graph editing and optimization", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No):\r\nyes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIt dosnt seen to be possible to do this in Tensorflow. Ive read that pyTorch has this ability although never tested it since iam developing in Tensorflow for a couple of months now (and Tensorflow has a handful of libs and other langs api what make me not want to go test the other frame)\r\n\r\n**Will this change the current api? How?**\r\nMaybe, i dont know really, i wanna you opinion if it will change the API and if it is desirable.\r\n\r\n**Who will benefit with this feature?**\r\nAlthough the infra host machine has to be very powerful it's really a benefit to have a ability to change your comp graph on the fly while the other graph trains, it speeds up the researching process.\r\n\r\n**Any Other info.**\r\nIam not talking about editing the same graph that is optimizing, but editing one instance diverse of graph then that one that is optimizing", "comments": ["@Uiuran \r\n\r\nCan you please elaborate the context.Will it be possible to provide related code.Can you provide more details about any use-case for this feature? Thanks!\r\n", "Soon enough.\r\n\r\nJust optimizing for initialization and signal namescope wiring (got an mkldnn error(status 3), but was unable to reproduce in a simplistic code fashion, and i dont wanna to do the downgrade thing and know that the full traceback goes to Intel lib, so its easier to try the rewiring then correcting the bug directly).\r\n", "Update: \r\n1- API that encloses session must refers to diverse default var collections and graph defs. \r\n2- Default GraphKeys  ('__varscope',) and  ('__var_store',) is ready for that since the second element of the key tuple could be a tag or number for the different graph.\r\n\r\nThis name/graph-editing feature request is also present in the following issue\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/30991#", "@jaingaurav Do you know any context regrading this?", "@kkimdev @jaingaurav  The following can clarify:\r\nAlthough Variables are created to be shared to as much sessions are necessary (for example, distributing and saving/reloading), it still not possible to copy them with graph connectivity information, rename variable scope, add to renamed collection, add to the standard graph and then restart the session. \r\n\r\nThat is, resuming all the said above, the variable and graph creation are not dynamical as it could be. \r\n\r\nIt does make harder to create some small packages of graphs, say, a gated RNN, and them save it and reproduce, readd in the same graph but with diverse var scope name, such (variable_scopes,['gated_rnn_0','gated_rnn_1','gated_rnn_2',...]).\r\n\r\nHope this clarify what iam talking about.", "@Uiuran if I correctly understand your requirements, are you looking for ways to create identical copies of the same graph, and have these copies share variables?", "That's right, but i add that one of these copies would be in training session and another of the copies is being edited to give a new version (e.g a memory optimized one) or maybe a complete new arch that surpass the one being optimized. One aim achievable is to compose one Network based on the evidence of the training of another, useful if you have enough hardware to not have to wait the full validation (or you can try to early validate if you think is meaning).", "This should be achievable using tf.function. For example like so, to show a minimal example that just prints a tensor:\r\n\r\n```\r\nv = tf.Variable(1)\r\n\r\n@tf.function\r\ndef f(name, v):  # helps create different subgraphs, see below\r\n  with tf.name_scope(name):\r\n    tf.print(v)\r\n\r\nprint(f.get_concrete_function('graph1', v).graph.as_graph_def())\r\nprint(f.get_concrete_function('graph2', v).graph.as_graph_def())  # because name has a new Python value, a second graph is created\r\n\r\nf('graph1', v)  # invokes the first subgraph\r\nf('graph2, v)  # invokes the second subgraph\r\n```\r\n\r\nSee the latest [API docs](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py#L989) explaining the mechanism above in more detail.\r\n\r\nWould this work for your purpose?", "This is 2.0 feature ? \r\nStill have to test it.  In mean-time, my question is: Does with this function iam able to edit graph12 while changing the variable values in a session in graph1 ? Then change variable value in the graph12 (e.g. training) without changing graph1 weights?\r\nIam not sure that sharing variables achieve what iam asking.", "In that case it appears the you don't need variable sharing. Rather, something like this:\r\n\r\n```\r\nv1 = tf.Variable(...)\r\nv2 = tf.Variable(...)\r\n\r\nf('graph1', v1)\r\nf('graph2', v2)\r\n```\r\n\r\nThen the two graphs operate on entirely different variables and if any sharing was needed, you'd need to manually assign values to the respective variables.", "@Uiuran\r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 31304, "title": "Constructor for diagonal arrays (like numpy.diag)", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\nAt the moment the diagonal matrix constructor `tf.linalg.tensor_diag` does not support a second argument to specify which diagonal to fill. Something like the second argument in `numpy.diag` would be great.\r\n\r\nThis allows to simplify the process of generating powers of super- or sub-diagonal matrices by allowing a user to compute the off-diagonal elements directly and then filling the appropriate diagonal of a new array. Useful also to generate matrix exponentials of super- and sub-diagonal arrays.\r\n", "comments": ["@ziofil this functionality was recently added to tf.linalg.diag. Would that suffice? It will be available in the next release of TensorFlow, or you can get it from the current build at head:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L1955", "Yes, that's wonderful thank you!"]}, {"number": 31303, "title": "Change `kernel_initializer` in some `tf.keras` layers for improved performance", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: P100\r\n\r\n**Describe the current behavior**\r\nThe current `Conv2D` and `dense` layers in the `tf.keras` package have `glorot_uniform` as the default kernel initializer which doesn't play well with advanced activations like `relu`, `prelu`, `selu`, etc.  Given the fact that `relu` is a default choice for modern architectures, the kernel should be initialized from a different distribution.\r\n\r\n**Describe the expected behavior**\r\nThe `kernel initializer` should be changed to `he_uniform` in `Conv`, `SeparableConv`, `DepthwiseConv` and `Dense` layers from this\r\n\r\n```\r\n__init__(\r\n    filters,\r\n    kernel_size,\r\n    strides=(1, 1),\r\n    padding='valid',\r\n    data_format=None,\r\n    dilation_rate=(1, 1),\r\n    activation=None,\r\n    use_bias=True,\r\n    kernel_initializer='glorot_uniform',\r\n    bias_initializer='zeros',\r\n    kernel_regularizer=None,\r\n    bias_regularizer=None,\r\n    activity_regularizer=None,\r\n    kernel_constraint=None,\r\n    bias_constraint=None,\r\n    **kwargs\r\n)\r\n```\r\n\r\nto this\r\n```\r\n__init__(\r\n    filters,\r\n    kernel_size,\r\n    strides=(1, 1),\r\n    padding='valid',\r\n    data_format=None,\r\n    dilation_rate=(1, 1),\r\n    activation=None,\r\n    use_bias=True,\r\n    kernel_initializer='he_uniform',\r\n    bias_initializer='zeros',\r\n    kernel_regularizer=None,\r\n    bias_regularizer=None,\r\n    activity_regularizer=None,\r\n    kernel_constraint=None,\r\n    bias_constraint=None,\r\n    **kwargs\r\n)\r\n```\r\n\r\n**Other info / logs**\r\nHere are the resources that you can look into:\r\n1) The original paper for `Kaiming init`: https://arxiv.org/pdf/1502.01852.pdf\r\n2) Blog post: https://towardsdatascience.com/why-default-cnn-are-broken-in-keras-and-how-to-fix-them-ce295e5e5f2\r\n3) Blog post: https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79", "comments": ["This would be backward incompatible, but it might be worth considering for 2.0 as the justification seems fairly strong. @fchollet WDYT?", "@AakashKumarNain \r\nIt looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.4.1 or 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 31302, "title": "bazel build benchmark_model for android_arm failed In MacOS", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nmacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version:\r\n1.14.0\r\n- Python version:\r\n3.5\r\n- Installed using virtualenv? pip? conda?:\r\nanconda\r\n- Bazel version (if compiling from source):\r\n0.24.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nclang-1001.0.46.4\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nbazel build benchmark_model for android_arm failed In MacOS\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build -c opt --config=android_arm   tensorflow/lite/tools/benchmark:benchmark_model --verbose_failures\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nit seems cannot find /bin/false,  but I found the file /usr/bin/false \r\nso I tried:  ln -s /bin/false /usr/bin/false ,  but It's not permitted\r\nThen I replace  /bin/false  to /usr/bin/false in total workspace and bazel clean &&  rebuild ,\r\nIt' s still not work.\r\n it's only worked when I remove the  --config=android_arm\r\n\r\n==============================================\r\nbazel build -c opt --config=android_arm   tensorflow/lite/tools/benchmark:benchmark_model --verbose_failures\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=125\r\nINFO: Reading rc options for 'build' from /Users/80256276/workspace/github/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nINFO: Reading rc options for 'build' from /Users/80256276/workspace/github/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/80256276/workspace/anaconda3/envs/tensorflow-debug/bin/python --action_env PYTHON_LIB_PATH=/Users/80256276/workspace/anaconda3/envs/tensorflow-debug/lib/python3.5/site-packages --python_path=/Users/80256276/workspace/anaconda3/envs/tensorflow-debug/bin/python --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:android_arm in file /Users/80256276/workspace/github/tensorflow/.bazelrc: --config=android --cpu=armeabi-v7a --fat_apk_cpu=armeabi-v7a\r\nINFO: Found applicable config definition build:android in file /Users/80256276/workspace/github/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nINFO: Build options --cpu, --crosstool_top, and --host_crosstool_top have changed, discarding analysis cache.\r\nINFO: Analysed target //tensorflow/lite/tools/benchmark:benchmark_model (0 packages loaded, 1610 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /Users/80256276/workspace/github/tensorflow/tensorflow/lite/experimental/ruy/BUILD:136:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:blocking_counter' failed (Exit 1): false failed: error executing command \r\n  (cd /private/var/tmp/_bazel_80256276/20fdfdd4dfe4794de5bc0e54eeed4611/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/80256276/workspace/anaconda3/condabin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/go/bin:/Users/80256276/Library/Android/sdk/platform-tools:/Users/80256276/workspace/anaconda3/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/Users/80256276/workspace/anaconda3/envs/tensorflow-debug/bin/python \\\r\n    PYTHON_LIB_PATH=/Users/80256276/workspace/anaconda3/envs/tensorflow-debug/lib/python3.5/site-packages \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/false -MD -MF bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/experimental/ruy/_objs/blocking_counter/blocking_counter.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/experimental/ruy/_objs/blocking_counter/blocking_counter.o' -iquote . -iquote bazel-out/armeabi-v7a-opt/genfiles -iquote bazel-out/armeabi-v7a-opt/bin -c tensorflow/lite/experimental/ruy/blocking_counter.cc -o bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/experimental/ruy/_objs/blocking_counter/blocking_counter.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nsrc/main/tools/process-wrapper-legacy.cc:58: \"execvp(/bin/false, ...)\": No such file or directory\r\nTarget //tensorflow/lite/tools/benchmark:benchmark_model failed to build\r\nINFO: Elapsed time: 0.471s, Critical Path: 0.05s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["@srjoglekar246 could you take a look?", "Apparently these errors are seen when Bazel has issues finding the right executables (I guess the NDK compiler in this case). Quoting from the answer [here](https://stackoverflow.com/questions/41487069/build-error-with-tensorflow-android-demo/42614810):\r\n\r\n> You'll need to also edit your WORKSPACE file with your NDK and SDK settings according to the directions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android. /bin/false errors are typically seen when Bazel can't find the appropriate executable to run, in this case the ndk gcc compiler.\r\n\r\nCould you try the suggested procedure and report if it works?", "> Apparently these errors are seen when Bazel has issues finding the right executables (I guess the NDK compiler in this case). Quoting from the answer [here](https://stackoverflow.com/questions/41487069/build-error-with-tensorflow-android-demo/42614810):\r\n> \r\n> > You'll need to also edit your WORKSPACE file with your NDK and SDK settings according to the directions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android. /bin/false errors are typically seen when Bazel can't find the appropriate executable to run, in this case the ndk gcc compiler.\r\n> \r\n> Could you try the suggested procedure and report if it works?\r\n\r\nTried again as you say , /bin/false error has been solved. \r\nbut  another error occurs. seems like  c++ version and ndk version problems .\r\nthank you very much !\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31302\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31302\">No</a>\n"]}, {"number": 31301, "title": "nsync ~per_thread() issue causing SIGSEGV in glibc __run_exit_handlers exit.c", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I have linked against libtensorflow_cc.so but have used static linking\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 6.10 build / CentOS 7.4 runtime\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): v1.12.0\r\n- TensorFlow version (use command below):\r\n- Python version: NA\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): gcc 4.8.5\r\n- CUDA/cuDNN version: 10.0.130,7.4.2.24\r\n- GPU model and memory:GTX 1060\r\n\r\n\r\n**Describe the current behavior**\r\nSegfault at exit when unloading the Tensorflow Plugin in Autodesk Flame 2020.0\r\n\r\nError message\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n0x00007fa78f98adc0 in ?? ()\r\n```\r\n\r\nStacktrace\r\n```\r\n(gdb) bt\r\n#0  0x00007fa78f98adc0 in  ()\r\n#1  0x00007faba74ceb19 in  () at /lib64/libstdc++.so.6\r\n#2  0x00007faba6bc5b69 in __run_exit_handlers (status=0, listp=0x7faba6f526c8 <__exit_funcs>, run_list_atexit=run_list_atexit@entry=true) at exit.c:77\r\n#3  0x00007faba6bc5bb7 in __GI_exit (status=<optimized out>) at exit.c:99\r\n#4  0x000000000218b5e9 in  ()\r\n#5  0x0000000000703ce9 in  ()\r\n#6  0x000000000218a5ee in  ()\r\n#7  0x000000000218a6f1 in  ()\r\n#8  0x0000000000704358 in  ()\r\n#9  0x00000000004d9eb5 in  ()\r\n#10 0x00007faba6bae3d5 in __libc_start_main (main=\r\n    0x4d72c0, argc=1, argv=0x7ffcb9bb5dd8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7ffcb9bb5dc8)\r\n    at ../csu/libc-start.c:266\r\n#11 0x00000000005c6ee1 in  ()\r\n```\r\nSymbol at 0x00007fa78f98adc0  <_ZN5nsync12_GLOBAL__N_110per_threadD2Ev>\r\nc++filt _ZN5nsync12_GLOBAL__N_110per_threadD2Ev\r\n\r\n nsync::(anonymous namespace)::per_thread::~per_thread()\r\n\r\nsee:\r\nhttps://github.com/google/nsync/blob/5e8b19a81e5729922629dd505daa651f6ffdf107/platform/c%2B%2B11/src/per_thread_waiter.cc#L31\r\n\r\n**Describe the expected behavior**\r\nClose down cleanly.\r\n\r\n**Code to reproduce the issue**\r\nNot possible, as Autodesk Flame framework is required\r\n\r\n**Other info / logs**\r\nLooking at https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/tools/benchmark/benchmark_model.cc \r\n\r\nThere doesn't seem to be any special destructors used.\r\n\r\nCloses down cleanly in other runtime environments.\r\n\r\nThe Plugin can be in any state when exiting, but other destructors can be called earlier to clean up the session.\r\n\r\nWhat destructors would have to be used to make sure that the nsync::(anonymous_namespace)::per_thread::~per_thread() desctructor cannot result in the segfault with the atexit handlers from glibc?\r\n", "comments": ["@m3bm3b do you have any insight?", "It may relate to this:\r\n\r\nhttps://stackoverflow.com/questions/52683649/libtensorflow-cc-so-initialised-a-second-time-causes-segfault\r\n\r\nThe runtime environment has a parent application which is linked against libtensorfow_(cc)(framework).so the plugin has the same symbols statically linked.\r\n\r\nThe destructor is failing to clean up the nsync per_thread object in the plugin with the static linking.", "How frustrating.\r\n\r\nA possilble workaround for the moment is to call quick_exit() instead of exit().\r\n\r\nI believe a fix for nsync will be to avoid using the C++ per_thread_waiter machinery\r\n(per_thread_waiter.cc) and instead use the Posix machinery (per_thread_waiter.c)\r\nexcept on platforms where the latter is unavailable (which is just Windows, as far as I know).\r\nIf building with bazel, that could be achieved by changing this line in the BUILD file \r\n        \"//conditions:default\": [\"platform/c++11/src/per_thread_waiter.cc\"],\r\nto\r\n         \"//conditions:default\": [\"platform/posix/src/per_thread_waiter.c\"],\r\n\r\nWould you be able to test these possibilities?  \r\nWIll one of them work for you temporarily, until I can \r\nimplement the second fix in nsync?\r\n\r\nIf this is caused by libraries being pulled into the address space multiple times,\r\nwe will have to be careful with other libraries too.\r\n\r\n\r\nBy the way, it's _always_ risky to call exit() in a multithreaded \r\nC++ programme; it's safer to call quick_exit().\r\nThat's because invoking the destructor of any static variable could cause \r\nanother running thread to crash, as it may be about to access that variable.\r\nYou can't get around this safely by forcibly suspending all the threads first, \r\nbecause that could cause the destructors to deadlock the exiting thread.  \r\nAnd you can't shut down all the threads cleanly, first because you can't \r\neven name them, and second because there may not\r\nbe a deadlock-free shutdown order in general.   That's why quick_exit() exists.\r\nAlas, quick_exit() was defined not only to avoid running static destructors, but also\r\nto fail to run explicit atexit() handlers, so you may have to flush stdout/stderr before calling\r\nquick_exit().\r\n", "Thanks for your generous response\r\n\r\nThe whole quick_exit() vs exit() may be beyond my control.\r\n\r\nMy software is a plugin to Autodesk Flame and it is Autodesk Flame that invokes the shutdown.\r\n\r\nUnless I can register atexit handlers in my objects, I need to get more knowledge about the whole tear down process and glibc.\r\n\r\nBut I can certainly build a new libnsync.a and link both Tensorflow and my plugin against the version that uses the C code rather than the C++ code if you think that will fix the crash at exit.\r\n\r\nThe crash is only effecting Linux, then only under Autodesk Flame, other plugin hosts with the identical software build exit cleanly.\r\n\r\nI can see if I can build the custom nsync today. \r\n\r\nYou have no idea how many searches have come back for the boy band *NSYNC \r\n\r\nSam", "Now for the fun bit:\r\n\r\nTensorflow is a bunch of archived obj files, because of the need for static linking, and no way to build a static libtensorflow_cc.a and libtensorflow_framework.a\r\n\r\nSo I did it myself and made libgputf.a, by creating a slurry of objs from the bazel-bin folder.\r\n\r\nI also have a bunch of obj files for the change you recomends as below\r\n\r\n```\r\n[samh@apollo-centos6 nsync-1.21.0-modified]$ nm nsync-1.21.0/bazel-out/k8-fastbuild/bin/_objs/*/*.o |  grep per_thread | c++filt\r\n                 U nsync_set_per_thread_waiter_\r\n                 U nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\nnsync-1.21.0/bazel-out/k8-fastbuild/bin/_objs/nsync_cpp/per_thread_waiter.pic.o:\r\n000000000000003c t nsync::(anonymous namespace)::per_thread::get(void (*)(void*))\r\n000000000000005e t nsync::(anonymous namespace)::per_thread::set(void*, void (*)(void*))\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000087 T nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000000000a9 T nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\nnsync-1.21.0/bazel-out/k8-fastbuild/bin/_objs/nsync/per_thread_waiter.pic.o:\r\n00000000000000b3 T nsync_per_thread_waiter_\r\n00000000000000e1 T nsync_set_per_thread_waiter_\r\n```\r\n\r\nThe exising .a file I am linking against which causes the bug, is a slurry of objs files from the tensorflow bazel-build folder\r\n\r\n```\r\n[samh@apollo-centos6 tensorflow]$ nm libgputf.a | grep per_thread | c++filt\r\nper_thread_waiter.pic.o:\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 T nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n0000000000000000 T nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n                 U nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n0000000000000000 u EigenForTFLite::NonBlockingThreadPoolTempl<EigenForTFLite::StlThreadEnvironment>::GetPerThread()::per_thread_\r\n0000000000000000 u Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::GetPerThread()::per_thread_\r\n0000000000000000 D tensorflow::per_thread_max_parallism\r\n0000000000000000 T stream_executor::KernelMetadata::set_registers_per_thread(int)\r\n0000000000000000 T stream_executor::KernelMetadata::registers_per_thread(int*) const\r\n                 U stream_executor::KernelMetadata::set_registers_per_thread(int)\r\n                 U stream_executor::KernelMetadata::registers_per_thread(int*) const\r\n```\r\n\r\nand allobjs.txt has a list of these obj files\r\n\r\n```\r\n[samh@apollo-centos6 tensorflow]$ cat allobjs.txt | sed \"s| |\\n|g\" allobjs.txt | grep nsync\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/platform/c++11/src/time_rep_timespec.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/platform/c++11/src/nsync_panic.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/platform/c++11/src/per_thread_waiter.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/platform/c++11/src/yield.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/platform/linux/src/nsync_semaphore_futex.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/note.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/counter.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/mu_wait.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/dll.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/sem_wait.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/common.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/cv.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/debug.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/mu.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/time_internal.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/once.pic.o\r\nbazel-bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/wait.pic.o\r\n```\r\n\r\nSo my instinct is that I make a new archive where I include the objs from the symbols that are in the libnsync_cpp.a where the change was made to the bazel file as per your suggestions (~/dev/nsync-1.21.0-modified/nsync-1.21.0) into the libgputf-updated.a instead of the tensorflow/bazel-bin/external/nsync/_objs/nsync_cpp\r\n\r\nThen link my plugin against the edited bazel file\r\n\r\nie these guys\r\n\r\n```\r\n[samh@apollo-centos6 tensorflow]$ nm ~/dev/nsync-1.21.0-modified/nsync-1.21.0/bazel-bin/libnsync_cpp.a | c++filt\r\n\r\ncommon.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n00000000000005cb t _GLOBAL__sub_I_common.c\r\n00000000000005a0 t __static_initialization_and_destruction_0(int, int)\r\n                 U nsync::nsync_yield_()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000163 T nsync::nsync_dll_waiter_(nsync::nsync_dll_element_s_*)\r\n0000000000000000 B nsync::nsync_malloc_ptr_\r\n0000000000000035 T nsync::nsync_spin_delay_(unsigned int)\r\n00000000000002c5 T nsync::nsync_waiter_new_()\r\n0000000000000008 D nsync::nsync_reader_type_\r\n00000000000004f7 T nsync::nsync_waiter_free_(nsync::waiter*)\r\n0000000000000000 D nsync::nsync_writer_type_\r\n0000000000000118 T nsync::nsync_dll_nsync_waiter_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n0000000000000080 T nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000001d7 T nsync::nsync_dll_waiter_samecond_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n0000000000000020 d nsync::Xreader_type\r\n0000000000000000 d nsync::Xwriter_type\r\n0000000000000008 b nsync::free_waiters\r\n0000000000000224 t nsync::waiter_destroy(void*)\r\n0000000000000010 b nsync::free_waiters_mu\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 b nsync::waiter_for_thread\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W void std::atomic_store<unsigned int>(std::atomic<unsigned int>*, unsigned int)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U __tls_get_addr\r\n                 U malloc\r\n\r\ncounter.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n00000000000000e9 T nsync::nsync_counter_add(nsync::nsync_counter_s_*, int)\r\n0000000000000035 T nsync::nsync_counter_new(unsigned int)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000008b T nsync::nsync_counter_free(nsync::nsync_counter_s_*)\r\n000000000000029e T nsync::nsync_counter_wait(nsync::nsync_counter_s_*, timespec)\r\n0000000000000275 T nsync::nsync_counter_value(nsync::nsync_counter_s_*)\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_counter_waitable_funcs\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000045e t nsync::counter_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000000003a3 t nsync::counter_enqueue(void*, nsync::nsync_waiter_s*)\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000333 t nsync::counter_ready_time(void*, nsync::nsync_waiter_s*)\r\n0000000000000000 t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n                 U memset\r\n\r\ncv.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n000000000000009f T nsync::nsync_cv_init(nsync::nsync_cv_s_*)\r\n0000000000000ea7 T nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n0000000000000947 T nsync::nsync_cv_signal(nsync::nsync_cv_s_*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n0000000000000c7d T nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_cv_waitable_funcs\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000000000e58 T nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000004e1 T nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*)\r\n00000000000000a0 r nsync::WAITER_TAG\r\n0000000000000fce t nsync::cv_dequeue(void*, nsync::nsync_waiter_s*)\r\n0000000000000f39 t nsync::cv_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000000004ad t nsync::void_mu_lock(void*)\r\n00000000000000c3 t nsync::wake_waiters(nsync::nsync_dll_element_s_*, int)\r\n0000000000000ee0 t nsync::cv_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000000004c7 t nsync::void_mu_unlock(void*)\r\n00000000000000a4 r nsync::NSYNC_WAITER_TAG\r\n0000000000000035 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U memset\r\n\r\ndebug.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000a48 T nsync::nsync_cv_debugger(nsync::nsync_cv_s_*)\r\n0000000000000a0c T nsync::nsync_mu_debugger(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_writer_type_\r\n0000000000000949 T nsync::nsync_cv_debug_state(nsync::nsync_cv_s_*, char*, int)\r\n0000000000000908 T nsync::nsync_mu_debug_state(nsync::nsync_mu_s_*, char*, int)\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000009cb T nsync::nsync_cv_debug_state_and_waiters(nsync::nsync_cv_s_*, char*, int)\r\n000000000000098a T nsync::nsync_mu_debug_state_and_waiters(nsync::nsync_mu_s_*, char*, int)\r\n00000000000000e4 r nsync::WAITER_TAG\r\n00000000000000ef t nsync::emit_print(nsync::emit_buf*, char const*, ...)\r\n00000000000003ee t nsync::emit_waiters(nsync::emit_buf*, nsync::nsync_dll_element_s_*)\r\n00000000000007e1 t nsync::emit_cv_state(nsync::emit_buf*, nsync::nsync_cv_s_*, int, int)\r\n000000000000068b t nsync::emit_mu_state(nsync::emit_buf*, nsync::nsync_mu_s_*, int, int)\r\n0000000000000000 b nsync::nsync_debug_buf\r\n00000000000000e8 r nsync::NSYNC_WAITER_TAG\r\n00000000000000e0 d nsync::waiter_flags_bit\r\n00000000000000a0 d nsync::cv_bit\r\n0000000000000040 t nsync::emit_c(nsync::emit_buf*, int)\r\n0000000000000000 d nsync::mu_bit\r\n0000000000000000 t nsync::emit_init(nsync::emit_buf*, char*, int)\r\n0000000000000368 t nsync::emit_word(nsync::emit_buf*, nsync::bit_name const*, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n0000000000000120 r nsync::emit_c(nsync::emit_buf*, int)::suffix\r\n\r\ndll.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n00000000000001bd T nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n00000000000001cb T nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000001fa T nsync::nsync_dll_prev_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000195 T nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000046 T nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000031 T nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n00000000000000c2 T nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000015a T nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000115 T nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nmu.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n000000000000009f T nsync::nsync_mu_init(nsync::nsync_mu_s_*)\r\n00000000000003cd T nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n0000000000000509 T nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000e32 T nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000efc T nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n0000000000000345 T nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000482 T nsync::nsync_mu_rtrylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n000000000000104f T nsync::nsync_mu_is_reader(nsync::nsync_mu_s_ const*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n000000000000011d T nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n0000000000000fe2 T nsync::nsync_mu_assert_held(nsync::nsync_mu_s_ const*)\r\n                 U nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n0000000000001019 T nsync::nsync_mu_rassert_held(nsync::nsync_mu_s_ const*)\r\n000000000000090e T nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n                 U nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000007cf T nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000067c T nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000190 r nsync::WAITER_TAG\r\n00000000000005bd t nsync::condition_true(nsync::nsync_dll_element_s_*)\r\n0000000000000194 r nsync::NSYNC_WAITER_TAG\r\n0000000000000035 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000000000c3 t nsync::mu_release_spinlock(nsync::nsync_mu_s_*)\r\n00000000000005fb t nsync::skip_past_same_condition(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U memset\r\n\r\nmu_wait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n0000000000000642 T nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n                 U nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n                 U nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n                 U nsync::nsync_time_no_deadline\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000000000224 T nsync::nsync_mu_wait_with_deadline(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*), timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000006a5 T nsync::nsync_mu_unlock_without_wakeup(nsync::nsync_mu_s_*)\r\n000000000000010c r nsync::WAITER_TAG\r\n0000000000000110 r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000009f t nsync::mu_try_acquire_after_timeout_or_cancel(nsync::nsync_mu_s_*, nsync::lock_type_s*, nsync::waiter*, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\nnote.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n000000000000052d T nsync::nsync_note_new(nsync::nsync_note_s_*, timespec)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n00000000000006cf T nsync::nsync_note_free(nsync::nsync_note_s_*)\r\n0000000000000952 T nsync::nsync_note_wait(nsync::nsync_note_s_*, timespec)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000009c4 T nsync::nsync_note_expiry(nsync::nsync_note_s_*)\r\n00000000000008f5 T nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n00000000000004d7 T nsync::nsync_note_is_notified(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_note_waitable_funcs\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000003ae T nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000003a t nsync::no_children(void const*)\r\n0000000000000b1a t nsync::note_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000000009f8 t nsync::note_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000000009da t nsync::note_ready_time(void*, nsync::nsync_waiter_s*)\r\n0000000000000000 t nsync::set_expiry_time(nsync::nsync_note_s_*, timespec)\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000058 t nsync::note_notify_child(nsync::nsync_note_s_*, nsync::nsync_note_s_*)\r\n0000000000000252 t nsync::notify(nsync::nsync_note_s_*)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n                 U memset\r\n\r\nonce.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n00000000000003e8 t _GLOBAL__sub_I_once.c\r\n0000000000000398 t __static_initialization_and_destruction_0(int, int)\r\n0000000000000000 W nsync::nsync_cv_s_::nsync_cv_s_()\r\n0000000000000000 W nsync::nsync_cv_s_::nsync_cv_s_()\r\n0000000000000000 W nsync::nsync_mu_s_::nsync_mu_s_()\r\n0000000000000000 W nsync::nsync_mu_s_::nsync_mu_s_()\r\n0000000000000000 W nsync::once_sync_s::once_sync_s()\r\n0000000000000000 W nsync::once_sync_s::once_sync_s()\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_ms(unsigned int)\r\n0000000000000200 T nsync::nsync_run_once(std::atomic<unsigned int>*, void (*)())\r\n                 U nsync::nsync_time_add(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n0000000000000278 T nsync::nsync_run_once_arg(std::atomic<unsigned int>*, void (*)(void*), void*)\r\n00000000000002f8 T nsync::nsync_run_once_spin(std::atomic<unsigned int>*, void (*)())\r\n0000000000000344 T nsync::nsync_run_once_arg_spin(std::atomic<unsigned int>*, void (*)(void*), void*)\r\n                 U nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::nsync_run_once_impl(std::atomic<unsigned int>*, nsync::once_sync_s*, void (*)(), void (*)(void*), void*)\r\n0000000000000000 b nsync::once_sync\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\nsem_wait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 T nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\ntime_internal.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_time_ms(unsigned int)\r\n000000000000004d T nsync::nsync_time_us(unsigned int)\r\n                 U nsync::nsync_time_s_ns(long, unsigned int)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nwait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_waiter_new_()\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n\r\ntime_rep_timespec.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000247 T nsync::nsync_time_add(timespec, timespec)\r\n0000000000000330 T nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000148 T nsync::nsync_time_now()\r\n00000000000002b8 T nsync::nsync_time_sub(timespec, timespec)\r\n0000000000000000 T nsync::nsync_time_s_ns(long, unsigned int)\r\n0000000000000020 R nsync::nsync_time_zero\r\n000000000000015b T nsync::nsync_time_sleep(timespec)\r\n00000000000000d9 T nsync::nsync_to_time_point_(timespec)\r\n000000000000003e T nsync::nsync_from_time_point_(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >)\r\n0000000000000010 R nsync::nsync_time_no_deadline\r\n0000000000000030 r __gnu_cxx::__default_lock_policy\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::time_since_epoch() const\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::count() const\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> >::count() const\r\n                 U std::this_thread::__sleep_for(std::chrono::duration<long, std::ratio<1l, 1l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> >)\r\n0000000000000000 W void std::this_thread::sleep_for<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::time_point(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::value, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::value, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1l> > >::value, std::chrono::duration<long, std::ratio<1l, 1l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::ratio<1000000000l, 1l>, long, false, true>::__cast<long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::ratio<1l, 1l>, long, true, true>::__cast<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1l> >, std::ratio<1l, 1000000000l>, long, true, false>::__cast<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n                 U std::chrono::_V2::system_clock::now()\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, std::ratio<1l, 1l>, void>(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, void>(long const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, std::ratio<1l, 1l>, void>(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> >::duration<long, void>(long const&)\r\n0000000000000000 W std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1l> > >::type std::chrono::operator-<long, std::ratio<1l, 1000000000l>, long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&, std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W _ZNSt6chronomiIlSt5ratioILl1ELl1000000000EElS1_ILl1ELl1EEEENSt11common_typeIJNS_8durationIT_T0_EENS5_IT1_T2_EEEE4typeERKS8_RKSB_\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type> std::chrono::operator+<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > > const&, std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W _ZNSt6chronoplINS_3_V212system_clockENS_8durationIlSt5ratioILl1ELl1000000000EEEElS5_EENS_10time_pointIT_NSt11common_typeIJT0_NS3_IT1_T2_EEEE4typeEEERKNS7_IS8_SA_EERKSD_\r\n0000000000000000 W std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::operator+<long, std::ratio<1l, 1000000000l>, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&, std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W _ZNSt6chronoplIlSt5ratioILl1ELl1000000000EElS2_EENSt11common_typeIJNS_8durationIT_T0_EENS4_IT1_T2_EEEE4typeERKS7_RKSA_\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n                 U memset\r\n\r\nnsync_panic.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n000000000000007e t _GLOBAL__sub_I_nsync_panic.cc\r\n0000000000000036 t __static_initialization_and_destruction_0(int, int)\r\n0000000000000000 T nsync::nsync_panic_(char const*)\r\n                 U std::ios_base::Init::Init()\r\n                 U std::ios_base::Init::~Init()\r\n                 U std::cerr\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 b std::__ioinit\r\n                 U std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)\r\n                 U __cxa_atexit\r\n                 U __dso_handle\r\n                 U abort\r\n\r\nyield.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_yield_()\r\n0000000000000008 r __gnu_cxx::__default_lock_policy\r\n0000000000000000 W std::this_thread::yield()\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nnsync_semaphore_futex.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n00000000000000d6 T nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n000000000000031b T nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n00000000000000ba T nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n000000000000018e T nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::assert_int_size\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 d nsync::sem_big_enough_for_futex\r\n000000000000006a t nsync::futex(int*, int, int, timespec const*, int*, int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U __errno_location\r\n                 U memset\r\n                 U syscall\r\n\r\nper_thread_waiter.pic.o:\r\n0000000000000000 V DW.ref.__gxx_personality_v0\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n000000000000003c t nsync::(anonymous namespace)::per_thread::get(void (*)(void*))\r\n000000000000005e t nsync::(anonymous namespace)::per_thread::set(void*, void (*)(void*))\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 b nsync::(anonymous namespace)::thread_specific\r\n0000000000000087 T nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000000000a9 T nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n000000000000012c t _ZTWN5nsync12_GLOBAL__N_115thread_specificE\r\n                 U __cxa_thread_atexit\r\n                 U __dso_handle\r\n                 U __gxx_personality_v0\r\n                 U __tls_get_addr\r\n0000000000000010 b __tls_guard\r\n00000000000000d3 t __tls_init\r\n[samh@apollo-centos6 tensorflow]$ nm ~/dev/nsync-1.21.0-modified/nsync-1.21.0/bazel-bin/libnsync_cpp.a | c++filt\r\n\r\ncommon.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n00000000000005cb t _GLOBAL__sub_I_common.c\r\n00000000000005a0 t __static_initialization_and_destruction_0(int, int)\r\n                 U nsync::nsync_yield_()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000163 T nsync::nsync_dll_waiter_(nsync::nsync_dll_element_s_*)\r\n0000000000000000 B nsync::nsync_malloc_ptr_\r\n0000000000000035 T nsync::nsync_spin_delay_(unsigned int)\r\n00000000000002c5 T nsync::nsync_waiter_new_()\r\n0000000000000008 D nsync::nsync_reader_type_\r\n00000000000004f7 T nsync::nsync_waiter_free_(nsync::waiter*)\r\n0000000000000000 D nsync::nsync_writer_type_\r\n0000000000000118 T nsync::nsync_dll_nsync_waiter_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n0000000000000080 T nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000001d7 T nsync::nsync_dll_waiter_samecond_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n0000000000000020 d nsync::Xreader_type\r\n0000000000000000 d nsync::Xwriter_type\r\n0000000000000008 b nsync::free_waiters\r\n0000000000000224 t nsync::waiter_destroy(void*)\r\n0000000000000010 b nsync::free_waiters_mu\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 b nsync::waiter_for_thread\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W void std::atomic_store<unsigned int>(std::atomic<unsigned int>*, unsigned int)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U __tls_get_addr\r\n                 U malloc\r\n\r\ncounter.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n00000000000000e9 T nsync::nsync_counter_add(nsync::nsync_counter_s_*, int)\r\n0000000000000035 T nsync::nsync_counter_new(unsigned int)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000008b T nsync::nsync_counter_free(nsync::nsync_counter_s_*)\r\n000000000000029e T nsync::nsync_counter_wait(nsync::nsync_counter_s_*, timespec)\r\n0000000000000275 T nsync::nsync_counter_value(nsync::nsync_counter_s_*)\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_counter_waitable_funcs\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000045e t nsync::counter_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000000003a3 t nsync::counter_enqueue(void*, nsync::nsync_waiter_s*)\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000333 t nsync::counter_ready_time(void*, nsync::nsync_waiter_s*)\r\n0000000000000000 t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n                 U memset\r\n\r\ncv.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n000000000000009f T nsync::nsync_cv_init(nsync::nsync_cv_s_*)\r\n0000000000000ea7 T nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n0000000000000947 T nsync::nsync_cv_signal(nsync::nsync_cv_s_*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n0000000000000c7d T nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_cv_waitable_funcs\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000000000e58 T nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000004e1 T nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*)\r\n00000000000000a0 r nsync::WAITER_TAG\r\n0000000000000fce t nsync::cv_dequeue(void*, nsync::nsync_waiter_s*)\r\n0000000000000f39 t nsync::cv_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000000004ad t nsync::void_mu_lock(void*)\r\n00000000000000c3 t nsync::wake_waiters(nsync::nsync_dll_element_s_*, int)\r\n0000000000000ee0 t nsync::cv_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000000004c7 t nsync::void_mu_unlock(void*)\r\n00000000000000a4 r nsync::NSYNC_WAITER_TAG\r\n0000000000000035 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U memset\r\n\r\ndebug.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000a48 T nsync::nsync_cv_debugger(nsync::nsync_cv_s_*)\r\n0000000000000a0c T nsync::nsync_mu_debugger(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_writer_type_\r\n0000000000000949 T nsync::nsync_cv_debug_state(nsync::nsync_cv_s_*, char*, int)\r\n0000000000000908 T nsync::nsync_mu_debug_state(nsync::nsync_mu_s_*, char*, int)\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000009cb T nsync::nsync_cv_debug_state_and_waiters(nsync::nsync_cv_s_*, char*, int)\r\n000000000000098a T nsync::nsync_mu_debug_state_and_waiters(nsync::nsync_mu_s_*, char*, int)\r\n00000000000000e4 r nsync::WAITER_TAG\r\n00000000000000ef t nsync::emit_print(nsync::emit_buf*, char const*, ...)\r\n00000000000003ee t nsync::emit_waiters(nsync::emit_buf*, nsync::nsync_dll_element_s_*)\r\n00000000000007e1 t nsync::emit_cv_state(nsync::emit_buf*, nsync::nsync_cv_s_*, int, int)\r\n000000000000068b t nsync::emit_mu_state(nsync::emit_buf*, nsync::nsync_mu_s_*, int, int)\r\n0000000000000000 b nsync::nsync_debug_buf\r\n00000000000000e8 r nsync::NSYNC_WAITER_TAG\r\n00000000000000e0 d nsync::waiter_flags_bit\r\n00000000000000a0 d nsync::cv_bit\r\n0000000000000040 t nsync::emit_c(nsync::emit_buf*, int)\r\n0000000000000000 d nsync::mu_bit\r\n0000000000000000 t nsync::emit_init(nsync::emit_buf*, char*, int)\r\n0000000000000368 t nsync::emit_word(nsync::emit_buf*, nsync::bit_name const*, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n0000000000000120 r nsync::emit_c(nsync::emit_buf*, int)::suffix\r\n\r\ndll.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n00000000000001bd T nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n00000000000001cb T nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000001fa T nsync::nsync_dll_prev_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000195 T nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000046 T nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000031 T nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n00000000000000c2 T nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000015a T nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000115 T nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nmu.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n000000000000009f T nsync::nsync_mu_init(nsync::nsync_mu_s_*)\r\n00000000000003cd T nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n0000000000000509 T nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000e32 T nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n0000000000000efc T nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n0000000000000345 T nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000482 T nsync::nsync_mu_rtrylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n000000000000104f T nsync::nsync_mu_is_reader(nsync::nsync_mu_s_ const*)\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n000000000000011d T nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n0000000000000fe2 T nsync::nsync_mu_assert_held(nsync::nsync_mu_s_ const*)\r\n                 U nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n0000000000001019 T nsync::nsync_mu_rassert_held(nsync::nsync_mu_s_ const*)\r\n000000000000090e T nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n                 U nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n00000000000007cf T nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n000000000000067c T nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000190 r nsync::WAITER_TAG\r\n00000000000005bd t nsync::condition_true(nsync::nsync_dll_element_s_*)\r\n0000000000000194 r nsync::NSYNC_WAITER_TAG\r\n0000000000000035 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000000000c3 t nsync::mu_release_spinlock(nsync::nsync_mu_s_*)\r\n00000000000005fb t nsync::skip_past_same_condition(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U memset\r\n\r\nmu_wait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_panic_(char const*)\r\n0000000000000642 T nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n                 U nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_waiter_new_()\r\n                 U nsync::nsync_reader_type_\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_writer_type_\r\n                 U nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n                 U nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n                 U nsync::nsync_time_no_deadline\r\n                 U nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000000000224 T nsync::nsync_mu_wait_with_deadline(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*), timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000006a5 T nsync::nsync_mu_unlock_without_wakeup(nsync::nsync_mu_s_*)\r\n000000000000010c r nsync::WAITER_TAG\r\n0000000000000110 r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000006a t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n000000000000009f t nsync::mu_try_acquire_after_timeout_or_cancel(nsync::nsync_mu_s_*, nsync::lock_type_s*, nsync::waiter*, unsigned int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\nnote.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n000000000000052d T nsync::nsync_note_new(nsync::nsync_note_s_*, timespec)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n00000000000006cf T nsync::nsync_note_free(nsync::nsync_note_s_*)\r\n0000000000000952 T nsync::nsync_note_wait(nsync::nsync_note_s_*, timespec)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000009c4 T nsync::nsync_note_expiry(nsync::nsync_note_s_*)\r\n00000000000008f5 T nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n00000000000004d7 T nsync::nsync_note_is_notified(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 D nsync::nsync_note_waitable_funcs\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000000003ae T nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000003a t nsync::no_children(void const*)\r\n0000000000000b1a t nsync::note_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000000009f8 t nsync::note_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000000009da t nsync::note_ready_time(void*, nsync::nsync_waiter_s*)\r\n0000000000000000 t nsync::set_expiry_time(nsync::nsync_note_s_*, timespec)\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000058 t nsync::note_notify_child(nsync::nsync_note_s_*, nsync::nsync_note_s_*)\r\n0000000000000252 t nsync::notify(nsync::nsync_note_s_*)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n                 U memset\r\n\r\nonce.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n00000000000003e8 t _GLOBAL__sub_I_once.c\r\n0000000000000398 t __static_initialization_and_destruction_0(int, int)\r\n0000000000000000 W nsync::nsync_cv_s_::nsync_cv_s_()\r\n0000000000000000 W nsync::nsync_cv_s_::nsync_cv_s_()\r\n0000000000000000 W nsync::nsync_mu_s_::nsync_mu_s_()\r\n0000000000000000 W nsync::nsync_mu_s_::nsync_mu_s_()\r\n0000000000000000 W nsync::once_sync_s::once_sync_s()\r\n0000000000000000 W nsync::once_sync_s::once_sync_s()\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_ms(unsigned int)\r\n0000000000000200 T nsync::nsync_run_once(std::atomic<unsigned int>*, void (*)())\r\n                 U nsync::nsync_time_add(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_spin_delay_(unsigned int)\r\n                 U nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n0000000000000278 T nsync::nsync_run_once_arg(std::atomic<unsigned int>*, void (*)(void*), void*)\r\n00000000000002f8 T nsync::nsync_run_once_spin(std::atomic<unsigned int>*, void (*)())\r\n0000000000000344 T nsync::nsync_run_once_arg_spin(std::atomic<unsigned int>*, void (*)(void*), void*)\r\n                 U nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::nsync_run_once_impl(std::atomic<unsigned int>*, nsync::once_sync_s*, void (*)(), void (*)(void*), void*)\r\n0000000000000000 b nsync::once_sync\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\nsem_wait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n0000000000000000 T nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n                 U nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n                 U nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n                 U nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n\r\ntime_internal.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_time_ms(unsigned int)\r\n000000000000004d T nsync::nsync_time_us(unsigned int)\r\n                 U nsync::nsync_time_s_ns(long, unsigned int)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nwait.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n0000000000000000 W nsync::nsync_waiter_s::nsync_waiter_s()\r\n                 U nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n                 U nsync::nsync_time_zero\r\n                 U nsync::nsync_waiter_new_()\r\n                 U nsync::nsync_waiter_free_(nsync::waiter*)\r\n                 U nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::WAITER_TAG\r\n000000000000000c r nsync::NSYNC_WAITER_TAG\r\n0000000000000000 W std::__atomic_base<unsigned int>::store(unsigned int, std::memory_order)\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::__atomic_base<unsigned int>::__atomic_base()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W std::atomic<unsigned int>::atomic()\r\n0000000000000000 W void std::atomic_store_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U free\r\n                 U malloc\r\n\r\ntime_rep_timespec.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000247 T nsync::nsync_time_add(timespec, timespec)\r\n0000000000000330 T nsync::nsync_time_cmp(timespec, timespec)\r\n0000000000000148 T nsync::nsync_time_now()\r\n00000000000002b8 T nsync::nsync_time_sub(timespec, timespec)\r\n0000000000000000 T nsync::nsync_time_s_ns(long, unsigned int)\r\n0000000000000020 R nsync::nsync_time_zero\r\n000000000000015b T nsync::nsync_time_sleep(timespec)\r\n00000000000000d9 T nsync::nsync_to_time_point_(timespec)\r\n000000000000003e T nsync::nsync_from_time_point_(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >)\r\n0000000000000010 R nsync::nsync_time_no_deadline\r\n0000000000000030 r __gnu_cxx::__default_lock_policy\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::time_since_epoch() const\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::count() const\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> >::count() const\r\n                 U std::this_thread::__sleep_for(std::chrono::duration<long, std::ratio<1l, 1l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> >)\r\n0000000000000000 W void std::this_thread::sleep_for<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::time_point(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::value, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::value, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::enable_if<std::chrono::__is_duration<std::chrono::duration<long, std::ratio<1l, 1l> > >::value, std::chrono::duration<long, std::ratio<1l, 1l> > >::type std::chrono::duration_cast<std::chrono::duration<long, std::ratio<1l, 1l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::ratio<1000000000l, 1l>, long, false, true>::__cast<long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::ratio<1l, 1l>, long, true, true>::__cast<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> > std::chrono::__duration_cast_impl<std::chrono::duration<long, std::ratio<1l, 1l> >, std::ratio<1l, 1000000000l>, long, true, false>::__cast<long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n                 U std::chrono::_V2::system_clock::now()\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, std::ratio<1l, 1l>, void>(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, void>(long const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1000000000l> >::duration<long, std::ratio<1l, 1l>, void>(std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W std::chrono::duration<long, std::ratio<1l, 1l> >::duration<long, void>(long const&)\r\n0000000000000000 W std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1l> > >::type std::chrono::operator-<long, std::ratio<1l, 1000000000l>, long, std::ratio<1l, 1l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&, std::chrono::duration<long, std::ratio<1l, 1l> > const&)\r\n0000000000000000 W _ZNSt6chronomiIlSt5ratioILl1ELl1000000000EElS1_ILl1ELl1EEEENSt11common_typeIJNS_8durationIT_T0_EENS5_IT1_T2_EEEE4typeERKS8_RKSB_\r\n0000000000000000 W std::chrono::time_point<std::chrono::_V2::system_clock, std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type> std::chrono::operator+<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> >, long, std::ratio<1l, 1000000000l> >(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > > const&, std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W _ZNSt6chronoplINS_3_V212system_clockENS_8durationIlSt5ratioILl1ELl1000000000EEEElS5_EENS_10time_pointIT_NSt11common_typeIJT0_NS3_IT1_T2_EEEE4typeEEERKNS7_IS8_SA_EERKSD_\r\n0000000000000000 W std::common_type<std::chrono::duration<long, std::ratio<1l, 1000000000l> >, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >::type std::chrono::operator+<long, std::ratio<1l, 1000000000l>, long, std::ratio<1l, 1000000000l> >(std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&, std::chrono::duration<long, std::ratio<1l, 1000000000l> > const&)\r\n0000000000000000 W _ZNSt6chronoplIlSt5ratioILl1ELl1000000000EElS2_EENSt11common_typeIJNS_8durationIT_T0_EENS4_IT1_T2_EEEE4typeERKS7_RKSA_\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n                 U memset\r\n\r\nnsync_panic.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n000000000000007e t _GLOBAL__sub_I_nsync_panic.cc\r\n0000000000000036 t __static_initialization_and_destruction_0(int, int)\r\n0000000000000000 T nsync::nsync_panic_(char const*)\r\n                 U std::ios_base::Init::Init()\r\n                 U std::ios_base::Init::~Init()\r\n                 U std::cerr\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 b std::__ioinit\r\n                 U std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)\r\n                 U __cxa_atexit\r\n                 U __dso_handle\r\n                 U abort\r\n\r\nyield.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n0000000000000000 T nsync::nsync_yield_()\r\n0000000000000008 r __gnu_cxx::__default_lock_policy\r\n0000000000000000 W std::this_thread::yield()\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n\r\nnsync_semaphore_futex.pic.o:\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n                 U nsync::nsync_time_cmp(timespec, timespec)\r\n                 U nsync::nsync_time_now()\r\n00000000000000d6 T nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n000000000000031b T nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n                 U nsync::nsync_time_no_deadline\r\n00000000000000ba T nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n000000000000018e T nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n0000000000000008 r nsync::assert_int_size\r\n0000000000000000 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000035 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n0000000000000000 d nsync::sem_big_enough_for_futex\r\n000000000000006a t nsync::futex(int*, int, int, timespec const*, int*, int)\r\n0000000000000000 W std::__atomic_base<unsigned int>::load(std::memory_order) const\r\n0000000000000000 W std::__atomic_base<unsigned int>::compare_exchange_strong(unsigned int&, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000000 W unsigned int std::atomic_load_explicit<unsigned int>(std::atomic<unsigned int> const*, std::memory_order)\r\n0000000000000000 W bool std::atomic_compare_exchange_strong_explicit<unsigned int>(std::atomic<unsigned int>*, unsigned int*, unsigned int, std::memory_order, std::memory_order)\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n0000000000000000 W std::operator&(std::memory_order, std::__memory_order_modifier)\r\n                 U __errno_location\r\n                 U memset\r\n                 U syscall\r\n\r\nper_thread_waiter.pic.o:\r\n0000000000000000 V DW.ref.__gxx_personality_v0\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n000000000000003c t nsync::(anonymous namespace)::per_thread::get(void (*)(void*))\r\n000000000000005e t nsync::(anonymous namespace)::per_thread::set(void*, void (*)(void*))\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 b nsync::(anonymous namespace)::thread_specific\r\n0000000000000087 T nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000000000a9 T nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n000000000000012c t _ZTWN5nsync12_GLOBAL__N_115thread_specificE\r\n                 U __cxa_thread_atexit\r\n                 U __dso_handle\r\n                 U __gxx_personality_v0\r\n                 U __tls_get_addr\r\n0000000000000010 b __tls_guard\r\n00000000000000d3 t __tls_init\r\n```\r\n\r\nThat hopefully will splice in the good stuff.\r\n\r\nOr go down in a ball of flames trying.\r\n\r\nSam\r\n", "OK so I got rid of the symbols in the big archive (libgputf.a) and made the same archive less the nsync objs and then linked against libnsync_cpp.a with the created from bazel modification you suggested.\r\n\r\nNow I get the following\r\n\r\n```\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n0x00007f182f78a5bc in ?? ()\r\n```\r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007f182f78a5bc in  ()\r\n#1  0x00007f1c432b4b19 in  () at /lib64/libstdc++.so.6\r\n#2  0x00007f1c429abb69 in __run_exit_handlers (status=0, listp=0x7f1c42d386c8 <__exit_funcs>, run_list_atexit=run_list_atexit@entry=true) at exit.c:77\r\n#3  0x00007f1c429abbb7 in __GI_exit (status=<optimized out>) at exit.c:99\r\n#4  0x000000000218b5e9 in  ()\r\n#5  0x0000000000703ce9 in  ()\r\n#6  0x000000000218a5ee in  ()\r\n#7  0x000000000218a6f1 in  ()\r\n#8  0x0000000000704358 in  ()\r\n#9  0x00000000004d9eb5 in  ()\r\n#10 0x00007f1c429943d5 in __libc_start_main (main=0x4d72c0, argc=1, argv=0x7ffdc3a40698, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7ffdc3a40688)\r\n    at ../csu/libc-start.c:266\r\n#11 0x00000000005c6ee1 in  ()\r\n```\r\nand the mystery symbol is now\r\n\r\nnsync::(anonymous namespace)::per_thread::~per_thread()\r\n\r\nWhich is always:\r\n50DE5BC offset from the start my binary rotobot.ofx\r\n\r\nSo no real change with my modifications, I think I need to recompile rather than just relink", "Here is my symbol dump if it helps at all.\r\n\r\n```\r\n(base) [kognat@vxfhost Kognat]$ nm /opt/Kognat/rotobot.ofx.bundle/Contents/Linux-x86-64/rotobot.ofx | grep nsync | c++filt\r\n00000000050dcd3e t _GLOBAL__sub_I_nsync_panic.cc\r\n00000000050de5f8 t nsync::(anonymous namespace)::per_thread::get(void (*)(void*))\r\n00000000050de61a t nsync::(anonymous namespace)::per_thread::set(void*, void (*)(void*))\r\n00000000050de5bc t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n00000000050de5bc t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n00000000000011e0 b nsync::(anonymous namespace)::thread_specific\r\n00000000050dccc0 t nsync::nsync_panic_(char const*)\r\n00000000050ddf84 t nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n00000000050de5a8 t nsync::nsync_yield_()\r\n00000000050d969b t nsync::nsync_cv_init(nsync::nsync_cv_s_*)\r\n00000000050da4a3 t nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*)\r\n00000000050daaaf t nsync::nsync_mu_init(nsync::nsync_mu_s_*)\r\n00000000050daddd t nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n00000000050ded46 t nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n00000000050daf19 t nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n00000000050dd889 t nsync::nsync_note_new(nsync::nsync_note_s_*, timespec)\r\n00000000050dca2b t nsync::nsync_time_add(timespec, timespec)\r\n00000000050dcb14 t nsync::nsync_time_cmp(timespec, timespec)\r\n00000000050dc92c t nsync::nsync_time_now()\r\n00000000050dca9c t nsync::nsync_time_sub(timespec, timespec)\r\n00000000050dbdde t nsync::nsync_waiter_s::nsync_waiter_s()\r\n00000000050dbdde t nsync::nsync_waiter_s::nsync_waiter_s()\r\n00000000050d9f43 t nsync::nsync_cv_signal(nsync::nsync_cv_s_*)\r\n00000000050da7e0 t nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n00000000050da99d t nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n00000000050da9ab t nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050da9da t nsync::nsync_dll_prev_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050db842 t nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n00000000050dda2b t nsync::nsync_note_free(nsync::nsync_note_s_*)\r\n00000000050ddcae t nsync::nsync_note_wait(nsync::nsync_note_s_*, timespec)\r\n00000000050dc7e4 t nsync::nsync_time_s_ns(long, unsigned int)\r\n00000000061dce90 r nsync::nsync_time_zero\r\n00000000050da975 t nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n00000000050db90c t nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n00000000050dad55 t nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n00000000050dc93f t nsync::nsync_time_sleep(timespec)\r\n00000000050da826 t nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dceb7 t nsync::nsync_dll_waiter_(nsync::nsync_dll_element_s_*)\r\n0000000018317628 b nsync::nsync_malloc_ptr_\r\n00000000050dae92 t nsync::nsync_mu_rtrylock(nsync::nsync_mu_s_*)\r\n00000000050ddd20 t nsync::nsync_note_expiry(nsync::nsync_note_s_*)\r\n00000000050ddc51 t nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n00000000050dcd89 t nsync::nsync_spin_delay_(unsigned int)\r\n00000000050dd019 t nsync::nsync_waiter_new_()\r\n00000000050da279 t nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n00000000050dba5f t nsync::nsync_mu_is_reader(nsync::nsync_mu_s_ const*)\r\n00000000181cf9c0 d nsync::nsync_reader_type_\r\n00000000050dd24b t nsync::nsync_waiter_free_(nsync::waiter*)\r\n00000000181cf9b8 d nsync::nsync_writer_type_\r\n00000000050da811 t nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n00000000050dab2d t nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n00000000050db9f2 t nsync::nsync_mu_assert_held(nsync::nsync_mu_s_ const*)\r\n00000000050dbf25 t nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n00000000050dc18a t nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n00000000050dc8bd t nsync::nsync_to_time_point_(timespec)\r\n00000000050dba29 t nsync::nsync_mu_rassert_held(nsync::nsync_mu_s_ const*)\r\n00000000050db31e t nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n00000000050dc822 t nsync::nsync_from_time_point_(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >)\r\n00000000050dd833 t nsync::nsync_note_is_notified(nsync::nsync_note_s_*)\r\n00000000061dce80 r nsync::nsync_time_no_deadline\r\n0000000017fb9380 d nsync::nsync_cv_waitable_funcs\r\n00000000050dce6c t nsync::nsync_dll_nsync_waiter_(nsync::nsync_dll_element_s_*)\r\n00000000050da8a2 t nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dbe9d t nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n00000000050de643 t nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000050dcdd4 t nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000017fb93a0 d nsync::nsync_note_waitable_funcs\r\n00000000050dcf2b t nsync::nsync_dll_waiter_samecond_(nsync::nsync_dll_element_s_*)\r\n00000000050da454 t nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n00000000050de928 t nsync::nsync_mu_wait_with_deadline(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*), timespec, nsync::nsync_note_s_*)\r\n00000000050db1df t nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dbaa4 t nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n00000000050da93a t nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050de665 t nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n00000000050da8f5 t nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050db08c t nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dd70a t nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n00000000050deda9 t nsync::nsync_mu_unlock_without_wakeup(nsync::nsync_mu_s_*)\r\n00000000050dbfc6 t nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n00000000050d9add t nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*)\r\n00000000050da5ca t nsync::cv_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000050da535 t nsync::cv_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000061dcca8 r nsync::WAITER_TAG\r\n00000000061dce48 r nsync::WAITER_TAG\r\n00000000061dce58 r nsync::WAITER_TAG\r\n00000000061dcebc r nsync::WAITER_TAG\r\n00000000061dcecc r nsync::WAITER_TAG\r\n00000000061dcedc r nsync::WAITER_TAG\r\n00000000061dd004 r nsync::WAITER_TAG\r\n00000000050dd396 t nsync::no_children(void const*)\r\n0000000018317630 b nsync::free_waiters\r\n00000000050dde76 t nsync::note_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000050ddd54 t nsync::note_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000050d9aa9 t nsync::void_mu_lock(void*)\r\n00000000050d96bf t nsync::wake_waiters(nsync::nsync_dll_element_s_*, int)\r\n00000000181cf9a0 d nsync::Xreader_type\r\n00000000181cf980 d nsync::Xwriter_type\r\n00000000050da4dc t nsync::cv_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000050dafcd t nsync::condition_true(nsync::nsync_dll_element_s_*)\r\n00000000050d9ac3 t nsync::void_mu_unlock(void*)\r\n00000000050dcf78 t nsync::waiter_destroy(void*)\r\n0000000018317638 b nsync::free_waiters_mu\r\n00000000050ddd36 t nsync::note_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000050dd35c t nsync::set_expiry_time(nsync::nsync_note_s_*, timespec)\r\n00000000050d9631 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050daa45 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dcd54 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050de704 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050d9666 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050daa7a t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050de739 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000061dccac r nsync::NSYNC_WAITER_TAG\r\n00000000061dce4c r nsync::NSYNC_WAITER_TAG\r\n00000000061dce5c r nsync::NSYNC_WAITER_TAG\r\n00000000061dcec0 r nsync::NSYNC_WAITER_TAG\r\n00000000061dced0 r nsync::NSYNC_WAITER_TAG\r\n00000000061dcee0 r nsync::NSYNC_WAITER_TAG\r\n00000000061dd008 r nsync::NSYNC_WAITER_TAG\r\n00000000050d95fc t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050daa10 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dd3b4 t nsync::note_notify_child(nsync::nsync_note_s_*, nsync::nsync_note_s_*)\r\n00000000000011d8 b nsync::waiter_for_thread\r\n00000000050de76e t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050daad3 t nsync::mu_release_spinlock(nsync::nsync_mu_s_*)\r\n00000000050db00b t nsync::skip_past_same_condition(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050de7a3 t nsync::mu_try_acquire_after_timeout_or_cancel(nsync::nsync_mu_s_*, nsync::lock_type_s*, nsync::waiter*, unsigned int)\r\n00000000050dd5ae t nsync::notify(nsync::nsync_note_s_*)\r\n0000000005853984 t Iex_2_2::El2nsyncExc::El2nsyncExc(std::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\r\n0000000005853984 t Iex_2_2::El2nsyncExc::El2nsyncExc(std::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\r\n00000000058539fe t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n00000000058539bc t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n00000000058539bc t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n0000000018146530 d typeinfo for Iex_2_2::El2nsyncExc\r\n00000000062dcc20 r typeinfo name for Iex_2_2::El2nsyncExc\r\n00000000181451a0 d vtable for Iex_2_2::El2nsyncExc\r\n00000000050de6e8 t TLS wrapper function for nsync::(anonymous namespace)::thread_specific\r\n```\r\n\r\nSo it is different but not solved.", "You little ripper I think I have solved it exit.c demangles before calling the destructor and there are two symbols with different addresses with the same demangled name so the exit code gets in a tangle.\r\n\r\nBut why have I got two copies of the same destructor and how can I make it go away?\r\n\r\nMore when I solve it.", "Now I need to find out why I am getting this in twice.\r\n\r\n```\r\n(base) [kognat@vxfhost Kognat]$ nm /opt/Kognat/rotobot.ofx.bundle/Contents/Linux-x86-64/rotobot.ofx | grep 00000000050de5bc\r\n00000000050de5bc t _ZN5nsync12_GLOBAL__N_110per_threadD1Ev\r\n00000000050de5bc t _ZN5nsync12_GLOBAL__N_110per_threadD2Ev\r\n```", "OK it is like that in the .o file\r\n\r\n```\r\n[samh@apollo-centos6 Rotobot-GPU-static]$ nm ~/dev/nsync/bazel-out/k8-fastbuild/bin/_objs/nsync_cpp/per_thread_waiter.pic.o | c++filt\r\n0000000000000000 V DW.ref.__gxx_personality_v0\r\n                 U _GLOBAL_OFFSET_TABLE_\r\n000000000000003c t nsync::(anonymous namespace)::per_thread::get(void (*)(void*))\r\n000000000000005e t nsync::(anonymous namespace)::per_thread::set(void*, void (*)(void*))\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 t nsync::(anonymous namespace)::per_thread::~per_thread()\r\n0000000000000000 b nsync::(anonymous namespace)::thread_specific\r\n0000000000000087 T nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000000000a9 T nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n0000000000000005 r std::adopt_lock\r\n0000000000000003 r std::defer_lock\r\n0000000000000004 r std::try_to_lock\r\n0000000000000001 r std::allocator_arg\r\n0000000000000000 r std::piecewise_construct\r\n0000000000000002 r std::ignore\r\n000000000000012c t _ZTWN5nsync12_GLOBAL__N_115thread_specificE\r\n                 U __cxa_thread_atexit\r\n                 U __dso_handle\r\n                 U __gxx_personality_v0\r\n                 U __tls_get_addr\r\n0000000000000010 b __tls_guard\r\n00000000000000d3 t __tls_init\r\n\r\n```", "Looks like I am clumsy I edited the wrong BUILD file for bazel.", "Now the crash symbols are gone we will see what happens\r\n\r\n```\r\n[samh@apollo-centos6 Rotobot-GPU-static]$ nm Linux-64-debug/rotobot.ofx.bundle/Contents/Linux-x86-64/rotobot.ofx  | c++filt | grep nsync\r\n00000000050dc4e6 t _GLOBAL__sub_I_nsync_panic.cc\r\n00000000050dc468 t nsync::nsync_panic_(char const*)\r\n00000000050ddacc t nsync::nsync_wait_n(void*, void (*)(void*), void (*)(void*), timespec, int, nsync::nsync_waitable_s**)\r\n00000000050de0f0 t nsync::nsync_yield_()\r\n00000000050d95fb t nsync::nsync_cv_init(nsync::nsync_cv_s_*)\r\n00000000050da403 t nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*)\r\n00000000050daa0f t nsync::nsync_mu_init(nsync::nsync_mu_s_*)\r\n00000000050dad3d t nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\r\n00000000050de8ea t nsync::nsync_mu_wait(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*))\r\n00000000050dae79 t nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\r\n00000000050dd3d1 t nsync::nsync_note_new(nsync::nsync_note_s_*, timespec)\r\n00000000050dbfa3 t nsync::nsync_time_add(timespec, timespec)\r\n00000000050dc08c t nsync::nsync_time_cmp(timespec, timespec)\r\n00000000050dbea4 t nsync::nsync_time_now()\r\n00000000050dc014 t nsync::nsync_time_sub(timespec, timespec)\r\n00000000050dbd3e t nsync::nsync_waiter_s::nsync_waiter_s()\r\n00000000050dbd3e t nsync::nsync_waiter_s::nsync_waiter_s()\r\n00000000050d9ea3 t nsync::nsync_cv_signal(nsync::nsync_cv_s_*)\r\n00000000050da740 t nsync::nsync_dll_init_(nsync::nsync_dll_element_s_*, void*)\r\n00000000050da8fd t nsync::nsync_dll_last_(nsync::nsync_dll_element_s_*)\r\n00000000050da90b t nsync::nsync_dll_next_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050da93a t nsync::nsync_dll_prev_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050db7a2 t nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\r\n00000000050dd573 t nsync::nsync_note_free(nsync::nsync_note_s_*)\r\n00000000050dd7f6 t nsync::nsync_note_wait(nsync::nsync_note_s_*, timespec)\r\n00000000050dbd5c t nsync::nsync_time_s_ns(long, unsigned int)\r\n00000000061dca20 r nsync::nsync_time_zero\r\n00000000050da8d5 t nsync::nsync_dll_first_(nsync::nsync_dll_element_s_*)\r\n00000000050db86c t nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\r\n00000000050dacb5 t nsync::nsync_mu_trylock(nsync::nsync_mu_s_*)\r\n00000000050dbeb7 t nsync::nsync_time_sleep(timespec)\r\n00000000050da786 t nsync::nsync_dll_remove_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dc9ff t nsync::nsync_dll_waiter_(nsync::nsync_dll_element_s_*)\r\n00000000183165e8 b nsync::nsync_malloc_ptr_\r\n00000000050dadf2 t nsync::nsync_mu_rtrylock(nsync::nsync_mu_s_*)\r\n00000000050dd868 t nsync::nsync_note_expiry(nsync::nsync_note_s_*)\r\n00000000050dd799 t nsync::nsync_note_notify(nsync::nsync_note_s_*)\r\n00000000050dc8d1 t nsync::nsync_spin_delay_(unsigned int)\r\n00000000050dcb61 t nsync::nsync_waiter_new_()\r\n00000000050da1d9 t nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\r\n00000000050db9bf t nsync::nsync_mu_is_reader(nsync::nsync_mu_s_ const*)\r\n00000000181ce9a0 d nsync::nsync_reader_type_\r\n00000000050dcd93 t nsync::nsync_waiter_free_(nsync::waiter*)\r\n00000000181ce998 d nsync::nsync_writer_type_\r\n00000000050da771 t nsync::nsync_dll_is_empty_(nsync::nsync_dll_element_s_*)\r\n00000000050daa8d t nsync::nsync_mu_lock_slow_(nsync::nsync_mu_s_*, nsync::waiter*, unsigned int, nsync::lock_type_s*)\r\n00000000050db952 t nsync::nsync_mu_assert_held(nsync::nsync_mu_s_ const*)\r\n00000000050dc5d2 t nsync::nsync_mu_semaphore_p(nsync::nsync_semaphore_s_*)\r\n00000000050dc817 t nsync::nsync_mu_semaphore_v(nsync::nsync_semaphore_s_*)\r\n00000000050dbe35 t nsync::nsync_to_time_point_(timespec)\r\n00000000050db989 t nsync::nsync_mu_rassert_held(nsync::nsync_mu_s_ const*)\r\n00000000050db27e t nsync::nsync_mu_unlock_slow_(nsync::nsync_mu_s_*, nsync::lock_type_s*)\r\n00000000050dbd9a t nsync::nsync_from_time_point_(std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long, std::ratio<1l, 1000000000l> > >)\r\n00000000050dd37b t nsync::nsync_note_is_notified(nsync::nsync_note_s_*)\r\n00000000061dca10 r nsync::nsync_time_no_deadline\r\n0000000017fb8380 d nsync::nsync_cv_waitable_funcs\r\n00000000050dc9b4 t nsync::nsync_dll_nsync_waiter_(nsync::nsync_dll_element_s_*)\r\n00000000050da802 t nsync::nsync_dll_splice_after_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dc5b6 t nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*)\r\n00000000050de200 t nsync::nsync_per_thread_waiter_(void (*)(void*))\r\n00000000050dc91c t nsync::nsync_spin_test_and_set_(std::atomic<unsigned int>*, unsigned int, unsigned int, unsigned int)\r\n0000000017fb83a0 d nsync::nsync_note_waitable_funcs\r\n00000000050dca73 t nsync::nsync_dll_waiter_samecond_(nsync::nsync_dll_element_s_*)\r\n00000000050da3b4 t nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\r\n00000000050de4cc t nsync::nsync_mu_wait_with_deadline(nsync::nsync_mu_s_*, int (*)(void const*), void const*, int (*)(void const*, void const*), timespec, nsync::nsync_note_s_*)\r\n00000000050db13f t nsync::nsync_remove_from_mu_queue_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dba04 t nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*)\r\n00000000050da89a t nsync::nsync_dll_make_last_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050de22e t nsync::nsync_set_per_thread_waiter_(void*, void (*)(void*))\r\n00000000050da855 t nsync::nsync_dll_make_first_in_list_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dafec t nsync::nsync_maybe_merge_conditions_(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050dd252 t nsync::nsync_note_notified_deadline_(nsync::nsync_note_s_*)\r\n00000000050de94d t nsync::nsync_mu_unlock_without_wakeup(nsync::nsync_mu_s_*)\r\n00000000050dc68a t nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec)\r\n00000000050d9a3d t nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*)\r\n00000000061dc848 r nsync::WAITER_TAG\r\n00000000061dc9e8 r nsync::WAITER_TAG\r\n00000000061dc9f8 r nsync::WAITER_TAG\r\n00000000061dca58 r nsync::WAITER_TAG\r\n00000000061dca68 r nsync::WAITER_TAG\r\n00000000061dca78 r nsync::WAITER_TAG\r\n00000000061dcba4 r nsync::WAITER_TAG\r\n00000000050da52a t nsync::cv_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000050da495 t nsync::cv_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000183165fc b nsync::waiter_key\r\n00000000050dcede t nsync::no_children(void const*)\r\n00000000181ce980 d nsync::Xreader_type\r\n00000000181ce960 d nsync::Xwriter_type\r\n00000000183165f0 b nsync::free_waiters\r\n00000000050dd9be t nsync::note_dequeue(void*, nsync::nsync_waiter_s*)\r\n00000000050dd89c t nsync::note_enqueue(void*, nsync::nsync_waiter_s*)\r\n00000000050d9a09 t nsync::void_mu_lock(void*)\r\n00000000050d961f t nsync::wake_waiters(nsync::nsync_dll_element_s_*, int)\r\n00000000050da43c t nsync::cv_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000050daf2d t nsync::condition_true(nsync::nsync_dll_element_s_*)\r\n00000000050d9a23 t nsync::void_mu_unlock(void*)\r\n00000000050dcac0 t nsync::waiter_destroy(void*)\r\n00000000061dca4c r nsync::assert_int_size\r\n00000000183165f8 b nsync::free_waiters_mu\r\n00000000050dd87e t nsync::note_ready_time(void*, nsync::nsync_waiter_s*)\r\n00000000050dcea4 t nsync::set_expiry_time(nsync::nsync_note_s_*, timespec)\r\n00000000061dc84c r nsync::NSYNC_WAITER_TAG\r\n00000000061dc9ec r nsync::NSYNC_WAITER_TAG\r\n00000000061dc9fc r nsync::NSYNC_WAITER_TAG\r\n00000000061dca5c r nsync::NSYNC_WAITER_TAG\r\n00000000061dca6c r nsync::NSYNC_WAITER_TAG\r\n00000000061dca7c r nsync::NSYNC_WAITER_TAG\r\n00000000061dcba8 r nsync::NSYNC_WAITER_TAG\r\n00000000050d9591 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050da9a5 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dc4fc t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dc89c t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050de104 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050de2a8 t nsync::atm_cas_acq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050d95c6 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050da9da t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dc531 t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050de2dd t nsync::atm_cas_rel_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050d955c t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050da970 t nsync::atm_cas_nomb_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050dcefc t nsync::note_notify_child(nsync::nsync_note_s_*, nsync::nsync_note_s_*)\r\n00000000000011d8 b nsync::waiter_for_thread\r\n00000000050de312 t nsync::atm_cas_relacq_u32_(std::atomic<unsigned int>*, unsigned int, unsigned int)\r\n00000000050daa33 t nsync::mu_release_spinlock(nsync::nsync_mu_s_*)\r\n00000000181ce958 d nsync::sem_big_enough_for_futex\r\n00000000050daf6b t nsync::skip_past_same_condition(nsync::nsync_dll_element_s_*, nsync::nsync_dll_element_s_*)\r\n00000000050de347 t nsync::mu_try_acquire_after_timeout_or_cancel(nsync::nsync_mu_s_*, nsync::lock_type_s*, nsync::waiter*, unsigned int)\r\n00000000050dc566 t nsync::futex(int*, int, int, timespec const*, int*, int)\r\n00000000050dd0f6 t nsync::notify(nsync::nsync_note_s_*)\r\n00000000050de139 t nsync::do_once(std::atomic<unsigned int>*, void (*)(void*))\r\n0000000018316600 b nsync::pt_once\r\n0000000005853524 t Iex_2_2::El2nsyncExc::El2nsyncExc(std::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\r\n0000000005853524 t Iex_2_2::El2nsyncExc::El2nsyncExc(std::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\r\n000000000585359e t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n000000000585355c t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n000000000585355c t Iex_2_2::El2nsyncExc::~El2nsyncExc()\r\n0000000018145530 d typeinfo for Iex_2_2::El2nsyncExc\r\n00000000062dc7c0 r typeinfo name for Iex_2_2::El2nsyncExc\r\n00000000181441a0 d vtable for Iex_2_2::El2nsyncExc\r\n```", "BOOM!\r\n```\r\n[Inferior 1 (process 7903) exited normally]\r\n```\r\n\r\nThis issue has been hanging around my neck like a lead weight for at least six weeks thanks for your immediate solution.", "I'm glad that fixed it.\r\n\r\nI will work on getting that into a release of nsync, and then of TensorFlow.\r\n\r\nWe'll also need to look into the issue of nsync being linked into multiple \r\nshared libraries.  That's not so much because we can't make nsync workl like that,\r\nbut if it[s happening to nsync, it's probavbly happening to other things that might \r\ncause similar problems in the future.", "@m3bm3b\r\n\r\nDo you think the same demangled symbol name for the two symbols for the destructor is the root cause of the crash?\r\n\r\nFor me I am happy with the work around, my build system is so rough another shim doesn\u2019t matter.\r\n\r\nBut my next goal is to sure everything up and at least encapsulate all of the shims.\r\n\r\nSam", "> Do you think the same demangled symbol name for the two symbols \r\n> for the destructor is the root cause of the crash?\r\n\r\nI do not know the precise cause, but it seems likely that the double-linking of that\r\nmodule caused the problems.\r\nFor example, perhaps the same thread_local variable was destructed twice: \r\nonce by one shared library, and once by another.   \r\n\r\nI'm unsure how to verify the precise cause\r\nwithout single-stepping through the exit() handling.   \r\nIt's also possible that the bevaviour will vary from platform\r\nto platform, since this likely depends on eactly how the linker\r\nand dynamic linker interact with the C++ runtime handling of \r\nthread_local destructors.\r\n\r\nThe C++11 spec for the handling of destructors at exit()\r\nis so thread-hostile that I suspect my best approach on most platforms\r\nis to avoid using C++11's thread_local.  For Windows, where it's messy to\r\navoid thread_local, I shall add a few lines of defensive\r\ncode in the hope of tolerating multiple calls to the destructor.\r\n\r\n\r\n", "So sorry, I didn\u2019t mean to spoil your Sunday.\r\n\r\nThanks for all your help, it is an honour to have someone with as many accolades as yourself to help with my scruffy application.", "Thanks a lot for your help, @m3bm3b!\r\n\r\n@samhodge, this looks fixed--can the issue be closed?", "I think the workaround is OK.", "This should now be fixed at TensorFlow head."]}, {"number": 31300, "title": "Problem when saving/loading keras model with '.tf' extension and stateful ConvLSTM2D as a layer", "body": "**System information**\r\n- WSL Win10 Ubuntu 18.04 (it also happens in a real ubuntu 18)\r\n- tf-nightly-gpu-2.0-preview==2.0.0.dev20190802 (happens in cpu and gpu)\r\n- python3.7\r\n\r\n**Describe the current behavior**\r\n\r\nI have a simple test to serialized and deserialize a model which has a stateful LSTM. The 'tf' version returns an error, the 'h5' version works ok.\r\n\r\n**Describe the expected behavior**\r\n\r\nCorrect serialization and deserialization of the code in both cases.\r\n\r\n**Code  to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.ConvLSTM2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(1, 28, 28, 1), padding='same', strides=2,\r\n                            stateful=True))\r\nmodel.add(layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\nmodel.compile(optimizer='adam', loss=['mse'])\r\nmodel.save('teste.tf')\r\nmodel = tf.keras.models.load_model('teste.tf')\r\nprint(model)\r\n```\r\n\r\n```python\r\n2019-08-03 04:32:09.606349: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 04:32:09.606533: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 04:32:09.606718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 04:32:09.607091: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 04:32:09.616262: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 04:32:09.617989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffff2cf88d0 executing computations on platform Host. Devices:\r\n2019-08-03 04:32:09.618144: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0803 04:32:10.136887 140094640752448 save.py:130] Skipping full serialization of object <tensorflow.python.keras.layers.convolutional_recurrent.ConvLSTM2D object at 0x7f69f49960f0>, because an error occurred while tracing layer functions. Error message: Expected Operation, Variable, or Tensor, got None\r\n2019-08-03 04:32:10.714903: W tensorflow/python/util/util.cc:288] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nW0803 04:32:10.904490 140094640752448 deprecation.py:506] From /home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1784: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\", line 21, in <module>\r\n    model.save('teste.tf')\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1164, in save\r\n    saving.save_model(self, filepath, overwrite, include_optimizer, save_format)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 107, in save_model\r\n    saved_model_save.save(model, filepath, overwrite, include_optimizer)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 86, in save\r\n    save_lib.save(model, filepath)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 855, in save\r\n    meta_graph_def, saveable_view, signatures)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 585, in _fill_meta_graph_def\r\n    signatures = _generate_signatures(signature_functions, resource_map)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 459, in _generate_signatures\r\n    function, mapped_inputs, resource_map)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 411, in _call_function_with_mapped_captures\r\n    function.graph.captures, resource_map)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 333, in _map_captures_to_created_tensors\r\n    .format(interior))\r\nAssertionError: Tried to export a function which references untracked object Tensor(\"StatefulPartitionedCall/args_4:0\", shape=(), dtype=resource).TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n**Working code  for comparisons**\r\n\r\nWhen not stateful, the code works ok\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.ConvLSTM2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(1, 28, 28, 1), padding='same', strides=2))\r\nmodel.add(layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\nmodel.compile(optimizer='adam', loss=['mse'])\r\nmodel.save('teste.tf')\r\nmodel = tf.keras.models.load_model('teste.tf')\r\nprint(model)\r\n```\r\n\r\n```python\r\n2019-08-03 04:36:08.915912: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 04:36:08.916094: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 04:36:08.916278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 04:36:08.916617: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 04:36:08.925594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 04:36:08.927217: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffe038cb10 executing computations on platform Host. Devices:\r\n2019-08-03 04:36:08.927361: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-08-03 04:36:10.081493: W tensorflow/python/util/util.cc:288] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0803 04:36:10.614284 140013092800320 deprecation.py:506] From /home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1784: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n<tensorflow.python.keras.saving.saved_model.load.Sequential object at 0x7f56a80c2cf8>\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\n** Working code 2 for comparisons**\r\n\r\nWhen 'h5' works ok in both cases\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.ConvLSTM2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(1, 28, 28, 1), padding='same', strides=2))\r\nmodel.add(layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\nmodel.compile(optimizer='adam', loss=['mse'])\r\nmodel.save('teste.h5')\r\nmodel = tf.keras.models.load_model('teste.h5')\r\nprint(model)\r\n```\r\n\r\n```python\r\n2019-08-03 04:37:27.733190: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 04:37:27.733380: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 04:37:27.733531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 04:37:27.733891: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 04:37:27.743100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 04:37:27.745015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffd380cc50 executing computations on platform Host. Devices:\r\n2019-08-03 04:37:27.745198: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f32b028f550>\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers, models\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.ConvLSTM2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(1, 28, 28, 1), padding='same', strides=2,\r\n                            stateful=True))\r\nmodel.add(layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\nmodel.compile(optimizer='adam', loss=['mse'])\r\nmodel.save('teste.h5')\r\nmodel = tf.keras.models.load_model('teste.h5')\r\nprint(model)\r\n```\r\n\r\n```python\r\n2019-08-03 04:37:48.546310: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 04:37:48.546554: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 04:37:48.546700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 04:37:48.547055: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 04:37:48.556123: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 04:37:48.557773: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffcde1a9a0 executing computations on platform Host. Devices:\r\n2019-08-03 04:37:48.557917: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f091c0ac860>\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\n", "comments": ["I am able to reproduce the issue on Colab with tf-nightly-gpu-2.0-preview==2.0.0.dev20190802. Please take a look at [Colab](https://colab.research.google.com/drive/1QbZwhKN62RicooTE2CAzoDMmuOgWCPLk). Thanks!", "Assign to Kathy who works on save model.", "@nguerinjr  Looks like this was resolved in recent `tf-nightly`. I was not able to reproduce the issue. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/386c2ee4d3b2ec7268bc8f576f2e7b56/31300.ipynb).\r\n\r\nPlease close the issue if it was resolved for you. Thanks!", "Closing this as this issue has been fixed. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31300\">No</a>\n", "I have noticed the same problem on stable tensorflow 2.1.\r\nIs there a regression test for this ? Does it pass ?\r\n\r\nMaybe we need to reopen this issue.", "I also have a similar issue on 2.2 with saving/loading models with stateful GRU layers in TF format. \r\n\r\nI think the issue should be reopened."]}, {"number": 31299, "title": "Lower performance when use multi gpu", "body": "**System information**\r\n-Windows 10 1903 workstation x64\r\n-ASRock X570 Taichi\r\n-AMD Ryzen 3700x\r\n-Corsair 8GB LPX 3000MHz RAM x4 (32GB Tot.)\r\n-GIGABYTE RTX 2080ti Turbo 11G x2 (with out nvlink)\r\n-SAMSUNG PM981 256GB NVMe SSD For System and DataSet\r\n-Cuda 10.0.130, cuDNN 7.6.0\r\n-python 3.7.4 x64\r\n\r\n\r\n**Describe the current behavior**\r\nWhen I use three examples from doc about train keras model with multi gpus, it used more time than single gpu.\r\nShould I buy a NVLink or change the code.\r\nOn example please if need change the code.\r\n\r\n**Code**\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom DataSets import Imagenet\r\nfrom Models import efficientnet\r\n\r\ntf_config = tf.ConfigProto()\r\ntf_config.gpu_options.allow_growth = True\r\nwith tf.Session(config=tf_config) as sess:\r\n    model = efficientnet.efficientnet_b7(1000)\r\n    model.summary()\r\n    model.load_weights('/Models/efficientnet_b7')\r\n    model = tf.keras.utils.multi_gpu_model(model,2, cpu_merge=False)\r\n    model.compile('sgd', 'sparse_categorical_crossentropy', ['accuracy'])\r\n    train_ds, test_ds = Imagenet.classification_dataset(6,100,True,[224,224,3])\r\n    while True:\r\n        model.fit(train_ds,\r\n                  epochs=int(Imagenet.train_images/50000),\r\n                  steps_per_epoch=10000,\r\n                  callbacks=[tf.keras.callbacks.ModelCheckpoint('/Models/efficientnet_b7','loss',save_best_only=True,save_weights_only=True,mode='min')])\r\n        model.evaluate(test_ds,steps=int(Imagenet.test_images/5))\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> 2019-08-03 12:25:38.658805: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n> 2019-08-03 12:25:38.665648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\r\n> 2019-08-03 12:25:39.153806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\n> name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\r\n> pciBusID: 0000:0e:00.0\r\n> 2019-08-03 12:25:39.158542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\n> name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\r\n> pciBusID: 0000:0f:00.0\r\n> 2019-08-03 12:25:39.171135: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n> 2019-08-03 12:25:39.174610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1\r\n> 2019-08-03 12:25:40.496910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-08-03 12:25:40.500248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1\r\n> 2019-08-03 12:25:40.501954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N\r\n> 2019-08-03 12:25:40.503661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N\r\n> 2019-08-03 12:25:40.506310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8694 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:0e:00.0, compute capability: 7.5)\r\n> 2019-08-03 12:25:40.522921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8695 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:0f:00.0, compute capability: 7.5)", "comments": ["Some details:\r\n-When use mult_gpu_mode, the dataset batch doesn't distribute to two cards. The warning info shows it just copy one to another.\r\n-In mult_gpu_mode, gpu0 cudas use about 50% and 7% to gpu1. When use single card it used about 97%.", "`multi_gpu_mode` is slow on multiple GPUs -- just avoid using it for multi-GPU training.\r\nYou can see at [here](https://github.com/tensorpack/benchmarks/tree/master/other-wrappers) how much speedup you can get by implementing multiple GPU training in a more efficient way.", "> multi_gpu_mode is slow on multiple GPUs -- just avoid using it for multi-GPU training.\r\n> You can see at here how much speedup you can get by implementing multiple GPU training in a more efficient way.\r\n\r\n### **Thanks, but it didn't solve the problem.**\r\n### **Here are the warning**\r\n\r\n### Single GPU\r\n> 2019-08-04 10:38:50.586762: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.591843: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.663687: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.668414: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.682640: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.687666: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.700564: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.706184: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.801138: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:38:50.806526: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n>    27/10000 [..............................] - ETA: 2:41:29 - loss: 6.8965 - acc: 0.1815Traceback (most recent call last):\r\n\r\n### Multi:\r\n\r\n> W0804 10:39:48.921536  5668 deprecation.py:323] From C:\\Users\\HLSS\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> 2019-08-04 10:40:36.255884: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.262362: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.269665: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.278412: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.295469: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.302160: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.308701: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.315426: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.351322: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> 2019-08-04 10:40:36.357775: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n>     9/10000 [..............................] - ETA: 18:53:10 - loss: 5.5566 - acc: 0.4889Traceback (most recent call last):", "@HLSS-Hen ,\r\nCan you please provide below details.\r\n\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n\r\nThanks!", "@HLSS-Hen ,\r\nCan you please let us know the Version of Tensorflow you are using so that we can reproduce the issue and can work towards its resolution.", "@rmothukuru \r\ninstalled from pip (alliyun source)\r\nversion:1.14.0", "@rmothukuru @ppwwyyxx \r\nI bought a nvlink and use `tf.distribute`.\r\nNow I get recently double performance(it just about 160% performance without nvlink). \r\n\r\nCodes:\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom DataSets import CIFAR100\r\nfrom Models import efficientnet\r\n\r\nstrategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\nwith strategy.scope():\r\n    tf_config = tf.ConfigProto()\r\n    tf_config.gpu_options.allow_growth = True\r\n    with tf.Session(config=tf_config) as sess:\r\n        model =efficientnet.efficientnet_b7(1000)\r\n        model.summary()\r\n        model.compile(tf.keras.optimizers.Adam(), \r\n                      tf.keras.losses.SparseCategoricalCrossentropy(),\r\n                      [tf.keras.metrics.SparseTopKCategoricalAccuracy(1, 'top1'), tf.keras.metrics.SparseTopKCategoricalAccuracy(5, 'top5')])\r\n        train_ds, test_ds = CIFAR100.Basic_Dataset(10, 100, [224, 224, 3])\r\n        while True:\r\n            model.fit(train_ds,\r\n                      epochs=1000,\r\n                      steps_per_epoch=int(CIFAR100.train_images/10),\r\n                      validation_data=test_ds,\r\n                      validation_steps=int(CIFAR100.test_images/10),\r\n                      callbacks=[tf.keras.callbacks.ModelCheckpoint('/Models/efficientnet_b7', save_best_only=True,save_weights_only=True)])\r\n```\r\n", "I'm the wrong person to own this bug. Tentatively assigning the bug to @guptapriya, who leads tf.distribute.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31299\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31299\">No</a>\n"]}, {"number": 31298, "title": "Serialization problems in keras when using add_loss or '.tf' extension for saving", "body": "**System information**\r\n- WSL Win10 Ubuntu 18.04 (it also happens in a real ubuntu 18)\r\n- tf-nightly-gpu-2.0-preview==2.0.0.dev20190802 (happens in cpu and gpu)\r\n- python3.7\r\n\r\n**Describe the current behavior**\r\n\r\nI have a simple test to serialized and deserialize a model which has no compiled loss, just one added with add_loss.\r\n\r\n**Describe the expected behavior**\r\n\r\nCorrect serialization and deserialization of the code\r\n\r\n**Code 1 to reproduce the issue**\r\n\r\nOccurs with both the pure loss function (which on earlier version would return json errors, but now seems ok), but also with the Lambda wrapper.\r\n\r\n``` python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tf_k\r\n\r\nmodel = tf_k.models.Sequential()\r\nmodel.add(tf_k.layers.Conv2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(28, 28, 1), padding='same', strides=2))\r\nmodel.add(tf_k.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(tf_k.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\n#loss = tf_k.layers.Lambda(lambda i: tf_k.losses.mse(*i))([model.inputs[0], model.outputs[0]])\r\nloss = tf_k.losses.mean_squared_error(model.inputs[0], tf.zeros_like(model.inputs[0]))\r\nmodel.add_loss(loss)\r\nmodel.compile(optimizer='adam')\r\nmodel.save('teste.h5')\r\nmodel = tf.keras.models.load_model('teste.h5')\r\n```\r\n\r\n```python\r\n2019-08-03 03:38:05.624310: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 03:38:05.624506: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 03:38:05.624652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 03:38:05.624991: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 03:38:05.634458: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 03:38:05.636116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffe06c0120 executing computations on platform Host. Devices:\r\n2019-08-03 03:38:05.636259: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0803 03:38:05.683956 139979377280832 training_utils.py:1320] Output conv2d_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to conv2d_1.\r\nTraceback (most recent call last):\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1554, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 1 inputs specified of 2 inputs in Op while building NodeDef 'tf_op_layer_SquaredDifference/SquaredDifference' using Op<name=SquaredDifference; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\", line 14, in <module>\r\n    model = tf.keras.models.load_model('teste.h5')\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 138, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 162, in load_model_from_hdf5\r\n    custom_objects=custom_objects)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 55, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 98, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 191, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\", line 369, in from_config\r\n    model.add(layer)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\", line 195, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 799, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2507, in call\r\n    return self._make_op(inputs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2530, in _make_op\r\n    c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1557, in _create_c_op\r\n    raise ValueError(str(e))\r\nValueError: 1 inputs specified of 2 inputs in Op while building NodeDef 'tf_op_layer_SquaredDifference/SquaredDifference' using Op<name=SquaredDifference; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true>\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n**Code 2 to reproduce the issue**\r\n\r\nPutting the '.tf' suffix, only changes the error message. Here's an example\r\n\r\n``` python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tf_k\r\n\r\nmodel = tf_k.models.Sequential()\r\nmodel.add(tf_k.layers.Conv2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(28, 28, 1), padding='same', strides=2))\r\nmodel.add(tf_k.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(tf_k.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\n\r\n#loss = tf_k.layers.Lambda(lambda i: tf_k.losses.mse(*i))([model.inputs[0], model.outputs[0]])\r\nloss = tf_k.losses.mean_squared_error(model.inputs[0], tf.zeros_like(model.inputs[0]))\r\nmodel.add_loss(loss)\r\nmodel.compile(optimizer='adam')\r\nmodel.save('teste.tf')\r\nmodel = tf.keras.models.load_model('teste.tf')\r\n```\r\n\r\n```python\r\n2019-08-03 03:38:42.774544: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 03:38:42.774737: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 03:38:42.774932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 03:38:42.775273: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 03:38:42.784443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 03:38:42.786142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffc04e4040 executing computations on platform Host. Devices:\r\n2019-08-03 03:38:42.786289: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0803 03:38:42.835703 140157751789376 training_utils.py:1320] Output conv2d_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to conv2d_1.\r\n2019-08-03 03:38:43.281262: W tensorflow/python/util/util.cc:288] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nW0803 03:38:43.369712 140157751789376 deprecation.py:506] From /home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1784: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\", line 14, in <module>\r\n    model = tf.keras.models.load_model('teste.tf')\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 142, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 86, in load\r\n    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py\", line 541, in load_internal\r\n    export_dir)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 103, in __init__\r\n    self._finalize()\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 127, in _finalize\r\n    node.add(layer)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\", line 195, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 799, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\", line 57, in return_outputs_and_add_losses\r\n    outputs, losses = fn(inputs, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 382, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1806, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2106, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1997, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 884, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 325, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py\", line 262, in restored_function_body\r\n    \"\\n\\n\".join(signature_descriptions)))\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * Tensor(\"inputs:0\", shape=(32, 28, 28, 1), dtype=float32)\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 1 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (1 total):\r\n    * [TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs/0')]\r\n  Keyword arguments: {}\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n> Is there something wrong with this simple example? Something I'm missing. Or it's just that the add_loss still have some problems wrt serialization / deserialization?\r\n\r\nI perceived a bunch of errors have been fixed since my last report about this custom uses of keras (https://github.com/tensorflow/tensorflow/issues/30378). For example, I know a workaround for this, which seems ok in this nightly version, is to use a custom compiled loss, which was not working at that time, as another issue I had reported  (https://github.com/tensorflow/tensorflow/issues/30384)\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tf_k\r\n\r\nmodel = tf_k.models.Sequential()\r\nmodel.add(tf_k.layers.Conv2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(28, 28, 1), padding='same', strides=2))\r\nmodel.add(tf_k.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(tf_k.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\n\r\ndef my_loss(y_true, y_pred):\r\n    return y_true\r\n\r\ndef my_loss2(y_true, y_pred):\r\n    return y_pred\r\n\r\nmodel.compile(optimizer='adam', loss=[my_loss])\r\nmodel.save('teste.h5')\r\n\r\nmodel = tf.keras.models.load_model('teste.h5', custom_objects={'my_loss': my_loss, 'my_loss2': my_loss2})\r\nprint(model)\r\n```\r\n\r\n```python\r\n/home/nguerinjr/Documents/deep_coding_project/venv/bin/python /home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\r\n2019-08-03 03:46:57.744222: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 03:46:57.744406: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 03:46:57.744557: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 03:46:57.744891: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 03:46:57.755141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 03:46:57.756825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffea867eb0 executing computations on platform Host. Devices:\r\n2019-08-03 03:46:57.757004: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4e203ee940>\r\n\r\nProcess finished with exit code 0\r\n```\r\n\r\nBut, as an extension to these tests, I've noticed the '.tf' version does not work correctly, which seems another related bug:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tf_k\r\n\r\nmodel = tf_k.models.Sequential()\r\nmodel.add(tf_k.layers.Conv2D(32, (3, 3), activation='relu', batch_size=32, input_shape=(28, 28, 1), padding='same', strides=2))\r\nmodel.add(tf_k.layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same'))\r\nmodel.add(tf_k.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\r\n\r\ndef my_loss(y_true, y_pred):\r\n    return y_true\r\n\r\ndef my_loss2(y_true, y_pred):\r\n    return y_pred\r\n\r\nmodel.compile(optimizer='adam', loss=[my_loss])\r\nmodel.save('teste.tf')\r\n\r\nmodel = tf.keras.models.load_model('teste.tf', custom_objects={'my_loss': my_loss, 'my_loss2': my_loss2})\r\nprint(model)\r\n```\r\n\r\n```python\r\n/home/nguerinjr/Documents/deep_coding_project/venv/bin/python /home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\r\n2019-08-03 03:47:16.464514: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-08-03 03:47:16.464702: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-08-03 03:47:16.464859: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GUERINJR): /proc/driver/nvidia/version does not exist\r\n2019-08-03 03:47:16.465200: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-08-03 03:47:16.474429: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-08-03 03:47:16.476021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffbb87a7b0 executing computations on platform Host. Devices:\r\n2019-08-03 03:47:16.476185: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-08-03 03:47:16.873280: W tensorflow/python/util/util.cc:288] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0803 03:47:16.921350 140320731367232 deprecation.py:506] From /home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1784: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/img_common/teste.py\", line 25, in <module>\r\n    model = tf.keras.models.load_model('teste.tf', custom_objects={'my_loss': my_loss, 'my_loss2': my_loss2})\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 142, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 93, in load\r\n    model._training_config))  # pylint: disable=protected-access\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 340, in compile\r\n    self.loss, self.output_names)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 1329, in prepare_loss_functions\r\n    loss_functions = nest.map_structure(get_loss_function, loss)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 523, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 523, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 1086, in get_loss_function\r\n    loss_fn = losses.get(loss)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 1166, in get\r\n    return deserialize(identifier)\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 1157, in deserialize\r\n    printable_module_name='loss function')\r\n  File \"/home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 210, in deserialize_keras_object\r\n    raise ValueError('Unknown ' + printable_module_name + ':' + object_name)\r\nValueError: Unknown loss function:my_loss\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nThe real point about my interest in the add_loss it that's the only way, at least I think, to use losses in a flexible way. I still need very flexible losses. add_loss seems an interesting way to do this.", "comments": ["@nguerinjr \r\nCan you please check with the nightly version ```pip install tf-nightly-2.0-preview``` and see if the problem still persists.\r\nThanks!", "@ravikyram \r\n\r\nYes. All problems occur exactly the same way in version installed with `pip3 install tf-nightly-2.0-preview` which is, today, 2.0.0.dev20190808", "I have tried on colab with TF version nightly versions 2.0.0.dev20190802  , 2.0.0.dev20190808 and was able to reproduce the issue.Please, find the [gist](https://colab.research.google.com/drive/1wvHL89WOQOecyY42lxfKDrueo2Jg3dyn) here. Thanks!", "@nguerinjr,\r\nTwo of the code samples which you have provided work without any issues with the latest TF-nightly i.e. TF v2.2.0-dev20200416. \r\n\r\nFor the first two samples, I'm facing an error stating `IndexError: list index out of range`.\r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/34a61b44d8345cfa53d720e268bf9b2e/31298-tf-nightly.ipynb#scrollTo=hDtMnuD42hsu). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@nguerinjr,\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31298\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31298\">No</a>\n"]}, {"number": 31297, "title": "tf.gradients with unconnected_gradients=\"zero\" returns wrong shape for unconnected resource variables", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 5.2.1-arch1-1-ARCH x86_64\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nCalling `tf.gradients` with `unconnected_gradients=\"zero\"` returns scalars for unconnected resource variables.\r\n\r\n**Describe the expected behavior**\r\nCalling `tf.gradients` with `unconnected_gradients=\"zero\"` returns appropriately shaped zero tensors for unconnected resource variables.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\na = tf.Variable(initial_value=[2., 3.])\r\nb = tf.Variable(initial_value=[3., 4.], use_resource=True)\r\nc = tf.constant(0.)\r\nprint(tf.gradients(c, [a, b], unconnected_gradients=\"zero\"))\r\n# => [<tf.Tensor 'zeros_like:0' shape=(2,) dtype=float32>,\r\n#     <tf.Tensor 'zeros_like_1:0' shape=() dtype=float32>]\r\n```", "comments": ["Could able to reproduce the issue on Colab with Tensorflow 1.14.0. Please find the gist [here](https://colab.research.google.com/drive/1Kt85ANNP_7Hy1HCVcPSfgSHN0ogRuTzX). Thanks! ", "@saxenasaurabh I think you improved inferred gradient shape of variables recently in another place; is the same fix applicable here?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31297\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31297\">No</a>\n"]}, {"number": 31296, "title": "add api doc", "body": "This PR adds some missing api doc. ", "comments": ["Can one of the admins verify this patch?", "@autoih Could you please address the build failures? Thanks!", "The fails are from `do_pylint PYTHON2: Python 2 pylint` and `do_pylint PYTHON3: Python 3 pylint`. I've checked with (pylint), it looks like most of them are bad indentation. @alextp, do you have any suggestions? Thank you. ", "Please fix the indentation\n\nOn Thu, Sep 19, 2019 at 3:36 PM prcvih <notifications@github.com> wrote:\n\n> The fails are from do_pylint PYTHON2: Python 2 pylint and do_pylint\n> PYTHON3: Python 3 pylint. I've checked with (pylint), it looks like most\n> of them are bad indentation. I am not sure how to deal with it. @alextp\n> <https://github.com/alextp>, do you have any suggestions? Thank you.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31296?email_source=notifications&email_token=AAABHRMR7EPX55AEMOSAOF3QKPICDA5CNFSM4IJB2HBKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7ER6PY#issuecomment-533274431>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIBK2JNEEQMHMFQY2DQKPICDANCNFSM4IJB2HBA>\n> .\n>\n\n\n-- \n - Alex\n", "Is there a command to locally run the doctests, yash?\n\nOn Tue, Sep 24, 2019 at 10:11 AM Yash Katariya <notifications@github.com>\nwrote:\n\n> *@yashk2810* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/ops/array_ops.py\n> <https://github.com/tensorflow/tensorflow/pull/31296#discussion_r327730162>\n> :\n>\n> > +\n> +  In other words:\n> +\n> +  ```python\n> +  out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]\n> +  ```\n> +\n> +  For example, given this input:\n> +  ```python\n> +  x = [1, 2, 3, 4, 5, 6]\n> +  y = [1, 3, 5]\n> +  ```\n> +\n> +  This operation would return:\n> +\n> +  ```python\n>\n> As Alex said, it would be nice to have this in the doctest\n> <https://docs.python.org/3/library/doctest.html> format.\n>\n> Please remove the python and after you add >>>.\n>\n> Try the code out locally on your machine with TF2 rc2 and python3.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/31296?email_source=notifications&email_token=AAABHRKWYSME4C5M4IY5KPDQLJC3PA5CNFSM4IJB2HBKYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCFYE24I#pullrequestreview-292572529>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRPPWYWRMLTMQTMQLHTQLJC3PANCNFSM4IJB2HBA>\n> .\n>\n\n\n-- \n - Alex\n", "> Is there a command to locally run the doctests, yash?\r\n\r\n@alextp @autoih Currently, there is no way of running locally, unless you build tensorflow from source. If you do that, then please run `python tf_doctest.py --module=ops.array_ops`.\r\n\r\nI am working on local running such tests and a doc that describes the process of doing this.", "Thanks @yashk2810 and @alextp, but I updated it without running locally. If it's necessary, I'll run it later. ", "> without running locally. If it's necessary, I'll run it later.\r\n\r\nYou will need to show the output where you are printing it, otherwise doctest will fail.\r\n\r\nTo get the output, you can run the code inside a terminal and paste the output here. ", "You can also refer this guide: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md", "There is a way to locally test the changes: https://github.com/tensorflow/docs/blob/master/site/en/community/contribute/docs_ref.md#test-on-your-local-machine"]}, {"number": 31295, "title": "Add tests of SamplingDataset and fix a bug", "body": "This PR adds regression tests for the SamplingDataset kernel, following the example of the tests for AssertNextDataset. @feihugis helped guide me through this task. To allow my tests to create instances of the SamplingDataset class, I refactored the SamplingDataset class from a single .cc file into a header file and a code file. I also fixed a bug in the dataset's save/restore code that was preventing one of the tests from running.\r\n\r\nI've broken the refactoring, the tests, and the bug fixes into separate commits.\r\n", "comments": ["Sorry, @jsimsa, I think I may have removed some review comments from you while squashing commits. Did you request any changes?", "Can one of the admins verify this patch?", "Fails internal tests with:\r\n\r\n```\r\nIn module '//testing/base/public:gunit_headers':\r\nthird_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:401:16: error: allocating an object of abstract class type 'tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test'\r\n    return new TestClass();\r\n               ^\r\nthird_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:397:12: note: in instantiation of member function 'testing::internal::ParameterizedTestFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::CreateTest' requested here\r\n  explicit ParameterizedTestFactory(ParamType parameter) :\r\n           ^\r\nthird_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:439:16: note: in instantiation of member function 'testing::internal::ParameterizedTestFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::ParameterizedTestFactory' requested here\r\n    return new ParameterizedTestFactory<TestSuite>(parameter);\r\n               ^\r\nthird_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:436:3: note: in instantiation of member function 'testing::internal::TestMetaFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::CreateTestFactory' requested here\r\n  TestMetaFactory() {}\r\n  ^\r\nthird_party/tensorflow/core/kernels/data/experimental/sampling_dataset_op_test.cc:176:1: note: in instantiation of member function 'testing::internal::TestMetaFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::TestMetaFactory' requested here\r\nTEST_P(ParameterizedGetNextTest, GetNext) {\r\n^\r\nthird_party/googletest/googletest/include/gtest/gtest-param-test.h:432:19: note: expanded from macro 'TEST_P'\r\n              new ::testing::internal::TestMetaFactory<GTEST_TEST_CLASS_NAME_( \\\r\n                  ^\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:488:18: note: unimplemented pure virtual method 'MakeDatasetOpKernel' in 'ParameterizedGetNextTest_GetNext_Test'\r\n  virtual Status MakeDatasetOpKernel(\r\n                 ^\r\n```", "> Fails internal tests with:\r\n> \r\n> ```\r\n> In module '//testing/base/public:gunit_headers':\r\n> third_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:401:16: error: allocating an object of abstract class type 'tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test'\r\n>     return new TestClass();\r\n>                ^\r\n> third_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:397:12: note: in instantiation of member function 'testing::internal::ParameterizedTestFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::CreateTest' requested here\r\n>   explicit ParameterizedTestFactory(ParamType parameter) :\r\n>            ^\r\n> third_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:439:16: note: in instantiation of member function 'testing::internal::ParameterizedTestFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::ParameterizedTestFactory' requested here\r\n>     return new ParameterizedTestFactory<TestSuite>(parameter);\r\n>                ^\r\n> third_party/googletest/googletest/include/gtest/internal/gtest-param-util.h:436:3: note: in instantiation of member function 'testing::internal::TestMetaFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::CreateTestFactory' requested here\r\n>   TestMetaFactory() {}\r\n>   ^\r\n> third_party/tensorflow/core/kernels/data/experimental/sampling_dataset_op_test.cc:176:1: note: in instantiation of member function 'testing::internal::TestMetaFactory<tensorflow::data::experimental::(anonymous namespace)::ParameterizedGetNextTest_GetNext_Test>::TestMetaFactory' requested here\r\n> TEST_P(ParameterizedGetNextTest, GetNext) {\r\n> ^\r\n> third_party/googletest/googletest/include/gtest/gtest-param-test.h:432:19: note: expanded from macro 'TEST_P'\r\n>               new ::testing::internal::TestMetaFactory<GTEST_TEST_CLASS_NAME_( \\\r\n>                   ^\r\n> ./third_party/tensorflow/core/kernels/data/dataset_test_base.h:488:18: note: unimplemented pure virtual method 'MakeDatasetOpKernel' in 'ParameterizedGetNextTest_GetNext_Test'\r\n>   virtual Status MakeDatasetOpKernel(\r\n>                  ^\r\n> ```\r\n\r\nThanks for the heads-up. It looks like this change set crossed paths with a conflicting set of changes in `dataset_test_base.h`. I have pulled the latest changes from master and updated the tests for `SamplingDataset`. I also switched over to using the new test macros. Changes are in commit 42fc1ab.\r\n"]}, {"number": 31294, "title": "cuDNN supports batch major data inputs under TF2 Keras RNN APIs", "body": "The CuDNNRNNV3 op is able to process the inputs with both time- and batch-major format.\r\n\r\nPrevious Keras RNN API will transpose the batch-major input to time-major before invoking the cudnn_rnnv3.\r\n\r\nThis PR skips the transpose and directly calls the cudnn_rnnv3.\r\n\r\nfyi. @nluehr \r\n", "comments": []}, {"number": 31293, "title": "Change project steward", "body": "Replace Sarah with @theadactyl", "comments": ["@theadactyl please verify you're OK with joining me as a project steward", "LGTM!"]}, {"number": 31292, "title": "Remove symbolic link from Docker build tests", "body": "This was added directly to the partials in a recent PR, so this test fails with\na \"link already exists\" warning.", "comments": []}, {"number": 31291, "title": "tf.keras.optimizers.SGD with momentum does not fit when model metrics are provided", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.4 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: CUDA Version: 10.1\r\n- GPU model and memory: 1080TI \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n`momentum` in  `tensorflow.keras.optimizers.SGD` and `metrics` in model compilation cannot be used together when using `fit_generator`. However, each works independently. The problem does not exist when using `fit`\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom tensorflow.keras.layers import Embedding, Input, Dense, Lambda\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras import Model\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\n\r\ndef get_more():\r\n    while(True):\r\n        yield ({'a_input': np.random.randint(0, 10, (32, 1200))},\r\n               np.random.rand(32, 1))\r\n\r\n\r\ndef build():\r\n\r\n    input = Input(shape=(1200,), name='a_input', dtype='int32')\r\n    x = Embedding(input_dim=10,\r\n                  output_dim=4,\r\n                  input_length=1200,\r\n                  trainable=True, name='embedding')(input)\r\n    x = Dense(1, activation='linear')(x)\r\n    x = Lambda(lambda x: K.squeeze(x, axis=-1))(x)\r\n    x = Dense(1, name='output')(x)\r\n    this_model = Model(input, x)\r\n\r\n    return this_model\r\n\r\n\r\n####### FAIL\r\n# Situation 1 (+METRICS +MOMENTUM)\r\n#######\r\nK.clear_session()\r\nthis_model = build()\r\noptimizer = keras.optimizers.SGD(lr=0.05, momentum=0.9)\r\nthis_model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\r\nthis_model.fit_generator(iter(get_more()), steps_per_epoch=10)\r\n\r\n####### PASS\r\n# Situation 2 (+METRICS -MOMENTUM)\r\n#######\r\nK.clear_session()\r\nthis_model = build()\r\noptimizer = keras.optimizers.SGD(lr=0.05)\r\nthis_model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\r\nthis_model.fit_generator(iter(get_more()), steps_per_epoch=10)\r\n\r\n####### PASS\r\n# Situation 3 (-METRICS +MOMENTUM)\r\n#######\r\nK.clear_session()\r\nthis_model = build()\r\noptimizer = keras.optimizers.SGD(lr=0.05, momentum=0.9)\r\nthis_model.compile(loss='mse', optimizer=optimizer)\r\nthis_model.fit_generator(iter(get_more()), steps_per_epoch=10)\r\n\r\n####### PASS\r\n# Situation 4 (+METRICS +MOMENTUM)  (fit instead of fit_generator)\r\n#######\r\nK.clear_session()\r\nthis_model = build()\r\noptimizer = keras.optimizers.SGD(lr=0.05, momentum=0.9)\r\nthis_model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\r\nx_in = {'a_input': np.random.randint(0,10,(500,1200))}\r\ny_out = np.random.rand(500,1)\r\nthis_model.fit(x_in, y_out)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1355     try:\r\n-> 1356       return fn(*args)\r\n   1357     except errors.OpError as e:\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1338       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1339       self._extend_graph()\r\n   1340       return self._call_tf_sessionrun(\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1373     with self._graph._session_run_lock():  # pylint: disable=protected-access\r\n-> 1374       tf_session.ExtendSession(self._session)\r\n   1375 \r\n\r\nInvalidArgumentError: Cannot assign a device for operation embedding/embeddings/Initializer/random_uniform/sub: Could not satisfy explicit device specification '' because the node {{colocation_node embedding/embeddings/Initializer/random_uniform/sub}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\r\nResourceSparseApplyKerasMomentum: CPU \r\nIdentity: GPU CPU XLA_CPU XLA_GPU \r\nResourceGather: GPU CPU XLA_CPU XLA_GPU \r\nAssignVariableOp: GPU CPU XLA_CPU XLA_GPU \r\nRandomUniform: GPU CPU XLA_CPU XLA_GPU \r\nVarIsInitializedOp: GPU CPU XLA_CPU XLA_GPU \r\nConst: GPU CPU XLA_CPU XLA_GPU \r\nMul: GPU CPU XLA_CPU XLA_GPU \r\nReadVariableOp: GPU CPU XLA_CPU XLA_GPU \r\nSub: GPU CPU XLA_CPU XLA_GPU \r\nVarHandleOp: GPU CPU XLA_CPU XLA_GPU \r\nAdd: GPU CPU XLA_CPU XLA_GPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  embedding/embeddings/Initializer/random_uniform/shape (Const) \r\n  embedding/embeddings/Initializer/random_uniform/min (Const) \r\n  embedding/embeddings/Initializer/random_uniform/max (Const) \r\n  embedding/embeddings/Initializer/random_uniform/RandomUniform (RandomUniform)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embeddings/Initializer/random_uniform/sub (Sub) \r\n  embedding/embeddings/Initializer/random_uniform/mul (Mul) \r\n  embedding/embeddings/Initializer/random_uniform (Add) \r\n  embedding/embeddings (VarHandleOp)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embeddings/IsInitialized/VarIsInitializedOp (VarIsInitializedOp)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embeddings/Assign (AssignVariableOp)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embeddings/Read/ReadVariableOp (ReadVariableOp)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embedding_lookup (ResourceGather)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  embedding/embedding_lookup/Identity (Identity) \r\n  VarIsInitializedOp_4 (VarIsInitializedOp)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\r\n  SGD/embedding/embeddings/momentum/Initializer/zeros (Const) \r\n  SGD/embedding/embeddings/momentum (VarHandleOp) \r\n  SGD/embedding/embeddings/momentum/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) \r\n  SGD/embedding/embeddings/momentum/Assign (AssignVariableOp) \r\n  SGD/embedding/embeddings/momentum/Read/ReadVariableOp (ReadVariableOp) \r\n  SGD/SGD/update_embedding/embeddings/ResourceSparseApplyKerasMomentum (ResourceSparseApplyKerasMomentum) \r\n  VarIsInitializedOp_7 (VarIsInitializedOp) \r\n\r\n\t [[{{node embedding/embeddings/Initializer/random_uniform/sub}}]]\r\n\r\n```", "comments": ["Was able to reproduce the issue with Tensorflow 1.14.0 on Colab. Please take a look at gist [here](https://colab.research.google.com/drive/1NQk0_HDfUislaKeFCT77xC7KJ4KHia6h). Thanks! ", "@xuevin This is not issue with Tenosrflow 2.0.0.beta1 and tf-nightly-2.0-preview. You might want to give it a try instead. Thanks!", "Thanks! The problem must be limited to 1.14 then. 1.13.* seems to be unaffected. ", "@ I couldn't reproduce the issue with `tf-nightly`. Please check the [ gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/b350996a893a58e8a54cad0f3cf1a253/tf_31291_keras_opt.ipynb). Thanks!", "Thanks @jvishnuvardhan ! @xuevin it seems to be fixed after 1.14", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31291\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31291\">No</a>\n", "@gadagashwini @jvishnuvardhan This issue happens with gpu-enabled tensorflow.", "@llan-ml Based on error trace [mentioned here](https://github.com/tensorflow/tensorflow/issues/31291#issue-476337948), the `momentum` related ops looking for a specific device. So when I assign a device like below, everything worked as expected.\r\n```\r\nwith tf.device('/cpu:0'):\r\n  this_model.fit_generator(iter(get_more()), steps_per_epoch=10) \r\n```\r\nWhen you select gpu as `with tf.device('gpu:0'):`, this will throw same error as follows. Error clearly mentions that the `supported_device_types_=[CPU]`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/b350996a893a58e8a54cad0f3cf1a253/tf_31291_keras_opt.ipynb#scrollTo=_Aw5V87sllwL).\r\n\r\n```\r\nInvalidArgumentError: Cannot assign a device for operation embedding/embeddings/Initializer/random_uniform/sub: Could not satisfy explicit device specification '' because the node {{colocation_node embedding/embeddings/Initializer/random_uniform/sub}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\r\nResourceSparseApplyKerasMomentum: CPU \r\n```\r\n\r\nThanks!", "@jvishnuvardhan Thanks for your explanation. I know there are some ops used by Momentum that do not have gpu implementations. However, it is really a limitation that we cannot try the Momentum optimizer for optimizing a model with GPU. \r\n\r\nI do not know the internal implementations of different optimizers, but other optimizers such as Adam and RMSprop work normally on GPUs.\r\n\r\nSorry that I just realized that this may not be related to the topic of this issue.", "@llan-ml I think none of the optimizers would work with GPU given sparse. And this is something that we're planning to fix and should probably be done by Nov 2019 -- But contribution welcome if this is urgent to you.", "@tanzhenyu Just in my cases, my model can be trained with Adam, but it raises the error when I declare the optimizer with `optimizer = tf.keras.optimizers.SGD(momentum=0.9)` and without any other code changed. I'm using tf-nightly-gpu-preview and follow the subclassed model style with custom training loops. If needed, I can provide some tiny scripts to reproduce.", "@llan-ml Oh sorry I missed that, adam is the only one that would probably work in your case because we haven't made a sparse op yet so every op it uses can be run on GPU. "]}, {"number": 31290, "title": "Override zip on AutoGraph ", "body": "This pull request address what @mdanatg said on #31038 PR about overriding zip on AutoGraph. The current implementation override zip when all of the input was dataset. But when not all of it was a dataset, it will execute the built-in python zip. Is this the correct behaviour?", "comments": ["Hmm, why there's an error happened while migrating the change? Is there anything I needed to fix?", "Can one of the admins verify this patch?"]}, {"number": 31289, "title": "Update API docs for SamplingDataset op", "body": "Following a discussion with @jsimsa on #31176, I've started updating the API docs for the C++ side of `tf.data.experimental`. This PR contains updates to the documentation for `SamplingDataset`. I've added a description of what type of sampling the dataset performs, as well as information about the code paths by which the dataset is instantiated.", "comments": ["@frreiss thank you for the documentation improvement, left a couple of small comments", "> Optionally, add a comment into the sampling_dataset_op.cc source file that points on that the documentation of the SamplingDatasetOp API can be found here.\r\n\r\nI'm finishing up another PR that adds tests to SamplingDataset. I'll add that comment to that other PR."]}, {"number": 31288, "title": "[INTEL MKL] Reverting changes made to Add + Conv fusion during MKL-DNN v1.x integration", "body": "This fixes the accuracy regression in Resnet-50 for FP32.", "comments": ["@penpornk Done."]}, {"number": 31287, "title": "Optimizer (Adam) does not propagate hyperparameter update on first update", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 64b\r\n- TensorFlow version (use command below): 2.0.0b1\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nUsing tf.keras.optimizers.Adam and updating hyperparameters results in hyperparameters not updating on the first update.\r\n\r\n**Describe the expected behavior**\r\nHyperparameters DO update on the first run, ie they are initialized to tf.Variables at constructor of the optimizer, not on first call.\r\n\r\n**Code to reproduce the issue**\r\n`adam = tf.keras.optimizers.Adam()`\r\n`adam.learning_rate = 0.00001   # this does not update learning_rate, but changes python-typed ` `hyperparameters in \"_hyper\" dictionary to tf.Variables`\r\n`adam.learning_rate = 0.00001  # this finally updates the tf.Variable `\r\n\r\n\r\nCalling adam._hyper before update yields:\r\n\r\n`{'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999}`\r\n\r\nCalling adam._hyper after first update yields:\r\n\r\n`{'learning_rate': <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>, 'decay': <tf.Variable 'decay:0' shape=() dtype=float32, numpy=0.0>, 'beta_1': <tf.Variable 'beta_1:0' shape=() dtype=float32, numpy=0.9>, 'beta_2': <tf.Variable 'beta_2:0' shape=() dtype=float32, numpy=0.999>}`\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Well actually to get it working, first a getter must be called for `adam.learning_rate` and only then the python-typed variables are replaced with tf.Variable variables and one can use the setter.", "@svobora, In order to expedite the trouble-shooting process, please provide a complete code to reproduce the issue reported here. Thanks!\r\n", "Hello, I will provide a simple and complete, yet a little different example. I believe the actual problem is with the tf.train.Checkpoint. Probably the variables are overwritten by the restored values when adam._hyper is converted from plaintext format to tf.Variable format.\r\n\r\nIn the provided example, the optimizer.learning_rate is not properly stored. Even though it is a different problem, I believe they are connected. I am not yet able to easily reproduce the first problem, because it appears after ckpt.restore() call (I was able to reproduce it with minimal example), but it depends on the manager.save() (I was not yet able to reproduct with minimal example).\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef save():\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    ckpt = tf.train.Checkpoint(optimizer=optimizer)\r\n    manager = tf.train.CheckpointManager(ckpt, \"tmp\", max_to_keep=3)\r\n    _ = optimizer.learning_rate  # comment this line and \"load()\" will print (0.001)\r\n    optimizer.learning_rate = 0.0003\r\n    manager.save()\r\n\r\ndef load():\r\n    pretrained_model = \"tmp/ckpt-1\"\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    ckpt = tf.train.Checkpoint(optimizer=optimizer)\r\n    ckpt.restore(str(pretrained_model))\r\n    print(\"Learning rate for epoch {} set to {}.\".format(0, optimizer.learning_rate))\r\n\r\nif __name__ == '__main__':\r\n    save()\r\n    load()\r\n```\r\n\r\nComment the suggested line to see a bug.\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "@svobora Thanks for providing the reproducible code.\r\nI am able to reproduce the issue with Tenosrflow 2.0.0.beta1 on Colab. Please see the colab [gist](https://colab.research.google.com/drive/1LmQbwnFbOcEF9g1XZvWWkqQjcgP-Dck_). Thanks!", "I think this issue surfaces a discrepancy in ```Save and Restore``` method and is not necessarily a bug on  ```tf.keras.optimizers.Adam``` side.\r\nCan you please try setting ```learning_rate``` arg for the ```tf.keras.optimizers.Adam()``` instead?", "I believe the main issue is that `tf.keras.optimizers.Adam()` returns not fully initialized object. What is the reason not to construct the object with `tf.Variable` hyperparameters in the first place? Why is the object constructed with hyperparameters in the form `{'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999}` and only on first getter call converted to `tf.Variable`?", "Thanks for the report!\r\nVariable creation is deferred so that Estimator use case is supported. (you can't create a variable outside of Estimator graph)\r\nThe workaround here is just to call opt._create_hypers() so that things will get initialized correctly before calling Checkpoint, but I'm concerned this is not a good solution.", "@allenlavoie from the minimal example here, do you think it's better if we create variables eagerly, since checkpoint needs to capture variables at creation time?", "How about the setter also creates a Variable? So if you pass the constructor argument you don't get a variable (since presumably you'll always pass that same value, so no need to restore it from a checkpoint) but if you assign to the attribute you always get a variable.", "You can simply initialize the optimizer with the right learning_rate. This seems a niche case to support. Closing it for now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31287\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31287\">No</a>\n", "_You can simply initialize the optimizer with the right learning_rate._\r\n\r\nReally? But maybe I should be aware first that save function called on an object doesn't save anything to know that I have to set it manually. The issue is in unexpected behavior of the Saver, which depends on background creation of some other object no user knows about. Like the @allenlavoie  said, either create on assignment, or ban assignment. Do not allow to assign to preliminary objects.", "What I ended up doing is calling a getter on the object, which as opposed to setter, actually creates the Variable.\r\n\r\n`_ = optimizer.learning_rate`\r\n", "> What I ended up doing is calling a getter on the object, which as opposed to setter, actually creates the Variable.\r\n> \r\n> `_ = optimizer.learning_rate`\r\n\r\nThis is only a workaround, b/c there are quite some other hyper parameters. I'm not sure what your use case is, why would you use an optimizer without minimizing anything?\r\nOn the other hand, we're moving forward with having Adam(var_list) or something like that, which should be able to fix this problem", "_why would you use an optimizer without minimizing anything?_\r\n\r\nHow did you infer that I do not minimize anything? I posted a toy example to reproduce the issue, not my company's code, which was affected and I had to find the issue and fix it.\r\n\r\n_On the other hand, we're moving forward with having Adam(var_list) or something like that, which should be able to fix this problem_\r\n\r\nGreat! Hopefully things will improve over time. Thx for reply.\r\n", "> _why would you use an optimizer without minimizing anything?_\r\n> \r\n> How did you infer that I do not minimize anything? I posted a toy example to reproduce the issue, not my company's code, which was affected and I had to find the issue and fix it.\r\nIf you minimize a list of variables, it will create the hyper parameters as tf.Variables after it, so the saving and loading would work.\r\n> \r\n> _On the other hand, we're moving forward with having Adam(var_list) or something like that, which should be able to fix this problem_\r\n> \r\n> Great! Hopefully things will improve over time. Thx for reply.\r\n\r\n", "_If you minimize a list of variables, it will create the hyper parameters as tf.Variables after it, so the saving and loading would work._\r\n\r\nCould you point me to a documentation that specifies you cannot call Saver before minimizing a set of variables?", "> _If you minimize a list of variables, it will create the hyper parameters as tf.Variables after it, so the saving and loading would work._\r\n> \r\n> Could you point me to a documentation that specifies you cannot call Saver before minimizing a set of variables?\r\n\r\nWhat I mean is it will serve as a workaround for you before this is fixed in nightly or 2.3", "OK, thanks!"]}, {"number": 31286, "title": "ValueError: Cannot add function 'TRTEngineOp_0_native_segment' because a different function with the same name already exists.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubunti 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nNot able to call trt.create_inference_graph more than  once to create TF-TRT nodes for  disjointed sub-graphs.  Throws the above error. \r\n\r\n**Describe the expected behavior**\r\n\r\nShould not throw the above error.\r\n\r\n**Code to reproduce the issue**\r\n\r\nShould not be difficult to create a sample code.  Will try to get one soon. \r\n\r\n**Other info / logs**\r\n\r\n```\r\n File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 430, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Cannot add function 'TRTEngineOp_0_native_segment' because a different function with the same name already exists.\r\n```\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Hi, with the following code I see the error in the \"docker pull nvcr.io/nvidia/tensorflow:19.07-py2\" container.  However in the \"docker pull tensorflow/tensorflow:devel-gpu\" , I did not observe the error. My suspicion is TF-TRT is not working in \"tensorflow/tensorflow:devel-gpu\" !! Can you please confirm both ? \r\n\r\n```\r\nfrom tensorflow.contrib.slim.nets import resnet_v1\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\nimport time\r\nimport os\r\nfrom PIL import Image\r\n#import tensorflow.contrib.tensorrt as tftrt\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as tftrt\r\nimport argparse\r\n\r\nPATH_TO_CKPT = \"resnet_v1_50.ckpt\"\r\nTEST_IMAGE_PATHS = [ \"elephant_small.jpg\", \"tabby_tiger_cat.jpg\"]\r\nBATCH_SIZE=25\r\nMAX_BATCH_SIZE=1000\r\nHEIGHT=224\r\nWIDTH=224\r\nCHANNELS=3\r\n\r\n\r\ndef load_image_into_numpy_array(image, batch_size=1):\r\n  (im_width, im_height) = image.size\r\n  x = np.array(image.getdata()).reshape(\r\n      (HEIGHT, WIDTH, CHANNELS)).astype(np.uint8)\r\n  x = np.expand_dims(x, axis=0)\r\n  xsl = list (x.shape)\r\n  xsl[0] = batch_size#MAX_BATCH_SIZE\r\n  x = np.broadcast_to(x[0,:,:,:], xsl) \r\n  return x\r\n\r\ndef run_resnet_50():\r\n    # Create graph\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)\r\n    \r\n    saver = tf.train.Saver()\r\n    \r\n    with tf.Session() as sess:\r\n            saver.restore(sess, PATH_TO_CKPT)\r\n            representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0') # if you don't know names like these, consider referring to corresponding model file or generate .pbtxt file as mentioned in  @civilman628 's answer above\r\n            img = np.ones((batch_size, height, width, channels))   #load image here with size [1, 224,224, 3]\r\n            features = sess.run(representation_tensor, {'Placeholder:0': img})\r\n            print ( \"features\", features)\r\n\r\ndef renamed_ckpt_save(name):\r\n    with tf.Session() as sess:# Restore the TF checkpoint\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\n        ckpt_dir = \"/tmp/\"+name\r\n        if not os.path.exists(ckpt_dir):\r\n            os.mkdir(ckpt_dir)\r\n        sess.run(tf.global_variables_initializer())\r\n        saver = tf.train.Saver()\r\n        saver.save(sess, ckpt_dir)\r\n\r\ndef renamed_ckpt_mem(sess, name):\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\ndef build_graph (sess, input_graph, name='graph1'):\r\n\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=name)\r\n\r\n    with input_graph.as_default():\r\n      # Get handles to input and output tensors\r\n      ops = tf.get_default_graph().get_operations()\r\n      all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n      tensor_dict = {}\r\n      for key in [\r\n          'pool5',\r\n      ]:\r\n        if name == '':\r\n            tensor_name = key + ':0'\r\n        else :\r\n            tensor_name = name+'/'+key + ':0'\r\n        if tensor_name in all_tensor_names:\r\n                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                tensor_name)\r\n                print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n        else:\r\n           print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n\r\n    # Restore the TF checkpoint\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, \"/tmp/\"+name)\r\n    return tensor_dict\r\n\r\nclass TfTrt():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name='import'):\r\n        tensor_dict = build_graph(sess, graph, name=name, )\r\n\r\n        outputl = []\r\n        for i,nname in enumerate(tensor_dict):\r\n            nvalue = tensor_dict[nname].name.split(\":\")[0]\r\n            print( i, nname, tensor_dict[nname].name )\r\n            outputl.append(nvalue)\r\n        print ( \"outputl \", outputl)\r\n\r\n        #node_names = [n.name for n in graph.as_graph_def().node]\r\n        #import pdb\r\n        #pdb.set_trace()\r\n\r\n        # Freeze the graph:\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph_def,\r\n        output_node_names= outputl)\r\n\r\n        # remove training nodes\r\n        frozen_graph = tf.compat.v1.graph_util.remove_training_nodes(frozen_graph)\r\n        # Now you can create a TensorRT inference graph from your frozen graph\r\n\r\n        tftrt_graph = tftrt.create_inference_graph(\r\n            input_graph_def=frozen_graph,\r\n            outputs = outputl,\r\n            max_batch_size = MAX_BATCH_SIZE ,\r\n            max_workspace_size_bytes= 1024*1024*1024,\r\n            precision_mode=\"FP16\")\r\n\r\n        output_nodes = tf.import_graph_def(\r\n            tftrt_graph,\r\n            return_elements = outputl,\r\n            name=import_name\r\n        )\r\n\r\n        tensor_dict = {}\r\n        for opname, opnode in zip (outputl, output_nodes):\r\n            tensor_dict[opnode.name] = opnode.outputs[0]\r\n\r\n        print ( \"tensor_dict\", tensor_dict)\r\n\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\nclass Tf():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name=None):\r\n        return build_graph(sess, graph, name=name)\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\ndef run (runtime='TF'):\r\n\r\n    if runtime=='TF':\r\n        RunClass = Tf\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFTRT':\r\n        RunClass = TfTrt\r\n        import_name1 = 'import1'\r\n        import_name2 = 'import2'\r\n        placeholder_name1 = 'import1/Placeholder:0'\r\n        placeholder_name2 = 'import2/Placeholder_1:0'\r\n\r\n    graph = tf.Graph()\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.33\r\n    config.graph_options.rewrite_options.auto_mixed_precision = 1\r\n    with tf.Session(graph=graph, config=config) as sess:\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_1')\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_2')\r\n        tensor_dict1 = RunClass.build(sess, graph, name='resnet_v1_50_1', import_name=import_name1)\r\n        tensor_dict2 = RunClass.build(sess, graph, name='resnet_v1_50_2', import_name=import_name2)\r\n        tensorboard_dir = os.environ['TENSORBOARD_DIR']\r\n        file_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\r\n        image_path = TEST_IMAGE_PATHS[0]\r\n        print ( \"image_path {}\".format(image_path))\r\n        image = Image.open(image_path)\r\n        image = image.resize((WIDTH, HEIGHT))\r\n        image_np_expanded = load_image_into_numpy_array(image, batch_size=BATCH_SIZE)\r\n        image_tensor1 = graph.get_tensor_by_name(placeholder_name1)\r\n        image_tensor2 = graph.get_tensor_by_name(placeholder_name2)\r\n        time0 = time.time()\r\n        for i in range(1,1001):\r\n            output_dict1 = RunClass.run(sess, tensor_dict1, image_tensor1, image_np_expanded)\r\n            output_dict2 = RunClass.run(sess, tensor_dict2, image_tensor2, image_np_expanded)\r\n            if i % 100 == 0:\r\n                time_taken = (time.time() - time0 )/(i * 1.0)\r\n                print (i, time_taken)\r\n        time_taken = (time.time() - time0 )/(i * 1.0)\r\n        print (\"time_taken \", time_taken, \"output_dict\", output_dict1, output_dict2)\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--runtime', default='TF', help='TF or TFTRT')\r\n    parser.add_argument('--rewrite_ckpt', action='store_true',  help='rename checkpoints')\r\n    args = parser.parse_args()\r\n    if args.rewrite_ckpt:\r\n        renamed_ckpt_save('resnet_v1_50_1')\r\n        renamed_ckpt_save('resnet_v1_50_2')\r\n\r\n    run (args.runtime)\r\n\r\n\r\n\r\n```\r\n", "Is this  code and info enough for you to reopen the issue ? ", "use tf.Graph().as_default() to separate differnt Scope, it works.\r\n\r\nwith tf.Graph().as_default() as g:\r\n            sess = tf.Session(config=config_gpu)\r\n            meta_graph_def = tf.saved_model.loader.load(sess, [\"serve\"], model_path)\r\n            signature = meta_graph_def.signature_def\r\n"]}, {"number": 31285, "title": "two neural networks running at the same time GPU-Util drops ", "body": "I'm running two neural networks on the same process, one depends  on the other. the first one is an image classifier (YOLO) the other one is a Lstm that depends on the deteccions of the yolo, when I run more than one YOLO network everythings goin right, the util of the gpu is hight, same when I run more than one Lstm, the problem is when the two networks runs together, the gpu-uils drops and the all process is slow. I tried in python and c++ tensorflow api same results any help ? ", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nThanks!\r\n", "> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> Thanks!\r\n\r\nI'm using Ubuntu 18.04 x86 64 bits, I'm using tensorflow 1.14 I've tried from binary and compiling from source, same problem hope we can figure out what's going on ", "@andres0820m Please provide us the minimal reproducible code snippet. It will indeed help us to move faster.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 31284, "title": "tf.2 VAE example iteration time same despite increasing number of GPUs", "body": "- Have I written custom code: \r\nNo. I am using the copy of the code provided in the VAE tf2 MNIST example (https://www.tensorflow.org/beta/tutorials/generative/cvae). The only change I made: I commented out lines related to IPython module which is not used as I am using it without Colab, directly running on gcloud.\r\n\r\n- OS Platform and Distribution: \r\nLinux Ubuntu 16.04 installed on Google Cloud compute engine VM\r\n\r\n- TensorFlow installed from (source or binary):\r\npip install tensorflow-gpu==2.0.0-beta1\r\n\r\n- TensorFlow version (use command below):\r\n2.0-beta1\r\n\r\n- Python version:\r\nPython3.5\r\n\r\n- GCC/Compiler version (if compiling from source):\r\ngcc-5.4 (auto-installed with nvidia-cuda)\r\n\r\n- CUDA/cuDNN version:\r\ncuda-10.0 / libcudnn7_7.6.1.34\r\n\r\n- GPU model and memory:\r\nI am comparing 3 configurations:\r\nCONFIG_GPU_8: GCE, 8xV100 128 GB total memory with 24x vCPUs 128GB total memory\r\nvs.\r\nCONFIG_GPU_4: GCE, 4xP100 128 GB total memory with 16x vCPU 64 GB total memory\r\nvs.\r\nCONFIG_GPU_0: local machine WITHOUT GPU, only 2 CPUs with 3.5 GB total memory (in this case tf version is no-gpu version: tensorflow==2.0.0-beta1)\r\n\r\n\r\n**Current behavior**\r\nWhen running the MNIST training example, the reported time spent on each training epoch is the following (on average):\r\nCONFIG_GPU_8:  ~17.5 seconds\r\nCONFIG_GPU_4:  ~17.6 seconds\r\nCONFIG_GPU_0:  ~98 seconds\r\n\r\n**Describe the expected behavior**\r\nThe training speed should improve much more when going from CONFIG_GPU_0 to CONFIG_GPU_4 and it should improve by more than a factor of 2 when going from CONFIG_GPU_4 to CONFIG_GPU_8 (notice that in addition to using twice as many GPUs, each GPU in CONFIG_GPU_8 is V100 which is in itself should be much more powerful than P100 in CONFIG_GPU_4).\r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nimport os\r\nimport time\r\nimport numpy as np\r\nimport glob\r\nimport matplotlib as mpl\r\nmpl.use('Agg')\r\nimport matplotlib.pyplot as plt\r\nimport PIL\r\nimport imageio\r\n# from IPython import display\r\n\r\n(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\r\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\r\n\r\n# Normalizing the images to the range of [0., 1.]\r\ntrain_images /= 255.\r\ntest_images /= 255.\r\n\r\n# Binarization\r\ntrain_images[train_images >= .5] = 1.\r\ntrain_images[train_images < .5] = 0.\r\ntest_images[test_images >= .5] = 1.\r\ntest_images[test_images < .5] = 0.\r\n\r\nTRAIN_BUF = 60000\r\nBATCH_SIZE = 100\r\n\r\nTEST_BUF = 10000\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\r\ntest_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)\r\n\r\n\r\n# Network architecture\r\n\r\nclass CVAE(tf.keras.Model):\r\n    def __init__(self, latent_dim):\r\n        super(CVAE, self).__init__()\r\n        self.latent_dim = latent_dim\r\n        self.inference_net = tf.keras.Sequential(\r\n            [\r\n                tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\r\n                tf.keras.layers.Conv2D(\r\n                    filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\r\n                tf.keras.layers.Conv2D(\r\n                    filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\r\n                tf.keras.layers.Flatten(),\r\n                # No activation\r\n                tf.keras.layers.Dense(latent_dim + latent_dim),\r\n            ]\r\n        )\r\n\r\n        self.generative_net = tf.keras.Sequential(\r\n            [\r\n              tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\r\n              tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\r\n              tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\r\n              tf.keras.layers.Conv2DTranspose(\r\n                  filters=64,\r\n                  kernel_size=3,\r\n                  strides=(2, 2),\r\n                  padding=\"SAME\",\r\n                  activation='relu'),\r\n              tf.keras.layers.Conv2DTranspose(\r\n                  filters=32,\r\n                  kernel_size=3,\r\n                  strides=(2, 2),\r\n                  padding=\"SAME\",\r\n                  activation='relu'),\r\n              # No activation\r\n              tf.keras.layers.Conv2DTranspose(\r\n                  filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\"),\r\n            ]\r\n        )\r\n\r\n    def sample(self, eps=None):\r\n        if eps is None:\r\n            eps = tf.random.normal(shape=(100, self.latent_dim))\r\n        return self.decode(eps, apply_sigmoid=True)\r\n\r\n    def encode(self, x):\r\n        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\r\n        return mean, logvar\r\n\r\n    def reparameterize(self, mean, logvar):\r\n        eps = tf.random.normal(shape=mean.shape)\r\n        return eps * tf.exp(logvar * .5) + mean\r\n\r\n    def decode(self, z, apply_sigmoid=False):\r\n        logits = self.generative_net(z)\r\n        if apply_sigmoid:\r\n            probs = tf.sigmoid(logits)\r\n            return probs\r\n\r\n        return logits\r\n\r\n\r\n\r\n# Define loss and optimizer:\r\n\r\noptimizer = tf.keras.optimizers.Adam(1e-4)\r\n\r\ndef log_normal_pdf(sample, mean, logvar, raxis=1):\r\n  log2pi = tf.math.log(2. * np.pi)\r\n  return tf.reduce_sum(\r\n      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\r\n      axis=raxis)\r\n\r\ndef compute_loss(model, x):\r\n  mean, logvar = model.encode(x)\r\n  z = model.reparameterize(mean, logvar)\r\n  x_logit = model.decode(z)\r\n\r\n  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\r\n  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\r\n  logpz = log_normal_pdf(z, 0., 0.)\r\n  logqz_x = log_normal_pdf(z, mean, logvar)\r\n  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\r\n\r\ndef compute_gradients(model, x):\r\n  with tf.GradientTape() as tape:\r\n      loss = compute_loss(model, x)\r\n  return tape.gradient(loss, model.trainable_variables), loss\r\n\r\ndef apply_gradients(optimizer, gradients, variables):\r\n  optimizer.apply_gradients(zip(gradients, variables))\r\n\r\n\r\n\r\n# Training and generating images:\r\n\r\nepochs = 100\r\nlatent_dim = 50\r\nnum_examples_to_generate = 16\r\n\r\n# keeping the random vector constant for generation (prediction) so\r\n# it will be easier to see the improvement.\r\nrandom_vector_for_generation = tf.random.normal(\r\n    shape=[num_examples_to_generate, latent_dim])\r\nmodel = CVAE(latent_dim)\r\n\r\ndef generate_and_save_images(model, epoch, test_input):\r\n  predictions = model.sample(test_input)\r\n  fig = plt.figure(figsize=(4,4))\r\n\r\n  for i in range(predictions.shape[0]):\r\n      plt.subplot(4, 4, i+1)\r\n      plt.imshow(predictions[i, :, :, 0], cmap='gray')\r\n      plt.axis('off')\r\n\r\n  # tight_layout minimizes the overlap between 2 sub-plots\r\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\r\n  # plt.show()\r\n\r\n\r\ngenerate_and_save_images(model, 0, random_vector_for_generation)\r\n\r\nfor epoch in range(1, epochs + 1):\r\n  start_time = time.time()\r\n  for train_x in train_dataset:\r\n    gradients, loss = compute_gradients(model, train_x)\r\n    apply_gradients(optimizer, gradients, model.trainable_variables)\r\n  end_time = time.time()\r\n\r\n  if epoch % 1 == 0:\r\n    loss = tf.keras.metrics.Mean()\r\n    for test_x in test_dataset:\r\n      loss(compute_loss(model, test_x))\r\n    elbo = -loss.result()\r\n    # display.clear_output(wait=False)\r\n    print('Epoch: {}, Test set ELBO: {}, '\r\n          'time elapse for current epoch {}'.format(epoch,\r\n                                                    elbo,\r\n                                                    end_time - start_time))\r\n    generate_and_save_images(\r\n        model, epoch, random_vector_for_generation)\r\n\r\n\r\n\r\n# display image using the epoch number\r\n\r\ndef display_image(epoch_no):\r\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\r\n\r\n\r\nplt.imshow(display_image(epochs))\r\nplt.axis('off')# Display images\r\n\r\n# generate gif of all the saved images\r\n\r\nanim_file = 'cvae.gif'\r\n\r\nwith imageio.get_writer(anim_file, mode='I') as writer:\r\n  filenames = glob.glob('image*.png')\r\n  filenames = sorted(filenames)\r\n  last = -1\r\n  for i,filename in enumerate(filenames):\r\n    frame = 2*(i**0.5)\r\n    if round(frame) > round(last):\r\n      last = frame\r\n    else:\r\n      continue\r\n    image = imageio.imread(filename)\r\n    writer.append_data(image)\r\n  image = imageio.imread(filename)\r\n  writer.append_data(image)\r\n\r\nprint(\"done\")\r\n# import IPython\r\n# if IPython.version_info >= (6,2,0,''):\r\n#   display.Image(filename=anim_file)\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\nSee below the log for the first 8 training epochs for each of the 3 configuration, one after the other. Please notice that the GPUs (4 or 8) are properly detected and recognized and there is no error and everything seems to work fine apart from the lack of performance improvement despite adding extra GPUs and memory.\r\n\r\n\r\nCONFIG_GPU_8:\r\n\r\n> sudo+ssh://kristofgiber@34.90.27.163:22/usr/bin/python3.5 -u /home/kristofgiber/VAE/MNIST/vae-tf2-mnist.py\r\n> Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n> 11493376/11490434 [==============================] - 0s 0us/step\r\n> 2019-08-02 16:09:34.912011: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n> 2019-08-02 16:09:35.661220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.662802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:04.0\r\n> 2019-08-02 16:09:35.662873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.664279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:05.0\r\n> 2019-08-02 16:09:35.664331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.665726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:06.0\r\n> 2019-08-02 16:09:35.665773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.667167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:07.0\r\n> 2019-08-02 16:09:35.667215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.668597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 4 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:08.0\r\n> 2019-08-02 16:09:35.668641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.670037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 5 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:09.0\r\n> 2019-08-02 16:09:35.670083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.671471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 6 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:0a.0\r\n> 2019-08-02 16:09:35.671515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:35.672967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 7 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:0b.0\r\n> 2019-08-02 16:09:35.841569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-02 16:09:36.289413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-02 16:09:36.633804: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-08-02 16:09:36.782869: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-08-02 16:09:37.188381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-08-02 16:09:37.447535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-08-02 16:09:38.620709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-08-02 16:09:38.620897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.622663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.624230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.625717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.627194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.628617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.630123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.631639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.633059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.634502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.635955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.637491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.639068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.640578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.642202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.643758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:38.645293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n> 2019-08-02 16:09:38.732034: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n> 2019-08-02 16:09:39.951150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:39.962194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:39.994318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.003139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.031364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.065523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.095806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.136847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.154130: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x554e540 executing computations on platform CUDA. Devices:\r\n> 2019-08-02 16:09:40.154183: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154192: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154198: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154203: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154209: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (4): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154215: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (5): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154221: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (6): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.154227: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (7): Tesla V100-SXM2-16GB, Compute Capability 7.0\r\n> 2019-08-02 16:09:40.429307: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000129999 Hz\r\n> 2019-08-02 16:09:40.431667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e65bb0 executing computations on platform Host. Devices:\r\n> 2019-08-02 16:09:40.431701: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n> 2019-08-02 16:09:40.444469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.445999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:04.0\r\n> 2019-08-02 16:09:40.446087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.447539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:05.0\r\n> 2019-08-02 16:09:40.447587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.449025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:06.0\r\n> 2019-08-02 16:09:40.449072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.450563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:07.0\r\n> 2019-08-02 16:09:40.450613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.452069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 4 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:08.0\r\n> 2019-08-02 16:09:40.452116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.453551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 5 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:09.0\r\n> 2019-08-02 16:09:40.453595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.455093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 6 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:0a.0\r\n> 2019-08-02 16:09:40.455146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.456592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 7 with properties: \r\n> name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n> pciBusID: 0000:00:0b.0\r\n> 2019-08-02 16:09:40.456638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-02 16:09:40.456649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-02 16:09:40.456658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-08-02 16:09:40.456666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-08-02 16:09:40.456675: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-08-02 16:09:40.456683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-08-02 16:09:40.456692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-08-02 16:09:40.456726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.458227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.459791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.461375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.462851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.464313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.465793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.467269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.468718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.470246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.471724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.473176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.474585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.476026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.477528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.479125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.480704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n> 2019-08-02 16:09:40.521657: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-02 16:09:40.544337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-08-02 16:09:40.544370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 4 5 6 7 \r\n> 2019-08-02 16:09:40.544379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y Y N Y N N \r\n> 2019-08-02 16:09:40.544384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y Y N N N N \r\n> 2019-08-02 16:09:40.544390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N Y N N N Y \r\n> 2019-08-02 16:09:40.544395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   Y Y Y N N N N N \r\n> 2019-08-02 16:09:40.544401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 4:   N N N N N Y Y Y \r\n> 2019-08-02 16:09:40.544406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 5:   Y N N N Y N Y Y \r\n> 2019-08-02 16:09:40.544412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 6:   N N N N Y Y N Y \r\n> 2019-08-02 16:09:40.544417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 7:   N N Y N Y Y Y N \r\n> 2019-08-02 16:09:40.546196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.547686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.549121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.550673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.552148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.553626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.555043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.556558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.558033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.560367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.561099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.562619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15021 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:05.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.563084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.564620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15021 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:06.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.565064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.566603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15021 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.567064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.568599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 15021 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:08.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.569266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.570857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 15021 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:09.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.571494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.573081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 15021 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0a.0, compute capability: 7.0)\r\n> 2019-08-02 16:09:40.573449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-02 16:09:40.574937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 15021 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)\r\n> 2019-08-02 16:10:01.170625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-02 16:10:04.602996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> WARNING: Logging before flag parsing goes to stderr.\r\n> W0802 16:10:18.277444 139908641928960 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> Epoch: 1, Test set ELBO: -186.47406005859375, time elapse for current epoch 19.488028049468994\r\n> Epoch: 2, Test set ELBO: -148.20664978027344, time elapse for current epoch 17.490494966506958\r\n> Epoch: 3, Test set ELBO: -121.98389434814453, time elapse for current epoch 17.440164804458618\r\n> Epoch: 4, Test set ELBO: -111.5521011352539, time elapse for current epoch 17.79745864868164\r\n> Epoch: 5, Test set ELBO: -105.51742553710938, time elapse for current epoch 18.477241277694702\r\n> Epoch: 6, Test set ELBO: -101.38650512695312, time elapse for current epoch 17.363281726837158\r\n> Epoch: 7, Test set ELBO: -98.83760070800781, time elapse for current epoch 17.08821129798889\r\n> Epoch: 8, Test set ELBO: -96.58488464355469, time elapse for current epoch 16.95319962501526\r\n\r\n\r\n\r\n\r\nCONFIG_GPU_4:\r\n\r\n> sudo+ssh://kristofgiber@35.233.7.176:22/usr/bin/python3.5 -u /home/kristofgiber/pycharm_project/VAE/MNIST/vae-tf2-mnist.py\r\n> Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n> 11493376/11490434 [==============================] - 0s 0us/step\r\n> 2019-08-01 22:24:39.613833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n> 2019-08-01 22:24:40.055413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:40.056313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:04.0\r\n> 2019-08-01 22:24:40.056387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:40.057185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:05.0\r\n> 2019-08-01 22:24:40.057242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:40.058027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:06.0\r\n> 2019-08-01 22:24:40.058080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:40.058874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:07.0\r\n> 2019-08-01 22:24:40.190754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-01 22:24:40.667941: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-01 22:24:40.888660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-08-01 22:24:40.975729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-08-01 22:24:41.345616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-08-01 22:24:41.705419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-08-01 22:24:43.004212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-08-01 22:24:43.004423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.005380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.006229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.007045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.007955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.009103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.009919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.010734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.011540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n> 2019-08-01 22:24:43.116342: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2019-08-01 22:24:43.899581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.899630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.899708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.899709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:43.975951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ff38a0 executing computations on platform CUDA. Devices:\r\n> 2019-08-01 22:24:43.976033: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n> 2019-08-01 22:24:43.976044: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n> 2019-08-01 22:24:43.976068: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n> 2019-08-01 22:24:43.976076: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n> 2019-08-01 22:24:44.240728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n> 2019-08-01 22:24:44.241991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x581cf30 executing computations on platform Host. Devices:\r\n> 2019-08-01 22:24:44.242029: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n> 2019-08-01 22:24:44.245715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.246563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:04.0\r\n> 2019-08-01 22:24:44.246633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.247439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:05.0\r\n> 2019-08-01 22:24:44.247499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.248289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:06.0\r\n> 2019-08-01 22:24:44.248340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.249122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \r\n> name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\n> pciBusID: 0000:00:07.0\r\n> 2019-08-01 22:24:44.249193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-01 22:24:44.249219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-01 22:24:44.249247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-08-01 22:24:44.249273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-08-01 22:24:44.249297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-08-01 22:24:44.249312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-08-01 22:24:44.249344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-08-01 22:24:44.249386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.250193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.251001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.251828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.252663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.253475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.254302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.255141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.255953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3\r\n> 2019-08-01 22:24:44.256368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-08-01 22:24:44.260879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-08-01 22:24:44.260918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 \r\n> 2019-08-01 22:24:44.260929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N \r\n> 2019-08-01 22:24:44.260936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N \r\n> 2019-08-01 22:24:44.260943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y \r\n> 2019-08-01 22:24:44.260950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N \r\n> 2019-08-01 22:24:44.262165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.263013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.263904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.264737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.265689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.323846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15121 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\r\n> 2019-08-01 22:24:44.324561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.325385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15216 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0)\r\n> 2019-08-01 22:24:44.326219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.327027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15216 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0)\r\n> 2019-08-01 22:24:44.327741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-08-01 22:24:44.328630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15216 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0)\r\n> 2019-08-01 22:25:04.473450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-08-01 22:25:07.950765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n> WARNING: Logging before flag parsing goes to stderr.\r\n> W0801 22:25:20.674070 140465772844800 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> Epoch: 1, Test set ELBO: -188.11668395996094, time elapse for current epoch 18.63205885887146\r\n> Epoch: 2, Test set ELBO: -145.51783752441406, time elapse for current epoch 17.303343534469604\r\n> Epoch: 3, Test set ELBO: -122.49842071533203, time elapse for current epoch 17.674144983291626\r\n> Epoch: 4, Test set ELBO: -112.31964111328125, time elapse for current epoch 17.33092761039734\r\n> Epoch: 5, Test set ELBO: -106.07232666015625, time elapse for current epoch 17.66222333908081\r\n> Epoch: 6, Test set ELBO: -101.88775634765625, time elapse for current epoch 17.44078493118286\r\n> Epoch: 7, Test set ELBO: -98.75122833251953, time elapse for current epoch 17.688755989074707\r\n> Epoch: 8, Test set ELBO: -96.532958984375, time elapse for current epoch 17.955048084259033\r\n\r\n\r\n\r\n\r\n\r\nCONFIG_GPU_0:\r\n\r\n> 8f8678b6dd38:python3 -u /opt/project/VAE/MNIST/vae-tf2-mnist.py\r\n> Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n> 11493376/11490434 [==============================] - 13s 1us/step\r\n> 2019-08-01 22:42:21.195909: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2019-08-01 22:42:21.226199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299735000 Hz\r\n> 2019-08-01 22:42:21.227229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3736960 executing computations on platform Host. Devices:\r\n> 2019-08-01 22:42:21.227333: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n> 2019-08-01 22:42:21.228834: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\r\n> 2019-08-01 22:42:22.128135: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\r\n> WARNING: Logging before flag parsing goes to stderr.\r\n> W0801 22:42:23.402617 140101723539200 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> Epoch: 1, Test set ELBO: -188.50021362304688, time elapse for current epoch 92.1476879119873\r\n> 2019-08-01 22:43:59.586590: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\r\n> Epoch: 2, Test set ELBO: -143.65415954589844, time elapse for current epoch 97.12298655509949\r\n> 2019-08-01 22:45:41.824794: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\r\n> Epoch: 3, Test set ELBO: -121.26383972167969, time elapse for current epoch 96.25376057624817\r\n> 2019-08-01 22:47:28.103122: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of system memory.\r\n> Epoch: 4, Test set ELBO: -111.30313110351562, time elapse for current epoch 98.79311537742615\r\n> Epoch: 5, Test set ELBO: -105.29031372070312, time elapse for current epoch 110.05837559700012\r\n> Epoch: 6, Test set ELBO: -101.54240417480469, time elapse for current epoch 102.19214820861816\r\n> Epoch: 7, Test set ELBO: -98.74303436279297, time elapse for current epoch 97.86401653289795\r\n> Epoch: 8, Test set ELBO: -96.51799774169922, time elapse for current epoch 96.82956838607788\r\n\r\n\r\n\r\n\r\n", "comments": ["This is likely an issue of setting the correct hyperparameters for training (eg batch size). This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31284\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31284\">No</a>\n", "Thank you @karmel. Even if more GPU power has an emphasized benefit as those hyperparameters such as batch size grow (due to more room for parallelization), this doesn't explain why the  processing speed is the same despite a doubled CPU memory (since in the above configurations that I compared, the number of CPUs and their memory also increases from 64Gb to 128Gb, not only the GPUs). So by maintaining the same batch size and hyperparameter settings while doubling the CPU (and GPU) power, I think the expected behavior is faster processing - regardless of the batch size. "]}, {"number": 31283, "title": "Tensorflow graph execution does not give expected result.", "body": "I am using `Tesla V100-PCIE-16GB` GPU on my system and using tensorflow version 1.13.1 .\r\nI have two python example script. `example-1.py` runs fine. `example-2.py` contains same statements as `example-1.py` but multiple times. `example-2.py` fails with GPU OOM error. Because it transfer all the matrix data to the GPU initially.\r\n\r\n### example-1.py\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\nN=20000\r\nm=N\r\nn=N\r\nk=N\r\n\r\ntf.random.set_random_seed(1234)\r\nwith tf.device('/cpu:0'):\r\n  a1=tf.random.normal([m, k])\r\n  b1=tf.random.normal([k, n])\r\n\r\n  a2=tf.random.normal([m, k])\r\n  b2=tf.random.normal([k, n])\r\n\r\nwith tf.device('/gpu:0'):\r\n  c1=tf.matmul(a1, b1)\r\n  c2=tf.matmul(a2, b2)\r\n\r\nwith tf.device('/cpu:0'):\r\n  RESULT=tf.concat([c1, c2], 0)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\nstart=time.time()\r\na_out=sess.run(RESULT)\r\nprint(a_out.shape)\r\nprint(\"Time Taken: %s\" % str(time.time() - start))\r\n```\r\n\r\n### example-2.py\r\n```\r\nimport tensorflow as tf\r\nimport time\r\n\r\nN=20000\r\nm=N\r\nn=N\r\nk=N\r\n\r\ntf.random.set_random_seed(1234)\r\nwith tf.device('/cpu:0'):\r\n  a1=tf.random.normal([m, k])\r\n  b1=tf.random.normal([k, n])\r\n\r\n  a2=tf.random.normal([m, k])\r\n  b2=tf.random.normal([k, n])\r\n\r\nwith tf.device('/gpu:0'):\r\n  c1=tf.matmul(a1, b1)\r\n  c2=tf.matmul(a2, b2)\r\n\r\nwith tf.device('/cpu:0'):\r\n  RESULT=tf.concat([c1, c2], 0)\r\n\r\nwith tf.device('/cpu:0'):\r\n  a3=tf.random.normal([m, k])\r\n  b3=tf.random.normal([k, n])\r\n\r\n  a4=tf.random.normal([m, k])\r\n  b4=tf.random.normal([k, n])\r\n\r\nwith tf.device('/gpu:0'):\r\n  c3=tf.matmul(a3, b3)\r\n  c4=tf.matmul(a4, b4)\r\n\r\nwith tf.device('/cpu:0'):\r\n  tmp=tf.concat([c3, c4], 0)\r\n  RESULT=tf.concat([RESULT, tmp], 0)\r\n\r\nwith tf.device('/cpu:0'):\r\n  a5=tf.random.normal([m, k])\r\n  b5=tf.random.normal([k, n])\r\n\r\n  a6=tf.random.normal([m, k])\r\n  b6=tf.random.normal([k, n])\r\n\r\nwith tf.device('/gpu:0'):\r\n  c5=tf.matmul(a5, b5)\r\n  c6=tf.matmul(a6, b6)\r\n\r\nwith tf.device('/cpu:0'):\r\n  tmp=tf.concat([c5, c6], 0)\r\n  RESULT=tf.concat([RESULT, tmp], 0)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\nstart=time.time()\r\na_out=sess.run(RESULT)\r\nprint(a_out.shape)\r\nprint(\"Time Taken: %s\" % str(time.time() - start))\r\n```\r\n\r\n### Other Details:\r\n```\r\n$ python --version\r\nPython 3.6.8 :: Anaconda, Inc.\r\n$ python -c 'import tensorflow as tf; print(tf.__version__)'\r\n1.13.1\r\n$ cat /etc/lsb-release\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=18.04\r\nDISTRIB_CODENAME=bionic\r\nDISTRIB_DESCRIPTION=\"Ubuntu 18.04.2 LTS\"\r\n```\r\n\r\nThanks.\r\n", "comments": ["I have tried on colab with TF version 1.13.1 and was able to reproduce the issue.Please, find the [gist ](https://colab.research.google.com/drive/1xqa5oMMosbVUpbuNsdpyhDGrN8ql_bFG)here. Thanks!", "`help wanted`", "@asispatra Please check the detailed description on [performance of TF](https://www.tensorflow.org/guide/performance/overview) and [`using_gpu`](https://www.tensorflow.org/guide/using_gpu) on its website. There are many other resources on GitHub, Stackoverflow and elsewhere. Creating a TF data pipeline is one of the most important step when the data is too big.\r\n\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "@jvishnuvardhan, Thanks for pointing me to `performance of TF`, `using_gpu` and `Tf data pipeline`. In this issue I am not talking about `Build/Installation` or `Bug/Performance`.\r\n\r\nThrough the example i have just tried to show that in that particular case `example-2.py`, using tensorflow I may get GPU OOM error. Even this may occur for small size data where number of matrix multiplication will be more.\r\n\r\nI have asked the same question in the `big community` 5 days back. but have not get any reply.\r\nhttps://stackoverflow.com/questions/57330969/tensorflow-graph-execution-does-not-give-expected-result\r\n\r\nThanks.", "@asispatra Your `example-2.py` needs to be modified for performance through data pipeline. Please follow example in TF website and other places. I hope community will respond to you soon or else we might answer there. I am closing the issue here. Thanks!"]}, {"number": 31282, "title": "\"TypeError: expected str, bytes or os.PathLike object, not _io.BytesIO\" when trying to restore a model from a byte stream in tensorflow 2.0.0-beta0", "body": "in tensorflow version 2.0.0-alpha0 I was able to serialize and deserialize a model in memory by using the following code:\r\n\r\n```\r\n    def _serializeModel(self, model):\r\n        import h5py\r\n\r\n        with h5py.File('does not matter', driver='core', backing_store=False) as h5file:\r\n            model.save(h5file)\r\n            h5file.flush()\r\n            return h5file.id.get_file_image().hex()\r\n\r\n    def _restoreModel(self, serialized):\r\n        from tensorflow.keras.models import load_model\r\n        from io import BytesIO\r\n\r\n        return load_model(BytesIO(bytes.fromhex(serialized)))\r\n```\r\n\r\nfrom tensorflow 2.0.0-beta0, instead, the `restoreModel` function throws the error:\r\n\r\n```\r\n  File \"/usr/local/lib/python3.6/site-packages/statwolfml/models/base_model.py\", line 142, in train\r\n    self._model = self._restoreModel(self._model)\r\n  File \"/usr/local/lib/python3.6/site-packages/statwolfml/models/base_model.py\", line 165, in _restoreModel\r\n    return load_model(BytesIO(bytes.fromhex(serialized)))\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py\", line 136, in load_model\r\n    isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\r\n  File \"/usr/local/lib/python3.6/site-packages/h5py/_hl/base.py\", line 41, in is_hdf5\r\n    fname = os.path.abspath(fspath(fname))\r\nTypeError: expected str, bytes or os.PathLike object, not _io.BytesIO\r\n```\r\n\r\nDid you remove the support to byte stream or is this a bug?\r\n\r\nThanks\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): all\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: don't know\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): >= 2.0.0-beta0\r\n- Python version: 3.6\r\n", "comments": ["@helloIAmPau Will it possible to provide the full code to reproduce the reported issue. Thanks!", "@gadagashwini sure:\r\n\r\n```python\r\n#! /usr/bin/env python3\r\n\r\nimport tensorflow\r\nfrom tensorflow.keras.layers import Input, Dense\r\nfrom tensorflow.keras.models import Model, load_model\r\n\r\nfrom io import BytesIO\r\nimport h5py\r\n\r\ninputLayer = Input(batch_shape=(None, 5, 10))\r\nfinal = Dense(10)(inputLayer)\r\n\r\nmodel = Model(inputs=[ inputLayer ], outputs=[ final ])\r\nopt = tensorflow.optimizers.get({\r\n    'class_name': 'Adam',\r\n    'config': {}\r\n});\r\nmodel.compile(opt, loss='mean_squared_error', metrics=['mse'])\r\n\r\n# Serialization here works fine\r\nwith h5py.File('does not matter', driver='core', backing_store=False) as h5file:\r\n    model.save(h5file)\r\n    h5file.flush()\r\n    serialized = h5file.id.get_file_image().hex()\r\n\r\n# Deserialization here throws error for tf >= 2.0.0-beta0\r\nrestored = load_model(BytesIO(bytes.fromhex(serialized)))\r\n```", "@helloIAmPau Thanks for reproducible code.\r\nI am able to reproduce the issue on Colab with Tensorflow 2.0.0.beta1. Please take a look at gist [here](https://colab.research.google.com/drive/1uI3_BwH-HZ94j6LT8n_xwKNtp-Y2wDh9). Thanks! ", "I tried running the colab with `tensorflow==2.0.0-alpha0`, but the model was still unable to be loaded. `load_model`'s docstring states that it only supports:\r\n```\r\nfilepath: One of the following:\r\n          - String, path to the saved model\r\n          - `h5py.File` object from which to load the model\r\n```\r\n\r\nCan you try passing the h5 File object to load_model instead?", "@helloIAmPau, Did you try @k-w-w's comment.\r\nPlease close the issue if it was already resolved for you. Thanks!", "we changed the approach in our application. we don't need the fix anymore, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31282\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31282\">No</a>\n"]}, {"number": 31281, "title": "Running Tensorflow on CPU is faster than running it on GPU", "body": "I have an ASUS n552vw laptop that has a 4GB dedicated Geforce GTX 960M graphic card. I put these lines of code in the beginning of my code to compare training speed using GPU or CPU, and I saw it seems using the CPU wins!\r\n\r\nFor GPU:\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n    \r\n\r\nFor CPU:\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n    \r\n\r\nI have installed CUDA, cuDNN, tensorflow-gpu, etc to increase my training speed but seems inverse thing happened! \r\n\r\nWhen I try the first code, it says(before execution start):\r\n\r\n    Train on 2128 samples, validate on 22 samples\r\n    Epoch 1/1\r\n    2019-08-02 18:49:41.828287: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n    2019-08-02 18:49:42.457662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\n    name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176\r\n    pciBusID: 0000:01:00.0\r\n    totalMemory: 4.00GiB freeMemory: 3.34GiB\r\n    2019-08-02 18:49:42.458819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n    2019-08-02 18:49:43.776498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2019-08-02 18:49:43.777007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n    2019-08-02 18:49:43.777385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n    2019-08-02 18:49:43.777855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3050 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n    2019-08-02 18:49:51.834610: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library cublas64_100.dll locally\r\n\r\nAnd it's really slow ` [Finished in 263.2s]`, But when I try the second code it says:\r\n\r\n    Train on 2128 samples, validate on 22 samples\r\n    Epoch 1/1\r\n    2019-08-02 18:51:43.021867: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n    2019-08-02 18:51:43.641123: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n    2019-08-02 18:51:43.645072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: DESKTOP-UQ8B9FK\r\n    2019-08-02 18:51:43.645818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: DESKTOP-UQ8B9FK\r\n\r\nAnd it's much faster than the first code `[Finished in 104.7s]` ! How is it possible??\r\n\r\nThis is the part of code that is related to `Tensorflow` :\r\n\r\n    model = Sequential()\r\n    model.add((LSTM(un , return_sequences = True)))\r\n    model.add(Dropout(dp)) \r\n    \r\n    model.add((LSTM(un , return_sequences = True)))\r\n    model.add(Dropout(dp)) \r\n    \r\n    model.add((LSTM(un , return_sequences = True)))\r\n    model.add(Dropout(dp)) \r\n    \r\n    model.add((LSTM(un , return_sequences = True)))\r\n    model.add(Dropout(dp)) \r\n    \r\n    model.add((LSTM(un , return_sequences = False)))\r\n    model.add(Dropout(dp)) \r\n    \r\n    model.add(RepeatVector(rp))\r\n      \r\n    model.add((LSTM(un , return_sequences= True))) \r\n    model.add(Dropout(dp))   \r\n    \r\n    model.add((LSTM(un , return_sequences= True))) \r\n    model.add(Dropout(dp))\r\n    \r\n    model.add((LSTM(un , return_sequences= True))) \r\n    model.add(Dropout(dp))\r\n    \r\n    model.add((LSTM(un , return_sequences= True))) \r\n    model.add(Dropout(dp))\r\n    \r\n    model.add((LSTM(un , return_sequences= True))) \r\n    model.add(Dropout(dp))\r\n\r\n    model.add(TimeDistributed(Dense(ds))) ", "comments": ["Im getting a 60% performance \"boost\" without GPU!\r\nIm training on 2 different systems.  \r\nMy server, without a GPU:\r\n- Intel Core i5 6500T (4x@2.5 ghz) Notebook processor\r\n- Network attached storage for training data and output\r\n- 16 Gb DDR 3 Ram\r\n\r\nMy Desktop PC:\r\n- Intel core i7 3770k (4x3,5-4 ghz)\r\n- Nvidia GTX 970\r\n- 32gb ddr3 ram\r\n- Same training data on NAS\r\n\r\nNow interestingly 3000 epochs, 100000 records each takes roughly 3h on the server using TF 1.14\r\nThe same on my Desktop with GPU takes 8h with TF 2.0 \r\nIt clearly doesn't utilize my GPU properly. It sits with full Ram but at 3% graphical processor use. \r\nThe main processor is at 30% use while 100% with any CPU build.\r\n\r\nMy model is a fairly simple keras sequential lstm:\r\n\r\n```\r\nfor learningrate in learningrates:\r\n\tfor layerdensity in layerdensitys:\r\n\t\tfor layer in amount_of_layers:\r\n\t\t\t################################\r\n\t\t\t# generate model               #\r\n\t\t\t################################\r\n\t\t\tmodelname = f\"{layer}-layer_{layerdensity}-nodes_selu-adam_{learningrate}-learningrate_{records_per_epoch}-epochsize_{appendix}\"\r\n\t\t\tmodel = keras.Sequential()\r\n\t\t\t## layertypes ##\r\n\t\t\t# dense // general\r\n\t\t\t# convolutional; max pooling // image classification\r\n\t\t\t# CuDNNLSTM // long short term memory (cudnn gpu optimized otherwise just lstm) (same as dense just cudnn)\r\n\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu, input_dim=15))\r\n\t\t\tfor i in range(layer-1):\r\n\t\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu))\r\n\t\t\tmodel.add(Dense(9,activation=tf.nn.softmax, name = \"Output\"))\r\n\t\t\t# Compile\r\n\t\t\toptimizer = tf.keras.optimizers.Adam(lr=learningrate)\r\n\t\t\tmodel.compile(\r\n\t\t\t\toptimizer=optimizer,\r\n\t\t\t\tloss='sparse_categorical_crossentropy',\r\n\t\t\t\tmetrics=['accuracy'])\r\n\t\t\tmodel.summary()\r\n\t\t\ttensorboard = TensorBoard(log_dir=\"\\\\\\\\drg-fs01\\\\BigData\\\\Projects\\\\Notebooks\\\\PokerBot\\\\log\\\\\" + modelname,\r\n\t\t\t\thistogram_freq = 100, write_graph = False)\r\n            #cp_callback = tf.keras.callbacks.ModelCheckpoint(\"\\\\\\\\drg-fs01\\\\BigData\\\\Projects\\\\Notebooks\\\\PokerBot\\\\checkpoints\\\\\" + modelname, verbose=0)\r\n            ################################\r\n            # train model                  #\r\n            ################################\r\n\t\t\tmodel.fit(trainSet, \r\n\t\t\t\tepochs = epochs, \r\n\t\t\t\tsteps_per_epoch = trainSteps, \r\n\t\t\t\tshuffle = True, \r\n\t\t\t\tvalidation_data = testSet, \r\n\t\t\t\tvalidation_steps = testSteps, \r\n\t\t\t\tvalidation_freq = int(epochs/maxTestEpochs),\r\n\t\t\t\tverbose = verbose, \r\n\t\t\t\tcallbacks = [tensorboard])#,cp_callback])\r\n\t\t\tmodel.save(basePath+'saved_models/' + modelname + '.h5')\r\n```\r\nHow can I debug this?", "@rezaee Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@forReason Can you please post a new issue by providing the information asked by the [template](https://github.com/tensorflow/tensorflow/issues/new/choose)?\r\nThe reason for this is we can focus on your specific configuration and problem since the root cause can be unrelated even though the error messages are similar. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}]