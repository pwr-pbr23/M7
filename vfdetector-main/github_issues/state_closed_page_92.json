[{"number": 52399, "title": "[tensorflow/compiler/xla/tests/test_utils.cc] Add calls to `reserve()` before populating vectors", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": []}, {"number": 52398, "title": "[tensorflow/compiler/xla/tests/transfer_manager_test.cc] Add calls to `reserve()` before populating vectors", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": ["I won't review any change in a test file:\r\n1) this isn't worth anyone time\r\n2) I don't think we agree that this change is good in the first place.", "@joker-eph Ok your call. I don't work for Google I'm just a community contributor."]}, {"number": 52397, "title": "[tensorflow/compiler/xla/tests/vector_ops_simple_test.cc] Add calls to `reserve()` before populating vectors", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": []}, {"number": 52396, "title": "[tensorflow/compiler/xrt/kernels/xrt_execute_op.cc] Add calls to `reserve()` before populating vector", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": []}, {"number": 52395, "title": "[tensorflow/compiler/xrt/tests/raw_api_test.cc] Add calls to `reserve()` before populating vectors", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": ["> I'll defer to your judgement. But eventually someone will write a linter\u2014and maybe even a refactorer in LLVM's LibClang and/or LibTooling\u2014that will automatically insert these `.reserve` calls on every vector they aren't existent. And the number of lines this tool changes should be small compared to my original #51739\r\n>\r\n> (whereas if you don't merge these trivially correct occurrences, then it'll end up being too many SLoC)\r\n- #52462", "Closing, given consensus to not change tests."]}, {"number": 52394, "title": "[tensorflow/core/kernels/matmul_op_impl.h] Use correct size type for `batch_size`", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": []}, {"number": 52393, "title": "[tensorflow/lite/toco/graph_transformations/unroll_batch_matmul.cc] Add calls to `reserve()` before populating vectors", "body": "https://github.com/tensorflow/tensorflow/pull/51739#issuecomment-940389562 told me to split the larger PR into one PR per file; thus this (thanks `bash`, `git` and `gh`!)", "comments": []}, {"number": 52391, "title": "Training Object Detection model on Cloud VM error with TPU RET_CHECK failure", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud TPU VM default\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.6\r\n- Python version: default on TPU VM (3.8.10)\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: TPU\r\n\r\n\r\n**Describe the current behavior**\r\nI am running the EfficentdetD0 OD model installed from tensorflow/models. The model training fails with an error 'tensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure' although is saving a checkpoint. \r\n\r\n\r\nThe same model configuration runs OK on my local machine\r\nThe same model configuration trains OK when run using the cpu on the cloud VM (but slow) i.e. --use_tpu=false\r\nI have tried this using accelerator-type=v3-8 and 2-8 and in different regions\r\nFor some reason I cant create older version of the TPU/tf. the only version I can create is 2.6.0 or alpha, so have only tested against these.\r\nPython env: created via pip3 install -r /usr/share/tpu/models/official/requirements.txt\r\n\r\n**Describe the expected behavior**\r\nModel trains correctly using TPU\r\n\r\n**Standalone code to reproduce the issue**\r\nTPU VM created: gcloud alpha compute tpus tpu-vm  create efficientd0-2 --zone=us-central1-a --accelerator-type=v3-8 --version=tpu-vm-tf-2.6.0\r\nOD installed: git clone https://github.com/tensorflow/models.git\r\nudo protoc object_detection/protos/*.proto --python_out=.\r\nInstall TensorFlow Object Detection API.\r\ncp object_detection/packages/tf2/setup.py .\r\npip3 install --use-feature=2020-resolver .\r\n\r\nI need to run these for some reason:\r\nsudo apt-get update\r\napt install libgl1-mesa-glx\r\n\r\nThe command I am running is: python3 object_detection/model_main_tf2.py --pipeline_config_path=gs://cloudtest1bx/data/pipeline.config --model_dir=gs://cloudtest1bx/model --use_tpu=true --tpu_name=local --alsologtostderr\r\n\r\nStack trace\r\n2021-10-14 20:43:30.134769: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:263] Subgraph fingerprint:7734062378992412431\r\n2021-10-14 20:43:30.604562: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:263] Subgraph fingerprint:16822654659801201346\r\n2021-10-14 20:43:35.926086: E tensorflow/compiler/xla/status_macros.cc:56] Internal: RET_CHECK failure (tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass.cc:1777) arg_shape.handle_type != DT_INVALID  input edge: [id=19474 Func/while/body/_1/input/_2460:0 -> cluster_while_body_128945:1265]\r\n*** Begin stack trace ***\r\n        tensorflow::CurrentStackTrace[abi:cxx11]()\r\n\r\n        xla::status_macros::MakeErrorStream::Impl::GetStatus()\r\n        tensorflow::DistributedTPURewritePass::GetArgAndRetvalShapes(std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> > > > > const&, tensorflow::Node const&, tensorflow::DistributedTPURewritePass::ParameterInfo const&, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> >*, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> >*)\r\n        tensorflow::DistributedTPURewritePass::RewriteTPUReplicateNode(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::DeviceSet const&, tensorflow::Node*, tensorflow::FunctionLibraryDefinition*, tensorflow::FunctionLibraryRuntime*, tensorflow::Node*, std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > > > > const&, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > const&, absl::lts_20210324::node_hash_map<tensorflow::Node*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >, absl::lts_20210324::container_internal::HashEq<tensorflow::Node*, void>::Hash, absl::lts_20210324::container_internal::HashEq<tensorflow::Node*, void>::Eq, std::allocator<std::pair<tensorflow::Node* const, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> > > > >*, tensorflow::Graph*, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<tensorflow::InferredShape, std::allocator<tensorflow::InferredShape> > > > > const&, absl::lts_20210324::flat_hash_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::vector<std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > >, absl::lts_20210324::container_internal::StringHash, absl::lts_20210324::container_internal::StringHashEq::Eq, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::vector<std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > > > > > >*, long)\r\n        tensorflow::DistributedTPURewritePass::Run(tensorflow::GraphOptimizationPassOptions const&)\r\n        tensorflow::OptimizationPassRegistry::RunGrouping(tensorflow::OptimizationPassRegistry::Grouping, tensorflow::GraphOptimizationPassOptions const&)\r\n        tensorflow::ProcessFunctionLibraryRuntime::InstantiateMultiDevice(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)\r\n        tensorflow::ProcessFunctionLibraryRuntime::Instantiate(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::AttrSlice, tensorflow::FunctionLibraryRuntime::InstantiateOptions const&, unsigned long*)\r\n        tensorflow::KernelAndDeviceFunc::InstantiateFunc(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)\r\n        tensorflow::KernelAndDeviceFunc::Init(bool, tensorflow::NodeDef const&, tensorflow::GraphCollector*)\r\n\r\n\r\n        tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*)\r\n        tensorflow::EagerOperation::Execute(absl::lts_20210324::Span<tensorflow::AbstractTensorHandle*>, int*)\r\n        tensorflow::CustomDeviceOpHandler::Execute(tensorflow::ImmediateExecutionOperation*, tensorflow::ImmediateExecutionTensorHandle**, int*)\r\n        TFE_Execute\r\n        TFE_Py_ExecuteCancelable(TFE_Context*, char const*, char const*, absl::lts_20210324::InlinedVector<TFE_TensorHandle*, 4ul, std::allocator<TFE_TensorHandle*> >*, _object*, TFE_CancellationManager*, absl::lts_20210324::InlinedVector<TFE_TensorHandle*, 2ul, std::allocator<TFE_TensorHandle*> >*, TF_Status*)\r\n\r\n\r\n\r\n        PyCFunction_Call\r\n        _PyObject_MakeTpCall\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyFunction_Vectorcall\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyFunction_Vectorcall\r\n        _PyObject_FastCallDict\r\n        _PyObject_Call_Prepend\r\n\r\n        PyObject_Call\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyFunction_Vectorcall\r\n\r\n        PyObject_Call\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyObject_FastCallDict\r\n        _PyObject_Call_Prepend\r\n\r\n        _PyObject_MakeTpCall\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyFunction_Vectorcall\r\n        _PyEval_EvalFrameDefault\r\n        _PyFunction_Vectorcall\r\n        _PyEval_EvalFrameDefault\r\n        _PyFunction_Vectorcall\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        _PyFunction_Vectorcall\r\n        _PyEval_EvalFrameDefault\r\n\r\n        _PyEval_EvalFrameDefault\r\n        _PyEval_EvalCodeWithName\r\n        PyEval_EvalCode\r\n\r\n\r\n\r\n        PyRun_SimpleFileExFlags\r\n        Py_RunMain\r\n        Py_BytesMain\r\n        __libc_start_main\r\n        _start\r\n*** End stack trace ***\r\n\r\nTraceback (most recent call last):\r\n  File \"object_detection/model_main_tf2.py\", line 115, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/danbu/.local/lib/python3.8/site-packages/absl/app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"/home/danbu/.local/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"object_detection/model_main_tf2.py\", line 106, in main\r\n    model_lib_v2.train_loop(\r\n  File \"/home/danbu/.local/lib/python3.8/site-packages/object_detection/model_lib_v2.py\", line 678, in train_loop\r\n    losses_dict = _dist_train_step(train_input_iter)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3039, in __call__\r\n    return graph_function._call_flat(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (tensorflow/core/tpu/graph_rewrite/distributed_tpu_rewrite_pass.cc:1777) arg_shape.handle_type != DT_INVALID  input edge: [id=19474 Func/while/body/_1/input/_2460:0 -> cluster_while_body_128945:1265] [Op:__inference__dist_train_step_200662]\r\n", "comments": ["@danbull-lynker ,\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52391\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52391\">No</a>\n"]}, {"number": 52390, "title": "Fixed tfl.strided_slice lowering to tosa for negative stride", "body": "Negative strides should reverse those axis after the slice is performed.\r\nWe insert tosa.reverse operations after the slicing / reshaping work is\r\nfinished.", "comments": []}, {"number": 52389, "title": "Fixed tfl.strided_slice lowering to tosa for negative stride", "body": "Negative strides should reverse those axis after the slice is performed.\r\nWe insert tosa.reverse operations after the slicing / reshaping work is\r\nfinished.", "comments": []}, {"number": 52387, "title": "Multilingual Universal Sentence Encoder  Quantization-aware training error", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution: Ubuntu 20.04.2\r\n- TensorFlow installation : 2.6.0\r\n\r\n### 2. Code\r\n```\r\ndef create_model():        \r\n       hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\", input_shape=[], \r\n                           dtype=tf.string, trainable=False)\r\n        model = tf.keras.Sequential()\r\n        model.add(hub_layer)\r\n        model.add(tf.keras.layers.Dense(64, activation='relu'))\r\n        model.add(tf.keras.layers.Dense(1, activation='softmax'))\r\n        optimizer = SGD(lr=0.001, momentum=0.6, decay=1e-6)\r\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n        model.summary()\r\n        return model\r\n\r\ncustom_objects={'KerasLayer':hub.KerasLayer}        \r\nbase_model = create_model()\r\nwith tfmot.quantization.keras.quantize_scope(custom_objects):\r\n    q_model = tfmot.quantization.keras.quantize_model(base_model)\r\nq_model.compile(loss=self.model_param.loss, optimizer=optimizer, metrics=self.model_param.metrics)\r\n\r\nhistory = q_model.fit()\r\nq_model.save(model_file_name)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(q_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n    ]\r\nquantized_tflite_model = converter.convert()\r\n```\r\n\r\n\r\n### 3. Failure after conversion\r\nConversion failed at this part :\r\n```\r\nwith tfmot.quantization.keras.quantize_scope(custom_objects):\r\n    q_model = tfmot.quantization.keras.quantize_model(base_model)\r\n```\r\nBelow is the error message:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/user/quant_model_multilingual.py\", line 125, in qat\r\n    **q_model = tfmot.quantization.keras.quantize_model(base_model)**\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\", line 138, in quantize_model\r\n    **return quantize_apply(annotated_model)**\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py\", line 71, in inner\r\n    raise error\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py\", line 66, in inner\r\n    results = func(*args, **kwargs)\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\", line 436, in quantize_apply\r\n    transformed_model, layer_quantize_map = quantize_transform.apply(\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_layout_transform.py\", line 71, in apply\r\n    return model_transformer.ModelTransformer(\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer.py\", line 622, in transform\r\n    transformed_model = keras.Sequential.from_config(self._config,\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/sequential.py\", line 434, in from_config\r\n    model.add(layer)\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 530, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/sequential.py\", line 217, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 976, in __call__\r\n    return self._functional_construction_call(inputs, args, kwargs,\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1114, in _functional_construction_call\r\n    outputs = self._keras_tensor_symbolic_call(\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 848, in _keras_tensor_symbolic_call\r\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n  File \"/home/user/py38/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 888, in _infer_output_signature\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/home/user/py38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\n\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_layer.py:69 quantizer_fn  *\r\n        inputs, train_var,\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/keras/utils.py:54 smart_cond  *\r\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantizers.py:341 __call__  *\r\n        weights['max_var'],\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quant_ops.py:79 AllValuesQuantize  *\r\n        max_var,\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quant_ops.py:340 _FakeQuantWithMinMaxVars  *\r\n        inputs, min_var, max_var, num_bits=num_bits, narrow_range=narrow_range)\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:2890 fake_quant_with_min_max_vars  **\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    /home/user/py38/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:544 _apply_op_helper\r\n        raise TypeError(\"%s expected type of %s.\" %\r\n\r\n    TypeError: Input 'inputs' of 'FakeQuantWithMinMaxVars' Op has type string that does not match expected type of float32.\r\n```\r\n\r\n\r\nIt seems that the error is caused because \"multilingual universal sentence encoder\" has input type as tf.string, and the output to the dense layer is float32.\r\n\r\n\r\n", "comments": ["@ns-xinjun In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52387\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52387\">No</a>\n"]}, {"number": 52386, "title": "Improve overall readablity of code", "body": "Hi,\r\nI am trying to improve the overall readability of the code by correcting grammatical and spelling errors\r\n\r\nthanks", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52386) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "Thanks @gbaned ", "I want to address more corrections before merging\r\n\r\nThanks"]}, {"number": 52385, "title": "Push upper and lower limits of python deps for the open source people\u2026", "body": "\u2026 who might have a different version of the dep that still works. Dep versions are still pinned in CI\r\n\r\nPiperOrigin-RevId: 400270872\r\nChange-Id: Ibf2818764b402b99e637c7624f3af435e78b48b0", "comments": []}, {"number": 52384, "title": "Tensorflow 2.5 and above causes crash on load on Ubuntu 20.04", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): `sudo pip3 install tensorflow`\r\n- TensorFlow version: 2.5+\r\n- Python version: 3.8.10\r\n- Installed using virtualenv? pip? conda?: pip `sudo pip3 install tensorflow`\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): Not relevant, but `gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0`\r\n- CUDA/cuDNN version: Not installed\r\n- GPU model and memory: GeForce GTX 750 Ti [nouveau drivers installed, CUDA is NOT installed, not currently using the GPU]\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nIf I install Tensorflow 2.5 or above and then attempt to import it in a simple Python program, it causes an instant and highly reproducible crash.\r\n\r\nI don't care about GPU support. I just want to be able to use Tensorflow at all....\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFirst, install Tensorflow:\r\n\r\n```bash\r\nsudo pip3 install tensorflow==2.5\r\n```\r\n\r\nOR\r\n\r\n```bash\r\nsudo pip3 install tensorflow==2.6\r\n```\r\n\r\nOR\r\n\r\n```bash\r\nsudo pip3 install tensorflow\r\n```\r\n\r\nThen, create a simple test program:\r\n\r\n```python\r\n#/usr/bin/env python3\r\n\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n```\r\n\r\nFinally, chmod and run the test program:\r\n\r\n```bash\r\nchmod +x path/to/test.py\r\npath/to/test.py\r\n```\r\n\r\nSee crash.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nExample crash from tensorflow 2.5:\r\n\r\n```\r\n2021-10-14 16:46:53.912576: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-10-14 16:46:53.912599: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"./src/image_classifier.py\", line 10, in <module>\r\n    import tensorflow as tf\r\n  File \"/home/bryan-smithl/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 436, in <module>\r\n    _ll.load_library(_main_dir)\r\n  File \"/home/bryan-smithl/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 153, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow6StatusC1ENS_5error4CodeEN4absl14lts_2020_09_2311string_viewEOSt6vectorINS_10StackFrameESaIS7_EE\r\n````\r\n\r\nExample crash from Tensorflow 2.6:\r\n\r\n```\r\n2021-10-14 16:40:43.830370: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-10-14 16:40:43.830389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"./src/image_classifier.py\", line 10, in <module>\r\n    import tensorflow as tf\r\n  File \"/home/bryan-smithl/.local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 436, in <module>\r\n    _ll.load_library(_main_dir)\r\n  File \"/home/bryan-smithl/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 153, in load_library\r\n    py_tf.TF_LoadLibrary(lib)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE\r\n````\r\n\r\nTensorflow 2.4 and below work fine:\r\n\r\n```\r\n2021-10-14 16:53:07.554556: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-10-14 16:53:07.554582: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.4.1\r\n```", "comments": ["@sbrl \r\nPlease confirm if you have referred to [this guide](https://www.tensorflow.org/install/pip) and try:\r\nconda install cudatoolkit\r\n\r\nsimilar issue:#45930,[link](https://stackoverflow.com/questions/43162667/importerror-libcudart-so-8-0-cannot-open-shared-object-file-no-such-file-or-d) and let us know.", "> this guide\r\n\r\nThat's even worse. If I follow that guide to the letter, `tensorflow` fails to install:\r\n\r\n```\r\n$ pip3 install --user --upgrade tensorflow\r\nRequirement already satisfied: tensorflow in /home/bryan-smithl/.local/lib/python3.8/site-packages (2.4.1)\r\nCollecting tensorflow\r\n  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 458.4 MB 51 kB/s               \r\nCollecting grpcio<2.0,>=1.37.0\r\n  Downloading grpcio-1.41.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.9 MB 53.4 MB/s            \r\nRequirement already satisfied: numpy~=1.19.2 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.19.5)\r\nRequirement already satisfied: astunparse~=1.6.3 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\r\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\r\nRequirement already satisfied: flatbuffers~=1.12.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.12)\r\nRequirement already satisfied: absl-py~=0.10 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (0.12.0)\r\nCollecting h5py~=3.1.0\r\n  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.4 MB 66.5 MB/s            \r\nCollecting wheel~=0.35\r\n  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\r\nRequirement already satisfied: google-pasta~=0.2 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\r\nRequirement already satisfied: opt-einsum~=3.3.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\r\nRequirement already satisfied: termcolor~=1.1.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: keras~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.6.0)\r\nRequirement already satisfied: protobuf>=3.9.2 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (3.17.0)\r\nRequirement already satisfied: wrapt~=1.12.1 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\r\nCollecting gast==0.4.0\r\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\r\nRequirement already satisfied: clang~=5.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (5.0)\r\nRequirement already satisfied: typing-extensions~=3.7.4 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\r\nCollecting tensorboard~=2.6\r\n  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.8 MB 82.1 MB/s            \r\nCollecting tensorflow-estimator~=2.6\r\n  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 462 kB 46.6 MB/s            \r\nRequirement already satisfied: six~=1.15.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorflow) (1.15.0)\r\nRequirement already satisfied: werkzeug>=0.11.15 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.0)\r\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\r\nRequirement already satisfied: setuptools>=41.0.0 in ./lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (44.0.0)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.4)\r\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.30.0)\r\nRequirement already satisfied: markdown>=2.6.8 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\r\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/bryan-smithl/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\r\nERROR: Will not install to the user site because it will lack sys.path precedence to wheel in /home/bryan-smithl/Documents/venv-tensorflow/lib/python3.8/site-packages\r\n```\r\n\r\n> conda install cudatoolkit\r\n\r\nI don't have conda installed.\r\n\r\n> similar issue #45930,link\r\n\r\nNo helpful. Both of these are about CUDA support. I **do not care about CUDA or GPU support**.", "@sbrl \r\nCan you please confirm if you have verified the [system requirements](https://www.tensorflow.org/install/pip#system-requirements)\r\n\r\nAre you compilant with these steps?\r\n\r\nInstall the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. Starting with the TensorFlow 2.1.0 version, the msvcp140_1.dll file is required from this package (which may not be provided from older redistributable packages). The redistributable comes with Visual Studio 2019 but can be installed separately:\r\n\r\nGo to the Microsoft Visual C++ downloads,\r\nScroll down the page to the Visual Studio 2015, 2017 and 2019 section.\r\nDownload and install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 for your platform.\r\nMake sure long paths are enabled on Windows.\r\nInstall the 64-bit Python 3 release for Windows (select pip as an optional feature).\r\n", "After which  you may , Prepare  venv with this version and install tensorflow with pip inside the venv and let us know.", "> Install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019\r\n\r\nNo, I can't install that because I'm not running Windows @Saduf2019. As I've mentioned above, I am running **Ubuntu Linux**, not Windows.", "@sbrl \r\nRight sbrl can you confirm the remaining requirements are met.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52384\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52384\">No</a>\n", "I'm not sure what you're asking @Saduf2019. Can you clarify please?\r\n\r\nI tried a workaround [here](https://stackoverflow.com/a/67510891/1460422) (delete tensorflow/core/kernels/libtfkernel_sobol_op.so) which works, so this clearly indicates it's a bug in Tensorflow."]}, {"number": 52383, "title": "Inputs to eager execution function cannot be Keras symbolic tensors, Custom loss function, Tensorflow 2.3.0, Gradient Tape", "body": "I am trying to use a custom loss function in my `Keras` model (TensorFlow 2.3.0). This custom loss (ideally) will calculate the data loss plus the residual of a physical equation (say, diffusion equation, Navier Stokes, etc.). This residual error is based on the model output derivative wrt its inputs and I want to use `GradientTape`.\r\n\r\nIn this MWE, I removed the data loss term and other equation losses, and just used the derivative of the output wrt its first input. The dataset can be found [here][1]. \r\n\r\n    from numpy import loadtxt\r\n    from keras.models import Sequential\r\n    from keras.layers import Dense\r\n    import tensorflow as tf #tf.__version__ = '2.3.0'\r\n    # tf.compat.v1.disable_eager_execution()\r\n    \r\n    # load the dataset\r\n    dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\r\n    # split into input (X) and output (y) variables\r\n    X = dataset[:,0:8] #X.shape = (768, 8)\r\n    y = dataset[:,8]\r\n    \r\n    def customLoss(yTrue,yPred):\r\n        x_tensor = tf.convert_to_tensor(model.input, dtype=tf.float32)\r\n        x_tensor = tf.cast(x_tensor, tf.float32)\r\n        with tf.GradientTape() as t:\r\n            t.watch(x_tensor)\r\n            output = model(model.input)\r\n        DyDX = t.gradient(output, model.input)    \r\n        dy_t = DyDX[:, 1:2][0]\r\n        R_pred=dy_t\r\n        # loss_data = tf.reduce_mean(tf.square(yTrue - yPred), axis=-1)\r\n        loss_PDE = tf.reduce_mean(tf.square(R_pred))\r\n        return loss_PDE\r\n    \r\n    model = Sequential()\r\n    model.add(Dense(12, input_dim=8, activation='relu'))\r\n    model.add(Dense(12, activation='relu'))\r\n    model.add(Dense(1, activation='sigmoid'))\r\n    \r\n    model.compile(loss=customLoss, optimizer='adam', metrics=['accuracy'])\r\n    \r\n    model.fit(X, y, epochs=15, batch_size=10)\r\n\r\nAfter execution, I get this `_SymbolicException`:\r\n\r\n    _SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'dense_6_input:0' shape=(None, 8) dtype=float32>]\r\n\r\nWhen I uncomment `tf.compat.v1.disable_eager_execution()` (the fifth line), the issue seems to vanish and the model starts training. I was wondering why I am getting this `_SymbolicException` and how can I work it out without disabling eager execution. Any ideas? (By the way, I know questions similar to this have been posted, but they used `gradients `instead.)\r\n\r\n  [1]: https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv", "comments": ["Hi @MilowSa! Have you tried latest version 2.6 yet?", "I just tried 2.6.0 for `tf `and `keras`. I am getting another error now. Also, I modified the `GradientTape` input in the previous code. Here is the code that I am using:\r\n\r\n```\r\nfrom numpy import loadtxt\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nimport tensorflow as tf #tf.__version__ = '2.6.0'\r\n# tf.compat.v1.disable_eager_execution()\r\n# load the dataset\r\ndataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\r\n# split into input (X) and output (y) variables\r\nX = dataset[:,0:8] #X.shape = (768, 8)\r\ny = dataset[:,8]\r\n\r\ndef customLoss(yTrue,yPred):\r\n    x_tensor = tf.convert_to_tensor(model.input, dtype=tf.float32)\r\n    x_tensor = tf.cast(x_tensor, tf.float32)\r\n    with tf.GradientTape() as t:\r\n        t.watch(x_tensor)\r\n        output = model(x_tensor)\r\n    DyDX = t.gradient(output, x_tensor)    \r\n    dy_t = DyDX[:, 5:6][0]\r\n    R_pred=dy_t\r\n    # loss_data = tf.reduce_mean(tf.square(yTrue - yPred), axis=-1)\r\n    loss_PDE = tf.reduce_mean(tf.square(R_pred))\r\n    return loss_PDE\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(12, input_dim=8, activation='relu'))\r\nmodel.add(Dense(12, activation='relu'))\r\nmodel.add(Dense(12, activation='relu'))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\n\r\nmodel.compile(loss=customLoss, optimizer='adam', metrics=['accuracy'])\r\n\r\nmodel.fit(X, y, epochs=15, batch_size=10)\r\n```\r\n\r\n\r\nWhen I execute it, I get this `ValueError`:\r\n\r\n`ValueError: Passed in object of type <class 'keras.engine.keras_tensor.KerasTensor'>, not tf.Tensor`\r\n\r\nI believe it is the `t.watch(x_tensor)` line that is causing this `ValueError`, but I don't know why. [Here ](https://pastebin.com/BWb73yNy)is the full terminal output to the code above.", "Hi @MilowSa! \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) too.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52383\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52383\">No</a>\n"]}, {"number": 52382, "title": "AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'to_tensor'", "body": "**System information**\r\nTensorflow: 2.6.0\r\nThe problem arises running the example code provided in Hugging face in Keras/Tensorflow: https://huggingface.co/transformers/training.html\r\nPlatform: Google Colab (Public and Pro) (in all GPU, TPU and CPU)\r\nPython version: 3.7.12\r\n\r\n**Describe the current behavior**\r\nGetting this error when running the model:\r\n![image](https://user-images.githubusercontent.com/70186411/137340499-de614365-78db-4b52-b4ae-c533a87c505e.png)\r\n\r\n**Describe the expected behavior**\r\nSame model runs locally in Apple M1 system without errors.\r\nTwo days ago was running fine in Google Colab too. \r\nMaybe an update in the system?\r\n", "comments": ["I created the code below for reproducibility of the error. I hope you can shed some light on this:\r\n\r\n```\r\n!pip install transformers\r\n!pip install datasets\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom transformers import AutoTokenizer\r\nfrom datasets import Dataset\r\n\r\n# dummy sentences\r\nsentences = ['the house is blue and big', 'this is fun stuff','what a horrible thing to say']\r\n\r\n# create a pandas dataframe and converto to Hugging Face dataset\r\ndf = pd.DataFrame({'Text': sentences})\r\ndataset = Dataset.from_pandas(df)\r\n\r\n#download bert tokenizer\r\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n\r\n# tokenize each sentence in dataset\r\ndataset_tok = dataset.map(lambda x: tokenizer(x['Text'], truncation=True, padding=True, max_length=10), batched=True)\r\n\r\n# remove original text column and set format\r\ndataset_tok = dataset_tok.remove_columns(['Text']).with_format('tensorflow')\r\n\r\n# extract features\r\nfeatures = {x: dataset_tok[x].to_tensor() for x in tokenizer.model_input_names}\r\n```\r\n", "Both environments have tensorflow 2.6.0", "@sanatmpa1 Was able to reproduce the issue on Colab using TF v2.6.0 and tf-nightly on [cpu](https://colab.research.google.com/gist/sushreebarsa/ef878beaa24217fef6708942ca71c031/52382-cpu.ipynb) , [gpu](https://colab.research.google.com/gist/sushreebarsa/0b476e6f85d472bed639971e4611bd2b/52382-gpu.ipynb) and [tpu](https://colab.research.google.com/gist/sushreebarsa/9b95d5f69bcb9b6c97707c97302b3ccb/52382-tpu.ipynb) runtime ,Please find the attached gists for reference .Thank you!", "@ipietri,\r\n\r\nThe error here is reported because of `to_tensor` function, You are calling `to_tensor` on a object which is already a tensor by itself.\r\n\r\nIf you take a look at this [gist](https://colab.research.google.com/gist/sanatmpa1/3b37bc11497afccc13fb62ec76f75fc1/52382.ipynb), I modified this line `features = {x: dataset_tok[x].to_tensor() for x in tokenizer.model_input_names}` to this `features = {x: dataset_tok[x] for x in tokenizer.model_input_names}` i.e I removed `to_tensor()` and it worked fine. If you still want to use the tensor conversion, you can use [tf.convert_to_tensor](https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor). Let me know if it helps. Thanks!", "@sanatmpa1 Yes, that solves the problem. Thank you. I realize that the statement is redundant. I just want to point out that previous versions of TensorFlow do not throw an error in this scenario. I have a tf 2.6.0 version in my Apple M1 and it runs without throwing any error. Thanks a lot for your help", "@ipietri,\r\n\r\nGlad that it solves your problem, Also I have checked in TF 2.3 and 2.5, and the same Attribute error is thrown as expected, Take a look at the [gist here](https://colab.sandbox.google.com/gist/sanatmpa1/7a2252d61b9b56ea81751dbe07e2e215/52382.ipynb). If you have questions related to tensorflow on M1, please open a new issue on this [repo](https://github.com/apple/tensorflow_macos). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52382\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52382\">No</a>\n"]}, {"number": 52381, "title": "How to enable multi thread computing for tf.data", "body": "System: Ubuntu 20.04\r\nGPU/CUDA: RTX3090 CUDA10.1(must be upgraded)\r\nBefore Dataloader the data doesn't goes to the GPU. And i have read about, that df.data runs on cpu. And i have tried:\r\n\r\n```\r\ntf.config.threading.set_intra_op_parallelism_threads(64)\r\ntf.config.threading.set_inter_op_parallelism_threads(64)\r\n```\r\nbefore the code:\r\n`train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_lbl))`\r\nSince i ran the line, it always come to such warning:\r\n`W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7957118976 exceeds 10% of free system memory.`\r\nIs that because always max. 2 threads are used. (I have 64 threads cpu). Thanks for the help!", "comments": ["@yc0619 ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code  and the TensorFlow version you are using.Thanks!\r\n", "`df_train, df_val, df_test = shuffle_load.scannerdata_split(csv_paths, train_percentage, val_percentage)` \r\n(train, val, test images and labels are saved as dataframe)\r\n`train_data, train_lbl = utils.getDataLbl(df_train)\r\n    val_data, val_lbl = utils.getDataLbl(df_val)`\r\n(train_data, train_lbl as np array)\r\n`train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_lbl))\r\n train_loader = train_dataset.batch(batch_size=batch)\r\n val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_lbl))\r\n val_loader = val_dataset.batch(8)`\r\n\uff08in these line only 2 threads of cpu will be used, even if i used the code before\uff09\r\n`tf.config.threading.set_intra_op_parallelism_threads(64)\r\ntf.config.threading.set_inter_op_parallelism_threads(64)`\r\nafter dataloader i have used `mirrored_strategy = tf.distribute.MirroredStrategy()`\r\nand i have read about that tf.data is operated in cpu, so how can i enable the programm to load a big dataset to train and without sigkill 9?", "@yc0619 ,\r\nLooks like code is incomplete. Request you to provide complete code and tensorflow flow version to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "Sorry i am not allowed to give you the entire code. But i can tell you the workflow (these codes are right)\r\n1. in csv: data label, image path\r\n2. read csv to get dataframe, append image in dataframe\r\n3. from datafram get data, lbl and use tf.data.Dataset.from_tensor_slices((data, lbl))\r\nAnd in the third step, just 2 of cpu threads are used, but when i give the data and lbl (np.array) in model.fit, it could be run, but at validation, cpu are heavily used (2 of the 64 threads are used). So i would like to ask if there is some methode to enable me use other 10 or 20 more threads for the code.\r\n\r\nbest regards! :)", "@yc0619 ,\r\nWithout the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, could you please provide a complete code and the TensorFlow version you are using.Thanks!\r\n", "Also please take a look at this SO [link](https://stackoverflow.com/questions/47086599/parallelising-tf-data-dataset-from-generator) with the similar information.It helps.If you are unable to provide the reproducible code, please post this issue in tf discussion as this is not either feature or bug request.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52380, "title": "Meshgrid does not work with tf.function", "body": "The following code fails at runtime:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef f(x, y):\r\n    return tf.meshgrid(x, y)\r\n\r\n\r\n@tf.function\r\ndef g(x, y):\r\n    return tf.meshgrid(x, y)\r\n\r\n\r\ndef main():\r\n    print(f\"tensorflow version: {tf.version.VERSION}\")\r\n    all_values = tf.range(0.0, 1.0, .1)\r\n    x = y = tf.expand_dims(all_values, -1)\r\n\r\n    print(f(x, y))  # This works\r\n    print(g(x, y)) # This fails\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nThe output:\r\n\r\n```\r\n2021-10-14 12:51:02.388948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-14 12:51:03.952753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-10-14 12:51:04.028174: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2021-10-14 12:51:04.028234: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (removed): /proc/driver/nvidia/version does not exist\r\n2021-10-14 12:51:04.028962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\ntensorflow version: 2.5.1\r\n[<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\r\narray([[0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ],\r\n       [0.        , 0.1       , 0.2       , 0.3       , 0.4       ,\r\n        0.5       , 0.6       , 0.70000005, 0.8000001 , 0.9000001 ]],\r\n      dtype=float32)>, <tf.Tensor: shape=(10, 10), dtype=float32, numpy=\r\narray([[0.        , 0.        , 0.        , 0.        , 0.        ,\r\n        0.        , 0.        , 0.        , 0.        , 0.        ],\r\n       [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\r\n       [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\r\n        0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\r\n       [0.3       , 0.3       , 0.3       , 0.3       , 0.3       ,\r\n        0.3       , 0.3       , 0.3       , 0.3       , 0.3       ],\r\n       [0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\r\n        0.4       , 0.4       , 0.4       , 0.4       , 0.4       ],\r\n       [0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\r\n        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ],\r\n       [0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\r\n        0.6       , 0.6       , 0.6       , 0.6       , 0.6       ],\r\n       [0.70000005, 0.70000005, 0.70000005, 0.70000005, 0.70000005,\r\n        0.70000005, 0.70000005, 0.70000005, 0.70000005, 0.70000005],\r\n       [0.8000001 , 0.8000001 , 0.8000001 , 0.8000001 , 0.8000001 ,\r\n        0.8000001 , 0.8000001 , 0.8000001 , 0.8000001 , 0.8000001 ],\r\n       [0.9000001 , 0.9000001 , 0.9000001 , 0.9000001 , 0.9000001 ,\r\n        0.9000001 , 0.9000001 , 0.9000001 , 0.9000001 , 0.9000001 ]],\r\n      dtype=float32)>]\r\nTraceback (most recent call last):\r\n  File \"/mnt/workspace/tmp/pycharm_project_951/python_gamma/meshgrid_bug.py\", line 23, in <module>\r\n    main()\r\n  File \"/mnt/workspace/tmp/pycharm_project_951/python_gamma/meshgrid_bug.py\", line 19, in main\r\n    print(g(x, y))\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 764, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3289, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib64/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nNotImplementedError: in user code:\r\n\r\n    /mnt/workspace/tmp/pycharm_project_951/python_gamma/meshgrid_bug.py:11 g  *\r\n        return tf.meshgrid(x, y)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/array_ops.py:3644 meshgrid\r\n        mult_fact = ones(shapes, output_dtype)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/array_ops.py:3212 ones\r\n        output = _constant_if_small(one, shape, dtype, name)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2896 _constant_if_small\r\n        if np.prod(shape) < 1000:\r\n    <__array_function__ internals>:6 prod\r\n        \r\n    /mnt/workspace/python/numpy/core/fromnumeric.py:3052 prod\r\n        keepdims=keepdims, initial=initial, where=where)\r\n    /mnt/workspace/python/numpy/core/fromnumeric.py:86 _wrapreduction\r\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n    /usr/local/lib64/python3.7/site-packages/tensorflow/python/framework/ops.py:870 __array__\r\n        \" a NumPy call, which is not supported\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (meshgrid/Size_1:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n\r\nThis is running the AWS DLAMI for TF 2.5.1 using the following AMI: ami-09ddcd88a97c092e5. The EC2 instance type is a t3.small. ", "comments": ["After some digging it appears that this is related to a using a newer version of numpy. \r\n\r\n* 1.19.x works\r\n* 1.21.x does not work\r\n\r\nThis guess was inspired by this page: https://forum.nengo.ai/t/notimplementederror-cannot-convert-a-symbolic-tensor-tensorgraph-while-iteration-0-elementwiseincbuilder-meshgrid-size-0-to-a-numpy-array/1595", "Hi @aewhite! I replicated this issue in [TF 2.5 ](https://colab.research.google.com/gist/mohantym/30562f63284b726c041e69ee7f9b5a98/github_52380.ipynb#scrollTo=pkz0_fX7IMLq)with 1.21.2  , It is getting resolved in [TF 2.6 ](https://colab.research.google.com/gist/mohantym/cb25675b3a4ae62c33acef4876428c8d/github_52380.ipynb#scrollTo=vCxQQBCNJjgN)and [nightly](https://colab.research.google.com/gist/mohantym/9178834bcedb9e1e44272b8463cd8972/github_52380.ipynb#scrollTo=pkz0_fX7IMLq) . Numpy latest version 1.21.2 seems to be working in latest version now.  Thank you!", "I have a workaround for 2.5.x (downgrade numpy to 1.19) and I don't plan to update to 2.6 at the moment. Feel free to update this issue according to your process. ", "Ok! Closing this issue as it seems to be resolved ! Thanks !", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52380\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52380\">No</a>\n"]}, {"number": 52379, "title": "ctc_loss_calculator.h:499] No valid path found", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOs Big Sur 11.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0\r\n- Python version: 3.9.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nThe issue is addressed in multiple SO questions and none provides a clear solution if any answers at all\r\n\r\n - [CTC loss Tensorflow, No valid path found](https://stackoverflow.com/questions/47461331/ctc-loss-tensorflow-no-valid-path-found)\r\n - [ctc_loss error \"No valid path found.\"](https://stackoverflow.com/questions/45130184/ctc-loss-error-no-valid-path-found)\r\n - [CTC Loss bug: no valid path found? OCR difficulties in Tf.keras](https://stackoverflow.com/questions/64676073/ctc-loss-bug-no-valid-path-found-ocr-difficulties-in-tf-keras)\r\n - [Tensorflow ctc_loss_calculator: No valid path found](https://stackoverflow.com/questions/44195801/tensorflow-ctc-loss-calculator-no-valid-path-found)\r\n\r\nHere's the code I run ...\r\n\r\n    from itertools import groupby\r\n    from pathlib import Path\r\n    \r\n    import numpy as np\r\n    import tensorflow as tf\r\n    from matplotlib import pyplot as plt\r\n    from tensorflow.keras import Model\r\n    from tensorflow.keras.callbacks import EarlyStopping\r\n    from tensorflow.keras.layers import (LSTM, BatchNormalization, Bidirectional,\r\n                                         Conv2D, Dense, Input, Lambda, Layer,\r\n                                         MaxPool2D)\r\n    from tensorflow.keras.layers.experimental.preprocessing import StringLookup\r\n    from tensorflow.keras.optimizers import Adam\r\n    from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n    \r\n    \r\n    class CTCLayer(Layer):\r\n        def __init__(self, *args, **kwargs):\r\n            super().__init__(*args, **kwargs)\r\n            self.loss_fn = tf.keras.backend.ctc_batch_cost\r\n    \r\n        def call(self, y_true, *args, **kwargs):\r\n            y_pred = args[0]\r\n            batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\r\n            input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\r\n            label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\r\n            input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\r\n            label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\r\n            loss = self.loss_fn(y_true, y_pred, input_length, label_length)\r\n            self.add_loss(loss)\r\n            return y_pred\r\n    \r\n    \r\n    class TrainingManager:\r\n        def __init__(\r\n            self, images, labels, batch_size=256, validation_size=0.1, resize=(32, 128)\r\n        ):\r\n            self.images = images\r\n            self.labels = labels\r\n            self.batch_size = batch_size\r\n            self.validation_size = validation_size\r\n            self.resize = resize\r\n            self.vocabulary = sorted(set(''.join(self.labels)))\r\n            self.max_label_length = len(max(self.labels, key=len))\r\n            self.char_to_num = StringLookup(\r\n                vocabulary=self.vocabulary, num_oov_indices=0, mask_token=None\r\n            )\r\n            self.num_to_char = StringLookup(\r\n                vocabulary=self.char_to_num.get_vocabulary(), mask_token=None, invert=True\r\n            )\r\n    \r\n        def process_example(self, img_path, label):\r\n            img = tf.io.read_file(img_path)\r\n            img = tf.io.decode_png(img, channels=1)\r\n            img = tf.image.convert_image_dtype(img, tf.float32)\r\n            img = tf.image.resize(img, self.resize)\r\n            return {'image': img, 'label': label}\r\n    \r\n        def preview_dataset(self, dataset, n_rows, n_cols, fig_size=(15, 10)):\r\n            fig, ax = plt.subplots(n_rows, n_cols, figsize=fig_size)\r\n            for batch in dataset.take(1):\r\n                images = batch['image']\r\n                labels = batch['label']\r\n                for i in range(n_rows * n_cols):\r\n                    img = (images[i] * 255).numpy().astype('uint8')\r\n                    label = (\r\n                        tf.strings.reduce_join(self.num_to_char(labels[i] + 1))\r\n                        .numpy()\r\n                        .decode('utf-8')\r\n                        .replace('[UNK]', '')\r\n                    )\r\n                    ax[i // n_rows, i % n_cols].imshow(img[:, :, 0], cmap='gray')\r\n                    ax[i // n_rows, i % n_cols].set_title(label)\r\n                    ax[i // n_rows, i % n_cols].axis('off')\r\n    \r\n        def decode_predictions(self, predictions):\r\n            text_list = []\r\n            prediction_indices = np.argmax(predictions, axis=2)\r\n            for i in range(prediction_indices.shape[0]):\r\n                text = ''\r\n                for p, _ in groupby(prediction_indices[i]):\r\n                    if p != len(self.vocabulary):\r\n                        text += self.vocabulary[p]\r\n                text_list.append(text)\r\n            return text_list\r\n    \r\n        def create_dataset(self, x, y):\r\n            dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n            return (\r\n                dataset.map(\r\n                    self.process_example, num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n                )\r\n                .batch(self.batch_size)\r\n                .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n            )\r\n    \r\n        def split_data(self):\r\n            separation_idx = int(len(self.images) * (self.validation_size - 1))\r\n            train_images = self.images[:separation_idx]\r\n            valid_images = self.images[separation_idx:]\r\n            labels = [\r\n                self.char_to_num(tf.strings.unicode_split(label, input_encoding='UTF-8'))\r\n                for label in self.labels\r\n            ]\r\n            labels = pad_sequences(labels, self.max_label_length, padding='post')\r\n            train_labels = labels[:separation_idx]\r\n            valid_labels = labels[separation_idx:]\r\n            return train_images, valid_images, train_labels, valid_labels\r\n    \r\n        def create_datasets(self):\r\n            train_images, valid_images, train_labels, valid_labels = self.split_data()\r\n            train_dataset = self.create_dataset(train_images, train_labels)\r\n            valid_dataset = self.create_dataset(valid_images, valid_labels)\r\n            return train_dataset, valid_dataset\r\n    \r\n        def create_model(self, training=True):\r\n            x0 = Input(shape=(32, 128, 1), name='image')\r\n            x = Conv2D(32, (3, 3), activation='selu', padding='same')(x0)\r\n            x = MaxPool2D(pool_size=(2, 2))(x)\r\n            x = Conv2D(64, (3, 3), activation='selu', padding='same')(x)\r\n            x = MaxPool2D(pool_size=(2, 2))(x)\r\n            x = Conv2D(128, (3, 3), activation='selu', padding='same')(x)\r\n            x = Conv2D(128, (3, 3), activation='selu', padding='same')(x)\r\n            x = MaxPool2D(pool_size=(2, 1))(x)\r\n            x = Conv2D(256, (3, 3), activation='selu', padding='same')(x)\r\n            x = BatchNormalization()(x)\r\n            x = Conv2D(256, (3, 3), activation='selu', padding='same')(x)\r\n            x = BatchNormalization()(x)\r\n            x = MaxPool2D(pool_size=(2, 1))(x)\r\n            x = Conv2D(64, (2, 2), activation='selu')(x)\r\n            x = Lambda(lambda i: tf.squeeze(i, 1))(x)\r\n            x = Bidirectional(LSTM(128, return_sequences=True))(x)\r\n            x = Bidirectional(LSTM(128, return_sequences=True))(x)\r\n            output = Dense(len(self.vocabulary) + 1, activation='softmax', name='dense')(x)\r\n            if not training:\r\n                return Model(x0, output)\r\n            labels = Input(name='label', shape=(None,), dtype='float32')\r\n            output = CTCLayer(name='ctc_loss')(labels, output)\r\n            return Model(inputs=[x0, labels], outputs=output)\r\n    \r\n    \r\n    if __name__ == '__main__':\r\n        photos, texts = [], []\r\n        for line in open('labels.txt'):\r\n            photo_path, photo_text = line.split(',')\r\n            photos.append((Path('examples') / photo_path).as_posix())\r\n            texts.append(photo_text.strip())\r\n        manager = TrainingManager(photos, texts, batch_size=32)\r\n        optimizer = Adam()\r\n        model = manager.create_model()\r\n        model.compile(optimizer=optimizer, metrics=[tf.keras.metrics.Accuracy()])\r\n        model.summary()\r\n        tds, vds = manager.create_datasets()\r\n        manager.preview_dataset(tds, 2, 2)\r\n        plt.show()\r\n        history = model.fit(\r\n            tds,\r\n            epochs=100,\r\n            validation_data=vds,\r\n            verbose=1,\r\n            callbacks=[EarlyStopping(verbose=1, patience=3, restore_best_weights=True)],\r\n            shuffle=True,\r\n        )\r\n\r\n**`examples` + `labels.txt` (inside examples folder)**\r\n\r\n[examples.tar.gz](https://drive.google.com/file/d/1hBVhUNvlpwhENgLf5Ui_AS7eiSb_L39B/view?usp=sharing)\r\n\r\n**Note:** The code works perfectly fine for labels that are 15 characters long or shorter. The labels and respective photos in the example above have 1-20 characters each. What exactly do I need to modify, to make it work, given a label of length n? \r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n2021-10-14 05:22:31.610 Python[18731:595755] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/hr/61r_7jcx2r3cnklwrr2zwbqw0000gn/T/org.python.python.savedState\r\n    2021-10-14 05:22:31.746089: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n    Epoch 1/100\r\n    2021-10-14 05:22:41.480510: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:41.480551: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:41.480614: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:41.480785: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - ETA: 0s - loss: inf - accuracy: 0.0000e+002021-10-14 05:22:44.004554: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004595: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004646: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004705: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004822: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004859: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004890: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.004907: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005056: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005073: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005204: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005233: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005292: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.005322: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160657: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160745: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160787: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160862: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160886: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.160959: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161019: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161058: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161081: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161108: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161236: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161306: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161352: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161394: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161416: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161439: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161504: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.161650: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.315489: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.315528: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.315676: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.316045: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.316060: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.316151: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.316276: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.316282: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.467841: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.467882: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.467911: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468036: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468267: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468388: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468427: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468476: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468526: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468723: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.468737: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.510596: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - 9s 9s/step - loss: inf - accuracy: 0.0000e+00 - val_loss: inf - val_accuracy: 0.0000e+00\r\n    Epoch 2/100\r\n    2021-10-14 05:22:44.622235: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.622277: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.622401: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:44.622617: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - ETA: 0s - loss: inf - accuracy: 0.0000e+002021-10-14 05:22:45.075456: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075495: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075544: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075600: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075660: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075716: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075740: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075760: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075806: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075877: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.075995: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.076016: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.076178: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.076210: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234284: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234392: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234438: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234483: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234530: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234544: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234596: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234639: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234768: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234837: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234882: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234913: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234959: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.234991: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.235021: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.235153: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.235235: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.235299: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.391722: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.391763: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.391838: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.391867: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.391914: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.392013: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.392028: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.392276: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.545771: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.545837: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.545860: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546005: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546136: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546205: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546389: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546450: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546475: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546489: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.546529: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.587576: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - 1s 1s/step - loss: inf - accuracy: 0.0000e+00 - val_loss: inf - val_accuracy: 0.0000e+00\r\n    Epoch 3/100\r\n    2021-10-14 05:22:45.698230: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.698437: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.698533: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:45.698647: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - ETA: 0s - loss: inf - accuracy: 0.0000e+002021-10-14 05:22:46.127968: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128016: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128060: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128121: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128177: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128236: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128244: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128368: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128391: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128524: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128631: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128675: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128696: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.128926: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290187: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290274: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290309: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290390: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290411: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290485: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290545: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290574: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290605: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290663: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290756: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290822: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290884: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290895: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.290993: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.291033: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.291057: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.291095: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448088: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448374: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448476: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448486: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448636: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448658: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448730: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.448954: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.604924: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.604977: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.604992: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605256: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605280: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605321: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605429: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605523: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605583: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605591: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.605646: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    2021-10-14 05:22:46.646805: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.\r\n    1/1 [==============================] - 1s 1s/step - loss: inf - accuracy: 0.0000e+00 - val_loss: inf - val_accuracy: 0.0000e+00\r\n    Restoring model weights from the end of the best epoch.\r\n    Epoch 00003: early stopping\r\n", "comments": ["@schissmantics \r\nThis error is due to incorrect coding, it is not a bug from TF, there are few reasons [It turns out that the ctc_loss requires that the label lengths be shorter than the input lengths. If the label lengths are too long, the loss calculator cannot unroll completely and therefore cannot compute the loss.]\r\nPlease post this issue in tf discussion forum as there is a larger community to support there.", "ok, I closed the issue for being irrelevant.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52379\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52379\">No</a>\n"]}, {"number": 52378, "title": "GPU not found on Tensorflow 1.4.1", "body": "**System information**\r\n- Linux Ubuntu 20.04\r\n- tensorflow-gpu            1.4.1                    pypi_0    pypi\r\n- Python version: 2.7.15\r\n- Installed using virtualenv? pip? conda?:\r\n- CUDA/cuDNN version: CUDA version 8.0.61 with cuDNN version 6.0.21\r\n- 1x GTX 1080TI\r\n\r\n**The problem**\r\nI cannot run any scripts from GPU using tensorflow. When I run:\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\nprint(tf.test.gpu_device_name())\r\n```\r\nI get:\r\n```\r\n2021-10-14 11:35:56.443831: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2021-10-14 11:35:57.277446: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE\r\n2021-10-14 11:35:57.277535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: erwin-SYS\r\n2021-10-14 11:35:57.277557: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: erwin-SYS\r\n2021-10-14 11:35:57.277638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 470.74.0\r\n2021-10-14 11:35:57.277692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  470.74  Mon Sep 13 23:09:15 UTC 2021\r\nGCC version:  gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)\r\n\"\"\"\r\n2021-10-14 11:35:57.277742: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 470.74.0\r\n2021-10-14 11:35:57.277762: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 470.74.0\r\n''\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\nWhen I run nvidia-smi it does find the gpu:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 27%   26C    P8     6W / 180W |     14MiB /  8118MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n\r\n```\r\n", "comments": ["@erwinerdem ,\r\nWe see that you are using tf version 1.4, 1.x is not actively supported, please update to latest stable version 2.6 and let us know if you are using same issue.Thanks!", "@tilakrayal \nI need this specific version of Tensorflow as it required by an old project. Any idea what the problem could be?", "@erwinerdem ,\r\nPlease take a look at this [issue1](https://github.com/tensorflow/tensorflow/issues/38990), [issue2](https://github.com/tensorflow/tensorflow/issues/35195) with the similar error.Also  Its unlikely for TF 1.x version to receive any bug fixes except when we have security patches. There is a high possibility that this was fixed with later TF versions. Perhaps you can use latest tf versions for your case. Thanks!", "I didn't really solve the problem directly but I was able to get it working using a [docker image](https://hub.docker.com/layers/floydhub/tensorflow/1.4.1-gpu.cuda8cudnn6-py2_aws.19/images/sha256-eb47df096ed7d48b119d040744b29280a017910a3fe025bc32f0eb3b8d56fbde?context=explore).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52378\">No</a>\n"]}, {"number": 52377, "title": "Build libtensorflow-lite.a failed on centos 7 platform", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux CentOS 7):\r\n- TensorFlow installed from (source or binary):source \r\n- TensorFlow version:current master branch and r2.6\r\n- Python version:N/A\r\n- Installed using virtualenv? pip? conda?: compile from source code\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\ncmake ../tensorflow_src/tensorflow/lite return fail\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. git clone https://github.com/tensorflow/tensorflow.git tensorflow_src\r\n2. mkdir tflite_build\r\n3. cd tflite_build\r\n4. cmake ../tensorflow_src/tensorflow/lite  \r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\ner@RC802802663 tflite_build]$ cmake ../tensorflow_src/tensorflow/lite\r\n-- Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.\r\n[ 11%] Performing download step (git clone) for 'eigen-populate'\r\nCloning into 'eigen'...\r\nerror: RPC failed; result=22, HTTP code = 422\r\nfatal: the remote end hung up unexpectedly\r\nCloning into 'eigen'...\r\nerror: RPC failed; result=22, HTTP code = 422\r\nfatal: the remote end hung up unexpectedly\r\nCloning into 'eigen'...\r\nerror: RPC failed; result=22, HTTP code = 422\r\nfatal: the remote end hung up unexpectedly\r\n-- Had to git clone more than once:\r\n          3 times.\r\nCMake Error at tmp/eigen-populate-gitclone.cmake:31 (message):\r\n  Failed to clone repository: 'https://gitlab.com/libeigen/eigen'\r\n\r\n\r\ngmake[2]: *** [/home/80280266user/work/ubuntu/mylite/tflite_build/src/eigen-populate-stamp/eigen-populate-download] Error 1\r\ngmake[1]: *** [CMakeFiles/eigen-populate.dir/all] Error 2\r\ngmake: *** [all] Error 2\r\n\r\nCMake Error at /usr/local/share/cmake-3.18/Modules/FetchContent.cmake:987 (message):\r\n  Build step for eigen failed: 2\r\nCall Stack (most recent call first):\r\n  /usr/local/share/cmake-3.18/Modules/FetchContent.cmake:1082:EVAL:2 (__FetchContent_directPopulate)\r\n  /usr/local/share/cmake-3.18/Modules/FetchContent.cmake:1082 (cmake_language)\r\n  tools/cmake/modules/OverridableFetchContent.cmake:531 (FetchContent_Populate)\r\n  tools/cmake/modules/eigen.cmake:39 (OverridableFetchContent_Populate)\r\n  tools/cmake/modules/Findeigen.cmake:18 (include)\r\n  CMakeLists.txt:128 (find_package)\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/home/80280266user/work/ubuntu/mylite/tflite_build/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/home/80280266user/work/ubuntu/mylite/tflite_build/CMakeFiles/CMakeError.log\".\r\n[80280266user@RC802802663 tflite_build]$ \r\n\r\nsolution:\r\ner@RC802802663 tensorflow_src]$ git diff\r\ndiff --git a/tensorflow/lite/tools/cmake/modules/eigen.cmake b/tensorflow/lite/tools/cmake/modules/eigen.cmake\r\nindex 0b9080a476e..8879364bac2 100644\r\n--- a/tensorflow/lite/tools/cmake/modules/eigen.cmake\r\n+++ b/tensorflow/lite/tools/cmake/modules/eigen.cmake\r\n@@ -21,7 +21,7 @@ include(OverridableFetchContent)\r\n \r\n OverridableFetchContent_Declare(\r\n   eigen\r\n-  GIT_REPOSITORY https://gitlab.com/libeigen/eigen\r\n+  GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git\r\n   # Sync with tensorflow/third_party/eigen3/workspace.bzl\r\n   GIT_TAG 7b35638ddb99a0298c5d3450de506a8e8e0203d3\r\n   # It's not currently (cmake 3.17) possible to shallow clone with a GIT TAG\r\n[80280266user@RC802802663 tensorflow_src]$ \r\n\r\n\r\n", "comments": ["Hi @liuchang3! Have you followed instructions from  [here](https://www.tensorflow.org/lite/guide/build_cmake) ? ", "> Hi @liuchang3! Have you followed instructions from [here](https://www.tensorflow.org/lite/guide/build_cmake) ?\r\n\r\nyes, i follow that.\r\nit's compiled successfully on ubuntu 18.04\r\nbut failed on centos 7", "Hi @sachinprasadhs! Could you please look at this issue ?", "I think we've updated eigen tag. Do you still have the issue?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52377\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52377\">No</a>\n", "i check the modified code, it's solved now i think."]}, {"number": 52376, "title": "Run lite/tools/benchmark: setting use_hexagon to be true does not works.", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung, cpuinfo: \"Qualcomm Technologies, Inc KONA\"\r\n![image](https://user-images.githubusercontent.com/39039715/137239991-47fa8809-e78f-4955-99d3-ad3ff7ac0c6f.png)\r\n\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: commit id: 0088a1ada5a45c383e35c31ba7a552894936f998\r\n![image](https://user-images.githubusercontent.com/39039715/137240102-942e1b22-9a43-4734-b024-67ed8e7d324b.png)\r\n\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): bazel 3.7.2\r\n- GCC/Compiler version (if compiling from source): gcc (GCC) 7.3.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nRun lite/tools/benchmark: setting use_hexagon to be true does not works.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. Build from source:\r\n```\r\nbazel build -c opt --config=android_arm --distdir=/usr1/tf_downloads --repository_cache=/usr1/tf_downloads tensorflow/lite/tools/benchmark:benchmark_model\r\n```\r\n2. push `benchmark_model` and `libhexagon_interface.so` to the phone\r\n3. Run the model:\r\n```\r\n./benchmark_model --graph=video_infer.tflite --use_hexagon=true\r\n```\r\n\r\n```\r\nWARNING: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\n```\r\n\r\n![Snipaste_2021-10-14_10-14-07](https://user-images.githubusercontent.com/39039715/137240424-19c1b665-b485-4e38-b6bf-422dda385663.png)\r\n\r\n> `libhexagon_nn_skel.so` is in the path `/vendor/lib/rfsa/adsp`, which is read-only file system. \r\n\r\n4. To solve the problem in step3, I download `libhexagon_nn_skel.so` from the [document](https://www.tensorflow.org/lite/performance/hexagon_delegate). I download hexagon_nn_skel.run of v1.21. `/vendor/lib/rfsa/adsp`  is read-only file system, so I push the `libhexagon_nn_skel.so` to path  `/data/local/tmp/tf` \r\n\r\n```\r\nLD_PRELOAD=/data/local/tmp/tf/libhexagon_nn_skel.so ./benchmark_model --graph=video_infer.tflite --use_hexagon=true\r\n```\r\n\r\n```\r\nCANNOT LINK EXECUTABLE \"./benchmark_model\": \"/data/local/tmp/tf/libhexagon_nn_skel.so\" is for EM_??? (164) instead of EM_ARM (40)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/39039715/137242448-14680126-c881-4c38-b9e8-91f329764a78.png)\r\n\r\n\r\nHow can I run  `benchmark_model` with `use_hexagon=true`?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@yangruoqi Thanks for the report!\r\nWe see that you are using nightly version which is not a stable one could you please try to use TF **v2.6.0** and have a look at the guide to build from  [source,](https://www.tensorflow.org/install/source)[link](https://www.tensorflow.org/lite/performance/hexagon_delegate) for TF lite Hexagon.Please have a look at the [issue](https://github.com/tensorflow/tensorflow/issues/37506) for reference and let us know if it helps? Thank you!", "@sushreebarsa Thank you for your reply.\r\nI got the code from the r2.6 branch and recompiled it. I replaced the phone with a Samsung S9 (Inc SDM845) but still got the error.\r\n\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [mobilenet_v2_1.0_224_quant.tflite]\r\nUse Hexagon: [1]\r\nLoaded model mobilenet_v2_1.0_224_quant.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nloaded libcdsprpc.so\r\nFunc remote_handle_control not available on this device (NULL).\r\nWARNING: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\nINFO: Hexagon Delegate is not supported.\r\n\r\nCould not create Hexagon delegate: platform may not support delegate or required libraries are missing\r\nGoing to apply 0 delegates one after another.\r\nThe input model file size (MB): 3.57776\r\nInitialized session in 41.075ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\ncount=15 first=43572 curr=34309 min=34210 max=43572 avg=34953.2 std=2305\r\n\r\nRunning benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\r\ncount=50 first=34309 curr=34347 min=34182 max=34499 avg=34319.5 std=69\r\n\r\nInference timings in us: Init: 41075, First inference: 43572, Warmup (avg): 34953.2, Inference (avg): 34319.5\r\nNote: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\r\nPeak memory footprint (MB): init=3.58984 overall=7.78516\r\n```\r\n\r\nThis is my workspace on the phone, with benchmark_model and the *.so needed. \r\n![image](https://user-images.githubusercontent.com/39039715/137453210-fa9e2b6c-2568-404b-b7ce-a7d343b36a99.png)\r\n\r\n\r\nDid I choose the wrong unsupported  device?  Or is there any other reason?", "@yangruoqi \r\nCan you please confirm if you have followed this [guide](https://www.tensorflow.org/lite/performance/hexagon_delegate).\r\nThis issue is already reported and is in progress you may refer to:#45014", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52376\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52376\">No</a>\n", "If you're using benchmark tool push all your files to /data/local/tmp/  this is the default path the tool is configured to look for the shared libraries in."]}, {"number": 52375, "title": "meet error when i restore my model ", "body": "**when i restore my model i meet issues:\r\nNot found: Key g_/g_f_h0_lin/bias not found in checkpoint\r\nNot found: Key g_/g_f_h0_lin/Matrix not found in checkpoint\r\nNot found: Key g_/g_f_h0_lin/bias/Adam_1 not found in checkpoint**\r\n\r\n**I restore my model:**\r\nsaver = tf.train.Saver()\r\ncoord = tf.train.Coordinator()\r\n\r\nsess = tf.Session(config=config)\r\ninit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\nsess.run(init_op)\r\nsaver.restore(sess, os.path.join(checkpoint_dir,params.checkpoint))\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n**but  these param is not in my model**\r\n**here are my generator param:**\r\n('g_/BatchNorm/beta', [64])\r\n('g_/BatchNorm/beta/Adam', [64])\r\n('g_/BatchNorm/beta/Adam_1', [64])\r\n('g_/BatchNorm/moving_mean', [64])\r\n('g_/BatchNorm/moving_variance', [64])\r\n('g_/enc_bn2/beta', [128])\r\n('g_/enc_bn2/beta/Adam', [128])\r\n('g_/enc_bn2/beta/Adam_1', [128])\r\n('g_/enc_bn2/moving_mean', [128])\r\n('g_/enc_bn2/moving_variance', [128])\r\n('g_/enc_bn3/beta', [256])\r\n('g_/enc_bn3/beta/Adam', [256])\r\n('g_/enc_bn3/beta/Adam_1', [256])\r\n('g_/enc_bn3/moving_mean', [256])\r\n('g_/enc_bn3/moving_variance', [256])\r\n('g_/enc_bn4/beta', [512])\r\n('g_/enc_bn4/beta/Adam', [512])\r\n('g_/enc_bn4/beta/Adam_1', [512])\r\n('g_/enc_bn4/moving_mean', [512])\r\n('g_/enc_bn4/moving_variance', [512])\r\n('g_/enc_conv1/biases', [64])\r\n('g_/enc_conv1/biases/Adam', [64])\r\n('g_/enc_conv1/biases/Adam_1', [64])\r\n('g_/enc_conv1/filters', [4, 4, 4, 3, 64])\r\n('g_/enc_conv1/filters/Adam', [4, 4, 4, 3, 64])\r\n('g_/enc_conv1/filters/Adam_1', [4, 4, 4, 3, 64])\r\n('g_/enc_conv1/filters_init', [4, 4, 4, 3, 64])\r\n('g_/enc_conv2/biases', [128])\r\n('g_/enc_conv2/biases/Adam', [128])\r\n('g_/enc_conv2/biases/Adam_1', [128])\r\n('g_/enc_conv2/filters', [4, 4, 4, 64, 128])\r\n('g_/enc_conv2/filters/Adam', [4, 4, 4, 64, 128])\r\n('g_/enc_conv2/filters/Adam_1', [4, 4, 4, 64, 128])\r\n('g_/enc_conv2/filters_init', [4, 4, 4, 64, 128])\r\n('g_/enc_conv3/biases', [256])\r\n('g_/enc_conv3/biases/Adam', [256])\r\n('g_/enc_conv3/biases/Adam_1', [256])\r\n('g_/enc_conv3/filters', [4, 4, 4, 128, 256])\r\n('g_/enc_conv3/filters/Adam', [4, 4, 4, 128, 256])\r\n('g_/enc_conv3/filters/Adam_1', [4, 4, 4, 128, 256])\r\n('g_/enc_conv3/filters_init', [4, 4, 4, 128, 256])\r\n('g_/enc_conv4/biases', [512])\r\n('g_/enc_conv4/biases/Adam', [512])\r\n('g_/enc_conv4/biases/Adam_1', [512])\r\n('g_/enc_conv4/filters', [4, 4, 4, 256, 512])\r\n('g_/enc_conv4/filters/Adam', [4, 4, 4, 256, 512])\r\n('g_/enc_conv4/filters/Adam_1', [4, 4, 4, 256, 512])\r\n('g_/enc_conv4/filters_init', [4, 4, 4, 256, 512])\r\n('g_/g_f_bn0/beta', [512])\r\n('g_/g_f_bn0/beta/Adam', [512])\r\n('g_/g_f_bn0/beta/Adam_1', [512])\r\n('g_/g_f_bn0/moving_mean', [512])\r\n('g_/g_f_bn0/moving_variance', [512])\r\n('g_/g_f_bn1/beta', [256])\r\n('g_/g_f_bn1/beta/Adam', [256])\r\n('g_/g_f_bn1/beta/Adam_1', [256])\r\n('g_/g_f_bn1/moving_mean', [256])\r\n('g_/g_f_bn1/moving_variance', [256])\r\n('g_/g_f_bn2/beta', [128])\r\n('g_/g_f_bn2/beta/Adam', [128])\r\n('g_/g_f_bn2/beta/Adam_1', [128])\r\n('g_/g_f_bn2/moving_mean', [128])\r\n('g_/g_f_bn2/moving_variance', [128])\r\n('g_/g_f_bn3/beta', [64])\r\n('g_/g_f_bn3/beta/Adam', [64])\r\n('g_/g_f_bn3/beta/Adam_1', [64])\r\n('g_/g_f_bn3/moving_mean', [64])\r\n('g_/g_f_bn3/moving_variance', [64])\r\n('g_/g_f_h1/biases', [256])\r\n('g_/g_f_h1/biases/Adam', [256])\r\n('g_/g_f_h1/biases/Adam_1', [256])\r\n('g_/g_f_h1/filter_init', [4, 4, 4, 256, 512])\r\n('g_/g_f_h1/filters', [4, 4, 4, 256, 512])\r\n('g_/g_f_h1/filters/Adam', [4, 4, 4, 256, 512])\r\n('g_/g_f_h1/filters/Adam_1', [4, 4, 4, 256, 512])\r\n('g_/g_f_h2/biases', [128])\r\n('g_/g_f_h2/biases/Adam', [128])\r\n('g_/g_f_h2/biases/Adam_1', [128])\r\n('g_/g_f_h2/filter_init', [4, 4, 4, 128, 256])\r\n('g_/g_f_h2/filters', [4, 4, 4, 128, 256])\r\n('g_/g_f_h2/filters/Adam', [4, 4, 4, 128, 256])\r\n('g_/g_f_h2/filters/Adam_1', [4, 4, 4, 128, 256])\r\n('g_/g_f_h3/biases', [64])\r\n('g_/g_f_h3/biases/Adam', [64])\r\n('g_/g_f_h3/biases/Adam_1', [64])\r\n('g_/g_f_h3/filter_init', [4, 4, 4, 64, 128])\r\n('g_/g_f_h3/filters', [4, 4, 4, 64, 128])\r\n('g_/g_f_h3/filters/Adam', [4, 4, 4, 64, 128])\r\n('g_/g_f_h3/filters/Adam_1', [4, 4, 4, 64, 128])\r\n('g_/g_f_h4/biases', [3])\r\n('g_/g_f_h4/biases/Adam', [3])\r\n('g_/g_f_h4/biases/Adam_1', [3])\r\n('g_/g_f_h4/filter_init', [4, 4, 4, 3, 64])\r\n('g_/g_f_h4/filters', [4, 4, 4, 3, 64])\r\n('g_/g_f_h4/filters/Adam', [4, 4, 4, 3, 64])\r\n('g_/g_f_h4/filters/Adam_1', [4, 4, 4, 3, 64])\r\n\r\n\r\n", "comments": ["@OnlyFlashEobard ,\r\n In order to expedite the trouble-shooting process, could you please provide a minimal code snippet and the TensorFlow version you are using.\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@OnlyFlashEobard ,\r\nPlease take a look at this [comment](https://github.com/tensorflow/models/issues/5003#issuecomment-485274023) from the issue with the similar error.It helps.Thanks!", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52374, "title": "Added lowering for tfl.pad_v2 to tosa.concat operations", "body": "tfl.pad_v2 requires specifying the pad value. Tosa.pad defaults to zero so the\r\neasiest method to pad is to concat the values together. This should work for\r\nmost static cases and some dynamic cases.", "comments": []}, {"number": 52373, "title": "TensorFlow Lite Build and Linker issues in 2.4 -> 2.8 versions", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.4 -> 2.8\r\n- Python version: 3.x\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: AMD Radeon series\r\n\r\nI pulled a number of versions starting with 2.4 to 2.8 or so and couldn't seem to get the tflite minimal example to build on my own.  I am linking to the libtensorflow-lite.a fine but it is producing strange linker errors with ruy library, even though I am explicitly building it with -DTFLITE_ENABLE_RUY=Off.  I cleaned a million times and it just includes ruy references without being compiled for it.\r\n\r\ncmake ../tensorflow/lite -DTFLITE_ENABLE_RUY=OFF -DTFLITE_ENABLE_NNAPI=OFF -DTFLITE_ENABLE_GPU=OFF -DTFLITE_ENABLE_XNNPACK=OFF -DTFLITE_ENABLE_MMAP=OFF\r\n\r\nmake\r\n\r\nIt seems to build ruy right away here:\r\n$ make\r\n[  0%] Building CXX object _deps/ruy-build/CMakeFiles/ruy.dir/__/__/ruy/ruy/allocator.cc.o\r\n[  0%] Building CXX object _deps/ruy-build/CMakeFiles/ruy.dir/__/__/ruy/ruy/apply_multiplier.cc.o\r\n[  0%] Building CXX object _deps/ruy-build/CMakeFiles/ruy.dir/__/__/ruy/ruy/block_map.cc.o\r\n[  0%] Building CXX object _deps/ruy-build/CMakeFiles/ruy.dir/__/__/ruy/ruy/blocking_counter.cc.o\r\n[  0%] Building CXX object _deps/ruy-build/CMakeFiles/ruy.dir/__/__/ruy/ruy/cont\r\n...\r\n\r\nAnd when I link against the libtensorflow-lite.a library I get these:\r\nUndefined symbol: ruy::ThreadPool::ExecuteImpl(int, int, ruy::Task*)\r\nUndefined symbol: ruy::Kernel8bitAvx(ruy::KernelParams8bit<8, 8> const&)\r\nUndefined symbol: ruy::Kernel8bitAvx2(ruy::KernelParams8bit<8, 8> const&)\r\nUndefined symbol: ruy::KernelFloatAvx(ruy::KernelParamsFloat<8, 8> const&)\r\nUndefined symbol: ruy::KernelFloatAvx2(ruy::KernelParamsFloat<8, 8> const&)\r\nUndefined symbol: ruy::Kernel8bitAvx512(ruy::KernelParams8bit<16, 16> const&)\r\n...", "comments": ["Hi @krworks! Could you please look at these threads  for answer? [Link1](https://github.com/tensorflow/tensorflow/issues/39478),[Link2](https://stackoverflow.com/questions/63609132/what-is-a-proper-command-to-build-tensorflow-lite-c-api-for-macos),[Link3](https://www.tensorflow.org/lite/guide/build_cmake)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52373\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52373\">No</a>\n"]}, {"number": 52371, "title": "Allow to apply tf-promote-resources-to-args on any function", "body": "Allow to specify on which function apply --tf-promote-resources-to-args, with the following command line : `tf-opt --tf-promote-resources-to-args=functions=\"func1,func2\" myfile.mlir`\r\nThe initial behaviour is not broken : --tf-promote-resources-to-args alone still applies on the function \"main\".\r\nRelative to the discussion on the forum [here](https://discuss.tensorflow.org/t/promote-resources-to-args-with-tf-opt/4915/3)", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52371) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "Thanks! Just a few minors things inline."]}, {"number": 52370, "title": "SavedModel Loading Issue - '_UserObject' object has no attribute 'add_slot'", "body": "Some models that used to be working in TensorFlow 2.5 are now impossible to load with TF 2.6 and onward.\r\n\r\nGoogle Colab to reproduce the issue: https://colab.research.google.com/drive/1n_FY1YNBDaWd43SJI8oxjHPEsA32FPEV?usp=sharing\r\n\r\nScript:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.saved_model import tag_constants\r\n\r\nprint(\"TF Version:\", tf.__version__)\r\n\r\nsaved_model_loaded = tf.saved_model.load(\r\n    \"resnet_v1.5_50_tfv2\", tags=[tag_constants.SERVING]\r\n)\r\n\r\nprint(\"Success !\")\r\n```\r\n\r\nError:\r\n```python\r\nAttributeError                            Traceback (most recent call last)\r\n\r\n<ipython-input-2-714dfc7741a0> in <module>()\r\n      5 \r\n      6 saved_model_loaded = tf.saved_model.load(\r\n----> 7     \"resnet_v1.5_50_tfv2\", tags=[tag_constants.SERVING]\r\n      8 )\r\n      9 \r\n\r\n4 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py in _load_nodes(self)\r\n    446         optimized_variable = nodes[\r\n    447             slot_variable_proto.original_variable_node_id]\r\n--> 448         slot_variable = optimizer_object.add_slot(\r\n    449             var=optimized_variable,\r\n    450             slot_name=slot_variable_proto.slot_name)\r\n\r\nAttributeError: '_UserObject' object has no attribute 'add_slot'\r\n```", "comments": ["@DEKHTIARJonathan Was able to reproduce the issue on colab using TF [v2.6](https://colab.research.google.com/gist/sushreebarsa/17029aa9e6effca91060480dfffeccb4/untitled467.ipynb) but the issue is not replicating in [tf-nightly ](https://colab.research.google.com/gist/sushreebarsa/b3c5cd4a4c7922f346cb5307039d9367/untitled468.ipynb#scrollTo=eRSv8cOXzDns)version 2.8.0-dev20211012,Could you please find the attached gists and confirm the same ? This issue seems to be fixed in recent nightly version .Thank you!", "@sushreebarsa indeed looks like the issue is fixed in the nightly.\r\nAny chance you could point me to the commit that fixed the issue ?", "@DEKHTIARJonathan Could you please find the latest  [commit](https://github.com/tensorflow/tensorflow/commit/59e882af21831eea9e24d74c9af4242cc1514c6e) reference and let us know if it helps ?\r\nPlease move this issue to closed status if it is resolved for you.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52370\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52370\">No</a>\n", "@DEKHTIARJonathan \r\nI had the same issue. I loaded the model in the same notebook that I was trying to load the saved_model and solved the problem. I assume TensorFlow recognizes the used objects in RAM and it prevents further errors. ", "I also encounter this issue. \r\nWith all the respect but this issue is not solved as the problem is still there in all of the versions of 2.6 (2.6.0, 2.6.1, 2.6.2), it does indeed work for 2.7, but this version comes with other changes which might not be suitable for everybody. \r\nI don't think ``nighly`` is the version which you can safely run on production,  which means that basically saving does not work and issue is not solved. \r\n@pooya-mohammadi loading in the very same notebook is not always possible, for instance when you try to optimize the model for production hardware and methods under the hood actually load graph via ``tf.saved_model.load(..)``. \r\nAfter some investigation I found a few things:\r\n- Loading model (``tf.saved_model.load(...)``) works somehow if you add an import ``import tensorflow_io as tfio``, but that's might be specific for my model. \r\n- It is not always possible to add to runtime ``tensorflow_io`` so I also tried saving the model after training without the optimizer(``tf.keras.models.save_model( ...,include_optimizer=False)``) which also worked. \r\n\r\nThis makes me believe that there is some problem with the graph, optimizer itself and its scope while saving a model. The issue is somehow solved on TF-2-7. \r\nI will try to add Colab with a meaningful example soon, but ofc it will need to be restarted between saving the model and loading it, to simulate the behaviour of saving and loading in different notebooks (different kernel/scope). ", "@rpytel1 Tnx for sharing. I had a custom layer in my network, which I knew would cause errors, and indeed it did. How about your optimizer? Is it a custom or one of the pre-defined ones? \r\n  ", "@pooya-mohammadi I use only ``tf.keras.optimizers.Adam`` with ``tf.keras.experimental.CosineDecay`` learning rate. But indeed I do have some custom layers. Also as stated on multiple other similar issues, this used to work earlier (i.e. TF-2.3.4) without adding anything to ``custom_object`` flags.", "I have same problem, in TF2.6. But, I fix it just need append\r\n`from tensorflow.keras import Model`\r\n\r\nhope it's useful for you."]}, {"number": 52369, "title": "Update Readme - minor format change", "body": null, "comments": []}, {"number": 52368, "title": "keras.models.load_model resets the optimizer's state", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `yes, mostly based on the example from https://www.tensorflow.org/guide/keras/save_and_serialize`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab (`Linux 59a52e5448f6 5.4.104+ #1 SMP Sat Jun 5 09:50:34 PDT 2021 x86_64 x86_64 x86_64 GNU/Linux`)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `no`\r\n- TensorFlow installed from (source or binary): `google colab version`\r\n- TensorFlow version (use command below): `v2.6.0-0-g919f693420e 2.6.0`\r\n- Python version: `3.7.12 (default, Sep 10 2021, 00:21:48)  [GCC 7.5.0]`\r\n- Bazel version (if compiling from source): `no`\r\n- GCC/Compiler version (if compiling from source): `no`\r\n- CUDA/cuDNN version: `11.2`\r\n- GPU model and memory: `Tesla K80, 11441MiB`\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen restoring a keras model with `keras.models.load_model`, the returned model's optimizer is in the reset state (e.g. its `weights` attribute is empty).\r\n\r\n**Describe the expected behavior**\r\n\r\nThe original call:\r\n```python\r\nreconstructed_model = tf.keras.models.load_model(\"my_model\")\r\n```\r\nshould have restored and kept the optimizer's weights.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): `no`\r\n- Briefly describe your candidate solution(if contributing): `-`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef get_model():\r\n    # Create a simple model.\r\n    inputs = tf.keras.Input(shape=(32,))\r\n    outputs = tf.keras.layers.Dense(1)(inputs)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\r\n    return model\r\n\r\n\r\nmodel = get_model()\r\n\r\n# Train the model.\r\ntest_input = np.random.random((128, 32))\r\ntest_target = np.random.random((128, 1))\r\nmodel.fit(test_input, test_target)\r\n\r\n# Calling `save('my_model')` creates a SavedModel folder `my_model`.\r\nmodel.save(\"my_model\")\r\n\r\n# It can be used to reconstruct the model identically.\r\nreconstructed_model = tf.keras.models.load_model(\"my_model\")\r\n\r\nprint(reconstructed_model.optimizer.weights)\r\n```\r\noutput:\r\n> 4/4 [==============================] - 1s 4ms/step - loss: 0.1829\r\nINFO:tensorflow:Assets written to: my_model/assets\r\n[]\r\n\r\nIf we additionally provide a `compile=False` argument, the optimizer's weights are restored:\r\n```python\r\nreconstructed_model = tf.keras.models.load_model(\"my_model\", compile=False)\r\nfor w in reconstructed_model.optimizer.weights:\r\n    print(w.shape)\r\n```\r\noutput:\r\n>(32, 1)\r\n(1,)\r\n(32, 1)\r\n(1,)\r\n\r\nHowever, trying to use the restored optimizer fails with an exception:\r\n\r\n```python\r\nreconstructed_model.compile(reconstructed_model.optimizer, loss=\"mean_squared_error\")\r\nreconstructed_model.fit(test_input, test_target)\r\n```\r\noutput:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-3-22a4ff24818b> in <module>()\r\n      1 reconstructed_model.compile(reconstructed_model.optimizer, loss=\"mean_squared_error\")\r\n----> 2 reconstructed_model.fit(test_input, test_target)\r\n\r\n9 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    992           except Exception as e:  # pylint:disable=broad-except\r\n    993             if hasattr(e, \"ag_error_metadata\"):\r\n--> 994               raise e.ag_error_metadata.to_exception(e)\r\n    995             else:\r\n    996               raise\r\n\r\nNotImplementedError: in user code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:791 train_step\r\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\r\n    /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:522 minimize\r\n        return self.apply_gradients(grads_and_vars, name=name)\r\n    /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:660 apply_gradients\r\n        apply_state)\r\n    /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:707 _distributed_apply\r\n        var, apply_grad_to_update_var, args=(grad,), group=False)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2595 update\r\n        var, fn, args=args, kwargs=kwargs, group=group)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2473 _replica_ctx_update\r\n        return replica_context.merge_call(merge_fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3064 merge_call\r\n        return self._merge_call(merge_fn, args, kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3071 _merge_call\r\n        return merge_fn(self._strategy, *args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2471 merge_fn  **\r\n        return self.update(var, fn, merged_args, merged_kwargs, group=group)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2592 update\r\n        return self._update(var, fn, args, kwargs, group)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3646 _update\r\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3652 _update_non_slot\r\n        result = fn(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:689 apply_grad_to_update_var  **\r\n        update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:1241 _resource_apply_dense\r\n        raise NotImplementedError(\"Must be implemented in subclasses.\")\r\n\r\n    NotImplementedError: Must be implemented in subclasses.\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@SiLiKhon ,\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "@tilakrayal \r\nThanks and sorry for having missed the migration...\r\nIssue posted.", "@SiLiKhon ,\r\nPlease feel free to close this issue, so that we can track the issue there.Thanks!", "@tilakrayal \r\nSure, closing it here.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52368\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52368\">No</a>\n"]}, {"number": 52367, "title": "[ROCM] enable QR_op on ROCM", "body": "This PR enables the QR op on the rocm platform.", "comments": ["@cheshire @chsigg gentle ping", "@gbaned @chsigg Let me know if there is anything I should address", "@cheshire @chsigg any news on this PR?", "@cheshire @stevenireeves changes implemented.", "@cheshire can we get another look at this? ", "@cheshire gentle nudge on this one. thx!", "@chsigg \r\n\r\nThe macos error doesnot seem to have anything to do with our change\r\n\r\n``` ERROR: /Volumes/BuildData/tmpfs/tmp/bazel/external/build_bazel_rules_apple/tools/realpath/BUILD:9:14: in _apple_genrule_inner rule @build_bazel_rules_apple//tools/realpath:realpath_genrule:\r\nTraceback (most recent call last):\r\n\tFile \"/Volumes/BuildData/tmpfs/tmp/bazel/external/build_bazel_apple_support/rules/apple_genrule.bzl\", line 78, column 28, in _apple_genrule_impl\r\n\t\tapple_support.run_shell(\r\n\tFile \"/Volumes/BuildData/tmpfs/tmp/bazel/external/build_bazel_apple_support/lib/apple_support.bzl\", line 339, column 26, in _run_shell\r\n\t\tctx.actions.run_shell(**_kwargs_for_apple_platform(ctx, **kwargs))\r\nError in run_shell: 'command' must be of type string. passing a sequence of strings as 'command' is deprecated. To temporarily disable this check, set --incompatible_run_shell_command_string=false.\r\nINFO: Repository remote_java_tools_darwin instantiated at:\r\n```\r\n\r\nSamething for tflite tests\r\n\r\n```   external/local_config_cc/wrapped_clang '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG '-DNS_BLOCK_ASSERTIONS=1' '-std=c++11' -fdebug-compilation-dir . -iquote . -iquote bazel-out/darwin-opt/bin -iquote external/com_google_absl -iquote bazel-out/darwin-opt/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/darwin-opt/bin/external/eigen_archive -iquote external/nsync -iquote bazel-out/darwin-opt/bin/external/nsync -isystem external/eigen_archive -isystem bazel-out/darwin-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/darwin-opt/bin/external/nsync/public -MD -MF bazel-out/darwin-opt/bin/tensorflow/core/common_runtime/_objs/cost_util/cost_util.d -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-frandom-seed=bazel-out/darwin-opt/bin/tensorflow/core/common_runtime/_objs/cost_util/cost_util.o' -isysroot __BAZEL_XCODE_SDKROOT__ -F__BAZEL_XCODE_SDKROOT__/System/Library/Frameworks -F__BAZEL_XCODE_DEVELOPER_DIR__/Platforms/MacOSX.platform/Developer/Library/Frameworks '-mmacosx-version-min=10.14' -DGRPC_BAZEL_BUILD -w '-std=c++14' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/common_runtime/cost_util.cc -o bazel-out/darwin-opt/bin/tensorflow/core/common_runtime/_objs/cost_util/cost_util.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nclang: error: unknown argument: '-fdebug-compilation-dir'\r\nERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/core/lib/strings/BUILD:36:11: Compiling tensorflow/core/lib/strings/ordered_code.cc failed: (Exit 1): wrapped_clang failed: error executing command  ```"]}]