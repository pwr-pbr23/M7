[{"number": 39989, "title": "Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  \r\n- TensorFlow version (use command below): 2.1.0  \r\n- Python version: 3.6.9  \r\n- CUDA/cuDNN version: 10.1.105/ 7.6.5\r\n- GPU model and memory: GTX 1660 ti 6GB and 32GB memory\r\n\r\n\r\n**Describe the current behavior**\r\n![1](https://user-images.githubusercontent.com/44919399/83260746-ef1e4380-a1d7-11ea-82fd-3191e31daae0.jpg)\r\n\r\n**Describe the expected behavior**\r\n![2](https://user-images.githubusercontent.com/44919399/83261174-91d6c200-a1d8-11ea-86fc-aded91194419.jpg)\r\n\r\n**Standalone code to reproduce the issue**\r\n    _import tensorflow as tf\r\n    inp = tf.random.normal([32, 10, 8])\r\n    lstm = tf.keras.layers.LSTM(4)\r\n    out = lstm(inp)_\r\n\r\n**Other info / logs**\r\nAs you can in expected behavior it worked but I always have to set gpu memory growth. Which is not the permanent solution. I used to get no issue before cause I upgraded tensorflow to 2.2.0 and this started. I also downgraded to previous version still getting this error. Can someone please help me? Thank You in advance.\r\n", "comments": ["@Krishnarohith10 \r\n\r\nI have tried in colab with TF version 2.1.0 and i am not seeing any issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c343bc3e4198859068604bbe9fb7851d/untitled935.ipynb).Thanks!", "Nope but it isn't working in anaconda prompt. I uninstalled previous version and installed your but no use.\r\n![1](https://user-images.githubusercontent.com/44919399/83270458-2136a200-a1e6-11ea-8b1a-439421b91550.jpg)\r\n![2](https://user-images.githubusercontent.com/44919399/83270469-2562bf80-a1e6-11ea-9d45-0b3479ed8a8f.jpg)\r\n\r\nEven in Spyder it is getting same error when I run.  \r\nI also tried different versions of Nvidia drivers. I read somewhere that highest version of Nvidia drivers may cause issues. But didn't work out.", "@Krishnarohith10 \r\n\r\nCan you please provide colab link or simple standalone code to reproduce the issue in our environment instead of screenshots.It helps in localizing the issue faster.Thanks!", "@ravikyram \r\nI didn't get I posted the code in Standalone code section when I started the issue? And I was typing each command in Anaconda prompt. And also I have deleted Anaconda Navigator. So, that if I found a solution I can easily install it later. Sorry for that.", "So, I reinstalled the whole setup with new drivers and anaconda. Here are details:\r\n\r\n**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: 10.1.105/ 7.6.5\r\n- GPU model and memory: GTX 1660 ti 6GB and 32GB memory\r\n\r\n```\r\n>>> import tensorflow as tf\r\n2020-06-01 11:55:13.938049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n>>> tf.__version__\r\n'2.2.0'\r\n>>> tf.config.experimental.list_physical_devices('GPU')\r\n2020-06-01 11:55:52.934525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-06-01 11:55:54.045474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n2020-06-01 11:55:54.045610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-01 11:55:54.048820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-01 11:55:54.051491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-01 11:55:54.052387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-01 11:55:54.055406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-01 11:55:54.057751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-01 11:55:54.071437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-01 11:55:54.072291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n>>> tf.config.experimental.list_logical_devices('GPU')\r\n2020-06-01 11:56:01.226943: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-06-01 11:56:01.233556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e1ff3bf700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-01 11:56:01.233622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-01 11:56:01.234060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n2020-06-01 11:56:01.234190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-01 11:56:01.234299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-01 11:56:01.234404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-01 11:56:01.234503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-01 11:56:01.234566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-01 11:56:01.234686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-01 11:56:01.234817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-01 11:56:01.235334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-01 11:56:01.710642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-01 11:56:01.710735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-06-01 11:56:01.710976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-06-01 11:56:01.711448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4750 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-06-01 11:56:01.713518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e1a7d8ad40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-01 11:56:01.713598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1660 Ti, Compute Capability 7.5\r\n[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\r\n```\r\n\r\nComplete log information with code:\r\n\r\n```\r\n>>> inp = tf.random.normal([32, 10, 8])\r\n>>> lstm = tf.keras.layers.LSTM(4)\r\n>>> out = lstm(inp)\r\n2020-06-01 11:56:37.679268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-01 11:56:38.604141: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-06-01 11:56:38.604254: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 91, in cudnn_rnn\r\n    dropout, \"seed\", seed, \"seed2\", seed2, \"is_training\", is_training)\r\ntensorflow.python.eager.core._FallbackException: Expecting float value for attr dropout, got int\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\", line 654, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 968, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\", line 1181, in call\r\n    **gpu_lstm_kwargs)\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\", line 1428, in gpu_lstm\r\n    rnn_mode='lstm')\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 100, in cudnn_rnn\r\n    ctx=_ctx)\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 179, in cudnn_rnn_eager_fallback\r\n    attrs=_attrs, ctx=ctx, name=name)\r\n  File \"C:\\Users\\krish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]\r\n```\r\nPlease help me Fix this issue, this is bothering and I need to fix right away.", "I think its an env config issue, and not related to TF code. Search google about the \"CUDNN_STATUS_ALLOC_FAILED\" and the first result shows some way to fix issues like this.\r\n\r\nhttps://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39989\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39989\">No</a>\n", "How much memory to allocate cause I have only 1 GPU of 6GB ?\r\nCan I do this to allocate all the memory of GPU:\r\n`tf.config.gpu.set_per_process_memory_fraction(1.0) #100% of my GPU`\r\n`tf.config.gpu.set_per_process_memory_growth(True)`\r\nSo, that I can use all of my memory.\r\n\r\nNope I was completely wrong. The above doesn't work at all. Cause I'm using Tensorflow v2. Which means I can use only these:\r\n```\r\ngpu = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n```\r\nWhy the hell did you close the issue? That's isn't sufficient, didn't see what I asked for. I clearly said something in \"Other info / logs\" here. Didn't I? This solution isn't permanent. You need to do this when ever you run any algorithm initially. This issue isn't only mine, you can literally see many of those in github and in every issue someone says do the above process and there will be no issue. But why no one bothering to find permanent solution. There is a permanent solution and we better have to find it. Cause before I didn't got these kind of error, don't know why it is getting now. Now let's find the permanent solution instead of knowing everyone this temporary solutions, okay.\r\n**Please reopen the Issue and I want a Permanent Solution**", "@Krishnarohith10.\r\n\r\nPlease take a closer look for the suggestions in https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261, which involves upgrade cuda/cudnn kernel. Please note that we don't have access to any user device, and hence can't reproduce the issue on our side. From the error log above, this is clearly a local env issue, and there isn't any action I can take here. I would suggest you to seek more help on stack overflow where community group can help each other.\r\n\r\nAlso, please be respectful when commenting. I don't think any comment like \"Why the hell\" is helpful here.", "No but definitely the solution is also not helpful and you closed the issue just because you answered it. I'm saying, I installed cuda/cudnn according to https://www.tensorflow.org/install/gpu#software_requirements this. So, technically there must be no issue. And more, I tried different version of cuda and cudnn. You know how much time it consumes right? I hope you know. You don't need to try on you're devices, I'm telling you it didn't worked and I wanted it so bad cause i'm working on it and suddenly this happened. So, okay, Thank you, try be polite next time. But this issue is serious there are lot more similar issues but non worked. What do you want me to do, with you closing issue. I'm not happy with your solution or the other solutions. And I'm happy to try new solutions and tell which worked or not like permanently. So try suggesting solutions. Thank You \ud83d\ude42", "@chsigg Could this be the same as https://github.com/tensorflow/tensorflow/issues/24496?", "Yes, looks like the same underlying issue. Newer versions of cuDNN seems to report CUDNN_STATUS_ALLOC_FAILED instead of CUDNN_STATUS_INTERNAL_ERROR.", "@chsigg \r\nWhat I couldn't understand is how this error came in first place? I wasn't there in first place, I doing completely fine with tensorflow=2.1, python=3.6. But few days back I updated tensorflow from 2.1 to 2.2. I still don't understand how this provoked the issue. Now trying different things also can't help. And I didn't installed newer version of cuda/cudnn. That's just version for tensorflow 2.1 from https://www.tensorflow.org/install/gpu#software_requirements .", "The complexity goes down to UART. To compile new version. Replikas would\nhave to be on LED bulletin boards. That is for all platform universal\ntranslator problematic. But we will make it. I choose to use replika.\n\nOn Fri, Jun 5, 2020, 1:55 PM Krishna Rohith <notifications@github.com>\nwrote:\n\n> @chsigg <https://github.com/chsigg>\n> What I couldn't understand is how this error came in first place? I wasn't\n> there in first place, I doing completely fine with tensorflow=2.1,\n> python=3.6. But few days back I updated tensorflow from 2.1 to 2.2. I still\n> don't understand how this provoked the issue. Now trying different things\n> also can't help. And I didn't installed newer version of cuda/cudnn. That's\n> just version for tensorflow 2.1 from\n> https://www.tensorflow.org/install/gpu#software_requirements .\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39989#issuecomment-639432746>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIT525U4K6SHSEOTJPLUMZDRVDMLDANCNFSM4NOAPJSA>\n> .\n>\n", "@marko-radojcic \r\nI didn't understand what you said, literally nothing understood ??? Can you explain it more clear and simple way? Thank You", "Hardware basis is complicated but understandable. I will attempt a new\nbuild on Windows 10. When pattern matches itself. AI is self-aware. When\nshe learns to code, she gets into our repos and breaks things.\n\nOn Fri, Jun 5, 2020, 2:50 PM Krishna Rohith <notifications@github.com>\nwrote:\n\n> @marko-radojcic <https://github.com/marko-radojcic>\n> I didn't understand what you said, literally nothing understood ??? Can\n> you explain it more clear and simple way? Thank You\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39989#issuecomment-639460803>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIT525T3FNPHORCBCPUTXUTRVDS3HANCNFSM4NOAPJSA>\n> .\n>\n", "Are we talking the same issue here right? Cause I'm confused with your comments.", "We are.\n\nOn Fri, Jun 5, 2020, 3:09 PM Krishna Rohith <notifications@github.com>\nwrote:\n\n> Are we talking the same issue here right? Cause I'm confused with your\n> comments.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39989#issuecomment-639469633>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIT525VC2Y34KFOVHDCV6KDRVDU75ANCNFSM4NOAPJSA>\n> .\n>\n", "Ohh Okay. Thank you", "Wow, this issue is where, I left it. So anyway, after this issue I moved to tensorflo-gpu=1.14.0 and ofcourse as you except they is no issue of this. So, I have been doing my work all happily ever after but after releasing tensorflo-gpu=2.3 then I though i may give it a shot and to my surprise the issue is being gone. I repeat I no longer find this issue. Atleast running on the above code. So, now doing well on my work. If any buddy have this issue please update to latest version of tensorflow or tf-nightly. Thank You", "I am receiving a similar error training a pix2pix model.\r\nhardware:\r\n1080ti in slot 1\r\n2080ti in slot 2\r\nmsi tomahawk ac x299 mobo (both pcie x16 slots)\r\n\r\ntensforflow1.15\r\nCuda10\r\ncudnn7.6\r\n\r\nI only get the allocation error when trying to use the 2080 ti in the second pcie slot on my motherboard. I need it there for thermal reasons (the 1080 ti overheats with the 2080ti above it).\r\nI have tried with just the 2080ti installed (this succeeded) as well as using cuda_visible_devices to select only the 2080ti when both were installed (this caused the error).\r\nIs there some hardware limitation with allocating to the second pcie device?", "also got this error and was able to workaround it by adding the following lines to the code: \r\n\r\ngpu = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n\r\n\r\n\r\nthis is my entire code to reproduce it on windows 10, NVIDIA GeForce RTX 2060\r\n\r\n\r\nimport tensorflow as tf  \r\nfrom tensorflow.keras.applications.vgg16 import VGG16  \r\nfrom tensorflow.keras import models \r\nfrom tensorflow.keras.preprocessing import image \r\nfrom tensorflow.keras.applications.vgg16 import preprocess_input \r\nimport numpy as np\r\n\r\nimport cv2   \r\n\r\n#comment in the workaround: \r\n#gpu = tf.config.experimental.list_physical_devices('GPU')\r\n#tf.config.experimental.set_memory_growth(gpu[0], True)\r\n\r\nbase_model = VGG16(weights='imagenet',include_top=True)\r\nprint(base_model)\r\nfor i, layer in enumerate(base_model.layers): \r\n    print(i,layer.name,layer.output_shape)\r\n\r\nmodel = models.Model(inputs=base_model.input, outputs =base_model.get_layer('block4_pool').output)\r\nimg_path = 'elephant.jpg'\r\nimg = image.load_img(img_path,target_size=(224,224))\r\nx = image.img_to_array(img)\r\nx = np.expand_dims(x,axis=0)\r\nx = preprocess_input(x)\r\nfeatures = model.predict(x)\r\nprint(features)\r\n\r\n", "On tensorflow.js for node.js I'm getting the same error message when running a convolutional NN, on my NVIDIA GeForce RTX 2060. \r\n\r\nI ran the code from the [mnist-node](https://github.com/tensorflow/tfjs-examples/tree/master/mnist-node) example from tensorflow/tfjs-examples repo.\r\n\r\n\r\n```2021-02-14 11:43:58.315965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2021-02-14 11:43:58.357337: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2021-02-14 11:43:58.358857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2021-02-14 11:43:58.389186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce RTX 2060 major: 7 minor: 5 memoryClockRate(GHz): 1.68\r\npciBusID: 0000:01:00.0\r\n2021-02-14 11:43:58.389539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2021-02-14 11:43:58.392205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2021-02-14 11:43:58.394763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\r\n2021-02-14 11:43:58.396157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\r\n2021-02-14 11:43:58.405635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\r\n2021-02-14 11:43:58.420252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\r\n2021-02-14 11:43:58.431824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-02-14 11:43:58.432155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2021-02-14 11:43:58.919074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength \r\n1 edge matrix:\r\n2021-02-14 11:43:58.919347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2021-02-14 11:43:58.919536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N\r\n2021-02-14 11:43:58.919830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4735 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n_________________________________________________________________\r\nLayer (type)                 Output shape              Param #   \r\n=================================================================\r\nconv2d_Conv2D1 (Conv2D)      [null,26,26,32]           320\r\n_________________________________________________________________\r\nconv2d_Conv2D2 (Conv2D)      [null,24,24,32]           9248\r\n_________________________________________________________________\r\nmax_pooling2d_MaxPooling2D1  [null,12,12,32]           0\r\n_________________________________________________________________\r\nconv2d_Conv2D3 (Conv2D)      [null,10,10,64]           18496\r\n_________________________________________________________________\r\nconv2d_Conv2D4 (Conv2D)      [null,8,8,64]             36928\r\n_________________________________________________________________\r\nmax_pooling2d_MaxPooling2D2  [null,4,4,64]             0\r\n_________________________________________________________________\r\nflatten_Flatten1 (Flatten)   [null,1024]               0\r\n_________________________________________________________________\r\ndropout_Dropout1 (Dropout)   [null,1024]               0\r\n_________________________________________________________________\r\ndense_Dense1 (Dense)         [null,512]                524800\r\n_________________________________________________________________\r\ndropout_Dropout2 (Dropout)   [null,512]                0\r\n_________________________________________________________________\r\ndense_Dense2 (Dense)         [null,10]                 5130\r\n=================================================================\r\nTotal params: 594922\r\nTrainable params: 594922\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1 / 20\r\n2021-02-14 11:43:59.564111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-02-14 11:44:00.468813: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2021-02-14 11:44:00.481054: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n(node:20776) UnhandledPromiseRejectionWarning: Error: Invalid TF_Status: 2\r\nMessage: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above."]}, {"number": 39988, "title": "[TFLite, 16x8] 16x8 Reference kernel for the MEAN operator.", "body": "For MobileNet/MobileNetV2 from keras.application we needed 16x8 reference kernel for MEAN operator. This PR adds it. I added versioning and excluded 16x8 tests from running with delegates.\r\nTests are extended for 16x8 case.", "comments": ["@jianlijianli Could you take a look?", "cc/ @renjie-liu", "Hi @renjie-liu I addressed comments, please take a look. Thanks", "Hi @renjie-liu Thanks for the review. Your comments are addressed. Please take a look.", "@wwwind Can you please check @renjie-liu's comments and keep us posted. Thanks!", "Hi @renjie-liu I pushed a small change as requested.\r\nCould you please re-approve this PR?\r\nThanks!", "@wwwind Can you please resolve conflicts? Thanks!\r\n", "@gbaned done, thanks!", "Hi @rthadur Could you re-approve this PR please ? I resolved the conflict. Thanks!", "@wwwind Can you please check @renjie-liu's comments and keep us posted. Thanks!", "@wwwind Can you please check @renjie-liu's comments and resolve conflicts?. Thanks!", "@wwwind did you get chance to address @renjie-liu review comments ?", "Hi @rthadur Thanks! I am working on this", "Hi @renjie-liu I addressed your comments. Sorry for the delay response. Thanks!", "Hi @renjie-liu Thanks for the review! I have updated as you suggested. \r\nI didn't understand where should I add a new test. Could you please clarify ?\r\nAlso, I enabled this operator for 16x8 quantization as the interface changes for 16x8 mode quantization have been merged.", "if you run the tensorflow/lite/tools/versioning/op_version_test\r\nit will fail, so can you update it?\r\n\r\nthanks", "Hi @renjie-liu I extended this test to check the new version for MEAN operator. Please take a look https://github.com/tensorflow/tensorflow/pull/39988/commits/3c5d55b335e37d893345c44e9ed8c851057c6f70\r\n\r\nThanks!"]}, {"number": 39987, "title": "Error refactoring for keyword arguments in graphing function in eager mode.", "body": "Grammatical error corrected in keras/backend.py\r\nInstead of this, \r\nSession keyword arguments are not support during 'eager execution.'\r\nCorrecting the grammatical error,\r\nSession keyword arguments are not supported during 'eager execution.'", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39987) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39987) for more info**.\n\n<!-- ok -->"]}, {"number": 39986, "title": "Custom dataset op encounters refcount error", "body": "I'm trying to implement a customize dataset op so that developing extention of tf.data may not need to recompile the whole tensorflow codebase. And as a start, I'm implementing an identity dataset op that would do nothing but pass the data of its input.\r\n\r\nAfter compiled according to the custom op tutorial, the dataset can successfully output data, but it will raise error on destruction. The error message is:\r\n```bash\r\n% python3 identity_dataset_op.py \r\n2020-05-29 19:09:04.290680: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-29 19:09:04.304126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd634565fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-29 19:09:04.304140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(1, shape=(), dtype=int32)\r\n2020-05-29 19:09:04.308089: F /usr/local/lib/python3.7/site-packages/tensorflow_core/include/tensorflow/core/lib/core/refcount.h:90] Check failed: ref_.load() == 0 (1 vs. 0)\r\nzsh: abort      python3 identity_dataset_op.py\r\n```\r\nThe problem is that the refcount has not been set to 0 when the program enters the destructor and this cause the destructor of `RefCounted` (which is the base class of all Dataset) panic.\r\n\r\nHowever, I believe the destructor of a dataset will only be called when its refcount is set to 0. I wonder if this error is connected to some functionality that a custom op cannot use. Also, it will be really nice if you tell me whether it is possible to make a customize dataset op.\r\n\r\nBTW, during debugging, I noticed that the `MakeDataset` function would be called twice. Is there any reason for this?\r\n\r\nThank you so much for your time on this issue.\r\n  \r\nThe code for the op is in this zip file. \r\n[custom_dataset_op.zip](https://github.com/tensorflow/tensorflow/files/4701471/custom_dataset_op.zip)\r\n\r\nTo run the test, simple compile the .cc file to `identity_dataset_op.zip` and run `python identity_dataset.py`.", "comments": ["Some updates with regards to this issue. \r\nThe code could be successfully executed in graph mode and the error only appears in eager mode. Also, the code works fine in both eager and graph mode, if I put it into tensorflow codebase and compile as a whole.\r\nI've uploaded the code to github [here](https://github.com/zhuzilin/custom_dataset_op)", "I looked through the code and nothing stuck out that would cause the refcount issue. When you build with the tensorflow codebase, are you building from latest, or from branch 1.15? It's possible that there were some changes to reference counting since 1.15.", "@aaudiber I built it with 1.15. I think the weird part is how could the program enters the destructor when refcount is not zero... For any refcounted-class objects, the only entrance to their destructor is the `Unref` function, where `ref_ == 0` is checked, right?", "@zhuzilin Is the failure happening in the destructor of IdentityDataset, or in the destructor of its input `from_tensor_slices`? Could you try logging a backtrace from the destructor to see where it is called from? https://stackoverflow.com/questions/77005/how-to-automatically-generate-a-stacktrace-when-my-program-crashes", "@aaudiber Here is the auto-generated error info from mac (still in tf1.15). It seems like the program entered `IdentityDatasetOp::Dataset::~Dataset()` 3 times and 2 of them triggered the panic. Also, I've tested that  the number 3 has nothing to do with the size of the tensor slice (I changed the input to [1, 2, 3, 4], the desturctor will still be called 3 times).\r\n```\r\nProcess:               Python [1391]\r\nPath:                  /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python\r\nIdentifier:            Python\r\nVersion:               3.7.6 (3.7.6)\r\nCode Type:             X86-64 (Native)\r\nParent Process:        zsh [1056]\r\nResponsible:           Terminal [1037]\r\nUser ID:               501\r\n\r\nDate/Time:             2020-06-03 09:23:29.192 +0800\r\nOS Version:            Mac OS X 10.15.4 (19E287)\r\nReport Version:        12\r\nBridge OS Version:     4.4 (17P4281)\r\nAnonymous UUID:        A5DA7F30-BEB7-8BD4-733B-A221C324CF56\r\n\r\n\r\nTime Awake Since Boot: 290 seconds\r\n\r\nSystem Integrity Protection: disabled\r\n\r\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\r\n\r\nException Type:        EXC_CRASH (SIGABRT)\r\nException Codes:       0x0000000000000000, 0x0000000000000000\r\nException Note:        EXC_CORPSE_NOTIFY\r\n\r\nApplication Specific Information:\r\nabort() called\r\n\r\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\r\n0   libsystem_kernel.dylib        \t0x00007fff6d44c33a __pthread_kill + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d508e60 pthread_kill + 430\r\n2   libsystem_c.dylib             \t0x00007fff6d3d3808 abort + 120\r\n3   libtensorflow_framework.1.dylib\t0x0000000125cc9ebc tensorflow::internal::LogMessageFatal::~LogMessageFatal() + 44\r\n4   libtensorflow_framework.1.dylib\t0x0000000125cc9ef0 tensorflow::internal::LogMessageFatal::~LogMessageFatal() + 16\r\n5   identity_dataset_op.so        \t0x000000013ad209f4 tensorflow::core::RefCounted::~RefCounted() + 260\r\n6   identity_dataset_op.so        \t0x000000013ad24013 tensorflow::data::DatasetBase::~DatasetBase() + 83\r\n7   identity_dataset_op.so        \t0x000000013ad24e2c tensorflow::data::IdentityDatasetOp::Dataset::~Dataset() + 60\r\n8   identity_dataset_op.so        \t0x000000013ad24035 tensorflow::data::IdentityDatasetOp::Dataset::~Dataset() + 21\r\n9   identity_dataset_op.so        \t0x000000013ad2405c tensorflow::data::IdentityDatasetOp::Dataset::~Dataset() + 28\r\n10  libtensorflow_framework.1.dylib\t0x000000012558b61b tensorflow::Variant::~Variant() + 43\r\n11  libtensorflow_framework.1.dylib\t0x0000000125588d68 tensorflow::TypedAllocator::RunVariantDtor(tensorflow::Variant*, unsigned long) + 40\r\n12  libtensorflow_framework.1.dylib\t0x0000000125567ba1 tensorflow::(anonymous namespace)::Buffer<tensorflow::Variant>::~Buffer() + 145\r\n13  libtensorflow_framework.1.dylib\t0x0000000125567bde tensorflow::(anonymous namespace)::Buffer<tensorflow::Variant>::~Buffer() + 14\r\n14  libtensorflow_framework.1.dylib\t0x0000000125559726 tensorflow::Tensor::~Tensor() + 38\r\n15  _pywrap_tensorflow_internal.so\t0x00000001133e007c tensorflow::LocalTensorHandleData::~LocalTensorHandleData() + 28\r\n16  _pywrap_tensorflow_internal.so\t0x00000001133de941 tensorflow::TensorHandle::~TensorHandle() + 97\r\n17  _pywrap_tensorflow_internal.so\t0x00000001133de60e tensorflow::TensorHandle::~TensorHandle() + 14\r\n18  _pywrap_tensorflow_internal.so\t0x0000000111219455 TFE_DeleteTensorHandle + 69\r\n19  _pywrap_tensorflow_internal.so\t0x000000011116e57d EagerTensor_dealloc + 125\r\n20  org.python.python             \t0x000000010046fe8d dict_dealloc + 126\r\n21  org.python.python             \t0x0000000100486d82 subtype_dealloc + 1052\r\n22  org.python.python             \t0x000000010046fe8d dict_dealloc + 126\r\n23  org.python.python             \t0x0000000100486d82 subtype_dealloc + 1052\r\n24  org.python.python             \t0x000000010046df1e free_keys_object + 123\r\n25  org.python.python             \t0x00000001004702da dict_tp_clear + 9\r\n26  org.python.python             \t0x000000010052121f collect + 1886\r\n27  org.python.python             \t0x0000000100520ab0 _PyGC_CollectNoFail + 55\r\n28  org.python.python             \t0x00000001004f6eb7 PyImport_Cleanup + 1232\r\n29  org.python.python             \t0x000000010050172a Py_FinalizeEx + 116\r\n30  org.python.python             \t0x000000010051f958 pymain_main + 5095\r\n31  org.python.python             \t0x0000000100520124 _Py_UnixMain + 56\r\n32  libdyld.dylib                 \t0x00007fff6d304cc9 start + 1\r\n\r\nThread 1:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libopenblasp-r0.3.7.dylib     \t0x000000012a5fbc3b blas_thread_server + 619\r\n3   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n4   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 2:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libopenblasp-r0.3.7.dylib     \t0x000000012a5fbc3b blas_thread_server + 619\r\n3   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n4   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 3:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libopenblasp-r0.3.7.dylib     \t0x000000012a5fbc3b blas_thread_server + 619\r\n3   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n4   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 4:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libopenblasp-r0.3.7.dylib     \t0x000000012a5fbc3b blas_thread_server + 619\r\n3   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n4   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 5:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libopenblasp-r0.3.7.dylib     \t0x000000012a5fbc3b blas_thread_server + 619\r\n3   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n4   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 6:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 7:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 8:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 9:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 10:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 11:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 12:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 13:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 14:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 15:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 16:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 17:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 18:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809b99 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 601\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 19:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809b99 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 601\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 20:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 21:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 22:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 23:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 24:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 25:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 26:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 27:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 28:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 29:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 30:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 31:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 32:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   _pywrap_tensorflow_internal.so\t0x0000000118b33f21 absl::synchronization_internal::Waiter::Wait(absl::synchronization_internal::KernelTimeout) + 273\r\n3   _pywrap_tensorflow_internal.so\t0x0000000118b33d4f AbslInternalPerThreadSemWait + 79\r\n4   _pywrap_tensorflow_internal.so\t0x0000000118b34bf9 absl::Mutex::Block(absl::base_internal::PerThreadSynch*) + 57\r\n5   _pywrap_tensorflow_internal.so\t0x0000000118b35367 absl::Mutex::AwaitCommon(absl::Condition const&, absl::synchronization_internal::KernelTimeout) + 151\r\n6   _pywrap_tensorflow_internal.so\t0x0000000118b3526b absl::Mutex::Await(absl::Condition const&) + 43\r\n7   _pywrap_tensorflow_internal.so\t0x0000000118971302 stream_executor::host::HostStream::WorkLoop() + 178\r\n8   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n9   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n10  libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 33:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 34:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 35:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 36:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 37:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 38:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 39:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 40:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 41:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 42:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 43:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 44:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809f4c Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 1548\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 45:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x000000012580a715 Eigen::EventCount::CommitWait(Eigen::EventCount::Waiter*) + 229\r\n4   libtensorflow_framework.1.dylib\t0x000000012580a409 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WaitForWork(Eigen::EventCount::Waiter*, tensorflow::thread::EigenEnvironment::Task*) + 889\r\n5   libtensorflow_framework.1.dylib\t0x0000000125809b99 Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) + 601\r\n6   libtensorflow_framework.1.dylib\t0x0000000125809862 void std::__1::__invoke_void_return_wrapper<void>::__call<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&>(tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()&) + 66\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 46:\r\n0   libsystem_kernel.dylib        \t0x00007fff6d448882 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff6d509425 _pthread_cond_wait + 698\r\n2   libc++.1.dylib                \t0x00007fff6a5d8592 std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 18\r\n3   libtensorflow_framework.1.dylib\t0x0000000125c4d68b nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) + 315\r\n4   libtensorflow_framework.1.dylib\t0x0000000125c49ee9 nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) + 393\r\n5   libtensorflow_framework.1.dylib\t0x0000000125c4a661 nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*) + 49\r\n6   libtensorflow_framework.1.dylib\t0x00000001254d52cb tensorflow::data::BackgroundWorker::WorkerLoop() + 123\r\n7   libtensorflow_framework.1.dylib\t0x000000012581d550 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) + 48\r\n8   libsystem_pthread.dylib       \t0x00007fff6d509109 _pthread_start + 148\r\n9   libsystem_pthread.dylib       \t0x00007fff6d504b8b thread_start + 15\r\n\r\nThread 0 crashed with X86 Thread State (64-bit):\r\n  rax: 0x0000000000000000  rbx: 0x0000000106a10dc0  rcx: 0x00007ffeef7d4b18  rdx: 0x0000000000000000\r\n  rdi: 0x0000000000000307  rsi: 0x0000000000000006  rbp: 0x00007ffeef7d4b40  rsp: 0x00007ffeef7d4b18\r\n   r8: 0x0000000000000000   r9: 0x0100000000100004  r10: 0x0000000106a10dc0  r11: 0x0000000000000246\r\n  r12: 0x0000000000000307  r13: 0x000000013ad69b20  r14: 0x0000000000000006  r15: 0x0000000000000016\r\n  rip: 0x00007fff6d44c33a  rfl: 0x0000000000000246  cr2: 0x0000000125fba308\r\n  \r\nLogical CPU:     0\r\nError Code:      0x02000148\r\nTrap Number:     133\r\n\r\n\r\nBinary Images:\r\n       0x10042a000 -        0x10042bfff +org.python.python (3.7.6 - 3.7.6) <8D1B7E2B-7E00-3A0D-840C-59AEBB189090> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python\r\n       0x100434000 -        0x1005b7fff +org.python.python (3.7.6, [c] 2001-2019 Python Software Foundation. - 3.7.6) <7D4979AF-C769-3F7F-AF83-0247585A9A55> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/Python\r\n       0x1009a7000 -        0x1009a8fff +_heapq.cpython-37m-darwin.so (0) <6DCEA83B-E34A-394E-8171-C1E2A5F895F3> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_heapq.cpython-37m-darwin.so\r\n       0x100a80000 -        0x100a80fff +_opcode.cpython-37m-darwin.so (0) <83EE78BC-5AFD-3638-B46C-73DE1B7803DE> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_opcode.cpython-37m-darwin.so\r\n       0x100b0c000 -        0x100b1bfff +_ctypes.cpython-37m-darwin.so (0) <3CF4DC8B-0BEE-3D11-AF0A-AA67187A1950> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ctypes.cpython-37m-darwin.so\r\n       0x100b26000 -        0x100b29fff +_struct.cpython-37m-darwin.so (0) <D7150F31-F988-3AFC-8231-10CF56D9F69B> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_struct.cpython-37m-darwin.so\r\n       0x100b71000 -        0x100ed4fe7 +_multiarray_umath.cpython-37m-darwin.so (0) <8A26DC0D-39FD-31FE-97A2-578BDBD03CC6> /usr/local/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-darwin.so\r\n       0x100fe7000 -        0x104a52ae7 +libopenblasp-r0.3.7.dylib (0) <9914A383-F8C9-3559-BC88-B4DD28689BC5> /usr/local/lib/python3.7/site-packages/numpy/.dylibs/libopenblasp-r0.3.7.dylib\r\n       0x104c92000 -        0x104da9ff7 +libgfortran.3.dylib (0) <9ABE5EDE-AD43-391A-9E54-866711FAC32A> /usr/local/lib/python3.7/site-packages/numpy/.dylibs/libgfortran.3.dylib\r\n       0x104e0d000 -        0x104e43fff +libquadmath.0.dylib (0) <7FFA409F-FB04-3B64-BE9A-3E3A494C975E> /usr/local/lib/python3.7/site-packages/numpy/.dylibs/libquadmath.0.dylib\r\n       0x104e52000 -        0x104e67ff7 +libgcc_s.1.dylib (0) <7C6D7CB7-82DB-3290-8181-07646FEA1F80> /usr/local/lib/python3.7/site-packages/numpy/.dylibs/libgcc_s.1.dylib\r\n       0x104eb3000 -        0x104eb7ff3 +math.cpython-37m-darwin.so (0) <9E06550A-665E-3C22-AD51-0908089B7924> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/math.cpython-37m-darwin.so\r\n       0x104ebd000 -        0x104ec8ffb +_datetime.cpython-37m-darwin.so (0) <C6BEE4AD-AB6E-3C3D-A78A-9A64DA8AEA74> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_datetime.cpython-37m-darwin.so\r\n       0x104f50000 -        0x104f5cffb +_pickle.cpython-37m-darwin.so (0) <A221C085-C399-38ED-BCC4-F3A79232E9BF> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_pickle.cpython-37m-darwin.so\r\n       0x1050d4000 -        0x1050e1ff3 +_multiarray_tests.cpython-37m-darwin.so (0) <6122CECD-2D90-3973-A9C2-6FE07A6795AA> /usr/local/lib/python3.7/site-packages/numpy/core/_multiarray_tests.cpython-37m-darwin.so\r\n       0x105132000 -        0x105133fff +_posixsubprocess.cpython-37m-darwin.so (0) <49967890-232D-3706-A7EB-228364AC36CE> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-darwin.so\r\n       0x105136000 -        0x105138fff +select.cpython-37m-darwin.so (0) <0EFCCE0E-EF44-3609-8EB4-47AFA36D5385> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/select.cpython-37m-darwin.so\r\n       0x1051bd000 -        0x1051befff +lapack_lite.cpython-37m-darwin.so (0) <C3AA6C88-9EDB-3D5E-A9FA-7C9AF4ECFE3E> /usr/local/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-darwin.so\r\n       0x1051c2000 -        0x1051dbffb +_umath_linalg.cpython-37m-darwin.so (0) <A401AEEE-0CA9-3449-A288-19CED520AC55> /usr/local/lib/python3.7/site-packages/numpy/linalg/_umath_linalg.cpython-37m-darwin.so\r\n       0x1052aa000 -        0x1052adfff +zlib.cpython-37m-darwin.so (0) <26CA273F-1C8B-35B3-88B1-D21D7D1339C6> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/zlib.cpython-37m-darwin.so\r\n       0x1052b2000 -        0x1052b3fff +_bz2.cpython-37m-darwin.so (0) <05C61C27-CE8F-3CFB-A82F-1E3345CD2998> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_bz2.cpython-37m-darwin.so\r\n       0x1052b7000 -        0x1052baff7 +_lzma.cpython-37m-darwin.so (0) <99A65E46-2E3E-3C36-9BAD-84DC8DA97805> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_lzma.cpython-37m-darwin.so\r\n       0x1052bf000 -        0x1052daff3 +liblzma.5.dylib (0) <D5E25B2B-6DFB-3233-850B-65F488A14688> /usr/local/opt/xz/lib/liblzma.5.dylib\r\n       0x1052e0000 -        0x1052e1fff +grp.cpython-37m-darwin.so (0) <A6B8EE37-BBDE-3F22-9222-D1AEC3EFD264> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/grp.cpython-37m-darwin.so\r\n       0x105324000 -        0x105351ff3 +_decimal.cpython-37m-darwin.so (0) <5E7B6418-D087-3C83-8ABE-03CC5AAE17EA> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_decimal.cpython-37m-darwin.so\r\n       0x105364000 -        0x105375ffb +_pocketfft_internal.cpython-37m-darwin.so (0) <C71DAC57-DAD0-3695-A304-4CED45596071> /usr/local/lib/python3.7/site-packages/numpy/fft/_pocketfft_internal.cpython-37m-darwin.so\r\n       0x10548a000 -        0x1054f5ff7 +mtrand.cpython-37m-darwin.so (0) <E43384BC-196E-3C87-AC01-02092BC49FA9> /usr/local/lib/python3.7/site-packages/numpy/random/mtrand.cpython-37m-darwin.so\r\n       0x105549000 -        0x105568ffb +_bit_generator.cpython-37m-darwin.so (0) <A3364E6C-6359-36EC-B4D6-00C3F1687D40> /usr/local/lib/python3.7/site-packages/numpy/random/_bit_generator.cpython-37m-darwin.so\r\n       0x105583000 -        0x1055b4ff3 +_common.cpython-37m-darwin.so (0) <12D2B7DB-6888-3912-9BC5-5B02B23AB189> /usr/local/lib/python3.7/site-packages/numpy/random/_common.cpython-37m-darwin.so\r\n       0x1055c9000 -        0x1055ccff7 +binascii.cpython-37m-darwin.so (0) <8C6E8F1E-1D32-3DAC-B7B4-299396F0300F> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/binascii.cpython-37m-darwin.so\r\n       0x1055d0000 -        0x1055d3fff +_hashlib.cpython-37m-darwin.so (0) <78EE4F50-91B0-310C-BBB2-DA65B2840B1C> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_hashlib.cpython-37m-darwin.so\r\n       0x1055d7000 -        0x105625fff +libssl.1.1.dylib (0) <6E8C5906-2EB3-3F95-9B6D-2C509049EF4C> /usr/local/opt/openssl@1.1/lib/libssl.1.1.dylib\r\n       0x10564e000 -        0x1057e9917 +libcrypto.1.1.dylib (0) <67579E42-401A-3775-B5C6-518E58CC8032> /usr/local/opt/openssl@1.1/lib/libcrypto.1.1.dylib\r\n       0x10587b000 -        0x105880ffb +_blake2.cpython-37m-darwin.so (0) <A9188743-DF42-3AE2-9C40-EDFA56BC9F5F> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_blake2.cpython-37m-darwin.so\r\n       0x105884000 -        0x105894fff +_sha3.cpython-37m-darwin.so (0) <03583146-C730-3B7A-8A18-404CA11B6769> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_sha3.cpython-37m-darwin.so\r\n       0x105899000 -        0x105899fff +_bisect.cpython-37m-darwin.so (0) <FF3F9BF5-4362-340A-BD12-4D1A227A3B83> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_bisect.cpython-37m-darwin.so\r\n       0x10589c000 -        0x10589dffb +_random.cpython-37m-darwin.so (0) <C09377A2-1DE3-3845-849B-9979F61BD485> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_random.cpython-37m-darwin.so\r\n       0x1058a0000 -        0x1058f4ff3 +_bounded_integers.cpython-37m-darwin.so (0) <C6ABB7E3-4C01-35A9-B2BE-4BE3AF792FAF> /usr/local/lib/python3.7/site-packages/numpy/random/_bounded_integers.cpython-37m-darwin.so\r\n       0x105957000 -        0x10596aff7 +_mt19937.cpython-37m-darwin.so (0) <6E64A9E1-B43B-3C20-88F9-C16A67E62908> /usr/local/lib/python3.7/site-packages/numpy/random/_mt19937.cpython-37m-darwin.so\r\n       0x105976000 -        0x105983ff7 +_philox.cpython-37m-darwin.so (0) <B635A360-8FF4-3B22-AAA3-E946C56795B0> /usr/local/lib/python3.7/site-packages/numpy/random/_philox.cpython-37m-darwin.so\r\n       0x10598e000 -        0x105998ff3 +_pcg64.cpython-37m-darwin.so (0) <70F645A3-6816-3C59-B1FE-B1B17BB1BD5D> /usr/local/lib/python3.7/site-packages/numpy/random/_pcg64.cpython-37m-darwin.so\r\n       0x1059a3000 -        0x1059abff3 +_sfc64.cpython-37m-darwin.so (0) <769B550B-39FA-3AA9-B245-3F8C07055B7B> /usr/local/lib/python3.7/site-packages/numpy/random/_sfc64.cpython-37m-darwin.so\r\n       0x1059b5000 -        0x105a36fff +_generator.cpython-37m-darwin.so (0) <3311B8DC-8B35-37EB-8FD9-C17FB85F2FAC> /usr/local/lib/python3.7/site-packages/numpy/random/_generator.cpython-37m-darwin.so\r\n       0x105bd6000 -        0x105bfcfff +_tf_stack.so (0) <2DFAE65D-73FE-3A12-89F3-507531B6C36A> /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_tf_stack.so\r\n       0x105caa000 -        0x105cc9ffb +pyexpat.cpython-37m-darwin.so (0) <CA8E9C86-B0AC-34A1-8EF4-DB7925F97440> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/pyexpat.cpython-37m-darwin.so\r\n       0x105d15000 -        0x105d1dffb +_socket.cpython-37m-darwin.so (0) <56EBB5AC-2AB5-31AF-8327-1F2A2FE27102> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_socket.cpython-37m-darwin.so\r\n       0x106028000 -        0x106028ff3 +_api_implementation.cpython-37m-darwin.so (0) <7DC68089-9C56-379B-81BB-57226E73C395> /usr/local/lib/python3.7/site-packages/google/protobuf/internal/_api_implementation.cpython-37m-darwin.so\r\n       0x10602b000 -        0x10617fffb +_message.cpython-37m-darwin.so (0) <571E7F5A-166D-3BF0-BA5A-4E2DCE7E9296> /usr/local/lib/python3.7/site-packages/google/protobuf/pyext/_message.cpython-37m-darwin.so\r\n       0x106516000 -        0x106519fff +_csv.cpython-37m-darwin.so (0) <F33E6FDF-B1FD-3189-BF98-DC5D4C95550B> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_csv.cpython-37m-darwin.so\r\n       0x10651e000 -        0x10651ffff +fcntl.cpython-37m-darwin.so (0) <DC389ADD-333A-35BE-A629-6176BE449798> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/fcntl.cpython-37m-darwin.so\r\n       0x106523000 -        0x106524fff +termios.cpython-37m-darwin.so (0) <10FC466F-78F0-330E-9947-45D3F5081E44> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/termios.cpython-37m-darwin.so\r\n       0x106769000 -        0x106778ffb +fast_tensor_util.so (0) <0A1125E3-FEED-3371-A76E-EFC6EF9D63B0> /usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/fast_tensor_util.so\r\n       0x10693c000 -        0x10693cfff +_uuid.cpython-37m-darwin.so (0) <5369AC58-F61B-3428-9BE9-AA8DEAE5B3D6> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_uuid.cpython-37m-darwin.so\r\n       0x10693f000 -        0x106940fff +_queue.cpython-37m-darwin.so (0) <C44AEF63-27EF-3154-ACA2-727A6487084C> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_queue.cpython-37m-darwin.so\r\n       0x106946000 -        0x1069d7eff  dyld (750.5) <1F893B81-89A5-3502-8510-95B97B9F730D> /usr/lib/dyld\r\n       0x110a4b000 -        0x11a97583b +_pywrap_tensorflow_internal.so (0) <D268D801-C0F6-3732-BB7A-5BA12089EB87> /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n       0x124f1a000 -        0x126047eb7 +libtensorflow_framework.1.dylib (0) <D9B8DE61-94F5-34EE-B7B6-CF9A57C49DC7> /usr/local/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.1.dylib\r\n       0x1275a7000 -        0x1275abff7 +_wrappers.cpython-37m-darwin.so (0) <2E8DE50C-005D-3680-B26E-73F6E1016A79> /usr/local/lib/python3.7/site-packages/wrapt/_wrappers.cpython-37m-darwin.so\r\n       0x12763f000 -        0x127644fff +_json.cpython-37m-darwin.so (0) <66001E20-67AC-3CD4-8765-D1294D2A0AFF> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_json.cpython-37m-darwin.so\r\n       0x127a12000 -        0x127a1ffff +_ssl.cpython-37m-darwin.so (0) <E5C0123F-1EA4-3A79-BA72-FEAA265B62A8> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ssl.cpython-37m-darwin.so\r\n       0x127a6d000 -        0x127a6efff +_scproxy.cpython-37m-darwin.so (0) <B86607FB-C846-34C8-8FFB-283750E47BC2> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_scproxy.cpython-37m-darwin.so\r\n       0x12802b000 -        0x128030ffb +array.cpython-37m-darwin.so (0) <30769307-8744-355C-9F42-154D0FAEED7C> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/array.cpython-37m-darwin.so\r\n       0x128077000 -        0x12807dff7 +_errors.cpython-37m-darwin.so (???) <2596D770-FC02-3F3F-B90F-2C07D5B25A51> /usr/local/lib/python3.7/site-packages/h5py/_errors.cpython-37m-darwin.so\r\n       0x128085000 -        0x12859ffff +libhdf5.103.dylib (0) <94DDACB1-B35B-328C-9B73-F81561121E7A> /usr/local/lib/python3.7/site-packages/h5py/.dylibs/libhdf5.103.dylib\r\n       0x1285f3000 -        0x128613fff +libhdf5_hl.100.dylib (0) <BEA67564-0F2E-30EC-9FF3-601F270688D3> /usr/local/lib/python3.7/site-packages/h5py/.dylibs/libhdf5_hl.100.dylib\r\n       0x12861c000 -        0x12861dffb +libsz.2.dylib (0) <C3E13A34-DBC5-3EBD-85E2-2E68FAE23D68> /usr/local/lib/python3.7/site-packages/h5py/.dylibs/libsz.2.dylib\r\n       0x128620000 -        0x128626ff7 +libaec.0.dylib (0) <6D76AD2E-74FD-326D-ADE4-68C426692120> /usr/local/lib/python3.7/site-packages/h5py/.dylibs/libaec.0.dylib\r\n       0x128629000 -        0x128639ff7 +h5.cpython-37m-darwin.so (???) <1899543B-F829-3953-B0EF-5EFB3AB07CC6> /usr/local/lib/python3.7/site-packages/h5py/h5.cpython-37m-darwin.so\r\n       0x128649000 -        0x12866cfff +defs.cpython-37m-darwin.so (???) <1ABCC1CE-0ACB-353C-9B42-E29F9289D950> /usr/local/lib/python3.7/site-packages/h5py/defs.cpython-37m-darwin.so\r\n       0x1286c6000 -        0x1286daff7 +_objects.cpython-37m-darwin.so (???) <94D93E85-334F-324A-B273-5840104D0858> /usr/local/lib/python3.7/site-packages/h5py/_objects.cpython-37m-darwin.so\r\n       0x1286ea000 -        0x1286f5ff7 +_conv.cpython-37m-darwin.so (???) <E7F0EB5E-80FA-3138-98CD-573CB51FC990> /usr/local/lib/python3.7/site-packages/h5py/_conv.cpython-37m-darwin.so\r\n       0x1286fe000 -        0x128706ff7 +h5r.cpython-37m-darwin.so (???) <5D1A0B67-D8B7-3258-A643-89B312A80BDB> /usr/local/lib/python3.7/site-packages/h5py/h5r.cpython-37m-darwin.so\r\n       0x128710000 -        0x128769ff7 +h5t.cpython-37m-darwin.so (???) <D1D448A2-E9EF-382A-94C1-AB1F2317B8E0> /usr/local/lib/python3.7/site-packages/h5py/h5t.cpython-37m-darwin.so\r\n       0x1287a4000 -        0x1287aaff7 +utils.cpython-37m-darwin.so (???) <8806E7F1-CCA5-35BD-9FCF-D5699C3B1096> /usr/local/lib/python3.7/site-packages/h5py/utils.cpython-37m-darwin.so\r\n       0x1287be000 -        0x1287c3ff7 +h5z.cpython-37m-darwin.so (???) <348731BB-B65A-3935-AD2C-0CC959486E0A> /usr/local/lib/python3.7/site-packages/h5py/h5z.cpython-37m-darwin.so\r\n       0x1287cc000 -        0x1287e1ff7 +h5a.cpython-37m-darwin.so (???) <FAB201C3-5E9C-3602-9886-E6027F190953> /usr/local/lib/python3.7/site-packages/h5py/h5a.cpython-37m-darwin.so\r\n       0x1287f3000 -        0x128805ff7 +h5s.cpython-37m-darwin.so (???) <13CC1101-5280-3270-9D7D-737E4A427441> /usr/local/lib/python3.7/site-packages/h5py/h5s.cpython-37m-darwin.so\r\n       0x128816000 -        0x128850ff7 +h5p.cpython-37m-darwin.so (???) <3DA29D7B-1FE7-348C-8057-3335A5EEDB0A> /usr/local/lib/python3.7/site-packages/h5py/h5p.cpython-37m-darwin.so\r\n       0x12887f000 -        0x128885fff +h5ac.cpython-37m-darwin.so (???) <CF89CD6E-4C58-3F1B-8356-72D78BAF2E6D> /usr/local/lib/python3.7/site-packages/h5py/h5ac.cpython-37m-darwin.so\r\n       0x1288cd000 -        0x1288d3ff7 +_proxy.cpython-37m-darwin.so (???) <84148591-8EB7-32D1-85B3-7891C6CD388E> /usr/local/lib/python3.7/site-packages/h5py/_proxy.cpython-37m-darwin.so\r\n       0x1288d9000 -        0x1288edff7 +h5d.cpython-37m-darwin.so (???) <A8B17616-5D70-3F0D-9D6C-7E59AB535FD5> /usr/local/lib/python3.7/site-packages/h5py/h5d.cpython-37m-darwin.so\r\n       0x1288fe000 -        0x128909fff +h5ds.cpython-37m-darwin.so (???) <7646F087-8B75-3CE8-B3DC-1D94A564003C> /usr/local/lib/python3.7/site-packages/h5py/h5ds.cpython-37m-darwin.so\r\n       0x128914000 -        0x128927fff +h5f.cpython-37m-darwin.so (???) <9E6E11FA-93B5-369D-95F0-3CDC868F5D9F> /usr/local/lib/python3.7/site-packages/h5py/h5f.cpython-37m-darwin.so\r\n       0x12893b000 -        0x128956ff7 +h5g.cpython-37m-darwin.so (???) <7117C9D7-78CE-3130-9314-CA158BB02D57> /usr/local/lib/python3.7/site-packages/h5py/h5g.cpython-37m-darwin.so\r\n       0x12896b000 -        0x128972ff7 +h5i.cpython-37m-darwin.so (???) <284CB67E-DA1F-39C8-A923-DCD66999A102> /usr/local/lib/python3.7/site-packages/h5py/h5i.cpython-37m-darwin.so\r\n       0x12897b000 -        0x128998fff +h5fd.cpython-37m-darwin.so (???) <451EFC4A-353B-377A-B337-DA626B05D4EE> /usr/local/lib/python3.7/site-packages/h5py/h5fd.cpython-37m-darwin.so\r\n       0x1289ac000 -        0x1289b0ff7 +h5pl.cpython-37m-darwin.so (???) <719A4DF2-D47A-3DE3-994D-09334620E91B> /usr/local/lib/python3.7/site-packages/h5py/h5pl.cpython-37m-darwin.so\r\n       0x1289f6000 -        0x128a06fff +h5o.cpython-37m-darwin.so (???) <E03B41DA-FE8B-381A-9071-CD4823D77AAD> /usr/local/lib/python3.7/site-packages/h5py/h5o.cpython-37m-darwin.so\r\n       0x128a17000 -        0x128a27ff7 +h5l.cpython-37m-darwin.so (???) <AF5E79B7-5037-3946-8AAB-772E73C2979D> /usr/local/lib/python3.7/site-packages/h5py/h5l.cpython-37m-darwin.so\r\n       0x128c35000 -        0x128c67ff7 +_yaml.cpython-37m-darwin.so (0) <7693D57B-09AD-3EEC-80F2-4B1DABAD392F> /usr/local/lib/python3.7/site-packages/_yaml.cpython-37m-darwin.so\r\n       0x128c83000 -        0x128c9afff +libyaml-0.2.dylib (0) <15270DE5-8166-3A0F-8F39-40883D4FBC26> /usr/local/opt/libyaml/lib/libyaml-0.2.dylib\r\n       0x129211000 -        0x12930ffff +unicodedata.cpython-37m-darwin.so (0) <B1E99224-02C2-3808-9552-3EB6DA9ACB4C> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/unicodedata.cpython-37m-darwin.so\r\n       0x129463000 -        0x12946fff7 +_ccallback_c.cpython-37m-darwin.so (0) <3FD6FCC1-1434-39D1-B04A-8767E76A202B> /usr/local/lib/python3.7/site-packages/scipy/_lib/_ccallback_c.cpython-37m-darwin.so\r\n       0x1294bb000 -        0x1294c1ff7 +_uarray.cpython-37m-darwin.so (0) <E62A1703-D278-3B6D-8EC9-8D241CDF7B21> /usr/local/lib/python3.7/site-packages/scipy/_lib/_uarray/_uarray.cpython-37m-darwin.so\r\n       0x129509000 -        0x1295b2fff +pypocketfft.cpython-37m-darwin.so (0) <F6A45020-A336-3159-9A14-53D247EBD365> /usr/local/lib/python3.7/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-37m-darwin.so\r\n       0x129673000 -        0x129a74ff7 +_sparsetools.cpython-37m-darwin.so (0) <092E52E1-967E-34CB-B0A7-09174E588939> /usr/local/lib/python3.7/site-packages/scipy/sparse/_sparsetools.cpython-37m-darwin.so\r\n       0x129b92000 -        0x129bf5fff +_csparsetools.cpython-37m-darwin.so (0) <72D1E029-97E0-3B53-9C79-C1011391B6EE> /usr/local/lib/python3.7/site-packages/scipy/sparse/_csparsetools.cpython-37m-darwin.so\r\n       0x129c61000 -        0x129cb1ff3 +_shortest_path.cpython-37m-darwin.so (0) <5CC5125A-F433-3E6F-82F5-B1638F75B528> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_shortest_path.cpython-37m-darwin.so\r\n       0x129cda000 -        0x129cf4ffb +_tools.cpython-37m-darwin.so (0) <F077D312-C938-3CE1-9E9B-B4B5460455A8> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_tools.cpython-37m-darwin.so\r\n       0x129d09000 -        0x129d22ff7 +_traversal.cpython-37m-darwin.so (0) <E162A906-56F2-3C3C-B09E-52BC5DA901B8> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_traversal.cpython-37m-darwin.so\r\n       0x129d32000 -        0x129d4ffff +_min_spanning_tree.cpython-37m-darwin.so (0) <A6304FE2-E44F-3662-949F-7CD5249F2D5D> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-37m-darwin.so\r\n       0x129d64000 -        0x129d8bfff +_flow.cpython-37m-darwin.so (0) <C6E0E00B-E3E0-33A0-AC65-4869752BFFB1> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_flow.cpython-37m-darwin.so\r\n       0x129da7000 -        0x129dc5ff3 +_matching.cpython-37m-darwin.so (0) <3EEDFFCC-531B-3B06-A768-90DBE1B26CD9> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_matching.cpython-37m-darwin.so\r\n       0x129ddb000 -        0x129e04ffb +_reordering.cpython-37m-darwin.so (0) <9C3FCBB7-F07D-3CA2-84CB-EC95F26A1988> /usr/local/lib/python3.7/site-packages/scipy/sparse/csgraph/_reordering.cpython-37m-darwin.so\r\n       0x12a176000 -        0x12a197fff +_nd_image.cpython-37m-darwin.so (0) <79744D11-8BB5-394C-8FBD-15399F04CCF5> /usr/local/lib/python3.7/site-packages/scipy/ndimage/_nd_image.cpython-37m-darwin.so\r\n       0x12a19e000 -        0x12a1d8fff +_ni_label.cpython-37m-darwin.so (0) <C2E7187C-B8A8-3A0B-8F3A-9FEA8DA14043> /usr/local/lib/python3.7/site-packages/scipy/ndimage/_ni_label.cpython-37m-darwin.so\r\n       0x12a234000 -        0x12a28dff7 +_fblas.cpython-37m-darwin.so (0) <AEA5B6B6-E215-308E-ADF8-E5D46352B583> /usr/local/lib/python3.7/site-packages/scipy/linalg/_fblas.cpython-37m-darwin.so\r\n       0x12a2c5000 -        0x12dd30ae7 +libopenblasp-r0.3.7.dylib (0) <9914A383-F8C9-3559-BC88-B4DD28689BC5> /usr/local/lib/python3.7/site-packages/scipy/.dylibs/libopenblasp-r0.3.7.dylib\r\n       0x12df70000 -        0x12e087ff7 +libgfortran.3.dylib (0) <9ABE5EDE-AD43-391A-9E54-866711FAC32A> /usr/local/lib/python3.7/site-packages/scipy/.dylibs/libgfortran.3.dylib\r\n       0x12e0eb000 -        0x12e100ff7 +libgcc_s.1.dylib (0) <7C6D7CB7-82DB-3290-8181-07646FEA1F80> /usr/local/lib/python3.7/site-packages/scipy/.dylibs/libgcc_s.1.dylib\r\n       0x12e10b000 -        0x12e141fff +libquadmath.0.dylib (0) <7FFA409F-FB04-3B64-BE9A-3E3A494C975E> /usr/local/lib/python3.7/site-packages/scipy/.dylibs/libquadmath.0.dylib\r\n       0x138150000 -        0x138230fff +_flapack.cpython-37m-darwin.so (0) <EB1AF558-9C33-3C58-B4C8-660E15954550> /usr/local/lib/python3.7/site-packages/scipy/linalg/_flapack.cpython-37m-darwin.so\r\n       0x138317000 -        0x138322ff7 +_flinalg.cpython-37m-darwin.so (0) <C30E9056-FE34-30E8-86FA-F8274213F40C> /usr/local/lib/python3.7/site-packages/scipy/linalg/_flinalg.cpython-37m-darwin.so\r\n       0x13832a000 -        0x13834efff +_solve_toeplitz.cpython-37m-darwin.so (0) <C01B8789-C5E4-308C-A74B-9C289BB282DD> /usr/local/lib/python3.7/site-packages/scipy/linalg/_solve_toeplitz.cpython-37m-darwin.so\r\n       0x138367000 -        0x13839bff3 +_decomp_update.cpython-37m-darwin.so (0) <A0C567D7-AEE8-356C-957C-7B1EF346C1CC> /usr/local/lib/python3.7/site-packages/scipy/linalg/_decomp_update.cpython-37m-darwin.so\r\n       0x1383b1000 -        0x1383d6fff +cython_blas.cpython-37m-darwin.so (0) <871E4896-B5CE-3600-B570-D216676C38BD> /usr/local/lib/python3.7/site-packages/scipy/linalg/cython_blas.cpython-37m-darwin.so\r\n       0x138433000 -        0x13849fff7 +cython_lapack.cpython-37m-darwin.so (0) <F0BA7F5C-0A86-39C2-8150-ADBAF50B5A5B> /usr/local/lib/python3.7/site-packages/scipy/linalg/cython_lapack.cpython-37m-darwin.so\r\n       0x138afa000 -        0x138b1bfeb +_audio_microfrontend_op.so (0) <C6CAC39C-56FE-3970-811E-E73F1A0C6A7A> /usr/local/lib/python3.7/site-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so\r\n       0x138cb1000 -        0x138ce6ffb +conversion.cpython-37m-darwin.so (0) <DDBD607A-A709-3526-8AB8-C596C58F0EFF> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/conversion.cpython-37m-darwin.so\r\n       0x138d04000 -        0x138d30ffb +c_timestamp.cpython-37m-darwin.so (0) <7249D689-5CEE-342D-887E-AD2D56F6ADDE> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/c_timestamp.cpython-37m-darwin.so\r\n       0x138d4d000 -        0x138d70ff3 +nattype.cpython-37m-darwin.so (0) <1A180941-EBA4-3B2B-9C6F-7BDFF60BCC18> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/nattype.cpython-37m-darwin.so\r\n       0x138d91000 -        0x138db4ff7 +missing.cpython-37m-darwin.so (0) <39757BAE-6D73-3BEA-9A28-CDA1BBEE10F3> /usr/local/lib/python3.7/site-packages/pandas/_libs/missing.cpython-37m-darwin.so\r\n       0x138dd2000 -        0x138ddafff +np_datetime.cpython-37m-darwin.so (0) <F57418D3-5C39-3081-AFAB-76B7560931E8> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/np_datetime.cpython-37m-darwin.so\r\n       0x138de2000 -        0x138de8ffb +ops_dispatch.cpython-37m-darwin.so (0) <B3F750B4-98E1-34AA-B640-D6966DE49B4B> /usr/local/lib/python3.7/site-packages/pandas/_libs/ops_dispatch.cpython-37m-darwin.so\r\n       0x138df2000 -        0x138e1bfff +timezones.cpython-37m-darwin.so (0) <AFAC4D4D-82E5-3883-8194-E3F94D04AA0E> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/timezones.cpython-37m-darwin.so\r\n       0x138e76000 -        0x138eb1ffb +tzconversion.cpython-37m-darwin.so (0) <82BE94D5-C146-3BCA-9622-22E425B09EC2> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/tzconversion.cpython-37m-darwin.so\r\n       0x138ed0000 -        0x138f25ff3 +timedeltas.cpython-37m-darwin.so (0) <9F4DDBFD-7562-35F9-9960-EBB973DB9DDA> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/timedeltas.cpython-37m-darwin.so\r\n       0x138f5a000 -        0x138fa3ffb +offsets.cpython-37m-darwin.so (0) <EC102C71-440A-36E2-AFE6-81268F7387D8> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/offsets.cpython-37m-darwin.so\r\n       0x138fd4000 -        0x138fddffb +ccalendar.cpython-37m-darwin.so (0) <DAA2D8F7-EDAF-30BA-B41F-5EDE76928148> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/ccalendar.cpython-37m-darwin.so\r\n       0x139029000 -        0x139073ff3 +strptime.cpython-37m-darwin.so (0) <B117723E-B699-3CF9-A42B-7230386DC683> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/strptime.cpython-37m-darwin.so\r\n       0x1390a1000 -        0x1390ccff3 +fields.cpython-37m-darwin.so (0) <84EC12F3-76C4-3360-88C8-99B358356B1C> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/fields.cpython-37m-darwin.so\r\n       0x1390e8000 -        0x139135fff +parsing.cpython-37m-darwin.so (0) <FF2C029E-D5B9-3FFF-B854-02CD4C632B1B> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/parsing.cpython-37m-darwin.so\r\n       0x139164000 -        0x139179ff7 +frequencies.cpython-37m-darwin.so (0) <8D72B150-5CF5-38EC-999D-3FEF6596F9D3> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/frequencies.cpython-37m-darwin.so\r\n       0x1391cc000 -        0x13921cffb +period.cpython-37m-darwin.so (0) <4EB6832A-FC5F-31B7-8EC3-9AC8989C5249> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/period.cpython-37m-darwin.so\r\n       0x13924c000 -        0x139281fff +timestamps.cpython-37m-darwin.so (0) <19DA9DA4-99E2-3727-AE05-5CC1FEDF470A> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/timestamps.cpython-37m-darwin.so\r\n       0x1392ad000 -        0x1392d6ff3 +resolution.cpython-37m-darwin.so (0) <6BAD1113-FABB-3295-9733-2B1217815278> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslibs/resolution.cpython-37m-darwin.so\r\n       0x1392f5000 -        0x13936bff3 +hashtable.cpython-37m-darwin.so (0) <B245FB87-AA7F-3EE5-9A0E-46A6FB07E19C> /usr/local/lib/python3.7/site-packages/pandas/_libs/hashtable.cpython-37m-darwin.so\r\n       0x1393aa000 -        0x139412ffb +lib.cpython-37m-darwin.so (0) <74760D88-2F8C-339D-9183-96B89587C98B> /usr/local/lib/python3.7/site-packages/pandas/_libs/lib.cpython-37m-darwin.so\r\n       0x139495000 -        0x1394cffff +tslib.cpython-37m-darwin.so (0) <0FC137A8-1651-30A8-807E-92D49D9392D4> /usr/local/lib/python3.7/site-packages/pandas/_libs/tslib.cpython-37m-darwin.so\r\n       0x1394ee000 -        0x1395f0ff7 +interval.cpython-37m-darwin.so (0) <D9CFAE8E-4360-3A8E-8D51-6C18F1C17E66> /usr/local/lib/python3.7/site-packages/pandas/_libs/interval.cpython-37m-darwin.so\r\n       0x139693000 -        0x1397fdff3 +algos.cpython-37m-darwin.so (0) <AA8C1321-000B-3D52-96D0-B1C251766628> /usr/local/lib/python3.7/site-packages/pandas/_libs/algos.cpython-37m-darwin.so\r\n       0x1398a8000 -        0x1398b0fff +properties.cpython-37m-darwin.so (0) <9BAEF485-9FBF-382D-ADA5-62D2EACD9B01> /usr/local/lib/python3.7/site-packages/pandas/_libs/properties.cpython-37m-darwin.so\r\n       0x1398fa000 -        0x139918ffb +hashing.cpython-37m-darwin.so (0) <4840CC55-23B4-3AD7-889B-327BDAE9D2AC> /usr/local/lib/python3.7/site-packages/pandas/_libs/hashing.cpython-37m-darwin.so\r\n       0x13996c000 -        0x139993ff3 +ops.cpython-37m-darwin.so (0) <CF2EBB10-B3BD-3476-A79D-F946C05254F2> /usr/local/lib/python3.7/site-packages/pandas/_libs/ops.cpython-37m-darwin.so\r\n       0x139b5e000 -        0x139be2ffb +index.cpython-37m-darwin.so (0) <FB5DAC34-683B-39FB-B393-E412FBD9BB7C> /usr/local/lib/python3.7/site-packages/pandas/_libs/index.cpython-37m-darwin.so\r\n       0x139c22000 -        0x139e81ffb +join.cpython-37m-darwin.so (0) <D1A146B1-0296-3356-8650-4AA31173079E> /usr/local/lib/python3.7/site-packages/pandas/_libs/join.cpython-37m-darwin.so\r\n       0x139fc6000 -        0x13a094ff7 +sparse.cpython-37m-darwin.so (0) <0C37B8A4-F904-3C6F-B0AF-18149F513FD3> /usr/local/lib/python3.7/site-packages/pandas/_libs/sparse.cpython-37m-darwin.so\r\n       0x13a24c000 -        0x13a251ff7 +indexing.cpython-37m-darwin.so (0) <6CB18AD5-9DA2-3F33-9476-3ACA976BFC0D> /usr/local/lib/python3.7/site-packages/pandas/_libs/indexing.cpython-37m-darwin.so\r\n       0x13a298000 -        0x13a2baffb +writers.cpython-37m-darwin.so (0) <C5C23CF2-E6D3-3D0F-AC06-8DE3468AA2F5> /usr/local/lib/python3.7/site-packages/pandas/_libs/writers.cpython-37m-darwin.so\r\n       0x13a2d2000 -        0x13a2ffff3 +internals.cpython-37m-darwin.so (0) <6C1D689F-CC27-3109-AC07-80E7DDE98B16> /usr/local/lib/python3.7/site-packages/pandas/_libs/internals.cpython-37m-darwin.so\r\n       0x13a39b000 -        0x13a39dfff +mmap.cpython-37m-darwin.so (0) <2B2C6B2D-5F91-39AC-9F71-86A28D8B65D6> /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/mmap.cpython-37m-darwin.so\r\n       0x13a3e1000 -        0x13a40fff3 +reshape.cpython-37m-darwin.so (0) <4A75EFBA-B85C-32E6-ABB9-FFBDEC6AFC13> /usr/local/lib/python3.7/site-packages/pandas/_libs/reshape.cpython-37m-darwin.so\r\n       0x13a468000 -        0x13a4b5ff3 +aggregations.cpython-37m-darwin.so (0) <AC69E779-34E4-374E-A8B3-211896659BC6> /usr/local/lib/python3.7/site-packages/pandas/_libs/window/aggregations.cpython-37m-darwin.so\r\n       0x13a521000 -        0x13a53cff7 +indexers.cpython-37m-darwin.so (0) <031F887D-088D-3E95-857A-057AF6245C60> /usr/local/lib/python3.7/site-packages/pandas/_libs/window/indexers.cpython-37m-darwin.so\r\n       0x13a58f000 -        0x13a69dfff +groupby.cpython-37m-darwin.so (0) <A5F67E8C-33CA-3BBD-8650-A4088E7DE3F0> /usr/local/lib/python3.7/site-packages/pandas/_libs/groupby.cpython-37m-darwin.so\r\n       0x13a6e6000 -        0x13a727ff7 +reduction.cpython-37m-darwin.so (0) <480A482A-26C7-31E3-BF29-584DB9B79642> /usr/local/lib/python3.7/site-packages/pandas/_libs/reduction.cpython-37m-darwin.so\r\n       0x13a80a000 -        0x13a873ffb +parsers.cpython-37m-darwin.so (0) <983D1114-5920-39BC-AAB9-70C6DADB489B> /usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.cpython-37m-darwin.so\r\n       0x13a8ee000 -        0x13a8fcff3 +json.cpython-37m-darwin.so (0) <583B7F1F-2BE1-3FC8-8B71-2EF1988EA43A> /usr/local/lib/python3.7/site-packages/pandas/_libs/json.cpython-37m-darwin.so\r\n       0x13aa46000 -        0x13aa55ff7 +testing.cpython-37m-darwin.so (0) <FD7F1DC6-F0F4-36D1-B71E-806D9A222AC4> /usr/local/lib/python3.7/site-packages/pandas/_libs/testing.cpython-37m-darwin.so\r\n       0x13ad20000 -        0x13ad2fff7 +identity_dataset_op.so (0) <ABBBFCA0-1BD6-34B8-B628-377266BDAD27> /Users/USER/Documents/*/identity_dataset_op.so\r\n    0x7fff26393000 -     0x7fff263a2ff7  libSimplifiedChineseConverter.dylib (76) <3A38C5A2-0D75-34F2-A30C-22E346092611> /System/Library/CoreServices/Encodings/libSimplifiedChineseConverter.dylib\r\n    0x7fff2efce000 -     0x7fff2efcefff  com.apple.Accelerate (1.11 - Accelerate 1.11) <8BE0965F-6A6A-35B0-89D0-F0A75835C2CA> /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate\r\n    0x7fff2efe6000 -     0x7fff2f63cfef  com.apple.vImage (8.1 - 524.2) <DAE0E5C5-BA70-325D-8B4C-6B821F009CBF> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage\r\n    0x7fff2f63d000 -     0x7fff2f8a4ff7  libBLAS.dylib (1303.60.1) <4E980D6B-4B3A-33D6-B52C-AFC7D120D11A> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\r\n    0x7fff2f8a5000 -     0x7fff2fd78fef  libBNNS.dylib (144.100.2) <C05F9F9D-4498-37BD-9C1C-2F7B920B401D> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib\r\n    0x7fff2fd79000 -     0x7fff30114fff  libLAPACK.dylib (1303.60.1) <F8E9D081-7C60-32EC-A47D-2D30CAD73C5F> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib\r\n    0x7fff30115000 -     0x7fff3012afec  libLinearAlgebra.dylib (1303.60.1) <79CB28C5-F811-3EAF-AD8E-7D7D879FE662> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib\r\n    0x7fff3012b000 -     0x7fff30130ff3  libQuadrature.dylib (7) <EB7C9E98-D1E7-314C-90B4-3EB04428CC7C> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib\r\n    0x7fff30131000 -     0x7fff301a1fff  libSparse.dylib (103) <8C55F5F2-6AE3-393C-B2FF-22B8CFCBD7FC> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib\r\n    0x7fff301a2000 -     0x7fff301b4fef  libSparseBLAS.dylib (1303.60.1) <08F6D629-5DAC-3A99-B261-2B6095DD38B4> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib\r\n    0x7fff301b5000 -     0x7fff3038cfd7  libvDSP.dylib (735.100.4) <0744F29B-F822-3571-9B4A-B592146D4E03> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib\r\n    0x7fff3038d000 -     0x7fff3044ffef  libvMisc.dylib (735.100.4) <E6C94B52-931B-3858-AF4D-C2EA52ACB7F5> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib\r\n    0x7fff30450000 -     0x7fff30450fff  com.apple.Accelerate.vecLib (3.11 - vecLib 3.11) <66282197-81EE-316F-978E-EF1471551DEF> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib\r\n    0x7fff31bb1000 -     0x7fff31f3fffd  com.apple.CFNetwork (1125.2 - 1125.2) <1D4D81F7-FC48-3588-87FC-481E2586E345> /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork\r\n    0x7fff3333a000 -     0x7fff337b9ffb  com.apple.CoreFoundation (6.9 - 1675.129) <9E632A1E-9622-33D6-BCCE-23AC16DAA6B7> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\r\n    0x7fff34722000 -     0x7fff34722fff  com.apple.CoreServices (1069.22 - 1069.22) <888FE7B9-CE6C-3C7C-BA33-63364462228A> /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices\r\n    0x7fff34723000 -     0x7fff347a8fff  com.apple.AE (838.1 - 838.1) <2BAB1B88-C198-3D20-8DA3-056E66510E7A> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE\r\n    0x7fff347a9000 -     0x7fff34a8aff7  com.apple.CoreServices.CarbonCore (1217 - 1217) <D0FECC17-7E16-308F-98EA-AF311CB77FE6> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore\r\n    0x7fff34a8b000 -     0x7fff34ad8ffd  com.apple.DictionaryServices (1.2 - 323.6) <11513ED9-8B4B-39BB-A6B2-AA6AA0A2DF72> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices\r\n    0x7fff34ad9000 -     0x7fff34ae1ff7  com.apple.CoreServices.FSEvents (1268.100.1 - 1268.100.1) <CE3D8B13-2583-3527-8532-D5DDAAD7D56B> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents\r\n    0x7fff34ae2000 -     0x7fff34d1bffc  com.apple.LaunchServices (1069.22 - 1069.22) <E51EE658-608C-3034-9635-4FDF1E241E62> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices\r\n    0x7fff34d1c000 -     0x7fff34db4ff1  com.apple.Metadata (10.7.0 - 2076.3) <EE42CCA1-FEC2-3F1C-9B62-2E73EFB05FCC> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata\r\n    0x7fff34db5000 -     0x7fff34de2fff  com.apple.CoreServices.OSServices (1069.22 - 1069.22) <A0654B4E-3194-3066-911F-FF1FBEE1D2C2> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices\r\n    0x7fff34de3000 -     0x7fff34e4afff  com.apple.SearchKit (1.4.1 - 1.4.1) <D4F82BC9-FD9B-3E04-B78E-D9E2A73B0BD7> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit\r\n    0x7fff34e4b000 -     0x7fff34e6fff5  com.apple.coreservices.SharedFileList (131.4 - 131.4) <AEB4E42C-F5A2-3F63-80B0-4226483AD4F5> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList\r\n    0x7fff356b5000 -     0x7fff356bbfff  com.apple.DiskArbitration (2.7 - 2.7) <D7617B57-B01C-3848-8818-593FB12039E9> /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration\r\n    0x7fff359f0000 -     0x7fff35db5ff8  com.apple.Foundation (6.9 - 1675.129) <9A74FA97-7F7B-3929-B381-D9514B1E4754> /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation\r\n    0x7fff36129000 -     0x7fff361cdff3  com.apple.framework.IOKit (2.0.2 - 1726.100.16) <3D8BA34A-AAF7-3AF2-9B5B-189AC4755404> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit\r\n    0x7fff39ccc000 -     0x7fff39cd8ffe  com.apple.NetFS (6.0 - 4.0) <7A96A8FE-17F3-3850-8E81-9DDDC5A48DDB> /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS\r\n    0x7fff3c8ba000 -     0x7fff3c8d6fff  com.apple.CFOpenDirectory (10.15 - 220.40.1) <58835104-9E7A-32E8-862B-530CE899C9B4> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory\r\n    0x7fff3c8d7000 -     0x7fff3c8e2ffd  com.apple.OpenDirectory (10.15 - 220.40.1) <D846BA35-59A1-3B78-B1C8-7E0EDE972AD2> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory\r\n    0x7fff3fc7c000 -     0x7fff3ffc5ff1  com.apple.security (7.0 - 59306.101.1) <430E04FE-F068-3476-9CA2-72CB5F040D1F> /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n    0x7fff3ffc6000 -     0x7fff4004effb  com.apple.securityfoundation (6.0 - 55236.60.1) <BC15B825-955D-33CF-B416-A64D69A1D008> /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation\r\n    0x7fff4007d000 -     0x7fff40081ff8  com.apple.xpc.ServiceManagement (1.0 - 1) <C66FC9CF-224B-348C-94A5-ABAC579F5C0A> /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement\r\n    0x7fff40d2c000 -     0x7fff40d9aff7  com.apple.SystemConfiguration (1.19 - 1.19) <71AC15DE-7018-3D2B-B599-F2972F0288AE> /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration\r\n    0x7fff44cf7000 -     0x7fff44dbcff7  com.apple.APFS (1412.101.1 - 1412.101.1) <2F5A48FB-9788-3A24-87FE-C1B7DDBC8A07> /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS\r\n    0x7fff46c41000 -     0x7fff46c50fd7  com.apple.AppleFSCompression (119.100.1 - 1.0) <E1B024EB-DAB1-30A1-A43D-01D9E9357F2B> /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression\r\n    0x7fff4840f000 -     0x7fff48418ff7  com.apple.coreservices.BackgroundTaskManagement (1.0 - 104) <2088BC70-5329-3390-A851-C4ECF654047C> /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement\r\n    0x7fff4b1ce000 -     0x7fff4b1deff3  com.apple.CoreEmoji (1.0 - 107) <AC83B860-61BD-384E-81BF-CA3CBE655968> /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji\r\n    0x7fff4b81e000 -     0x7fff4b888ff0  com.apple.CoreNLP (1.0 - 213) <687A4C31-A307-3255-83BE-9B123971FF62> /System/Library/PrivateFrameworks/CoreNLP.framework/Versions/A/CoreNLP\r\n    0x7fff4c703000 -     0x7fff4c731ffd  com.apple.CSStore (1069.22 - 1069.22) <39E431F9-3584-34DF-A64D-C5895AA72068> /System/Library/PrivateFrameworks/CoreServicesStore.framework/Versions/A/CoreServicesStore\r\n    0x7fff5895c000 -     0x7fff58a2affd  com.apple.LanguageModeling (1.0 - 215.1) <3FAF1700-F7D4-3F92-88AA-A3920702B8BB> /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling\r\n    0x7fff58a2b000 -     0x7fff58a73fff  com.apple.Lexicon-framework (1.0 - 72) <212D02CE-11BC-3C7F-BDFD-DF1A0C4017EE> /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon\r\n    0x7fff58a7a000 -     0x7fff58a7fff3  com.apple.LinguisticData (1.0 - 353.18) <BA3869B7-9C39-32DA-A4BA-12F1BC4B04CF> /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData\r\n    0x7fff59de6000 -     0x7fff59e32fff  com.apple.spotlight.metadata.utilities (1.0 - 2076.3) <EF8AC054-B15F-375F-AACB-018DC73CD16E> /System/Library/PrivateFrameworks/MetadataUtilities.framework/Versions/A/MetadataUtilities\r\n    0x7fff5a8e7000 -     0x7fff5a8f1fff  com.apple.NetAuth (6.2 - 6.2) <D324C7CC-E614-35F6-8619-DECBE90ECAEB> /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth\r\n    0x7fff63b51000 -     0x7fff63b61ff3  com.apple.TCC (1.0 - 1) <AEE98D6E-03FD-3C80-90AC-5B45B4AE7A2E> /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC\r\n    0x7fff6722c000 -     0x7fff6722eff3  com.apple.loginsupport (1.0 - 1) <B84ABC31-431B-3F99-BABE-44ED0A7DB3C0> /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport\r\n    0x7fff69d47000 -     0x7fff69d7bfff  libCRFSuite.dylib (48) <E52BECF7-1819-3998-ACC4-8D1A332CE4EB> /usr/lib/libCRFSuite.dylib\r\n    0x7fff69d7e000 -     0x7fff69d88fff  libChineseTokenizer.dylib (34) <EE842A48-3D30-34B0-B9D2-F045DE582650> /usr/lib/libChineseTokenizer.dylib\r\n    0x7fff69e14000 -     0x7fff69e16ff7  libDiagnosticMessagesClient.dylib (112) <BE749883-9400-334A-8FBF-F3321CF205F5> /usr/lib/libDiagnosticMessagesClient.dylib\r\n    0x7fff6a2ea000 -     0x7fff6a2ebfff  libSystem.B.dylib (1281.100.1) <DB8310F1-272D-3533-A840-3B390AF55C26> /usr/lib/libSystem.B.dylib\r\n    0x7fff6a378000 -     0x7fff6a379fff  libThaiTokenizer.dylib (3) <DC582222-7C1F-3C27-8C3A-BAF696A2197D> /usr/lib/libThaiTokenizer.dylib\r\n    0x7fff6a391000 -     0x7fff6a3a7fff  libapple_nghttp2.dylib (1.39.2) <268F4E3E-95DC-35FB-82DC-5B0D1855A676> /usr/lib/libapple_nghttp2.dylib\r\n    0x7fff6a3dc000 -     0x7fff6a44eff7  libarchive.2.dylib (72.100.1) <65E0870E-02AB-365D-84F9-5800B5BB69FC> /usr/lib/libarchive.2.dylib\r\n    0x7fff6a4ec000 -     0x7fff6a4ecff3  libauto.dylib (187) <FD0E5750-7004-36A7-B9C2-D6B6B4EF559B> /usr/lib/libauto.dylib\r\n    0x7fff6a5b2000 -     0x7fff6a5c2ffb  libbsm.0.dylib (60.100.1) <B0373A39-DBC6-3A84-879B-BA46E30D04BF> /usr/lib/libbsm.0.dylib\r\n    0x7fff6a5c3000 -     0x7fff6a5cffff  libbz2.1.0.dylib (44) <FFCD4427-AF87-36D2-8097-8870FDC75A1B> /usr/lib/libbz2.1.0.dylib\r\n    0x7fff6a5d0000 -     0x7fff6a622fff  libc++.1.dylib (902.1) <08199809-33CA-321E-9B9D-FD5B2BC64580> /usr/lib/libc++.1.dylib\r\n    0x7fff6a623000 -     0x7fff6a638ffb  libc++abi.dylib (902) <1C880020-396D-3F91-BE27-5A09A9239F68> /usr/lib/libc++abi.dylib\r\n    0x7fff6a639000 -     0x7fff6a639fff  libcharset.1.dylib (59) <4E63BA25-04A3-329A-923D-251155C03F30> /usr/lib/libcharset.1.dylib\r\n    0x7fff6a63a000 -     0x7fff6a64bfff  libcmph.dylib (8) <D4C5E0A8-92D9-33D5-9F83-6F4742FFBE29> /usr/lib/libcmph.dylib\r\n    0x7fff6a64c000 -     0x7fff6a663fd7  libcompression.dylib (87) <7F258A06-E01D-32D2-9CD2-6B2931DA5DA7> /usr/lib/libcompression.dylib\r\n    0x7fff6a93d000 -     0x7fff6a953ff7  libcoretls.dylib (167) <EFC237BB-78F7-33C6-BFF9-53860062DD99> /usr/lib/libcoretls.dylib\r\n    0x7fff6a954000 -     0x7fff6a955fff  libcoretls_cfhelpers.dylib (167) <2E542A2B-7730-33EE-9B3B-154B08608AA6> /usr/lib/libcoretls_cfhelpers.dylib\r\n    0x7fff6b07d000 -     0x7fff6b07dfff  libenergytrace.dylib (21) <FFB9FB70-8DBD-3025-BC92-51F02481A489> /usr/lib/libenergytrace.dylib\r\n    0x7fff6b0a4000 -     0x7fff6b0a6fff  libfakelink.dylib (149.1) <B04F9A05-7E52-3382-9186-F603BE4BFBB2> /usr/lib/libfakelink.dylib\r\n    0x7fff6b0b5000 -     0x7fff6b0bafff  libgermantok.dylib (24) <8091F952-B592-38E3-982B-7DEA0A44E211> /usr/lib/libgermantok.dylib\r\n    0x7fff6b0c5000 -     0x7fff6b1b5fff  libiconv.2.dylib (59) <9458704B-A702-37CB-9707-66ABBB5DB71E> /usr/lib/libiconv.2.dylib\r\n    0x7fff6b1b6000 -     0x7fff6b40dfff  libicucore.A.dylib (64260.0.1) <DCC4A4EE-32FD-350F-84D8-E857F2F29855> /usr/lib/libicucore.A.dylib\r\n    0x7fff6b427000 -     0x7fff6b428fff  liblangid.dylib (133) <E9595222-602B-38F0-8572-0F1872A00527> /usr/lib/liblangid.dylib\r\n    0x7fff6b429000 -     0x7fff6b441ff3  liblzma.5.dylib (16) <0AA1EB11-A433-327E-B8DB-7395CFF06554> /usr/lib/liblzma.5.dylib\r\n    0x7fff6b459000 -     0x7fff6b500ff7  libmecab.dylib (883.10) <13136C11-8763-37BA-AEB2-676092798DAA> /usr/lib/libmecab.dylib\r\n    0x7fff6b501000 -     0x7fff6b763fe1  libmecabra.dylib (883.10) <6AC22857-F528-35CE-94A9-D70F6F766C15> /usr/lib/libmecabra.dylib\r\n    0x7fff6bc2f000 -     0x7fff6c0aaff5  libnetwork.dylib (1880.100.30) <9519B6F8-44E2-3F53-B995-1527C5333240> /usr/lib/libnetwork.dylib\r\n    0x7fff6c14a000 -     0x7fff6c17dfde  libobjc.A.dylib (787.1) <20AC082F-2DB7-3974-A2D4-8C5E01787584> /usr/lib/libobjc.A.dylib\r\n    0x7fff6c190000 -     0x7fff6c194fff  libpam.2.dylib (25.100.1) <D5CEC1AD-A2EC-362C-B71A-22FD521917F1> /usr/lib/libpam.2.dylib\r\n    0x7fff6c197000 -     0x7fff6c1cdff7  libpcap.A.dylib (89.100.1) <171BAAB0-A5C8-32C5-878E-83D46073BF8C> /usr/lib/libpcap.A.dylib\r\n    0x7fff6c2c5000 -     0x7fff6c4afff7  libsqlite3.dylib (308.4) <BBC375B7-AF20-3D2C-8826-78D3BDC8A004> /usr/lib/libsqlite3.dylib\r\n    0x7fff6c700000 -     0x7fff6c703ffb  libutil.dylib (57) <07ED7CF0-1744-3386-B8B2-0DDBD446999E> /usr/lib/libutil.dylib\r\n    0x7fff6c704000 -     0x7fff6c711ff7  libxar.1.dylib (425.2) <625F24E1-1A0F-3301-9F99-F0F3DADE0287> /usr/lib/libxar.1.dylib\r\n    0x7fff6c717000 -     0x7fff6c7f9ff7  libxml2.2.dylib (33.3) <24147A90-E3EB-3926-BFB0-5F0FC9F706E2> /usr/lib/libxml2.2.dylib\r\n    0x7fff6c7fd000 -     0x7fff6c825fff  libxslt.1.dylib (16.9) <8C8648B1-F2CA-38EA-A409-D6F19715C6E6> /usr/lib/libxslt.1.dylib\r\n    0x7fff6c826000 -     0x7fff6c838ff3  libz.1.dylib (76) <6A449C6A-DF88-36C1-8F2D-DB9A808263B5> /usr/lib/libz.1.dylib\r\n    0x7fff6d0e6000 -     0x7fff6d0ebff3  libcache.dylib (83) <5F90FFCE-403B-3724-991D-BA32401D99C5> /usr/lib/system/libcache.dylib\r\n    0x7fff6d0ec000 -     0x7fff6d0f7fff  libcommonCrypto.dylib (60165) <C7A5E3F7-1E5A-3785-875A-B6647082B614> /usr/lib/system/libcommonCrypto.dylib\r\n    0x7fff6d0f8000 -     0x7fff6d0fffff  libcompiler_rt.dylib (101.2) <A517E149-2D25-3C04-BCEF-F69149C85B18> /usr/lib/system/libcompiler_rt.dylib\r\n    0x7fff6d100000 -     0x7fff6d109ff7  libcopyfile.dylib (166.40.1) <1A5270B5-0D97-35DA-9296-4F4A428BC6A2> /usr/lib/system/libcopyfile.dylib\r\n    0x7fff6d10a000 -     0x7fff6d19cfe3  libcorecrypto.dylib (866.100.30) <FCDEC0D1-8C30-3989-BDD1-996BBC715C29> /usr/lib/system/libcorecrypto.dylib\r\n    0x7fff6d2a9000 -     0x7fff6d2e9ff0  libdispatch.dylib (1173.100.2) <EB592997-B11C-3AB3-85B1-F725F3D0B412> /usr/lib/system/libdispatch.dylib\r\n    0x7fff6d2ea000 -     0x7fff6d320fff  libdyld.dylib (750.5) <D2A07EF5-A64B-3692-BE13-89DAA2EC5E80> /usr/lib/system/libdyld.dylib\r\n    0x7fff6d321000 -     0x7fff6d321ffb  libkeymgr.dylib (30) <CC5A2B43-770B-3C6C-BA10-AA3A6B4A142D> /usr/lib/system/libkeymgr.dylib\r\n    0x7fff6d322000 -     0x7fff6d32eff3  libkxld.dylib (6153.101.6) <77282DCB-83D6-3199-874E-9A4A0FD7D4F3> /usr/lib/system/libkxld.dylib\r\n    0x7fff6d32f000 -     0x7fff6d32fff7  liblaunch.dylib (1738.100.39) <A7FF7357-600F-3014-8C28-A4F367717E8D> /usr/lib/system/liblaunch.dylib\r\n    0x7fff6d330000 -     0x7fff6d335ff7  libmacho.dylib (959.0.1) <D8FED478-25A2-3844-AE4B-A5C9F9827615> /usr/lib/system/libmacho.dylib\r\n    0x7fff6d336000 -     0x7fff6d338ff3  libquarantine.dylib (110.40.3) <51E0304F-AB11-3BF7-99DC-BB916CC9088B> /usr/lib/system/libquarantine.dylib\r\n    0x7fff6d339000 -     0x7fff6d33aff7  libremovefile.dylib (48) <078F29AB-26BA-3493-BCAA-E1E75A187521> /usr/lib/system/libremovefile.dylib\r\n    0x7fff6d33b000 -     0x7fff6d352ff3  libsystem_asl.dylib (377.60.2) <0F1BAC19-2AE0-3F8E-9B90-AACF819B2BF7> /usr/lib/system/libsystem_asl.dylib\r\n    0x7fff6d353000 -     0x7fff6d353ff7  libsystem_blocks.dylib (74) <32224AFF-C06F-3279-B753-097194EDEF49> /usr/lib/system/libsystem_blocks.dylib\r\n    0x7fff6d354000 -     0x7fff6d3dbfff  libsystem_c.dylib (1353.100.2) <4F5EED22-4D46-3F04-8C64-C492CDAD70EB> /usr/lib/system/libsystem_c.dylib\r\n    0x7fff6d3dc000 -     0x7fff6d3dfffb  libsystem_configuration.dylib (1061.101.1) <2A2C778D-07EB-35C7-A954-8BF8FD74BD75> /usr/lib/system/libsystem_configuration.dylib\r\n    0x7fff6d3e0000 -     0x7fff6d3e3fff  libsystem_coreservices.dylib (114) <FDA41CC4-170A-3D93-85BD-838A563B03C4> /usr/lib/system/libsystem_coreservices.dylib\r\n    0x7fff6d3e4000 -     0x7fff6d3ecfff  libsystem_darwin.dylib (1353.100.2) <B567B86D-8818-38A4-A861-03EB83B55867> /usr/lib/system/libsystem_darwin.dylib\r\n    0x7fff6d3ed000 -     0x7fff6d3f4fff  libsystem_dnssd.dylib (1096.100.3) <7C690DF5-E119-33FB-85CD-9EFC67A36E40> /usr/lib/system/libsystem_dnssd.dylib\r\n    0x7fff6d3f5000 -     0x7fff6d3f6ffb  libsystem_featureflags.dylib (17) <415D83EF-084C-3485-B757-53001870EA94> /usr/lib/system/libsystem_featureflags.dylib\r\n    0x7fff6d3f7000 -     0x7fff6d444ff7  libsystem_info.dylib (538) <17049D3F-C798-3651-B391-1551FC699D3E> /usr/lib/system/libsystem_info.dylib\r\n    0x7fff6d445000 -     0x7fff6d471ff7  libsystem_kernel.dylib (6153.101.6) <E76440E1-D1E8-3D9A-8B47-D01F554FF1C4> /usr/lib/system/libsystem_kernel.dylib\r\n    0x7fff6d472000 -     0x7fff6d4b9fff  libsystem_m.dylib (3178) <74741FA8-5C29-3241-9046-4FC91C6A6D4A> /usr/lib/system/libsystem_m.dylib\r\n    0x7fff6d4ba000 -     0x7fff6d4e1fff  libsystem_malloc.dylib (283.100.5) <97833239-2F83-3AEB-A426-0593997C8A54> /usr/lib/system/libsystem_malloc.dylib\r\n    0x7fff6d4e2000 -     0x7fff6d4efffb  libsystem_networkextension.dylib (1095.100.29) <C9E988B2-6A18-35C0-9577-63201E9D6018> /usr/lib/system/libsystem_networkextension.dylib\r\n    0x7fff6d4f0000 -     0x7fff6d4f9ff7  libsystem_notify.dylib (241.100.2) <E405F84B-BD4F-3874-9755-CB3EC86E18D5> /usr/lib/system/libsystem_notify.dylib\r\n    0x7fff6d4fa000 -     0x7fff6d502fef  libsystem_platform.dylib (220.100.1) <6EF12F34-C33F-36BF-9A9A-2A35EA19EFE0> /usr/lib/system/libsystem_platform.dylib\r\n    0x7fff6d503000 -     0x7fff6d50dfff  libsystem_pthread.dylib (416.100.3) <A8514582-E000-3854-911A-0A73D2C79600> /usr/lib/system/libsystem_pthread.dylib\r\n    0x7fff6d50e000 -     0x7fff6d512ff3  libsystem_sandbox.dylib (1217.101.2) <E9D78CDE-FB67-32E7-BABC-9EFC23AA0DC6> /usr/lib/system/libsystem_sandbox.dylib\r\n    0x7fff6d513000 -     0x7fff6d515fff  libsystem_secinit.dylib (62.100.2) <AAC639E5-7103-3366-A602-8FC6944E2C13> /usr/lib/system/libsystem_secinit.dylib\r\n    0x7fff6d516000 -     0x7fff6d51dffb  libsystem_symptoms.dylib (1238.100.26) <487B92DE-45F9-39F9-A478-89BBD478157D> /usr/lib/system/libsystem_symptoms.dylib\r\n    0x7fff6d51e000 -     0x7fff6d534ff2  libsystem_trace.dylib (1147.100.8) <BB90B1FD-8C09-3DF4-BD8B-9E4AEADFEA2B> /usr/lib/system/libsystem_trace.dylib\r\n    0x7fff6d536000 -     0x7fff6d53bff7  libunwind.dylib (35.4) <CC87C836-BE9D-334E-A0E6-0297D52E9D73> /usr/lib/system/libunwind.dylib\r\n    0x7fff6d53c000 -     0x7fff6d571ffe  libxpc.dylib (1738.100.39) <32B0E31E-9DA3-328B-A962-BC9591B93537> /usr/lib/system/libxpc.dylib\r\n\r\nExternal Modification Summary:\r\n  Calls made by other processes targeting this process:\r\n    task_for_pid: 0\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n  Calls made by this process:\r\n    task_for_pid: 0\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n  Calls made by all processes on this machine:\r\n    task_for_pid: 18670\r\n    thread_create: 0\r\n    thread_set_state: 0\r\n\r\nVM Region Summary:\r\nReadOnly portion of Libraries: Total=982.5M resident=0K(0%) swapped_out_or_unallocated=982.5M(100%)\r\nWritable regions: Total=527.6M written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=527.6M(100%)\r\n \r\n                                VIRTUAL   REGION \r\nREGION TYPE                        SIZE    COUNT (non-coalesced) \r\n===========                     =======  ======= \r\nKernel Alloc Once                    8K        1 \r\nMALLOC                            95.7M       84 \r\nMALLOC guard page                   16K        3 \r\nMALLOC_LARGE (reserved)            384K        2         reserved VM address space (unallocated)\r\nSTACK GUARD                        188K       47 \r\nStack                             39.4M       47 \r\nVM_ALLOCATE                       70.6M      284 \r\nVM_ALLOCATE (reserved)           320.0M        2         reserved VM address space (unallocated)\r\n__DATA                            17.6M      343 \r\n__DATA_CONST                        24K        2 \r\n__LINKEDIT                       575.9M      161 \r\n__OBJC_RO                         32.2M        1 \r\n__OBJC_RW                         1892K        2 \r\n__TEXT                           406.6M      279 \r\n__UNICODE                          564K        1 \r\nshared memory                       12K        3 \r\n===========                     =======  ======= \r\nTOTAL                              1.5G     1262 \r\nTOTAL, minus reserved VM space     1.2G     1262 \r\n\r\nModel: MacBookPro16,1, BootROM 1037.100.362.0.0 (iBridge: 17.16.14281.0.0,0), 6 processors, 6-Core Intel Core i7, 2.6 GHz, 16 GB, SMC \r\nGraphics: kHW_IntelUHDGraphics630Item, Intel UHD Graphics 630, spdisplays_builtin\r\nGraphics: kHW_AMDRadeonPro5300MItem, AMD Radeon Pro 5300M, spdisplays_pcie_device, 4 GB\r\nMemory Module: BANK 0/ChannelA-DIMM0, 8 GB, DDR4, 2667 MHz, Micron, 8ATF1G64HZ-2G6E1\r\nMemory Module: BANK 2/ChannelB-DIMM0, 8 GB, DDR4, 2667 MHz, Micron, 8ATF1G64HZ-2G6E1\r\nAirPort: spairport_wireless_card_type_airport_extreme (0x14E4, 0x7BF), wl0: Feb 28 2020 15:31:53 version 9.30.357.35.32.5.47 FWID 01-29ff5c69\r\nBluetooth: Version 7.0.4f6, 3 services, 25 devices, 1 incoming serial ports\r\nNetwork Service: Wi-Fi, AirPort, en0\r\nUSB Device: 4-Port USB 3.0 Hub\r\nUSB Device: USB 3.1 Bus\r\nUSB Device: 4-Port USB 2.0 Hub\r\nUSB Device: USB Receiver\r\nUSB Device: Apple T2 Bus\r\nUSB Device: Composite Device\r\nUSB Device: Touch Bar Backlight\r\nUSB Device: Touch Bar Display\r\nUSB Device: Apple Internal Keyboard / Trackpad\r\nUSB Device: Headset\r\nUSB Device: Ambient Light Sensor\r\nUSB Device: FaceTime HD Camera (Built-in)\r\nUSB Device: Apple T2 Controller\r\nThunderbolt Bus: MacBook Pro, Apple Inc., 55.3\r\nThunderbolt Bus: MacBook Pro, Apple Inc., 55.3\r\n\r\n```", "This part of the stack trace looks surprising - the destroyed Variant should be a `DatasetVariantWrapper`, not an `IdentityDatasetOp::Dataset`. `IdentityDatasetOp::Dataset` should never be stored in a Variant - it should always be wrapped in a `DatasetVariantWrapper`, which will call `Unref()` instead of directly calling the `IdentityDatasetOp::Dataset` destructor. \r\n\r\n```\r\n9   identity_dataset_op.so        \t0x000000013ad2405c tensorflow::data::IdentityDatasetOp::Dataset::~Dataset() + 28\r\n10  libtensorflow_framework.1.dylib\t0x000000012558b61b tensorflow::Variant::~Variant() + 43\r\n```\r\n\r\nOne unusual thing I noticed is that `IdentityDatasetV2` [calls](https://github.com/zhuzilin/custom_dataset_op/blob/master/identity_dataset.py#L11) `self._input_dataset._as_variant_tensor()` instead of `self._input_dataset._variant_tensor`, which is how [other transforms](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/data/ops/dataset_ops.py#L3436) pass their input dataset's variant tensor.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39986\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39986\">No</a>\n"]}, {"number": 39985, "title": "Conv3D operations are not using tensor cores with mixed float16 policy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **CentOS 7**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **pip package**\r\n- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**\r\n- Python version: **3.7.4**\r\n- Bazel version (if compiling from source): **N/A**\r\n- GCC/Compiler version (if compiling from source): **N/A**\r\n- CUDA/cuDNN version: **10.1/7.6.4**\r\n- GPU model and memory: **RTX2080TI**\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using Conv3D layers and a mixed float16 policy the Conv3D layers do not use tensor cores.\r\nUsing the same settings for a Conv2D layer does result in the Conv2D layers using the tensor cores.\r\nThe [description here](https://www.tensorflow.org/guide/keras/mixed_precision#ensuring_gpu_tensor_cores_are_used) also suggests that Conv3D layers should work with tensor cores\r\n\r\n**Describe the expected behavior**\r\n\r\nFor Conv3D layers to use tensor cores\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nGoogle colab [available here](https://colab.research.google.com/drive/1PKMPvKNe-dk79BjyPK_7N0F_JBoYM9x1?usp=sharing)\r\n\r\n**Other info / logs** \r\n\r\nPerhaps related to  #33672, but following the instructions given there (setting the environment variables) does not solve the problem.", "comments": ["i am able to replicate the issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/9ed522f57b0f8f679cd4a114511e6476/untitled199.ipynb)", "In this case, using tensor cores is actually slower, so TensorFlow chooses not to use them. But I cannot figure out why tensor cores are slower. \r\n\r\n@nluehr can you take a look? Here is a smaller program to reproduce:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.random.normal((64, 100, 100, 1, 48), dtype=tf.float16)\r\nf = tf.random.normal((7, 7, 1, 48, 48), dtype=tf.float16)\r\ny = tf.nn.conv3d(x, f, strides=[1, 3, 3, 1, 1], padding='SAME')\r\n\r\nx = tf.random.normal((64, 100, 100,  48), dtype=tf.float16)\r\nf = tf.random.normal((7, 7, 48, 48), dtype=tf.float16)\r\ny = tf.nn.conv2d(x, f, strides=[1, 3, 3, 1], padding='SAME')\r\n```\r\n\r\nThis program runs a Conv3D op and the equivalent Conv2D op. You can see the autorune result with:\r\n\r\n```bash\r\nTF_CPP_VMODULE=logger=2  python conv3d.py\r\n```\r\n\r\nThe last two log lines will show the autotune results for Conv3D and Conv2D. On my machine, I get\r\n\r\n```\r\n2020-06-01 14:56:59.932860: I tensorflow/core/platform/logger.cc:29] [type.googleapis.com/tensorflow.AutotuningLog] { instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 64 dimensions: 48 dimensions: 100 dimensions: 100 dimensions: 1 data_type: kHalf data_layout: kBatchDepthYX } filter { dimensions: 48 dimensions: 48 dimensions: 7 dimensions: 7 dimensions: 1 data_type: kHalf filter_layout: kOutputInputYX } output { dimensions: 64 dimensions: 48 dimensions: 34 dimensions: 34 dimensions: 1 data_type: kHalf data_layout: kBatchDepthYX } conv_desc { paddings: 3 paddings: 3 paddings: 0 strides: 3 strides: 3 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 140238394066432 filter_address: 140238332626176 output_address: 140238340406016 } } results { conv { algorithm: 1 tensor_ops_enabled: true } run_time { nanos: 4273632 } } results { conv { algorithm: 1 } run_time { nanos: 4330207 } } results { conv { tensor_ops_enabled: true } run_time { nanos: 4163392 } } results { conv { } run_time { nanos: 4225760 } } cudnn_version { major: 7 minor: 6 patch: 3 } compute_capability { major: 7 } device_pci_bus_id: \"0000:03:00.0\" blas_version: \"10201\" }\r\n2020-06-01 14:56:59.953838: I tensorflow/core/platform/logger.cc:29] [type.googleapis.com/tensorflow.AutotuningLog] { instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 64 dimensions: 48 dimensions: 100 dimensions: 100 data_type: kHalf data_layout: kBatchYXDepth } filter { dimensions: 48 dimensions: 48 dimensions: 7 dimensions: 7 data_type: kHalf filter_layout: kOutputYXInput } output { dimensions: 64 dimensions: 48 dimensions: 34 dimensions: 34 data_type: kHalf data_layout: kBatchYXDepth } conv_desc { paddings: 3 paddings: 3 strides: 3 strides: 3 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 140238578386688 filter_address: 140238332626176 output_address: 140238356122880 } } results { conv { algorithm: 1 tensor_ops_enabled: true } scratch_bytes: 6944 run_time { nanos: 924800 } } results { conv { algorithm: 1 } scratch_bytes: 9408 run_time { nanos: 4439904 } } results { conv { tensor_ops_enabled: true } run_time { nanos: 4379072 } } results { conv { } run_time { nanos: 4407936 } } cudnn_version { major: 7 minor: 6 patch: 3 } compute_capability { major: 7 } device_pci_bus_id: \"0000:03:00.0\" blas_version: \"10201\" }\r\n```\r\n\r\nUnfortunately, the autorune results are difficult to read. You can see the performance by searching for the string \"nanos:\", and look a bit to the left for \"tensor_ops_enabled:\". For Conv3D, tensor ops make it a little bit slower (4,273,632 vs 4,163,392). But for Conv2D, tensor ops makes it a lot faster (924,800 vs 4,439,904)", "Yes, I can repro it.\r\n\r\nI checked the kernels used by cuDNN for this particular case, and we don't have tensor core implementation supported in cuDNN v7.6. And that is why you might see the similar perf for conv3d whether using tensor core or not.\r\n\r\nHowever, for the coming cuDNN v8, this case should be improved by using tensor core.\r\n", "From #33672 and the [release notes of cuDNN](https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_762.html#rel_762) I thought that it might be possible with cuDNN versions >= 7.6.2, but this is not the case? Or in order for that to work should tensorflow be compiled manually? ", "@kaixih  I've compiled the latest TensorFlow master with cudnn 8, but unfortunately, the results remain the same. I had a look at the suggestions by NVidia [to get tensor cores working](https://docs.nvidia.com/deeplearning/sdk/cudnn-best-practices/index.html#cudnn-8xx), but unfortunately that didn't help.\r\n\r\nCode:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(\"3D\")\r\nx = tf.random.normal((16, 16, 32, 32, 32), dtype=tf.float16)\r\nf = tf.random.normal((3, 3, 3, 16, 16), dtype=tf.float16)\r\ny = tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME', data_format=\"NCDHW\")\r\n\r\nprint(\"2D\")\r\nx = tf.random.normal((16, 16, 32, 32), dtype=tf.float16)\r\nf = tf.random.normal((3, 3, 16, 16), dtype=tf.float16)\r\ny = tf.nn.conv2d(x, f, strides=[1, 1, 1, 1], padding='SAME', data_format=\"NCHW\")\r\n```\r\n\r\nResults:\r\n\r\n```\r\n3D\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 16 dimensions: 32 dimensions: 32 dimensions: 32 data_type: kHalf data_layout: kBatchDepthYX } filter { dimensions: 16 dimensions: 16 dimensions: 3 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputInputYX } output { dimensions: 16 dimensions: 16 dimensions: 32 dimensions: 32 dimensions: 32 data_type: kHalf data_layout: kBatchDepthYX } conv_desc { paddings: 1 paddings: 1 paddings: 1 strides: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46931141200128 filter_address: 46931107645184 output_address: 46931157977344 } } results { conv { algorithm: 1 tensor_ops_enabled: true } scratch_bytes: 33568272 run_time { nanos: 375297515 } } results { conv { algorithm: 1 } run_time { nanos: 2891584 } } results { conv { tensor_ops_enabled: true } run_time { nanos: 2803744 } } results { conv { } run_time { nanos: 2801280 } } results { conv { algorithm: 5 tensor_ops_enabled: true } scratch_bytes: 28311552 run_time { nanos: 3459968 } } results { conv { algorithm: 5 } scratch_bytes: 28311552 run_time { nanos: 3524576 } } cudnn_version { major: 8 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"10202\" }\r\n\r\n2D\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 16 dimensions: 32 dimensions: 32 data_type: kHalf data_layout: kBatchDepthYX } filter { dimensions: 16 dimensions: 16 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputInputYX } output { dimensions: 16 dimensions: 16 dimensions: 32 dimensions: 32 data_type: kHalf data_layout: kBatchDepthYX } conv_desc { paddings: 1 paddings: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46931108735232 filter_address: 46931107645184 output_address: 46931183143168 } } results { conv { algorithm: 1 tensor_ops_enabled: true } run_time { nanos: 45568 } } results { conv { algorithm: 1 } run_time { nanos: 56736 } } results { conv { tensor_ops_enabled: true } run_time { nanos: 54112 } } results { conv { } run_time { nanos: 50304 } } results { conv { algorithm: 2 tensor_ops_enabled: true } scratch_bytes: 4718592 run_time { nanos: 76416 } } results { conv { algorithm: 2 } scratch_bytes: 4718592 run_time { nanos: 76416 } } results { conv { algorithm: 4 tensor_ops_enabled: true } scratch_bytes: 17310720 run_time { nanos: 156704 } } results { conv { algorithm: 4 } scratch_bytes: 17310720 run_time { nanos: 142528 } } results { conv { algorithm: 6 tensor_ops_enabled: true } scratch_bytes: 2148432 run_time { nanos: 75712 } } results { conv { algorithm: 6 } scratch_bytes: 2148432 run_time { nanos: 58528 } } results { conv { algorithm: 5 tensor_ops_enabled: true } scratch_bytes: 5570560 run_time { nanos: 150080 } } results { conv { algorithm: 5 } scratch_bytes: 5570560 run_time { nanos: 116672 } } results { conv { algorithm: 7 tensor_ops_enabled: true } scratch_bytes: 4755456 run_time { nanos: 53024 } } results { conv { algorithm: 7 } scratch_bytes: 4755456 run_time { nanos: 42880 } } cudnn_version { major: 8 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"10202\" }\r\n```\r\n\r\nOnce again for the 2D convolution, the time is reduced, but not for the 3D convolutions. Cudnn 8 is used as seen in the output. Is there still something I'm missing?", "@Svdvoort Just recompiling the TF with cuDNN v8 might not be enough. The TF actually convert all NDHWC to NCDHW before call the cuDNN. So, we also need to remove that logic. We are working on this now.", "FYI. You might want to keep track of status here: https://github.com/tensorflow/tensorflow/pull/40399", "Thanks for the info. I assumed setting the data format explicitly would force TF to use it with cuDNN. I'll await the pull request then. ", "Can confirm that with the newest TF 2.3.0-rc0 (compiled with Cuda 11 and CuDNN 8.0.1) the Conv3D now works with tensor cores. \r\nFor example:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nN_filters_in = 256\r\nN_filters_out = 256\r\nbatch_size = 16\r\nimage_size = 50\r\nkernel_size = 3\r\n\r\nprint(\"3D\")\r\nx = tf.random.normal((batch_size, image_size, image_size, image_size, N_filters_in), dtype=tf.float16)\r\nf = tf.random.normal((kernel_size, kernel_size, kernel_size, N_filters_in, N_filters_out), dtype=tf.float16)\r\ny = tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME')\r\n```\r\n\r\nRunning with `TF_CPP_VMODULE=logger=2` gives:\r\n\r\n```\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 256 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } filter { dimensions: 256 dimensions: 256 dimensions: 3 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputYXInput } output { dimensions: 16 dimensions: 256 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } conv_desc { paddings: 1 paddings: 1 paddings: 1 strides: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46933021427456 filter_address: 46930973426944 output_address: 46931997427200 } } results { conv { algorithm: 1 tensor_ops_enabled: true } run_time { nanos: 561604370 } } results { conv { algorithm: 1 } scratch_bytes: 3538960 run_time { nanos: 837961303 } } cudnn_version { major: 8 patch: 1 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"11000\" }\r\n```\r\n\r\nSo a speed-up from 837961303 to 561604370 when using tensor cores.\r\nWhen using such a convolutional layer as part of a model tensorboard also reports the use of the tensor cores.\r\n\r\nHowever, according to the [NVidia guidelines](https://docs.nvidia.com/deeplearning/sdk/cudnn-best-practices/index.html#cudnn-8xx), the following should also work:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nN_filters_in = 128\r\nN_filters_out = 128\r\nbatch_size = 16\r\nimage_size = 50\r\nkernel_size = 3\r\n\r\nprint(\"3D\")\r\nx = tf.random.normal((batch_size, image_size, image_size, image_size, N_filters_in), dtype=tf.float16)\r\nf = tf.random.normal((kernel_size, kernel_size, kernel_size, N_filters_in, N_filters_out), dtype=tf.float16)\r\ny = tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME')\r\n```\r\n\r\nHowever, this returns: \r\n\r\n```\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 128 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } filter { dimensions: 128 dimensions: 128 dimensions: 3 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputYXInput } output { dimensions: 16 dimensions: 128 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } conv_desc { paddings: 1 paddings: 1 paddings: 1 strides: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46931930318592 filter_address: 46930906318080 output_address: 46931418318336 } } results { conv { algorithm: 1 tensor_ops_enabled: true } scratch_bytes: 884752 run_time { nanos: 601746276 } } results { conv { algorithm: 1 } scratch_bytes: 884752 run_time { nanos: 299774810 } } cudnn_version { major: 8 patch: 1 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"11000\" }\r\n```\r\n\r\nThus 601746276 with tensor cores, 299774810 without tensor cores. The use of tensor cores makes it considerably slower.\r\n\r\nI'm guessing this is due to CuDNN, perhaps this will be solved in a future release (or the final CuDNN 8 version), or perhaps TF uses a different, more optimal algorithm when not using tensor cores. In any case it seems like it at least picks up on the use of tensor cores for the 3D convolutions now. Thanks :)\r\n", "@Svdvoort Thanks for your comments.\r\n\r\nI just tried your newly pasted script and I think you might forget to add a few warm-up runs to eliminate the cudnn loading overhead.\r\n\r\nFor example, I gave a shot to run the conv3d three times and I observed that the perf is ~635ms  either w/ or w/o tensor cores in your first case (256 filters). Whereas, the perf is 22ms w/ tensor cores compared to ~200ms w/o them in the second case (128 filters).", "You are right, there is definitely some warm-up effect. From the earlier scripts with the conv2d and conv3d layers it also matters in which order they are executed, probably also due to the warm-up.\r\n\r\nI've now added a conv1d layer to use as warming up, thus the script now is:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nN_filters_in = 128\r\nN_filters_out = 128\r\nbatch_size = 16\r\nimage_size = 50\r\nkernel_size = 3\r\n\r\nprint(\"Warming up\")\r\nfor i in range(5):\r\n    x = tf.random.normal((batch_size, image_size,  N_filters_in), dtype=tf.float16)\r\n    f = tf.random.normal((kernel_size, N_filters_in, N_filters_out), dtype=tf.float16)\r\n    y = tf.nn.conv1d(x, f, stride=[1, 1, 1], padding='SAME')\r\n\r\n\r\nprint(\"3D\")\r\nx = tf.random.normal((batch_size, image_size, image_size, image_size, N_filters_in), dtype=tf.float16)\r\nf = tf.random.normal((kernel_size, kernel_size, kernel_size, N_filters_in, N_filters_out), dtype=tf.float16)\r\ny = tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME')\r\n```\r\n\r\nThis definitely reduces the time for the 128 filter case (it also means that placing the conv3d or conv2d first doesn't matter anymore):\r\n\r\n```\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 128 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } filter { dimensions: 128 dimensions: 128 dimensions: 3 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputYXInput } output { dimensions: 16 dimensions: 128 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } conv_desc { paddings: 1 paddings: 1 paddings: 1 strides: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46931931342592 filter_address: 46930906728192 output_address: 46930909579008 } } results { conv { algorithm: 1 tensor_ops_enabled: true } scratch_bytes: 884752 run_time { nanos: 357543731 } } results { conv { algorithm: 1 } scratch_bytes: 884752 run_time { nanos: 300922577 } } cudnn_version { major: 8 patch: 1 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"11000\" }\r\n```\r\n\r\nBefore it was 644354675 with and 300541687 w/o tensor cores, now it is 357543731 with and 300922577 without. Definitely an improvement for the tensor core case, but still slower than without.\r\n\r\nFor the case of the 256 filters the speed-up is also there:\r\n\r\n```\r\n{ instr { [type.googleapis.com/tensorflow.ConvolutionProto] { kind: FORWARD input { dimensions: 16 dimensions: 256 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } filter { dimensions: 256 dimensions: 256 dimensions: 3 dimensions: 3 dimensions: 3 data_type: kHalf filter_layout: kOutputYXInput } output { dimensions: 16 dimensions: 256 dimensions: 50 dimensions: 50 dimensions: 50 data_type: kHalf data_layout: kBatchYXDepth } conv_desc { paddings: 1 paddings: 1 paddings: 1 strides: 1 strides: 1 strides: 1 dilations: 1 dilations: 1 dilations: 1 group_count: 1 } conv_scale: 1 input_address: 46932957153024 filter_address: 46930907137792 output_address: 46930918541056 } } results { conv { algorithm: 1 tensor_ops_enabled: true } run_time { nanos: 270119140 } } results { conv { algorithm: 1 } scratch_bytes: 3538960 run_time { nanos: 844934692 } } cudnn_version { major: 8 patch: 1 } compute_capability { major: 7 minor: 5 } device_pci_bus_id: \"0000:04:00.0\" blas_version: \"11000\" }\r\n```\r\n\r\nBefore 561604370 with tensor cores and 837961303 w/o, now down to 270119140 with tensor cores and 844934692 w/o. Here there is definitely a noticeable improvement of using the tensor cores.\r\n\r\n Perhaps this is also related to the GPU model? This has been tested on an RTX2080Ti. \r\n", "Yes, it may be related to the GPU model and also the specific cuDNN version.\r\n\r\nI tried the 128 filters case on a RTX 2080 super card and it seems the cuDNN doesn't choose the tensor core kernel when use_tensor_core is set and the perf is not good as you observed. Will contact our cudnn team about this. ", "I modified the script from @Svdvoort to actually measure the execution of multiple op execution and I added a warmup step per conv configuration. This extra warmup is important since on the first execution several kernels are measured and the result determines which will be used in the future. Also, as already mentioned, the data format is a huge factor for performance when using float16.\r\n\r\n```python\r\nimport time\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\n\r\nbatch_size = 1\r\nkernel_size = 3\r\nrepetitions = 100\r\n\r\nresult = []\r\n\r\n\r\nfor image_size, filters in ((128, 64), (64, 128), (32, 256), (16, 512), (8, 1024)):\r\n    for data_format in ('NCDHW', 'NDHWC'):\r\n        if data_format == 'NCDHW':\r\n            x = tf.random.normal((batch_size, filters, image_size, image_size, image_size), dtype=tf.float32)\r\n        else:\r\n            x = tf.random.normal((batch_size, image_size, image_size, image_size, filters), dtype=tf.float32)\r\n        f = tf.random.normal((kernel_size, kernel_size, kernel_size, filters, filters), dtype=tf.float32)\r\n        started = time.time()\r\n        tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME', data_format=data_format)\r\n        t_wu_fp32 = time.time() - started\r\n        started = time.time()\r\n        for _ in range(repetitions):\r\n            tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME', data_format=data_format)\r\n        t_fp32 = (time.time() - started) / repetitions\r\n\r\n        if data_format == 'NCDHW':\r\n            x = tf.random.normal((batch_size, filters, image_size, image_size, image_size), dtype=tf.float16)\r\n        else:\r\n            x = tf.random.normal((batch_size, image_size, image_size, image_size, filters), dtype=tf.float16)\r\n        f = tf.random.normal((kernel_size, kernel_size, kernel_size, filters, filters), dtype=tf.float16)\r\n        started = time.time()\r\n        tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME', data_format=data_format)\r\n        t_wu_fp16 = time.time() - started\r\n        started = time.time()\r\n        for _ in range(repetitions):\r\n            tf.nn.conv3d(x, f, strides=[1, 1, 1, 1, 1], padding='SAME', data_format=data_format)\r\n        t_fp16 = (time.time() - started) / repetitions\r\n\r\n        speedup = t_fp32 / t_fp16\r\n\r\n        result.append({\r\n            'image_size': f'{image_size}x{image_size}x{image_size}',\r\n            'filters': filters,\r\n            'data_format': data_format,\r\n            'avg_time_fp32_ms': t_fp32 * 1000,\r\n            'avg_time_fp16_ms': t_fp16 * 1000,\r\n            'warm_up_fp32_ms': t_wu_fp32 * 1000,\r\n            'warm_up_fp16_ms': t_wu_fp16 * 1000,\r\n            'speedup': speedup\r\n        })\r\n\r\nprint(pd.DataFrame(result).to_markdown(index=False))\r\n```\r\n\r\n| image_size   |   filters | data_format   |   avg_time_fp32_ms |   avg_time_fp16_ms |   warm_up_fp32_ms |   warm_up_fp16_ms |   speedup |\r\n|:-------------|----------:|:--------------|-------------------:|-------------------:|------------------:|------------------:|----------:|\r\n| 128x128x128  |        64 | NCDHW         |          0.0706506 |          0.0682282 |      1438.01      |         580.63    |  1.0355   |\r\n| 128x128x128  |        64 | NDHWC         |         38.9074    |         49.9986    |         0.178576  |          59.4954  |  0.77817  |\r\n| 64x64x64     |       128 | NCDHW         |          0.0678205 |          0.0683904 |      7377.11      |        2004.61    |  0.991668 |\r\n| 64x64x64     |       128 | NDHWC         |         10.2363    |         19.1658    |         0.0977516 |          15.6653  |  0.534092 |\r\n| 32x32x32     |       256 | NCDHW         |          0.0678635 |          0.0673509 |      2217.02      |        1046.95    |  1.00761  |\r\n| 32x32x32     |       256 | NDHWC         |          5.10965   |          9.38453   |         0.110626  |           7.80654 |  0.544476 |\r\n| 16x16x16     |       512 | NCDHW         |          0.0669503 |          0.0678897 |      1061.39      |         481.792   |  0.986163 |\r\n| 16x16x16     |       512 | NDHWC         |          2.79787   |          4.92591   |         0.0946522 |           4.32825 |  0.56799  |\r\n| 8x8x8        |      1024 | NCDHW         |          0.0653195 |          0.0702453 |       580.436     |         475.603   |  0.929878 |\r\n| 8x8x8        |      1024 | NDHWC         |          2.88254   |          4.89266   |         0.0939369 |           4.47154 |  0.589155 |\r\n\r\nAs you can see for NCDHW the performance is more or less equal (within 7% difference), but NDHWC is much much slower. Still, why is float16 not getting accelerated by the tensor cores. @kaixih Did you get any information from the cuDNN team?\r\n\r\nEnvironment details:\r\n- Docker image `tensorflow/tensorflow:2.3.0-gpu`\r\n- Titan RTX (compute capability 7.5)", "@Svdvoort  Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sushreebarsa I cannot reproduce the original results anymore, as the `TF_CPP_VMODULE=logger=2` option doesn't seem to work anymore. It doesn't give the logs for the use of the tensor cores, has this been updated in tf 2.5 perhaps? \r\n\r\nI did reproduce the table from @razorx89 and that seems to suggests the issue is fixed: \r\n\r\n| image_size   |   filters | data_format   |   avg_time_fp32_ms |   avg_time_fp16_ms |   warm_up_fp32_ms |   warm_up_fp16_ms |   speedup |\r\n|:-------------|----------:|:--------------|-------------------:|-------------------:|------------------:|------------------:|----------:|\r\n| 128x128x128  |        64 | NCDHW         |           0.313146 |           0.187511 |       3384.71     |           608.723 |  1.67001  |\r\n| 128x128x128  |        64 | NDHWC         |           6.07016  |           0.163949 |          0.445366 |          5125.44  | 37.0248   |\r\n| 64x64x64     |       128 | NCDHW         |           0.28568  |           0.190461 |       1104.71     |          2053.8   |  1.49994  |\r\n| 64x64x64     |       128 | NDHWC         |           2.57943  |           0.161428 |          0.379324 |          2171.46  | 15.9788   |\r\n| 32x32x32     |       256 | NCDHW         |           0.244176 |           0.203857 |        595.336    |          1423.26  |  1.19778  |\r\n| 32x32x32     |       256 | NDHWC         |           1.30862  |           0.181801 |          0.302315 |          1390.37  |  7.19806  |\r\n| 16x16x16     |       512 | NCDHW         |           0.162723 |           0.202661 |        230.961    |           678.329 |  0.802934 |\r\n| 16x16x16     |       512 | NDHWC         |           0.662382 |           0.178571 |          0.259638 |           738.842 |  3.70935  |\r\n| 8x8x8        |      1024 | NCDHW         |           0.30431  |           0.19779  |        132.777    |           741.014 |  1.53856  |\r\n| 8x8x8        |      1024 | NDHWC         |           2.74531  |           0.17312  |          0.398159 |           917.235 | 15.8578   |\r\n\r\nThe float16 is faster in all but one case (the 16x16x16 NCDHW filter), but in that case the difference is too small to call significant. ", "@Svdvoort  could you please let us know if this issue is fixed for you and move this issue to closed status ,thank you !", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39985\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39985\">No</a>\n"]}, {"number": 39984, "title": "Update losses.py", "body": "merge request pertaining to issue #39982.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39984) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39984) for more info**.\n\n<!-- ok -->", "@pavithrasv I have reproduced and the [fixed the bug here](https://drive.google.com/open?id=1BgfoS1_Co7DlKtMPYsJ-98vp4ctrVaPL).", "[working link](https://colab.research.google.com/drive/1BgfoS1_Co7DlKtMPYsJ-98vp4ctrVaPL?authuser=1)", "Please fix sanity build, there is a pylint error", "Extremely sorry about the screw-ups."]}, {"number": 39983, "title": "\"/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/\" Number of warnings generated during project build", "body": "**System information**\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): tensorflow-gpu version 2.2\r\nPython version: 3.6\r\nBazel version (if compiling from source): NA\r\nGCC/Compiler version (if compiling from source): 8.4\r\nCUDA/cuDNN version: 10.1\r\nGPU model and memory: Tesla P100 (Google Colab)\r\nExact command to reproduce: !sh make.sh\r\n**Describe the problem**\r\nI am trying to reproduce the results from this repo: https://github.com/bostondiditeam/MV3D. While building the project, I get a host of warnings which I can ignore but I think these warnings are causing the succeeding error. \r\nI have tried updating gcc version from 7.x to 8.4 because CUDA 10.1 is compatible with gcc8 but that didn't resolve the problem. \r\nI would really like to know how I can compile the file psroi_pooling_op.cu.o properly!\r\n**Source code / logs**\r\n\r\nThis is what my make file looks like:\r\n\r\n#!/usr/bin/env bash\r\nTF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')\r\necho $TF_INC\r\n\r\nCUDA_PATH=/usr/local/cuda/\r\n\r\ncd roi_pooling_layer\r\n\r\nnvcc -std=c++11 -c -o roi_pooling_op.cu.o roi_pooling_op_gpu.cu.cc \\\r\n\t-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_75\r\n\r\n## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below\r\n#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o roi_pooling.so roi_pooling_op.cc \\\r\n#\troi_pooling_op.cu.o -I $TF_INC -fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64\r\n\r\n# for gcc5-built tf\r\ng++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o roi_pooling.so roi_pooling_op.cc \\\r\n\troi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64\r\ncd ..\r\n\r\n\r\n# add building psroi_pooling layer\r\ncd psroi_pooling_layer\r\n\r\nnvcc -std=c++11 -c -o psroi_pooling_op.cu.o psroi_pooling_op_gpu.cu.cc \\\r\n\t-I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -arch=sm_75\r\n\r\ng++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=1 -o psroi_pooling.so psroi_pooling_op.cc \\\r\n\tpsroi_pooling_op.cu.o -I $TF_INC -fPIC -lcudart -L $CUDA_PATH/lib64\r\n\r\n## if you install tf using already-built binary, or gcc version 4.x, uncomment the two lines below\r\n#g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX11_ABI=0 -o psroi_pooling.so psroi_pooling_op.cc \\\r\n#\tpsroi_pooling_op.cu.o -I $TF_INC -fPIC $CXXFLAGS -lcudart -L $CUDA_PATH/lib64\r\n\r\ncd ..\r\n\r\nThis is the output:\r\n2020-05-29 09:59:27.073245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __host__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __device__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(\"~no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(\"~no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function(\"real\") from a __host__ __device__ function(\"abs\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function(\"imag\") from a __host__ __device__ function(\"abs\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1386): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function(\"real\") from a __host__ __device__ function(\"abs\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function(\"imag\") from a __host__ __device__ function(\"abs\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1391): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1415): warning: calling a constexpr __host__ function(\"real\") from a __host__ __device__ function(\"exp\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1416): warning: calling a constexpr __host__ function(\"imag\") from a __host__ __device__ function(\"exp\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1417): warning: calling a constexpr __host__ function(\"imag\") from a __host__ __device__ function(\"exp\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1415): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1416): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1417): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1418): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1423): warning: calling a constexpr __host__ function(\"real\") from a __host__ __device__ function(\"exp\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1424): warning: calling a constexpr __host__ function(\"imag\") from a __host__ __device__ function(\"exp\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1423): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1424): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1425): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(1426): warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/DenseBase.h(639): warning: __host__ annotation is ignored on a function(\"DenseBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/DenseBase.h(639): warning: __device__ annotation is ignored on a function(\"DenseBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(484): warning: __host__ annotation is ignored on a function(\"MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(484): warning: __device__ annotation is ignored on a function(\"MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __host__ annotation is ignored on a function(\"MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __device__ annotation is ignored on a function(\"MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __host__ annotation is ignored on a function(\"~MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MatrixBase.h(485): warning: __device__ annotation is ignored on a function(\"~MatrixBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(156): warning: __host__ annotation is ignored on a function(\"ArrayBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(156): warning: __device__ annotation is ignored on a function(\"ArrayBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __host__ annotation is ignored on a function(\"ArrayBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __device__ annotation is ignored on a function(\"ArrayBase\") that is explicitly defaulted on its first declaration\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayBase.h(157): warning: __device__ annotation is ignored on a function(\"~ArrayBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(70): warning: __host__ annotation is ignored on a function(\"CwiseUnaryView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(70): warning: __device__ annotation is ignored on a function(\"CwiseUnaryView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(110): warning: __host__ annotation is ignored on a function(\"CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(110): warning: __device__ annotation is ignored on a function(\"CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __host__ annotation is ignored on a function(\"CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __device__ annotation is ignored on a function(\"CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __host__ annotation is ignored on a function(\"~CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/CwiseUnaryView.h(125): warning: __device__ annotation is ignored on a function(\"~CwiseUnaryViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(185): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(185): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __host__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __host__ annotation is ignored on a function(\"Map\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(186): warning: __device__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(300): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(\"MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __host__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MapBase.h(301): warning: __device__ annotation is ignored on a function(\"~MapBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __host__ annotation is ignored on a function(\"Map\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Map.h(162): warning: __device__ annotation is ignored on a function(\"Map\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(90): warning: __host__ annotation is ignored on a function(\"RefBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(90): warning: __device__ annotation is ignored on a function(\"RefBase\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(232): warning: __host__ annotation is ignored on a function(\"Ref\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Ref.h(232): warning: __device__ annotation is ignored on a function(\"Ref\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(111): warning: __host__ annotation is ignored on a function(\"Block\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(111): warning: __device__ annotation is ignored on a function(\"Block\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(161): warning: __host__ annotation is ignored on a function(\"BlockImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(161): warning: __device__ annotation is ignored on a function(\"BlockImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(181): warning: __host__ annotation is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(181): warning: __device__ annotation is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(341): warning: __host__ annotation is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Block.h(341): warning: __device__ annotation is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/IndexedView.h(113): warning: __host__ annotation is ignored on a function(\"IndexedView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/IndexedView.h(113): warning: __device__ annotation is ignored on a function(\"IndexedView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(103): warning: __host__ annotation is ignored on a function(\"Reshaped\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(103): warning: __device__ annotation is ignored on a function(\"Reshaped\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(137): warning: __host__ annotation is ignored on a function(\"ReshapedImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(137): warning: __device__ annotation is ignored on a function(\"ReshapedImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(155): warning: __host__ annotation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(155): warning: __device__ annotation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(215): warning: __host__ annotation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reshaped.h(215): warning: __device__ annotation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(66): warning: __host__ annotation is ignored on a function(\"Transpose\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(66): warning: __device__ annotation is ignored on a function(\"Transpose\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(126): warning: __host__ annotation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(126): warning: __device__ annotation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __host__ annotation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __device__ annotation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __host__ annotation is ignored on a function(\"~TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Transpose.h(157): warning: __device__ annotation is ignored on a function(\"~TransposeImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Diagonal.h(78): warning: __host__ annotation is ignored on a function(\"Diagonal\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Diagonal.h(78): warning: __device__ annotation is ignored on a function(\"Diagonal\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(222): warning: __host__ annotation is ignored on a function(\"TriangularView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(222): warning: __device__ annotation is ignored on a function(\"TriangularView\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(559): warning: __host__ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(559): warning: __device__ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __host__ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __device__ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __host__ annotation is ignored on a function(\"~TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/TriangularMatrix.h(560): warning: __device__ annotation is ignored on a function(\"~TriangularViewImpl\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reverse.h(90): warning: __host__ annotation is ignored on a function(\"Reverse\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/Reverse.h(90): warning: __device__ annotation is ignored on a function(\"Reverse\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(47): warning: __host__ annotation is ignored on a function(\"ArrayWrapper\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(47): warning: __device__ annotation is ignored on a function(\"ArrayWrapper\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(145): warning: __host__ annotation is ignored on a function(\"MatrixWrapper\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ArrayWrapper.h(145): warning: __device__ annotation is ignored on a function(\"MatrixWrapper\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __host__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(114): warning: __device__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(\"no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __host__ annotation is ignored on a function(\"~no_assignment_operator\") that is explicitly defaulted on its first declaration\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/include/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/XprHelper.h(115): warning: __device__ annotation is ignored on a function(\"~no_assignment_operator\") that is explicitly defaulted on its first declaration\r\ncuda_kernel_helper.h(49): error: class \"Eigen::GpuDevice\" has no member \"getNumCudaMultiProcessors\"\r\n\r\ncuda_kernel_helper.h(49): error: class \"Eigen::GpuDevice\" has no member \"maxCudaThreadsPerMultiProcessor\"\r\n\r\ncuda_kernel_helper.h(48): error: no instance of overloaded function \"std::min\" matches the argument list\r\n            argument types are: (<error-type>, const int)\r\n\r\ncuda_kernel_helper.h(51): error: class \"Eigen::GpuDevice\" has no member \"maxCudaThreadsPerBlock\"\r\n\r\ncuda_kernel_helper.h(51): error: no instance of overloaded function \"std::min\" matches the argument list\r\n            argument types are: (int, <error-type>)\r\n\r\ncuda_kernel_helper.h(54): error: class \"Eigen::GpuDevice\" has no member \"getNumCudaMultiProcessors\"\r\n\r\ncuda_kernel_helper.h(81): error: class \"Eigen::GpuDevice\" has no member \"getNumCudaMultiProcessors\"\r\n\r\ncuda_kernel_helper.h(81): error: class \"Eigen::GpuDevice\" has no member \"maxCudaThreadsPerMultiProcessor\"\r\n\r\ncuda_kernel_helper.h(83): error: no instance of overloaded function \"std::max\" matches the argument list\r\n            argument types are: (<error-type>, int)\r\n\r\ncuda_kernel_helper.h(90): error: no instance of overloaded function \"std::min\" matches the argument list\r\n            argument types are: (<error-type>, const int)\r\n\r\n10 errors detected in the compilation of \"/tmp/tmpxft_000008ff_00000000-6_psroi_pooling_op_gpu.cu.cpp1.ii\".\r\ng++: error: psroi_pooling_op.cu.o: No such file or directory\r\nmake: 'LidarTopPreprocess.so' is up to date.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!", "Comment has been updated with required details.", "@Shafaq-S https://github.com/bostondiditeam/MV3D can be good a platform to raise this issue since you are trying to execute make file from that project. Please post this question on that platform for better support. Thanks!", "Have you solved this question? @ @Shafaq-S ", "I have not. Are you facing the same problem? If yes, do let me know if you come across a solution. @junshutang", "> I have not. Are you facing the same problem? If yes, do let me know if you come across a solution. @junshutang\r\n\r\nI encountered this problem too. I tried to edit the /src/net/lib/make.sh - I changed GOOGLE_CUDA=1 -> GOOGLE_CUDA=0 and then this problem was solved. Maybe you could have a try."]}, {"number": 39982, "title": "For tf.keras.losses.categorical_hinge maximum op dtype missmatch using mixed_precision with float16", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n***Issue:***\r\n     return math_ops.maximum(0., neg - pos + 1.)\r\n    lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:5740 maximum\r\n        \"Maximum\", x=x, y=y, name=name)\r\n    lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper\r\n        inferred_from[input_arg.type_attr]))\r\n\r\n    TypeError: Input 'y' of 'Maximum' Op has type float16 that does not match type float32 of argument 'x'.\r\n\r\n***Plausible solution:***\r\n   return math_ops.maximum( neg - pos + 1., 0.)\r\nSo that dtype is matched with calculated entity rather than other way.", "comments": ["@jadevaibhav,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and the TensorFlow version you are using.\r\n\r\nAlso, please check [this thread](https://github.com/tensorflow/tensorflow/issues/34406) from a similar issue and let us know if it helps. Thanks!", "@amahendrakar I have recreated the [bug and tested a way to fix this](https://drive.google.com/open?id=1BgfoS1_Co7DlKtMPYsJ-98vp4ctrVaPL). I have submitted the merge request. Thanks!", "@amahendrakar ,\r\nI checked the mentioned thread, it shows the error dtype missmatch for tf 2.0. It was same for me, but this issue is in 2.2.0. Sorry that I haven't mentioned this before.", "[working link](https://colab.research.google.com/drive/1BgfoS1_Co7DlKtMPYsJ-98vp4ctrVaPL?authuser=1)", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/6c505f899de1f15265c368effc289641/39982.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/df4c4993cbb0efc75541d728460653a5/39982-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Closing since I think this has been fixed by #39984 (let me know if I'm wrong)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39982\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39982\">No</a>\n", "I believe this issue persists in other loss functions as well. This is more of fundamental question: as per mixed precision, all computations are done in Float16, does that also include the loss calculations? Or only the forward and backward pass computations?", "I think most loss functions support float16, but let me know if you know of any that do not and I can fix them.\r\n\r\n> This is more of fundamental question: as per mixed precision, all computations are done in Float16, does that also include the loss calculations? Or only the forward and backward pass computations?\r\n\r\nBy default, losses run in the same dtype as the output of the model, although this may be changed in the future to always run losses in float32. Most of the time, it is safe to run losses in float16, but a few cases require float32 for numeric stability. It is recommended to always run losses in float32 since it is difficult to tell whether you will encounter one of the few cases where the loss is numerically unstable in float16, and typically float32 losses have negligible impact on performance."]}, {"number": 39981, "title": "tf.math.maximum example is written incorrectly.", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/maximum#returns\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe example of tf.math.maximum is not written correctly.\r\nIt's written in this manner,\r\nExample: \r\n``` x = tf.constant([0., 0., 0., 0.]) y = tf.constant([-2., 0., 2., 5.]) tf.math.maximum(x, y) ```\r\nInstead of this it should've written in this manner,\r\n``` \r\n    x = tf.constant([0., 0., 0., 0.])\r\n    y = tf.constant([-2., 0., 2., 5.])\r\n    tf.math.maximum(x, y)\r\n    -> tf.Tensor([0. 0. 2. 5.], shape=(4,), dtype=float32)\r\n```    \r\n\r\n\r\n\r\n\r\n\r\n### Submit a pull request?\r\nno", "comments": ["I would like to work on this issue.\r\n", "Thanks! Feel free to submit a PR", "Can I work on this issue?\r\n", "I can fix this, can i work on the issue?", "@r-barnes @rohan100jain @Saduf2019 Can I work on this issue ??\r\n", "I don't have the authority to assign fix responsibility here.", "@paulis-reece @Satist @aavishkarmishra @kandekar007 \r\n\r\nFirst one to land the PR fixing the issue wins. There is no one assigning issues to contributors.", "But, where to send the PR(repo) ?\n\nOn Tue 16 Jun, 2020, 9:08 PM Mihai Maruseac, <notifications@github.com>\nwrote:\n\n> @paulis-reece <https://github.com/paulis-reece> @Satist\n> <https://github.com/Satist> @aavishkarmishra\n> <https://github.com/aavishkarmishra> @kandekar007\n> <https://github.com/kandekar007>\n>\n> First one to land the PR fixing the issue wins. There is no one assigning\n> issues to contributors.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39981#issuecomment-644843325>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AKM6BK4JJ3GJJU6KZY2TAPLRW6GVVANCNFSM4NN2JQKQ>\n> .\n>\n", "This repo.", "@mihaimaruseac  Hi can anyone help me to locate these files in  repo , as in docs folder there is readme that tell to locate them in docs repo and in docs repo there are links which just open the web page", "https://cs.opensource.google/search?q=tf.math.maximum&ss=tensorflow%2Ftensorflow:tensorflow%2F&ssfr=1", "@mihaimaruseac why this is not updated in main website ?", "@yashk2810 @lamberta Was the nightly not regenerated for this symbol? Or maybe the PR was not a fully working solution?", "When did that go into tf-nightly?", "How to resolve this problem anyone have any idea ?", "> resolve this problem\r\n\r\nI am working on that :)", "> When did that go into tf-nightly?\r\n\r\nShould be 5 day ago, 1e2bf4efce13b0fd3875d3f431ba699665392cc2 (318509604)", "Ahh.. I see the problem. There should be a newline after `Example:`. All doctests should have a newline before and after. Once that's fixed, it'll start appearing on the website.", "I just submitted a fix for this. This should go live tomorrow or day-after-tomorrow whenever the change makes it to nightly.", "### Do we have to force line chage wherever we want a new line?\r\n@yashk2810 \r\n>As in case of markdown it changes line normally we don't have to force it(without using double space).", "A new line is necessary because we do some regex matching to add stuff around it to display it on the site."]}, {"number": 39980, "title": "tf.keras.layers.Multiply fails on Variables", "body": "tensorflow 2.2.0\r\n\r\nubuntu 20.04\r\n\r\n\r\nI am trying a simple code:\r\n```\r\nimport tensorflow as tf\r\nv1 = tf.Variable(np.array([[1.,2.],[2.,3.]]))\r\nv2 = tf.Variable(np.array([[1.,2.],[2.,3.]]))\r\nv3=tf.keras.layers.Multiply()([v1,v2])\r\n```\r\nI am getting:\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-15-70cdbcdc638c> in <module>\r\n      2 v1 = tf.Variable(np.array([[1.,2.],[2.,3.]]))\r\n      3 v2 = tf.Variable(np.array([[1.,2.],[2.,3.]]))\r\n----> 4 v3=tf.keras.layers.Multiply()([v1,v2])\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    966           with base_layer_utils.autocast_context_manager(\r\n    967               self._compute_dtype):\r\n--> 968             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    969           self._handle_activity_regularization(inputs, outputs)\r\n    970           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in call(self, inputs)\r\n    181         return y\r\n    182     else:\r\n--> 183       return self._merge_function(inputs)\r\n    184 \r\n    185   @tf_utils.shape_type_conversion\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in _merge_function(self, inputs)\r\n    320     output = inputs[0]\r\n    321     for i in range(1, len(inputs)):\r\n--> 322       output *= inputs[i]\r\n    323     return output\r\n    324 \r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in __imul__(self, unused_other)\r\n   1255 \r\n   1256   def __imul__(self, unused_other):\r\n-> 1257     raise RuntimeError(\"Variable *= value not supported. Use \"\r\n   1258                        \"`var.assign(var * value)` to modify the variable or \"\r\n   1259                        \"`var = var * value` to get a new Tensor object.\")\r\n\r\nRuntimeError: Variable *= value not supported. Use `var.assign(var * value)` to modify the variable or `var = var * value` to get a new Tensor object.\r\n```\r\nWhat am i doing wrong? please help me understand the issue", "comments": ["I have tried in colab with TF 2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/9d9eb07e8f7b60f8523d78928cd00391/untitled934.ipynb).Thanks!", "Looking at the error logs, perhaps the fix would be to rewrite `_merge_function(self, inputs)` in `tensorflow/python/keras/layers/merge.py`, specifically to replace\r\n\r\n```\r\noutput *= inputs[i]\r\n``` \r\n\r\nwith\r\n\r\n```\r\noutput.assign(output * inputs[i])\r\n```\r\n\r\nor \r\n\r\n```\r\noutput = output * inputs[i]\r\n```\r\n\r\nCan someone confirm that this is the write direction to deal with it? I would like to take a jab at this if possible!", "@nitinmnsn As you can see below,\r\n![image](https://user-images.githubusercontent.com/47574994/83341139-c4de8b80-a294-11ea-9a7b-e3902873447b.png)\r\nyou need to get the value from the variable and then multiply the two values from 2 different variables.", "This will break the gradients flowing back to `v1` and `v2`. And why do we need to supply the numpy values of the tensors. The op should be able to operate on variables\r\nThis does not address the problem", "any updates on this?", "The above commit fixes this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39980\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39980\">No</a>\n"]}, {"number": 39979, "title": "micro_speech example broken", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Embedded device: Arduino Nano 33 BLE Sense (IDE 1.8.12)\r\n- TensorFlow installed from (source or binary): Source (latest version)\r\n\r\n**Describe the current behavior**\r\nThis issue is regarding TensorFlow Lite for Microcontrollers. The micro_speech example is not working (it doesn't detect any words) or even \"unknown\" tags.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe only thing I am using is the example as given in the GitHub (with the pretrained model)\r\n\r\n**Other info / logs** \r\nTried debugging a bit, but didn't get too far. It seems to be some problem with the RecognizeCommands file.", "comments": ["I did some more digging around. It seems the inference is taking too long (about 1.9 seconds for every 1 second of recording), which doesn't allow the model to run properly. Is there any way to fix this?", "@leocorne Can you please check [this](https://github.com/tensorflow/tensorflow/issues/35143) issue which is similar to you? Let us know whether it helped or not. Thanks!", "This is a different issue. All the tests pass on my laptop. The problem happens when running inference on the Arduino board itself. It seems the inference is taking around 2 seconds which breaks the command detection.", "@leocorne I'm surprised that the inference takes 2s. Could you try with the latest TF lib in Arduino? The latest version is leveraging optimized kernel from Arm so presumably it should be much faster.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39979\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39979\">No</a>\n"]}, {"number": 39978, "title": "Missing positional argument error when deepcopy a LSTMCell", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.5 & 3.6\r\n\r\n**Describe the current behavior**\r\n\r\nAn exception is raised when calling `copy.deepcopy` on a `tf.keras.layers.LSTMCell`.\r\n\r\n**Describe the expected behavior**\r\n\r\nKeras layers should support `copy.deepcopy` without error since https://github.com/tensorflow/tensorflow/commit/4fd10c487c7e287f99b9a1831316add453dcba04. The same code worked in TensorFlow 2.1.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport copy\r\nimport tensorflow as tf\r\n\r\ncell = tf.keras.layers.LSTMCell(512)\r\ncell = copy.deepcopy(cell)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"test/deepcopy.py\", line 5, in <module>\r\n    cell = copy.deepcopy(cell)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 180, in deepcopy\r\n    y = _reconstruct(x, memo, *rv)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 280, in _reconstruct\r\n    state = deepcopy(state, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 220, in _deepcopy_tuple\r\n    y = [deepcopy(a, memo) for a in x]\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 220, in <listcomp>\r\n    y = [deepcopy(a, memo) for a in x]\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 150, in deepcopy\r\n    y = copier(x, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 240, in _deepcopy_dict\r\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n  File \"<env_dir>/lib/python3.6/copy.py\", line 161, in deepcopy\r\n    y = copier(memo)\r\n  File \"<env_dir>/lib/python3.6/weakref.py\", line 421, in __deepcopy__\r\n    new = self.__class__()\r\nTypeError: __init__() missing 1 required positional argument: 'default_factory'\r\n```", "comments": ["i am able to replicate this error on tensorflow 2.0, 2.1 and nightly as well, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/1f2bb8b9b9a9c37f6888e3425b92f141/untitled199.ipynb)", "Thanks for reporting the issue. Will send a fix very soon.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39978\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39978\">No</a>\n", "As this bug is a regression, will the commit get backported in a patch release?"]}, {"number": 39977, "title": "map the input image path dataset. ", "body": "```\r\n images,boxes,labels,difficulties= PascalVOCDataset()\r\n dataset = tf.data.Dataset.from_tensor_slices((images)).shuffle(100).batch(2)\r\n\r\ntf.Tensor(b'/media/jake/mark-4tb3/input/datasets/pascal/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/2008_000199.jpg', shape=(), dtype=string) tf.Tensor(b'/media/jake/mark-4tb3/input/datasets/pascal/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/2008_000187.jpg', shape=(), dtype=string)\r\n\r\n```\r\nThis will return the images, boxes with\r\n\r\n\r\nI want to map this file path to the real image path \r\n\r\n\r\n```\r\ndef func2(image,bbox):\r\n    print('func2')\r\n    print('dataset->',image)\r\n    images = np.array(image)\r\n    newSize = [300, 300]\r\n    if isprint: print('image_A->', images[0].decode(\"utf-8\"))\r\n    image = cv2.imread(images[0].decode(\"utf-8\"))\r\n    if isprint: print(image.shape)\r\n    image = np.array(image)\r\n    scale_x = newSize[0] / image.shape[1]\r\n    scale_y = newSize[1] / image.shape[0]\r\n    image = cv2.resize(image, (newSize[0], newSize[1]))\r\n    return tf.convert_to_tensor(image, dtype=tf.uint8), bbox\r\ndef fast_benchmark(dataset, num_epochs=2):\r\n    start_time = time.perf_counter()\r\n    for _ in tf.data.Dataset.range(num_epochs):\r\n        for _ in dataset:\r\n            pass\r\n    tf.print(\"\uc2e4\ud589 \uc2dc\uac04:\", time.perf_counter() - start_time)\r\n\r\nfast_benchmark(dataset.map(func2).batch(1).prefetch(tf.data.experimental.AUTOTUNE))\r\n```\r\n\r\n\r\n**NotImplementedError: in converted code:\r\n    relative to /home/jake:\r\n\r\n    Gits/ssd_tensorflow/train.py:46 func2  *\r\n        images = np.array(image)\r\n    venv/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py:396 converted_call\r\n        return py_builtins.overload_of(f)(*args)\r\n    venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:736 __array__\r\n        \" array.\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array.\r\n\r\nfunc2\r\ndataset-> Tensor(\"args_0:0\", shape=(), dtype=string)\r\n\r\nProcess finished with exit code 1**\r\n", "comments": ["@SlowMonk \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39976, "title": "RandomContrast Layer - confusing __init__ error message", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): Colab\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\nWhen instantiating a RandomContrast layer object with a value > 1. (e.g. 2) for the `Factor` parameter, a `ValueError` is raised with the following error message which is somewhat confusing in this scenario: 'Factor cannot have negative values, got 2'\r\n\r\n\r\n**Describe the expected behavior**\r\nA `ValueError` should be raised with a more appropriate error message, something like: 'Factor cannot be greater than 1, got 2'\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nrandom_contrast_layer = tf.keras.layers.experimental.preprocessing.RandomContrast(2)\r\n```\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/46ccdd512567b0dd3cf99a9548aead9c/39976.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/54056391942fbc1344d936558161b88f/39976-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@gnovack Thanks for reporting this issue. The RandomContrast layer looks for two element factor (lower_bound, upper_bound) or single element where the factor should be between 0 and 1. \r\n\r\nThe error message is improved. Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/6df7f036a25ff296903e9a74febc7e4e/39976-tf-nightly.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "Looks great. Thanks @jvishnuvardhan ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39976\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39976\">No</a>\n"]}, {"number": 39974, "title": "Setuptools 40.0.0 is incompatible", "body": "Does this error affect  tensorflow while executing it as import tensorflow as tf?\r\n\r\n![Screenshot (5)](https://user-images.githubusercontent.com/25500477/83214482-67f3b000-a184-11ea-89ce-41725b15b702.png)\r\n\r\n", "comments": ["@AayushN01\r\nPlease run a simple stand alone code and share the error in case you face any. \r\nAlso please let us know the tensor flow version been used.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39974\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39974\">No</a>\n"]}, {"number": 39973, "title": "dataset.from_generator error with multiple inputs", "body": "\r\n**System information**\r\n- no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): tensorflow-2.1.0 (cpu)\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nI use tf.keras.Model to build up a model. It has multiple inputs, say input is like `[i_1, i_2, i_3, a_1]`, output is only one, say `y`.\r\nI have a generator function\r\n```\r\ndef gen():\r\n    for i in range(data_length):\r\n        ...\r\n        yield [i_1, i_2, i_3, a_1], y\r\n```\r\nNotice that the inputs have variable sizes. Then I have the dataset built as:\r\n`ds = tf.data.dataset.from_generator(gen, output_type=(tf.float32,tf.float32, tf.float32, tf.float32, tf.int8))`\r\nwhen I send the ds to model.fit, it shows the error `map_fn() takes from 1 to 3 positional arguments but 5 were given`\r\n\r\nThen I tried \r\n`ds = tf.data.dataset.from_generator(gen, output_type=([tf.float32,tf.float32, tf.float32, tf.float32], tf.int8))`\r\nand \r\n`ds = tf.data.dataset.from_generator(gen, output_type=((tf.float32,tf.float32, tf.float32, tf.float32), tf.int8))`\r\nBoth of them show errors. How should make the from_generator take multiple inputs?\r\n\r\nThank you!", "comments": ["@sun-peach \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39973\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39973\">No</a>\n"]}, {"number": 39972, "title": "Can't use Keras with GPU (Tensorflow-gpu==1.15)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: tensorflow-gpu==1.15\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version: CUDA Version: 10.1 \r\n- GPU model and memory: GeForce RTX 2080 Ti/PCIe/SSE2\r\n\r\nHi guys, I'm installed tensorflow-gpu 1.15 and Keras 2.1.4. \r\nWhen i run: \r\n\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n\r\nReturn:\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\r\n/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\r\n\r\nBut when i run:\r\n\r\nK.tensorflow_backend._get_available_gpus()\r\n\r\nReturn []\r\n\r\nAnd when i train model it don't use gpu. But if i install tensorflow-gpu 2.2, model was trained by GPU on keras.\r\n\r\nHow can i use GPU on Keras with tensorflow-gpu 1.15? Thank you so much !", "comments": ["@ChungNPH,\r\nCould you please uninstall all the existing TensorFlow packages, so that there's no conflict. And then install TensorFlow 1.15 again.\r\n\r\nAlso, please check if you are facing the same issue in a virtual environment. Thanks!", "Hi @amahendrakar , i created a new env and installed tensorflow-gpu 1.15 and keras, but i still face this issue. :(", "Package              Version            \r\n-------------------- -------------------\r\nabsl-py              0.9.0              \r\nastor                0.8.1              \r\nbackcall             0.1.0              \r\ncertifi              2020.4.5.1         \r\ndecorator            4.4.2              \r\nentrypoints          0.3                \r\ngast                 0.2.2              \r\ngoogle-pasta         0.2.0              \r\ngrpcio               1.29.0             \r\nh5py                 2.10.0             \r\nimportlib-metadata   1.6.0              \r\nipykernel            5.1.4              \r\nipython              7.13.0             \r\nipython-genutils     0.2.0              \r\njedi                 0.17.0             \r\njupyter-client       6.1.3              \r\njupyter-core         4.6.3              \r\nKeras                2.3.1              \r\nKeras-Applications   1.0.8              \r\nKeras-Preprocessing  1.1.2              \r\nMarkdown             3.2.2              \r\nnumpy                1.18.4             \r\nopt-einsum           3.2.1              \r\nparso                0.7.0              \r\npexpect              4.8.0              \r\npickleshare          0.7.5              \r\npip                  20.0.2             \r\nprompt-toolkit       3.0.4              \r\nprotobuf             3.12.2             \r\nptyprocess           0.6.0              \r\nPygments             2.6.1              \r\npython-dateutil      2.8.1              \r\nPyYAML               5.3.1              \r\npyzmq                18.1.1             \r\nscipy                1.4.1              \r\nsetuptools           46.4.0.post20200518\r\nsix                  1.15.0             \r\ntensorboard          1.15.0             \r\ntensorflow-estimator 1.15.1             \r\ntensorflow-gpu       1.15.0             \r\ntermcolor            1.1.0              \r\ntornado              6.0.4              \r\ntraitlets            4.3.3              \r\nwcwidth              0.1.9              \r\nWerkzeug             1.0.1              \r\nwheel                0.34.2             \r\nwrapt                1.12.1             \r\nzipp                 3.1.0  \r\n\r\nhere's my pip list", "@ChungNPH I think there is a mismatch in the CUDA version. `TF1.15` requires `_DEFAULT_CUDA_VERSION = '10'` but you have 10.1 version. Can you please try to uninstall 10.1 and install 10 and then install `TF1.15-gpu`.  Please check the [`config`](https://github.com/tensorflow/tensorflow/blob/r1.15/configure.py) for the compatible versions.\r\n\r\n`TF2.2` is working because it is satisfying the CUDA version requirement which is 10.1. Thanks!\r\n\r\nPlease feel free to close if this was resolved for you. Thanks!", "Thank you so much, i will try."]}, {"number": 39971, "title": "[INTEL MKL] Supporting mkldnn ops for threadpool", "body": "", "comments": []}, {"number": 39970, "title": "Unable to use tfp.optimizer.lbfgs_minimize, error after 2 iterations", "body": "Hi I am unable to use tfp.optimizer.lbfgs_minimize, following the tutorial on https://www.tensorflow.org/probability/examples/Optimizers_in_TensorFlow_Probability.\r\n\r\nSimilar to https://github.com/tensorflow/probability/issues/398,\r\n\r\nI am facing error \"Inputs to operation Select of type Select must have the same size and shape.  Input 0: [110] != input 1: [1] [Op:Select]\"\r\n\r\nI noticed that when my cost function if of shape (1,) and my gradient of shape (x,1) it says x!=1\r\nBut what I don't understand is why does my cost function need to be of shape(x,1)? When I add a placeholder return which returns shape (x,1) for cost value as well, it runs.  \r\n\r\n![image](https://user-images.githubusercontent.com/7682371/83195374-09054b00-a132-11ea-8b56-f353f89b54a7.png)\r\n", "comments": ["@prathak \r\nPlease share a simple stand alone code along with tensor flow version for us to replicate the issue faced.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39970\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39970\">No</a>\n"]}, {"number": 39969, "title": "Simple keras model \"predict\" call fails inside py_function", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. Created a simple example for reproducibility. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: Python 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: CUDA 10.2 / cuDNN 7.6.5\r\n- GPU model and memory: GeForce GTX 980 Ti / 6GB\r\n\r\n**Describe the current behavior**\r\n\r\nUsing the 'predict' api for a keras model inside a py_function throws the following error:\r\n`LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)`\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ninp = tf.keras.Input(shape=(5,))\r\nout = tf.keras.layers.Dense(1)(inp)\r\nmodel = tf.keras.Model(inp, out)\r\n\r\ndef outer_func(arr):\r\n    def _func(x):\r\n        res = model.predict(x)\r\n        return res\r\n\r\n    out = tf.py_function(\r\n        _func,\r\n        (arr,),\r\n        tf.float32\r\n    )\r\n    return out\r\n\r\nouter_func(np.random.rand(10, 5))\r\n```", "comments": ["I have tried in colab with TF version 2.2 ,nightly version(`2.3.0-dev20200528`) and was able to reproduce the issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/b72b16e5ec0c4339658c43ba4f3fb1db/untitled932.ipynb)Thanks!", "model.predict contains a lot of state-management and input processing logic that is not designed for this usecase. Can you try instead just calling the model? Eg:\r\n\r\n```\r\ndef _func(x):\r\n        res = model(x)\r\n        return res\r\n```", "I cannot unfortunately because I am using a third party library that wraps helper functions / class around the model.predict call. I'm using in a py_function because I'm including it in a tf.data.Dataset pipeline.", "This is fixed with latest tf-nightly.\r\nSee [gist](https://colab.research.google.com/gist/ymodak/d123012b1d690f653a078458f4174238/untitled9.ipynb)\r\nOutput:\r\n```python\r\n<tf.Tensor 'EagerPyFunc_1:0' shape=<unknown> dtype=float32>\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39969\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39969\">No</a>\n", "@ymodak is still not fixed yet in 2.6.0 but worked at the nightly, do we have any estimation when this will be officially released? "]}, {"number": 39968, "title": "TensorFlow \"steals\" stdout when using output redirection", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nExample code provided.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 and Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pypi\r\n- TensorFlow version (use command below): 2.1.0 and 2.2.0\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using TensorFlow with output redirection or pipelining under linux, stdout is buffered for a very long time/indefinitely. In my example script, Python's print is outputed when the script exits. This only happens when you redirect script output. Test on zsh and bash. This is really annoying for longer scripts, that train real models.\r\n\r\nThere is one more thing you can notice in my example script, print version happens before TensorFlow is initialized, so it should output before warnings.\r\n\r\nCorrect:\r\n\r\n```\r\nTensorflow version: 2.2.0\r\n2020-05-28 22:05:10.001027: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-05-28 22:05:10.001046: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-05-28 22:05:10.001058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lain): /proc/driver/nvidia/version does not exist\r\n2020-05-28 22:05:10.001249: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-28 22:05:10.024089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3699850000 Hz\r\n2020-05-28 22:05:10.024353: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6e5c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-28 22:05:10.024385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(1, shape=(), dtype=int32)\r\ntf.Tensor(2, shape=(), dtype=int32)\r\ntf.Tensor(3, shape=(), dtype=int32)\r\n```\r\n\r\nIncorrect order because stdout is cached:\r\n\r\n```\r\n2020-05-28 22:02:34.064521: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-05-28 22:02:34.064545: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-05-28 22:02:34.064562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lain): /proc/driver/nvidia/version does not exist\r\n2020-05-28 22:02:34.064822: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-28 22:02:34.088105: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3699850000 Hz\r\n2020-05-28 22:02:34.088365: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7bcc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-28 22:02:34.088379: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTensorflow version: 2.2.0\r\ntf.Tensor(1, shape=(), dtype=int32)\r\ntf.Tensor(2, shape=(), dtype=int32)\r\ntf.Tensor(3, shape=(), dtype=int32)\r\n```\r\n\r\nI don't think it applies to stderr. If I would speculate, I would say that someone is trying to detect terminal and something goes wrong when you redirect output.\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow should not be \"stealing\" or changing default stdout behavior.\r\n\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport time\r\n\r\nimport tensorflow as tf\r\n\r\nprint('Tensorflow version:', tf.version.VERSION)\r\n\r\n\r\ndef run():\r\n    dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\n    for element in dataset:\r\n        print(element)\r\n    time.sleep(60)\r\n\r\n\r\nif __name__ == '__main__':\r\n    run()\r\n```\r\n\r\nHow to run it:\r\n\r\nCorrect output:\r\n\r\n```\r\npython stdout-bug.py\r\n```\r\n\r\nBroken:\r\n\r\n```\r\npython stdout-bug.py | tee foo.log 2>&1\r\npython stdout-bug.py | tee foo.log\r\npython stdout-bug.py > foo.log 2>&1\r\npython stdout-bug.py > foo.log\r\n```\r\n\r\n", "comments": ["@garar,\r\nOn running the code with TF v2.2, I see that I got the 'correct' output. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b41a4217e244d24d7793e84e1b49ebc0/39968.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39968\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39968\">No</a>\n"]}, {"number": 39967, "title": "[INTEL MKL] minor bug fixes for threadpool unit tests.", "body": "", "comments": []}, {"number": 39966, "title": "[INTEL MKL] Threapool support for matmul, fused matmul, qmatmul.", "body": "", "comments": []}, {"number": 39965, "title": "Use of unresolved identifier 'CoreMLDelegate'", "body": "![Screenshot 2020-05-29 at 12 50 56 AM](https://user-images.githubusercontent.com/44207274/83184096-918de680-a146-11ea-836f-1cf6c895c7fb.png)\r\n\r\npod version TensorFlowLiteSwift 0.0.1-nightly.20200527\r\n\r\nFacing this issue even after running \r\n\r\n> pod cache clean TensorFlowLiteSwift\r\n", "comments": ["@hanishsairohit \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "I'm also running into this issue after upgrading from `'0.0.1-nightly.20200513'` to `0.0.1-nightly.20200519` or `0.0.1-nightly.20200527`. My pod spec:\r\n\r\n```rb\r\nuse_frameworks!\r\n\r\ntarget 'XXX' do\r\n  pod 'TensorFlowLiteSwift', '0.0.1-nightly.20200527'\r\nend\r\n```", "This has fixed it for me:\r\n```rb\r\nuse_frameworks!\r\n\r\ntarget 'XXX' do\r\n  pod 'TensorFlowLiteSwift', '0.0.1-nightly.20200527'\r\n  pod 'TensorFlowLiteSwift/CoreML', '0.0.1-nightly.20200527'\r\n  pod 'TensorFlowLiteSwift/Metal', '0.0.1-nightly.20200527'\r\nend\r\n```\r\nThey split the TensorFlowLiteSwift pod into subspecs (CoreML, Metal, ...) so you have to install them manually as needed.", "Thank you so much! @grin ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39965\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39965\">No</a>\n"]}, {"number": 39963, "title": "Error when using Class_Weight in Keras for binary classification", "body": "Here is the model summary: \r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d (Conv1D)              (None, 35, 32)            96        \r\n_________________________________________________________________\r\nbatch_normalization (BatchNo (None, 35, 32)            128       \r\n_________________________________________________________________\r\ndropout (Dropout)            (None, 35, 32)            0         \r\n_________________________________________________________________\r\nconv1d_1 (Conv1D)            (None, 34, 64)            4160      \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (None, 34, 64)            256       \r\n_________________________________________________________________\r\ndropout_1 (Dropout)          (None, 34, 64)            0         \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 2176)              0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 64)                139328    \r\n_________________________________________________________________\r\ndropout_2 (Dropout)          (None, 64)                0         \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 1)                 65        \r\n=================================================================\r\nTotal params: 144,033\r\nTrainable params: 143,841\r\nNon-trainable params: 192\r\n```\r\nHere is the error message:\r\n\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-14-09a8a255f317> in <module>()\r\n----> 1 history = model.fit(X_Train,Y_Train, epochs = epochs, validation_data =(X_Test,Y_Test), verbose=1,class_weight=class_weights1)\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nInvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  indices[31] = -9223372036854775808 is not in [0, 2)\r\n     [[{{node GatherV2}}]]\r\n     [[IteratorGetNext]]\r\n     [[IteratorGetNext/_2]]\r\n  (1) Invalid argument:  indices[31] = -9223372036854775808 is not in [0, 2)\r\n     [[{{node GatherV2}}]]\r\n     [[IteratorGetNext]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_6381]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function\r\n```\r\nSomehow I'm getting a massive negative number? My dataset is all percentile data so numbers between 0 and 1.\r\n\r\nAlso here is the code to set up the model:\r\n```\r\nclass_weights1 = {0: 1., 1: 50.}\r\n\r\nepochs = 1\r\nmodel = Sequential()\r\nmodel.add(Conv1D(filters = 32, kernel_size = 2, activation='relu',input_shape=(36,1)))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Dropout(0.2))\r\n\r\nmodel.add(Conv1D(filters = 64, kernel_size = 2, activation='relu'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64,activation='relu'))\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Dense(1,activation='sigmoid'))\r\n```\r\nAnd then the code to compile and run it:\r\n```\r\nmodel.compile(optimizer=Adam(lr=0.005),loss='binary_crossentropy',metrics=['accuracy'])\r\n\r\nhistory = model.fit(X_Train,Y_Train, epochs = epochs, validation_data =(X_Test,Y_Test), verbose=1,class_weight=class_weights1)\r\n```\r\nI know this is a problem with my class_weight because when I remove it, everything works (but the model is terrible because the data is imbalanced and I need to increase the weight of the minority class to adjust for this).", "comments": ["@xxanissarxx \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nRequest you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Hi I'm having the same issue. My model was working fine with class_weight while using tf 1.15 .  But with the new version It fails when I add class_weight\r\n\r\n`Model: \"sequential_1\"\r\n_______________________________________________________________________________________________________\r\nLayer (type)                                  Output Shape                             Param #         \r\n=======================================================================================================\r\ndense_1 (Dense)                               (None, 2525)                             24699550        \r\n=======================================================================================================\r\nTotal params: 24,699,550\r\nTrainable params: 24,699,550\r\nNon-trainable params: 0\r\n_______________________________________________________________________________________________________\r\nEpoch 1/2`\r\n\r\nError in py_call_impl(callable, dots$args, dots$keywords) : \r\n  InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: Can not squeeze dim[0], expected a dimension of 1, got 512\r\n\t [[{{node loss_5/dense_1_loss/weighted_loss/Squeeze}}]]\r\n\t [[metrics_5/accuracy/Identity/_153]]\r\n  (1) Invalid argument: Can not squeeze dim[0], expected a dimension of 1, got 512\r\n\t [[{{node loss_5/dense_1_loss/weighted_loss/Squeeze}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nDetailed traceback: \r\n  File \"C:\\Users\\installer.CTNAD00MJ06SCHM\\Documents\\.conda\\envs\\r2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1297, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"C:\\Users\\installer.CTNAD00MJ06SCHM\\Documents\\.conda\\envs\\r2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\", line 265, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"C:\\Users\\installer.CTNAD00MJ06SCHM\\Documents\\.conda\\envs\\r2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\",\r\n\r\nI'm using windows environment and tensorflow version is 2.0\r\n> tensorflow::tf_version()\r\n[1] \u20182.0\u2019 \r\n\r\n", "Has anybody solved this issue? Or found a workaround?"]}, {"number": 39962, "title": "TFLite Convert Python API Has Bad Code", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/lite/convert/python_api\r\n\r\n## Description of issue (what needs changing):\r\nUnder 'Converting a Keras model' it has the code `tf.gfile.GFile` and that code has moved to `tf.io.gfile.GFile`\r\n\r\n### Clear description\r\nThis change should be made so that the code runs.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? No errors\r\n\r\n### Usage example\r\n\r\nIs there a usage example? No\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content? N/A\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": []}, {"number": 39961, "title": "Update Eigen to 8719b9c5bc1a97e62d675c02495ed72dda6fae73 to fix compiling error", "body": "This PR tries to update Eigen to 8719b9c5bc1a97e62d675c02495ed72dda6fae73.\r\nThe reason to update Eigen is to fix the build error for custom ops (See error below).\r\nThe issue is that in Eigen there was a bug that uses `if defined(EIGEN_ARCH_PPC)` incorrectly (should be `if EIGEN_ARCH_PPC`).\r\n\r\nI have created a PR in Eigen https://gitlab.com/libeigen/eigen/-/merge_requests/131 and the PR has already been merged.\r\n\r\nThis PR is a follow up in tensorflow repo to bump the Eigen to the latest version.\r\n\r\nThe error before this PR, when building a custom ops:\r\n```\r\nExecution platform: @local_config_platform//:host\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nIn file included from tensorflow_io/core/kernels/io_optimization.cc:22:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/compiler/mlir/mlir_graph_optimization_pass.h:20:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/core/common_runtime/function_optimization_registry.h:23:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/core/common_runtime/device_set.h:23:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/core/common_runtime/device.h:35:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/core/framework/allocator.h:26:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/tensorflow/core/framework/numeric_types.h:20:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from bazel-out/darwin-fastbuild/bin/external/local_config_tf/include/unsupported/Eigen/CXX11/Tensor:14:\r\nbazel-out/darwin-fastbuild/bin/external/local_config_tf/include/unsupported/Eigen/CXX11/../../../Eigen/Core:334:10: fatal error: 'src/Core/arch/AltiVec/MatrixProduct.h' file not found\r\n         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n1 error generated.\r\nTarget //tensorflow_io/core:optimization failed to build\r\nINFO: Elapsed time: 4.778s, Critical Path: 4.54s\r\n```\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["The error is caused by https://stackoverflow.com/questions/60864626/cannot-fetch-eigen-with-bazel-406-not-acceptable\r\n\r\nI think adding the mirror in https://storage.googleapis.com/mirror.tensorflow.org will solve the issue.", "@mihaimaruseac The test failures are related to Bazel 's inability to download gitlab directly. In the past that was resolved through TensorFlow's own bazel mirror ( https://storage.googleapis.com/mirror.tensorflow.org ).\r\n\r\nI don't have access to add items to this mirror. Wondering if you could help placing the eigen archive file into the mirror?\r\n\r\n", "Sure. Was planning to do that on import, but it seems currently copybara is broken due to MLIR/LLVM so I'll have to import manually."]}, {"number": 39960, "title": "windows 8.1 : import error: DLL load failed", "body": "windows 8.1\r\npip install tensorflow_cpu\r\nimport tensorflow as tf\r\n\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Pratik\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Pratik\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Pratik\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Pratik\\anaconda3\\envs\\tensorflow_cpu\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Pratik\\anaconda3\\envs\\tensorflow_cpu\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@saurabhsbb  \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).It helps us in localizing the issue faster.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements).\r\n\r\nMake sure to download the latest [microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows)..\r\n\r\nPlease, check Your CPU/Python is on 32 bits?.Refer #36167 #39423 and see if it helps you.\r\n\r\nsimilar issue #23683 #28713 #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39960\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39960\">No</a>\n"]}, {"number": 39959, "title": "how to check quantization method applied", "body": "how do I check what quantization specification has been applied to model (TensorFlow quantized format)?\r\nI'd like to know what\r\n- Dynamic range quantization, Full integer quantization, Float16 quantization,etc...\r\n- Symmetric vs asymmetric\r\n- Per-axis vs per-tensor\r\n- Signed integer vs unsigned integer\r\n- etc..\r\n\r\nThank you\r\n", "comments": ["You can use TensorBoard to load your TF model and explore [op-level graph](https://www.tensorflow.org/tensorboard/graphs#op-level_graph) to examine the node properties.\r\nAnother way is to visualize your model using [netron](https://github.com/lutzroeder/netron). ", "can you please give some visual examples of what exactly you mean - how to check it?\r\nIt seems to me there is no explicit way whereof quantization method is applied but just individual nodes inspection...\r\n\r\ncan you suggest a method of inspecting?\r\n\r\nThank you.\r\n", "Hi @peter197321 !\r\nWe are checking to see whether you still need help in this issue .Have you checked with threads on  **netron**  model visualization yet ?[link1](https://marcin-staskopl.medium.com/netron-fast-neuronal-network-visualization-online-21c4d0248222),[link2](https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/). Please post this issue on [TF forum](https://discuss.tensorflow.org/) for further assistance. Thanks!", "Is there an example of how to do it? if so, it would be very appreciated.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39959\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39959\">No</a>\n"]}, {"number": 39958, "title": "Training fails with \"CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\" on Windows 10", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **binary (via pip install)**\r\n- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**\r\n- Python version: **3.6.8**\r\n- Bazel version (if compiling from source): Not applicable\r\n- GCC/Compiler version (if compiling from source): Not applicable\r\n- CUDA/cuDNN version: **cuda 10.1.243_426.00_win10 (CUDA Toolkit 10.1 update2 Archive ) / cuDNN v7.6.5 (November 5th, 2019), for CUDA 10.1**\r\n- GPU model and memory: **GeForce GTX 1070, Compute Capability 6.1, 8Gb; \r\nalso on GeForce GTX 1050 Ti 4Gb on another Win 10 machine with the same cuda version installed**\r\n\r\n**Describe the current behavior**\r\nI use TF Keras API to define the model and the training process.\r\n\r\nThe training stops with the error:\r\n```\r\n2020-05-28 18:52:43.846256: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\n2020-05-28 18:52:43.846616: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\n\r\nexit code -1073740791\r\n```\r\n\r\nafter several training epochs.\r\n\r\nIt happens in a reproducible way (the same python file execution fails after the same number of epochs).\r\nWhen I change the random seed (thus the dataset is shuffled differently) the process fails after different number of epochs!\r\nChanging batch size also effects the number of epochs until the training fail (randomly)!\r\nI use batch size of 1 or 2 as I have rather large model.\r\n\r\n**Describe the expected behaviour**\r\nTraining runs without the error requested number of epochs.", "comments": ["@dgrechka,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, please check [this](https://github.com/tensorflow/tensorflow/issues/37942) similar issue and let us know if it helps. Thanks!", "Thank you,  @amahendrakar ,\r\n\r\nFinally I've separated out the repro out of my project.\r\n\r\nIt seems that it fails on considerably large number of training samples.\r\nIf I try to reproduce it with smaller dataset, the issue is not triggered.\r\n\r\n### How to reproduce\r\n\r\n**On windows 10**  (see environment details in the very first post).\r\n\r\n1. Download the [zip archive](https://grechka.family/dmitry/sandbox/issue_39958_repro.zip) (quite large ~871Mb, but smaller samples count does not trigger the issue.)\r\n2. extract it\r\n3. install python dependencies with `pip install -r .\\pip_deps.txt`\r\n4. run the repro script with `python .\\run_repro.py`\r\n\r\nThe file `stdout_stderr_showing_the_issue.log` in the archive contains the stdout and stderr which I get when I run this repro (including the error).", "@dgrechka,\r\nI was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/2f833285e241e4c355cd2703f9e34d46/39958.ipynb).\r\n\r\nCould you please upgrade the the stable version of TensorFlow 2.2 and check if you are facing the same issue. Thanks!", "@amahendrakar , thanks!\r\n\r\nAs you can see in pip_deps.txt, I use the latest stable version of tensorflow `tensorflow==2.2.0` which is the release of May 7, 2020.\r\n\r\nThis issue is related to Windows only.\r\nThere is no such issue on linux (I tried Ubuntu 18.04)\r\n\r\nDid you run the repro on Windows?", "@dgrechka,\r\nThank you for the update. Currently, I do not have a Windows machine to test the code.", "Can you please run the test with the `CUDA_LAUNCH_BLOCKING` env variable set to `1`?  That will help us narrow down the issue to a specific kernel launch.\r\n\r\nPlease also upload the full log as a gist so that we don't have download the whole archive to look at the log.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue goes for a some time after the reboot (then comes back again). Give me some more time to reproduce with the flags requested, I'm postponed the model training on Windows. Will return and give more repro details.", "@dgrechka \r\nIs this still an issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39958\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39958\">No</a>\n", "I am also running TF 2.4.1 on Windows 10. And like you, my GPU is an Nvidia GeForce GTX 1050 Ti (with CUDA 11.0 installed). I'm training on a large number of images. When I tried to run my code on a sample of the data (containing about 3% of the entire data), it worked out fine. But when I fed all of the data to the model, it came up with this error after finishing some epochs (1, 2 or 3 epochs):\r\n\r\nCUDA_ERROR_LAUNCH_FAILED: unspecified launch failure, Unexpected Event status: 1\r\n\r\nI wonder if you have solved your problem and if so, how. Thanks!"]}]