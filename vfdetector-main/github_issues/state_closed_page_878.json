[{"number": 27151, "title": "God", "body": "#27044 ", "comments": ["Guys please help me I am tired of these merged conflicts whenever I am adding a new commit all my past commits are automatically get  added in my pull request what to do????", "> Guys please help me I am tired of these merged conflicts whenever I am adding a new commit all my past commits are automatically get added in my pull request what to do????\r\n\r\nYou can upstream the forked repo and merge with the new commits that you have done.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 27150, "title": "keras.metrics.MeanIoU - AttributeError: 'list' object has no attribute 'shape'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.7.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: not relevant\r\n- GPU model and memory: not relevant\r\n\r\n**Describe the current behavior**\r\nThe example given for tf.keras.metrics.MeanIoU returns `AttributeError: 'list' object has no attribute 'shape'`. If I convert the lists to tf arrays as input, it runs without error.\r\n\r\n**Describe the expected behavior**\r\nThe example given in the tf.keras.metrics.MeanIoU documentation should run without error.\r\n\r\n**Code to reproduce the issue**\r\nThis is the example given in the docs with error message returned when ran:\r\n\r\n```python\r\nm = tf.keras.metrics.MeanIoU(num_classes=2)\r\nm.update_state([0, 0, 1, 1], [0, 1, 0, 1])\r\n# cm = [[1, 1],\r\n#      [1, 1]]\r\n# sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\r\n# iou = true_positives / (sum_row + sum_col - true_positives))\r\n# result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2 = 0.33\r\nprint('Final result: ', m.result().numpy())  # Final result: 0.33\r\n```\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-29-75e080c0562a> in <module>\r\n      1 m = tf.keras.metrics.MeanIoU(num_classes=2)\r\n----> 2 m.update_state([0, 0, 1, 1], [0, 1, 0, 1])\r\n      3 # cm = [[1, 1],\r\n      4 #      [1, 1]]\r\n      5 # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py in decorated(metric_obj, *args, **kwargs)\r\n     69     \"\"\"Decorated function with `add_update()`.\"\"\"\r\n     70 \r\n---> 71     update_op = update_state_fn(*args, **kwargs)\r\n     72     if update_op is not None:  # update_op will be None in eager execution.\r\n     73       metric_obj.add_update(update_op, inputs=True)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py in update_state(self, y_true, y_pred, sample_weight)\r\n   2273     \"\"\"\r\n   2274     # Flatten the input if its rank > 1.\r\n-> 2275     if y_pred.shape.ndims > 1:\r\n   2276       y_pred = array_ops.reshape(y_pred, [-1])\r\n   2277 \r\n\r\nAttributeError: 'list' object has no attribute 'shape'\r\n```\r\n", "comments": ["Thank you for the PR. ", "Closing this issue as PR is merged."]}, {"number": 27149, "title": "how to generate batch pictures of myselt dataset", "body": " Based on MNIST recognition project,I want to train myself dataset,I want to generate more pictures on the basis of the existing captured pictures. thank you for your reply as soon as possible.\r\n ", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 27148, "title": "Change tensorflow GPU docker file to be compatible with Kubernetes GPU doc", "body": "@angersson, reference to #26393.\r\n\r\nI'm not sure if I was in the right direction, I change some package version from CUDA9.0 to CUDA10.0,\r\nI'll check if it's  compatible Kubernetes GPU settings.\r\n\r\nHope could get some advice from you.\r\n\r\nThanks.", "comments": ["@a6802739 Our Docker images are all built from the `dockerfiles` directory, rather than the `docker` directory (I'm trying to remove the old directory in https://github.com/tensorflow/tensorflow/pull/26113, because it's confusing). Can you take a look there, instead?", "@angersson Thanks for your response, so I should wait for #26113 done, and then merge the change after?\r\n", "If you like, you can start looking at the dockerfiles/ directory now. No need to wait on that change -- all it does is delete the old directory.", "@angersson, Thanks! Just done that as you say. Please take a loot at it.", "@a6802739, please take a look at the README in the dockerfiles directory. You'll have to update the partial files and recreate the images from there.", "@a6802739 can you please check latest review comments.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27147, "title": "AttentionMechanism not be supported in Eager Mode", "body": "When I want to add certain classical AttetionMechansim through Tensorflow API, I find that Tensorflow 's AttentionMechansim API dose not support Eager Mode for the reason that \"memory\" parameter is in the attention mechiansim s' __init__ method. Because in general, I construct a AttentionMechanism in static graph mode, it must be constructed transferring a parameter \"memory\" , a tensor whose value is decided by the model input. However, in Eager Mode,  when constructing a AttentionMechanism, \"memory\" is deterministically taking real values, which enables me not to change to a new memory values in a new training iteration.\r\n", "comments": ["Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. It would be great if you can provide a small code to reproduce the error. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27146, "title": "Should `fold_constants` be before or after `flatten_atrous_conv`", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: v1.13.1\r\n- Doc Link: https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/tools/graph_transforms/README.md#flatten_atrous_conv\r\n\r\n\r\n**Describe the documentation issue**\r\nThe `flatten_atrous_conv` section lists `Prerequisites: fold_constants`, whereas in the main paragraph, it says `You will need to make sure you run fold_constants after this transform.`\r\nSo should `fold_constants` be before or after `flatten_atrous_conv`?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI assume it's before `flatten_atrous_conv`, so I submitted a PR.\r\nhttps://github.com/tensorflow/tensorflow/pull/27145", "comments": ["Hey @suharshs, any idea about the answer? or more generally the status of GraphTransform Tool?", "@lee-bin,\r\nCan you please let us know if this change is still relevant as we don't use `Graph Transform Tool` much in **`Tensorflow 2.x`** ? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 27145, "title": "Fix flatten_atrous_conv doc", "body": "", "comments": ["I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 27144, "title": "CUDNN_STATUS_INTERNAL_ERROR on GTX 1660 TI", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, simple dummy code\r\n```\r\nimport tensorflow as tf\r\n\r\ndef main():\r\n    config = tf.ConfigProto()\r\n    \r\n    sess = tf.Session(config=config)\r\n\r\n    x = tf.random.uniform([16, 64, 64, 3])\r\n    net = x\r\n    net = tf.layers.conv2d(net, filters=16, kernel_size=3, padding='same', strides=2)\r\n    net = tf.layers.flatten(net)\r\n    net = tf.layers.dense(net, 1)\r\n\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n    out = sess.run(net)\r\n    print(out)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Both source and compiled tested\r\n- TensorFlow version (use command below): v1.13.1-0-g6612da8951\r\n- Python version: Tested on both 3.5 and 3.6\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): gcc-6 (Ubuntu 6.5.0-2ubuntu1~18.04) 6.5.0 20181026\r\n- CUDA/cuDNN version: Tested with 10.0/7.5 and 10.1/7.5\r\n- GPU model and memory: GTX 1660 TI 6GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nUsing any convolution layers fails. Same error with all both versions of CUDA. `~/.nv` directory cleared between runs. Same error in docker images as well. CUDNN verified to be working correctly with simple CUDNN programs (e.g. [this](https://gist.github.com/odashi/1c20ba90388cf02330e1b95963d78039))\r\n\r\n**Describe the expected behavior**\r\nCode should print an array of 16 numbers\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n```\r\n2019-03-26 11:14:43.230340: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-03-26 11:14:43.330837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-26 11:14:43.331452: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3d4a090 executing computations on platform CUDA. Devices:\r\n2019-03-26 11:14:43.331472: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1660 Ti, Compute Capability 7.5\r\n2019-03-26 11:14:43.356898: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3400255000 Hz\r\n2019-03-26 11:14:43.357161: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3db1d00 executing computations on platform Host. Devices:\r\n2019-03-26 11:14:43.357190: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-26 11:14:43.357646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.8\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 5.77GiB freeMemory: 5.19GiB\r\n2019-03-26 11:14:43.357674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-26 11:14:43.358609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-26 11:14:43.358630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-26 11:14:43.358640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-26 11:14:43.359045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5016 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\nWARNING:tensorflow:From simpletf_test/tf_convnet.py:11: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.conv2d instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From simpletf_test/tf_convnet.py:12: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.flatten instead.\r\nWARNING:tensorflow:From simpletf_test/tf_convnet.py:13: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.dense instead.\r\n2019-03-26 11:14:43.819308: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n2019-03-26 11:14:44.479283: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-03-26 11:14:44.498430: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node conv2d/Conv2D}}]]\r\n\t [[{{node dense/BiasAdd}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"simpletf_test/tf_convnet.py\", line 22, in <module>\r\n    main()\r\n  File \"simpletf_test/tf_convnet.py\", line 18, in main\r\n    out = sess.run(net)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node conv2d/Conv2D (defined at simpletf_test/tf_convnet.py:11) ]]\r\n\t [[node dense/BiasAdd (defined at simpletf_test/tf_convnet.py:13) ]]\r\n\r\nCaused by op 'conv2d/Conv2D', defined at:\r\n  File \"simpletf_test/tf_convnet.py\", line 22, in <module>\r\n    main()\r\n  File \"simpletf_test/tf_convnet.py\", line 11, in main\r\n    net = tf.layers.conv2d(net, filters=16, kernel_size=3)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 424, in conv2d\r\n    return layer.apply(inputs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node conv2d/Conv2D (defined at simpletf_test/tf_convnet.py:11) ]]\r\n\t [[node dense/BiasAdd (defined at simpletf_test/tf_convnet.py:13) ]]\r\n\r\n```", "comments": ["I am having the same issue on RTX 2080 and Tf 2.0,  #27141 \r\n\r\n", "Duplicate #24496 \r\nCan you please try the solution that worked for other users in the above issue? Thanks!", "Looks like setting `allow_growth=True` allows the toy program to run. Interestingly, using TF1.12 in the docker container works without this setting. \r\n\r\nIs this the way forward and is there a way to set this by default? Seems like it will require me to touch a large number of files in my unit tests...\r\n\r\nThanks!", "I am glad it hack worked for you. Unfortunately, Currently we don't have a feature to set ```allow_growth=True``` by default. I will close this issue since its resolved. Feel free to reopen if have any further questions. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27144\">No</a>\n", "in python keras package modify file tensorflow_backend.py\r\ndef get_session():\r\n# add by sloan fix CUDNN_STATUS_INTERNAL_ERROR\r\n            config.gpu_options.allow_growth = True\r\n            _SESSION = tf.Session(config=config)"]}, {"number": 27143, "title": "[TF 2.0] tf 2 around 40 times slower than tf 1 for unrolled taylor series", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: Python 3.6.7\r\n- CUDA/cuDNN version: 10.0/7.4\r\n- GPU model and memory: GeForce GTX 1060, Compute Capability 6.1, 6GB RAM\r\n\r\nThis issue follows on from https://github.com/tensorflow/tensorflow/issues/26807\r\n\r\n**Describe the current behavior**\r\n\r\nThe code linked at the bottom calculates a matrix exponential (`expm`) using a [taylor series](https://en.wikipedia.org/wiki/Taylor_series#Exponential_function). It outputs the following when running with the latest TF1 and TF2 installations from pip:\r\n\r\n```shell\r\n(tf1) $ python expm.py \r\nBENCHMARKS:\r\ntf took 0.1590 seconds for 25 iterations\r\ntaylor took 0.0158 seconds for 25 iterations\r\n\r\n(tf2) $ python expm.py \r\nBENCHMARKS:\r\ntf took 0.7530 seconds for 25 iterations\r\ntaylor took 1.0743 seconds for 25 iterations\r\ntaylor_v2 took 0.6025 seconds for 25 iterations\r\nPROFILES:\r\nprofile for taylor_v2\r\n         2251 function calls in 0.634 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n       25    0.000    0.000    0.634    0.025 expm.py:74(<lambda>)\r\n       25    0.000    0.000    0.634    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py:400(__call__)\r\n       25    0.000    0.000    0.634    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:1267(__call__)\r\n       25    0.000    0.000    0.632    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:542(_filtered_call)\r\n       25    0.000    0.000    0.632    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:560(_call_flat)\r\n       25    0.000    0.000    0.630    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:379(call)\r\n       25    0.000    0.000    0.630    0.025 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py:33(quick_execute)\r\n       25    0.630    0.025    0.630    0.025 {built-in method _pywrap_tensorflow_internal.TFE_Py_Execute}\r\n       25    0.000    0.000    0.001    0.000 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:1505(_maybe_define_function)\r\n   ...\r\n```\r\n\r\nI've included some profiling information for the function of interest (`taylor_v2` in TF 2) which shows that it spends all the time in `_pywrap_tensorflow_internal.TFE_Py_Execute`.\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect TF 1 `taylor` (which uses `tf.Session.run`) and TF 2 `taylor_v2` (which uses `tf.function`) to have similar performance.\r\n\r\n**Code to reproduce the issue**\r\n\r\n``` python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time as tm\r\nimport cProfile as pr\r\nimport io\r\nimport pstats as ps\r\n\r\nMATRIX_DIM = 1000\r\nTAYLOR_SUM = 30\r\nEPS = 1e-2\r\nWARMUP = 10\r\nITERATIONS = 25\r\n\r\n\r\ndef benchmark(name, fn):\r\n    for _ in range(WARMUP):\r\n        value = fn()\r\n    start = tm.time()\r\n    for _ in range(ITERATIONS):\r\n        value = fn()\r\n    end = tm.time()\r\n    runtime = end - start\r\n    print(f\"{name} took {runtime:.4f} seconds for {ITERATIONS} iterations\")\r\n    return value\r\n\r\n\r\ndef profile(name, fn):\r\n    for _ in range(WARMUP):\r\n        value = fn()\r\n\r\n    profile = pr.Profile()\r\n    profile.enable()\r\n\r\n    for _ in range(ITERATIONS):\r\n        value = fn()\r\n\r\n    profile.disable()\r\n    s = io.StringIO()\r\n    sortby = \"cumulative\"\r\n    stats = ps.Stats(profile, stream=s).sort_stats(sortby)\r\n    stats.print_stats()\r\n    print(f\"profile for {name}\")\r\n    print(s.getvalue())\r\n\r\n    return value\r\n\r\n\r\ndef taylor_expm(x, n):\r\n    x_0 = tf.eye(tf.shape(x)[0], dtype=x.dtype)\r\n    x_i = x\r\n    y = x_0 + x_i\r\n    for i in range(2, n + 1):\r\n        x_i = (x_i @ x) / tf.cast(i, x.dtype)\r\n        y = y + x_i\r\n    return y\r\n\r\n\r\nnp.random.seed(42)\r\n\r\nx = tf.constant(np.random.uniform(-0.5, 0.5, [MATRIX_DIM, MATRIX_DIM]), tf.float32)\r\n\r\nif tf.__version__.startswith(\"2\"):\r\n\r\n    @tf.function\r\n    def taylor_expm_v2(x, n):\r\n        return taylor_expm(x, n)\r\n\r\n    print(\"\\nBENCHMARKS:\")\r\n    tf_expm = benchmark(\"tf\", lambda: tf.linalg.expm(x))\r\n    my_expm = benchmark(\"taylor\", lambda: taylor_expm(x, TAYLOR_SUM))\r\n    my_expm_v2_b = benchmark(\"taylor_v2\", lambda: taylor_expm_v2(x, TAYLOR_SUM))\r\n\r\n    print(\"\\nPROFILES:\")\r\n    my_expm_v2_p = profile(\"taylor_v2\", lambda: taylor_expm_v2(x, TAYLOR_SUM))\r\n\r\n    np.testing.assert_allclose(tf_expm.numpy(), my_expm.numpy(), atol=EPS)\r\n    np.testing.assert_allclose(tf_expm.numpy(), my_expm_v2_b.numpy(), atol=EPS)\r\n    np.testing.assert_allclose(tf_expm.numpy(), my_expm_v2_p.numpy(), atol=EPS)\r\nelse:\r\n    tf_expm_ = tf.linalg.expm(x)\r\n    my_expm_ = taylor_expm(x, TAYLOR_SUM)\r\n\r\n    with tf.Session() as sess:\r\n        print(\"\\nBENCHMARKS:\")\r\n        tf_expm = benchmark(\"tf\", lambda: sess.run(tf_expm_))\r\n        my_expm = benchmark(\"taylor\", lambda: sess.run(my_expm_))\r\n\r\n    np.testing.assert_allclose(tf_expm, my_expm, atol=EPS)\r\n```\r\n", "comments": ["Ah!\r\n\r\nThis is the subtlest and most common trap when it comes to profiling tensorflow: if you use a tf.constant to represent a graph's inputs, by default TF will constant fold the entire graph out of existence.\r\n\r\nSo if you replace x = tf.constant with x = tf.placeholder and use a feed_dict you'll get something closer to the real performance numbers, and session.run is no faster than tf.function.", "@alextp that's amazing - thank you!"]}, {"number": 27142, "title": "AttributeError: 'LeakyReLU' object has no attribute '__name__' when running the train model.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\nDocker container from tensorflow:2.0.0a0-gpu-py3\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nI use leaky relu activation from advanced_activations module like this.\r\n` from tensorflow.python.keras.layers.advanced_activations import LeakyReLU `\r\n` x1 = Conv2D(filters=32, kernel_size=(8, 8), strides=(2, 2), activation=learky_relu)(inputs) `\r\n\r\nAnd error occurred as follow when run the train my model.\r\n```\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/activations.py\", line 206, in serialize\r\n    if activation.__name__ in _TF_ACTIVATIONS_V2:\r\nAttributeError: 'LeakyReLU' object has no attribute '__name__'\r\n```\r\n\r\nSo the leaky relu instance is sent to `activations.serialize` and called attribute '__name__' at https://github.com/tensorflow/tensorflow/blob/1e43727d9c4ef56c66af8c63ecca9d8465b786c7/tensorflow/python/keras/activations.py#L255.\r\nBut common python objects aren't have attribute '__name__' so this bug is occurred.\r\n\r\n** expected behavior **\r\nMy model should get 100% accuracy and my self-driving RC move as like human driving. \r\n\r\n\r\n\r\nI don't know why advanced_activation classes are implement the Layer. \r\nMaybe I think it better to make abstract class for advanced activation or make them independent function.\r\nI want it is fixed as soon as possible.\r\ngood luck.\r\n\r\nMore info.\r\nMy train code is as follow.\r\n```\r\n    def train(self, X, y, saved_model_path, batch_size=8, epochs=100,  train_split=0.8, verbose=1, min_delta=.0005, patience=5, use_early_stop=True):\r\n        \"\"\"\r\n        Args:\r\n            train: list of traininig data\r\n            validate: list of validation data\r\n            saved_model_path: saved previous model path\r\n        \"\"\"\r\n        \r\n        # checkpoint to save model after each epoch\r\n        save_best = ModelCheckpoint(saved_model_path,\r\n                                    monitor='val_loss',\r\n                                    verbose=verbose,\r\n                                    save_best_only=True,\r\n                                    mode='min')\r\n\r\n        # stop training if the validation error stops improving.\r\n        early_stop = EarlyStopping(monitor='val_loss',\r\n                                    min_delta=min_delta,\r\n                                    patience=patience,\r\n                                    verbose=verbose,\r\n                                    mode='auto')\r\n\r\n        callbacks_list = [save_best]\r\n        if use_early_stop:\r\n            callbacks_list.append(early_stop)\r\n\r\n        hist = self.model.fit(\r\n            X,\r\n            y,\r\n            batch_size=batch_size,\r\n            epochs=epochs,\r\n            verbose=1,\r\n            validation_split=0.2,\r\n            callbacks=callbacks_list,\r\n        )\r\n        return hist\r\n```\r\n\r\nSee My model code as follow.\r\n\r\n```\r\nfrom tensorflow.python.keras import Input\r\nfrom tensorflow.python.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\r\nfrom tensorflow.python.keras.layers.advanced_activations import LeakyReLU\r\nfrom tensorflow.python.keras.models import Model\r\nfrom tensorflow.python.keras.utils import plot_model\r\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStoppin\r\n\r\ndef linear():\r\n    learky_relu = LeakyReLU()\r\n    inputs = Input(shape=(391, 554, 3), name='inputs')\r\n    x1 = Conv2D(filters=32, kernel_size=(8, 8), strides=(2, 2), activation=learky_relu)(inputs)\r\n    x2 = MaxPool2D(pool_size=(4, 4), strides=2)(x1)\r\n    x3 = Conv2D(filters=32, kernel_size=(4, 4), strides=(3, 3), activation=learky_relu)(x2)\r\n    x4 = MaxPool2D(pool_size=(3, 3), strides=2)(x3)\r\n    x5 = Conv2D(filters=48, kernel_size=(4, 4), strides=(2, 2), activation=learky_relu)(x4)\r\n    x6 = MaxPool2D(pool_size=(2, 2), strides=2)(x5)\r\n    x7 = Flatten(name='flattened')(x6)\r\n    d1 = Dense(units=100, activation='linear')(x7)\r\n    d2 = Dense(units=50, activation='linear')(d1)\r\n    handling = Dense(units=1, activation='linear', name='handling')(d2)\r\n    model = Model(inputs=[inputs], outputs=handling)\r\n    model.compile(optimizer='adam', loss={'handling': 'mean_squared_error'} , loss_weights={'handling': 0.5 })\r\n    return model\r\n\r\n```\r\n\r\n", "comments": ["AFAIK LeakyRelu (advanced activation) should be used as a layer instead of an activation argument.\r\nSo something like this should pass,\r\n```python\r\nfrom keras import Sequential\r\nfrom keras.layers import Conv2D, LeakyReLU\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='linear',input_shape=(30, 30, 1)))\r\nmodel.add(LeakyReLU(alpha=0.01))\r\n```", "Thanks. I try it. \r\n\r\nMaybe I had misunderstanding about how to use advanced activations.\r\n\r\nI saw several blogs about general usage of keras and they write that advance activations is able to use for activations argument.", "The keras documentation is not clear about the usage of advanced activation's. Using LeakyRelu as layer makes sense since its imported as any other keras layer. I will close this issue now that we have a workaround. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27142\">No</a>\n", "leakyrelu_alpha = 0.2    \r\n\r\ngen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\r\ngen5 = LeakyReLU(alpha=leakyrelu_alpha)(gen5)#Activation('relu')'or #LeakyReLU(alpha=0.3)\r\n\r\nuse this, it will solve your problem", "> AFAIK LeakyRelu (advanced activation) should be used as a layer instead of an activation argument.\r\n> So something like this should pass,\r\n> \r\n> ```python\r\n> from keras import Sequential\r\n> from keras.layers import Conv2D, LeakyReLU\r\n> model = Sequential()\r\n> model.add(Conv2D(32, kernel_size=(3, 3), activation='linear',input_shape=(30, 30, 1)))\r\n> model.add(LeakyReLU(alpha=0.01))\r\n> ```\r\n\r\n\r\nDoes this have the same effect as the original activation?"]}, {"number": 27141, "title": "Tensorflow 2.0 failed to get convolution algorithm", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 29\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0.0-alpha\r\n- Python version: 3.6.6\r\n- Installed using virtualenv? pip? conda?: virtualenv and pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA-10.0, cuDNN 7.4.2 and 7.5.0\r\n- GPU model and memory: RTX 2080, 8 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nInstalled tensorflow 2.0 using pip in a virtualenv. Trying to train a model gives the following error message(tried both cuDNN 7.4 and 7.5)\r\n\r\n2019-03-26 14:44:26.468142: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-03-26 14:44:26.471383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-03-26 14:44:26.580198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-26 14:44:26.580761: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x1e8c600 executing computations on platform CUDA. Devices:\r\n2019-03-26 14:44:26.580775: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5\r\n2019-03-26 14:44:26.593170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\r\n2019-03-26 14:44:26.593891: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x1ee6d40 executing computations on platform Host. Devices:\r\n2019-03-26 14:44:26.593903: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-26 14:44:26.594049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: \r\nname: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.8\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.76GiB freeMemory: 7.21GiB\r\n2019-03-26 14:44:26.594061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0\r\n2019-03-26 14:44:26.594091: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-03-26 14:44:26.594521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-26 14:44:26.594530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 \r\n2019-03-26 14:44:26.594534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N \r\n2019-03-26 14:44:26.594620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7014 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2019-03-26 14:44:26.890272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-03-26 14:44:27.510334: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2019-03-26 14:44:27.514389: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 660, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 196, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1078, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 634, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 233, in __call__\r\n    name=self.name)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1951, in conv2d\r\n    name=name)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1031, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1130, in conv2d_eager_fallback\r\n    ctx=_ctx, name=name)\r\n  File \"/home/atom/PythonEnvs/Tensorflow_2_alpha/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]  \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nMinimal code snippet which raises the error:\r\n    tf.keras.layers.Conv2D(3,3,1)(tf.ones((1,5,5,3)))\r\n\r\n", "comments": ["@Atom-101 I think root-cause of the error (\"CUDNN_STATUS_INTERNAL_ERROR\") is due to problem in initializing CUDNN. Could you run the same code on a cpu based virtual env and see whether the bug persists? There is solution to similar issue by another user [here](https://github.com/tensorflow/tensorflow/issues/14048). Please follow those instructions and let us know how it progresses. Thanks!", "The problem does not occur when using CPU. \nI checked out the issue you referenced. I'm not really having a problem related to paths(I can import tensorflow just fine). As for running python as root, as suggested by one user, I haven't tried it yet. Although, I never needed to run python as root for tensorflow-gpu 1.12 or lower, so I'm not really hopeful about it.", "@Atom-101 did you install tf_gpu version in V env or tf_cpu version? Could you share a code to reproduce the bug? The one line code was working well for me. Thanks!", "I installed tf_gpu version in a virtual environment. Not a VM. Tf_gpu gives the aforementioned issue. Right now I have installed tf_cpu. Tf_cpu works without issues. \nAs for code to reproduce the bug, any simple snippet that runs a convolution on any matrix will give the error. If you can run my snippet without issues, your cuDNN is working correctly, I guess.", "@Atom-101 Yes. In order to run tf_gpu in vitrual env, you need to install NVIDIA driver, CUDA and cuDNN. I can run any convolution code without any issue. Please check other issues here in GitHub and Stackoverflow to install CUDA and cuDNN correctly. Please close the issue. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27141\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27141\">No</a>\n", "This problem may cause with tensorflow's docker (2.1.0-gpu-py3) in the below host\r\n\r\n- OS: 5.5.2-1-MANJARO\r\n- Cuda: 10.1\r\n- cuddn: 7.6.5\r\n- docker-compose version 1.25.4\r\n- docker-version: 19.03.5-ce, build 633a0ea838\r\n\r\nTensorflow is affected by HOST OS?", "For those who are facing issues regarding the above error, I sorted it just by installing CuDNN version compatible with the CUDA already installed in the system.\r\n\r\n1. - This suitable version can be downloaded from the website 'https://developer.nvidia.com/rdp/cudnn-archive'. You might need Nvidia account for it. This will be easily created by providing mail id and filling a questionnaire.\r\n2. - To check the CUDA version, run `NVCC --version`.\r\n3. - Once the suitable version is downloaded, extract the folder from the zip file. \r\n4. - Go to the bin folder of the extracted folder. copy the `cudnn64:7.dll` and paste it in the CUDA's bin folder. In my case, the location where Cuda is installed is `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin`.\r\n5. - This would most probably solve the problem.\r\n\r\nMy system details:\r\n\r\n1. Windows 10\r\n2. CUDA 10.0\r\n3. TensorFlow 2.0\r\n4. GPU- Nvidia GTX 1060"]}, {"number": 27140, "title": "Added Median filtering 2D ( Updated over Suggestion from pull request\u2026#26741)", "body": "( Updated over Suggestion from pull request\u2026 #26741)\r\n\r\nTest code -\r\n\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.util.tf_export import tf_export\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import image_ops_impl\r\nfrom tensorflow.python.ops import script_ops\r\n\r\nfname = 'index3.jpeg'\r\nimg = matplotlib.pyplot.imread(fname)\r\nimport numpy as np\r\n\r\ntf_img = tf.convert_to_tensor(img)\r\n\r\n\r\n@tf_export('image.median_filter_2D')\r\ndef median_filter_2D(input,filter_shape=(3,3)):\r\n    \"\"\"  This methods takes 3D Tensor Images.\r\n         Other than Tensor it takes optional parameter filter_Size\r\n         Default Filter Shape = (3 , 3)\r\n         This Median Filtering is done by using 2D filters of user's choice\r\n         Filter_size should be odd\r\n         This method takes both kind of images where pixel values lie between 0 to 255 and where it lies between 0.0 and 1.0\r\n    \"\"\"\r\n\r\n    input = image_ops_impl._Assert3DImage(input)\r\n    m,no,ch = int(input.shape[0]),int(input.shape[1]),int(input.shape[2])\r\n    filter_shapex = filter_shape[0]\r\n    filter_shapey = filter_shape[1]\r\n    if m < filter_shapex or no < filter_shapey:\r\n        raise ValueError(\"No of Pixels in each dimension of the image should be more than the filter size. Got filter_shape \"\r\n                         \"(%sx\" % filter_shape[0]+\"%s).\"%filter_shape[1] +\" Image Shape (%s)\"% input.shape)\r\n    if filter_shapex % 2 == 0 or filter_shapey % 2 == 0:\r\n        raise ValueError(\"Filter size should be odd. Got filter_shape (%sx\" % filter_shape[0]+\"%s)\"%filter_shape[1] )\r\n    input = math_ops.cast(input,dtypes.float64)\r\n    def my_func (input2):\r\n        tf_i = input2.reshape(m*no*ch)\r\n        maxi = max(tf_i)\r\n        if maxi == 1:\r\n            input2 /= maxi\r\n        else :\r\n            input2 /= 255\r\n        #k and l is the Zero-padding size\r\n        res = np.empty((m,no,ch))\r\n        for a in range(ch):\r\n            img = input2[:,:,a:a+1]\r\n            img = img.reshape(m,no)\r\n            k = filter_shapex - 1\r\n            l = filter_shapey - 1\r\n            img  = np.pad(img,((k / 2, k / 2), (l / 2,l / 2)),'constant', constant_values=(0, 0))\r\n            res1 = np.empty((m,no))\r\n            for i in range(img.shape[0] - k) :\r\n                for j in range(img.shape[1] - l) :\r\n                    li = []\r\n                    for b in range(i, i + filter_shapex):\r\n                        for d in range(j, j + filter_shapey):\r\n                            li.append(img[b][d])\r\n                    li.sort()\r\n                    res1[i][j] = li[len(li) / 2]\r\n            res1 = res1.reshape(m,no,1)\r\n            res[:,:,a:a+1] = res1\r\n        res *= 255\r\n        res = res.astype('int64')\r\n        return res\r\n\r\n    y = script_ops.py_func(my_func, [input], dtypes.int64)\r\n    return y\r\n\r\nsess = tf.InteractiveSession()\r\n\r\nmimage = median_filter_2D(tf_img,(5,5))\r\n\r\nfig = plt.figure()\r\nfig.add_subplot()\r\nplt.imshow(img,cmap='gray')\r\nplt.show()\r\nmimage = mimage.eval()\r\nfig.add_subplot()\r\nif mimage.shape[2] == 1:\r\n    mimage = mimage.reshape(mimage.shape[0],mimage.shape[1])\r\nplt.imshow(mimage,cmap = 'gray')\r\nplt.show()", "comments": ["I am planning to extend this feature for the batch of images in future. I have seen many tf.image operator works on single image. So,i have devised this operation for single image. ", "I still would like to see a unit test for this.\r\n\r\n@seanpmorgan I think this contribution will belong in tensorflow/addons once we've finalized the code review, in tfa.image. WDYT?", "Agree that it fits tfa.image. Unit tests are essential though so we know if it breaks going forward. Also, per the new [RFC](https://github.com/tensorflow/community/pull/84) we are looking for maintainers of tfa.image", "Please add a unit test, make sure it passes, and then submit this as a pr to tensorflow/addons.\r\n\r\nI think overall the structure of the code is good. Also please address the linter issues.", "How to add a unit test?  Like a test code?  And what are the linter\nissues.\n\nOn Thu 28 Mar, 2019, 12:59 AM Alexandre Passos, <notifications@github.com>\nwrote:\n\n> Please add a unit test, make sure it passes, and then submit this as a pr\n> to tensorflow/addons.\n>\n> I think overall the structure of the code is good. Also please address the\n> linter issues.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27140#issuecomment-477313104>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AiI2QtQfUlkekqB0s_hRsUaMnvKqVze_ks5va8aBgaJpZM4cK9F0>\n> .\n>\n", "Yes, unit tests are test code. There are files with _test.py, in this case\nyou probably want tensorflow/python/kernel_tests/image_ops_test.py\n\nOn Wed, Mar 27, 2019 at 12:35 PM Mainak Dutta <notifications@github.com>\nwrote:\n\n> How to add a unit test? Like a test code? And what are the linter\n> issues.\n>\n> On Thu 28 Mar, 2019, 12:59 AM Alexandre Passos, <notifications@github.com>\n> wrote:\n>\n> > Please add a unit test, make sure it passes, and then submit this as a pr\n> > to tensorflow/addons.\n> >\n> > I think overall the structure of the code is good. Also please address\n> the\n> > linter issues.\n> >\n> > \u2014\n> > You are receiving this because you authored the thread.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/tensorflow/tensorflow/pull/27140#issuecomment-477313104\n> >,\n> > or mute the thread\n> > <\n> https://github.com/notifications/unsubscribe-auth/AiI2QtQfUlkekqB0s_hRsUaMnvKqVze_ks5va8aBgaJpZM4cK9F0\n> >\n> > .\n> >\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27140#issuecomment-477315738>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxZnwqLeuaZA6qAuJjRvHbvBe7d_Iks5va8fxgaJpZM4cK9F0>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Unit tests are added. ", "@alextp In which file of addon package should i put the code? And what should be the location of the test file?", "@Mainak431 It should be placed in tfa.image and the test can live alongside of it in that directory:\r\nhttps://github.com/tensorflow/addons/tree/master/tensorflow_addons/image\r\n\r\nWe'll be happy to help with integrating in our package once the PR is open.", "@seanpmorgan  Created PR at https://github.com/tensorflow/addons/pull/111/", "@alextp I have also developed code for Median_filter_1D , Average_filter_1D and Average_filter_2D . Will they all belong to tensorflow addons package?", "Yes\n\nOn Fri, Mar 29, 2019 at 9:18 AM Mainak Dutta <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp> I have also developed code for\n> Median_filter_1D , Average_filter_1D and Average_filter_2D . Will they all\n> belong to tensorflow addons package?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/27140#issuecomment-478057507>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxXV8buPiMK9Gjx_ULweFghqKyCVXks5vbjzjgaJpZM4cK9F0>\n> .\n>\n\n\n-- \n - Alex\n", "Integrated @ tensorflow addons.  "]}, {"number": 27139, "title": "save_weights/load_weights with custom layer does not work in tensorflow 1.13.1, but work in tf 2.0.0a0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but very basic\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary (conda)\r\n- TensorFlow version (use command below): 1.13.1 and 2.0.0a0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nIn summary, I created a custom model in Model Subclassing style, which contained only 1 custom layer. After initial, I dumped its trainable weights to file and then restored it, by using save_weights and load_weights functions. The trainable weights before and after saving were different.\r\n\r\nI also ran the same test on Tensorflow 2.0.0a0, and it turned out the latter version did not get this phenomenon. \r\n**Describe the expected behavior**\r\nThe trainable weights before and after saving should be the same, as they are in TF 2.0.0a0.\r\n\r\n**Code to reproduce the issue**\r\nMy custom layer:\r\n```\r\nclass EncodingLayer(tf.keras.layers.Layer):\r\n    def __init__(self, out_size):\r\n        super().__init__()\r\n        self.rnn_layer = tf.keras.layers.GRU(out_size, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\r\n\r\n    def call(self, X, **kwargs):\r\n        output, state = self.rnn_layer(X)\r\n        return output, state\r\n```\r\nThe main part:\r\n```\r\nclass EncodingModel(tf.keras.Model):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.encoder_layer = EncodingLayer(out_size=1)\r\n\r\n    def infer(self, inputs):\r\n        output, state = self.encoder_layer(inputs)\r\n        return output\r\n\r\n\r\nif __name__ == '__main__':\r\n    # Comment line below for running in TF 2.0\r\n    tf.enable_eager_execution()\r\n\r\n    # shape == (2, 3, 2)\r\n    inputs = tf.convert_to_tensor([\r\n        [[1., 2.], [2., 3.], [4., 4.]],\r\n        [[1., 2.], [2., 3.], [4., 4.]],\r\n    ])\r\n\r\n    model = EncodingModel()\r\n\r\n    # Just for building the graph\r\n    model.infer(inputs)\r\n\r\n    print('Before saving model: ', model.trainable_weights[0].numpy().mean())\r\n    model.save_weights('weight')\r\n\r\n    new_model = EncodingModel()\r\n    new_model.infer(inputs)\r\n    new_model.load_weights('weight')\r\n    print('Loaded model: ', new_model.trainable_weights[0].numpy().mean())\r\n```\r\n\r\n**Other info / logs**\r\nThe result when running in TF 1.13.1:\r\n```\r\nBefore saving model:  0.28864467\r\nLoaded model:  0.117300846\r\n```\r\nThe result when running in TF 2.0.0a0:\r\n```\r\nBefore saving model:  -0.06922924\r\nLoaded model:  -0.06922924\r\n```", "comments": ["Yep, we recently enabled sub-Layer tracking for Layer, as Network/Model has been doing for a while. 1.14 when it comes out will have Layer doing this tracking as well. In the meantime you may need to use tf.keras.Model rather than Layer if you're composing other Layers."]}, {"number": 27138, "title": "Add sigma, k1, k2, etc. as default parameters to tf.image.ssim_multiscale", "body": "I previously requested a feature on tf.image.ssim for window size and sigma on this link. https://github.com/tensorflow/tensorflow/issues/26929 \r\nPlease read it for additional information.\r\n\r\nI would like to request for variables of multiscale ssim (such as sigma, k1, k2, etc.) to be listed as defaults (instead of being fixed inside the script) as well.\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.13\r\n- Are you willing to contribute it (Yes/No): No. Sorry, I am not qualified to alter the code.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, key parameters such as the sigma value are fixed when Tensorflow runs tf.image.ssim_multiscale. \r\n\r\nIt would be great if all the variables mentioned in the original paper proposing MS-SSIM could be altered by the user.\r\n(See Z. Wang, E. P. Simoncelli and A. C. Bovik, \u201cMulti-scale structural similarity for image quality assessment,\u201d IEEE Asilomar Conference Signals, Systems and Computers, Nov. 2003.)\r\n\r\nThis is especially important for those who wish to use MS-SSIM as a loss function as those variables have a significant influence on the character of the outputs.\r\n\r\n**Will this change the current api? How?**\r\nThere will be almost no change. If the parameters which are currently fixed are set as default values, most people will never notice the difference.\r\n\r\n**Who will benefit with this feature?**\r\nThose who wish to use MS-SSIM as a loss function or wish to fine tune it on a deep learning model.\r\n\r\n**Any Other info.**\r\nI do not understand all of the features of MS-SSIM perfectly. I understand that a minimum window size of 176x176 is fixed and that K1 and K2 parameters are usually not altered. Perhaps these values should be set as keyword arguments (**kwargs) to hide unnecessary complexity.\r\n", "comments": ["On second thoughts, I don't think that this is necessary for MS-SSIM as much as it is for SSIM.\r\nClosing issue.", "Also, I found that everything was already going on without a separate issue."]}, {"number": 27137, "title": "Update lite.py", "body": "If the model has it own loss function, the processing of the transforming will failed. So I set the compile=False when transform tf.keras model to tflite.\r\n\r\n@wangtz ", "comments": ["This PR changes the behavior of the converter for every user. If you want to use a model with this flag, please load your model into a Keras Session and use `TFLiteConverter.from_session` instead of using `TFLiteConverter.from_keras_model_file`."]}, {"number": 27136, "title": "Update lite.py", "body": "If the model has it own loss function, the processing of the transforming will failed. So I set the compile=False when transform tf.keras model to tflite.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27136) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 27135, "title": "TFLite got same result whatever feed any image", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 1+6T\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1050 Ti\r\n\r\n\r\n**Describe the current behavior**\r\nI used tf.keras built a FaceNet model and try to deploy it in Android TFLite, the processing of the transforming(from tf.keras to tflite) was smoothed, but when I try to deploy it in Android TFLite, whatever I feed any image, the Interpreter always send me the same result\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\n``` java\r\npackage org.blackwalnutlabs.angel.tensorflowmobile.model;\r\n\r\nimport android.app.Activity;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.graphics.Bitmap;\r\nimport android.util.Log;\r\n\r\nimport org.opencv.android.Utils;\r\nimport org.opencv.core.Mat;\r\nimport org.tensorflow.lite.Delegate;\r\nimport org.tensorflow.lite.Interpreter;\r\n\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.ByteOrder;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport java.util.Map;\r\n\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.DIM_BATCH_SIZE;\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.DIM_IMG_SIZE_X;\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.DIM_IMG_SIZE_Y;\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.DIM_PIXEL_SIZE;\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.IMAGE_STD;\r\nimport static org.blackwalnutlabs.angel.tensorflowmobile.setting.ModelSetting.MODELFILE;\r\n\r\npublic class TensorFlowLiteDetector {\r\n    private static final String TAG = \"Detector\";\r\n\r\n    // \u5b58\u50a8\u56fe\u50cf RGB \u503c\r\n    private int[] intValues = new int[DIM_IMG_SIZE_X * DIM_IMG_SIZE_Y];\r\n    // TFLite \u6267\u884c\u7c7b\r\n    private Interpreter tfLite;\r\n    // \u5b58\u50a8\u56fe\u50cf\u4f4d\u6570\u636e\r\n    private ByteBuffer imgData;\r\n    // \u5b58\u50a8\u9884\u6d4b\u7ed3\u679c\r\n    private float[][] embeddingArray;\r\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n\r\n    private Delegate gpuDelegate = null;\r\n    private MappedByteBuffer modelFile = null;\r\n\r\n\r\n    // \u521d\u59cb\u5316 TFLite\r\n    public TensorFlowLiteDetector(Map<String, Object> othersMap) {\r\n        try {\r\n            Activity activity = (Activity) othersMap.get(\"activity\");\r\n            modelFile = loadModelFile(activity);\r\n            tfLite = new Interpreter(modelFile, tfliteOptions);\r\n            useCPU();\r\n            imgData = ByteBuffer.allocateDirect(\r\n                    DIM_BATCH_SIZE * DIM_IMG_SIZE_X * DIM_IMG_SIZE_Y * DIM_PIXEL_SIZE * 4);\r\n            imgData.order(ByteOrder.nativeOrder());\r\n            embeddingArray = new float[1][128];\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\n    // \u8bfb\u53d6\u6a21\u578b\u6587\u4ef6\r\n    private MappedByteBuffer loadModelFile(Activity activity) throws IOException {\r\n        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODELFILE);\r\n        FileInputStream inputStream = new FileInputStream(\r\n                fileDescriptor.getFileDescriptor()\r\n        );\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n    }\r\n\r\n    // \u683c\u5f0f\u5316\u4f20\u5165\u56fe\u50cf\u50cf\u7d20\u503c\r\n    private void convertBitmapToByteBuffer(Bitmap bitmap) {\r\n        if (imgData == null) {\r\n            return;\r\n        }\r\n        imgData.rewind();\r\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(),\r\n                0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n\r\n        int pixel = 0;\r\n        for (int i = 0; i < DIM_IMG_SIZE_X; ++i) {\r\n            for (int j = 0; j < DIM_IMG_SIZE_Y; ++j) {\r\n                final int val = intValues[pixel++];\r\n                imgData.putFloat(((val >> 16) & 0xFF) / IMAGE_STD);\r\n                imgData.putFloat(((val >> 8) & 0xFF) / IMAGE_STD);\r\n                imgData.putFloat(((val) & 0xFF) / IMAGE_STD);\r\n            }\r\n        }\r\n    }\r\n\r\n    // \u6267\u884c\u9884\u6d4b\r\n    public float[][] detectImage(Mat src) {\r\n        if (tfLite != null) {\r\n            Bitmap bmp = Bitmap.createBitmap(src.width(), src.height(),\r\n                    Bitmap.Config.ARGB_8888);\r\n            Utils.matToBitmap(src, bmp);\r\n            convertBitmapToByteBuffer(bmp);\r\n\r\n            tfLite.resizeInput(0, new int[]{1, 96, 96, 3});\r\n            tfLite.run(imgData, embeddingArray);\r\n\r\n            return embeddingArray;\r\n        }\r\n        return null;\r\n    }\r\n\r\n    /**\r\n     * Enables use of the GPU for inference, if available.\r\n     */\r\n    private void useGpu() {\r\n        Log.e(TAG, \"\" + GpuDelegateHelper.isGpuDelegateAvailable());\r\n        if (gpuDelegate == null && GpuDelegateHelper.isGpuDelegateAvailable()) {\r\n            gpuDelegate = GpuDelegateHelper.createGpuDelegate();\r\n            tfliteOptions.addDelegate(gpuDelegate);\r\n            recreateInterpreter();\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Enables use of the CPU for inference.\r\n     */\r\n    private void useCPU() {\r\n        tfliteOptions.setUseNNAPI(false);\r\n        recreateInterpreter();\r\n    }\r\n\r\n    /**\r\n     * Enables use of NNAPI for inference, if available.\r\n     */\r\n    private void useNNAPI() {\r\n        tfliteOptions.setUseNNAPI(true);\r\n        recreateInterpreter();\r\n    }\r\n\r\n    /**\r\n     * Adjusts the number of threads used in CPU inference.\r\n     */\r\n    private void setNumThreads(int numThreads) {\r\n        tfliteOptions.setNumThreads(numThreads);\r\n        recreateInterpreter();\r\n    }\r\n\r\n    private void recreateInterpreter() {\r\n        if (tfLite != null) {\r\n            tfLite.close();\r\n            // TODO(b/120679982)\r\n            // gpuDelegate.close();\r\n            tfLite = new Interpreter(modelFile, tfliteOptions);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Closes the interpreter and model to release resources.\r\n     */\r\n    private void close() {\r\n        if (tfLite != null) {\r\n            tfLite.close();\r\n            tfLite = null;\r\n        }\r\n        modelFile = null;\r\n    }\r\n}\r\n\r\n```\r\n\r\n[converted_model.zip](https://github.com/tensorflow/tensorflow/files/3006839/converted_model.zip)\r\n\r\n```\r\n2019-03-26 15:01:46.346 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: --------------\r\n2019-03-26 15:01:46.347 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: [[0.13254969, 0.06506284, -0.12454985, -0.033946857, 0.13087335, 0.24849732, 0.13556245, -0.04702322, -0.1379856, -0.007572789, 0.019669764, 0.012697782, 0.13016781, -0.08282088, 0.07000842, -0.13634653, -0.033497285, 0.06713182, -0.056609895, 0.13066444, 0.031595007, 0.010904907, 0.06502004, 0.055475105, -0.042641174, -0.11620673, -0.13694304, -0.1973542, 0.023469506, 0.105563894, -0.018650757, 0.03307536, -0.098828435, 0.08058539, 0.08887855, 0.0022337863, 0.0055133225, 0.05411017, -0.044450507, -0.082797125, 0.07151169, -0.068259895, -0.09238541, 0.051023263, -0.26672673, 0.062153224, 0.089065045, 0.1272812, -0.15051614, 0.093154915, -0.04973236, -0.055004556, 0.028005369, 9.352369E-4, 0.021919679, -0.019822104, -0.02774606, 0.12849025, -0.051899977, -0.08593918, -0.08694194, 0.10073202, 0.20436272, -0.19222663, 0.084071614, -0.011063285, 0.037152126, 0.03323839, -0.13506632, -0.026216896, 0.012508951, 0.06862544, -0.023205, 0.013072543, -0.031873662, 0.025892422, -0.061958347, -0.06703131, 0.10233366, 0.06788932, -0.02056665, 0.0018195248, -0.07498662, -0.05542643, -0.01115404, 0.009607625, 0.029644933, -0.020729594, 0.0023015668, 0.09378674, 0.18983097, -0.11676965, -0.01661709, -0.019705301, -0.11590064, -0.13303259, 0.0070525194, 0.056587018, 0.02837071, -0.045306873, 0.105889864, 0.0897621, 0.0022198055, 0.043863844, -0.16235375, 0.06855683, -0.04233673, 0.10779853, -0.019658986, 0.096174344, 0.14861028, 0.09041121, -0.03691038, -0.040842745, -0.044187892, 0.06624289, -0.13923372, -0.038001977, -0.018037193, 0.114912674, -7.4458803E-4, -0.122649185, -0.010618781, 0.11189667, -0.03145326, 0.036915697, -0.0388509, -0.096018195]]\r\n2019-03-26 15:01:46.347 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: [[0.13254969, 0.06506284, -0.12454985, -0.033946857, 0.13087335, 0.24849732, 0.13556245, -0.04702322, -0.1379856, -0.007572789, 0.019669764, 0.012697782, 0.13016781, -0.08282088, 0.07000842, -0.13634653, -0.033497285, 0.06713182, -0.056609895, 0.13066444, 0.031595007, 0.010904907, 0.06502004, 0.055475105, -0.042641174, -0.11620673, -0.13694304, -0.1973542, 0.023469506, 0.105563894, -0.018650757, 0.03307536, -0.098828435, 0.08058539, 0.08887855, 0.0022337863, 0.0055133225, 0.05411017, -0.044450507, -0.082797125, 0.07151169, -0.068259895, -0.09238541, 0.051023263, -0.26672673, 0.062153224, 0.089065045, 0.1272812, -0.15051614, 0.093154915, -0.04973236, -0.055004556, 0.028005369, 9.352369E-4, 0.021919679, -0.019822104, -0.02774606, 0.12849025, -0.051899977, -0.08593918, -0.08694194, 0.10073202, 0.20436272, -0.19222663, 0.084071614, -0.011063285, 0.037152126, 0.03323839, -0.13506632, -0.026216896, 0.012508951, 0.06862544, -0.023205, 0.013072543, -0.031873662, 0.025892422, -0.061958347, -0.06703131, 0.10233366, 0.06788932, -0.02056665, 0.0018195248, -0.07498662, -0.05542643, -0.01115404, 0.009607625, 0.029644933, -0.020729594, 0.0023015668, 0.09378674, 0.18983097, -0.11676965, -0.01661709, -0.019705301, -0.11590064, -0.13303259, 0.0070525194, 0.056587018, 0.02837071, -0.045306873, 0.105889864, 0.0897621, 0.0022198055, 0.043863844, -0.16235375, 0.06855683, -0.04233673, 0.10779853, -0.019658986, 0.096174344, 0.14861028, 0.09041121, -0.03691038, -0.040842745, -0.044187892, 0.06624289, -0.13923372, -0.038001977, -0.018037193, 0.114912674, -7.4458803E-4, -0.122649185, -0.010618781, 0.11189667, -0.03145326, 0.036915697, -0.0388509, -0.096018195]]\r\n2019-03-26 15:01:46.347 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: --------------\r\n2019-03-26 15:01:46.464 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: --------------\r\n2019-03-26 15:01:46.464 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: [[0.13254969, 0.06506284, -0.12454985, -0.033946857, 0.13087335, 0.24849732, 0.13556245, -0.04702322, -0.1379856, -0.007572789, 0.019669764, 0.012697782, 0.13016781, -0.08282088, 0.07000842, -0.13634653, -0.033497285, 0.06713182, -0.056609895, 0.13066444, 0.031595007, 0.010904907, 0.06502004, 0.055475105, -0.042641174, -0.11620673, -0.13694304, -0.1973542, 0.023469506, 0.105563894, -0.018650757, 0.03307536, -0.098828435, 0.08058539, 0.08887855, 0.0022337863, 0.0055133225, 0.05411017, -0.044450507, -0.082797125, 0.07151169, -0.068259895, -0.09238541, 0.051023263, -0.26672673, 0.062153224, 0.089065045, 0.1272812, -0.15051614, 0.093154915, -0.04973236, -0.055004556, 0.028005369, 9.352369E-4, 0.021919679, -0.019822104, -0.02774606, 0.12849025, -0.051899977, -0.08593918, -0.08694194, 0.10073202, 0.20436272, -0.19222663, 0.084071614, -0.011063285, 0.037152126, 0.03323839, -0.13506632, -0.026216896, 0.012508951, 0.06862544, -0.023205, 0.013072543, -0.031873662, 0.025892422, -0.061958347, -0.06703131, 0.10233366, 0.06788932, -0.02056665, 0.0018195248, -0.07498662, -0.05542643, -0.01115404, 0.009607625, 0.029644933, -0.020729594, 0.0023015668, 0.09378674, 0.18983097, -0.11676965, -0.01661709, -0.019705301, -0.11590064, -0.13303259, 0.0070525194, 0.056587018, 0.02837071, -0.045306873, 0.105889864, 0.0897621, 0.0022198055, 0.043863844, -0.16235375, 0.06855683, -0.04233673, 0.10779853, -0.019658986, 0.096174344, 0.14861028, 0.09041121, -0.03691038, -0.040842745, -0.044187892, 0.06624289, -0.13923372, -0.038001977, -0.018037193, 0.114912674, -7.4458803E-4, -0.122649185, -0.010618781, 0.11189667, -0.03145326, 0.036915697, -0.0388509, -0.096018195]]\r\n2019-03-26 15:01:46.465 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: [[0.13254969, 0.06506284, -0.12454985, -0.033946857, 0.13087335, 0.24849732, 0.13556245, -0.04702322, -0.1379856, -0.007572789, 0.019669764, 0.012697782, 0.13016781, -0.08282088, 0.07000842, -0.13634653, -0.033497285, 0.06713182, -0.056609895, 0.13066444, 0.031595007, 0.010904907, 0.06502004, 0.055475105, -0.042641174, -0.11620673, -0.13694304, -0.1973542, 0.023469506, 0.105563894, -0.018650757, 0.03307536, -0.098828435, 0.08058539, 0.08887855, 0.0022337863, 0.0055133225, 0.05411017, -0.044450507, -0.082797125, 0.07151169, -0.068259895, -0.09238541, 0.051023263, -0.26672673, 0.062153224, 0.089065045, 0.1272812, -0.15051614, 0.093154915, -0.04973236, -0.055004556, 0.028005369, 9.352369E-4, 0.021919679, -0.019822104, -0.02774606, 0.12849025, -0.051899977, -0.08593918, -0.08694194, 0.10073202, 0.20436272, -0.19222663, 0.084071614, -0.011063285, 0.037152126, 0.03323839, -0.13506632, -0.026216896, 0.012508951, 0.06862544, -0.023205, 0.013072543, -0.031873662, 0.025892422, -0.061958347, -0.06703131, 0.10233366, 0.06788932, -0.02056665, 0.0018195248, -0.07498662, -0.05542643, -0.01115404, 0.009607625, 0.029644933, -0.020729594, 0.0023015668, 0.09378674, 0.18983097, -0.11676965, -0.01661709, -0.019705301, -0.11590064, -0.13303259, 0.0070525194, 0.056587018, 0.02837071, -0.045306873, 0.105889864, 0.0897621, 0.0022198055, 0.043863844, -0.16235375, 0.06855683, -0.04233673, 0.10779853, -0.019658986, 0.096174344, 0.14861028, 0.09041121, -0.03691038, -0.040842745, -0.044187892, 0.06624289, -0.13923372, -0.038001977, -0.018037193, 0.114912674, -7.4458803E-4, -0.122649185, -0.010618781, 0.11189667, -0.03145326, 0.036915697, -0.0388509, -0.096018195]]\r\n2019-03-26 15:01:46.465 11635-11823/org.blackwalnutlabs.angel.facedetection E/MainActivity: --------------\r\n```\r\n\r\n\r\n**Other info / logs**\r\nThe FaceNet has it own loss function, so I set compile=False in the tflite conventor source code.\r\n\r\n@wangtz ", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "> This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n> \r\n> If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n\r\nok, I will reasked it on StackOverflow, thank you."]}, {"number": 27134, "title": "Synced the implementation of QuantizationParams.", "body": "This is one of the TODO in the file.", "comments": ["@suharshs , thanks for the review, I agree with you but the problem is that both the function differ internally and to even sync them might trigger another level of big changes and testing, so i thought of syncing the function itself, kindly check and let me know if i can do any other better way.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78 can you please check failed build errors", "@gbaned , thanks for the update, i checked all the errors but none of them are related to tflite module, where my changes are there. On top of it i again ran all the sanity checks and it passed without any issue.\r\nCan you please let me know if you are talking about anything specific.\r\n\r\nRegards\r\nAmit", "@gbaned , can you please help to get this PR merged, this is already approved."]}, {"number": 27133, "title": "Fix segmentation fault with tf.stack an keras Input in TF2.0", "body": "This fix tries to address the issue raised in #26879 where tf.stack encounters segmantation fault with keras's Input in TF2.0:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input\r\n\r\nprint(tf.__version__)\r\n\r\ninput_ = Input((128, 128, 1), dtype='float32')\r\nprint(input_)\r\noutput = tf.stack(input_, axis=1)\r\n```\r\n\r\nThe issue is that in eager wrap, `PySequence_Fast_GET_ITEM` tries to access an object not through `PySequence_Fast`.\r\n\r\nThis fix adds the `PySequence_Fast` and checks the return value to make sure it is not nullptr.\r\n\r\nThis fix fixes #26879.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 27132, "title": "missing 2.0.0 alpha custom estimator guide", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha.0\r\n- Doc Link: https://www.tensorflow.org/alpha/guide/keras/estimators\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\nIt's confusing since abundant guide stuff were uploaded, since no guide for custom estimator, just an example of using boostedClassifier\r\n\r\nIs tf.keras.Model replacing tf.estimator?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["It is available here: https://www.tensorflow.org/alpha/guide/migration_guide#using_a_custom_model_fn", "@Nimishkhurana \r\nThanks a lot, it seems like estimator is deprecated since that document shows lots of \"compat.v1\"", "Estimators are supported in 2.0 however the custom estimators will run in TF 1.X style in 2.0"]}, {"number": 27131, "title": "Refactored and referenced optimized implmentation.", "body": "For Relu1 and Relu removed local implmentation.", "comments": ["@renjie-liu , thanks for pointing this out, i have updated the code as per the comments, Kindly check and approve.\r\n\r\nRegards\r\nAmit", "@renjie-liu , thanks for the review, really appreciate your efforts in making the code better.\r\n\r\nRegards\r\nAmit", "@jdduke , thanks for the review, i have updated the code as per your suggestion. Kindly check and approve.\r\n\r\nRegards\r\nAmit", "@rthadur & @gbaned , i have checked the error, it seems it is not caused by my code change , can you pls check and re trigger the build.\r\n\r\n_Traceback (most recent call last):\r\n  File \"check_load_py_test.py\", line 91, in <module>\r\n    main()\r\n  File \"check_load_py_test.py\", line 85, in main\r\n    '\\n'.join(files_missing_load)))\r\nRuntimeError: The following files are missing load(\"//tensorflow:tensorflow.bzl\", \"py_test\").\r\nThis load statement is needed because otherwise pip tests will try to use their dependencies, which are not visible to them.:\r\n tensorflow/contrib/input_pipeline/BUILD\r\ntensorflow/contrib/periodic_resample/BUILD_\r\n"]}, {"number": 27130, "title": "Update encode_proto_op.cc", "body": "Initialise the message_count", "comments": []}, {"number": 27129, "title": "[Feature Request] tf.data.Dataset.batch to return RaggedTensor when batching different shape Tensors", "body": "**System information**\r\n- TensorFlow version (you are using): TF 1.13.1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, when working with a tf.data.Dataset and batching together Tensors which have different shapes result in an error.\r\nThe new feature would return a RaggedTensor instead, which would also require tf.data.Dataset to handle RaggedTensor.\r\n\r\n\r\n**Will this change the current api? How?**\r\nAPI would be the same. Instead of an error, the Dataset might contain RaggedTensors.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone working with tensors with different shapes.\r\n\r\n**Any Other info.**\r\n", "comments": ["Thank you for your suggestion. We will have a look and revert on the same further.", "This is now done. Please give it a try and let us know if there are any issues."]}, {"number": 27128, "title": "dataset memory cache runs out of memory", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: \r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI use tf.dataset.cache to cache data and it will run out of my computer's memory\r\n**Describe the expected behavior**\r\ncache won't run out of memory\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n``` python\r\ndataset.cache()\r\n```\r\n\r\nIf we can use some cache storages just like leveldb which will provide high performance and will avoid memory leak. ", "comments": ["Thank you for reaching out to us. Can you please provide minimum reproducible code snippet and the error log to help us proceed further and verify what is going wrong", "> Thank you for reaching out to us. Can you please provide minimum reproducible code snippet and the error log to help us proceed further and verify what is going wrong\r\n``` python\r\ndataset.cache()\r\n```\r\nJust use cache when load data and memory will increase until ran out of memory.Because it will store data in memory without provide filename.", "@fsx950223 Could you describe more details about the issue and its context? Thanks!\r\n", "> @fsx950223 Could you describe more details about the issue and its context? Thanks!\r\n\r\nIf I use memory cache, it will run out of my memory.I won't use file cache because I read data from tfrecords and file cache just read data and write it to another file,it's useless for me.\r\nAnyway to avoid memory leak and provide high performance", "If your experiment runs out of memory when using `tf.data.Dataset.cache()` it means that your data does not fit into computers memory. This is not an indication of a memory leak but the intended behavior of your workload. The API is not intended to be using for caching only a subset of your dataset in memory.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27128\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27128\">No</a>\n", "I see similar behavior, and my dataset is about 1Gb, but it fills out 22Gb of free memory", "> I see similar behavior, and my dataset is about 1Gb, but it fills out 22Gb of free memory\r\n\r\nThat's probably because you have decoded/decompressed your data and stored raw bytes in the memory"]}, {"number": 27127, "title": "Issue while importing sugartensor --- tensorflow has no attribute core - SOLVED", "body": "I am using versions:\r\nTensorflow 1.13.1\r\nPython 3.6\r\nSugartensor (0.0.2.4)\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-1-5db6f289462a> in <module>\r\n     17 '''\r\n     18 from __future__ import print_function\r\n---> 19 import sugartensor as tf\r\n     20 import numpy as np\r\n     21 from prepro import *\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\myenv\\lib\\site-packages\\sugartensor\\__init__.py in <module>\r\n      1 from __future__ import absolute_import\r\n----> 2 from tensorflow import *\r\n      3 \r\n      4 from .sg_util import sg_opt\r\n      5 from .sg_main import *\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'core'\r\n\r\n```\r\n\r\n", "comments": ["Please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. It would be great if you can provide a small code to reproduce the error. Thanks!", "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows - Anaconda- Jupyter Notebook \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: pip in conda virtualenv\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am trying to execute below code, where the import sugartensor is giving me an error\r\nI have installed  Sugartensor (0.0.2.4) in virtual env using pip\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n -*- coding: utf-8 -*-\r\n\r\nfrom __future__ import print_function\r\nimport sugartensor as tf\r\nimport numpy as np\r\nfrom prepro import *\r\nfrom train import ModelGraph\r\nimport codecs\r\n\r\ndef main(): \r\n    g = ModelGraph(mode=\"test\")\r\n        \r\n    with tf.Session() as sess:\r\n        tf.sg_init(sess)\r\n\r\n        # restore parameters\r\n        saver = tf.train.Saver()\r\n        saver.restore(sess, tf.train.latest_checkpoint('asset/train'))\r\n        print(\"Restored!\")\r\n        mname = open('asset/train/checkpoint', 'r').read().split('\"')[1] # model name\r\n        \r\n        X, Y = load_test_data()\r\n        char2idx, idx2char = load_char_vocab()\r\n        word2idx, idx2word = load_word_vocab()\r\n        \r\n        results = []\r\n        rk = 0\r\n        num_para = 1\r\n        num_char = 1\r\n        for x, y in zip(X, Y):\r\n            stop_counting = False\r\n            x = np.concatenate( (np.zeros((Hyperparams.seqlen-1,)), \r\n                                 x[-np.count_nonzero(x):]))# lstrip and zero-pad\r\n            \r\n            para = \"\".join([idx2char[idx] for idx in x])\r\n            \r\n            chars, targets = [], [] # targets: the word that the char composes\r\n            for word in \"\".join(para).split():\r\n                chars.append(\" \")\r\n                targets.append(word)\r\n                for char in word:\r\n                    chars.append(char)\r\n                    targets.append(word)\r\n            \r\n            prefix = \"\" \r\n            preds = set()\r\n            for i, char_target in enumerate(zip(chars, targets)):\r\n                char, target = char_target\r\n                oov = \"\"\r\n                if target not in word2idx: \r\n                    oov = \"oov\"\r\n                \r\n                if i > Hyperparams.seqlen:\r\n                    ctx = np.array(x[i - Hyperparams.seqlen:i], np.int32) # \r\n                    \r\n                    if char == \" \":\r\n                        stop_counting = False\r\n                        preds = set()\r\n                        \r\n                    if not stop_counting:\r\n                        logits = sess.run(g.logits, {g.x: np.expand_dims(ctx, 0)}) #(1, 20970)\r\n                        while 1:\r\n                            pred = np.argmax(logits, -1)[0] # (1,)\r\n                            if pred in preds:\r\n                                logits[:, pred] = -100000000\r\n                            else:\r\n                                break\r\n                        \r\n                        rk += 1\r\n                        \r\n                        predword = idx2word.get(pred)    \r\n                        if predword == target: # S\r\n                            stop_counting = True\r\n                        preds.add(pred)\r\n                    \r\n                    results.append(u\"{},{},{},{},{},{},{}\".format(num_char, num_para, char, target, oov, predword, rk) )\r\n                    num_char += 1\r\n            \r\n            num_para += 1\r\n            \r\n        with codecs.open('data/output_{}_rk_{}.csv'.format(mname, rk), 'w', 'utf-8') as fout:\r\n            fout.write(\"\\n\".join(results))\r\n                                        \r\nif __name__ == '__main__':\r\n    main()\r\n    print(\"Done\")\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n# \r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-5db6f289462a> in <module>\r\n     17 '''\r\n     18 from __future__ import print_function\r\n---> 19 import sugartensor as tf\r\n     20 import numpy as np\r\n     21 from prepro import *\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\myenv\\lib\\site-packages\\sugartensor\\__init__.py in <module>\r\n      1 from __future__ import absolute_import\r\n----> 2 from tensorflow import *\r\n      3 \r\n      4 from .sg_util import sg_opt\r\n      5 from .sg_main import *\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'core'\r\n#\r\nfrom tensorflow import *\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-9e8f41c82356> in <module>\r\n----> 1 from tensorflow import *\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'core'\r\n#", "Please help me to solve this", "Installing right Python version (3.5) and tensorflow version (1.0) solved the issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27127\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27127\">No</a>\n", "\r\n\r\n   Python version (3.5) and tensorflow version (1.12.0) \r\n\r\nIssue while importing sugartensor --- tensorflow has no attribute core", "@sravan938  how did you solve this issue. please help me with this", "@aryachiranjeev I have uninstalled all the previously installed python versions. Created a environment with python version 3.5  and then installed tensorflow version (1.0) which solved the issue"]}, {"number": 27126, "title": "TF 2.0 TPUStrategy error 'explicit_paddings' not in Op<name=Conv2D; ...>", "body": "**System information**\r\n- TensorFlow version: 2.0.0-alpha0\r\n- Python version: 3.6\r\n- Environment: Google Collaboratory with TPU\r\n\r\n**Describe the current behavior**\r\nI'm trying to do TPUStrategy for tensorflow 2.0 with disabled eager execution. I'm using Keras for the CNN model. When I try to run the .fit function on the model, I get an error:\r\n\r\nNodeDef mentions attr 'explicit_paddings' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]; attr=dilations:list(int),default=[1, 1, 1, 1]>; NodeDef: {{node conv2d/Conv2D}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\r\n**Code to reproduce the issue**\r\nGoogle Collaboratory notebook: https://gist.github.com/thatsmesasha/0b7cca49517987166f479382158d2d42\r\n", "comments": ["TPUs are not yet supported with TensorFlow 2.0.\r\nYou can track [this issue](https://github.com/tensorflow/tensorflow/issues/24412) to stay up-to-date on progress.", "Closing this issue since we already have a tracking issue. Feel free to reopen if have any questions. Thanks!", "I am having this problem with TensorFlow 1.13.1 while trt.create_inference_graph\r\n"]}, {"number": 27125, "title": "Add the support of cuDNN Batch Norm Ex Operation", "body": "We added the support to the new cuDNN batch norm ex operation (available form 7.4.2). This operation provides faster NHWC kernels but needs to use an additional reserve_space and workspace.\r\n\r\nWhat we've done:\r\n(1) Register a new operation FusedBatchNormV3 (and corresponding grad ops)\r\n(2) Change python API to call the FusedBatchNormV3\r\n(3) Support XLA\r\n(4) Support TensorRT\r\n(5) Support Grappler pass\r\n\r\nFYI. @nluehr", "comments": ["@houtoms please resolve conflicts", "Thanks for your comments. I solved the conflicts and rebased my changes on the top of latest upstream/master. I will close this one and open another PR."]}, {"number": 27124, "title": "Add support to the new cuDNN Batch Norm Ex operation", "body": "We added the support to the new cuDNN batch norm ex operation (available form 7.4.2). This operation provides faster NHWC kernels but needs to use an additional reserve_space and workspace.\r\n\r\nWhat we've done:\r\n(1) Register a new operation FusedBatchNormV3 (and corresponding grad ops)\r\n(2) Change python API to call the FusedBatchNormV3\r\n(3) Support XLA\r\n(4) Support TensorRT\r\n(5) Support Grappler pass \r\n\r\nFYI. @nluehr ", "comments": []}, {"number": 27123, "title": "[Java] Implements EagerSession for eager execution.", "body": "This is part of eager execution in Java epic (work in progress).\r\n\r\nIt adds a `EagerSession` that implements the `ExecutionEnvironment` interface to make it interchangeable with `Graph`. For example:\r\n\r\nGraphExecution:\r\n```java\r\ntry (Graph g = new Graph()) {\r\n   Ops tf = Ops.create(g);\r\n    ...\r\n}  \r\n```\r\nEagerExecution:\r\n```java\r\ntry (EagerSession s = EagerSession.create()) {\r\n   Ops tf = Ops.create(s);\r\n   ...\r\n}\r\n```\r\nIn addition, since in eager mode we can't only rely on the `try-with-resources` technique to free up native resources (as we may create a lot, think of a while loop), it has its own cleanup mechanics that is closely bound to the JVM garbage collector to know when it is safe to release resources.\r\n\r\nCC: @sjamesr ", "comments": ["There seems to be a problem with `Android Demo App` target which might be related to those changes. I'll investigate and come back when I know more but it might be prudent to wait before merging this PR.", "As suggested by TFLite team, I added eager dependencies to the Android mobile build.\r\n\r\n@sjamesr , can you please reapprove this so we can see if that fixes the problem with the Android demo? Thanks", "The mobile_srcs_only_runtime change looks fine. @petewarden and @andrehentz might have some additional thoughts on whether this will work, but on the surface it should be OK.\r\n\r\nThe only other target that might need tweaking are in //tensorflow/lite/delegates/flex, where we reference several of the core/common_runtime/eager:* targets.", "@jdduke : effectively some eager dependencies in `//tensorflow/lite/delegates/flex` might not be required anymore, now that they are transited from `android_tensorflow_lib*`.\r\n\r\nBut that shouldn't prevent the build to succeed so maybe we can make that change after merging this feature? If you agree, can you also approve the PR as it is now? (the only unapproved changes  left are those dependencies updates). Thanks!", "> @jdduke : effectively some eager dependencies in //tensorflow/lite/delegates/flex might not be required anymore, now that they are transited from android_tensorflow_lib*.\r\n\r\nWell, you'd now have the same .cc code compiled in two separate libraries. We can always give this a try and the internal presubmits would catch a build error.", "@rthadur, is the build stuck somehow?", "@rthadur friendly reminder here, I need some help to know what is wrong with the build as I can't access the logs myself (link is internal), thanks!", "Ok @sjamesr , as we discussed, I reverted my last commit about Android build support. Can you please reapprove to see how it goes?"]}, {"number": 27122, "title": "Error selecting GPU programmatically from jupyter", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\nI have a multi-GPU machine and am trying to train different models on different GPUs. I'm trying to set the GPU programmatically rather than use env vars, but am running into issues. Here's my code:\r\n\r\n```python\r\ndef choose_gpu(gpu_id):\r\n    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\n    with K.tf.device(f'/gpu:{gpu_id}'):\r\n        config = tf.ConfigProto(intra_op_parallelism_threads=10,\r\n                                inter_op_parallelism_threads=10,\r\n                                allow_soft_placement=True,\r\n                                device_count={'CPU': 1, 'GPU': 1})\r\n        session = tf.Session(config=config)\r\n        K.set_session(session)\r\n```\r\n\r\nHowever, when I try to run the code in two separate jupyter notebooks, using ids 0 and 1, I get the following error:\r\n\r\n```\r\n2019-03-04 10:36:27.210489: W tensorflow/compiler/xla/service/platform_util.cc:240] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11523260416\r\n2019-03-04 10:36:27.210803: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56311c4bccf0 executing computations on platform CUDA. Devices:\r\n2019-03-04 10:36:27.211230: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value\r\ninstead of handling error Invalid argument: device CUDA:0 not supported by XLA service\r\n```\r\n\r\nIt works fine if I set `CUDA_VISIBLE_DEVICES` at the top of the script, but I'd rather not have to manage this. Any sense of what I may be doing wrong? I'm using\r\n- keras 2.2.4\r\n- tensorflow 1.13.1\r\n- ubuntu 18.04\r\n- jupyter 5.2.4\r\n- jupyter lab 0.35.4\r\n", "comments": []}]