[{"number": 14144, "title": "Eager: Device Placement of Constant Eager Tensors", "body": "When eager execution is enabled on 64bit machine, the following code snippet causes an error:\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  tf.split(np.array([1.0, 2.0]), np.array([1, 1]))`\r\n```\r\n```\r\nTensors on conflicting devices: cannot compute SplitV as input #1 was expected to be on \r\n/job:localhost/replica:0/task:0/device:CPU:0 but is actually on \r\n/job:localhost/replica:0/task:0/device:GPU:0 (operation running on \r\n/job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu(),\r\nor transparently copied by using tfe.enable_eager_execution(tfe.DEVICE_PLACEMENT_SILENT).\r\nCopying tensors between devices may slow down your model [Op:SplitV] name: split\r\n```\r\nThere are a couple of ways to fix this:\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  tf.split(np.array([1.0, 2.0]), np.array([1, 1], dtype=np.int32))`\r\n```\r\nor \r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  tf.split(np.array([1.0, 2.0]), [1, 1])`\r\n```\r\n\r\nThe error is thrown for the following reason. Kernel of operation `split` expects the `num_or_size_splits` argument to be in host memory (CPU RAM). For a tensor to be placed in host memory, it needs to be either created in the CPU context (e.g. `with tf.device(\"/cpu:0\")`) or have dtype of `int32`.  `numpy` defaults to creating `int64` tensors on 64bit machines. Hence the fixes - either explicitly request `int32` dtype from numpy or use python list (tensorflow defaults to `int32` for python sequences of small integers)\r\n\r\nAnother, more global, workaround is to enable automatic copying of tensors between devices as described in https://github.com/tensorflow/tensorflow/issues/14133..", "comments": ["It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 190 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 206 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 14143, "title": "Passing `clear_devices=True` to `SavedModelBuilder.add_meta_graph_and_variables()` loses function definitions", "body": "The `SavedModelBuilder` inadvertently strips all function definitions from the `MetaGraphDef` when `clear_devices=True`. See this gist for a repro (thanks @eggie5 for finding it!):\r\n\r\nhttps://gist.github.com/eggie5/f0838a1289ca851aa5a72593575b7f06\r\n\r\nThe bug appears to stem from `export_meta_graph()`, which builds a `GraphDef` by selective field copying when certain options (such as `clear_devices=True`) are passed. Passing `clear_devices=False` enables the code to succeed. However, it breaks compatibility between `tf.data` (and potentially other code) and `SavedModel`, so we should find a sustainable fix.\r\n\r\n@sukritiramesh Can you please take a look? Thanks!", "comments": []}, {"number": 14142, "title": "Tensorflow seq-to-seq Arabic chatbot", "body": "\r\ni'm working on an AI-chatbot for Arabic Language. I follow this tutorial in tensrflow seq-to-seq model. So far everything is doing great where i trained the model on my Arabic data using GPU and test the pre-trained model.But the some of them answers were correct while other are unrelated at all.\r\n\r\nSo, my questions are:\r\n\r\n1. the model uses GRU in creating the model, should i change it to LSTM?\r\n\r\n2. i used the same tokenizer in the (French to English translation tutorial), should i change it and use an Arabic tokenizer?\r\n\r\n3. Even if i write an input it will reply with Arabic sentence, what i need is if the inout is new to the chatbot it should say \"sorry i don't understand\" for example\r\n\r\nBasically, is there are changes should be done to make the chatbot handles the Arabic language very well", "comments": ["Hi @EmanSaad11, really cool you're using TF to build your chatbot for arabic. These questions are better suited for StackOverflow.com though, as Github issues are reserved for bugs and feature requests. Just look/post under the TensorFlow tag, there's great community support there.  ", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@EmanSaad11 what's the dataset that you're using? \r\ni am trying to build one as well but didn't land in any available corprus", "@abdallahmohammed197 Hi , that was my biggest problems so the solution was to create my own since my Arabic Chatbot is for customer service I built a data set with questions that the users could ask anlog with thier answer . ( the questions was collected by using a simple online survey)", "@EmanSaad11 is it possible to share the dataset? \r\ni would like to have your contact as well.  i am working in a similar problem\r\nyou can email me  abdullahbashir077@gmail.com. ", "@EmanSaad11 is it possible to share contacts please!. i am working in something similar and could really use your corpus. i've mentiond my email above", "@EmanSaad11 hi, I am working in similar and could really use your corpus. I really need it, can you share the dataset please, my email alhussayni83@gmail.com "]}, {"number": 14141, "title": "Resolve //tensorflow relative to tensorflow repo in tfcompile.bzl.", "body": "Do this so that tfcompile.bzl can be correctly loaded from another Bazel project", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "You wanted this cherry-picked to 1.4 correct?"]}, {"number": 14140, "title": "Update version strings to 1.4.0", "body": "", "comments": []}, {"number": 14139, "title": "Use 'LABEL maintainer=' in Dockerfile", "body": "* Use 'LABEL maintainer=' in Dockerfile\r\n\r\nThis fix is a follow up of 13961 to replace `MAINTAINER`\r\nwith `LABEL maintainer=` in Dockerfile. The keyword\r\n`MAINTAINER` has long been deprecated and is replaced by `LABEL`,\r\nwhich is much more flexible and is easily searchable through `docker\r\ninspect`.\r\n\r\nThis fix replaces remaining `MAINTAINER` with `LABEL`.\r\n\r\nSigned-off-by: Charlie Lewis <clewis@iqt.org>\r\n\r\n* Additional `MAITAINER` -> `LABEL`\r\n\r\nSigned-off-by: Charlie Lewis <clewis@iqt.org>", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Thanks for the PR @cglewis!", "@tensorflow-jenkins test this please."]}, {"number": 14138, "title": "feature request for TensorFlow  Speech Recognizer .apk", "body": "the Android .apk file is a great way to test TensorFlow  Speech Recognizer.\r\nIt would be even more useful with the addition of these two features:\r\n1. once any word is detected, specify the scores for all 10 words in the list.\r\n2. specify silence detection\r\n\r\nThank you in advance to anyone who is able to add these features!", "comments": ["@Vysha : We (the TensorFlow maintainers) will probably not have cycles to implement this in the near future, but we'd welcome pull requests to do so.\r\n\r\nThanks!"]}, {"number": 14137, "title": "[XLA] Rename symbols for OS/X only - it doesn't have sincos", "body": "On OS/X the sincos and sincosf are apparently not present.  There is a __sincos and __sincosf.  This change creates an alias for them on OS/X.\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "The types should be as follows:\r\n\r\n```\r\n#if defined(__APPLE__)\r\nstatic void sincos(double, double*, double*)  __attribute__((weakref (\"__sincos\")));\r\nstatic void sincosf(float, float*, float*) __attribute__((weakref (\"__sincosf\")));\r\n#endif\r\n```", "Updated - thanks @Timmmm \r\n", "i believe this was merged with the other fix"]}, {"number": 14136, "title": "eager: Update broken link in README", "body": "", "comments": []}, {"number": 14135, "title": "eager: Update broken links in guide.md", "body": "", "comments": []}, {"number": 14134, "title": "Eager: Random seeds", "body": "(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`) \r\n\r\nSetting the [graph-level random](https://www.tensorflow.org/api_docs/python/tf/set_random_seed) seed exactly once, before any operations are executed, works as intended; however, subsequent invocations to `tf.set_random_seed()` will not reset operation randomness. Furthermore, keyword arguments that set operation-level seeds have no effect when executing in eager mode. Random sequences generated by the same graph-seed will vary depending upon whether you are constructing a graph or executing eagerly.\r\n", "comments": ["Hi ! @asimshankar ,You seem to be using using an old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.6 and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 14133, "title": "Eager: Automatic Device Placement", "body": "When a GPU is available, TensorFlow automatically copies tensors between CPU and GPU memory (see [Using GPUs](https://www.tensorflow.org/tutorials/using_gpu)).\r\n\r\nWhen eager execution is enabled, automatic copying between devices is disabled by default. When executing imperatively, copying data between CPU and GPU is more likely to become a performance bottleneck. Avoiding automatic copying makes it easier to identify such bottlenecks. For example, consider the program:\r\n\r\n\r\n```python\r\nwith tf.device(\u201c/cpu:0\u201d):\r\n  x = tf.ones([2, 2])\r\nwith tf.device(\u201c/gpu:0\u201d):\r\n  y = tf.matmul(x, x)\r\n```\r\n\r\nThis will fail with an error like:\r\n\r\n```\r\nTensors on conflicting devices: cannot compute MatMul as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 \u2026\r\n```\r\n\r\n\r\nindicating that the `matmul` operation cannot be conducted on the GPU as its inputs were host memory.\r\n\r\nIf you run into this situation, your options are:\r\n\r\n- Accept the potential performance hit by explicitly enabling automatic copying between devices:\r\n\r\n\r\n```python\r\ntfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)\r\n```\r\n\r\n-  Explicitly copy the tensor yourself using `tf.identity` or `Tensor.gpu()`:\r\n\r\n```python\r\nwith tf.device(\u201c/gpu:0\u201d):\r\n  x = tf.identity(x)\r\n  y = tf.matmul(x, x)\r\n```", "comments": ["It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@asimshankar I un-marked this as \"awaiting\" to quiet the automatic reminder.", "Assigning to @asimshankar.  It's not clear to me that there's any desired action. Should this just be closed?", "Actually, this should be fixed by commit c6911faaf4702096064542790d8c9e8e6f938d52\r\nwhich makes placement of operations with eager execution similar to graph (use a GPU if available, and transparently copy).\r\n\r\nThese silent copies could be a performance bottleneck if there is too much back and forth between host and device memory. Explicitly using `tf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_EXPLICIT)` will help trace those down.\r\n", "@asimshankar I've found similar issues in TF 2.0. I cannot reproduce the same performance numbers (~9000 image/s) running Keras in-stock ResNet50 model in a DGX-1V, and I suspect it is because of either data pipeline or computing piecewise learning rate on CPU. Currently I cannot achieve better performance than ~3000 image/s with 8 V100 using MirroredStrategy.\r\n\r\nThe stack trace after setting device policy = explicit is not particularly helpful tracing down the root cause though:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in on_epoch(self, epoch, mode)\r\n    719     try:\r\n--> 720       yield epoch_logs\r\n    721     finally:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    309           with training_context.on_epoch(epoch, ModeKeys.TRAIN) as epoch_logs:\r\n--> 310             model.reset_metrics()\r\n    311             if training_data_iter is None or recreate_training_iterator:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py in reset_metrics(self)\r\n    908     for m in metrics:\r\n--> 909       m.reset_states()\r\n    910 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/metrics.py in reset_states(self)\r\n    208     \"\"\"\r\n--> 209     K.batch_set_value([(v, 0) for v in self.variables])\r\n    210 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py in batch_set_value(tuples)\r\n   3231       for x, value in tuples:\r\n-> 3232         x.assign(np.asarray(value, dtype=dtype(x)))\r\n   3233   else:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/values.py in assign(self, *args, **kwargs)\r\n   1220         if self._aggregation == vs.VariableAggregation.SUM:\r\n-> 1221           tensor = math_ops.cast(tensor / len(self.devices), self.dtype)\r\n   1222         return control_flow_ops.group(tuple(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    179     try:\r\n--> 180       return target(*args, **kwargs)\r\n    181     except (TypeError, ValueError):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_ops.py in cast(x, dtype, name)\r\n    703       if x.dtype.base_dtype != base_type:\r\n--> 704         x = gen_math_ops.cast(x, base_type, name=name)\r\n    705     if x.dtype.is_complex and base_type.is_floating:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/gen_math_ops.py in cast(x, DstT, Truncate, name)\r\n   2266         message = e.message\r\n-> 2267       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   2268   # Add nodes to the TensorFlow graph.\r\n\r\n/usr/local/lib/python3.5/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using: `with tf.device(device_name): x = tf.identity(x)` or transparently copied by using tf.config.experimental.set_device_policy('silent'). Copying tensors between devices may slow down your model [Op:Cast] name: Cast/\r\n```\r\n\r\nUsing device policy = warning, it seems multiple Ops are mis-placed:\r\n\r\n```\r\n2019-09-07 10:08:12.601275: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing PrefetchDataset input #1 was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:4 (operation running on /job:localhost/replica:0/task:0/device:GPU:4). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.602796: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing GeneratorDataset input #3 was expected to be on /job:localhost/replica:0/task:0/device:GPU:5 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:5). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.603128: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing PrefetchDataset input #1 was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:5 (operation running on /job:localhost/replica:0/task:0/device:GPU:5). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.604638: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing GeneratorDataset input #3 was expected to be on /job:localhost/replica:0/task:0/device:GPU:6 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:6). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.604974: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing PrefetchDataset input #1 was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:6 (operation running on /job:localhost/replica:0/task:0/device:GPU:6). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.606505: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing GeneratorDataset input #3 was expected to be on /job:localhost/replica:0/task:0/device:GPU:7 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:7). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:08:12.606828: W tensorflow/core/common_runtime/eager/execute.cc:166] before computing PrefetchDataset input #1 was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:7 (operation running on /job:localhost/replica:0/task:0/device:GPU:7). This triggers a copy which can be a performance bottleneck.\r\n2019-09-07 10:09:37.738050: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 4128/22835 nodes to float16 precision using 1304 cast(s) to float16 (excluding Const and Variable casts)\r\n``` "]}, {"number": 14132, "title": "Eager: Variable item-assignment", "body": "(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)\r\n\r\nCurrently, the following does not work:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\nx = tfe.Variable(tf.ones([10]), name=\u2019x\u2019)\r\nx[3] = 2.\r\n```\r\n\r\nThat last line, assigning a value to an element of the tensor will fail with: `object does not support item assignment`.\r\n\r\nWhile it would be possible to make item assignment for `Tensor` and `Variable` objects work when eager execution is enabled, it is trickier to make the same line of code work with graph construction (since the line `x[3] = 2.` does not return a `tf.Operation` object that can be provided to a `Session.run()` call).\r\n\r\nAt this early stage of eager execution, we\u2019re taking the conservative approach and disallowing Tensor assignment. This is probably worth revisiting at a future date. In the meantime, the verbose form of item assignment using `tf.scatter_update`:\r\n\r\n```python\r\ntf.scatter_update(x, [3], [2.])\r\n```\r\n", "comments": ["This is unfortunately a show-stopper for porting (dynamic) code from PyTorch", "(FWIW, currently `x[3].assign(2)` is shorter hand for `tf.scatter_update(x, [3], [2])` that works with or without eager execution)", "This is not working on models created with Keras sequential...i'm getting errors (see below).  Also agree with the above poster, the regular form of x[3]=2.0 needs to be enabled.\r\n\r\nline 297, in scatter_update\r\n    return ref._lazy_read(gen_resource_variable_ops.resource_scatter_update(  # pylint: disable=protected-access\r\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_lazy_read'", "@johnpjust : could you provide a short snippet to reproduce the error you're seeing? From the error message it appears that `scatter_update` is being invoked on a `Tensor` instead of a `Variable`. ", "Hi yes -- you are correct in that I am trying to set it on a single element of the variable array, which I thought is like what is happening above.  I've got this on SO as well since i wasn't sure if it was a bug, but when i use scatter_update I'm not finding the right combination to change a single element of, e.g., a 3x3 variable\r\n\r\nmodel.trainable_variables[0]\r\n<tf.Variable 'dense_5/kernel:0' shape=(3, 3) dtype=float64, numpy=\r\narray([[ 0.58309446,  0.47310445,  0.69813648],\r\n       [ 0.2342269 ,  0.01559285, -0.77714921],\r\n       [-0.43583301,  0.45498991,  1.31445808]])>\r\n\r\ntf.scatter_update(model.trainable_variables[0], [1,1],3.0) for instance will result in \r\n<tf.Variable 'UnreadVariable' shape=(3, 3) dtype=float64, numpy=\r\narray([[ 0.58309446,  0.47310445,  0.69813648],\r\n       [ 3.        ,  3.        ,  3.        ],\r\n       [-0.43583301,  0.45498991,  1.31445808]])>", "Hello. I would like to comment on this issue.\r\n\r\nIn fact, there is a method to get item assignment in both eager mode and graph mode.\r\n\r\nIf you look at the source code for tf.image.random_flip_up_down (specifically in the function _random_flip), there is a simple way to do what appears to be in-pace assignment (when viewed from far enough away). \r\n\r\nJust make a mask tensor with the indices that you want to replace set to 0 and the locations that you want to use set at 1 (call this tensor \"mask\").\r\n\r\nThen perform whatever operation that you want to do on a tensor that is the same size (or is broadcastable to) your original tensor (call this tensor \"other\").\r\n\r\nThen you can simply create a new tensor by doing the following:\r\n\r\nnew = original * mask + other * (1 - mask)\r\n\r\nThis would create a new tensor which appears to have undergone item assignment.\r\n", "@veritas9872 It seems like a good workaround! :+1: ", "I think that it would be great if Tensorflow could implement this natively at a lower level. However, I don't know how to get the attention of the people who could actually implement this.", "@veritas9872 How about write a PyPI module that does this job by a wrapper?\r\n\r\nIf there's feature is really a thing, then I believe lots of people will install and use it. :D", "The following is taken from tensorflow2.0 Alpha documentation:\r\n[link](https://www.tensorflow.org/alpha/tutorials/eager/tf_function)\r\n\"So, for example, the best way to accumulate data in a loop is still to use tf.TensorArray:\r\n@tf.function\r\ndef f(x):\r\n  ta = tf.TensorArray(tf.float32, size=10)\r\n  for i in tf.range(10):\r\n    x += x\r\n    ta = ta.write(i, x)\r\n  return ta.stack()\r\n\r\nf(10.0)\"\r\n", "Closing out this issue, as `tf.contrib` is no longer supported in TF 2.0. For eager behavior, please refer to the documentation referenced above by @RasoulNik. Thank you! \ud83d\ude42 ", "Tensorflow sucks", "In my case,  I had to assign depth_buffer[v,u] = point_depth. Here is the solution: \r\ndepth_buffer = depth_buffer[v:v+1,u:u+1].assign([point_depth])\r\n\r\nTensorflow does not suck on prod))", "@KhurramPirov nah i also use tf for prod but i know clearly that it's just a matter of time for pytorch to dominate at least vision community. ", "> Tensorflow sucks\r\n\r\nYes , Tensorflow really sucks , people have to solve some un-related problems due to tensorflows bad implementation, i don't know how long it will take to launch neat and clean Tensorflow version, sometimes I  thought the older 1.x was better that this rubbish tf 2.x  "]}, {"number": 14131, "title": "Eager: Using graphs in the same Python process", "body": "Once eager execution is enabled via `tfe.enable_eager_execution()`, it cannot be disabled in the same process. This means that eager and graph execution cannot be mixed in the same Python session.\r\n\r\nThis issue has been filed to track development of features to make the transition between eager and graph execution smoother -- allowing users to pick and choose portions of the computation that will be \u201ccompiled\u201d into graphs for optimized execution, and portions that will execute eagerly.\r\n", "comments": ["It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @asimshankar: It has been 105 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing this since https://github.com/tensorflow/tensorflow/commit/68430112b2ca5c160db6dd412d43f572ec69e72f addresses it I believe."]}, {"number": 14130, "title": "Eager: CPU Performance/Operation Overheads", "body": "(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)\r\n\r\nEager execution re-uses most of the same Python code used for constructing TensorFlow graphs. Many of these paths have not been optimized for part of the critical path of computation. As a result, the CPU overheads of executing Python code for every operation are higher than we\u2019d like.\r\n\r\nConsequently, the performance of eager execution on models with many small computations, or models executed on CPU may be dominated by these overheads.\r\n\r\nOverheads are measured using microbenchmarks such as in [`benchmarks_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/benchmarks_test.py) and model-level benchmarks such as those used for [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50) and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb)", "comments": ["Nagging Assignee @akshaym: It has been 195 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing this out as many many improvements have been made and others are coming too.\r\nNot sure about the value of this issue since it isn't very specific (yes, I know I filed this :))"]}, {"number": 14129, "title": "Eager: Distributed Execution", "body": "(This applies only when [eager execution](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/README.md) has been enabled via `tfe.enable_eager_execution()`)\r\n\r\n\r\nIf the model does not involve dynamic control flow in Python (i.e., changing the computation based on input), then the same model code can be used to construct a TensorFlow graph, which can then be trained with [distributed TensorFlow](https://www.tensorflow.org/deploy/distributed)\r\n\r\nSome example models like [MNIST](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/mnist), [ResNet50](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/resnet50), and the [PTB RNN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/rnn_ptb) include unittests outlining how the same model code can be used to construct and train TensorFlow graphs.\r\n\r\nA smoother path to distributed TensorFlow when eager execution is enabled is being charted out.\r\n", "comments": ["What's the status for this? ", "The `DistributionStrategy` API (in the process of being moved from [`contrib/distribute`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute) to [`tf.distribute`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/distribute) is being developed so that it is the mechanism to distribute computation when eager execution is enabled.\r\n\r\nRelease notes should reflect when it is ready to be advertised for broader use.\r\n\r\nCC @iganichev ", "tf.distribute work for TF 2.0 is going strong and being tracked internally. This issue serves no purpose."]}, {"number": 14128, "title": "Fix typos in Linear Model Tutorial samples and install_sources.md", "body": "1. test_file_name is undefined (should be test_file.name)\r\n2. train_file_name is undefined (should be train_file.name)\r\n\r\nPiperOrigin-RevId: 173733442", "comments": ["So \"Ubuntu Makefile\" is broken for 1.4 branch. Ignore those failures."]}, {"number": 14127, "title": "[Mac] Build @HEAD fails with XLA errors", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac High Sierra 10.13\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: HEAD at c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n1. Clone repo at head\r\n2. configure\r\n3. build with CPU support only and native arch optimization\r\n\r\nBuilding TensorFlow at TensorFlow@c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564 (HEAD) yields the errors below related to XLA (optimized for Intel(R) Core(TM) i7-7700HQ).\r\n\r\n```\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:220:3: error: reinterpret_cast cannot resolve overloaded function 'acos' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(acos);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:714:1: note: candidate function\r\nacos(_A1 __lcpp_x) _NOEXCEPT {return ::acos((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:708:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double acos(long double __lcpp_x) _NOEXCEPT {return ::acosl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:707:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       acos(float __lcpp_x) _NOEXCEPT       {return ::acosf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:323:15: note: candidate function\r\nextern double acos(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:221:3: error: reinterpret_cast cannot resolve overloaded function 'acosh' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(acosh);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1005:1: note: candidate function\r\nacosh(_A1 __lcpp_x) _NOEXCEPT {return ::acosh((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1000:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double acosh(long double __lcpp_x) _NOEXCEPT {return ::acoshl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:999:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       acosh(float __lcpp_x) _NOEXCEPT       {return ::acoshf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:351:15: note: candidate function\r\nextern double acosh(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:222:3: error: reinterpret_cast cannot resolve overloaded function 'asin' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(asin);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:726:1: note: candidate function\r\nasin(_A1 __lcpp_x) _NOEXCEPT {return ::asin((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:720:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double asin(long double __lcpp_x) _NOEXCEPT {return ::asinl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:719:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       asin(float __lcpp_x) _NOEXCEPT       {return ::asinf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:327:15: note: candidate function\r\nextern double asin(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:223:3: error: reinterpret_cast cannot resolve overloaded function 'asinh' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(asinh);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1017:1: note: candidate function\r\nasinh(_A1 __lcpp_x) _NOEXCEPT {return ::asinh((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1012:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double asinh(long double __lcpp_x) _NOEXCEPT {return ::asinhl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1011:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       asinh(float __lcpp_x) _NOEXCEPT       {return ::asinhf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:355:15: note: candidate function\r\nextern double asinh(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:224:3: error: reinterpret_cast cannot resolve overloaded function 'atan' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(atan);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:738:1: note: candidate function\r\natan(_A1 __lcpp_x) _NOEXCEPT {return ::atan((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:732:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double atan(long double __lcpp_x) _NOEXCEPT {return ::atanl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:731:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       atan(float __lcpp_x) _NOEXCEPT       {return ::atanf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:331:15: note: candidate function\r\nextern double atan(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:225:3: error: reinterpret_cast cannot resolve overloaded function 'atan2' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(atan2);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:755:1: note: candidate function\r\natan2(_A1 __lcpp_y, _A2 __lcpp_x) _NOEXCEPT\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:744:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double atan2(long double __lcpp_y, long double __lcpp_x) _NOEXCEPT {return ::atan2l(__lcpp_y, __lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:743:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       atan2(float __lcpp_y, float __lcpp_x) _NOEXCEPT             {return ::atan2f(__lcpp_y, __lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:335:15: note: candidate function\r\nextern double atan2(double, double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:226:3: error: reinterpret_cast cannot resolve overloaded function 'atanh' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(atanh);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1029:1: note: candidate function\r\natanh(_A1 __lcpp_x) _NOEXCEPT {return ::atanh((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1024:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double atanh(long double __lcpp_x) _NOEXCEPT {return ::atanhl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1023:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       atanh(float __lcpp_x) _NOEXCEPT       {return ::atanhf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:359:15: note: candidate function\r\nextern double atanh(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:227:3: error: reinterpret_cast cannot resolve overloaded function 'cbrt' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(cbrt);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1041:1: note: candidate function\r\ncbrt(_A1 __lcpp_x) _NOEXCEPT {return ::cbrt((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1036:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double cbrt(long double __lcpp_x) _NOEXCEPT {return ::cbrtl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1035:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       cbrt(float __lcpp_x) _NOEXCEPT       {return ::cbrtf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:435:15: note: candidate function\r\nextern double cbrt(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:228:3: error: reinterpret_cast cannot resolve overloaded function 'ceil' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(ceil);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:773:1: note: candidate function\r\nceil(_A1 __lcpp_x) _NOEXCEPT {return ::ceil((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:767:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double ceil(long double __lcpp_x) _NOEXCEPT {return ::ceill(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:766:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       ceil(float __lcpp_x) _NOEXCEPT       {return ::ceilf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:470:15: note: candidate function\r\nextern double ceil(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:229:3: error: reinterpret_cast cannot resolve overloaded function 'copysign' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(copysign);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1065:1: note: candidate function\r\ncopysign(_A1 __lcpp_x, _A2 __lcpp_y) _NOEXCEPT\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1052:1: note: candidate function\r\ncopysign(long double __lcpp_x, long double __lcpp_y) _NOEXCEPT {\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1047:40: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float copysign(float __lcpp_x,\r\n                                       ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:526:15: note: candidate function\r\nextern double copysign(double, double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:230:3: error: reinterpret_cast cannot resolve overloaded function 'cos' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(cos);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:785:1: note: candidate function\r\ncos(_A1 __lcpp_x) _NOEXCEPT {return ::cos((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:779:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double cos(long double __lcpp_x) _NOEXCEPT {return ::cosl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:778:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       cos(float __lcpp_x) _NOEXCEPT       {return ::cosf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:339:15: note: candidate function\r\nextern double cos(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:231:3: error: reinterpret_cast cannot resolve overloaded function 'cosh' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(cosh);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:797:1: note: candidate function\r\ncosh(_A1 __lcpp_x) _NOEXCEPT {return ::cosh((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:791:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double cosh(long double __lcpp_x) _NOEXCEPT {return ::coshl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:790:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       cosh(float __lcpp_x) _NOEXCEPT       {return ::coshf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:363:15: note: candidate function\r\nextern double cosh(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:232:3: error: reinterpret_cast cannot resolve overloaded function 'erf' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(erf);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1083:1: note: candidate function\r\nerf(_A1 __lcpp_x) _NOEXCEPT {return ::erf((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1078:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double erf(long double __lcpp_x) _NOEXCEPT {return ::erfl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1077:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       erf(float __lcpp_x) _NOEXCEPT       {return ::erff(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:451:15: note: candidate function\r\nextern double erf(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:233:3: error: reinterpret_cast cannot resolve overloaded function 'erfc' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(erfc);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1093:1: note: candidate function\r\nerfc(_A1 __lcpp_x) _NOEXCEPT {return ::erfc((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1088:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double erfc(long double __lcpp_x) _NOEXCEPT {return ::erfcl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1087:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       erfc(float __lcpp_x) _NOEXCEPT       {return ::erfcf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:455:15: note: candidate function\r\nextern double erfc(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:234:3: error: reinterpret_cast cannot resolve overloaded function 'exp' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(exp);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:809:1: note: candidate function\r\nexp(_A1 __lcpp_x) _NOEXCEPT {return ::exp((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:803:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double exp(long double __lcpp_x) _NOEXCEPT {return ::expl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:802:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       exp(float __lcpp_x) _NOEXCEPT       {return ::expf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:375:15: note: candidate function\r\nextern double exp(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:235:3: error: reinterpret_cast cannot resolve overloaded function 'exp2' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(exp2);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1103:1: note: candidate function\r\nexp2(_A1 __lcpp_x) _NOEXCEPT {return ::exp2((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1098:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double exp2(long double __lcpp_x) _NOEXCEPT {return ::exp2l(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1097:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       exp2(float __lcpp_x) _NOEXCEPT       {return ::exp2f(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:379:15: note: candidate function\r\nextern double exp2(double); \r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:236:3: error: reinterpret_cast cannot resolve overloaded function 'expm1' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(expm1);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1113:1: note: candidate function\r\nexpm1(_A1 __lcpp_x) _NOEXCEPT {return ::expm1((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1108:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double expm1(long double __lcpp_x) _NOEXCEPT {return ::expm1l(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1107:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       expm1(float __lcpp_x) _NOEXCEPT       {return ::expm1f(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:383:15: note: candidate function\r\nextern double expm1(double); \r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:237:3: error: reinterpret_cast cannot resolve overloaded function 'fabs' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(fabs);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:821:1: note: candidate function\r\nfabs(_A1 __lcpp_x) _NOEXCEPT {return ::fabs((double)__lcpp_x);}\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:815:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double fabs(long double __lcpp_x) _NOEXCEPT {return ::fabsl(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:814:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       fabs(float __lcpp_x) _NOEXCEPT       {return ::fabsf(__lcpp_x);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:431:15: note: candidate function\r\nextern double fabs(double);\r\n              ^\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:238:3: error: reinterpret_cast cannot resolve overloaded function 'fdim' to type 'void *'\r\n  REGISTER_LIBM_SYMBOL(fdim);\r\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:217:31: note: expanded from macro 'REGISTER_LIBM_SYMBOL'\r\n    registry->Register(#name, reinterpret_cast<void*>(name));         \\\r\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1128:1: note: candidate function\r\nfdim(_A1 __lcpp_x, _A2 __lcpp_y) _NOEXCEPT\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1118:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double fdim(long double __lcpp_x, long double __lcpp_y) _NOEXCEPT {return ::fdiml(__lcpp_x, __lcpp_y);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/math.h:1117:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       fdim(float __lcpp_x, float __lcpp_y) _NOEXCEPT             {return ::fdimf(__lcpp_x, __lcpp_y);}\r\n                                             ^\r\n/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/math.h:542:15: note: candidate function\r\nextern double fdim(double, double);\r\n              ^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n2 warnings and 20 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2220.010s, Critical Path: 87.74s\r\n\r\n\r\n```", "comments": ["Presumably XLA was enabled in `./configure`?\r\nThis might have been broken in https://github.com/tensorflow/tensorflow/commit/720efa37a4e93d5833e6e928993790f2523f0d85presumably because it seems that `math.h` included with Xcode defines overloads for `float` and `double`.\r\n\r\n@sanjoy : Mind taking a look?", "Yes, XLA was enabled.", "not exactly related, but you might be interested in this: https://github.com/tensorflow/tensorflow/pull/14137\r\n", "Same error [here](https://github.com/Project-OSRM/osrm-backend/issues/1000). The fundamental problem is that `double sin(double)` and `float sin(float)` (and so on) are both available in the global namespace so the cast is ambiguous.\r\n\r\nAs far as I understand it, when you `#include <math.h>` you should only get the `double` version and not the `float` version. When you `#include <cmath>` you should get `double std::sin(double)` and `float std::sin(float)`. However, Apple have set it up so that when you `#include <cmath>` you get both those functions imported into the global namespace.\r\n\r\nThe only reliable way around this seems to be to be explicit about the signature for the overloaded functions, as follows:\r\n\r\nFirst, add @DavidNorman's `sincos` fix, but with the correct function types:\r\n\r\n```\r\n#if defined(__APPLE__)\r\nstatic void sincos(double, double*, double*)  __attribute__((weakref (\"__sincos\")));\r\nstatic void sincosf(float, float*, float*) __attribute__((weakref (\"__sincosf\")));\r\n#endif\r\n```\r\n\r\nThen:\r\n\r\n```\r\n#define REGISTER_LIBM_SYMBOL(name, sig)                               \\\r\n  do {                                                                \\\r\n    /* Register both the F32 and F64 variants of the libm symbol.  */ \\\r\n    registry->Register(#name \"f\", reinterpret_cast<void*>(name##f));  \\\r\n    registry->Register(#name, reinterpret_cast<void*>(static_cast<sig>(name)));\\\r\n  } while (false)\r\n\r\n  REGISTER_LIBM_SYMBOL(acos, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(acosh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(asin, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(asinh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(atan, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(atan2, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(atanh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(cbrt, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(ceil, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(copysign, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(cos, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(cosh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(erf, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(erfc, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(exp, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(exp2, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(expm1, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(fabs, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(fdim, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(floor, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(fma, double(*)(double, double, double));\r\n  REGISTER_LIBM_SYMBOL(fmax, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(fmin, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(fmod, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(frexp, double(*)(double, int*));\r\n  REGISTER_LIBM_SYMBOL(hypot, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(ilogb, int(*)(double));\r\n  REGISTER_LIBM_SYMBOL(ldexp, double(*)(double, int));\r\n  REGISTER_LIBM_SYMBOL(lgamma, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(llrint, long long(*)(double));\r\n  REGISTER_LIBM_SYMBOL(llround, long long(*)(double));\r\n  REGISTER_LIBM_SYMBOL(log, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(log10, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(log1p, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(log2, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(logb, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(lrint, long(*)(double));\r\n  REGISTER_LIBM_SYMBOL(lround, long(*)(double));\r\n  REGISTER_LIBM_SYMBOL(modf, double(*)(double, double*));\r\n  REGISTER_LIBM_SYMBOL(nan, double(*)(const char*));\r\n  REGISTER_LIBM_SYMBOL(nearbyint, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(nextafter, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(nexttoward, double(*)(double, long double));\r\n  REGISTER_LIBM_SYMBOL(pow, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(remainder, double(*)(double, double));\r\n  REGISTER_LIBM_SYMBOL(remquo, double(*)(double, double, int*));\r\n  REGISTER_LIBM_SYMBOL(rint, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(round, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(scalbln, double(*)(double, long));\r\n  REGISTER_LIBM_SYMBOL(scalbn, double(*)(double, int));\r\n  REGISTER_LIBM_SYMBOL(sin, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(sincos, void(*)(double, double*, double*));\r\n  REGISTER_LIBM_SYMBOL(sinh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(sqrt, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(tan, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(tanh, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(tgamma, double(*)(double));\r\n  REGISTER_LIBM_SYMBOL(trunc, double(*)(double));\r\n```\r\n\r\nTedious but it seems to work. Fortunately the `sinf(float)` and similar functions are never overloaded so a cast isn't needed for those.", "Nice @Timmmm and @DavidNorman, thanks for the heads up and solution. Waiting for #14288 to merge :)", "I've made the modifications and tried to compile, this time getting just one error due to [this change](https://github.com/tensorflow/tensorflow/commit/4e69e02241067129379f73dd4fefe57f0a12bdc9#diff-866fd5845e79e513efd00ed931aa56f5L559) related to [LLVM API updates](https://reviews.llvm.org/rL317488) (replacing `setUnsafeAlgebra()` by `setFast()`). Upgrading LLVM should fix but they will only release v5.0.1 by the end of November.\r\n```\r\ntensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:560:11: error: no member named 'setFast' in 'llvm::FastMathFlags'\r\n    flags.setFast();\r\n    ~~~~~ ^\r\n```", "thanks for the heads up...", "Thanks for the fix @Carmezim - much appreciated.\r\n\r\n(Marking as \"contributions welcome\" - your contribution is welcome :)", "As https://github.com/tensorflow/tensorflow/pull/14288 is about to be merged I'll open a new issue to track the LLVM updates causing the compilation to fail. "]}, {"number": 14126, "title": "fail to build tensorflow-gpu by CUDA 9.0 cuDNN 7 at win10 envs ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: window 10 64bit\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: tensorflow-1.4.0 or tensorflow-1.3.0\r\n- **Python version**: python 3.5.4\r\n- **Bazel version (if compiling from source)**: cmake 3.6.3\r\n- **CUDA/cuDNN version**: CUDA 9.0 + cuDNN 7\r\n- **GPU model and memory**: gtx 1080ti (11GB)\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nhello\uff0cfor i can't use tensorflow gpu packet at win10, so i try to build tensorflow gpu by win10 env\uff0cthen met those issue\uff0c can anyone help me\uff0cthanks first.\r\nmy environment\uff1a\r\nwin10 + gtx 1080ti + cuda 9.0 + cuDNN 7 + visual studio profession 2015 + cmake 3.6.3 + python 3.5.4\r\nwhen i switch to tensorflow r1.4\uff0cand build by cmake at win10 environment\uff0cissue accur that\uff1a\r\n`CUSTOMBUILD : Internal error : assertion failed at: \"C:/dvs/p4/build/sw/rel/gpu_drv/r384/r384_00/drivers/compiler/edg/EDG_4.12/src/lookup.c\", line 2652 [C:\\TF\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\n1 catastrophic error detected in the compilation of \"C:/Users/ADMINI~1/AppData/Local/Temp/tmpxft_00000c94_00000000-8_adjust_contrast_op_gpu.cu.cpp4.ii\".\r\nCompilation aborted.\r\nadjust_contrast_op_gpu.cu.cc\r\nCUSTOMBUILD : nvcc error : 'cudafe++' died with status 0xC0000409 [C:\\TF\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\nCMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:267 (message):\r\nError generating file\r\nC:/TF/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir///core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`\r\n![image](https://user-images.githubusercontent.com/32933617/32231202-ee18adfa-be8f-11e7-87fd-0dff8854ae96.png)\r\n\r\nabove issue look like cuda compolie itself problem\uff0cbut when i switch tensorflow version to r1.3\uff0canother issue accur\uff1a\r\n`c:\\tf\\test\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src/Core/util/Macros.h(416): fatal error C1017:\r\n\u65e0\u6548\u7684\u6574\u6570\u5e38\u91cf\u8868\u8fbe\u5f0f [C:\\TF\\test\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\nCMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:267 (message):\r\nError generating file\r\nC:/TF/test/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir///core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`\r\n![image](https://user-images.githubusercontent.com/32933617/32231220-f8c0802a-be8f-11e7-9dcb-623cbc2a3429.png)\r\n\r\nit look like the file adjust_contrast_op_gpu.cu.cc have some problem\uff0cbut i can't find any error from it.\r\nsuch above issues trouble me few days\uff0cwish to someone help me going this try and success\uff0cand strong expect google upgrade tensorflow support cuda 9.0 and cudnn 7 at win10 environment.\r\n", "comments": ["CUDA v9 and cuDNN v7 are not supported by TensorFlow on Windows yet. Support will be provided officially from TensorFlow 1.5v forward. Could you try with the supported requirements and report back?", "@Carmezim OK\uff0ci willing to try and feekback\uff0cbut 1.3rc / 1.4rc haven\u2018t anyother solution\uff1fand when time  tensorflow 1.5rc will be release\uff1f", "@Carmezim, to confirm, should we install CUDA v8 and cuDNN v6? Thank you for your help.", "That's correct. If any other doubts come up regarding requirements you can\nfind all information in the docs :)\n\n\nOn Tue, Oct 31, 2017, 4:31 PM warpdriv <notifications@github.com> wrote:\n\n> @Carmezim <https://github.com/carmezim>, to confirm, should we install\n> CUDA v8 and cuDNN v6? Thank you for your help.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14126#issuecomment-340819009>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/APwNCgDVEhFTVfi9AXcEtp6WAZQFJJeqks5sx0tfgaJpZM4QM56e>\n> .\n>\n", "Thank you for helping our friend @Carmezim. I think it's great this is going to be solved with the 1.5 release. Since this issue probably isn't actionable in the meantime, I'm going to close it out. Provided new information, I'll reopen.", "CUDA 9 builds do seem to work on both Mac and Linux as per #12052, Windows is the only OS it is failing for. It is not clear if this is a Tensorflow bug or an nvcc bug that can be worked around, t[he messages that are thrown](https://github.com/tensorflow/tensorflow/issues/12052#issuecomment-341887171) are very none helpful. "]}, {"number": 14125, "title": "[feature request] Does android tensorflow make the without considering front-camera and landscape mode ?  ", "body": "Fist bump.\r\nI want to make a tensorflow application available in landscape also, facing-mode \r\n\r\nBut, during the development- \r\nThere was a problem that  coordinates were displayed wrong when the front camera and landscape mode was used to detect the object, after inference\r\nDo you have  any reference code or other resources ?\r\n\r\nHave a nice day  :) ", "comments": ["finally i solved landscape and facing mode.\r\nIf you need help, just contact me :)\r\n![kakaotalk_20171102_142109456](https://user-images.githubusercontent.com/17498974/32311043-cb058284-bfd9-11e7-9f6c-b884460a6e5e.jpg)", "Glad to hear you were able to figure things out.  If there is a pull request you'd like to contribute to improve the demo app, please feel encouraged to do so.\r\n\r\nThanks!", "@nanamare how did you change the orientation to landscape? I'll be grateful if you can help me", "@nanamare how did you change the orientation to landscape? I'll be grateful  too, if you can help me.", "I have a problem. When I use the front camera for detection, the bounding box is displayed in the wrong position. How do I flip the box position to the right position?\r\n\r\nWhen I moved left to right, the bounding box moved right to left...", "> finally i solved landscape and facing mode.\r\n> If you need help, just contact me :)\r\n> ![kakaotalk_20171102_142109456](https://user-images.githubusercontent.com/17498974/32311043-cb058284-bfd9-11e7-9f6c-b884460a6e5e.jpg)\r\n\r\n@nanamare Could you help me handle this problem?\r\nI succeeded in detecting object, but I got opposite direction in tracking bounding box. ", "@jktruimp1  You can find a function \"private RectF upscaleRect(final RectF downsampledFrameRect)\" in ObjectTracker.java\r\nYou can try modify \r\n`return new RectF(\r\n        downsampledFrameRect.left * DOWNSAMPLE_FACTOR,`\r\n`        downsampledFrameRect.top * DOWNSAMPLE_FACTOR,`\r\n`        downsampledFrameRect.right * DOWNSAMPLE_FACTOR,`\r\n`        downsampledFrameRect.bottom * DOWNSAMPLE_FACTOR); `\r\nto\r\n   ` return new RectF(\r\n            frameWidth - (downsampledFrameRect.right * DOWNSAMPLE_FACTOR),`\r\n`            downsampledFrameRect.top * DOWNSAMPLE_FACTOR,`\r\n`            frameWidth - (downsampledFrameRect.left * DOWNSAMPLE_FACTOR),`\r\n`            downsampledFrameRect.bottom * DOWNSAMPLE_FACTOR);`\r\n\r\nIt's work for me when using front camera.", "@linlin860320 \r\nThanks you very much!\r\nI have found the solution, I changed trackpos in multiboxtracker.java.\r\nI will try your way on Monday :)", "@jktruimp1 \r\nThough my way can solve the problem, but I'm think my way is not really the right solution.\r\nSo could you share what you change in MutiBoxTracker?", "@linlin860320\r\nvariable trackpos or something named like it, I guess ", "@jktruimp1, @Nanamare can you help me? I have the same problem"]}, {"number": 14124, "title": "Update golang to 1.9.2 in `install_golang.sh`", "body": "This fix updates install_golang.sh to `1.9.2`, see release:\r\nhttps://golang.org/doc/devel/release.html#go1.9.minor\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 14123, "title": "Branch 174023371", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 14122, "title": "Access denied to download faster_rcnn_nas_17_10_2017.tar.gz trained on COCO from the network zoo found in object detection", "body": "Following is link on which it says the network is available to download\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\r\nBut when i click the link to download http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_17_10_2017.tar.gz\r\nit says access denied", "comments": ["Could you be looking at an older version of `detection_model_zoo.md`?\r\nIt seems the link was updated in https://github.com/tensorflow/models/commit/819de0e330b7026e21044b2bc3e96d8c1eed8820#diff-40f0678d6846e6efc7bd00fc93c826b8 to http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_24_10_2017.tar.gz ", "The commit wasn't made at the time I asked ... Thanks!!!"]}, {"number": 14120, "title": " Recover the lost output channel number of atrous convolution for NC format", "body": "Fix #13861.\r\n\r\n### How to test\r\n\r\n+ [x] add new test case\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "Hi, @ebrevdo , @drpngx .  May you take a look?", "Jenkins, test this please.", "I checked the failed log on python 3:  Timed out  //tensorflow/python/keras:data_utils_test. seems unrelated?\r\n\r\nAnd it runs well on my local machine:\r\n```bash\r\nINFO: Elapsed time: 405.959s, Critical Path: 77.96s\r\n//tensorflow/python/keras:data_utils_test                                PASSED in 4.0s\r\n\r\nExecuted 1 out of 1 test: 1 test passes.\r\n```", "Yes, it looks like a timeout. Let's try again.", "Now the master branch of tensorflow/tensorflow failed on both Linux CPU and mac CPU, perhaps it blocks the PR. I'll merge the upstream and test the PR again when its latest master branch passes all tests.", "Hi, might we retest the PR? Thanks very much.", "Jenkins, test this please", "Thanks, @jhseu. Could you restart the test?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Jenkins, test this please.", "Hi, I test the failed case on my linux machine (python 3), however it works.\r\n\r\n```bash\r\n(py36) [facai@h1077922 tensorflow]$ bazel test -c opt //tensorflow/contrib/learn:dnn_linear_com\r\nbined_test\r\nINFO: Elapsed time: 1038.011s, Critical Path: 377.41s\r\n//tensorflow/contrib/learn:dnn_linear_combined_test                      PASSED in 223.9s\r\n  Stats over 4 runs: max = 223.9s, min = 135.5s, avg = 167.4s, dev = 34.1s\r\n\r\nExecuted 1 out of 1 test: 1 test passes.\r\n```\r\n\r\nThe failure seems introduced by the master branch itself, right?", "Jenkins, test this please.", "Thank you, @yifeif. Do I need rebase the latest commit to make CLA check pass?", "Framework failure.\r\n\r\nJenkins, test this please.", "No, but @martinwicke can override and merge.", "So can @gunan I think.", "Thank you, @drpngx @gunan  !", "Thank you @gunan !"]}, {"number": 14119, "title": "fix broken link", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks @larrytin!"]}, {"number": 14118, "title": "How to print shape of tensors in tf.contrib.learn.Estimator", "body": "tf.contrib.learn.Estimator and tf.contrib.learn.Experiment  are very convenience to build a model. But how to debug the user defined model? For example, in the [Abalone Age Predictor example,](https://www.tensorflow.org/extend/estimators) how to print shape of 'first_hidden_layer', 'second_hidden_layer' and 'predictions' in user defined 'model_fn' function? \r\n\r\n It is easy to print  shape of tensors if we build a model with session, and an example is as follows:\r\n`a = tf.Variable(tf.zeros(shape=(2, 3, 4)))\r\nwith tf.Session() as sess:\r\n    print sess.run(tf.shape(a))`\r\n\r\nBy the way, I also tried to debug  [Abalone Age Predictor example,](https://www.tensorflow.org/extend/estimators) with tf.python.debug.LocalCLIDebugHook, but 'first_hidden_layer', 'second_hidden_layer' and 'predictions' are not in debug window.\r\n\r\nMany thanks in advance.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14117, "title": "Error in CMake generated build script", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0-rc1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: - (I use cmake)\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**: Notebook 1070 8G\r\n- **Exact command to reproduce**: \r\nUse cmake to generate build script for `Visual Studio 2017 Win64`\r\n`CMAKE_C_COMPILER`, `CMAKE_CXX_COMPILER` and `CUDA_HOST_COMPILER` should be set manually, otherwise, it will failed the compilation phase calling to NVCC\r\n\r\n\r\n### Describe the problem\r\nThis problem happens when building with Visual Studio 2017.4 + CUDA 9.0 + cuDNN 7 + CMake + GPU build.\r\n\r\nSorry for lack of information. I build it yesterday (and failed) and it take so long the compile through and I didn't keep the log. This problem is LINK ERRORs. What I can identify is they are in the generated build script. The problems happens exactly  in\r\n```\r\n_beam_search_ops.vcxproj\r\n_gru_ops.vcxproj\r\n_lstm_ops.vcxproj\r\n_nearest_neighbor_ops.vcxproj\r\n```\r\ne.g. in  `_beam_search_ops.vcxproj` around line 103\r\n```\r\n    <Link>\r\n      <AdditionalDependencies>\\pywrap_tensorflow_internal.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cudart_static.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cuda.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cublas.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cublas_device.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cufft.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\curand.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\extras\\CUPTI\\libx64\\cupti.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cusolver.lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64\\cudnn.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>\r\n      <AdditionalLibraryDirectories>%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>\r\n      <AdditionalOptions>%(AdditionalOptions) /machine:x64 /ignore:4049 /ignore:4197 /ignore:4217 /ignore:4221</AdditionalOptions>\r\n      <GenerateDebugInformation>false</GenerateDebugInformation>\r\n      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>\r\n      <ImportLibrary>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.lib</ImportLibrary>\r\n      <ProgramDataBaseFile>D:/workspaces/tensorflow/tensorflow/contrib/cmake/build/Release/_beam_search_ops.pdb</ProgramDataBaseFile>\r\n      <SubSystem>Console</SubSystem>\r\n    </Link>\r\n```\r\n\r\nYou can see a `\\pywrap_tensorflow_internal.lib` in `<AdditionalDependencies>` cause the LINK ERROR, since the linker can't find file `pywrap_tensorflow_internal.lib`.\r\n\r\nThe prefix **backslash** seems to be the cause. I suspect it should be some `${BLAH_env_VARIBALE}pywrap_tensorflow_internal.lib` and this `${BLAH_env_VARIBALE}` happens to be empty string and results to a `\\pywrap_tensorflow_internal.lib`.\r\n\r\nAll four `.vcxproj` files comes from function call `AddUserOps` in `tf_python.cmake` , where the `AddUserOps` is defined in `tf_cc_ops.cmake` file. Due to my poor eye sight, I can't decide where is the problem from here...\r\n\r\nNotice, I CAN see the file `pywrap_tensorflow_internal.lib` in some directory so it should be problem related with the path .", "comments": ["Unfortunately, we (TensorFlow maintainers) do not have enough expertise or bandwidth to support builds on Windows right now (as per https://www.tensorflow.org/install/install_sources - \"We don't officially support building TensorFlow on Windows; however, you may try to build TensorFlow on Windows if you don't mind using the highly experimental Bazel on Windows or TensorFlow CMake build.\").\r\n\r\nSo, I'm going to mark this as \"community support\", in the hope that someone with more familiarity with Windows and CMake builds can chime in.", "I've got the same error using CMake 3.10.3; the problem is in tf_cc_ops.cmake ([https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_cc_ops.cmake](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_cc_ops.cmake))\r\n\r\n```\r\nif (WIN32)\r\n  if(${CMAKE_GENERATOR} MATCHES \"Visual Studio.*\")\r\n    set (pywrap_tensorflow_lib \"${CMAKE_CURRENT_BINARY_DIR}/${CMAKE_BUILD_TYPE}/pywrap_tensorflow_internal.lib\")\r\n  else()\r\n    set (pywrap_tensorflow_lib \"${CMAKE_CURRENT_BINARY_DIR}/pywrap_tensorflow_internal.lib\")\r\n  endif()\r\nelse (WIN32)\r\n  set (pywrap_tensorflow_lib \"${CMAKE_CURRENT_BINARY_DIR}/libpywrap_tensorflow_internal.so\")\r\nendif (WIN32)\r\n```\r\nHere, the variable ${CMAKE_BUILD_TYPE} is undefined; therefore the path to pywrap_tensorflow_lib becomes \"${CMAKE_CURRENT_BINARY_DIR}//pywrap_tensorflow_internal.lib\"\r\n\r\nSome manual check, for example the one suggested in [https://cmake.org/pipermail/cmake/2008-September/023808.html](https://cmake.org/pipermail/cmake/2008-September/023808.html), should fix the problem.\r\n[edit] The fix in the above link will not work for MSVC though unless the value for ${CMAKE_BUILD_TYPE} actually matches the build configuration in MSVC.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/14117\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/14117\">No</a>\n"]}, {"number": 14116, "title": "py_func cannot handle Chinese string correctly", "body": "tensorflow: 1.3.0\r\n\r\nI write a simple code to split and concatenate utf8 string. However, I found that only English string works well on python 2.7. \r\n\r\n### script:\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\r\nimport tensorflow as tf\r\n\r\ndef test_string(x):\r\n    return u\"/\".join(x.split())\r\n\r\nstr_en = tf.py_func(\r\n        test_string,\r\n        [tf.constant(u\"hello, world\")],\r\n        tf.string)\r\n\r\nstr_zh = tf.py_func(\r\n        test_string,\r\n        [tf.constant(u\"\u4f60\u597d, \u4e16\u754c\")],\r\n        tf.string)\r\n\r\nwith tf.Session() as sess:\r\n    print(\"English:\")\r\n    print(sess.run(str_en))\r\n    print(\"Chinese:\")\r\n    print(sess.run(str_zh))\r\n```\r\n\r\n### logs\r\n\r\n#### python: 2.7\r\n\r\nsuccess for English, failed for Chinese.\r\n\r\n```python\r\n(py27) ~/Downloads \u276f\u276f\u276f python test.py\r\nEnglish:\r\nhello,/world\r\nChinese:\r\n2017-10-31 11:23:39.491876: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 23, in <module>\r\n    print(sess.run(str_zh))\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\r\n         [[Node: PyFunc_1 = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=\"pyfunc_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Const_1)]]\r\n\r\nCaused by op u'PyFunc_1', defined at:\r\n  File \"test.py\", line 17, in <module>\r\n    tf.string)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/script_ops.py\", line 203, in py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_script_ops.py\", line 36, in _py_func\r\n    name=name)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): exceptions.UnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\r\n         [[Node: PyFunc_1 = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=\"pyfunc_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Const_1)]]\r\n```\r\n\r\n#### python 3.5.2\r\n\r\nboth failed.\r\n\r\n```python\r\n~/Downloads \u276f\u276f\u276f python test.py\r\nEnglish:\r\n2017-10-31 11:24:52.706080: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: TypeError: sequence item 0: expected str instance, bytes found\r\nTraceback (most recent call last):\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\r\n    return fn(*args)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\r\n    status, run_metadata)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: sequence item 0: expected str instance, bytes found\r\n         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=\"pyfunc_0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Const)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 21, in <module>\r\n    print(sess.run(str_en))\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    options, run_metadata)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: sequence item 0: expected str instance, bytes found\r\n         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=\"pyfunc_0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Const)]]\r\n\r\nCaused by op 'PyFunc', defined at:\r\n  File \"test.py\", line 12, in <module>\r\n    tf.string)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 203, in py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_script_ops.py\", line 36, in _py_func\r\n    name=name)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/Users/facai/Library/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): TypeError: sequence item 0: expected str instance, bytes found\r\n         [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_STRING], token=\"pyfunc_0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Const)]]\r\n```", "comments": ["Your example will work if the `u` prefixes are removed from strings. An important thing to note is that `tf.py_func` needs to turn Python strings into tensors before calling the func. We have a byte string tensor but no unicode tensor.\r\n\r\nThings could still probably be improved on our end. It's likely we're forgetting to call compat.as_bytes() somewhere in our py_func implementation, which is causing Python's default behavior of crash-and-burn-if-not-ASCII to shine through. Assigning to @panyx0718 who might be able to help us.", "Thanks for your quick reply, @jart . The `u` prefixes is intended to show that `py_func` cannot handle unicode string correctly. \r\n\r\nI indeed find that byte string always works well:\r\n```python\r\ndef test_string(x):\r\n  x = x.decode(\"utf8\")\r\n  # res = do_something_on(x)\r\n  return res.encode(\"utf8\")\r\n```\r\nHowever, the workground really burdens users. It could be better if `py_func` can handle unicode string as well. Thank you.", "I agree @facaiy. While there is a workaround, this issue has still been triaged as a bug. Once we find the specific lines that need to be updated, it should be a relatively straightforward fix. I believe this kind of polishing is worth doing, because I can see how this could lead to mild frustration. I believe everyone should have positive experiences with TensorFlow and I'm grateful that you took the time to bring this to our attention.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Closing as this is resolved, feel free to reopen if problem persists."]}, {"number": 14115, "title": "Disable clang_format check.", "body": "Different clang_format version can cause different formats with the same style option. This check might be too strict. Disable for now.", "comments": ["@tensorflow-jenkins test this please", "Thanks @gunan!", "@yifeif @gunan Thanks for the fix.\r\n\r\nI didn't realize that different version's of clang-format renders different outputs. I will do some investigation and see if there are more reliable solutions for C++ style check.\r\n\r\nAgain,  thanks for the fix and sorry for the inconvenience caused by `clang_format`.", "No worries, and thanks for contributing @yongtang!\r\n"]}, {"number": 14114, "title": "Add apt-key for ubuntu keyserver", "body": "", "comments": ["In my env:\r\n`[root@rpi4 ~]# cat /etc/redhat-release \r\nCentOS Linux release 7.8.2003 (AltArch)\r\n[root@rpi4 ~]# uname -a\r\nLinux rpi4.sbibits.com 5.4.28-v8.1.el7 #1 SMP PREEMPT Mon Mar 30 21:28:10 UTC 2020 aarch64 aarch64 aarch64 GNU/Linux\r\n`\r\n I comment out the `apt-key adv --keyserver` line, it goes forward, otherwise will break the installation. Anyone else same with me?\r\n"]}]