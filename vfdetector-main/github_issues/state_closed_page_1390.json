[{"number": 11362, "title": "Allowing the PIP_TEST_ROOT variable to be set.", "body": "PiperOrigin-RevId: 161087696", "comments": []}, {"number": 11361, "title": "Feature Request: Change REGISTER_OP macro to facilitate customization on static initialization sequence", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: iOS\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.0\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: iPhone series\r\n- **Exact command to reproduce**: N/A\r\n\r\n### `REGISTER_OP` current syntax is not friendly for customization\r\n\r\n`REGISTER_OP` in its current implementation, which leverages C++ macro trick to do method-chaining is not friendly for customization. For example, a typical `REGISTER_OP` macro call looks like this:\r\n\r\n```\r\nREGISTER_OP(\"DynamicPartition\")\r\n\u00a0   .Input(\"data: T\")\r\n\u00a0   .Input(\"partitions: int32\")\r\n\u00a0   .Output(\"outputs: num_partitions * T\")\r\n\u00a0   .Attr(\"num_partitions: int\")\r\n\u00a0   .Attr(\"T: type\")\r\n    ....;\r\n```\r\n\r\nWhen implementing lazy initialization, this macro, comparing with others from TensorFlow (`REGISTER_KERNEL_BUILDER` for example) is more difficult to customize. The reason is that the macro doesn't capture subsequent method calls, therefore, cannot scope these method calls into a function unit. But, this is easy to solve if we change the `REGISTER_OP` syntax a bit:\r\n\r\n```\r\nREGISTER_OP(Op(\"DynamicPartition\")\r\n\u00a0   .Input(\"data: T\")\r\n\u00a0   .Input(\"partitions: int32\")\r\n\u00a0   .Output(\"outputs: num_partitions * T\")\r\n\u00a0   .Attr(\"num_partitions: int\")\r\n\u00a0   .Attr(\"T: type\")\r\n    ....);\r\n```\r\nThe above example is very close to how `REGISTER_KERNEL_BUILDER` works:\r\n```\r\nREGISTER_KERNEL_BUILDER(Name(\"NoOp\").Device(DEVICE_CPU), NoOp);\r\n```\r\nso we have some consistencies there.\r\n\r\nA hypothetic change to the `REGISTER_OP` macro could look like this:\r\n```\r\nstatic inline OpDefBuilderWrapper<true> Op(const char name[]) {\r\n    return OpDefBuilderWrapper<true>(name);\r\n}\r\n}  // namespace register_op\r\n\r\n#define REGISTER_OP(op) REGISTER_OP_UNIQ_HELPER(__COUNTER__, op)\r\n#define REGISTER_OP_UNIQ_HELPER(ctr, op) REGISTER_OP_UNIQ(ctr, op)\r\n#define REGISTER_OP_UNIQ(ctr, op)                                            \\\r\n  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \\\r\n      TF_ATTRIBUTE_UNUSED =                                                  \\\r\n          ::tensorflow::register_op::op;\r\n```\r\n\r\nMore importantly, this small change enabled some lazy initialization opportunities regarding ops registration, you can imagine a platform-specific change (not likely to get upstreamed) to this macro:\r\n\r\n```\r\n#define REGISTER_OP_UNIQ(ctr, op)                                            \\\r\n__attribute__((used)) static void register_op_init##ctr(void) {              \\\r\n  static ::tensorflow::register_op::OpDefBuilderReceiver register_op##ctr    \\\r\n      TF_ATTRIBUTE_UNUSED =                                                  \\\r\n          ::tensorflow::register_op::op;                                     \\\r\n}                                                                            \\\r\n__attribute__((used)) __attribute__((section (\"__DATA,tf_reg_op\"))) static void *register_op_func##ctr = (void *)&register_op_init##ctr\r\n```\r\n\r\nWhich put the static initializers into a function and a lazy initializer can call op registrations by scanning the data section and invoke these functions one by one.\r\n\r\nPlease let me know if this will violate some core assumptions TensorFlow is making and your concerns.", "comments": ["@josh11b, this seems like deep C Macro wizardry. Are there design considerations that make @liuliu 's request difficult?", "Sorry for the slow response, it took me a while to remember the background here. There was a reason why we did it that way: we actually started with something similar to what you describe but we found out that it triggered a bug in some version of gcc.  In particular, we found that gcc had a problem with raw string literals passed to macros, which was an issue for our doc strings.", "@josh11b thank you for the explanation. That makes a lot of sense now. Do you have any suggestions on how to move these static initializers to other places besides the macro changes? Alternatively, I can scan the REQUIRE_OP function, and move all of them into a different method.", "@annarev has move the doc strings out of the op registration, so this is now more viable. It would however be a quite disruptive change with limited benefit.", "@josh11b perhaps you can make a call as to whether we'll attempt this change (or accept \"contributions welcome\"), or if it just doesn't seem worth it?", "Thank you! Yes, if you guys can accept the contribution, I can prepare the patch.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 11360, "title": "add h5py to dockerfile", "body": "Add h5py to dockerfile. Fixes #11356", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Fixed as requested. The list wasn't alphabetical to start with, so I fixed that too.", "Thanks, @yhenon ", "PR merged. The changes will take effect in the tensorflow/tensorflow release images after the next release and in the tensorflow/tensorflow:nightly* images after the next nightly build."]}, {"number": 11359, "title": "Feature : Multi-dimensional input in LSTM", "body": "Current input format for RNN Cell (ie LSTM) is\r\n```\r\n        (batch_size, Sequence_length)\r\n\r\n        cell_fn = gr iid_rnn.Grid2LSTMCell\r\n        additional_cell_args.update({'use_peepholes': True, 'forget_bias': 1.0})\r\n        cell = cell_fn(args.rnn_size, **additional_cell_args)\r\n        self.cell = cell = rnn_cell.MultiRNNCell([cell] * args.num_layers)\r\n        self.input_data =    tf.placeholder(tf.int32, [args.batch_size, args.seq_length])\r\n```\r\nit would be useful to have multi-dimensionnal input as below : \r\n\r\n`        (batch_size, Sequence_length, extra_dim1)`\r\n\r\n\r\n", "comments": ["What does the extra_dim1 argument do? You haven't modified any of the rest of the code, so I don't see how it should affect the operation of the LSTM cells. Can you not just fold it into the batch dimension?", "Lets example of CNN input:\n\n(Nbsample,  X, Y, Z)\nX, Y: 2D\nZ: color depth\nNbSample: nb of sample\n\nWe wish to add one more dimension in LSTM input (ex: to represent color depth).\n\n\nRegards\nKevin\n\n\n\n\n\n\n\n\n\n\nOn 8 Jul 2017, at 09:38, Cliff Young <notifications@github.com> wrote:\n\nWhat does the extra_dim1 argument do? You haven't modified any of the rest of the code, so I don't see how it should affect the operation of the LSTM cells. Can you not just fold it into the batch dimension?\n\n\u2015\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n", "So is it that you want a 3D grid LSTM cell? Or is it that you still want a 2D cell, but there's some way in which the num_units argument of the 2D cell doesn't meet your needs? \r\n\r\n(and my apologies if I'm just not getting it--I'm a systems person more than an NN person). ", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "Any updates on this? Seems like a useful feature to me."]}, {"number": 11358, "title": "Update README.md", "body": "Update readability in example, replaced HTTP link to HTTPS links, and added a link", "comments": ["Can one of the admins verify this patch?", "@wolffg Is there anything else I should change, or can this be merged now?", "I added a PR to change the last link to https://www.tensorflow.org/community/welcome, as the other link 404s.", "Jenkins, test this please"]}, {"number": 11357, "title": "Alpha Dropout", "body": "Fixes #10612", "comments": ["Can one of the admins verify this patch?", "New functions like this should go into contrib.  I think we have a tf.contrib.nn?  I'd put it there.", "The documentation for `tf.contrib.nn` says that \"Module for deprecated ops in tf.nn.\". Is that the correct place? or `tf.contrib.layers`?", "@ebrevdo BTW, did you mean to remove this function from `nn_ops.py` and add to `contrib` or add to both places? ", "I meant to move it there.  And you can remove the deprecated word of the\ndoc... New nn ops can go there too.\n\nOn Jul 7, 2017 1:40 PM, \"Anish Shah\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> BTW, did you mean to remove this\n> function from nn_ops.py and add to contrib or add to both places?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11357#issuecomment-313787642>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim5T2rAGx0zEQyaMDW7NBarVXvjkzks5sLpfOgaJpZM4ORMHQ>\n> .\n>\n", "ping for @AnishShah !", "I will update this in a day. Sorry for the delay.", "I have updated the PR. Please review.", "What's happening here?", "@vrv Sorry about that. I have changed that.", "@tensorflow-jenkins test this please", "The build was aborted. Can you run the tests again?", "The build was aborted because the sanity checks failed -- can you look at the logs here to see what went wrong?\r\n\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/5565/consoleFull", "There was some problem with BUILD file. I have fixed it. Please run the tests again.", "@tensorflow-jenkins test this please", "`//tensorflow/contrib/opt:drop_stale_gradient_optimizer_test              FAILED in 4.8s` - This test failed for Linux CPU Tests \r\n\r\nI don't think this is related to my changes. ", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 11356, "title": "Cannot run example in tensorflow docker due to missing dependency", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: running in official docker container\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: 2.7\r\n- **CUDA/cuDNN version**: CUDA 8.0\r\n- **GPU model and memory**: Titan X\r\n- **Exact command to reproduce**:\r\n`docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow`\r\n\r\n### Describe the problem\r\nThe official tensorflow docker container does not include h5py. This might be intentional?\r\n\r\nHowever, this breaks an example:\r\n- tensorflow/tensorflow/examples/learn/hdf5_classification.py\r\n\r\nThis also causes a number of contrib methods to raise exceptions:\r\n- tensorflow/tensorflow/contrib/learn/python/learn/learn_io/data_feeder_test.py\r\n- a numbert of keras.contrib files\r\n", "comments": ["@caisq can you please comment on whether leaving h5py might be intentional?", "@cy89, @yhenon No, leaving h5py out from the dockerfiles is not intentional. Nobody has requested it so far. I'm fine with adding it. Feel free to send a pull request to add h5py to the following Dockerfiles:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.gpu\r\n"]}, {"number": 11355, "title": "Use pretrained model VGG16 for android app (demo example)", "body": "I download demo example which uses tensorflow_inception_graph.pb from the google tensorflow download page.\r\n\r\nWhat I want to do is to replace it with vgg_16.pb. (The same demo app, only difference is the model')\r\n\r\nBut I need a help for replacing those with new ones.\r\n\r\nIn ClassifierActivity.java (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)\r\n\r\n  ```\r\nprivate static final int **INPUT_SIZE** = 224; ==> 224\r\n  private static final int **IMAGE_MEAN** = 117; ==> ?\r\n  private static final float **IMAGE_STD** = 1; ==> ?\r\n  private static final String **INPUT_NAME** = \"input\";\r\n  private static final String **OUTPUT_NAME** = \"output\";\r\n\r\n  private static final String MODEL_FILE = \"file:///android_asset/tensorflow_inception_graph.pb\"; ==>changing the file \r\n  private static final String **LABEL_FILE** =\r\n      \"file:///android_asset/imagenet_comp_graph_label_strings.txt\";  ==> reusing it. Is it ok? (vgg16 is also trained with imagenet data)\r\n```\r\n\r\nI want to replace \"tensorflow_inception_graph.pb\" with \"vgg_16.pb\"\r\n\r\nFor that, I followed those step\r\n1. converting ckpt to pbtxt\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nfrom nets.vgg import vgg_16, vgg_arg_scope\r\nimport numpy as np\r\n\r\nheight = 224\r\nwidth = 224\r\nchannels = 3\r\n\r\n# Create graph\r\nX = tf.placeholder(tf.float32, shape=[None, height, width, channels])\r\nwith slim.arg_scope(vgg_arg_scope()):\r\n        logits, end_points = vgg_16(X, num_classes=1000, is_training=False)\r\npredictions = end_points[\"vgg_16/fc8\"]\r\nsaver = tf.train.Saver()\r\n\r\nX_test = np.ones((1,224,224,3))\r\n\r\nwith tf.Session() as sess:\r\n        saver.restore(sess,\"./vgg_16.ckpt\")\r\n        predictions_val = predictions.eval(feed_dict={X: X_test})\r\n        tf.train.write_graph(sess.graph_def, './', 'vgg_16.pbtxt')\r\n```\r\n2. creating pb file \r\n`python [../../../../]tensorflow/tensorflow/python/tools/freeze_graph.py --input_graph=./vgg_16.pbtxt --input_checkpoint=./vgg_16.ckpt --output_graph=./vgg_16.pb --output_node_names=vgg_16/fc8/squeezed`\r\n\r\n3. Finding input, output \r\n```\r\n\r\nimport tensorflow as tf\r\nimport os\r\nimport numpy as np\r\nfrom tensorflow.python.platform import gfile\r\n\r\nwith gfile.FastGFile(\"./vgg_16.pb\",'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    tf.import_graph_def(graph_def, name='')\r\n\r\n[n.name + '=>' +  n.op for n in graph_def.node if n.op in ( 'Softmax','Placeholder', 'Squeeze')]\r\n```\r\n`[u'Placeholder=>Placeholder', u'vgg_16/fc8/squeezed=>Squeeze']`\r\n\r\n```\r\nwith tf.Session() as sess:\r\n    input_x = sess.graph.get_tensor_by_name(\"Placeholder:0\")\r\n    print input_x\r\n    input_x = sess.graph.get_operation_by_name(\"Placeholder\")\r\n    print input_x\r\n    out = sess.graph.get_tensor_by_name(\"vgg_16/fc8/squeezed:0\")\r\n    print out\r\n    output = sess.graph.get_operation_by_name(\"vgg_16/fc8/squeezed\")\r\n    print output\r\n```\r\n```\r\nTensor(\"Placeholder:0\", dtype=float32)\r\nname: \"Placeholder\"\r\nop: \"Placeholder\"\r\nattr {\r\n  key: \"dtype\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"shape\"\r\n  value {\r\n    shape {\r\n    }\r\n  }\r\n}\r\n\r\nTensor(\"vgg_16/fc8/squeezed:0\", shape=(?, 1000), dtype=float32)\r\nname: \"vgg_16/fc8/squeezed\"\r\nop: \"Squeeze\"\r\ninput: \"vgg_16/fc8/BiasAdd\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"squeeze_dims\"\r\n  value {\r\n    list {\r\n      i: 1\r\n      i: 2\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nBut why input and output is not kind of demo codes. Do I change it to \r\n```\r\n  private static final String **INPUT_NAME** = \"input\"; ==> \"Policeholde\"\r\n  private static final String **OUTPUT_NAME** = \"output\"; ==> \"vgg_16/fc8/squeezed\"\r\n```\r\n\r\n4. Last one. the size of \r\n  eventhough I run the script. the size is not changed much.. Still big 553MB\r\n`python ../../../../tensorflow/tensorflow/python/tools/optimize_for_inference.py --input=./inception_v3.pb --output=./vgg_16.pb --input_names= ? --output_names=vgg_16/fc8/squeezed`\r\n\r\n```\r\n553440161 Jul  7 16:06 optimized_graph_vgg_16.pb\r\n553444585 Jul  7 09:46 vgg_16.pb\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11354, "title": "Remove unnecessary empty BUILD file (DO NOT MERGE)", "body": "", "comments": []}, {"number": 11353, "title": "small update to partial_run_setup", "body": "leaving out the \"feeds\" argument for partial_run_setup produced an error due to the default being None. Passing an empty list as \"feeds\" fixed the problem so make this the default.", "comments": ["Can one of the admins verify this patch?", "@JKurland thanks for the pull request. Can you add a unit test (in `session_test.py`) for this fix?", "should I add a test to session_test.py or session_partial_run_test.py?", "@JKurland , please add the test to `session_partial_run_test.py`. I didn't realize that the partial-run tests have been split out in https://github.com/tensorflow/tensorflow/commit/7ed44f4c92c1553c0cefb607ce8a17b7d85f326f\r\n\r\nThanks.", "No problem, haven't done a unit test before, is this the sort of thing?\r\nhttps://github.com/tensorflow/tensorflow/pull/11381", "sorry, made a mistake in that one, here\r\nhttps://github.com/tensorflow/tensorflow/pull/11382", "@JKurland can you include the changes to session.py and session_partial_run_test.py in one pull request instead of two?", "@JKurland ping for update?  The same PR should include both the fix and the test. Thanks for the contribution!", "@JKurland could you please add a test for your fix? Thanks.", "Closing this out in favor of #11382 which includes both the change and the test."]}, {"number": 11352, "title": " Ran out of memory when running ROLO on tensorflow", "body": "Hello,\r\n\r\nEnvironment : ubuntu 14.04, Nvidia 740M 2Gb, 8Gb RAM, Cuda 7.5, TF 0.8.0\r\n\r\n`I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\r\nROLO init\r\nUtils init\r\nself.cfgPath=\r\nDefault: running ROLO test.\r\nBuilding ROLO graph...\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \r\nname: GeForce GT 740M\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 1.0325\r\npciBusID 0000:0a:00.0\r\nTotal memory: 1.96GiB\r\nFree memory: 1.81GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 1.00G (1073741824 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 921.60M (966367744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 829.44M (869731072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nLoading complete!\r\n\r\n('TESTING ROLO on video sequence: ', 'Human2')\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:0a:00.0)\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256): \tTotal Chunks: 1, Chunks in use: 0 256B allocated for chunks. 24B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0 96.2KiB allocated for chunks. 96.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0 442.5KiB allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 513.50MiB was 256.00MiB, Chunk State: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0000 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015c0100 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0200 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0300 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0400 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0500 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015d0600 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8700 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8800 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015e8900 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8a00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x5015f8b00 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610c00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610d00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610e00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501610f00 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501611100 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629300 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501629400 of size 65792\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501639500 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611000 of size 256\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501611200 of size 98560\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x501651600 of size 453120\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x501dc0000 of size 1073741824\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x541dc0000 of size 704482304\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size: \r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 14 Chunks of size 256 totalling 3.5KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 65792 totalling 192.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 98560 totalling 288.8KiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 704482304 totalling 671.85MiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1073741824 totalling 1.00GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.66GiB\r\nI tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats: \r\nLimit:                  1739522048\r\nInUse:                  1778720768\r\nMaxInUse:               1778819584\r\nNumAllocs:                      37\r\nMaxAllocSize:           1073741824\r\n\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:270] *******************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxx*******************************xxxxxxxxx\r\nW tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 513.50MiB.  See logs for memory state.\r\nW tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[8204,16408]\r\nTraceback (most recent call last):\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <module>\r\n    main(' ')\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\r\n    ROLO_TF(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 93, in __init__\r\n    self.ROLO(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 267, in ROLO\r\n    self.testing(x_path, y_path)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 157, in testing\r\n    sess.run(init)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\r\n    e.code)\r\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[8204,16408]\r\n\t [[Node: RNN/LSTMCell/W_0/Initializer/random_uniform/mul = Mul[T=DT_FLOAT, _class=[\"loc:@RNN/LSTMCell/W_0\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/LSTMCell/W_0/Initializer/random_uniform/RandomUniform, RNN/LSTMCell/W_0/Initializer/random_uniform/sub)]]\r\nCaused by op u'RNN/LSTMCell/W_0/Initializer/random_uniform/mul', defined at:\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 276, in <module>\r\n    main(' ')\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 272, in main\r\n    ROLO_TF(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 93, in __init__\r\n    self.ROLO(argvs)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 236, in ROLO\r\n    self.build_networks()\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 125, in build_networks\r\n    self.lstm_module = self.LSTM_single('lstm_test', self.x, self.istate, self.weights, self.biases)\r\n  File \"./experiments/testing/ROLO_network_test_all.py\", line 108, in LSTM_single\r\n    outputs, state = tf.nn.rnn(cell, [_X[step]], state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 143, in rnn\r\n    (output, state) = call_cell()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 136, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 352, in __call__\r\n    dtype, self._num_unit_shards)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 216, in _get_concat_variable\r\n    sharded_variable = _get_sharded_variable(name, shape, dtype, num_shards)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 246, in _get_sharded_variable\r\n    dtype=dtype))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable\r\n    collections=collections)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable\r\n    collections=collections, caching_device=caching_device)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable\r\n    dtype=variable_dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 275, in _init_from_args\r\n    self._initial_value = ops.convert_to_tensor(initial_value(),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 149, in <lambda>\r\n    init_val = lambda: initializer(shape.as_list(), dtype=dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py\", line 200, in _initializer\r\n    dtype, seed=seed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.py\", line 183, in random_uniform\r\n    return math_ops.add(rnd * (maxval - minval), minval, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 518, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1039, in mul\r\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\r\n    self._traceback = _extract_stack()`", "comments": ["Can you try this with the latest release of TF, please? ", "Good evening,\n\nOK I'll try it w and tell you the result of course.\n\nOn 7 Jul 2017 17:36, \"Cliff Young\" <notifications@github.com> wrote:\n\n> Can you try this with the latest release of TF, please?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11352#issuecomment-313730907>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AacoydQW-GW6N2s88BZYzGyoXOUoSXCJks5sLl56gaJpZM4ORACY>\n> .\n>\n", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11351, "title": "transform_graph quantize_weights doesn't compile on windows", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nI'm executing a command from documentation, and I don't think that my custom model is part of the issue.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nWindows Server 2012 R2 64-bit\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nLatest master (7/7/2017) compiled with bazel and msvc\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\ncommit 1e037850f1a (July 6 21:55:34 2017 -0400)\r\n\r\n- **Python version**: \r\n\r\n3.5.3 Anaconda 64-bit\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\n0.5.1\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\nCPU Only\r\n\r\n- **GPU model and memory**:\r\n\r\nCPU Only (CPU is dual socket Xeon E5-2687W v2)\r\n\r\n- **Exact command to reproduce**:\r\n```\r\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nquantize_weights'\r\n```\r\n\r\n### Describe the problem\r\n\r\nI originally asked this question on StackOverflow and I was recommended to file a bug report:\r\n\r\nhttps://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights\r\n\r\nThe `transform_graph` program in tensorflow does not include the `quantize_weights` transform. If I execute the command above without the `quantize_weights` transform it works correctly.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nquantize_weights'\r\n```\r\n```\r\n2017-07-06 13:21:10.361492: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_constants\r\n2017-07-06 13:21:10.476001: W C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-06 13:21:13.241688: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_batch_norms\r\n2017-07-06 13:21:16.088969: I C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:263] Applying fold_old_batch_norms\r\n2017-07-06 13:21:16.650913: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:209] Transform 'quantize_weights' not recognized.\r\n2017-07-06 13:21:16.650934: E C:\\tools\\msys64\\tmp\\_bazel_name\\avtc4yfu\\execroot\\tensorflow\\tensorflow\\tools\\graph_transforms\\transform_graph.cc:210] usage: C:\\Users\\name\\git-repos\\tensorflow\\bazel-bin\\tensorflow\\tools\\graph_transforms\\transform_graph.exe\r\nFlags:\r\n        --in_graph=\"\"                           string  input graph file name\r\n        --out_graph=\"\"                          string  output graph file name\r\n        --inputs=\"\"                             string  inputs\r\n        --outputs=\"\"                            string  outputs\r\n        --transforms=\"\"                         string  list of transforms\r\n        --output_as_text=false                  bool    whether to write the graph in text protobuf format\r\n\r\nTransforms are:\r\nadd_default_attributes\r\nbackport_concatv2\r\nbackport_tensor_array_v3\r\nfold_batch_norms\r\nfold_constants\r\nfold_old_batch_norms\r\nfreeze_requantization_ranges\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\ninsert_logging\r\nobfuscate_names\r\nremove_attribute\r\nremove_device\r\nremove_nodes\r\nrename_attribute\r\nrename_op\r\nset_device\r\nsort_by_execution_order\r\nsparsify_gather\r\nstrip_unused_nodes\r\n```\r\n", "comments": ["I am also facing the same problem. \r\n@MaxBareiss did you find any solution for this?", "@petewarden Is the support for quantize_weights and quantize_nodes available for windows now? or whether will be available sometime in near future? :)", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This bug has been open for quite a while, and I haven't been able to work on it, so I'm adding \"Contributions Welcome\" and removing myself as the assignee. As far as I know, the main barriers to porting to Windows are the threading calls that gemmlowp relies on."]}, {"number": 11350, "title": "MonitoredTrainingSession to have accessible summary writer.", "body": "**Tensorflow version: 1.2.1**\r\n\r\nI am using `MonitoredTrainingSession` extensively to train models, and for the most part does exactly what I want it to do. However, I would like to be able to extract (or pass in) a `FileWriter` object so I can report other summaries from inside my evaluation routines. This is because only one` FileWriter` can write to the events log:\r\n\r\nAt the moment, this is the best workaround I can do:\r\n\r\n```python\r\nsess = tf.train.MonitoredTrainingSession(\r\n       ...\r\n    )\r\n\r\n# HACK: this is so we use the same summary writer obj for both summaries, only way to do it.\r\nsummary_writer = sess._hooks[1]._summary_writer\r\n```\r\n\r\nThen I can use the `summary_writer` to manually report summaries in the evaluation part of my code:\r\n\r\n```python\r\nmean_test_loss = ...\r\nsummary = tf.Summary(value=[\r\n    tf.Summary.Value(tag='mean_test_loss', simple_value=mean_test_loss)\r\n])\r\nsummary_writer.add_summary(summary, current_step)\r\n\r\n```\r\n\r\nIt would be nice to have a non-hacky way to get the `summary_writer` from the session so only one `FileWriter` writes to the events file.\r\n\r\nOne thought I had is to have a `FileWriter` object as part of the `Scaffold` that is used to build the session. That way anyone can get hold of the scaffold and use the one `summary_writer` designated to write to the events log.\r\n\r\nI would be happy to help implementing this if other people are interested.\r\n\r\n", "comments": ["You can use `SummaryWriterCache`. (`from tensorflow.python.training.summary_io import SummaryWriterCache`).\r\n\r\nThis is what the [basic session hooks](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/training/basic_session_run_hooks.py) use.", "@coopie It sounds fine for me, and the workaround is make sense. What is the progress of the implementation? If you want, I can send a PR to implement the feature. It's good if you would like do me a favor. ", "@vierja  Could you give example? I have a problem adding summary operation with MonitoredTrainingSession.", "@spk921 Here's how I did it:\r\n\r\n```python\r\nsess = tf.train.MonitoredTrainingSession(master=self.server.target, is_chief=(self.wid == 0),\r\n                                         checkpoint_dir=SUMMARY_DIR,\r\n                                         save_summaries_steps=None, save_summaries_secs=None, hooks=hooks)\r\n\r\nwriter = SummaryWriterCache.get(SUMMARY_DIR)\r\n```\r\n\r\nwhere `SUMMARY_DIR` is the path to your summary directory", "@Anjum48 Could you provide the link to the above code? ", "@spk921 Here's a link to a working version of DeepMind's DPPO algorithm using the above code https://github.com/Anjum48/rl-examples/blob/master/dppo/dppo.py#L283", "Closing this issue since there is a working solution"]}, {"number": 11349, "title": "Fix misspells :)", "body": "Fix misspells on comments.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 11348, "title": "The order in which tensorflow libraries are loaded leads to segmentation fault", "body": "I have a simple java code below.Running this code produces a core dump.\r\ni am running this on debian/8 jessie system. I use tensorflow 1.2.1.\r\nThe same code works fine in mac osx but has problems when we run the same  in Linux.\r\nWhen the code is changed to load tensorflow libraries before rocksdb library it works fine on all platforms.\r\n\r\npackage com.test.tensorflow;\r\n\r\nimport org.rocksdb.RocksDB;\r\nimport org.rocksdb.RocksDBException;\r\nimport org.tensorflow.SavedModelBundle;\r\nimport org.tensorflow.Session;\r\nimport org.tensorflow.Tensor;\r\n\r\npublic class TestTensorFlow {\r\n\r\n\tpublic static void main(String[] args){\r\n\t\t\r\n\t\t System.out.println(\"before loading..\" + System.getProperty(\"java.io.tmpdir\"));\r\n\t\t\r\n\t\t\r\n\t\t RocksDB.loadLibrary();\r\n\t\t try {\r\n\t\t\tRocksDB db =RocksDB.open(\"/tmp/rocksdelete\");\r\n\t\t\tdb.close();\r\n\t\t} catch (RocksDBException e) {\r\n\t\t\t// TODO Auto-generated catch block\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t\t \r\n\t\t SavedModelBundle smb = SavedModelBundle.load(\"test-model\", \"serve\");\r\n\t\t Session tfSession = smb.session();\r\n\t\t System.out.println(\"loaded\");\r\n\r\n\t}\r\n}\r\n", "comments": ["I'm sorry not to be super helpful, but official support covers Ubuntu and CentOS. It'd be awesome if there were other Debian users who could offer help. ", "Automatically closing due to lack of recent activity. Please open a new issue if this persists with the latest tensorflow version.\r\n"]}, {"number": 11347, "title": "[Doc] tf.abs + complex numbers", "body": "TF 1.2.0\r\n\r\n`tf.abs` already supports complex numbers but this is not documented.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/abs", "comments": ["Do you have a suggestion for how you'd like it to read, or do you want to submit a PR with a specific fix?", "Dupe of #9827?", "Yes, this is a dupe."]}, {"number": 11346, "title": "Improve examples for Python 3 compatibility", "body": "This PR improves examples in docstrings for Python 3 compatibility.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 11345, "title": "//tensorflow/python:nn_test is failing on Windows", "body": "https://ci.tensorflow.org/job/tf-master-win-bzl/1218/consoleFull\r\n```\r\n18:54:32 INFO: From Testing //py_test_dir/tensorflow/python:nn_test:\r\n18:54:32 ==================== Test output for //py_test_dir/tensorflow/python:nn_test:\r\n18:54:32 ......................................F...........\r\n18:54:32 ======================================================================\r\n18:54:32 FAIL: testOutput4DInput123 (__main__.MomentsTest)\r\n18:54:32 ----------------------------------------------------------------------\r\n18:54:32 Traceback (most recent call last):\r\n18:54:32   File \"\\\\?\\c:\\temp\\Bazel.runfiles_nwtmklpc\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\ops\\nn_test.py\", line 878, in testOutput4DInput123\r\n18:54:32     self.doOutputTest((10, 10, 10, 30), (1, 2, 3))\r\n18:54:32   File \"\\\\?\\c:\\temp\\Bazel.runfiles_nwtmklpc\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\ops\\nn_test.py\", line 854, in doOutputTest\r\n18:54:32     self.assertAllClose(variance, expected_var, rtol=tol, atol=tol)\r\n18:54:32   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 660, in assertAllClose\r\n18:54:32     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)\r\n18:54:32   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 630, in _assertArrayLikeAllClose\r\n18:54:32     np.testing.assert_allclose(b, a, rtol=rtol, atol=atol, err_msg=msg)\r\n18:54:32   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 1411, in assert_allclose\r\n18:54:32     verbose=verbose, header=header, equal_nan=equal_nan)\r\n18:54:32   File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\testing\\utils.py\", line 796, in assert_array_compare\r\n18:54:32     raise AssertionError(msg)\r\n18:54:32 AssertionError: \r\n18:54:32 Not equal to tolerance rtol=0.0001, atol=0.0001\r\n18:54:32 None\r\n18:54:32 (mismatch 100.0%)\r\n18:54:32  x: array([[[[ 0.000834]]],\r\n18:54:32 \r\n18:54:32 ...\r\n18:54:32  y: array([[[[ 0.001117]]],\r\n18:54:32 \r\n18:54:32 ...\r\n```", "comments": ["Possible culprit: https://github.com/tensorflow/tensorflow/commit/eccd162119675d0bf5bc6f8e6a93dcda7ab6db4a", "@ekelsen any chance this is related to recent changes to the moments calculation?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly."]}, {"number": 11344, "title": "can't find some header files when i'm using c/c++ API, eg: tensorflow/core/example/example.pb.h", "body": "TF version 1.1.0      ubuntu 14.04 ,    install by pip \r\nIn many examples about c or c++ API in tensorflow, i can find some codes like:\r\n\r\n#include \"tensorflow/core/example/example.pb.h\"\r\n#include \"tensorflow/core/example/feature.pb.h\"\r\n#include \"tensorflow/core/framework/graph.pb_text.h\"\r\n\r\nbut in the folder where tensorflow is intalled, i can't find these file, someone knows why?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nThat said, note that the `pip` installation is for Python (`pip` is a python package manager). For now, to use the C++ API you need to build from source. See for example [related StackOverflow questions](https://stackoverflow.com/questions/33620794/how-to-build-and-use-google-tensorflow-c-api/43920376#43920376) or the C++ [label_image example README](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image).\r\n\r\nInstallation for some other language bindings like C, Java, Go and community supported C#, Rust, Haskell etc. might be easier if those work for you. See https://www.tensorflow.org/install/ and https://www.tensorflow.org/api_docs/", "am i must install tensorflow from source, using **.proto to generate **.pb.h and **.cc ?"]}, {"number": 11343, "title": "Does tensorflow support mfcc now?", "body": "Is mfcc support in tensorflow now? I found this https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mfcc.h\r\n\r\nbut I can't find this op in Python API in tensorflow. \r\n\r\nSo is that not open yet? Or it's wrapped in some other Python api?", "comments": ["Closing this as a duplicate of #11339. Let's continue discussion there.\r\n"]}, {"number": 11342, "title": "Fixed typo in docstring", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11341, "title": "Feature request: Add float16 support for Conv3D, MaxPool3D and AvgPool3D ops", "body": "Support for `tf.float16 dtype` was added ([#1300](https://github.com/tensorflow/tensorflow/issues/1300)) to a bunch of ops. Can we add it for conv3d too, please?\r\n\r\nconv3d is important to development of videos and medical images systems. Since both consumes a lot of memory, it would be good to have fp16 support to allow deeper models.", "comments": ["@sesse and @benoitsteiner could you comment on plans for further fp16 support, please?", "@cy89 I left Google over a year ago, so I'm not involved in this anymore.", "Thanks, @sesse; sorry I didn't know.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Looks like #12832 was merged, which (I believe) resolves this issue.  If I'm mistaken, just ping this issue and I'll re-open.", "Hi @tatatodd \r\n\r\n#12832 did not implemented support for MaxPool3D and AvgPool3D ops with half type. Would you please consider re-open this issue?", "When I set dtype to float16 for a model with Conv3D layers, I get the following errors \r\n_ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"spatial_stream_Conv3d_1a_7x7_conv/kernel/read:0\", shape=(7, 7, 7, 3, 64), dtype=float16)'\r\nTypeError: Input 'filter' of 'Conv3D' Op has type float16 that does not match type float32 of argument 'input'._\r\n\r\nSo it seems like fp16 is still not supported for Conv3D operations. It would be very welcome if this will be implemented with the current rise of mixed- and low precision GPUs."]}, {"number": 11340, "title": "Adapt TensorFlowTestCase.setUp() to new reset_default_graph() semantics", "body": "Avoid calling reset_default_graph() directly to prevent exceptions in\r\ncases where test methods error out from within nested graph contexts,\r\nwhich can leave _default_graph_stack non-empty in certain Python\r\nversions.\r\n\r\nThis should address the test failures (tensorflow/python:session_test and tensorflow/contrib/session_bundle:exporter_test) introduced by #11158 in certain Python versions (e.g., Mac Python 3.5).\r\ncc @Thenerdstation", "comments": ["This should address the test failures (tensorflow/python:session_test and tensorflow/contrib/session_bundle:exporter_test) introduced by #11158 in certain Python versions (e.g., Mac Python 3.5). \r\ncc @Thenerdstation", "Thank you for figuring this out! I wonder why it was Mac only.\r\n\r\nCan we call reset default graph after resetting the stack?", "@drpngx This is not only \"mac-only\". This seems to be \"mac + python 3.5 only\", because python 2.7 and 3.6 don't cause those tests to fail on mac.\r\n\r\nCalling reset_default_graph() after calling reset() on the stack seems redundant?", "Yeah I was just thinking that \ud83d\ude0b\n\nOn Jul 6, 2017 8:40 PM, \"Shanqing Cai\" <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> This is not only \"mac-only\". This\n> seems to be \"mac + python 3.5 only\", because python 2.7 and 3.6 don't cause\n> those tests to fail on mac.\n>\n> Calling reset_default_graph() after calling reset() on the stack seems\n> redundant?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11340#issuecomment-313579109>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_Sbd1tJK1gtqRt6FcH5dira-COYj4Sks5sLajGgaJpZM4OQci2>\n> .\n>\n", "@drpngx Actually on second thought, I think calling reset_default_graph() after reset() is a good idea. reset_default_graph() may do extra things in the future. Calling it gets rid of the need to track those future changes here. I made some further revision to add that and to make the comments clearer.", "Merging to fix nightlies.", "@mrry We can continue investigating whether there is a bug in the stack finally blocks.", "Ack, merging was the right way to go... I've looked in the implementation of `contextlib.py` for Python [3.5](https://github.com/python/cpython/blob/3.5/Lib/contextlib.py) and [3.6](https://github.com/python/cpython/blob/3.6/Lib/contextlib.py). While there are some small diffs, I can't see anything that looked relevant. My hunch is that there's something special about `RuntimeError` (since it gets used internally in the `contextlib` implementation), but I didn't find a smoking gun."]}, {"number": 11339, "title": "Implement Audio Ops for Python Client", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.10.5\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.5.2\r\n\r\nThere are some very useful audio operations defined in tensorflow/core/ops/audio_ops.cc. It would be great if python client users could access these by default. ", "comments": ["@petewarden would know about any plans for the state of these operations and whether they can be made available in the Python API", "@Abhipray @petewarden FYI I have recently [begun](../compare/master...andykernahan:wav-op-fixes) work on this. There are a couple of outstanding tasks:\r\n* Add tests for the `audio_ops.py`\r\n* Add tests cases for multi-channel inputs.\r\n* Determine why [`AudioSpectrogramOp`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spectrogram_op.cc) fails with `Spectrogram size calculation failed` for multi-channel inputs.", "Ahh hm, so there's a reason that those ops don't have Python wrappers yet -- we don't actually want to make them public / supported yet. I'm sorry this decision wasn't better documented, but could you please hold off on this work?", "Ah, that's a shame; may I inquire as to the reason why? Presumably the ops & kernels will remain in core, so it's safe to take a dependency on them in a saved model?", "We are planning on making them public soon, I have a pending change that I hope to get in over the next couple of weeks.", "Excellent, thanks.\r\n\r\nIn the mean while, I identified a small [issue](/andykernahan/tensorflow/commit/0c0152d31a5e02f0025b62d1c715dc3cecb7c876) with the `AudioSpectrogram` op shape function; should I submit a PR for this, or leave it?\r\n", "@petewarden @rryan Is the python wrapper for mfcc available in the 1.3 release of tensorflow ? Thanks", "Trying the \"Simple Audio Recognition\", but get the \" ImportError: cannot import name 'audio_ops'\", Any way or plans to make it work? \r\n", "Are you using the latest development version of TensorFlow? https://hub.docker.com/r/tensorflow/tensorflow/\r\n\r\nThe op changes missed the deadline for 1.3, but should be in 1.4.", "Can you please add an dct bool option to the \"audio_ops\", so that the current mfcc function can be used to extract log-mel features as well? Thanks!", "I cloned the master, don't use docker. don't see version 1.4, see only 1.3", "When will TensorFlow version 1.4 be available? Can anyone guild me how to get through the Speech Command example with version 1.3. Thanks", "@Joseph1977 It's in the nightly builds (e.g. `tensorflow/tensorflow:nightly-gpu-py3`).\r\n\r\n@leminhtrinh \r\nThis is somewhat along the lines of what I did:\r\n1. `docker pull tensorflow/tensorflow:nightly-gpu-py3`\r\n2. `nvidia-docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-gpu-py3`\r\n3. `docker exec -it jolly_lamport bash`\r\n4. The speech command example isn't Python 3 compatible, you'll need to fix the errors manually. I believe it's just like 4 lines of changes...", "Some good news! In addition to the audio ops changes Pete mentions above, TensorFlow 1.4 will have:\r\n\r\n* `tf.spectral.dct` - for computing the DCT-II, with GPU and gradient support (other DCT types coming soon).\r\n* `tf.contrib.signal.mfccs_from_log_mel_spectrograms` - for computing MFCCs from log mel spectrograms with GPU and gradient support.\r\n* `tf.contrib.signal.linear_to_mel_weight_matrix` - for reweighting a linear-scale spectrogram into the mel-scale.", "Hi @rryan , \r\nI can see that there are two alternatives for processing raw audio waveforms (to obtain spectrograms and mfccs, for example):\r\n\r\n1. `audio_ops.audio_spectrogram()`, `audio_ops.mfcc()`\r\n2. `contrib.signal.stft()`, some processing, `contrib.signal.mfcc_from_log_mel...()`\r\n\r\nWhat are the intended / recommended use cases of these two approaches ? It looks confusing to me.\r\n", "Is there any doc/tutorial for those APIs? It would be very helpful.", "> Hi @rryan ,\r\n> I can see that there are two alternatives for processing raw audio waveforms (to obtain spectrograms and mfccs, for example):\r\n> \r\n> audio_ops.audio_spectrogram(), audio_ops.mfcc()\r\n> contrib.signal.stft(), some processing, contrib.signal.mfcc_from_log_mel...()\r\n> What are the intended / recommended use cases of these two approaches ? It looks confusing to me.\r\n\r\nHi @georgesterpu,\r\n\r\nYou can think of `audio_ops.audio_spectrogram` and `audio_ops.mfcc` as \"fused\" ops (like fused batch-norm or fused LSTM cells that TensorFlow has) for the ops in `tf.contrib.signal`. I think the original motivation of them was that a fused op makes it easier to provide mobile support. I think long term it would be nice if we removed them and provided automatic fusing via XLA, or unified the API to match `tf.contrib.signal` API, and provided `fused` keyword arguments to `tf.contrib.signal` functions, like we do for `tf.layers.batch_normalization`.\r\n\r\nThe benefits of `tf.contrib.signal` are:\r\n* Support for backpropagation in training. If you are building machine learning models that generate audio this is crucial. For example, you could include an MFCC loss in a network that generates spectrograms (such as [Tacotron](https://google.github.io/tacotron/publications/tacotron/index.html)) that ensures the MFCCs of your generated spectrogram match those of the target spectrogram.\r\n* GPU/TPU support -- another crucial feature for training. It's so fast on GPU that you can just compute them as part of your network and feed raw waveforms into your model. We compute all our features on the fly on my team at Google. My team is adding TPU support for all of these right now (#12314).\r\n* Flexibility and experimentation -- you can change the computation of the MFCC or spectrogram to find out what combinations of operations (e.g. different compression options, different frequency warpings, etc.) work best for your use case. There is no \"one true\" way of computing a spectrogram. There are dozens of different choices that go into it, and machine learning practitioners need the flexibility to experiment.", "> Is there any doc/tutorial for those APIs? It would be very helpful.\r\n\r\n@NearLinHere: I wrote [a guide to using tf.contrib.signal](https://www.tensorflow.org/api_guides/python/contrib.signal) that is included in the TensorFlow documentation. Check it out!", "Hi there, when I used ``audio_ops.audio_spectrogram()`` and ``contrib.signal.stft()`` for generating MFCCs, I found that the one using ``audio_ops`` is faster than the ``contrib.signal`` one. Do you have the same feeling? And do you plan to improve contrib.signal? Thanks a lot!", "@jundengdeng, yup -- the main benefit of a \"fused\" op is that it avoids the compute and memory overhead of the TensorFlow runtime executing a graph of fine-grained ops. For this reason, on CPU the fused ops are likely to perform better (they don't support GPU/TPU).\r\n\r\nWe are working on making these faster, but as I said, on GPU they are plenty fast for use on the fly (no preprocessing). My suggestion would be to use them on GPU for training instead of running them on CPU in a preprocessing queue / tf.data pipeline.\r\n\r\nWe are working on making them faster. My hope is that XLA will be able to automatically compile `tf.contrib.signal` into something that is as fast as a hand-written fused op on CPU.", "Thank you, @rryan. \r\n\r\n> It's so fast on GPU that you can just compute them as part of your network and feed raw waveforms into your model. We compute all our features on the fly on my team at Google.\r\n\r\nDoes your terminal get flooded with the ffmpeg log whenever you decode audio on the fly ? Asked [here](https://stackoverflow.com/questions/47361507/tf-contrib-ffmpeg-decode-audio-verbosity) as well. I could not find an easy way such as an environment variable for ffmpeg to turn off the output log, there's only a command-line argument `loglevel` but TF's `decode_audio()` does not support it. Do you have any suggestion ?", "@georgesterpu, I don't use `decode_audio`, but that sounds quite annoying! Want to file an issue and CC me and @fredbertsch ? ", "@rryan What do you use to handle audio files ?", "We store all of our audio in a protobuf format that's roughly isomorphic to a WAV file (i.e. S16LE or float samples, uncompressed on disk). We use custom C++ ops to parse it / the associated metadata. `tf.SequenceExample` is pretty common, too.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "I believe the original issue (add python audio ops) has been resolved, closing this out.\r\n\r\nIf you feel there are remaining problems, either file a new issue, or ping this issue and I'll re-open.", "Hi @rryan \r\n\r\n> tf.contrib.signal.mfccs_from_log_mel_spectrograms - for computing MFCCs from log mel spectrograms with GPU and gradient support.\r\n\r\nDoes this mean GPU is used for feature extraction of audio signals or for training models.\r\n\r\nThanks  ", "> Does this mean GPU is used for feature extraction of audio signals or for training models.\r\n\r\nBoth! It's up to you whether a GPU is used for feature extraction -- you can control where the ops run with `tf.device`.", "The underlying ops all support CPU, GPU, or TPU execution.", "Hi, I am trying to update the feature extraction pipeline of an speech command recognition model replacing  the function `audio_ops.audio_spectrogram()` by  `tf.contrib.signal.stft()`. I assumed that they were equivalent, but  I am obtaining different results with the same input audio. Could someone explain the relation between the two methods, or whether it is possible to obtain the same results using `tf.contrib.signal.stft()`? \r\n\r\nMy code:\r\n\r\n1) `audio_ops` method:\r\n```\r\n#WAV audio loader\r\nwav_filename_placeholder_ = tf.placeholder(tf.string, [], name='wav_filename')\r\nwav_loader = io_ops.read_file(wav_filename_placeholder_)\r\nsample_rate = 16000\r\ndesired_samples = 16000 #1 sec audio\r\nwav_decoder = audio_ops.decode_wav(wav_loader, desired_channels=1, desired_samples=desired_samples)\r\n\r\n#Computing the spectrograms\r\nspectrogram = audio_ops.audio_spectrogram(wav_decoder.audio,\r\n                                              window_size=320,\r\n                                              stride=160,\r\n                                              magnitude_squared=False)\r\nwith tf.Session() as sess:\r\n    feed_dict={wav_filename_placeholder_:\"/<folder_path>/audio_sample.wav\"}\r\n    #Get the input audio and the spectrogram\r\n    audio_ops_wav_decoder_audio, audio_ops_spectrogram = sess.run([wav_decoder.audio, spectrogram], feed_dict)\r\n```\r\n\r\n2) `tf.contrib.signal` method\r\n```\r\n#Input WAV audio (will be initialized with the same audio signal: wav_decoder.audio )\r\nsignals = tf.placeholder(tf.float32, [None, None])\r\n\r\n#Compute the spectrograms and get the absolute values\r\nstfts = tf.contrib.signal.stft(signals, \r\n                               frame_length=320, \r\n                               frame_step=160, \r\n                               fft_length=512, \r\n                               window_fn=None)\r\nmagnitude_spectrograms = tf.abs(stfts)\r\nwith tf.Session() as sess:\r\n    feed_dict = {signals : audio_ops_wav_decoder_audio.reshape(1,16000)}\r\n    tf_original, tf_stfts, tf_spectrogram, = sess.run([signals, stfts, magnitude_spectrograms], feed_dict)\r\n```\r\n\r\nThank you in advance", "I would also like to know why there is a difference in the code provided by @vadel ", "Could it be related to this maybe?\r\n\r\n> https://stackoverflow.com/questions/48660391/using-tensorflow-contrib-framework-python-ops-audio-ops-audio-spectrogram-to-gen", "@vadel, @imranparuk -- the implementation of `audio_spectrogram` and `tf.contrib.signal.stft` are different (note, in TensorFlow >1.12 and 2.0, this will be `tf.signal.stft`, as `signal` is moving out of contrib into core). \r\n\r\n`audio_spectrogram` is a C++ implementation of an STFT, while `tf.signal.stft` uses TensorFlow ops to compute the STFT (and thus has CPU, GPU and TPU support).\r\n\r\nThe main cause of difference between them is that `audio_spectrogram` uses [`fft2d`](https://github.com/tensorflow/tensorflow/tree/master/third_party/fft2d) to compute FFTs while `tf.contrib.signal.stft` uses Eigen (CPU), cuFFT (GPU), and XLA (TPU). There is another very minor difference, which is that the default periodic Hann window used by each is slightly different. `tf.contrib.signal.stft` follows numpy/scipy's definition.\r\n\r\nFrom @vadel's code:\r\n```python\r\n#Compute the spectrograms and get the absolute values\r\nstfts = tf.contrib.signal.stft(signals, \r\n                               frame_length=320, \r\n                               frame_step=160, \r\n                               fft_length=512, \r\n                               window_fn=None)\r\n```\r\n\r\nSetting `window_fn=None` is the main problem here -- applying a window is a core part of the STFT. If you use the default window the difference between `audio_spectrogram` and `tf.contrib.signal.stft` is much smaller (to within a tolerance of `1e-3` for the simple example I link below, and `1e-4` when you fix the difference in default window). You cannot in general expect them to produce bit identical outputs because the implementations are different -- even order of operations of floating point operations will affect the result. \r\n\r\nWe should be able to get very close though -- [in this Colab notebook](https://colab.research.google.com/drive/1NEdUBNyFPWL2rr1wc-1T1FKIUl57tgvI), I show that the difference between the two is less than `1e-4` when using TensorFlow's CPU FFTs. The reason it isn't closer is that `tf.contrib.signal.stft` uses `float32` FFTs, while `audio_spectrogram` uses `float64` FFTs internally. Once I add `float64` support to `tf.spectral.rfft`, you will have the option of using 64-bit math with `tf.contrib.signal.stft`, which should improve on this bound.\r\n\r\n\r\n\r\n", "Thanks @rryan for the explanation! I recently ran into the same problem as @vadel when replicating the functionality in `audio_spectrogram` in another framework. Is there any way we can see what the default window function is for this op, or how it was done with Takuya Ooura's library? I appreciate the link, but the [`fft2d`](https://github.com/tensorflow/tensorflow/tree/master/third_party/fft2d) directory doesn't lend much insight.", "> @vadel, @imranparuk -- the implementation of `audio_spectrogram` and `tf.contrib.signal.stft` are different (note, in TensorFlow >1.12 and 2.0, this will be `tf.signal.stft`, as `signal` is moving out of contrib into core).\r\n> \r\n> `audio_spectrogram` is a C++ implementation of an STFT, while `tf.signal.stft` uses TensorFlow ops to compute the STFT (and thus has CPU, GPU and TPU support).\r\n> \r\n> The main cause of difference between them is that `audio_spectrogram` uses [`fft2d`](https://github.com/tensorflow/tensorflow/tree/master/third_party/fft2d) to compute FFTs while `tf.contrib.signal.stft` uses Eigen (CPU), cuFFT (GPU), and XLA (TPU). There is another very minor difference, which is that the default periodic Hann window used by each is slightly different. `tf.contrib.signal.stft` follows numpy/scipy's definition.\r\n> \r\n> From @vadel's code:\r\n> \r\n> ```python\r\n> #Compute the spectrograms and get the absolute values\r\n> stfts = tf.contrib.signal.stft(signals, \r\n>                                frame_length=320, \r\n>                                frame_step=160, \r\n>                                fft_length=512, \r\n>                                window_fn=None)\r\n> ```\r\n> \r\n> Setting `window_fn=None` is the main problem here -- applying a window is a core part of the STFT. If you use the default window the difference between `audio_spectrogram` and `tf.contrib.signal.stft` is much smaller (to within a tolerance of `1e-3` for the simple example I link below, and `1e-4` when you fix the difference in default window). You cannot in general expect them to produce bit identical outputs because the implementations are different -- even order of operations of floating point operations will affect the result.\r\n> \r\n> We should be able to get very close though -- [in this Colab notebook](https://colab.research.google.com/drive/1NEdUBNyFPWL2rr1wc-1T1FKIUl57tgvI), I show that the difference between the two is less than `1e-4` when using TensorFlow's CPU FFTs. The reason it isn't closer is that `tf.contrib.signal.stft` uses `float32` FFTs, while `audio_spectrogram` uses `float64` FFTs internally. Once I add `float64` support to `tf.spectral.rfft`, you will have the option of using 64-bit math with `tf.contrib.signal.stft`, which should improve on this bound.\r\n\r\nThanks for the explanation. Though the output is similar for the spectrogram when we have to calculate the mfccs the outputs for audio_ops.mfcc doesn't match with the output of tf.signal.mfccs_from_log_mel_spectrogram.\r\n\r\nThis notebook has the code which was written to replicate, [Colab Notebook](https://colab.research.google.com/drive/1kKm0SVhC4v7SfbBeLfBn9RF-xO_qT8rq)", "I am comparing audios_ops.mfcc and tf.signal.mfccs_from_log_mel_spectogram to each other. They are the same with a tolerance of 1e-1.\r\n\r\nIs that an expected amount of difference of should they be closer?\r\n\r\n"]}, {"number": 11338, "title": "Branch 161140653", "body": "", "comments": ["Jenkins, test this please.", "Flaky cmake test. Not the same one as last PR."]}, {"number": 11337, "title": "get error in tensorflow 1.2 but the code works on tensorflow 1.0", "body": "Hi,\r\n\r\nI have the following code. I can run it successfully in tf v1.0 but it failed in tf v1.2. The error is from the (inputs, state) in the GRUCell. Can you help me understand why the errors come from?\r\n\r\nThank you.\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom  tensorflow.contrib.learn.python.learn.estimators.dnn  import DNNClassifier\r\nfrom tensorflow.contrib.layers import real_valued_column\r\nfrom tensorflow.contrib.layers.python.layers.initializers import xavier_initializer\r\n\r\ndropout=0.2\r\nhidden_1_size = 1000\r\nhidden_2_size = 250\r\nNUM_EPOCHS=100\r\nBATCH_SIZE=50\r\nlr=0.0001\r\n\r\nnum_features = 2328\r\nRNN_HIDDEN_SIZE=100\r\nFIRST_LAYER_SIZE=1000\r\nSECOND_LAYER_SIZE=250\r\nNUM_LAYERS=2\r\nBATCH_SIZE=50\r\nNUM_EPOCHS=200\r\nlr=0.0003\r\nATTN_LENGTH=30\r\nbeta=0\r\n\r\n\r\nclass RNNModel():\r\n    def __init__(self):\r\n        global_step = tf.contrib.framework.get_or_create_global_step()\r\n        self.input_data = tf.placeholder(dtype=tf.float32,shape=[BATCH_SIZE,num_features])\r\n        self.target_data = tf.placeholder(dtype=tf.int32,shape=[BATCH_SIZE])\r\n        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])\r\n        \r\n        def makeGRUCells():\r\n            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,) \r\n            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False) \r\n            attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=layered_cell,attn_length=ATTN_LENGTH,state_is_tuple=False)\r\n            return attn_cell\r\n        \r\n        self.gru_cell = makeGRUCells()\r\n        self.zero_state = self.gru_cell.zero_state(1, tf.float32)\r\n        \r\n        self.start_state = tf.placeholder(dtype=tf.float32,shape=[1,self.gru_cell.state_size])\r\n        print((self.start_state))\r\n        \r\n        \r\n\r\n        with tf.variable_scope(\"fff\",initializer=xavier_initializer(uniform=False), reuse = None):\r\n            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)\r\n            \r\n            layer_1 = tf.contrib.layers.fully_connected(\r\n                num_outputs=FIRST_LAYER_SIZE,\r\n                inputs=droped_input,\r\n            )\r\n            layer_2 = tf.contrib.layers.fully_connected(\r\n                num_outputs=RNN_HIDDEN_SIZE,\r\n                inputs=layer_1,\r\n            )\r\n            \r\n        \r\n        split_inputs = tf.reshape(droped_input,shape=[1,BATCH_SIZE,num_features],name=\"reshape_l1\") # Each item in the batch is a time step, iterate through them\r\n        #print(split_inputs.shape)\r\n        split_inputs = tf.unstack(split_inputs,axis=1,name=\"unpack_l1\")\r\n        #print(\"lentgh is \" + str(len(split_inputs)))\r\n        states =[]\r\n        outputs =[]\r\n        with tf.variable_scope(\"rnn\",initializer=xavier_initializer(uniform=False), reuse = None) as scope:\r\n            state = self.start_state\r\n            for i, inp in enumerate(split_inputs):\r\n                if i >0:\r\n                    scope.reuse_variables()\r\n                print((state))\r\n                print((inp))\r\n                print(\"this is for \" + str(i))\r\n                output, state = self.gru_cell(inputs = inp, state = state)\r\n                states.append(state)\r\n                outputs.append(output)\r\n        self.end_state = states[-1]\r\n        outputs = tf.stack(outputs,axis=1) # Pack them back into a single tensor\r\n        outputs = tf.reshape(outputs,shape=[BATCH_SIZE,RNN_HIDDEN_SIZE])\r\n        self.logits = tf.contrib.layers.fully_connected(\r\n            num_outputs=num_classes,\r\n            inputs=outputs,\r\n            activation_fn=None\r\n        )\r\n\r\n            \r\n        with tf.variable_scope(\"loss\", reuse = None):\r\n            self.penalties =    tf.reduce_sum([beta*tf.nn.l2_loss(var) for var in tf.trainable_variables()])\r\n\r\n            \r\n            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits,labels = self.target_data)\r\n            self.loss = tf.reduce_sum(self.losses + beta*self.penalties)\r\n        \r\n        with tf.name_scope(\"train_step\"):\r\n            opt = tf.train.AdamOptimizer(lr)\r\n            gvs = opt.compute_gradients(self.loss)\r\n            self.train_op = opt.apply_gradients(gvs, global_step=global_step)\r\n        \r\n        with tf.name_scope(\"predictions\"):\r\n            probs = tf.nn.softmax(self.logits)\r\n            self.predictions = tf.argmax(probs, 1)\r\n            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)\r\n            self.accuracy = tf.reduce_mean(correct_pred)\r\n\r\n         \r\nwith tf.Graph().as_default():\r\n    model = RNNModel()\r\n```\r\n\r\n\r\n```python\r\n\r\nWARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x0000000038EB4CC0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:0\", shape=(1, 2328), dtype=float32)\r\nthis is for 0\r\n\r\n\r\n\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-20-2249079aecbe> in <module>()\r\n      1 with tf.Graph().as_default():\r\n----> 2     model = RNNModel()\r\n\r\n<ipython-input-19-58646adfd4d3> in __init__(self)\r\n     48                 print((inp))\r\n     49                 print(\"this is for \" + str(i))\r\n---> 50                 output, state = self.gru_cell(inputs = inp, state = state)\r\n     51                 states.append(state)\r\n     52                 outputs.append(output)\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    178       with vs.variable_scope(vs.get_variable_scope(),\r\n    179                              custom_getter=self._rnn_get_variable):\r\n--> 180         return super(RNNCell, self).__call__(inputs, state)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    439         # Check input assumptions set after layer building, e.g. input shape.\r\n    440         self._assert_input_compatibility(inputs)\r\n--> 441         outputs = self.call(inputs, *args, **kwargs)\r\n    442 \r\n    443         # Apply activity regularization.\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\rnn_cell.py in call(self, inputs, state)\r\n   1111       input_size = inputs.get_shape().as_list()[1]\r\n   1112     inputs = _linear([inputs, attns], input_size, True)\r\n-> 1113     lstm_output, new_state = self._cell(inputs, state)\r\n   1114     if self._state_is_tuple:\r\n   1115       new_state_cat = array_ops.concat(nest.flatten(new_state), 1)\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    178       with vs.variable_scope(vs.get_variable_scope(),\r\n    179                              custom_getter=self._rnn_get_variable):\r\n--> 180         return super(RNNCell, self).__call__(inputs, state)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    439         # Check input assumptions set after layer building, e.g. input shape.\r\n    440         self._assert_input_compatibility(inputs)\r\n--> 441         outputs = self.call(inputs, *args, **kwargs)\r\n    442 \r\n    443         # Apply activity regularization.\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in call(self, inputs, state)\r\n    914                                       [-1, cell.state_size])\r\n    915           cur_state_pos += cell.state_size\r\n--> 916         cur_inp, new_state = cell(cur_inp, cur_state)\r\n    917         new_states.append(new_state)\r\n    918 \r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in __call__(self, inputs, state, scope)\r\n    178       with vs.variable_scope(vs.get_variable_scope(),\r\n    179                              custom_getter=self._rnn_get_variable):\r\n--> 180         return super(RNNCell, self).__call__(inputs, state)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py in __call__(self, inputs, *args, **kwargs)\r\n    439         # Check input assumptions set after layer building, e.g. input shape.\r\n    440         self._assert_input_compatibility(inputs)\r\n--> 441         outputs = self.call(inputs, *args, **kwargs)\r\n    442 \r\n    443         # Apply activity regularization.\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in call(self, inputs, state)\r\n    293       value = math_ops.sigmoid(\r\n    294           _linear([inputs, state], 2 * self._num_units, True, bias_ones,\r\n--> 295                   self._kernel_initializer))\r\n    296       r, u = array_ops.split(value=value, num_or_size_splits=2, axis=1)\r\n    297     with vs.variable_scope(\"candidate\"):\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in _linear(args, output_size, bias, bias_initializer, kernel_initializer)\r\n   1015         _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],\r\n   1016         dtype=dtype,\r\n-> 1017         initializer=kernel_initializer)\r\n   1018     if len(args) == 1:\r\n   1019       res = math_ops.matmul(args[0], weights)\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\r\n   1063       collections=collections, caching_device=caching_device,\r\n   1064       partitioner=partitioner, validate_shape=validate_shape,\r\n-> 1065       use_resource=use_resource, custom_getter=custom_getter)\r\n   1066 get_variable_or_local_docstring = (\r\n   1067     \"\"\"%s\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\r\n    960           collections=collections, caching_device=caching_device,\r\n    961           partitioner=partitioner, validate_shape=validate_shape,\r\n--> 962           use_resource=use_resource, custom_getter=custom_getter)\r\n    963 \r\n    964   def _get_partitioned_variable(self,\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\r\n    358           reuse=reuse, trainable=trainable, collections=collections,\r\n    359           caching_device=caching_device, partitioner=partitioner,\r\n--> 360           validate_shape=validate_shape, use_resource=use_resource)\r\n    361     else:\r\n    362       return _true_getter(\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)\r\n   1403     return custom_getter(\r\n   1404         functools.partial(old_getter, getter),\r\n-> 1405         *args, **kwargs)\r\n   1406   return wrapped_custom_getter\r\n   1407 \r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n--> 183     variable = getter(*args, **kwargs)\r\n    184     trainable = (variable in tf_variables.trainable_variables() or\r\n    185                  (isinstance(variable, tf_variables.PartitionedVariable) and\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in wrapped_custom_getter(getter, *args, **kwargs)\r\n   1403     return custom_getter(\r\n   1404         functools.partial(old_getter, getter),\r\n-> 1405         *args, **kwargs)\r\n   1406   return wrapped_custom_getter\r\n   1407 \r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n--> 183     variable = getter(*args, **kwargs)\r\n    184     trainable = (variable in tf_variables.trainable_variables() or\r\n    185                  (isinstance(variable, tf_variables.PartitionedVariable) and\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)\r\n    181 \r\n    182   def _rnn_get_variable(self, getter, *args, **kwargs):\r\n--> 183     variable = getter(*args, **kwargs)\r\n    184     trainable = (variable in tf_variables.trainable_variables() or\r\n    185                  (isinstance(variable, tf_variables.PartitionedVariable) and\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\r\n    350           trainable=trainable, collections=collections,\r\n    351           caching_device=caching_device, validate_shape=validate_shape,\r\n--> 352           use_resource=use_resource)\r\n    353 \r\n    354     if custom_getter is not None:\r\n\r\nC:\\Users\\hsong01\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\r\n    667         raise ValueError(\"Trying to share variable %s, but specified shape %s\"\r\n    668                          \" and found shape %s.\" % (name, shape,\r\n--> 669                                                    found_var.get_shape()))\r\n    670       if not dtype.is_compatible_with(found_var.dtype):\r\n    671         dtype_str = dtype.name\r\n\r\nValueError: Trying to share variable rnn/attention_cell_wrapper/multi_rnn_cell/cell_0/gru_cell/gates/kernel, but specified shape (200, 200) and found shape (2428, 200).\r\n```\r\n", "comments": ["@ebrevdo can you comment on this?", "when I run on tensorflow 1.0.1, with the following change, there is no error message of shape unmatch and the code can run successfully.\r\n\r\n```python\r\n            base_cell = tf.contrib.rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,)\r\n            layered_cell = tf.contrib.rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False)\r\n```\r\n\r\n```python\r\nWARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x7efe0e913dd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"Placeholder_3:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:0\", shape=(1, 2328), dtype=float32)\r\nthis is for 0\r\nTensor(\"rnn/attention_cell_wrapper/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:1\", shape=(1, 2328), dtype=float32)\r\nthis is for 1\r\nTensor(\"rnn/attention_cell_wrapper_1/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:2\", shape=(1, 2328), dtype=float32)\r\nthis is for 2\r\nTensor(\"rnn/attention_cell_wrapper_2/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:3\", shape=(1, 2328), dtype=float32)\r\nthis is for 3\r\nTensor(\"rnn/attention_cell_wrapper_3/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:4\", shape=(1, 2328), dtype=float32)\r\nthis is for 4\r\nTensor(\"rnn/attention_cell_wrapper_4/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:5\", shape=(1, 2328), dtype=float32)\r\nthis is for 5\r\nTensor(\"rnn/attention_cell_wrapper_5/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:6\", shape=(1, 2328), dtype=float32)\r\nthis is for 6\r\nTensor(\"rnn/attention_cell_wrapper_6/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:7\", shape=(1, 2328), dtype=float32)\r\nthis is for 7\r\nTensor(\"rnn/attention_cell_wrapper_7/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:8\", shape=(1, 2328), dtype=float32)\r\nthis is for 8\r\nTensor(\"rnn/attention_cell_wrapper_8/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:9\", shape=(1, 2328), dtype=float32)\r\nthis is for 9\r\nTensor(\"rnn/attention_cell_wrapper_9/concat_2:0\", shape=(1, 3300), dtype=float32)\r\nTensor(\"unpack_l1:10\", shape=(1, 2328), dtype=float32)\r\n```", "Usage of MultiRNNCell has changed in 1.2. See https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md#major-features-and-improvements", "@ppwwyyxx  Thank you. I got it. After replace the following, it works now.\r\n\r\n```python\r\nlayered_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(num_units=RNN_HIDDEN_SIZE,) for _ in range(NUM_LAYERS)],state_is_tuple=False) \r\n```", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This was last updated in 2017, and seems to contain a fix. Closing."]}, {"number": 11336, "title": "TF 1.2 vs 1.1: Keras K.set_learning_phase(False) not working in 1.2 but works in 1.1", "body": "Hi all,\r\n\r\nWorks fine in 1.1 but in 1.2: \r\n```\r\nfrom tensorflow.contrib.keras.python.keras import backend as K\r\nfrom tensorflow.contrib.keras.python.keras.models import load_model\r\nK.set_learning_phase(False)\r\nmodel = load_model(MODEL_PATH)\r\n```\r\n```\r\nmodel.uses_learning_phase <-- returns TRUE\r\n```\r\n\r\nThis does not happen in 1.1. What may have changed that cause this in 1.2? \r\n\r\nThank you in advance.\r\nBest regards,\r\nDylan Randle\r\n\r\n", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Hi, Sorry for that. \r\n\r\nUbuntu 16.04 \r\nTensorflow version is 1.2 (install binary)\r\n\r\nTo clarify, the entire script is above, except:\r\n`model.uses_learning_phase <-- returns TRUE` \r\nis really\r\n```\r\nif model.uses_learning_phase:\r\n    raise RuntimeError('Model using learning phase.')\r\n```\r\n\r\n", "@fchollet could you comment on this? I don't understand some of the subtleties. It looks to me as if \"uses_learning_phase\" is intended to indicate whether a model behaves differently during learning or inference. But I think that the \"set_learning_phase\" flag is just indicating whether learning or inference is being done. ", "Hey all,\r\n\r\nIs there any update about this? Has anyone experienced the issue I am talking about? \r\n\r\nIt's not crucial because I can use tensorflow 1.1 to accomplish to task, but it would be nice if it could be fixed? \r\n\r\nThanks,\r\nDylan", "`model.uses_learning_phase` indicates whether the model is supposed to have a different behavior in inference and training. It's basically for regularization (dropout) and BatchNorm.\r\n\r\nThe \"learning phase\" is a flag is a flag which indicates training/inference. It is set to 1 when using e.g. `fit` and to 0 when using e.g. `predict`.\r\n\r\n`K.set_learning_phase(False)` sets the \"learning phase\" to be always 0, i.e. `fit` will have the model behave in inference mode (e.g. no dropout and BatchNorm behavior set to inference).\r\n\r\nThe value returned by `model.uses_learning_phase` depends only on the model and is independent from `K.set_learning_phase(False)`.\r\n", "Hi @fchollet Thank you very much. That solves my issue, however I'm still concerned about the different behaviour?\r\n\r\nIs there a reason why, for the exact same model, I would be getting model.uses_learning_phase <- False in Tf 1.1 and True in TF 1.2?\r\n\r\nBtw, great article yesterday! Looking forward to today's! :D ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Closing due to inactivity."]}, {"number": 11335, "title": "Branch 161124799", "body": "", "comments": ["cwise_ops_test is failing in Windows cmake build. This looks new:\r\n\r\nhttps://ci.tensorflow.org/job/tensorflow-pr-win-cmake-py/3175/console\r\n\r\nTesting again to find out whether this is reproducible.", "@tensorflow-jenkins test this please", "It was a bad merge conflict-fix, I'll retry this."]}, {"number": 11334, "title": "Memory Overhead/Leak in Android lib", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Nexus 6p, Android v7.1.2\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:  1.2.0-rc2\r\n- **Python version**: 2.7.10\r\n- **Bazel version (if compiling from source)**: 0.4.5-homebrew\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n-- Selective Headers: ` bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a `\r\n-- Added `tensorflow/core/kernels/random_shuffle_queue_op.cc` and `tensorflow/core/kernels/random_shuffle_op.cc` to `tf_op_files.txt` file\r\n-- Removed unused nodes: `bazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=model.pb \\\r\n--out_graph=optimized_model.pb \\\r\n--inputs='input' \\\r\n--outputs='output' \\\r\n--transforms='\r\n  strip_unused_nodes(type=float, shape=\"1,299,299,3\")'`\r\n\r\n### Describe the problem\r\nThe Tensorflow Android library is using a lot more memory than I expected. It almost seems like it's maintaining a reference to all input arrays, as memory usage balloons the longer the model is used. \r\nHere is an example of the memory usage with feed/run/fetch commented out (source code below):\r\n\r\n![no_tensorflow](https://user-images.githubusercontent.com/4616968/27930636-3342a548-624c-11e7-91ed-3f4f56b7cf5f.png)\r\n\r\nHere is the same timeframe, with the only difference being that feed/run/fetch is enabled:\r\n\r\n![tensorflow](https://user-images.githubusercontent.com/4616968/27930738-954e125e-624c-11e7-82f2-cc21e67bc5d3.png)\r\n\r\nMemory usage is over three times worse. The longer I leave the model running, the more memory usage increases (it eventually gets to 110 mb).\r\n\r\nThe below method is being called at a rate of 4.419011933 per sec (i.e. it's processing 4.412 input arrays per second), where each input array is of size 96\\*96\\*3 (27648).\r\n\r\nThis is being run on a Nexus 6p, running stock 7.1.2. The model is a conv net with inception, batch norm and dropout, trained using tensorflow slim. \r\n\r\n### Source code / logs\r\nCommented out:\r\n```java\r\npublic float[] runInference(float[] pixels) {\r\n        assertRightSize(pixels);\r\n        final float[] outputArray = new float[128];\r\n        // Simulate some sort of output\r\n        Arrays.fill(outputArray, new Random().nextInt(1000)/new Random().nextFloat());\r\n//     inferenceInterface.feed(\"phase_train\", new bool[]{false});\r\n//     inferenceInterface.feed(\"input\", pixels, 1, 96, 96, 3);\r\n//     inferenceInterface.run(new String[]{\"output\"});\r\n        // Copy the output Tensor back into the output array.\r\n//     inferenceInterface.fetch(\"output\", outputArray);\r\n\r\n        return outputArray;\r\n    }\r\n```\r\nEnabled:\r\n\r\n```java\r\npublic float[] runInference(float[] pixels) {\r\n        assertRightSize(pixels);\r\n        final float[] outputArray = new float[128];\r\n        inferenceInterface.feed(\"phase_train\", new bool[]{false});\r\n        inferenceInterface.feed(\"input\", pixels, 1, 96, 96, 3);\r\n        inferenceInterface.run(new String[]{\"output\"});\r\n        // Copy the output Tensor back into the output array.\r\n        inferenceInterface.fetch(\"output\", outputArray);\r\n\r\n        return outputArray;\r\n    }\r\n```\r\n\r\nwhere `float[] pixels` is a float array of size `27648`, denoting the pixels in an image of size 96x96.\r\n\r\nThe custom code is an update to the InferenceInterface to accept boolean types during feeding: \r\n\r\n```java\r\npublic void feed(String inputName, boolean[] src, long... dims) {\r\n        byte[] b = new byte[src.length];\r\n        for (int i = 0; i < src.length; ++i) {\r\n            b[i] = (byte) (src[i] ? 1 : 0);\r\n        }\r\n        addFeed(inputName, Tensor.create(DataType.BOOL, dims, ByteBuffer.wrap(b)));\r\n    }\r\n```\r\n\r\nPlease let me know if there's any other information I can provide.", "comments": ["It looks to me like there's a related discussion about the overheads of feed/run/fetch in #8712. Does any of that help? ", "@cy89 thanks for the response. I read that issue before posting mine and it was related. Unfortunately, the discussion turned towards timing and performance as opposed to memory allocation. ", "Makes sense. @petewarden, are there perhaps any updates about our Android TF ecosystem and its memory usage behavior?", "@faifai21 Thanks for the detailed report! Are you able to determine exactly how much the memory use increases per inference pass? If you change the size of your input array, does the rate of increase vary proportionally? I'm just curious if something else in the run() call could be allocating memory that never gets cleaned up.\r\n\r\n@asimshankar Any idea why this might be happening, given that closeFetches() and closeFeeds() are both guaranteed to be called every invocation of TensorFlowInferenceInterface.run()?", "There was a leak in 1.2.0-rc0 and prior versions,\r\n fixed by https://github.com/tensorflow/tensorflow/commit/8304e197ea9eeb617f224a1ba0cc4068596098d1\r\n\r\n@faifai21 : Since you're building from source, could you confirm that your build includes the commit mentioned above?\r\n", "@asimshankar I just checked and that commit is included in the build. I can try rebuilding from the latest release and see if the issue goes away. \r\n\r\n> Are you able to determine exactly how much the memory use increases per inference pass?\r\n\r\n@andrewharp I'll get you that information first thing tomorrow morning. ", "@asimshankar I pulled in the latest master and built against commit https://github.com/tensorflow/tensorflow/commit/99a38ffd9d77c55ca6d0c373c6d4b72686284ac5. The memory leak is still occurring though.\r\n\r\n@andrewharp It seems like memory is increasing by ~0.1 MB per inference pass, which makes sense as each input array is around 110kb. As well, increasing the size of the input array does cause the memory leak to increase:\r\n\r\n- With an input array of 96\\*96\\*3, each input array was 110kb. Memory usage was increasing at ~0.5 mb per sec. With 4.41 inputs processed per sec, it can be inferred that memory was increasing by ~0.11 mb per run.\r\n- With an input array of 120\\*120\\*3, each input array was 172kb. Memory usage was increasing at 0.7 mb per sec. Since input size was increased, we were processing slightly less inputs per sec than before. Assuming we were processing 4.1 inputs per sec now, we can infer that each run increased memory by ~0.17mb.\r\n\r\nI was unable to increase input size by anymore, as that caused BufferOverflow exceptions with FloatBuffer as the input array was copied over when creating the Tensor. ", "I also tried decreasing the size of the input array to 30\\*30\\*3, which resulted in each input having a size of 10kb. The memory leak was still present, but it was much less apparent. As expected though, memory usage increased by ~0.01 mb per run. ", "@andrewharp We are also experiencing the same issue with tensorflow library on android. The memory keeps on increasing as the number of inference runs keep on increasing. This is leading to lot of out of memory errors in our application. \r\nWe tried creating a new TensorFlowInferenceInterface after every inference but even that did not solve the problem. It looks like a memory leak in tensorflow c++ library.", "> We tried creating a new TensorFlowInferenceInterface after every inference but even that did not solve the problem.\r\n\r\nI tried the same thing, and can confirm that the memory leak was still there. ", "@andrewharp @asimshankar any updates on this?", "We've also found this issue in our iOS tensorflow library (also built from source), which makes sense, given that the memory leak seems to be in C/C++ code. ", "Experiencing the same problem as above: lots of memory leakage due to the feeding operation.\r\n\r\nWhile I'm sure I'm missing a lot of intricacies here, the source seems obvious to me. During every call to `feed`, we are allocating new memory for the input tensor (float tensor in my case):\r\n**`addFeed(inputName, Tensor.create(dims, FloatBuffer.wrap(src))); `**\r\n\r\nIs there no way to overwrite the data in the existing FloatBuffer after the initial feed call? Instead of allocating space for a new Tensor each time (with the call to `create`)? Would that not solve the memory leak we are experiencing?", "@faifai21 : No updates yet unfortunately. Since you have this in C++ land as well, perhaps you could come up with a small C++ snippet that demonstrates this - and it might make it easier to trace any problems by running the sample on a desktop/laptop instead of a mobile device.\r\n\r\n@Mr-Grieves : I'm not following. During every call to `feed` a new `Tensor` is created, but it is released with a call to [`closeFeeds()`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/contrib/android/java/org/tensorflow/contrib/android/TensorFlowInferenceInterface.java#L157) on every call to `run()`.  Are you experiencing \"leaks\" or is it that total memory usage is higher than you'd want (and waits for a garbage collection cycle to come down)?", "@asimshankar: The latter. I'm new to Java and still not totally comfortable with the idea of leaving objects around to be cleaned up by the GC... My app runs as desired initially, but slows down over time, and eventually grinds to a halt. I initially thought this issue was being caused by a memory leak, but perhaps the memory management is running as it should and the cause of the slowdown lies somewhere else... \r\n\r\nI've attached a screenshot of my Memory and CPU monitors. GC events are being triggered every 10s or so, with 99% of the allocations occurring during the `addFeed(inputName, Tensor.create(dims, FloatBuffer.wrap(src)));`.\r\n\r\nIf the memory is not the problem, my issue is most likely CPU related, in which case I am posting in the wrong thread.\r\n\r\n![memorytrace](https://user-images.githubusercontent.com/19175336/28688053-6c3455d4-72c5-11e7-981e-114d0cdf3d3d.png)\r\n", "@Mr-Grieves It could be thermal throttling slowing down the CPU frequency after sustained load. I'm not sure if you can view this in Android Studio, but you could try [printing the frequency](https://stackoverflow.com/questions/3021054/how-to-read-cpu-frequency-on-android-device) manually via `adb shell` and see if it changes during a run.", "@asimshankar Thanks for the response. I've spoken to our iOS engineers a few more times and it seems like the memory leak does not actually happen in iOS land. This seems to be an issue on Android only, perhaps in the JNI methods? ", "@asimshankar @andrewharp This memory leak is blocking us from shipping tensorflow on Android. Are there any updates for this? Is there anything I can do to help? I tried looking through the source code to find the memory leak, but I'm not well versed in c/c++. ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Sorry this fell through the cracks. Is that still a problem with the latest versions?\r\n\r\nOur current recommended platform for mobile is tflite, maybe that fits your needs better?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@drpngx  I'm facing the exact same issue on version `1.5.0`. As I keep performing inference on an Android device, the memory consumed by the app keeps increasing.\r\n\r\nNo. of Inference runs     |  Memory usage\r\n-------------------------- | ------------------\r\n1                                     |     5.7 Mb\r\n15                                   |     206 Mb\r\n20                                   |     242 Mb\r\n25                                   |     757 Mb\r\n30                                   |     922 Mb\r\n\r\n\r\nIs there a fix for this issue?\r\n", "@deepaksuresh : There isn't any known fixes. Could you file a new issue with the details, particularly if there are any instructions to reproduce the problem? Can you share the model perhaps?", "@asimshankar I'm running the model from a `.pb` file. It is 70 Mb, how can I share it with you?", "You could upload it to some shared public storage and share from there. Though, before that, is there anything you can do to isolate the leak? For example, does a simple loop over the `TensorFlowInferenceInterface` object's method show this leak? "]}, {"number": 11333, "title": "ValueError: Variable vgg_16/conv1/conv1_1/weights already exists, disallowed", "body": "I got this kind of error message when trying use existing weight.\r\n\r\n```\r\nValueError: Variable vgg_16/conv1/conv1_1/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\r\n\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 217, in variable\r\n    use_resource=use_resource)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 181, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 262, in model_variable\r\n    use_resource=use_resource)\r\n```\r\n\r\nCode: https://github.com/datomnurdin/tensorflow-image-segmentation/blob/master/index.ipynb\r\n\r\nPlease advice. Thank you.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}]