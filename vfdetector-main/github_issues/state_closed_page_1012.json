[{"number": 22992, "title": "Deployment Guides", "body": "It would be helpful to have a guide that describes Tensorflow Serving Deployment best practices.For example:\r\n\r\n1. Run time environment scaling.\r\n2. Best practices for maintaining a native installation of Tensorflow Serving\r\n3. Best practices for maintaining Tensorflow Serving in a Docker environment.\r\n4. Best practices for maintaining a model library for both a native installation and a Docker image.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "As you have mentioned this issue is related to TF Serving. So can you please open this issue on [TensorFlow Serving repo](https://github.com/tensorflow/serving/issues) . Its better to track it on TF Serving repo. Thanks!"]}, {"number": 22991, "title": "tf.contrib.feature_column.sequence_numeric_column normalize_fn argument not working", "body": "I am using tf.contrib.feature_column.sequence_numeric_column to normalize a sparse tensor through normalize_fn. Here is a minimal example of the error that I get:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\na = np.reshape(np.arange(12), (3, 4, 1))\r\nwith tf.Session() as sess:\r\n    a_t = tf.constant(a)\r\n    idx = tf.where(tf.not_equal(a_t, 0))\r\n    sparse = tf.SparseTensor(idx, tf.gather_nd(a_t, idx), a_t.get_shape())\r\n    seq_cols = tf.contrib.feature_column.sequence_numeric_column('test', default_value=.0, normalizer_fn=lambda x: (x - 2.) / .3)\r\n    seq_features, sequence_length = tf.contrib.feature_column.sequence_input_layer({'test': sparse}, [seq_cols])\r\n\r\n    b = sess.run(seq_features)\r\n```\r\nRises:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-12-137e79726dfc>\", line 9, in <module>\r\n    seq_features, sequence_length = tf.contrib.feature_column.sequence_input_layer({'test': sparse}, [seq_cols])\r\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/feature_column/python/feature_column/sequence_feature_column.py\", line 120, in sequence_input_layer\r\n    trainable=trainable)\r\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/feature_column/python/feature_column/sequence_feature_column.py\", line 448, in _get_sequence_dense_tensor\r\n    sp_tensor = inputs.get(self)\r\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2263, in get\r\n    transformed = column._transform_feature(self)  # pylint: disable=protected-access\r\n  File \"/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/feature_column/python/feature_column/sequence_feature_column.py\", line 435, in _transform_feature\r\n    input_tensor = self.normalizer_fn(input_tensor)\r\n  File \"<ipython-input-12-137e79726dfc>\", line 8, in <lambda>\r\n    seq_cols = tf.contrib.feature_column.sequence_numeric_column('test', default_value=.0, normalizer_fn=lambda x: (x - 2.) / .3)\r\nTypeError: unsupported operand type(s) for -: 'SparseTensor' and 'float'\r\n```\r\nNote that tf.contrib.feature_column.sequence_numeric_column is actually meant for sparse tensors so moving to dense is not an option here.\r\n\r\nI am running tf 1.11.0 on python2.7", "comments": ["Apparently a similar error arises with `tf.feature_column.numeric_column` when inputs have dtype `int`.\r\n\r\nHere is an example:\r\n\r\n```\r\na = np.reshape(np.arange(12), (12, 1))\r\nwith tf.Session() as sess:\r\n    a_t = tf.constant(a)\r\n    seq_cols = tf.feature_column.numeric_column('test', default_value=.0, normalizer_fn=lambda x: (x - 2.) / .3)\r\n    seq_features = tf.feature_column.input_layer({'test': a_t}, [seq_cols])\r\n\r\n    b = sess.run(seq_features)\r\n```\r\n\r\nInterestingly changing the above snippet with \r\n\r\n`a = np.reshape(np.arange(12, dtype=np.float32), (3, 4, 1))`\r\n\r\nsolve the issue on `tf.feature_column.numeric_column` but surprisingly not with `tf.contrib.feature_column.sequence_numeric_column`", "@cadama Hi, can you try with a lower version of tensorflow or tf-nightly and check if you still get this error. ", "@cadama - Hi, is this still an issue ?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "The issue exists even with tf1.14. "]}, {"number": 22990, "title": "Updated Tensor.java", "body": "Made variables more understandable and Documented some parts of the code. :+1:", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@mvhtech did you sign the CLA? You have to post a comment here with \"I signed it!\".", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 22989, "title": "GDR contrib- Suballocators fixes", "body": "This patch includes two fixes, all in the gdr contribution\r\nThe 1st one changes the ordering of the calls to gdr memory manager initialization and grpc initialization.\r\n\r\nThis is necessary because gdr initialization may initiates the GPU device and call GetCPUAllocator (or GetGPUAllocator), which are asserted to never occur before the registration of Suballocators to ProcessState's singleton (which happens on gdr memory manager init)\r\n\r\nThe 2nd fix is to change the cuda host sub allocators to be registered on both Numas, 0 and 1.\r\nThis fixed an error on my servers, and I think it should be fine on different setups too but please comment if you think I missed something.\r\n\r\n@byronyi @poxvoculi ", "comments": ["Thanks for the fix! I will check on our environment soon.", "Great! Note that I experienced an hang during initialization with master branch, but this also happened in vanilla grpc so it's probably unrelated. I didnt isolate the grpc problem yet but grpc and patched gdr worked with the 5 days old branch. (96a633367ecd5ae9b31e128c2436b1a3f81b27fd)\r\n\r\nEdit:\r\nTested again today, and grpc working well again on master.", "@byronyi let me know when you have confirmed that it works.", "With requested changes, I have tested the patch with CPU only, GPU without GDR, GPU with GDR but on different NUMA, and GPU with GDR on the same NUMA.\r\n\r\nThanks again!", "thanks for the comments. will go over them and re-commit tomorrow.", "@drpngx LGTM", "@yanivbl6 there's some import issue with another patch (#22559). Could you pull rebase and push again?", "Ok, but the referenced patch was my initial starting point, and I have done some rebasing since without issues.\r\n\r\nEdit:\r\nfetched and rebased on master, then forced pushed.", "@yifeif I'm not sure why it's not creating the CL after it's pulled and approved. Any idea?", "It might be due to https://blog.github.com/2018-10-21-october21-incident-report/ ", "not sure. The checks from the force push aren't done yet, but I don't think that's the problem as I didn't see any collisions when re-basing.\r\n\r\n@byronyi, I feel like I am delaying the fix with a code you already have for a while. Do you want me to close the PR so you can push what you have been testing?\r\n\r\nI can try a new PR but other than that I am out of ideas.", "OK, the process got unstuck. Now testing internally and waiting for internal review.", "@yanivbl6 It is alright. GitHub went down yesterday so let\u2019s just be patient to get this merged :)"]}, {"number": 22988, "title": "2x slower using post-training quantization from tensorflow-lite", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:  `pip install -U tf-nightly`\r\n- **TensorFlow version (use command below)**: `'1.12.0-dev20181012'`\r\n- **Python version**: 2.7.12\r\n\r\n### Describe the problem\r\nI read and run the post-training quantization code from official tensorflow Medium (https://medium.com/tensorflow/introducing-the-model-optimization-toolkit-for-tensorflow-254aca1ba0a3). \r\nThe post said the technique can result in up to 3x faster execution for relevant machine learning models. But I found during inference is 2x slower. \r\n\r\n### Source code / logs\r\nI run the Colab notebook (https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tutorials/post_training_quant.ipynb) and compare inference time before and after quantization from the *Evaluate the models* section. \r\n\r\nThe log before quantization: \r\n```\r\nAccuracy after 500 images: 0.976000\r\nAccuracy after 1000 images: 0.966000\r\nAccuracy after 1500 images: 0.958667\r\nAccuracy after 2000 images: 0.956500\r\nAccuracy after 2500 images: 0.952400\r\nAccuracy after 3000 images: 0.956667\r\nAccuracy after 3500 images: 0.957429\r\nAccuracy after 4000 images: 0.955000\r\nAccuracy after 4500 images: 0.955333\r\nAccuracy after 5000 images: 0.954800\r\nAccuracy after 5500 images: 0.958182\r\nAccuracy after 6000 images: 0.959000\r\nAccuracy after 6500 images: 0.960462\r\nAccuracy after 7000 images: 0.961571\r\nAccuracy after 7500 images: 0.963600\r\nAccuracy after 8000 images: 0.965250\r\nAccuracy after 8500 images: 0.966471\r\nAccuracy after 9000 images: 0.968222\r\nAccuracy after 9500 images: 0.969158\r\nAccuracy after 10000 images: 0.968000\r\n0.968\r\n42.6 sec\r\n```\r\n\r\nThe log after quantization: \r\n```\r\nAccuracy after 500 images: 0.976000\r\nAccuracy after 1000 images: 0.967000\r\nAccuracy after 1500 images: 0.959333\r\nAccuracy after 2000 images: 0.957000\r\nAccuracy after 2500 images: 0.952800\r\nAccuracy after 3000 images: 0.957000\r\nAccuracy after 3500 images: 0.957714\r\nAccuracy after 4000 images: 0.955500\r\nAccuracy after 4500 images: 0.955778\r\nAccuracy after 5000 images: 0.955200\r\nAccuracy after 5500 images: 0.958545\r\nAccuracy after 6000 images: 0.959333\r\nAccuracy after 6500 images: 0.960769\r\nAccuracy after 7000 images: 0.961857\r\nAccuracy after 7500 images: 0.963867\r\nAccuracy after 8000 images: 0.965500\r\nAccuracy after 8500 images: 0.966706\r\nAccuracy after 9000 images: 0.968444\r\nAccuracy after 9500 images: 0.969368\r\nAccuracy after 10000 images: 0.968300\r\n0.9683\r\n74.5 sec\r\n```\r\n\r\nThe accuracy is basically the same, but it's much slower. ", "comments": ["do you understand the principle of post-training ? how does it achieve the quant ?", "Why the issue is closed? ", "It is slower after quantization. During post training the weights are quantized whereas the activations are quantized and dequantized on the fly at inference. ", "@wt-huang Does the quantized model will using float at inference?"]}, {"number": 22987, "title": "Segmentation Fault (SIGSEGV) in middle of Training due to Runtime-statistics calculation ops.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nCustom code. The full code can be accessed [here at GitHub](https://github.com/grasseau/HAhRD/tree/master/GSOC18)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nCentOS Linux release 7.5.1804 (Core)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n('v1.8.0-0-g93bc2e2072', '1.8.0')\r\n- **Python version**:\r\nPython 2.7.5 (default, Apr 11 2018, 07:36:10)\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\ncuda-9.0-cudnn-7\r\n- **GPU model and memory**:\r\n2 Tesla V100 Nvidia GPUs, ~15 Gb each\r\n- **Exact command to reproduce**:\r\nPlease go through this instruction [here](https://github.com/BigBang0072/HAhRD/wiki/GSOC-18-Work-Summary) to run the code.\r\nThe training runs without error on small dataset. The problem arises when number of minibatches are\r\nmore per epoch keeping the batch size constant. (i.e more number of sess.run call per epoch)\r\n\r\n### Describe the problem\r\nThe training crashes with the error **Segmentation Fault (Core Dumped) in the middle of the training after around 14-18 epochs (with ~800 minibatches in each)** even though I have sufficient RAM (~12-20% utilization holding steadily before crash).\r\n\r\n![screenshot from 2018-10-14 16-46-38](https://user-images.githubusercontent.com/17550410/46916113-c4b44e00-cfd3-11e8-842b-686a42b2c486.png)\r\n\r\n**Possible Memory Leak Checked**\r\nInitially, I suspected a memory leak due to the addition of new ops after each iteration, so I finalized the graph in the training session. But this was not the source of the problem. No new nodes were added at each iteration.\r\n\r\n**Attempt 2: Locating the problem**\r\nAfter that, I ran the training on gdb (see the stack trace in logs section) and along with some commenting of the code I have almost pinpointed the source of error.  \r\nCurrently every 30 minibatch training I am saving the summary here in the code. The full code can be found [here](https://github.com/grasseau/HAhRD/blob/master/GSOC18/train_multi_gpu.py#L406)\r\n![screenshot from 2018-10-14 17-13-59](https://user-images.githubusercontent.com/17550410/46916189-c29ebf00-cfd4-11e8-9a94-08f67c12198d.png)\r\n\r\n\r\nThe train_track_op in line number 415 is a list of which looks like this:  \r\n[gradient_update_op, loss_GPU1, loss_GPU2, merged_summary_op]\r\n\r\nIf I comment out the section in lines 406-438 the training runs without error.\r\n\r\n**Attempt 3: Exact Location** \r\nNow I comment out line 422 to 438,(the part where I save timeline and summary). I have checked there is no problem due to these lines.\r\n\r\nNow if, I run merged_summary op along with rest of the training op and **comment out line 418 and 419,\r\ni.e removing the run_options and run_metadata, the training goes without error**. And if I leave these two lines uncommented the Segfault comes back.  \r\n![screenshot from 2018-10-15 17-41-41](https://user-images.githubusercontent.com/17550410/46951781-93588280-d0a6-11e8-8173-f52dfce1c3c6.png)\r\n\r\n**So, It seems some memory is being leaked when calculating the runtime statistics using  run_options and run_metadata when doing the full trace of the graph.**\r\n\r\n\r\n### Source code / logs\r\n**Stack Trace**\r\n\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7ff2d3fff700 (LWP 138819)]\r\n0x00007ff2b8b00d6f in ?? () from /usr/local/cuda-9.0/extras/CUPTI/lib64/libcupti.so.9.0\r\n\r\n(gdb) backtrace\r\n#0  0x00007ff2b8b00d6f in ?? () from /usr/local/cuda-9.0/extras/CUPTI/lib64/libcupti.so.9.0\r\n#1  0x00007ff2b8b04fd0 in ?? () from /usr/local/cuda-9.0/extras/CUPTI/lib64/libcupti.so.9.0\r\n#2  0x00007ff2b8d10c39 in ?? () from /usr/local/cuda-9.0/extras/CUPTI/lib64/libcupti.so.9.0\r\n#3  0x00007ffff77fae25 in start_thread () from /lib64/libpthread.so.0\r\n#4  0x00007ffff6e1bbad in clone () from /lib64/libc.so.6\r\n\r\n", "comments": ["CC @nluehr\r\n\r\nThis looks like an issue with CUPTI. Nathan, could you help us triage this issue?\r\n\r\nThanks in advance!", "@azaks2 The bug is not related to CUPTI.\r\n\r\nThe problem is that ExecutorState caches a raw pointer to the TraceCollector [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/executor.cc#L1369). The cached copy then outlives the owning unique_ptr created in [DirectSession::RunInternal()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/direct_session.cc#L550).\r\n\r\nEither a shared_ptr should be used (if multiple TraceCollectors can coexist) or a mutex is needed to keep direction_session from destroying the TraceCollector while it is in use by ExecutorState.", "I'm having the exact same problem with **run_options** and **run_metadata** on `tensorflow-gpu==1.12.0` (pip), `CUDA 9.0, cuDNN 7.1`, `CentOS Linux release 7.4.1708`, `Python 3.6.2`.", "@nluehr  thanks for debugging this. I see your point that things are horribly broken when there are concurrent RunInternal() calls. However, with one RunInternal() call things should work since RunInternal() waits for all executors to finish. \r\n\r\n@BigBang0072 do you have concurrent session runs?", "Not sure I see synchronization of runners in RunInternal.\r\n\r\nIn TF 1.12 I add two prints: one of `(traceing::TraceCollector*)this` in ~DeviceTracerImpl() after https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/core/platform/default/device_tracer.cc#L400 and the second of `trace_collector` after https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/core/common_runtime/executor.cc#L1578.\r\n\r\nThen I run `train_multi_gpu.py` provided above and the following output is generated before triggering a SEGFAULT at https://github.com/grasseau/HAhRD/blob/master/GSOC18/train_multi_gpu.py#L443-L447.\r\n\r\n```Using trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nDestroying DeviceTracerImpl=0x12d87c380 at tensorflow/core/platform/default/device_tracer.cc:404\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\nUsing trace_collector=0x12d87c380 at tensorflow/core/common_runtime/executor.cc:1585\r\n```\r\n\r\nSo the destructor seems to be called before the executor has completed.", "@azaks2 No, I just initiate one session while training.\r\nYou can see this here: \r\n [https://github.com/grasseau/HAhRD/blob/7eacc002672da28a1f53015227497469eb2af69d/GSOC18/train_multi_gpu.py#L368](url)", "I was able to reproduce the problem and have a fix. The problem was the data pipeline running concurrently with the training steps.", "Thanks for all your time.\r\nBut we have to run the data pipeline concurrently with the training. Otherwise, it will critically slow down our performance. Also, how is data pipeline affecting the tracing of the tensorflow graph? \r\nApart from that, if I just remove the tracing I don't get any Segmentation Fault even with the concurrent data pipeline running.\r\n\r\nMaybe I am missing something. Could you please elaborate on what you have found?\r\n\r\nThanks again for your help and time.", "I just fixed the lifetime of internal profiling related objects so they do not get GCed at the end of session.run", "I'm encountering a really similar issue with multi gpu (replicate_model_fn) training and a parallel data pipeline. Several hours into the training loop, and with no warning/error message, we get a segmentation fault from tf, and the training halts. Is this a known issue and if so, is it solved in a newer release?", "Dont log metadata for now, or log it very infrequently (mostly when you want to debug).\r\nI dont know about the newer release, but this will temporarily fix the problem."]}, {"number": 22986, "title": "tensorflow keras random seeds not working", "body": "Hello,\r\nI am using Tensorflow 1.5 and its embedded Keras on CPU.\r\nThe following simple program does not produce the same results at every run despite setting the random seeds for keras and TF\r\n\r\n    import numpy as np\r\n    np.random.seed(123)\r\n\r\n    import tensorflow as tf\r\n    tf.set_random_seed(123)\r\n    from tensorflow.python.keras.models import Sequential\r\n    from tensorflow.python.keras.layers import Dense\r\n\r\n\r\n    def create_model(input_dim, output_dim, training=True):\r\n        from tensorflow.python.keras.models import Sequential\r\n        from tensorflow.python.keras.layers import Dense\r\n        hidden_dim = 8 \r\n        model = Sequential()\r\n        model.add(Dense(input_dim=input_dim, units=hidden_dim))\r\n        model.add(Dense(units=output_dim, activation='linear'))\r\n        model.compile(loss='mse', optimizer='adam')\r\n        return model\r\n\r\n    N = 100000\r\n    X = np.random.normal(loc=0.0, scale=1.0, size=(N, 20))\r\n    Y = np.random.normal(loc=0.0, scale=1.0, size=(N, 2)) \r\n    input_dim = X.shape[1]\r\n    output_dim = Y.shape[1]\r\n\r\n    tf.reset_default_graph()\r\n    tf.set_random_seed(123)\r\n    model = create_model(input_dim, output_dim)\r\n    model.fit(X, Y, batch_size=100, epochs=1, verbose=1)\r\n\r\n    Y_pred = model.predict(X, batch_size=1)\r\n\r\n    print Y_pred[0:5]\r\n", "comments": ["Try with plain random seed first at the top of the file with 1.\r\n```\r\nfrom random import seed\r\nseed(1)\r\n```\r\nBtw, what is your python version?", "Thanks. Tried that. Does not work either. I am using Python 2.7", "What if you use random as a class?\r\n```\r\nfrom random import Random\r\n\r\nrandom = Random(123)\r\nprint random.random() \r\n```\r\nThis is working perfectly every time for me, with the same random values.", "I think the problem is with the initialisation of random values inside Keras and Tensorflow. Please take the code I put, you will see that you do not reproduce same values", "@volvador Hi, can you try with tf-nightly and see if you are running into the same problem. ", "@volvador  Is this still an issue ?  tf-nightly didn't work ?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22985, "title": "Difference in implementation of batch normalization between theano and tensorflow", "body": "Dear Sir: \r\n  I have a misunderstanding in the process of batch normalization. e.g.\r\n  The out put of convolution layer \r\n  [[[102. 138.]\r\n  [246. 282.]]]\r\n  [[[ 507.  624.]\r\n  [ 975. 1092.]]]\r\n  [[[ 912. 1110.]\r\n  [1704. 1902.]]]\r\n  I set the following config of batch norm\r\n  gamma  = [1,2,3]\r\n  beta = [0,0,0]\r\n  mean = [2,3,4]\r\n  Inv = [1/3,1/4,1/5]\r\n\r\n\r\n  Norm.append(gamma)\r\n  Norm.append(beta)\r\n  Norm.append(mean)\r\n  Norm.append(inv)\r\n \r\n\r\n  model.add(tf.keras.layers.BatchNormalization( momentum=1.0, epsilon=0,center = True,scale = True,trainable=False,renorm_momentum=1.0))\r\n  model.layers[1].set_weights(Norm)\r\n   \r\n   According to the definition of batch_norm , (x - mean/ inv)*gamma + beta, it should generate\uff1a \r\n   \r\n  [[[[   300.    408.]\r\n   [   732.    840.]]\r\n\r\n  [[  4032.   4968.]\r\n   [  7776.   8712.]]\r\n\r\n  [[ 13620.  16590.]\r\n   [ 25500.  28470.]]]]\r\n  \r\n   However, the final result is\r\n   [[[173.20248 235.55537]\r\n  [422.61404 484.96695]]]\r\n[[[2015.9596 2483.9502]\r\n  [3887.922  4355.9126]]]\r\n[[[ 6090.8965  7419.088 ]\r\n  [11403.661  12731.853 ]]]\r\n\r\n  Could anyone tell me what is wrong and how could I get the correct answer?\r\n\r\nBest Regards\r\nAllen\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have not written any custom code\r\nOS: Ubuntu 16.04\r\nTensorFlow installed from pip install \r\nVersion: 1.11.0\r\nCuda 8.0\r\ncudnn 5.0\r\n", "I have not written any custom code\nOS: Ubuntu 16.04\nTensorFlow installed from pip install\nVersion: 1.11.0\nCuda 8.0\ncudnn 5.0\nPC device\n\nAlfred Sorten Wolf <notifications@github.com> \u4e8e2018\u5e7410\u670816\u65e5\u5468\u4e8c \u4e0a\u53484:48\u5199\u9053\uff1a\n\n> Thank you for your post. We noticed you have not filled out the following\n> field in the issue template. Could you update them if they are relevant in\n> your case, or leave them as N/A? Thanks.\n> Have I written custom code\n> OS Platform and Distribution\n> TensorFlow installed from\n> TensorFlow version\n> Bazel version\n> CUDA/cuDNN version\n> GPU model and memory\n> Exact command to reproduce\n> Mobile device\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22985#issuecomment-430004591>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJuP3hQVs1i5Kstx8X9lSqh2ux04aWowks5ulPS0gaJpZM4XcF0z>\n> .\n>\n", "I try to check the detail implemented with the nn.batch_normalization layer, but I am wondering how could I get the value of mean, inv... within the batch_normalization layer", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Nagging Assignee @harshini-gadige: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22984, "title": "[XLA] Sink constants into the conditional computation in while loops", "body": "Modify the WhileLoopConstantSinking  pass so that it sinks the constants into the while loop conditional as well. From my (limited) experiments, this helps the `WhileLoopAnalysis::ComputeWhileLoopTripCount` function in being able to evaluate and get the trip count (at least for simple while loops created by `dynamic_rnn`s where the original conditional is `and`ed with the max_iterations) .", "comments": ["Thank you for the review comments! I think I have addressed all of them now.", "Done, thank you \ud83d\udc4d "]}, {"number": 22983, "title": "Feature request: reduce_random", "body": "Just as `tf.reduce_max`, `tf.reduce_random` is to randomly return the elements across dimensions of a tensor with some probabilities, such as respect to the value of the tensor at those dimensions.\r\n\r\nOr any other ways to implement it?", "comments": ["Could you first define __mathematically__ what is the operation you're requesting? I think it's not clear enough from your text description.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22982, "title": "lose some early epoch checkpoint file during training", "body": "Have I written custom code: Y\r\nOS Platform and Distribution: centos release 6.5\r\nTensorFlow installed from: pip install\r\nTensorFlow version: 1.40\r\nBazel version: N/A\r\nCUDA/cuDNN version: Cuda 8.0\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\nMobile device: N/A\r\nI found myself losing some checkpoint in the target dir after training. For example, I lose 1-13 epoch checkpoint files after 60-epoch training.\r\nI used tf.train.Saver and tf.train.Supervisor in my code:\r\n`tf.train.Supervisor(\r\n            is_chief=is_chief,\r\n            logdir=FLAGS.log_dir,\r\n            global_step=global_step,\r\n            saver=tf.train.Saver(var_list=var_list,max_to_keep=80,sharded=True),\r\n            save_model_secs=FLAGS.save_model_secs,\r\n            save_summaries_secs=FLAGS.save_summary_secs,\r\n            init_op=tf.global_variables_initializer(),\r\n            local_init_op=tf.group(tf.local_variables_initializer(),tf.tables_initializer())`\r\nwhere save_model_secs=1800, save_summary_secs=1800\r\nFYI, it costs me about 30 minutes for training 1 epoch.WHY?", "comments": ["@suzirui123 Hi, just to confirm, have you looked into protocol buffer to check the list of checkpoints ?", "@harshini-gadige I'm using distributed_training, could you please tell me where to find the protocol buffer you mentioned?", "@harshini-gadige Do you mean freeze the graph to check the pb of checkpoints? I haven't tried that.  But I succeeded restoring the checkpoint to predict auc of test data. I wonder whether this is caused by some arguments which cause the deleting of checkpoints?", "@suzirui123  - Hi, can you please try with the tensorflow latest versions(1.10 or 1.11) with CUDA /cuDNN \r\n 9/7 and see if you are running into the same problem.\r\n\r\nRequest you to provide the following information before we look into the issue. Thank you !\r\n\r\n->Small Code Snippet to reproduce the issue from our end. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22981, "title": "def TFE_ContextOptionsSetAsync(arg1, async):                                              ", "body": "Problem with installing tensorflow in Python 3.7.\r\n\r\nReferred to [#20444](https://github.com/tensorflow/tensorflow/issues/20444) but to no avail. :( ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Closing this. Temporarily working on a different virtual environment with Python 3.6 for my need.", "got this error while trying to install tensorflow. any help is highly entertained\r\n \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"E:\\School\\WEB\\django\\twitter-sentiment-analysis-web-app\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):\r\n"]}, {"number": 22980, "title": "Unable to build libtensorflow_cc.so", "body": "I'm trying to build libtensorflow_cc.so so I can utilize the C++ API of TensorFlow in my own project. But when I try to do that using the following command:\r\n\r\n`bazel build -c opt //tensorflow:libtensorflow_cc.so`\r\n\r\nI eventually get the error:\r\n\r\n```\r\n2 errors detected in the compilation of \"/tmp/tmpxft_000056f1_00000000-7_spacetobatch_functor_gpu.cu.cpp1.ii\".\r\nERROR: /home.net/aa17gil/tensorflow_from_source/tensorflow/tensorflow/core/kernels/BUILD:3825:1: output 'tensorflow/core/kernels/_objs/batch_space_ops_gpu/spacetobatch_functor_gpu.cu.pic.o' was not created\r\nERROR: /home.net/aa17gil/tensorflow_from_source/tensorflow/tensorflow/core/kernels/BUILD:3825:1: not all outputs were created or valid\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1219.021s, Critical Path: 81.53s\r\nINFO: 4992 processes: 4992 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\n\r\nAs stated in other issues, there is practically no official documentation or guide for how to build this library. I did go through many older issues, but the solutions proposed there don't work for me.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code: No**:\r\n- **OS Platform and Distribution: Ubuntu 14.04**:\r\n- **Mobile device: N/A**:\r\n- **TensorFlow installed from source**:\r\n- **TensorFlow version: cloned from master branch on 10.10.2018**:\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.17.2\r\n- **GCC/Compiler version (if compiling from source)**: GCC 4.8.4\r\n- **CUDA/cuDNN version**: CUDA 8.0, CuDNN 6.0.21\r\n- **GPU model and memory**: Nvidia GTX1050Ti\r\n- **Exact command to reproduce**: `bazel build -c opt //tensorflow:libtensorflow_cc.so`", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution", "@Ali2500 The the following command works for me:\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so\r\n```\r\nTry using bazel 0.15.0"]}, {"number": 22979, "title": "\"Unknwon layer\" error while using custom Keras layer with tf.contrib.distribute.MirroredStrategy", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. See STLSTM.py in https://gist.github.com/kami93/c49f0cdd19b318f3e2699df13971f7b1\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.1\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: Anaconda Python 3.6.6\r\n- **Bazel version (if compiling from source)**: 0.17.2\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.0\r\n- **CUDA/cuDNN version**:9.2\r\n- **GPU model and memory**:Gefroce 1080Ti * 4 (4-way GPU)\r\n- **Exact command to reproduce**: Run predRNN.py in https://gist.github.com/kami93/c49f0cdd19b318f3e2699df13971f7b1\r\n\r\n### Describe the problem\r\nHi. I am getting an \"Unknown layer\" error while running a custom keras layer with tf.contrib.distribute.MirroredStrategy turned on. The trackback is in the Source code / logs section.\r\n\r\nThe error is not raised when I omit the \"distribute\" argument from model compile method call (line 75 of the predRNN.py) so that the training runs without distribution strategy and only a single GPU works.\r\n\r\nBreif explanation on predRNN.py:\r\npredRNN.py builds input pipeline, makes, compiles and fits the Keras sequential model which includes the STLSTM2D custom layer.\r\nThe training data can be downloaded from http://www.cs.toronto.edu/~nitish/unsupervised_video/ (Moving MNIST dataset)\r\n\r\nBreif explanation on STLSTM.py:\r\nSTLSTM is a sophisticated convolutional RNN model suggested from PredRNN (Wang et al. 2017, https://papers.nips.cc/paper/6689-predrnn-recurrent-neural-networks-for-predictive-learning-using-spatiotemporal-lstms).\r\n\r\nSTLSTM.py contains three classes - STLSTM2D, StackedSTLSTMCells, STLSTMCell which inherit from the Keras RNN class(in tensorflow/python/keras/layers/recurrent.py), Keras Layer class, and Keras Layer class, repectively. \r\n\r\n- STLSTM2D  is based on ConvRNN2D class in tensorflow/python/keras/layers/convolutional_recurrent.py. It forms a Keras RNN layer that performs recurrent functions with the STLSTM Cell.\r\n\r\n- StackedSTLSTMCells is a wrapper to make a list of multiple STLSTMCells look like a single cell.\r\n\r\n- STLSTMCell is based on ConvLSTM2DCell in tensorflow/python/keras/layers/convolutional_recurrent.py. The modification is performed such that STLSTM has an additional hidden state (The M-state) and different operation procedure compared to the ConvLSTM2D.\r\n\r\n### Source code / logs\r\nSource code : https://gist.github.com/kami93/c49f0cdd19b318f3e2699df13971f7b1\r\nerror traceback : https://pastebin.com/6dPKZrzX", "comments": ["Please take a look at keras documentation for [handling custom layers (or other custom objects) in saved models](https://keras.io/getting-started/faq/#handling-custom-layers-or-other-custom-objects-in-saved-models) if haven't already.", "> Please take a look at keras documentation for [handling custom layers (or other custom objects) in saved models](https://keras.io/getting-started/faq/#handling-custom-layers-or-other-custom-objects-in-saved-models) if haven't already.\r\n\r\nWow thank you. The custom object scoping resolved my problem.\r\nex) Make, compile and fit the keras model with custom object under the custom object scope\r\n> with tf.keras.utils.custom_object_scope({'StackedSTLSTMCells':STLSTM.StackedSTLSTMCells,\r\n>                                                                  'STLSTMCell':STLSTM.STLSTMCell}):\r\n\r\n>    predRNN = keras.Sequential([\r\n>      STLSTM.STLSTM2D(cells, return_sequences=True, input_shape=(TOTAL_LEN, IMG_SIZE, IMG_SIZE, 1)),\r\n>      keras.layers.Reshape(target_shape=(IMG_SIZE*TOTAL_LEN, IMG_SIZE, FILTERS)),\r\n>      keras.layers.Conv2D(filters=1, kernel_size=1),\r\n>      keras.layers.Reshape(target_shape=(TOTAL_LEN, IMG_SIZE, IMG_SIZE, 1))\r\n>   ])", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22978, "title": "fatal error: absl/strings/string_view.h: No such file or directory", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@ShirleyYim Hi, request you to describe the problem and post a code snippet to reproduce the error. Also please provide the following information.\r\n\r\n**System information**\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version (use command below):\r\nPython version:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nExact command to reproduce:", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Same fatal appears at f905324 while building [tensorflow-object-detection-cpp](https://github.com/lysukhin/tensorflow-object-detection-cpp) with [custom](https://medium.com/@fanzongshaoxing/use-tensorflow-c-api-with-opencv3-bacb83ca5683) Tensorflow Bazel build ", "> \r\n> \r\n> Same fatal appears at [f905324](https://github.com/tensorflow/tensorflow/commit/f90532431c3785166cff35ff427b652fe460f60b) while building [tensorflow-object-detection-cpp](https://github.com/lysukhin/tensorflow-object-detection-cpp) with [custom](https://medium.com/@fanzongshaoxing/use-tensorflow-c-api-with-opencv3-bacb83ca5683) Tensorflow Bazel build\r\n\r\nU solved that ?", "> Same fatal appears at [f905324](https://github.com/tensorflow/tensorflow/commit/f90532431c3785166cff35ff427b652fe460f60b) while building [tensorflow-object-detection-cpp](https://github.com/lysukhin/tensorflow-object-detection-cpp) with [custom](https://medium.com/@fanzongshaoxing/use-tensorflow-c-api-with-opencv3-bacb83ca5683) Tensorflow Bazel build\r\n\r\nI got this error while trying to build this project too. Any update on that ? Thanks", "This issue has been resolved. Please open a new one, fill in issue template. Devs are rarely checking on closed issues."]}, {"number": 22976, "title": "ValueError: Unknown activation function:relu6", "body": "tf.keras.layers.Activation(tf.nn.relu6)(x)\r\n\r\nwhen i transform my model to tflite, this bug will happen", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 22974, "title": "[XLA] Add simple HLO if conversion pass", "body": "kConditional operations are currently generally disallowed in parallel contexts\r\n(e.g. in mapped computations). The julia XLA frontend was running into this limitation\r\nquite a bit, because existing julia code tends to use the terniary operator for select,\r\ne.g. to describe the derivative of a `max` call (and thus a `relu`) - see the\r\ndefinitions of the derivatives of `max` at\r\nhttps://github.com/JuliaDiff/DiffRules.jl/blob/master/src/rules.jl#L94\r\n\r\nTo support these sorts of patterns, add a simple if conversion pass that converts\r\nconditionals in parallel context by equivalent select operations (which are well supported),\r\ni.e. a computation like:\r\n\r\n```\r\nif {\r\n %pif = () parameter(0)\r\n ROOT %cif = f32[] constant(0)\r\n}\r\n\r\nelse {\r\n %pelse = () parameter(0)\r\n ROOT %celse = f32[] constant(1)\r\n}\r\n\r\nmapped {\r\n %a = f32[] parameter(0)\r\n %b = f32[] parameter(1)\r\n %lt = pred[] less-than(%a, %b)\r\n %t = () tuple()\r\n ROOT %conditional = f32[] conditional(%lt, %t, %t), true_computation=if, false_computation=else\r\n}\r\n\r\nENTRY comp {\r\n %p1 = f32[1000]{0} parameter(0)\r\n %p2 = f32[1000]{0} parameter(1)\r\n ROOT %mapped = f32[1000]{0} map(%p1, %p2), dimensions={0}, to_apply=mapped\r\n}\r\n```\r\n\r\ngets rewritten to\r\n\r\n```\r\nmapped {\r\n %a = f32[] parameter(0)\r\n %b = f32[] parameter(1)\r\n %cif = f32[] constant(0)\r\n %celse = f32[] constant(1)\r\n %lt = pred[] less-than(%a, %b)\r\n ROOT %select = f32[] select(%lt, %cif, %celse)\r\n}\r\n\r\nENTRY comp {\r\n %p1 = f32[1000]{0} parameter(0)\r\n %p2 = f32[1000]{0} parameter(1)\r\n ROOT %mapped = f32[1000]{0} map(%p1, %p2) dimensions={0} to_apply=mapped\r\n}\r\n```\r\n\r\nTo keep things simple, this is accomplished by first rewriting the conditional\r\nto two calls and a select and then inlining the individual calls. Naturally,\r\nthe transformation is only applied if the called computation do not\r\nhave side effects (which they generally don't if they're in parallel\r\ncontext). In the future, it would be good to let MapInliner further\r\nsimplify this to an implicitly mapped select.", "comments": ["Feedback addressed.", "Looks like there's some whitespace issues with my BUILD changes? Should I update the PR to fix that or do you want to do that as part of the merge?", "Hi Keno,\r\n\r\nIt'd be great if you could fix it on the PR itself; I believe the error message has a diff?  If you run into any unforeseen issues let me know and I'll send you a buildified BUILD file.", "Alright. Let's try that. I assume you'll have to re-trigger CI since that doesn't seem to run automatically.", "bump", "I've addressed those two comments. @davidel had some thoughts on the split of work here between HLO and the backend, but I think the conclusion ended up being that while we should fix this in the backend also, the HLO-level pass in nevertheless useful.", "@Keno Can you please resolve the conflicts? Thanks!", "done", "@Keno gentle ping. Can you please resolve the conflicts? Thanks!", "Well, I keep doing that but nothing happens after. Happy to do another rebase, but this PR tends to accumulate conflicts quickly.", "@ymodak I'm happy to manually pull in the CL to Google and check it in (and resolve the merge conflicts internally).  However it is missing the `[ready to pull]` label -- can I just add that label directly?", "@Keno do you mind resolving the conflicts? Thank you!", "I was under the impression @sanjoy would do that on import", "> I was under the impression @sanjoy would do that on import\r\n\r\nI tried to do that but it seems like we don't have a way to pull in a change with conflicts into piper (so that I can later resolve the conflicts).  @yifeif - is that accurate?", "@Keno @sanjoy @yifeif any updates on resolving conflicts ?", "Let me just do it. Sounds like that's easiest.", "> Let me just do it. Sounds like that's easiest.\r\n\r\nthank you ", "Thanks, @sanjoy."]}, {"number": 22973, "title": "Installation issue with all versions tried", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 17134.345\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nUsing pip install\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.11-GPU\r\n but error occurred when uninstalled and reinstalled with 1.8-GPU as well (slightly different one, noted below)\r\n\r\n- **Python version**:\r\n3.6.0\r\n\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA 9.0\r\ncuDNN 7.0.5\r\n\r\n- **GPU model and memory**:\r\nNVIDIA GTX 980M 8 GB memory\r\n\r\n- **Exact command to reproduce**:\r\npy -c \"import tensorflow as tf; print(tf.__version.__)\"\r\n\r\n\r\n### Describe the problem\r\nI have tried several times to install tensorflow with various versions but get the same DLL error and another issue with one of them\r\n\r\nI tried searching for the issue, and found similar ones with no real answer.\r\nOne thing I have noticed from looking at those threads is that my \"pywrap_tensorflow_internal\", and perhaps other DLLs, are missing from    ....../site-packages/tensorflow/python.\r\n\r\nAlso\r\ncudart64_90.dll' is stated to be missing when I use tensorflow-GPU 1.8\r\nand when I check my cuda/bin folder I only see cudart64_7, so that makes sense.\r\n\r\nI am not getting this error with 1.11, though, as you may note below.\r\n\r\nThis error seems simple but is frustrating me, and I would greatly appreciate all help in getting this done quickly, thanks!\r\n\r\n### Source code / logs\r\nERROR WITH 1.11:\r\nC:\\WINDOWS\\system32>py -c \"import tensorflow as tf;print(tf.__version__)\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n\r\nERROR WITH 1.8:\r\nC:\\WINDOWS\\system32>py -c \"import tensorflow as tf;print(tf.__version.__)\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ctypes\\__init__.py\", line 344, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit", "comments": ["I have updated what I tried and my errors, please look over my issue again and disregard the original post information!\r\n\r\nAlso, note that there are 2 traces provided, one time I tried tensorflow-gpu 1.11 and another I tried tensorflow-gpu 1.8. \r\nI think I should be using 1.11, but I am willing to use whatever will work!\r\n\r\nAgain,\r\n\r\nAll help greatly appreciated!", "@joshmorris23x You can follow the instructions in this [link](https://medium.com/@lmoroney_40129/installing-tensorflow-with-gpu-on-windows-10-3309fec55a00) to install TensorFlow on Windows 10.", "Closing this, feel free to reopen if running into additional errors."]}, {"number": 22972, "title": "Can't convert Keras model using tflite_convert", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS Mojave\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary (via Pip)\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: n/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: tflite_convert --keras_model_file ./mymodel.h5 --output_file ./mymodel.tflite\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm trying to convert a Keras model to TFLite, using the tflite_convert tool. However, I'm getting the below error, using Keras 2.2.4 and Tensorflow 1.11.0. I believe this to be a bug in the tool as this is just a standard H5 file which I've been using in production for months.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n```\r\n$ tflite_convert --keras_model_file ./mymodel.h5 --output_file ./mymodel.tflite\r\n2018-10-14 19:11:59.960314: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"~/anaconda3/envs/tf/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 401, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 397, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 100, in _convert_model\r\n    converter = _get_toco_converter(flags)\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 87, in _get_toco_converter\r\n    return converter_fn(**converter_kwargs)\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 356, in from_keras_model_file\r\n    keras_model = _keras.models.load_model(model_file)\r\n  File \"~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 251, in load_model\r\n    training_config['weighted_metrics'])\r\nKeyError: 'weighted_metrics'\r\n```\r\n", "comments": ["Can you please try using **tf-nightly** version? Also please take a look at documentation to [convert a keras .h5 file into tf lite](https://www.tensorflow.org/lite/convert/python_api#exporting_a_tfkeras_file_) and [additional instructions](https://www.tensorflow.org/lite/convert/python_api#converting_models_in_tensorflow_19_to_tensorflow_111_) if you haven't already.", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22971, "title": "Compile on debian with cuda 9.1, older CPU, cuda:cuda-extras failed (Segmentation fault): bash failed: error executing command", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux jet 4.18.0-2-amd64 #1 SMP Debian 4.18.10-1 (2018-09-30) x86_64 GNU/Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.11.0\r\n- **Python version**: Python 3.6.7rc1\r\n- **Bazel version (if compiling from source)**: 0.17.2 (compiled)\r\n- **GCC/Compiler version (if compiling from source)**: gcc-4.8\r\n- **CUDA/cuDNN version**: 7.3.1\r\n- **GPU model and memory**: GeForce GTX 1060 6GB \u2013 cuda 6.1\r\n- **Exact command to reproduce**: time bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n- **CPU and RAM**: AMD Phenom(tm) II X6 1090T Processor, 16Gb\r\n\r\n### Describe the problem\r\n\r\nI have to compile tensorflow myself, because of the AVX CPU extension problem (found the details about that in an [amikelive article](https://tech.amikelive.com/node-887/how-to-resolve-error-illegal-instruction-core-dumped-when-running-import-tensorflow-in-a-python-program/))\r\n\r\nIt worked compiling and then running tensorflow **without** cuda Support but **compiling with cuda** fails with the following **segmentation fault**.\r\n\r\n```\r\n\u2026\r\nERROR: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/local_config_cuda/cuda/BUILD:638:1: Executing genrule @local_config_cuda//cuda:cuda-extras failed (Segmentation fault): bash failed: error executing command\r\n\u2026\r\n```\r\n\r\nSee below for full output.\r\n\r\nCommands I ran after the successful compile without cuda.\r\n\r\n```\r\nbazel clean\r\n./configure (see below)\r\ntime bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n```\r\n\r\n### Source code / logs\r\n\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.6/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild --define with_jemalloc=true\r\nbuild:gcp --define with_gcp_support=true\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:aws --define with_aws_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild:ngraph --define with_ngraph_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.1\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env NCCL_INSTALL_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_NCCL_VERSION=\"2\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc-4.8\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\n```\r\n\r\n_(Btw. why is build:kafka --define with_kafka_support=true when I said \"n\"?)_\r\n\r\nCompile output:\r\n\r\n```\r\ntime bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures        \r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nDEBUG: /home/dedeibel/src/tensorflow-gpu/tensorflow/version_check.bzl:42:5: \r\nCurrent Bazel is not a release version, cannot check for compatibility.\r\nDEBUG: /home/dedeibel/src/tensorflow-gpu/tensorflow/version_check.bzl:43:5: Make sure that you are running at least Bazel 0.15.0.\r\nDEBUG: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:115:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nWARNING: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/core/BUILD:2463:1: in includes attribute of cc_library rule //tensorflow/core:framework_internal_headers_lib: '../../external/com_google_absl' resolves to 'external/com_google_absl' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/dedeibel/src/tensorflow-gpu/tensorflow/tensorflow.bzl:1373:20\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/core/BUILD:2548:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/com_google_absl' resolves to 'external/com_google_absl' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/dedeibel/src/tensorflow-gpu/tensorflow/tensorflow.bzl:1373:20\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/core/BUILD:2562:1: in includes attribute of cc_library rule //tensorflow/core:stream_executor_headers_lib: '../../external/com_google_absl' resolves to 'external/com_google_absl' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/dedeibel/src/tensorflow-gpu/tensorflow/tensorflow.bzl:1373:20\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/timeseries/python/timeseries/BUILD:354:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /home/dedeibel/src/tensorflow-gpu/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (310 packages loaded).\r\nINFO: Found 1 target...\r\nSlow read: a 2353-byte read from /home/dedeibel/src/tensorflow-gpu/tensorflow/core/distributed_runtime/rpc/grpc_util.cc took 5849 ms.\r\nSlow read: a 1998-byte read from /home/dedeibel/src/tensorflow-gpu/tensorflow/core/kernels/scatter_op_gpu.cu.cc took 5849 ms.\r\nERROR: /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/external/local_config_cuda/cuda/BUILD:638:1: Executing genrule @local_config_cuda//cuda:cuda-extras failed (Segmentation fault): bash failed: error executing command \r\n  (cd /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/opt/groovy/bin:/opt/grails/bin:/opt/gradle/bin:/home/dedeibel/bin:/home/dedeibel/ruby_bin:/home/dedeibel/perl_bin:/my/games/bin:/opt/bin:/home/dedeibel/opt/android/platform-tools:/home/dedeibel/go/bin:/opt/groovy/bin:/opt/grails/bin:/opt/gradle/bin:/home/dedeibel/bin:/home/dedeibel/ruby_bin:/home/dedeibel/perl_bin:/my/games/bin:/opt/bin:/home/dedeibel/opt/android/platform-tools:/home/dedeibel/go/bin \\\r\n  /bin/bash bazel-out/host/genfiles/external/local_config_cuda/cuda/cuda-extras.genrule_script.sh): bash failed: error executing command \r\n  (cd /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/opt/groovy/bin:/opt/grails/bin:/opt/gradle/bin:/home/dedeibel/bin:/home/dedeibel/ruby_bin:/home/dedeibel/perl_bin:/my/games/bin:/opt/bin:/home/dedeibel/opt/android/platform-tools:/home/dedeibel/go/bin:/opt/groovy/bin:/opt/grails/bin:/opt/gradle/bin:/home/dedeibel/bin:/home/dedeibel/ruby_bin:/home/dedeibel/perl_bin:/my/games/bin:/opt/bin:/home/dedeibel/opt/android/platform-tools:/home/dedeibel/go/bin \\\r\n  /bin/bash bazel-out/host/genfiles/external/local_config_cuda/cuda/cuda-extras.genrule_script.sh)\r\nSlow read: a 54035688-byte read from /home/dedeibel/.cache/bazel/_bazel_dedeibel/216944cd492986130e450b1bf5cd7b5e/execroot/org_tensorflow/bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/lib/libcublas.so.9.1 took 5918 ms.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2592.039s, Critical Path: 23.55s\r\nINFO: 58 processes: 58 local.\r\nFAILED: Build did NOT complete successfully\r\nbazel build --config=opt --config=cuda  --verbose_failures  0.28s user 0.17s system 0% cpu 43:15.42 total\r\n```\r\n\r\nSince I don't know what to do differently I suspect a bug and would love to get some advice. If it is my mistake, I am sorry to bother you.", "comments": ["@dedeibel Hi, thanks for the post. The following links would take you through the steps to install tensorflow from source. Hope you find these helpful to make sure all the steps are covered in the build process.\r\n\r\n1) [Build from source](https://www.tensorflow.org/install/source)\r\n2) [Install Tensorflow GPU from source](https://www.python36.com/install-tensorflow141-gpu/)", "Thanks for the hints to some other guides. I managed to compile it now. The guides for ubuntu where not applicable so I chose to install everything by hand.\r\n\r\nMy path was now to remove all debian distribution nvidia packages. Then install all libs and tools with matching version numbers.\r\n\r\n- bazel 0.15\r\n- geforce driver NVIDIA-Linux-x86_64-410.66.run\r\n- cuda_9.1.85_387.26_linux.run\r\n- cuda_9.1.85.1_linux.run (patche)\r\n- cuda_9.1.85.2_linux.run (patche)\r\n- cuda_9.1.85.3_linux.run (patche)\r\n- cudnn-9.1-linux-x64-v7.1.tgz\r\n- nccl_2.1.15-1+cuda9.1_x86_64.txz\r\n- gcc-4.8\r\n\r\nMy bazel config:\r\n\r\n```\r\n.tf_configure.bazelrc\r\n\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/lib/python3/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild --define with_jemalloc=true\r\nbuild:gcp --define with_gcp_support=true\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:aws --define with_aws_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild:ngraph --define with_ngraph_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.1\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-9.1\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env NCCL_INSTALL_PATH=\"/usr/local/cuda-9.1\"\r\nbuild --action_env TF_NCCL_VERSION=\"2\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/cuda-9.1/lib64\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc-4.8\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\n```\r\n\r\n(I tested cuda by runnig the samples, but had to add some env variables for it to build through \r\n`EXTRA_LDFLAGS='-lstdc++ -lm' HOST_COMPILER=/usr/bin/g++-6 CXX=/usr/bin/g++-6 CC=/usr/bin/gcc-6 make`\r\n\r\nAnd had to \"fix\" this line and add the output redirection to /dev/null.\r\n\r\n```\r\n0_Simple/UnifiedMemoryStreams/Makefile:$(shell echo \"#include <omp.h>\" > test.c ; echo \"int main() { omp_get_num_threads(); return 0; }\" >> test.c ; $(HOST_COMPILER) -fopenmp test.c > /dev/null 2> /dev/null)\r\n```)\r\n\r\n"]}, {"number": 22970, "title": "protobuf not seem to be recognized but it is installed", "body": "(base) D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection>python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config\r\nTraceback (most recent call last):\r\n  File \"legacy/train.py\", line 49, in <module>\r\n    from object_detection.builders import dataset_builder\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\builders\\dataset_builder.py\", line 27, in <module>\r\n    from object_detection.data_decoders import tf_example_decoder\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\data_decoders\\tf_example_decoder.py\", line 24, in <module>\r\n    from object_detection.protos import input_reader_pb2\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\protos\\input_reader_pb2.py\", line 11, in <module>\r\n    from google.protobuf import descriptor_pb2\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor_pb2.py\", line 1114, in <module>\r\n    serialized_options=None, file=DESCRIPTOR),\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 534, in __new__\r\n    return _message.default_pool.FindFieldByName(full_name)\r\nKeyError: \"Couldn't find field google.protobuf.FileOptions.php_metadata_namespace\"\r\n\r\n(base) D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection>python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config\r\nTraceback (most recent call last):\r\n  File \"legacy/train.py\", line 49, in <module>\r\n    from object_detection.builders import dataset_builder\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\builders\\dataset_builder.py\", line 27, in <module>\r\n    from object_detection.data_decoders import tf_example_decoder\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\data_decoders\\tf_example_decoder.py\", line 24, in <module>\r\n    from object_detection.protos import input_reader_pb2\r\n  File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\protos\\input_reader_pb2.py\", line 11, in <module>\r\n    from google.protobuf import descriptor_pb2\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor_pb2.py\", line 1114, in <module>\r\n    serialized_options=None, file=DESCRIPTOR),\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 534, in __new__\r\n    return _message.default_pool.FindFieldByName(full_name)\r\nKeyError: \"Couldn't find field google.protobuf.FileOptions.php_metadata_namespace\"\r\n\r\nPlease F1 aka Help\r\n", "comments": ["> (base) D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection>python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config\r\n> Traceback (most recent call last):\r\n> File \"legacy/train.py\", line 49, in \r\n> from object_detection.builders import dataset_builder\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\builders\\dataset_builder.py\", line 27, in \r\n> from object_detection.data_decoders import tf_example_decoder\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\data_decoders\\tf_example_decoder.py\", line 24, in \r\n> from object_detection.protos import input_reader_pb2\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\protos\\input_reader_pb2.py\", line 11, in \r\n> from google.protobuf import descriptor_pb2\r\n> File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor_pb2.py\", line 1114, in \r\n> serialized_options=None, file=DESCRIPTOR),\r\n> File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 534, in **new**\r\n> return _message.default_pool.FindFieldByName(full_name)\r\n> KeyError: \"Couldn't find field google.protobuf.FileOptions.php_metadata_namespace\"\r\n> \r\n> (base) D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection>python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config\r\n> Traceback (most recent call last):\r\n> File \"legacy/train.py\", line 49, in \r\n> from object_detection.builders import dataset_builder\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\builders\\dataset_builder.py\", line 27, in \r\n> from object_detection.data_decoders import tf_example_decoder\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\data_decoders\\tf_example_decoder.py\", line 24, in \r\n> from object_detection.protos import input_reader_pb2\r\n> File \"D:\\FINAL YEAR\\Final Project Fanally\\Project\\Workshop\\TensorFlow\\models\\object_detection\\protos\\input_reader_pb2.py\", line 11, in \r\n> from google.protobuf import descriptor_pb2\r\n> File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor_pb2.py\", line 1114, in \r\n> serialized_options=None, file=DESCRIPTOR),\r\n> File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 534, in **new**\r\n> return _message.default_pool.FindFieldByName(full_name)\r\n> KeyError: \"Couldn't find field google.protobuf.FileOptions.php_metadata_namespace\"\r\n> \r\n> Please F1 aka Help\r\n\r\nfound a solution working:\r\n\r\nUninstalled protobuf           => pip3 uninstall protobuf\r\nand Installed protobuf        => pip3 install protobuf\r\n\r\n", "@phishekwa Glad to know that you are able to use it after reinstalling protobuf. Feel free to close this issue if it is resolved. Thank you !"]}, {"number": 22969, "title": "ValueError: sequence_length must be a vector of length batch_size, but saw shape: (24, 1, 2)", "body": "import tensorflow as tf\r\n\r\nI am working with lstm using tensor flow when I am running the code it is showing me the error. the code is running fine but when I am running the function tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float64) it is showing Value ERROR\r\n\r\nwordsList = np.load('urduwords.npy')\r\nwordVectors = np.load('urduwordsMatrix.npy')\r\n\r\nbatchSize = 24\r\nlstmUnits = 64\r\nnumClasses = 2\r\niterations = 10000\r\n\r\ntf.reset_default_graph()\r\n\r\n\r\nlabels = tf.placeholder(tf.float32, [batchSize, numClasses])\r\ninput_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\r\n\r\nprint(labels)\r\n\r\ndata = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\r\nprint(data)\r\n\r\n\r\ndata = tf.nn.embedding_lookup(wordVectors,input_data)\r\nprint(data)\r\n\r\n\r\nlstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\r\nlstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.1)\r\n\r\nvalue, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float64)\r\n\r\ndata_mask = tf.cast(data, tf.bool)\r\ndata_len = tf.reduce_sum(tf.cast(data_mask, tf.float32), axis=1)\r\ntf.nn.dynamic_rnn(lstmCell, data, sequence_length=data_len, initial_state=initial_state)\r\n\r\nsequence_length must be a vector of length batch_size, but saw shape: (24, 1, 2)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tayyabvohra Hi, thanks for the post. Could you provide the length and shape of _data_len_. \r\nAlso can you try hard coding the sequence_length and check if tf.nn.dynamic_rnn works in that case.", "this is the shape of data when i am running  tf.nn.embedding_lookup(wordVectors,input_data) and the ouput i get \r\n\r\nTensor(\"embedding_lookup:0\", shape=(24, 30, 1, 2), dtype=int32)\r\n\r\n", "this is the shape of wordVectors array\r\n\r\n[[[    0     1]]\r\n\r\n [[    1     1]]\r\n\r\n [[    2     1]]\r\n\r\n ...\r\n\r\n [[14784     1]]\r\n\r\n [[14784     1]]\r\n\r\n [[11095     1]]]", "I have shape of input_data is\r\n\r\n`Tensor(\"Placeholder_1:0\", shape=(24, 30), dtype=int32)\r\n\r\nand when i am running the tf.nn.embedding_lookup(wordVectors,input_data) then shape of my data is\r\n\r\nTensor(\"embedding_lookup:0\", shape=(24, 30, 1, 2), dtype=int32)\r\nI am getting error when i am running the function tf.nn.dynamic_rnn()\r\n\r\nthis is my code\r\n\r\nimport tensorflow as tf\r\n\r\nbatchSize = 24\r\nlstmUnits = 64\r\nnumClasses = 2\r\niterations = 10000\r\nmaxSeqLength=30\r\nnumDimensions = 200 #Dimensions for each word vector\r\n\r\ntf.reset_default_graph()\r\n\r\nlabels = tf.placeholder(tf.int32, [batchSize, numClasses])\r\ninput_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\r\ndata = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]))\r\ndata = tf.nn.embedding_lookup(wordVectors,input_data)\r\nlstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\r\ninitial_state = lstmCell.zero_state(batchSize, dtype=tf.int32)\r\nlstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.25)\r\nvalue, _=tf.nn.dynamic_rnn(lstmCell,data,initial_state=initial_state,dtype=tf.float32)\r\nthis is the shape of my wordVectors\r\n\r\n[[[    0     1]]\r\n\r\n [[    1     1]]\r\n\r\n [[    2     1]]\r\n\r\n ...\r\n\r\n [[14784     1]]\r\n\r\n [[14784     1]]\r\n\r\n [[11095     1]]]\r\nValueError: Input 0 of layer basic_lstm_cell_1 is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: [24, 1, 2]", "any help from anyone @harshini-gadige  @tensorflowbutler ", "@tayyabvohra, you might want to double check the shape of the wordVectors loaded. Looks like it might have an extra dimension.\r\nThis issue is more suitable for stackoverflow, so I'm going to go ahead and close it. Let us know if you run into any bug or usability issue in the code. Thanks!"]}, {"number": 22968, "title": "remove noisy warning in StepCounterHook", "body": "fix #21523", "comments": ["@case540 Hi, could you give me a hand? Thanks.", "@xiejw Hi, would you mind taking a look?", "Nagging Reviewer @rchao: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@rchao Thanks for your review.", "@rthadur Thanks :-)"]}, {"number": 22967, "title": "libcublas.so.9.0: cannot open shared object file: No such file or directory", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["System information\r\n\r\n    Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):no\r\n    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n    TensorFlow installed from (source or binary):binary using pip install tensorflow-gpu\r\n    TensorFlow version (use command below):\r\n    Python version:3\r\n    Bazel version (if compiling from source):\r\n    GCC/Compiler version (if compiling from source):\r\n    CUDA/cuDNN version:10.0\r\n    GPU model and memory:P100\r\n    Exact command to reproduce:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow versi\r\n\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nSource code / logs\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.", "Closing as this is a duplicate of #22965 "]}, {"number": 22966, "title": "Revert \"Move bazel.rc to workspace root to support bazel-0.18.0\"", "body": "This reverts commit a74a3217f7ff2dbee2fb618aa658cf666861545c.\r\n\r\nBazel-0.18.0 is changing where it searches for .bazelrc files.\r\nOriginally it was removing /tools/bazel.rc and only using /.bazelrc.\r\nThis causes issues for gitignoring /.bazelrc and 0.18.0 has temporarily\r\nadded tools/bazel.rc back to the list until 0.19. The long term solution\r\nis to use try-import but that statement is new in 0.18 and we are not\r\ngoing to bump TF's minimum right away. When 0.19 is out things will need\r\nto be changed back and the minimum bumped to 0.18.\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/22762\r\nFixes: https://github.com/tensorflow/tensorflow/pull/22906\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["https://github.com/tensorflow/tensorflow/pull/22964 has the change to use try-import but will need to wait until bazel-0.19 is out.", "Unassigning, to make the sync rotation pick up the merge when tests are run.", "This needed some additional changes to our internal deployment configuration, so I made an internal change that is waiting on approval.", "Thanks @angersson !", "Thank you!"]}, {"number": 22965, "title": "I installed tensorflow-gpu using command  pip3 install tensorflow-gpu   but when I import tensorflow it throws error like this  ImportError: libcuda.so.9: cannot open shared object file: No such file or directory", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@abajaj945 Please find similar issue [10642](https://github.com/tensorflow/tensorflow/issues/10642). You should be able to use nvidia-docker to install TensorFlow.", "Closing this, feel free to reopen if problem persists."]}, {"number": 22964, "title": "Update to bazel-0.18.0 and use try-import", "body": "Bazel-0.18.0 adds a try-import option that will non-fatally try and\r\nimport a file. Use this for the configure options so that .bazelrc does\r\nnot need to change. ./configure rewriting .bazelrc makes using the git\r\nrepo annoying because the file is changed.\r\n\r\nAlso optionally import a /.bazelrc.user file that is gitignored so\r\nuser-specific options can go in there.\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/22762\r\nFixes: https://github.com/tensorflow/tensorflow/pull/22906\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["Bazel-0.18.0 is due out on monday. Lets merge this in as soon as we can. Having ./configure edit the .bazelrc is causing a lot of annoyance.", "Bumping the minimum required version to the cutting edge version has caused many issues before.\r\nDue to this, I am against this change in minimum requirement until at least bazel 0.19 is out.", "@gunan okay fair enough. In that case bazel-0.18.0 has temporarily added back reading tools/bazel.rc so I'll make a separate PR to move things back there then when 0.19.0 is out we do this change.", "The issue #22449 might be related (needs bazel `update > 0.17.1`).", "@gunan @perfinion It looks like bazel 0.19.0 has been released:\r\nhttps://github.com/bazelbuild/bazel/issues/6116", "Since Bazel 0.19.0 has come out, can we try again to merge this change?\r\nCurrently,  TensorFlow has been disabled from Bazel downstream projects due to the bazelrc file change, I wound like to bring it back before we cut 0.20.0.", "@perfinion Is this PR going to fix TF build with Bazel 0.19.0? If so, can you try to resolve the conflicts? Thanks!", "@gunan okay to merge now? bazel 0.19 is out", "We need to upgrade Bazel to 0.18.1 on all CI machines before merging this.", "@meteorcloudy Is that upgrade only required on TensorFlow's CI machines?\r\n@av8ramit  What do we need to do to upgrade Bazel on the CI machines?", "@angersson Yes, in order not to break anything, we should upgrade Bazel on all TF CI machines.\r\nBut, of course, after merging this change, anyone wants to build TensorFlow from HEAD needs at least 0.18.X.", "@meteorcloudy, then this change needs to be done internally, to be able to make all the test infra changes atomicly.\r\nWould you like to import this change and make those upgrades? @yifeif can provide the instructions to start by importing this change internally.", "Sounds good, I can help import this change and make those upgrades!", "Nagging Assignee @case540: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I updated this. min version is 0.18.0, max is 0.20.0. I added an env variable to skip the max bazel version check to make testing new versions easier.\r\nUser-specific changes should go in .bazelrc.user which is gitignored. Nothing should edit .bazelrc anymore since it is no longer gitignored.\r\n\r\nLooks like the the CI builds are all failing, do they need to be upgraded?", "Yes, looks like Bazel is still 0.16.1 on Ubuntu. Can we upgrade to the latest Bazel on all CI machines?\r\n@gunan @yifeif ", "@meteorcloudy I'll send you a change to upgrade ubuntu to the same bazel version internally. Ping me if you need help with pulling this PR in.", "@perfinion The Bazel version on CI machines has been upgraded now, can you rebase this PR again then we can rerun the presubmit for it. ;)"]}, {"number": 22963, "title": "Subclassing the tf.keras.model.Model class, throw \"ValueError: You tried to call `count_params` on dense_81, but the layer isn't built. You can build it manually via: `dense_81.build(batch_input_shape)`.\"", "body": "The example code :\r\n```python\r\nfrom tensorflow.keras.models import Sequential, Model\r\nfrom tensorflow.keras.layers import Dense, Input\r\n\r\nclass MyModel(Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.dense = Dense(4)\r\n    \r\n    def call(self, inputs):\r\n  \r\n        return self.dense(inputs)\r\n    \r\nmodel = MyModel()\r\n# inputs = Input(shape=(None, 10))\r\nmodel.build((None, 10))\r\nmodel.summary()\r\n```\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-103-b62d1ffe41d5> in <module>()\r\n     14 # inputs = Input(shape=(None, 10))\r\n     15 model.build((None, 10))\r\n---> 16 model.summary()\r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\engine\\network.py in summary(self, line_length, positions, print_fn)\r\n   1551                               line_length=line_length,\r\n   1552                               positions=positions,\r\n-> 1553                               print_fn=print_fn)\r\n   1554 \r\n   1555 \r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py in print_summary(model, line_length, positions, print_fn)\r\n    221   for i in range(len(layers)):\r\n    222     if sequential_like:\r\n--> 223       print_layer_summary(layers[i])\r\n    224     else:\r\n    225       print_layer_summary_with_connections(layers[i])\r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py in print_layer_summary(layer)\r\n    177     name = layer.name\r\n    178     cls_name = layer.__class__.__name__\r\n--> 179     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\r\n    180     print_row(fields, positions)\r\n    181 \r\n\r\n~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in count_params(self)\r\n   1324                          ', but the layer isn\\'t built. '\r\n   1325                          'You can build it manually via: `' + self.name +\r\n-> 1326                          '.build(batch_input_shape)`.')\r\n   1327     weight_shapes = [w.shape.as_list() for w in self.weights]\r\n   1328     return int(sum([np.prod(w) for w in weight_shapes]))\r\n\r\nValueError: You tried to call `count_params` on dense_84, but the layer isn't built. You can build it manually via: `dense_84.build(batch_input_shape)`.\r\n```\r\n\r\n>The environment in below:\r\nOS Platform: Window10 64bit\r\nDistribution: N\r\ntools: Jupyter Notebook\r\nPython:  python3.5\r\nTensorflow: tensorflow-gpu1.10 by pip installed\r\nBazel version: N\r\nCUDA: 9.0\r\ncuDNN: 7.0\r\nGPU: Quadro M2000/4G\r\nMobile device: N\r\n\r\nIn **Jupyter** result thrown ValueError, but result show as below in **Colab**\r\n```\r\n_______________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense_2 (Dense)              multiple                  44        \r\n=================================================================\r\nTotal params: 44\r\nTrainable params: 44\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler Thank for you reply. I am sorry, I will update the issue", "I have solved the reason for the question", "> I have solved the reason for the question\r\n\r\nHow did you solve that problem?\r\nUpdated to latest version of tensorflow and problem solved.", "@jaydu1 I ignore the eager mode", "Nagging Assignee @ymodak: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Please use the latest version of TensorFlow and test again. I was able to execute your script in jupyter successfully in TF version 1.11 and later. Feel free to reopen the issue if the problems still persists. Thanks!", "I receive \"ValueError: You tried to call `count_params` on digits, but the layer isn't built. You can build it manually via: `digits.build(batch_input_shape)`.\"  at line new_model.summary(). I'm using TF 2.0.\r\n\r\ninputs = keras.Input(shape=(784,), name='digits')\r\nx = layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\nx = layers.Dense(64, activation='relu', name='dense_2')(x)\r\noutputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\nmodel = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\r\nmodel.summary()\r\n\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784).astype('float32') / 255\r\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\r\n\r\nmodel.compile(loss='sparse_categorical_crossentropy',\r\n              optimizer=keras.optimizers.RMSprop(),\r\n              metrics=['accuracy'])\r\nhistory = model.fit(x_train, y_train,\r\n                    batch_size=64,\r\n                    epochs=2)\r\n\r\nmodel.save('saved_model', save_format='tf')\r\nnew_model = keras.models.load_model('saved_model')\r\nnew_model.summary()", "> I receive \"ValueError: You tried to call `count_params` on digits, but the layer isn't built. You can build it manually via: `digits.build(batch_input_shape)`.\" at line new_model.summary(). I'm using TF 2.0.\r\n> \r\n> inputs = keras.Input(shape=(784,), name='digits')\r\n> x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\n> x = layers.Dense(64, activation='relu', name='dense_2')(x)\r\n> outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\n> model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\r\n> model.summary()\r\n> \r\n> (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n> x_train = x_train.reshape(60000, 784).astype('float32') / 255\r\n> x_test = x_test.reshape(10000, 784).astype('float32') / 255\r\n> \r\n> model.compile(loss='sparse_categorical_crossentropy',\r\n> optimizer=keras.optimizers.RMSprop(),\r\n> metrics=['accuracy'])\r\n> history = model.fit(x_train, y_train,\r\n> batch_size=64,\r\n> epochs=2)\r\n> \r\n> model.save('saved_model', save_format='tf')\r\n> new_model = keras.models.load_model('saved_model')\r\n> new_model.summary()\r\nI got same issure,have you solved the problem?I also find this problem when I save as tf and then to load.I use tensorflow2.0\r\n", "> @jaydu1 I ignore the eager mode\r\n\r\nI got this problem when use tf2.0,tf2.0 is not all eager mode\uff1f", "> > @jaydu1 I ignore the eager mode\r\n> \r\n> I got this problem when use tf2.0,tf2.0 is not all eager mode\uff1f\r\n\r\nhave you resovled it ? thx, i met the same problem", "> > > @jaydu1 I ignore the eager mode\r\n> > \r\n> > \r\n> > I got this problem when use tf2.0,tf2.0 is not all eager mode\uff1f\r\n> \r\n> have you resovled it ? thx, i met the same problem\r\n\r\nI think even if we are using the eager mode, we can build the model by passing an input tensor to the model (i.e., a forward pass). After the model is fully built, hopefully, we can call the `summary` function."]}, {"number": 22962, "title": "How is loss (and average loss) computed in Canned estimators?", "body": "### System information\r\n- **Largely irrelevant, the issue concerns documentation**\r\n- **Tensorflow 1.11 (stable)**\r\n\r\n\r\nDocumentation only specifies:\r\n\r\n> loss (mean loss per mini-batch) and the average_loss (mean loss per sample)\r\n\r\nI understand that this might seem like enough, but since there are several, very different algorithms for computing loss (absolute, relative, square etc.), this can make a big difference.\r\n\r\nEspecially if you are comparing your custom estimator, with canned alternatives.\r\n\r\nFor example, I make my own DNN classifier, I run it and get eval dict with keys loss, accuracy, and global_step.  But does the `loss` key represent the same thing it does in canned equivalent? And even if it does, which algorithm I should pick if I want to compute average loss? \r\n\r\nIf you are using the canned estimators as a baseline, and many beginners do, then making wrong assumptions about metrics is the worst possible option.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This is a deficiency in documentation, not a bug report.", "@GSonderling For DNN classifier, loss is calculated by using softmax cross entropy.\r\n\r\nThere are many different types of losses and how they are calculated, please refer to [`tf.losses`.](https://www.tensorflow.org/api_docs/python/tf/losses). You should be able to modify the code to get average loss depending on how you define it.\r\n\r\n", "Closing this, feel free to reopen if running into any errors."]}, {"number": 22961, "title": "Fix MacOSX build failure", "body": "While building tensorflow on MaxOSX\r\n(`Apple LLVM version 10.0.0 (clang-1000.11.45.2)`, `Python 2.7.10`)\r\nthe following build failure surfaced:\r\n```\r\nIn file included from tensorflow/python/eager/pywrap_tfe_src.cc:18:\r\nIn file included from ./tensorflow/python/eager/pywrap_tfe.h:22:\r\nIn file included from ./tensorflow/core/lib/core/status.h:23:\r\nIn file included from bazel-out/host/genfiles/tensorflow/core/lib/core/error_codes.pb.h:9:\r\nIn file included from external/protobuf_archive/src/google/protobuf/stubs/common.h:39:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/iostream:38:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/ios:216:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__locale:518:15: error: C++ requires a type specifier for all declarations\r\n    char_type toupper(char_type __c) const\r\n              ^\r\nbazel-out/host/genfiles/external/local_config_python/python_include/pyport.h:731:29: note: expanded from macro 'toupper'\r\n```\r\n\r\nThis fix fixes the build failure.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["I'm somewhat confused about why people are running into this now when our Mac tests aren't failing. It looks like it's fixed with https://github.com/python/cpython/commit/98ba455b9afe3fa78751ecae2e9d29f1ba82e7f7 (https://bugs.python.org/issue10910). Does 2.7.10 not have that fix? Can you upgrade?\r\n\r\nIf we do need a workaround, what about:\r\n\r\n```\r\n#undef isalnum\r\n#undef isalpha\r\n#undef islower\r\n#undef isspace\r\n#undef isupper\r\n#undef tolower\r\n#undef toupper\r\n```", "@allenlavoie: With Mac users if they use the Homebrew-provided python then they'll have no problem. I had hit this issue with the system-provided python which is rarely updated. I think this PR is reasonable in its current state."]}]