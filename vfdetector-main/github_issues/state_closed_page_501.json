[{"number": 38735, "title": "Confusing use of \"Validation Set\" in beginner example", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/quickstart/beginner\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTutorial makes use of model.evaluate(), and the documentation says that this is usually done on a \"Validation Set\". Everything else I read (glossary, docs for model.fit()... including validation set parameters) points to this relating to a \"Test Set\" since it occurs after the training phase, and the parameters passed are \"x_test\" and \"y_test\". The confusion is unhelpful to beginners. Change from \"Validation Set\" to \"Test Set\"?\r\n\r\n### Correct links\r\n\r\nn/a\r\n\r\n### Parameters defined\r\n\r\nn/a\r\n\r\n### Returns defined\r\n\r\nn/a\r\n\r\n### Raises listed and defined\r\n\r\nn/a\r\n\r\n### Usage example\r\n\r\nn/a\r\n\r\n\r\n### Request visuals, if applicable\r\nn/a\r\n\r\n### Submit a pull request?\r\n\r\nNo. I'm a beginner, so I don't want to do anything, lest I create more confusion.\r\n", "comments": ["Hi, @omatai let me help you clarify.\r\nWe usually perform training on data using `model.fit(x_train, y_train)`. Since we know this data we cannot perform testing on this data. Hence we create two sets.\r\n\r\n- One is called the validation set and other called the test set. We validate our learning on the validation and performing testing on the test set. Here for simplicity, we did not divide our data into three parts.\r\n\r\n- I think rather than skipping it maybe raise a PR which shows training, validation and testing all three done clearly.\r\n\r\nWould that be fine @omatai ?", "As a beginner quickstart example, it might help to say:\r\n\r\n  *   Model.fit() has fit the model to the data using the training set, but we have not provided a validation set to model.fit() so that we can control the quality of fit. Lets bypass any concerns about over-fitting, and proceed to use model.evaluate() on a test set.\r\n\r\nThat is in line with my understanding of what the code is doing. I would keep the code the same, and adjust the documentation text.\r\n\r\nFrom: Aditya Oke <notifications@github.com>\r\nSent: Wednesday, 22 April 2020 9:16 am\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Paul Qualtrough <paulq@alchemysort.com>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] Confusing use of \"Validation Set\" in beginner example (#38735)\r\n\r\n\r\nHi, @omatai<https://github.com/omatai> let me help you clarify.\r\nWe usually perform training on data using model.fit(x_train, y_train). Since we know this data we cannot perform testing on this data. Hence we create two sets.\r\n\r\n  *   One is called the validation set and other called the test set. We validate our learning on the validation and performing testing on the test set. Here for simplicity, we did not divide our data into three parts.\r\n  *   I think rather than skipping it maybe raise a PR which shows training, validation and testing all three done clearly.\r\n\r\nWould that be fine @omatai<https://github.com/omatai> ?\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/38735#issuecomment-617418014>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AIQOMW5FCPOQXAJAFN4N5ALRNYEHJANCNFSM4MNAGXIA>.\r\n", "- Ok Let me fix as you say. I will make it clearer in documentation. ", "@omatai I have fixed as you said. Please have a look at the pull request.", "@omatai This PR [link](https://github.com/tensorflow/docs/pull/1549) is added. I hope it solves the issue.", "- It is fixed. PR is merged.", "I don\u2019t think it is fixed in  a way that will prevent future confusion \u2013 the links to both Validation Set and Test Set describe different things: validation set is related to training phase; test set is related to testing phase. The comment relates to testing phase, so if validation set is going to be mentioned at all, it needs further explanation as to why\u2026 which could be that the standard naming convention used on Tensorflow is not strictly adhered to and not universal.\r\n\r\nI don\u2019t think I\u2019m confused any more, but I expect others will be confused at some point. But hey: I\u2019m reasonably rusty on all this\u2026 and have much higher priorities. Thanks for your time \ud83d\ude0a\r\n\r\nFrom: Aditya Oke <notifications@github.com>\r\nSent: Thursday, 23 April 2020 2:27 am\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\r\nCc: Paul Qualtrough <paulq@alchemysort.com>; Mention <mention@noreply.github.com>\r\nSubject: Re: [tensorflow/tensorflow] Confusing use of \"Validation Set\" in beginner example (#38735)\r\n\r\n\r\n@omatai<https://github.com/omatai> This PR link<https://github.com/tensorflow/docs/pull/1549> is added. I hope it solves the issue.\r\n\r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/38735#issuecomment-617812384>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AIQOMW6SGCQ6FRMEU4IHG3DRN35DLANCNFSM4MNAGXIA>.\r\n", "@omatai I think the fix solves the problem as the definition for validation and test set has been interlinked. Please go ahead and close this issue as I think there is no confusion here. Thanks!"]}, {"number": 38734, "title": "What version of gast is required?", "body": "\r\n**System information**\r\n- OS Platform and Distribution : MacOS 10.14.3 \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n**Describe the problem**\r\nIn file [`setup.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L60), gast  is required to be version 0.3.3, but after I installed tensorflow version 2.1.0, gast was version 0.2.2. I want to use gast 0.3.3, but error\r\n```Python\r\nERROR: tensorflow 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible\r\n```", "comments": ["@liym27 \r\n\r\nCan you try downgrading from gast==0.3.3 to gast==0.2.2 should work.Please install by (`!pip install gast==0.2.2`).\r\n\r\nStarting from TensorFlow 2.2.0, it will work with gast 0.3.x but NOT gast 0.2.x any more. For TF <= 2.1, gast 0.2.2 is needed.Thanks!", "> @liym27\r\n> \r\n> Can you try downgrading from gast==0.3.3 to gast==0.2.2 should work.Please install by (`!pip install gast==0.2.2`).\r\n> \r\n> Starting from TensorFlow 2.2.0, it will work with gast 0.3.x but NOT gast 0.2.x any more. For TF <= 2.1, gast 0.2.2 is needed.Thanks!\r\n\r\nThanks! \r\n Where can I download the installation package of tensorflow 2.2.0? I didn't find it. And `pip install tensorflow==2.2.0rc3` didn't work.\r\n![image](https://user-images.githubusercontent.com/33742067/79836550-de153200-83e2-11ea-809d-4b489b789758.png)\r\n", "@liym27 \r\n\r\nCan you try downgrading from gast==0.3.3 to gast==0.2.2 (by installing (`!pip install gast==0.2.2`) should work.\r\n\r\nBy installing gast=0.2.2 it should work with TF 2.1.0.Thanks!", "@ravikyram \r\n> \r\n> Can you try downgrading from gast==0.3.3 to gast==0.2.2 (by installing (`!pip install gast==0.2.2`) should work.\r\n> \r\n> By installing gast=0.2.2 it should work with TF 2.1.0.Thanks!\r\n\r\nOf course, this is a solution. Thanks!\r\n\r\nBut is there a way to download package of tensorflow 2.2.0?\r\n", "@liym27 \r\n\r\nIt is not available yet in official TF website.But you can refer #38712 .Please, use https://drive.google.com/a/google.com/uc?id=1dpTFQcBl0AWMeo5zcCWv47tpeOegEeoB&export=download .\r\nAs original issue we have provided solution, please close this issue and raise new issue for any new queries by filling issue template.Thanks!", "> It is not available yet in official TF website.But you can refer #38712 .Please, use https://drive.google.com/a/google.com/uc?id=1dpTFQcBl0AWMeo5zcCWv47tpeOegEeoB&export=download .\r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38734\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38734\">No</a>\n"]}, {"number": 38733, "title": "tf.data.DatasetSpec is not accepted as `input_signature` of `@tf.function` decorator", "body": "System info\r\n- OS Ubuntu 18.10\r\n- Tensorflow 2.2\r\n\r\nI am unable to `@tf.function`-decorate a function that would accept tf.data.Dataset and specify input signature explicitly in the function definition:\r\n\r\nSimple example that produces an error (pasted in the bottom)\r\n```\r\nsimple_dataset = tf.data.Dataset.from_tensor_slices(np.arange(10).astype(np.int32)).batch(5)\r\n\r\n# plug in the output of this as an input signature fails\r\n# tf.data.DatasetSpec.from_value(simple_dataset)\r\n\r\n@tf.function(input_signature=[\r\n        tf.data.DatasetSpec(\r\n            tf.TensorSpec(shape=(None,), dtype=tf.int32, name=None), tf.TensorShape([]))\r\n        ])\r\ndef simple_function(dataset):\r\n  pass\r\n\r\nsimple_function(simple_dataset)\r\n```\r\nAlso `get_concrete_function` method after retracing function _without specifying_ input signature also suggests the above signature should work\r\n```\r\nsimple_function.get_concrete_function(simple_dataset).structured_input_signature\r\n```\r\n\r\nTraceback when executing a function after specifying the signature:\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-222-f3452c0ea6c1> in <module>()\r\n      8   pass\r\n      9 \r\n---> 10 simple_function(simple_dataset)\r\n\r\n7 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    646       canon_args, canon_kwds = \\\r\n    647           self._stateful_fn._function_spec.canonicalize_function_inputs(  # pylint: disable=protected-access\r\n--> 648               *args, **kwds)\r\n    649       # If we did not create any variables the trace we have is good enough.\r\n    650       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in canonicalize_function_inputs(self, *args, **kwargs)\r\n   2236           inputs,\r\n   2237           self._input_signature,\r\n-> 2238           self._flat_input_signature)\r\n   2239       return inputs, {}\r\n   2240 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _convert_inputs_to_signature(inputs, input_signature, flat_input_signature)\r\n   2278         inputs[:len(input_signature)],\r\n   2279         expand_composites=True,\r\n-> 2280         check_types=False)  # lists are convert to tuples for `tf.data`.\r\n   2281   except ValueError:\r\n   2282     raise ValueError(\"Structure of Python function inputs does not match \"\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in flatten_up_to(shallow_tree, input_tree, check_types, expand_composites)\r\n    932                            expand_composites=expand_composites)\r\n    933   # Discard paths returned by _yield_flat_up_to.\r\n--> 934   return list(v for _, v in _yield_flat_up_to(shallow_tree, input_tree, is_seq))\r\n    935 \r\n    936 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <genexpr>(.0)\r\n    932                            expand_composites=expand_composites)\r\n    933   # Discard paths returned by _yield_flat_up_to.\r\n--> 934   return list(v for _, v in _yield_flat_up_to(shallow_tree, input_tree, is_seq))\r\n    935 \r\n    936 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in _yield_flat_up_to(shallow_tree, input_tree, is_seq, path)\r\n    726       for leaf_path, leaf_value in _yield_flat_up_to(shallow_subtree,\r\n    727                                                      input_subtree, is_seq,\r\n--> 728                                                      path=subpath):\r\n    729         yield (leaf_path, leaf_value)\r\n    730 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in _yield_flat_up_to(shallow_tree, input_tree, is_seq, path)\r\n    723     for shallow_key, shallow_subtree in _yield_sorted_items(shallow_tree):\r\n    724       subpath = path + (shallow_key,)\r\n--> 725       input_subtree = input_tree[shallow_key]\r\n    726       for leaf_path, leaf_value in _yield_flat_up_to(shallow_subtree,\r\n    727                                                      input_subtree, is_seq,\r\n\r\nKeyError: '_VariantDataset'\r\n```\r\n\r\n", "comments": []}, {"number": 38732, "title": "TFLite MaxPool2D GPU op seems to modify source tensor", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac os x 10.15.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 4\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly==2.2.0.dev20200420, also using the nightly tflite (cpu and gpu) build on android.\r\n- Python version: 3.6.10\r\n\r\n\r\n**Describe the current behavior**\r\nHere's a fun one.  When running the max pool operator on the gpu (only tested the CL delegate), the input tensor was modified.  When running the model on the cpu, it outputs the original tensor as expected.\r\n\r\nI unfortunately don't have good code to repro on android, but the models produced in the snippet below should should the expected behavior when running on the cpu and then the gpu. \r\n\r\n**Describe the expected behavior**\r\nThe input tensor is not modified when running a max pool 2d on the source tensor.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport pathlib\r\nimport numpy\r\n\r\ndef convert(model, name):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    tflite_model = converter.convert()\r\n    pathlib.Path(name).write_bytes(tflite_model)\r\n    \r\n\r\ninpt = tf.keras.layers.Input(shape=[256, 256, 3])\r\nconv = tf.keras.layers.Conv2D(32, 1, padding=\"same\")(inpt)\r\n\r\nout = tf.keras.layers.Lambda(\r\n    lambda x: tf.nn.max_pool2d(\r\n        x, 16, strides=1, padding=\"SAME\"\r\n    )\r\n)(conv)\r\nmodel = tf.keras.Model(inpt, [conv, out])\r\nconvert(model, 'out_gpu.tflite')\r\n\r\n# Now force this to the maxpool to run on the cpu\r\ninpt = tf.keras.layers.Input(shape=[256, 256, 3])\r\nconv = tf.keras.layers.Conv2D(32, 1, padding=\"same\")(inpt)\r\n# This op should force the tensor onto the cpu.\r\nout = tf.where(tf.equal(conv, conv), conv, tf.zeros_like(conv))\r\nout = tf.keras.layers.Lambda(\r\n    lambda x: tf.nn.max_pool2d(\r\n        x, 16, strides=1, padding=\"SAME\"\r\n    )\r\n)(out)\r\nmodel = tf.keras.Model(inpt, [conv, out])\r\nconvert(model, 'out_cpu.tflite')\r\n```\r\n\r\n\r\n**Other info / logs** \r\nSample output of running `out_gpu.tflite` on the GPU.\r\n```\r\n// conv\r\nRow 0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,]\r\n// out\r\nRow 0: [0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, -0.0087890625]\r\n```\r\n\r\nSame model, but ran on cpu only:\r\n```\r\n// conv\r\nRow 0: [-0.23471934, -0.25280565, -0.26997373, -0.27565137, -0.2950689, -0.3190521, -0.34115076, -0.346938]\r\n// out:\r\nRow 0: [0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, -0.0088257985]\r\n```", "comments": ["@jdduke @impjdi Could you confirm if this is expected or a bug?", "Yeah, this may be broken unless you use the old GL delegate.  The new GPU delegate has a bug with intermediate tensors being graph output tensors.  Someone is in the process of fixing this, but I don't have an ETA.", "Thanks for the response! \r\n\r\nWhich delegate are you referring to when you say old GL delegate? using the current nightly build, \r\nI believe we saw this issue when using a phone that only had OpenGL.\r\n\r\nAlso, would you consider the tensor an output tensor if it is moving from GPU -> CPU? In the actual model we're using, the equivalent of `conv` is used further in the graph and gets corrupted at that step. ", "Old delegate: //tf/lite/delegates/gpu/gl_delegate.cc\r\nNew delegate: //tf/lite/delegates/gpu/delegate.cc\r\n\r\nI didn't fully get what you meant by \"it is moving from GPU -> CPU\".  did you mean that the next op is an op not supported by the GPU, and thus moves to CPU execution?", "Ah okay.  \r\n\r\nYes that's exactly it.  I think equals isn't supported on the gpu, so the graph is moved to cpu from then on. We see the same issue on the input to the select op.\r\n\r\n![image](https://user-images.githubusercontent.com/1422280/80225347-f1114780-8618-11ea-829c-6b39a1d88cc5.png)\r\n\r\n", "Equal isn't supported, but neither are ZerosLike, Select, TopkV2 and what not.  The graph should probably fall back to CPU around there, either cut off at Logistic or MaxPool2D.  Depends on the topological sort.", "Yup! From my digging it cuts off after the MaxPool2D, which causes the corruption of the maxpool's input tensor which is being passed to other tensors being ran on the cpu. (sorry having a hard time clearly putting this into words \ud83d\ude01)\r\n\r\nRe your comment: \"The new GPU delegate has a bug with intermediate tensors being graph output tensors.\"\r\nThe graph output tensor doesn't have to be the ultimate output returned to the user, correct? but can also be the output to a slice of the graph that is running on the cpu. ", "That is correct, it's just about the input/output tensors of the subgraph that the GPU delegate will handle.", "I tried to run the code with TF v2.5 on colab & getting warning message ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/5a0e0bc0a58776e30b32619e241c16fc/untitled334.ipynb)..Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38732\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38732\">No</a>\n"]}, {"number": 38731, "title": "TF 1.15 GPU version is not working as intended.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I wrote a custom code.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: running on servers\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: 10.0/7\r\n- GPU model and memory: GTX1060, 6GB\r\n\r\n**Describe the current behavior**\r\nI'm trying to build up Capsule Network using TF 1.15 by referring tutorial.\r\nThe source code seemed to work well with CPU.\r\nBut if GPU is used, the model did not seem to be trained.\r\nI turned on/off GPU by modifying LD_LIBRARY_PATH.\r\n![image](https://user-images.githubusercontent.com/661463/79819478-0a21ba80-83c5-11ea-8166-459df2d4615f.png)\r\n![image](https://user-images.githubusercontent.com/661463/79819492-0e4dd800-83c5-11ea-85b8-f1ed923569c5.png)\r\n\r\n**Describe the expected behavior**\r\nCPU and GPU version of the models need to be trained.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ncaps1_n = 32\r\ncaps1_dim = 8\r\ncaps2_n = 10\r\ncaps2_dim = 16\r\nexp_caps1_n = caps1_n * 6 * 6  # 1152 primary capsules\r\n\r\nm_plus = 0.9\r\nm_minus = 0.1\r\nlambda_ = 0.5\r\n\r\nconv1_params = {\r\n    \"filters\": 256,\r\n    \"kernel_size\": 9,\r\n    \"strides\": 1,\r\n    \"padding\": \"valid\",\r\n    \"activation\": tf.nn.relu,\r\n}\r\n\r\nconv2_params = {\r\n    \"filters\": caps1_n * caps1_dim, # 256 convolutional filters\r\n    \"kernel_size\": 9,\r\n    \"strides\": 2,\r\n    \"padding\": \"valid\",\r\n    \"activation\": tf.nn.relu\r\n}\r\n\r\ndef squash(s, axis=-1, epsilon=1e-7):\r\n    squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\r\n    safe_norm = tf.sqrt(squared_norm + epsilon)\r\n    squash_factor = squared_norm / (1. + squared_norm)\r\n    unit_vector = s / safe_norm\r\n    return squash_factor * unit_vector\r\n\r\ndef safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):\r\n    squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=keep_dims)\r\n    return tf.sqrt(squared_norm + epsilon)\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\n\r\nmnist = input_data.read_data_sets(\"data/\")\r\n\r\ntf.reset_default_graph()\r\nnp.random.seed(42)\r\ntf.set_random_seed(42)\r\n\r\n# Placeholders\r\nX = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)\r\nY = tf.placeholder(shape=[None], dtype=tf.int64)\r\nbatch_size = tf.shape(X)[0]\r\n\r\n# CapsuleizationLayer\r\nconv1 = tf.layers.conv2d(X, **conv1_params)\r\nconv2 = tf.layers.conv2d(conv1, **conv2_params)\r\ncaps1_raw = tf.reshape(conv2, [-1, exp_caps1_n, caps1_dim])\r\ncaps1_output = squash(caps1_raw)\r\n\r\ninit_sigma = 0.1\r\nW = tf.Variable(tf.random_normal(shape=(1, exp_caps1_n, caps2_n, caps2_dim, caps1_dim),\r\n                                 stddev=init_sigma, dtype=tf.float32))\r\nW_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1])\r\n\r\ncaps1_output_expanded = tf.expand_dims(caps1_output, -1)\r\ncaps1_output_tile = tf.expand_dims(caps1_output_expanded, 2)\r\ncaps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n, 1, 1])\r\nu_hat = tf.matmul(W_tiled, caps1_output_tiled)\r\n\r\n#===============================================================\r\n# Dynamic Routing\r\n#===============================================================\r\nraw_weights = tf.zeros([batch_size, exp_caps1_n, caps2_n, 1, 1], dtype=np.float32)\r\n\r\n# Round1, Line 4\r\nrouting_weights = tf.nn.softmax(raw_weights, dim=2)\r\n# Round1, Line 5\r\nweighted_predictions = tf.multiply(routing_weights, u_hat)\r\nweighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True)\r\n# Round1, Line 6\r\ncaps2_output_round_1 = squash(weighted_sum, axis=-2)\r\n# Round1, Line 7\r\ncaps2_output_round_1_tiled = tf.tile(caps2_output_round_1, [1, exp_caps1_n, 1, 1, 1])\r\nraw_weights2 = raw_weights + tf.matmul(u_hat, caps2_output_round_1_tiled, transpose_a=True)\r\n\r\n# Round2, Line 4\r\nrouting_weights_round_2 = tf.nn.softmax(raw_weights2, dim=2)\r\n# Round2, Line 5\r\nweighted_predictions_round_2 = tf.multiply(routing_weights_round_2, u_hat)\r\nweighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2, axis=1, keep_dims=True)\r\n# Round2, Line 6\r\ncaps2_output = squash(weighted_sum_round_2, axis=-2)\r\n#===============================================================\r\n\r\ny_proba = safe_norm(caps2_output, axis=-2)\r\ny_proba_argmax = tf.argmax(y_proba, axis=2)\r\ny_pred = tf.squeeze(y_proba_argmax, axis=[1, 2])\r\n\r\n# Loss: Margin loss\r\nT = tf.one_hot(Y, depth=caps2_n)\r\ncaps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True)\r\npresent_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm))\r\npresent_error = tf.reshape(present_error_raw, shape=(-1, 10))\r\nabsent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus))\r\nabsent_error = tf.reshape(absent_error_raw, shape=(-1, 10))\r\nL = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error)\r\nloss = margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1))\r\n\r\n# Loss: Reconstruction loss\r\ncorrect = tf.equal(Y, y_pred)\r\naccuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\r\n\r\n#default option for Adam\r\noptimizer = tf.train.AdamOptimizer()\r\ntraining_op = optimizer.minimize(loss)\r\n\r\ninit = tf.global_variables_initializer()\r\nsaver = tf.train.Saver()\r\n\r\nbatch_size = 50\r\nn_iterations_per_epoch = mnist.train.num_examples // batch_size\r\nn_iterations_validation = mnist.validation.num_examples // batch_size\r\n\r\nwith tf.Session() as sess:\r\n    init.run()\r\n\r\n    for epoch in range(10):\r\n        for iteration in range(1, n_iterations_per_epoch + 1):\r\n            X_batch, Y_batch = mnist.train.next_batch(batch_size)\r\n            # Run the training operation and measure the loss:\r\n            _, loss_train, acc_train = sess.run(\r\n                [training_op, loss, accuracy],\r\n                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\r\n                           Y: Y_batch})\r\n            print(\"Iteration: {}/{} ({:.1f}%)  Loss: {:.5f}, Acc: {:.5f}\".format(\r\n                      iteration, n_iterations_per_epoch,\r\n                      iteration * 100 / n_iterations_per_epoch,\r\n                      loss_train, acc_train * 100)\r\n                  )\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n**GPU version log**\r\n```\r\nIteration: 1/1100 (0.1%)  Loss: 0.30913, Acc: 6.00000\r\nIteration: 2/1100 (0.2%)  Loss: 0.47852, Acc: 16.00000\r\nIteration: 3/1100 (0.3%)  Loss: 0.00000, Acc: 8.00000\r\nIteration: 4/1100 (0.4%)  Loss: 0.33996, Acc: 4.00000\r\nIteration: 5/1100 (0.5%)  Loss: 0.00000, Acc: 10.00000\r\nIteration: 6/1100 (0.5%)  Loss: 0.21045, Acc: 12.00000\r\nIteration: 7/1100 (0.6%)  Loss: 0.33996, Acc: 8.00000\r\nIteration: 8/1100 (0.7%)  Loss: 0.00000, Acc: 12.00000\r\nIteration: 9/1100 (0.8%)  Loss: 0.00000, Acc: 10.00000\r\nIteration: 10/1100 (0.9%)  Loss: 0.00000, Acc: 8.00000\r\nIteration: 11/1100 (1.0%)  Loss: 0.21045, Acc: 16.00000\r\nIteration: 12/1100 (1.1%)  Loss: 0.21045, Acc: 12.00000\r\nIteration: 13/1100 (1.2%)  Loss: 0.40472, Acc: 6.00000\r\nIteration: 14/1100 (1.3%)  Loss: 0.00000, Acc: 8.00000\r\nIteration: 15/1100 (1.4%)  Loss: 0.61517, Acc: 14.00000\r\nIteration: 16/1100 (1.5%)  Loss: 0.33996, Acc: 10.00000\r\nIteration: 17/1100 (1.5%)  Loss: 0.00000, Acc: 14.00000\r\nIteration: 18/1100 (1.6%)  Loss: 0.33996, Acc: 12.00000\r\nIteration: 19/1100 (1.7%)  Loss: 0.00000, Acc: 8.00000\r\nIteration: 20/1100 (1.8%)  Loss: 0.21045, Acc: 12.00000\r\nIteration: 21/1100 (1.9%)  Loss: 0.33996, Acc: 18.00000\r\nIteration: 22/1100 (2.0%)  Loss: 0.00000, Acc: 4.00000\r\nIteration: 23/1100 (2.1%)  Loss: 0.21045, Acc: 8.00000\r\nIteration: 24/1100 (2.2%)  Loss: 0.33996, Acc: 12.00000\r\nIteration: 25/1100 (2.3%)  Loss: 0.00000, Acc: 10.00000\r\nIteration: 26/1100 (2.4%)  Loss: 0.21045, Acc: 16.00000\r\nIteration: 27/1100 (2.5%)  Loss: 0.61517, Acc: 8.00000\r\nIteration: 28/1100 (2.5%)  Loss: 0.33996, Acc: 8.00000\r\nIteration: 29/1100 (2.6%)  Loss: 0.00000, Acc: 16.00000\r\nIteration: 30/1100 (2.7%)  Loss: 0.21045, Acc: 6.00000\r\nIteration: 31/1100 (2.8%)  Loss: 0.00000, Acc: 6.00000\r\nIteration: 32/1100 (2.9%)  Loss: 0.21045, Acc: 10.00000\r\nIteration: 33/1100 (3.0%)  Loss: 0.61517, Acc: 14.00000\r\nIteration: 34/1100 (3.1%)  Loss: 0.21045, Acc: 10.00000\r\nIteration: 35/1100 (3.2%)  Loss: 0.21045, Acc: 4.00000\r\nIteration: 36/1100 (3.3%)  Loss: 0.21045, Acc: 12.00000\r\nIteration: 37/1100 (3.4%)  Loss: 0.61517, Acc: 10.00000\r\nIteration: 38/1100 (3.5%)  Loss: 0.21045, Acc: 12.00000\r\nIteration: 39/1100 (3.5%)  Loss: 0.21045, Acc: 6.00000\r\nIteration: 40/1100 (3.6%)  Loss: 0.00000, Acc: 12.00000\r\nIteration: 41/1100 (3.7%)  Loss: 0.00000, Acc: 14.00000\r\nIteration: 42/1100 (3.8%)  Loss: 0.21045, Acc: 16.00000\r\nIteration: 43/1100 (3.9%)  Loss: 0.21045, Acc: 16.00000\r\nIteration: 44/1100 (4.0%)  Loss: 0.33996, Acc: 12.00000\r\nIteration: 45/1100 (4.1%)  Loss: 0.00000, Acc: 6.00000\r\nIteration: 46/1100 (4.2%)  Loss: 0.00000, Acc: 4.00000\r\nIteration: 47/1100 (4.3%)  Loss: 0.21045, Acc: 10.00000\r\nIteration: 48/1100 (4.4%)  Loss: 0.33996, Acc: 12.00000\r\nIteration: 49/1100 (4.5%)  Loss: 0.00000, Acc: 14.00000\r\nIteration: 50/1100 (4.5%)  Loss: 0.21045, Acc: 10.00000\r\n```\r\n**CPU Version log**\r\n```\r\nIteration: 1/1100 (0.1%)  Loss:  0.80942, Acc: 8.00000\r\nIteration: 2/1100 (0.2%)  Loss:  0.63684, Acc: 10.00000\r\nIteration: 3/1100 (0.3%)  Loss:  1.88716, Acc: 8.00000\r\nIteration: 4/1100 (0.4%)  Loss:  0.80636, Acc: 4.00000\r\nIteration: 5/1100 (0.5%)  Loss:  0.60099, Acc: 10.00000\r\nIteration: 6/1100 (0.5%)  Loss:  0.54984, Acc: 12.00000\r\nIteration: 7/1100 (0.6%)  Loss:  0.52977, Acc: 28.00000\r\nIteration: 8/1100 (0.7%)  Loss:  0.52300, Acc: 12.00000\r\nIteration: 9/1100 (0.8%)  Loss:  0.54408, Acc: 8.00000\r\nIteration: 10/1100 (0.9%)  Loss: 0.49441, Acc: 16.00000\r\nIteration: 11/1100 (1.0%)  Loss: 0.48491, Acc: 20.00000\r\nIteration: 12/1100 (1.1%)  Loss: 0.49179, Acc: 36.00000\r\nIteration: 13/1100 (1.2%)  Loss: 0.46365, Acc: 50.00000\r\nIteration: 14/1100 (1.3%)  Loss: 0.45733, Acc: 54.00000\r\nIteration: 15/1100 (1.4%)  Loss: 0.41508, Acc: 64.00000\r\nIteration: 16/1100 (1.5%)  Loss: 0.40333, Acc: 64.00000\r\nIteration: 17/1100 (1.5%)  Loss: 0.37526, Acc: 58.00000\r\nIteration: 18/1100 (1.6%)  Loss: 0.37363, Acc: 58.00000\r\nIteration: 19/1100 (1.7%)  Loss: 0.37349, Acc: 50.00000\r\nIteration: 20/1100 (1.8%)  Loss: 0.37024, Acc: 52.00000\r\nIteration: 21/1100 (1.9%)  Loss: 0.31172, Acc: 64.00000\r\nIteration: 22/1100 (2.0%)  Loss: 0.29889, Acc: 64.00000\r\nIteration: 23/1100 (2.1%)  Loss: 0.32116, Acc: 66.00000\r\nIteration: 24/1100 (2.2%)  Loss: 0.31103, Acc: 74.00000\r\nIteration: 25/1100 (2.3%)  Loss: 0.28157, Acc: 76.00000\r\nIteration: 26/1100 (2.4%)  Loss: 0.22721, Acc: 82.00000\r\nIteration: 27/1100 (2.5%)  Loss: 0.24645, Acc: 80.00000\r\nIteration: 28/1100 (2.5%)  Loss: 0.28085, Acc: 76.00000\r\nIteration: 29/1100 (2.6%)  Loss: 0.21644, Acc: 82.00000\r\nIteration: 30/1100 (2.7%)  Loss: 0.22552, Acc: 82.00000\r\nIteration: 31/1100 (2.8%)  Loss: 0.19832, Acc: 84.00000\r\nIteration: 32/1100 (2.9%)  Loss: 0.18913, Acc: 86.00000\r\nIteration: 33/1100 (3.0%)  Loss: 0.18527, Acc: 86.00000\r\nIteration: 34/1100 (3.1%)  Loss: 0.19863, Acc: 84.00000\r\nIteration: 35/1100 (3.2%)  Loss: 0.16656, Acc: 90.00000\r\nIteration: 36/1100 (3.3%)  Loss: 0.17566, Acc: 80.00000\r\nIteration: 37/1100 (3.4%)  Loss: 0.16723, Acc: 82.00000\r\nIteration: 38/1100 (3.5%)  Loss: 0.13901, Acc: 94.00000\r\nIteration: 39/1100 (3.5%)  Loss: 0.14630, Acc: 88.00000\r\nIteration: 40/1100 (3.6%)  Loss: 0.16909, Acc: 84.00000\r\nIteration: 41/1100 (3.7%)  Loss: 0.13749, Acc: 90.00000\r\nIteration: 42/1100 (3.8%)  Loss: 0.16060, Acc: 84.00000\r\nIteration: 43/1100 (3.9%)  Loss: 0.12409, Acc: 92.00000\r\nIteration: 44/1100 (4.0%)  Loss: 0.16228, Acc: 82.00000\r\nIteration: 45/1100 (4.1%)  Loss: 0.14838, Acc: 86.00000\r\nIteration: 46/1100 (4.2%)  Loss: 0.13091, Acc: 90.00000\r\nIteration: 47/1100 (4.3%)  Loss: 0.13386, Acc: 92.00000\r\nIteration: 48/1100 (4.4%)  Loss: 0.15651, Acc: 84.00000\r\nIteration: 49/1100 (4.5%)  Loss: 0.15982, Acc: 84.00000\r\nIteration: 50/1100 (4.5%)  Loss: 0.12564, Acc: 90.00000\r\n```\r\n\r\n", "comments": ["@sephiroce,\r\nI tried to reproduce the issue, but did not observe much difference in the results on [CPU](https://colab.research.google.com/gist/amahendrakar/de66d100ff9842499d394fa69fd5188e/38731.ipynb) and [GPU](https://colab.research.google.com/gist/amahendrakar/419557fea3ade5839494a1ef19922354/38731-gpu.ipynb). Please find the attached gist. \r\n\r\nCould you please try upgrading to TF v1.15.2 and check if you are facing the same issue? Thanks!", "@amahendrar, Thank you!\r\nI upgraded TF to 1.15.2 but I'm still facing the same issue T.T..\r\nEspecially margin losses went wrong I guess.\r\n```\r\nIteration: 1/50 (2.0%)  Loss: 0.30925, Acc: 6.00000margin loss: 0.000000, reconstruction loss: 0.232661\r\nIteration: 2/50 (4.0%)  Loss: 0.00012, Acc: 14.00000margin loss: 0.000000, reconstruction loss: 0.232515\r\nIteration: 3/50 (6.0%)  Loss: 0.00012, Acc: 8.00000margin loss: 0.210452, reconstruction loss: 0.231619\r\nIteration: 4/50 (8.0%)  Loss: 0.21057, Acc: 4.00000margin loss: 0.210452, reconstruction loss: 0.231232\r\nIteration: 5/50 (10.0%)  Loss: 0.21057, Acc: 10.00000margin loss: 0.000000, reconstruction loss: 0.229791\r\nIteration: 6/50 (12.0%)  Loss: 0.00011, Acc: 12.00000margin loss: 0.000000, reconstruction loss: 0.231024\r\nIteration: 7/50 (14.0%)  Loss: 0.00012, Acc: 8.00000margin loss: 0.000000, reconstruction loss: 0.230170\r\nIteration: 8/50 (16.0%)  Loss: 0.00012, Acc: 12.00000margin loss: 0.000000, reconstruction loss: 0.231490\r\nIteration: 9/50 (18.0%)  Loss: 0.00012, Acc: 10.00000margin loss: 0.000000, reconstruction loss: 0.231016\r\nIteration: 10/50 (20.0%)  Loss: 0.00012, Acc: 8.00000margin loss: 0.000000, reconstruction loss: 0.230513\r\nIteration: 11/50 (22.0%)  Loss: 0.00012, Acc: 16.00000margin loss: 0.000000, reconstruction loss: 0.231000\r\n```\r\nI have another question. In the attached gists, the same pip commands are used.\r\nHow did you turn on/off GPU usage?", "@sephiroce,\r\nThere's an option to choose GPU as a hardware accelerator under 'Runtime' -> 'Change runtime type'.", "I converted my source code to TF2.1 and the issues have gone.\r\nI'll close this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38731\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38731\">No</a>\n"]}, {"number": 38730, "title": "[TF-TRT] - Adding user control to blacklist OP conversion", "body": "@tfeher FYI\r\n@bixia1 for review\r\n\r\nAs discussed, I introduce in this PR the env var `TF_TRT_OP_BLACKLIST`.\r\n\r\nObjective: In addition to allow users to carefully deactivate some OPs to be converted for whatever reasons. It will be much helpful to debug some weird behavior without having to recompile TF.\r\n\r\nBasically, you use it as follows: \r\n```bash\r\nexport TF_TRT_OP_BLACKLIST=\"Conv2D,BiasAdd\"  # Comma Separated\r\npython main.py\r\n```\r\n\r\nExample warning printed on the console to confirm the behavior:\r\n```bash\r\n2020-04-21 02:25:00.148330: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:472] Blacklisted as TF-TRT candidate, (Op type: Conv2D), (Op name: my_block/my_layer/Conv2D), (Reason: Blacklisted with the env var TF_TRT_OP_BLACKLIST)\r\n```\r\n\r\nAnd it will block TF-TRT converter from converting any Conv2D or BiasAdd OP.\r\n\r\n**Question 1:** should we introduce the same kind of behavior for OP fusing (see: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L1697-L1726) ?\r\n\r\n**Question 2:** Do you all agree with the name: `TF_TRT_OP_BLACKLIST` or do you prefer something else (please propose an alternative if so) ?\r\n", "comments": ["@bixia1 as requested, env var name has been changed to `TF_TRT_OP_BLACKLIST`."]}, {"number": 38729, "title": "ModelCheckpoint results in Input 0 of layer is incompatible with the layer", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: NVIDIA GTX 970\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nSaving a model using keras ModelCheckpoint callback results in the following error:\r\n```\r\nValueError: Input 0 of layer cls_outputs is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.\r\n```\r\n**Describe the expected behavior**\r\nShould save the model without errors.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://colab.research.google.com/drive/1Bf6EhjmnjzsZQUoiGAi1XVxjrFOPa2Cp\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nThe ModelCheckpoint callback works when using `save_weights_only=True`, but I need to save the whole model for deployment to AI platform.", "comments": ["I have tried on colab with TF version 2.1.0 , 2.2.0-rc3 and was able to reproduce the issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/4802ad8f173bcc0eb3b0a2bc56523235/untitled794.ipynb)Thanks!\r\n", "@david-wb \r\n\r\nI have tried in colab with TF nightly version(`2.4.0-dev20200916`) and i am not seeing any issue.Please, find the gist [here.](https://colab.research.google.com/gist/ravikyram/3a5b7a8ab828f6e845a207bccd69f73e/untitled373.ipynb).PLease, verify once and close the issue.Thanks!", "Verified thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38729\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38729\">No</a>\n"]}, {"number": 38728, "title": "[ROCm] Disabling a subtest within //tensorflow/python/eager:function_test_gpu\u2026", "body": "\u2026 because it checks output which is non-determnisitic in nature and therefore sporadically fails\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": []}, {"number": 38727, "title": "Does TensorFlow provide a half normal initialiser?", "body": "**System information**\r\n- TensorFlow version (you are using): 2.\r\n- Are you willing to contribute it (Yes/No): maybe\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI would like to have access to more initializers for variables (not just the weights of layers), but also variables e.g. created with `add_weight`. Specifically, I would like to have an initializer for half normals, i.e. normals that produce only positive numbers (it's like applying the absolute value to a normal).\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nEveryone.\r\n\r\n**Any Other info.**\r\n\r\nI've asked a [question on Stack Overflow regarding my specific problem that TF currently doesn't seem to address](https://stackoverflow.com/q/61333274/3924118).\r\n", "comments": ["Here's a custom initialiser that does what I want.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef random_half_normal(shape, **kwargs):\r\n    return tf.abs(tf.keras.backend.random_normal(shape, **kwargs))\r\n\r\n\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.my_var = self.add_weight(initializer=random_half_normal, \r\n                                      trainable=False)\r\n\r\n    def call(self, inputs):\r\n        tf.print(\"\\nself.my_var =\", self.my_var)\r\n        return inputs\r\n\r\n\r\ndef get_model():\r\n    inp = tf.keras.layers.Input(shape=(1,))\r\n    out = MyLayer(8)(inp)\r\n    model = tf.keras.Model(inputs=inp, outputs=out)\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef train():\r\n    model = get_model()\r\n    model.compile(optimizer=\"adam\", loss=\"mae\")\r\n    x_train = [2, 3, 4, 1, 2, 6]\r\n    y_train = [1, 0, 1, 0, 1, 1]\r\n    model.fit(x_train, y_train)\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\nSee also [my answer on Stack Overflow](https://stackoverflow.com/a/61357026/3924118)."]}, {"number": 38726, "title": "Tensorflow failed to load model", "body": "The main model was trained on my local machine with a GTX 1050 Ti GPU.  The error below is from the docker container being deployed in a VM in the Digital Ocean, and I've also tried it again on my local machine and works perfectly. \r\n\r\n**Dockerfile config:**\r\n```\r\nFROM  tensorflow/tensorflow:latest-py3\r\nRUN apt update\r\n\r\nCOPY requirements.txt /requirements.txt\r\nRUN python3 -m pip install -r requirements.txt && mkdir /app\r\n\r\nCOPY . /app\r\nWORKDIR /app\r\n\r\nENTRYPOINT [\"python3\", \"app.py\"]\r\n```\r\n\r\nError within the VM, where CPU is already being forced to be used via \"tf.config.set_visible_devices([], 'GPU')\"\r\n```\r\n2020-04-20 23:02:03.505874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:03.505973: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:03.505983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-04-20 23:02:04.285763: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:04.285824: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-20 23:02:04.285854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sanic-server-5f779b76c9-xth26): /proc/driver/nvidia/version does not exist\r\n2020-04-20 23:02:04.920805: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-04-20 23:02:04.928642: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294605000 Hz\r\n2020-04-20 23:02:04.929167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41ce6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-20 23:02:04.929206: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 70, in get_tensor\r\n    self, compat.as_bytes(tensor_str))\r\nRuntimeError: The length checksum does not match: expected 1137107832 but actual is 432382948\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"app.py\", line 17, in <module>\r\n    TF = TensorflowImg()\r\n  File \"/app/ml_modules/tensorflow_img.py\", line 28, in __init__\r\n    self.model = self.__load_model()\r\n  File \"/app/ml_modules/tensorflow_img.py\", line 48, in __load_model\r\n    \"KerasLayer\": hub.KerasLayer})\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 150, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 89, in load\r\n    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 552, in load_internal\r\n    export_dir)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 118, in __init__\r\n    super(KerasObjectLoader, self).__init__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 128, in __init__\r\n    self._restore_checkpoint()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 280, in _restore_checkpoint\r\n    load_status = saver.restore(variables_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1248, in restore\r\n    object_graph_string = reader.get_tensor(base.OBJECT_GRAPH_PROTO_KEY)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 74, in get_tensor\r\n    error_translator(e)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 48, in error_translator\r\n    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)\r\ntensorflow.python.framework.errors_impl.OpError: The length checksum does not match: expected 1137107832 but actual is 432382948\r\n```\r\n\r\nHere a successful one from my local-machine\r\n```\r\n2020-04-21 01:55:36.154300: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-21 01:55:36.156770: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory  \r\n2020-04-21 01:55:36.157413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-04-21 01:55:37.103847: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-21 01:55:37.105032: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-21 01:55:37.105865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (332fc060f5f6): /proc/driver/nvidia/version does not exist\r\n2020-04-21 01:55:37.703255: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-04-21 01:55:37.722212: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2495995000 Hz\r\n2020-04-21 01:55:37.724314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d226c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-21 01:55:37.724943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n[2020-04-21 01:55:41 +0000] [1] [INFO] Starting localhost development\r\n[2020-04-21 01:55:41 +0000] [1] [DEBUG]\r\n\r\n                 Sanic\r\n         Build Fast. Run Fast.\r\n\r\n\r\n[2020-04-21 01:55:41 +0000] [1] [INFO] Goin' Fast @ http://0.0.0.0:8000\r\n2020-04-21 01:55:42.388099: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-21 01:55:42.389311: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory  \r\n2020-04-21 01:55:42.390228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-04-21 01:55:43.083080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-21 01:55:43.083171: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-21 01:55:43.083197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (332fc060f5f6): /proc/driver/nvidia/version does not exist\r\n2020-04-21 01:55:43.682208: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-04-21 01:55:43.690862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2495995000 Hz\r\n2020-04-21 01:55:43.692032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a17d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-21 01:55:43.692692: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n[2020-04-21 01:55:47 +0000] [964] [INFO] Starting localhost development\r\n[2020-04-21 01:55:47 +0000] [964] [INFO] Starting worker [964]\r\n^CProcess Process-1:\r\n[2020-04-21 01:56:43 +0000] [964] [INFO] Stopping worker [964]\r\n[2020-04-21 01:56:43 +0000] [964] [INFO] Server Stopped\r\n```", "comments": ["@navalta3030 \r\n\r\nPlease, let us know which TensorFlow version you are using? Request you to provide colab link or simple standalone code to reproduce the issue in our environment. then it is easy for localizing the issue faster. Thanks !", "@ravikyram Hi, Would be nice to get the docker container working at least. As that's what my staging and production environment is running on.\r\n\r\n- Tensorflow version = 2.1.0\r\n\r\n# Steps to reproduce locally\r\n- git clone https://github.com/navalta3030/sanic_server.git\r\n- git checkout --track origin/no_issue\r\n- python3 -m venv .env\r\n- source .env/Scripts/activate\r\n- pip install -r requirements.txt\r\n- python app.py\r\n\r\nThe part where it fails is [Here](https://github.com/navalta3030/sanic_server/blob/no_issue/ml_modules/tensorflow_img.py#L40)\r\n\r\nThe saved model is located [Here](https://github.com/navalta3030/sanic_server/tree/no_issue/ml_modules/models/effusion.tf)\r\n\r\n# Steps to reproduce using docker container\r\n- git clone https://github.com/navalta3030/sanic_server.git\r\n- git checkout --track origin/no_issue\r\n- docker build -t test/sanic_tf .\r\n- docker run test/sanic_tf\r\n\r\n**ERROR FROM DOCKER CONTAINER**\r\n```\r\n2020-04-20 23:02:03.505874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:03.505973: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:03.505983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-04-20 23:02:04.285763: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-20 23:02:04.285824: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-20 23:02:04.285854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sanic-server-5f779b76c9-xth26): /proc/driver/nvidia/version does not exist\r\n2020-04-20 23:02:04.920805: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-04-20 23:02:04.928642: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294605000 Hz\r\n2020-04-20 23:02:04.929167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41ce6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-20 23:02:04.929206: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 70, in get_tensor\r\n    self, compat.as_bytes(tensor_str))\r\nRuntimeError: The length checksum does not match: expected 1137107832 but actual is 432382948\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"app.py\", line 17, in <module>\r\n    TF = TensorflowImg()\r\n  File \"/app/ml_modules/tensorflow_img.py\", line 28, in __init__\r\n    self.model = self.__load_model()\r\n  File \"/app/ml_modules/tensorflow_img.py\", line 48, in __load_model\r\n    \"KerasLayer\": hub.KerasLayer})\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 150, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 89, in load\r\n    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 552, in load_internal\r\n    export_dir)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 118, in __init__\r\n    super(KerasObjectLoader, self).__init__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 128, in __init__\r\n    self._restore_checkpoint()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\", line 280, in _restore_checkpoint\r\n    load_status = saver.restore(variables_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1248, in restore\r\n    object_graph_string = reader.get_tensor(base.OBJECT_GRAPH_PROTO_KEY)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 74, in get_tensor\r\n    error_translator(e)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 48, in error_translator\r\n    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)\r\ntensorflow.python.framework.errors_impl.OpError: The length checksum does not match: expected 1137107832 but actual is 432382948\r\n```", "Closing this one. \r\n\r\nThe issue was on github action, the compilation was done over there and there is a bit of disallignment on their build-machine."]}, {"number": 38725, "title": "Casting a string tensor to a list of string", "body": "I couldn't find an approach to casting a string tensor to a list of string. \r\nFor instance, if someone has the following `sample_string_tensor`:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nbatch_size = 4\r\nsample_string_tensor = tf.convert_to_tensor([\"s\u00e3mple utf-8 str\u00edng - \" + str(i) for i in range(n_strings)])\r\nsample_string_tensor\r\n# <tf.Tensor: shape=(4,), dtype=string, numpy=\r\n# array([b's\\xc3\\xa3mple utf-8 str\\xc3\\xadng - 0',\r\n#        b's\\xc3\\xa3mple utf-8 str\\xc3\\xadng - 1',\r\n#        b's\\xc3\\xa3mple utf-8 str\\xc3\\xadng - 2',\r\n#        b's\\xc3\\xa3mple utf-8 str\\xc3\\xadng - 3'], dtype=object)>\r\n```\r\nhow to cast to list of string below?\r\n```python\r\n['s\u00e3mple utf-8 str\u00edng - 0',\r\n 's\u00e3mple utf-8 str\u00edng - 1',\r\n 's\u00e3mple utf-8 str\u00edng - 2',\r\n 's\u00e3mple utf-8 str\u00edng - 3']\r\n\r\n```\r\nNote there are some no `ascii` character.\r\n", "comments": ["@Ceceu,\r\nYou can use `sample_string_tensor.numpy()` to extract the value from the tensor. Please check [this gist](https://colab.research.google.com/gist/amahendrakar/eacae34045839d34406beb71cb56ffaa/38725.ipynb) for reference.\r\n\r\nAlso, this question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is a larger community that reads questions there. Thanks!", "Thank you @amahendrakar, but that is not the answer. Note when you use `sample_string_tensor.numpy()` you actually have an array of byte strings `(b'example string')` which in turn, have to be decoded. A lot of tokenizers requires a string or a list of strings, that's the reason for my issue.\r\n\r\nTherefore, I am looking for an approach to decode the array of byte strings from a tensor into a batch of strings. As I have a large dataset to tokenize, this must be done in a vectorized manner  through the [map function](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#map).\r\n\r\nI already submitted a question on StackOverflow, but as no one has been able to answer so far, I thought it best to ask for help directly from those who maintain the Tensorflow.", "May be you can use [`tf.compat.as_str_any()`](https://www.tensorflow.org/api_docs/python/tf/compat/as_str_any) function to this?\r\nTake a look at a toy example:\r\n```python\r\ns = tf.convert_to_tensor('my_string')\r\nprint(type(s.numpy()))\r\nprint(type(tf.compat.as_str_any(s)))\r\n```\r\noutput:\r\n```python\r\n<class 'bytes'>\r\n<class 'str'>\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@ymodak, I don't know why your answer was downvoted since it's correct! It returns the value of a tensor as a string.\r\n\r\nThe answer to the preliminary question then is:\r\n```\r\nn_strings = 4\r\nsample_string_tensor = tf.convert_to_tensor([\"s\u00e3mple utf-8 str\u00edng - \" + str(i) for i in range(n_strings)])\r\nsample_string_tensor\r\nlist_of_sample_strings = [tf.compat.as_str_any(tensor.numpy()) for tensor in sample_string_tensor] \r\nlist_of_sample_strings\r\n```", "A simple way:\r\n\r\n```\r\n>>> list_of_sample_strings = [x.numpy().decode() for x in sample_string_tensor]\r\n>>> list_of_sample_strings\r\n\r\n['s\u00e3mple utf-8 str\u00edng - 0',\r\n 's\u00e3mple utf-8 str\u00edng - 1',\r\n 's\u00e3mple utf-8 str\u00edng - 2',\r\n 's\u00e3mple utf-8 str\u00edng - 3']\r\n```"]}, {"number": 38723, "title": "Tflite model provides good accuracy on edge device but not in pythonic Interpreter", "body": "OS system: linux (mintos)\r\nGraphics Card: Nvidia 1660 ti MaxQ\r\nSystem: Rog Zephyrus \r\n\r\nProblem:\r\nI have converted my model to tflite and installed it on android device. The performance and accuracy seems to be good enough for a started point but when I use the tflite model in the tflite interpreter I get completly bad results. \r\nI would like to know what I have done wrong.\r\n\r\nThis is the code to load tflite and the interpreter\r\n\r\n\r\n[tflite_detect.txt](https://github.com/tensorflow/tensorflow/files/4506390/tflite_detect.txt)\r\n", "comments": ["@muck27 \r\nPlease provide details about  your TensorFlow version. \r\nf you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Hello @Saduf2019 ..\r\nTF model: 2.1.0\r\nmethod for conversion:\r\n\r\n1. Convert saved model to tflite.graph \r\n\r\n$python research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path=$CONFIG_FILE --trained_checkpoint_prefix=$CHECKPOINT_PATH --output_directory=$OUTPUT_DIR --add_postprocessing_op=true\r\n\r\n\r\n2. Convert the tflite graph to tflite model:\r\n\r\ntflite_convert --output_file=./tflite/detect.tflite --graph_def_file=/models/tflite/tflite_graph.pb --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --input_shape=1,300,300,3 --allow_custom_ops\r\n", "@muck27,\r\nIf your model are train using coco dataset, I would recommend to check the accuracy using that dataset first before using images from your camera. \r\nto check it on PC, you can try with https://github.com/mlperf/mobile_app/tree/master/cpp/binary:\r\nbazel run  -c opt --cxxopt='--std=c++17' -- //cpp/binary:main TFLITE COCO \\\r\nthird_party/mlperf/mobile_app/cpp/binary:main \\\r\n--mode=SubmissionRun \\\r\n--model_file=<path to your model> \\\r\n--images_directory=<path to coco image dir> \\\r\n--groundtruth_file=<ground truth file> \\\r\n--num_threads=4 --num_classes=91 --offset=1 \\\r\n--delegate=None \\\r\n--output_dir=/<output dir>\r\nThe guide to download the coco dataset can be found at https://github.com/mlperf/mobile_app/tree/master/cpp/datasets\r\n\r\n", "@thaink \r\n\r\nI am building a custom object detector. So what should my groundtruth file be like? Does it need to be in a specific format like pascal or in tfrecord format?", "@muck27, Do you mean you are using your own dataset?", "@thaink yes I am\r\n", "@muck27 My main suspect is the pre-processing code.\r\nCould you check the pre-processing that you use on Android and in the python code is the same?\r\n", "@thaink even I feel the preprocessing part is giving wrong results. \r\nI have trained the model with input of 1200x1200.  I am attaching the android preprocessing part and the python code for interpretation. \r\n\r\n[tflite_detect.txt](https://github.com/tensorflow/tensorflow/files/4523345/tflite_detect.txt)\r\n![android](https://user-images.githubusercontent.com/48056260/80115188-0eef9580-85a2-11ea-9b4d-974de59e7747.png)\r\n", "my guess is you are missing the normalization part here\r\nhttps://github.com/tensorflow/examples/blob/318936de60224383901e5ef60a39799629a5df8d/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L162\r\nBut if you trained the model, you only need to make sure the way you preprocess the image is the same as the way you trained it.", "I will try normalizing the image as a preprocessing part before sending it to the network then", "@muck27 \r\nCould you please update, if this is resolved", "Hey the issue was resolved...it was a problem of preprocessing. I added a\ncv2 normalisation code before sending the image to the detector...it worked\nlike a charm\n\nThanks guys\n\nOn Thu, 30 Apr, 2020, 6:11 PM Saduf2019, <notifications@github.com> wrote:\n\n> @muck27 <https://github.com/muck27>\n> Could you please update, if this is resolved\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38723#issuecomment-621808657>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ALOUPRGWZLWS5UM3RFGCNNDRPFWXRANCNFSM4MMZL2NA>\n> .\n>\n", "Moving this to resolved status with confirmation."]}, {"number": 38722, "title": "TensorRT Converter could not work well with Bert model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly(2.2.0-dev20200420)\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: P100\r\n\r\n**Describe the current behavior**\r\n\r\nI tried to run the Bert-NER inference using TensorRT. I converted the model using the below code:\r\n```python\r\ndef convert(input_saved_model_dir, output_saved_model_dir):\r\n    params = DEFAULT_TRT_CONVERSION_PARAMS._replace(\r\n        max_batch_size=512,\r\n        maximum_cached_engines=16)\r\n    converter = tf.experimental.tensorrt.Converter(\r\n        input_saved_model_dir=input_saved_model_dir, conversion_params=params)\r\n    converter.convert()\r\n\r\n    def input_fn():\r\n        for _ in range(100):\r\n            yield np.ones(shape=[32, 128], dtype=np.int32), \\\r\n                  np.ones(shape=[32, 128], dtype=np.int32), \\\r\n                  np.ones(shape=[32, 128], dtype=np.int32)\r\n    converter.build(input_fn=input_fn)\r\n    converter.save(output_saved_model_dir)\r\n```\r\nHowever, I met a few issues:\r\n1. The shape for the batch dimension is not correct in the converted model; The original model could work with the same input data; The error log is in below:\r\n```\r\n2020-04-20 15:18:03.775850: W tensorflow/core/framework/op_kernel.cc:1751] OP_REQUIRES failed at trt_engine_op.cc:572 : Invalid argument: Input shapes are inconsistent on the batch dimension, for StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0: [[32,128,768], [32,128,768], [1,128,768]]\r\nTraceback (most recent call last):\r\n  File \"/home/feihu/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/feihu/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/../debugpy/server/cli.py\", line 429, in main\r\n    run()\r\n  File \"/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/../debugpy/server/cli.py\", line 266, in run_file\r\n    runpy.run_path(options.target, run_name=compat.force_str(\"__main__\"))\r\n  File \"/home/feihu/miniconda3/lib/python3.6/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/home/feihu/miniconda3/lib/python3.6/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/home/feihu/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/feihu/github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py\", line 28, in <module>\r\n    convert(input_saved_model_dir, output_saved_model_dir)\r\n  File \"/home/feihu/github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py\", line 21, in convert\r\n    converter.build(input_fn=input_fn)\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 1174, in build\r\n    func(*map(ops.convert_to_tensor, inp))\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1612, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 247, in _call_impl\r\n    args, kwargs, cancellation_manager)\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1649, in _call_impl\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 609, in call\r\n    ctx=ctx)\r\n  File \"/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Input shapes are inconsistent on the batch dimension, for StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0: [[32,128,768], [32,128,768], [1,128,768]]\r\n         [[node StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0 (defined at /github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py:14) ]] [Op:__inference_pruned_26783]\r\n```\r\n2. The saved model could not be larger than 2GB; Otherwise, there will be an error from protobuf about `GraphDef object could not exceed the size of 2GB`; \r\n\r\n3. The converted model could not work under the distributed strategy.\r\n\r\n\r\n\r\n", "comments": ["@feihugis \r\n\r\nRequest you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38722\">No</a>\n"]}, {"number": 38721, "title": "Kernel dies in Anaconda ", "body": "Good morning\r\nI'm still have the coronavirus in my set-up:\r\n\r\nMacPro (older), HighSierra -> Anaconda (the last version) -> select a Python (3,7) code which on other Macs/Anaconda worked -> RUN -> Kernel dies with the first Import command.\r\n\r\nI tried as here suggested:\r\n- re-istalled NumPy, directly in Anaconda and also with pip, nothing\r\n- hided NumPy some cells lower, nothing\r\n- installed some libraries here suggested, nothing\r\n\r\nI think it must be an Installation issue, but don't know where the problems could be, thanks for help\r\n\r\n\r\n\r\n", "comments": ["@istvan1000,\r\n\r\nIs this issue related to TensorFlow? \r\n\r\nIf not please get in touch with Anaconda support team, they will be able to help you in this case. Thanks!", "Well TensoFlow is in the list to import, but the notebook stops earlier.\r\nAnyway, is here in Github an Anaconda support group?\r\n", "@istvan1000,\r\nThe Anaconda Community [support page](https://www.anaconda.com/anaconda-community/) points to the [conda Github repo](https://github.com/conda/conda). Please raise an issue in that repo, they should be able to help you in this case. Thanks!", "Thank you"]}, {"number": 38720, "title": "How can I write some layer's logic based on the current epoch or step of epoch?", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1\r\n- Are you willing to contribute it (Yes/No): maybe\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI want to implement the logic of a custom layer based on the current epoch or step of epoch.\r\n\r\n**Will this change the current api? How?**\r\n\r\nI don't know.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nEveryone.\r\n\r\n**Any Other info.**\r\n\r\nYes, I've asked this question also on Stack Overflow: https://stackoverflow.com/q/61329343/3924118\r\n", "comments": ["@nbro \r\n\r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "@ravikyram \r\n\r\n> Do you have any use case that requires the feature you are interested in?\r\n\r\nYes. \r\n\r\nI tried to find a workaround by using callbacks, as I explain in my Stack Overflow question and in this issue related to my specific problem https://github.com/tensorflow/probability/issues/887. I need to solve this as soon as possible, otherwise, I am stuck.", "@nbro \r\n\r\nWill it be possible to share the related code. Thanks!", "@ravikyram What I want to do doesn't really require me to provide you code. I want to implement the logic of a certain (custom) layer that depends on some current state of training (e.g. current epoch or step) or, in general, some input. As I wrote above, you can find my specific problem in this issue: https://github.com/tensorflow/probability/issues/887.\r\n\r\nI've asked other questions on Stack Overflow in order to try to understand how TensorFlow works in certain cases, so that I can solve my specific problem. Please, have a look at them and [at the issue (in the other issue tracker)](https://github.com/tensorflow/probability/issues/887).\r\n\r\n- [Which properties or functions can be changed after the model has been created, compiled, fitted, evaluated and predicted?](https://stackoverflow.com/q/61357111/3924118)\r\n- [Why does tf.executing_eagerly() return False in TensorFlow 2, although I am not using tf.function?](https://stackoverflow.com/q/61355474/3924118)\r\n\r\nIf you know the answers to these Stack Overflow questions, please, let me know!", "@nbro Are you still facing the issue or has it been resolved?", "@gowthamkpr This is still a general issue, in my opinion. There should be a better way of having dynamic layers in TensorFlow/Keras. The workaround is to use variables and change them in a callback or whatever. But that doesn't look like a good solution to me. I would not close this issue, but, if you want, close it.", "Sure, as there is a workaround for this issue, I am closing this one. Thanks for your response"]}, {"number": 38719, "title": "S3 plugin filesystem", "body": "@mihaimaruseac \r\nThis PR is the s3 plugins filesystem for Modular Filesystem C API\r\nRelated Issue: https://github.com/tensorflow/tensorflow/issues/19297", "comments": ["@mihaimaruseac \r\nI think the problems with the test is not caused by s3 but by the test itself. It is true that S3 does not support the concept of directory, but it does not mean that directory-related operation should return the not implemented status. Here is a [quote](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/using-folders.html) from AWS:\r\n> In Amazon S3, buckets and objects are the primary resources, and objects are stored in buckets. Amazon S3 has a flat structure instead of a hierarchy like you would see in a file system. However, for the sake of organizational simplicity, the Amazon S3 console supports the folder concept as a means of grouping objects. Amazon S3 does this by using a shared name prefix for objects (that is, objects have names that begin with a common string). Object names are also referred to as key names.\r\n\r\n> For example, you can create a folder on the console named photos and store an object named myphoto.jpg in it. The object is then stored with the key name photos/myphoto.jpg, where photos/ is the prefix.\r\n\r\n> Here are two more examples:\r\n\r\n> If you have three objects in your bucket\u2014logs/date1.txt, logs/date2.txt, and logs/date3.txt\u2014the console will show a folder named logs. If you open the folder in the console, you will see three objects: date1.txt, date2.txt, and date3.txt.\r\n> If you have an object named photos/2017/example.jpg, the console will show you a folder named photos containing the folder 2017 and the object example.jpg.\r\n\r\nIn term of a normal filesystem language, it means that S3 can create file with any given path ( even if this path is invalid, point to a directory, parent not found, parent is a file, ... ) as long as the bucket is exist because with S3, it just an object with a key ( given path ). When we view it on the console, the parent directory is created automatically to give us the same feeling as in a normal filesystem.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/1c5c78488f5984f694dcb644d4b6b13d7eacb812/tensorflow/c/experimental/filesystem/modular_filesystem_test.cc#L215-L225\r\nThis test will create a file like `/tmp/test/a_file` and after that, it will try to create a file like `/tmp/test/a_file/a_file` which will be failed because of `/tmp/test/a_file` is a file, not a directory. In S3 filesystem, it is possible because they are 2 objects with distinct keys (`/tmp/test/a_file` and `/tmp/test/a_file/a_file`)\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/1c5c78488f5984f694dcb644d4b6b13d7eacb812/tensorflow/c/experimental/filesystem/modular_filesystem_test.cc#L198-L203\r\nBecause `/tmp/test/dir_ not_found/` does not exist, so this test will failed. However, on S3 filesystem, it is an object with key `/tmp/test/dir_not_found/a_file` so it return status `TF_OK`. When we log into the console, the `/tmp/test/dir_not_found` will be create automatically. ", "You're right. Give me a day or two to think of an alternative that minimizes test changes", "> You're right. Give me a day or two to think of an alternative that minimizes test changes\r\n\r\nOk. Take your time \ud83d\ude04 I think We don't need to hurry right now", "@mihaimaruseac \r\nI have another problems which I forgot to mention with the tests\r\n\r\n1. Test setting up. I will make a small PR for this issue if it is ok ?\r\n- `SetUp()` and should be something like this so that it will work on all filesystem. `mkdir` works only on posix\r\n- `::testing::TempDir()` works only with local filesystem. We should add to `root_dir_` bucket name for `s3`, `gcs` and nodename for `hdsf` as test arguments so I dont have to hardcode the bucket name. \r\nhttps://github.com/tensorflow/tensorflow/blob/f0910df10c191ded0744ed01da6c8fceb1e26682/tensorflow/c/experimental/filesystem/modular_filesystem_test.cc#L84-L106\r\n\r\n2. Test should call `Sync()` explicitly on `TF_WritatableFile`. Because when working with `S3`, everything will be save into a temp file. It will be synced to the server only when we call `Sync()` or when we close it. In `modular_filesystem_test`, some tests like `TestCreateThenAppendFile` do not call `Sync()` when creating file so I have to force the filesystem sync everytime I do something with `TF_WritatableFile`. I belive that tensorflow should be the one who know when to sync, not the filesystem itself.\r\n\r\nI will convert it to a draft PR, is it ok ?", "That sounds good. I was working on a similar set of changes to support Windows testing but I'll wait for your PR instead as I have to work on some high priority stuff elsewhere. Thank you\r\n\r\nPlease mention me on the PR so I can review quickly :)", "@mihaimaruseac \r\nA releated update about cloud filesystem.\r\nI have tested `gcs` and it work in a very similar way as `s3`. It has only one different that if we upload object without specify the filename, it will upload into the parent directory if this directory exists. Example:\r\n```\r\nWe will upload example.txt to GCS bucket \r\n- upload to bucket/path/parent/\r\n  // s3 in both situations will create (overwrite) a file whose path is bucket/path/parent/\r\n  if parent/ exists, it will create a file whose path is bucket/path/parent/example.txt\r\n  if parent/ does not exist,  it will create a file whose path is bucket/path/parent/example.txt\r\n\r\n- upload to bucket/path/parent \r\n  // s3 in both situations will create (overwrite) a file whose path is bucket/path/parent\r\n  if parent/ exists,  it will create a file whose path is bucket/path/parent/example.txt\r\n  if parent/ does not exist, it will create a file whose path is bucket/path/parent (parent is a file)\r\n```\r\n\r\nHdfs is a something like a mixture between cloud and local filesystem and I have not tested yet.\r\n\r\nIn short, for cloud filesystem (both s3 and gcs) we don't need to check \r\n- does parent directory exist ?\r\n- is parent path a file ?\r\n- is path point to a file or a directory or not existed ?", "@vnvo2409 This PR is in draft, any update on this? Please. Thanks!", "@mihaimaruseac \nDo you have any update ? If not, i will close this PR", "Sorry, didn't yet get a chance to fully review. Don't close it yet, I'll get an update by Monday", "@mihaimaruseac \r\nI have messed up with `modular_filesystem_test.cc` to have it run properly.  The change I made to `modular_filesystem_test.cc` here is just draft and should be dropped. About the coding style, I haven't paid attention to it yet as I will have it done when all the code works. In addition, the code will be refactored when the tests change. \n\nHere is the PR which I have already incorporated bucketname and root directory in a flag. I think we should review that PR, if you have any idea with the tests, I will do it in that PR too. After that PR is merged, I will rewrite all the code in this PR (S3 plugins PR)\r\nhttps://github.com/tensorflow/tensorflow/pull/38774", "@mihaimaruseac \r\nI have just received an email said that I have been accepted into GSoC 2020.\r\nFirst of all, I would like to say thanks to you for helping me with my proposal.\r\n\r\nSecond, I am thinking about modifying my project timeline. Since we have already had the source code, porting filesystems into plugins won't take too much time. I think I could make a draft PR for GCS and Hadoop by the end of May (Google filesystem as well if you need). After finishing porting all the filesystems, I could help you in anything related to Modular Filesystem C API. And hopefully, we can migrate Modular Filesystem C API to tensorflow/io by the end of summer.\r\n\r\nDo you think it is ok ?", "Congratulations for being accepted into GSoC \ud83c\udf8a \ud83c\udf89 \r\n\r\nI think the proposed changes are exceptional, we can alter the timeline as you suggested. This would be great.\r\n\r\nThank you", "So I will start working on `gcs_filesystem`. Please think about the changes in `modular_filesystem_test.cc`. \ud83d\ude04 ", "@mihaimaruseac \r\nCurrently, `gcs_filesystem` does not use [Google Cloud C++ API](https://github.com/googleapis/google-cloud-cpp). I think we should use it when we write code for `gcs_plugins` instead of writing our own client.\r\n\r\nIn this file https://github.com/tensorflow/tensorflow/blob/3725e1b8bd936cc038e5f370e0065136bec3cf94/tensorflow/workspace.bzl#L330-L342\r\nthe version of `google-cloud-cpp` is 0.17.0 and it is only built for `google/cloud/bigtable`. I would like to ask if I should build a seperate version of `googel-cloud-cpp` for `google/cloud/storage` with lastest release ( 1.13 ) since we will probably need a separate `BUILD` file as well when we move to `tensorflow/io`\r\n\r\nUpdate: It seems that this file is for liscensing purpose only ? So I have built my own `google-cloud-cpp` (1.13)", "It's reasonable to convert to using the GCP API\r\n\r\nLet's make a PR to increase `google-cloud-cpp` version to latest in `workspace.bzl`. Unfortunately, all components of TF will need to use the same version, so you cannot update in just one place (\" I would like to ask if I should build a seperate version of googel-cloud-cpp for google/cloud/storage with lastest release ( 1.13 ) \")", "> It's reasonable to convert to using the GCP API\r\n> \r\n> Let's make a PR to increase `google-cloud-cpp` version to latest in `workspace.bzl`. Unfortunately, all components of TF will need to use the same version, so you cannot update in just one place (\" I would like to ask if I should build a seperate version of googel-cloud-cpp for google/cloud/storage with lastest release ( 1.13 ) \")\r\n\r\nI have just built it with a different name `com_github_googleapis_google_cloud_cpp`. Can you explain `system_build_file` and `system_link_files`. When I go to these file, it just have 6 lines (last commit was two years ago) and it can not build anything except `LICENSE`\r\nhttps://github.com/tensorflow/tensorflow/blob/cbec9ecd1324b67b97b24a5fb858087948effc1a/third_party/systemlibs/google_cloud_cpp.BUILD#L1-L6", "They seem to only point to some symlinks? I will check more and be back.\r\n\r\nHere is where they are used: https://cs.opensource.google/tensorflow/tensorflow/+/master:third_party/repo.bzl;l=79-132;drc=c27d06e49c30e275d27633ceac3c0b3bd6580def", "@mihaimaruseac \r\nI have just made a draft PR for `GCS` https://github.com/tensorflow/tensorflow/pull/39216 , please take a look at it and especially the file `test.log`. Could you give me the list of all filesystems that needs to be ported into plugins. (`hadoop` supports normal concept of \"directory\")\r\n\r\nLastly, if a filesystem does not have a concept about \"directory\", I think we could keep the `CreateDir()` in `Setup()` and check the if the result status is `ok` or `unimplemented` ( let that test continue ) or something else ( skip that test ). However, I am not sure if this is a correct solution because it may break `tensorboard` since `tensorboard` seems to be dependent on `CreateDir` ( I haven't checked it though ).\r\n\r\nAnother solution which is the current solution is `CreateDir(path) = NewWritableFile(path + '/')` but it cause many test failed in `modular_filesystem_test.cc` and is a waste of resources (as this directory is an 0kb object)", "The filesystems we have are:\r\n\r\n* POSIX/Windows local filesystems. I'm handling the Windows one, POSIX is already implemented\r\n* RAM filesystem -- this is mostly for testing and I'll handle it\r\n* S3, Hadoop, GCS -- these 3 need to be modularized and then moved to SIG IO.\r\n\r\nIt seems that we were overengineering w.r.t. filesystems not supporting `CreateDir`, so let's use it in the `SetUp` and revisit later when we add support for a filesystem which won't support it.\r\n\r\nAnother idea I've been having but not fully explored is to have the test suite receive a path directory as a flag. This is the path where the test would run, defaulting to `GetTempDir` (`/tmp`, `C:\\\\Temp`, etc.) if not provided. Then, we can pass a cloud path to this and have a temporary bucket in the cloud, making the test suite agnostic to what file system it tests. Does not resolve the `CreateDir` in `SetUp` but removes the need for 2 different flags for 2 different paths. Let me know what you think about this, I will also investigate more on what changes it would entail.\r\n\r\nI'll dedicate some time today to carefully look over this and #39216, but I have some meetings this morning so probably the review feedback will be late today/early tomorrow. So far, on a quick glance, it looks good.", "> Another idea I've been having but not fully explored is to have the test suite receive a path directory as a flag. This is the path where the test would run, defaulting to `GetTempDir` (`/tmp`, `C:\\\\Temp`, etc.) if not provided. Then, we can pass a cloud path to this and have a temporary bucket in the cloud, making the test suite agnostic to what file system it tests. Does not resolve the `CreateDir` in `SetUp` but removes the need for 2 different flags for 2 different paths. Let me know what you think about this, I will also investigate more on what changes it would entail.\r\n> \r\nIf you means that we will have something like this, I am totally agree with you.\r\n```\r\n--tmp_dir = \"bucket_name/cloud_path\" // for cloud file instead of 2 args bucket_name and cloud_path\r\n--tmp_dir = \"/path/to/a/dir/\" // local filesystem\r\n```\r\n> I'll dedicate some time today to carefully look over this and #39216, but I have some meetings this morning so probably the review feedback will be late today/early tomorrow. So far, on a quick glance, it looks good.\r\n\r\nThis would be great. However, I think you should look over #39216. This PR is just an ugly copy of `s3_filesystem` and should be refactored completely ( after we make decisions about the changes of  `modular_filesystem_test.cc` ). About #39216, it lacks support for `resumable upload` and `multipart upload` for large file and will be added later. Please take a closer look over the file `test.log`, it could give you some insights about how `cloud filesystem` interacts with our test suites. If you don't understand why some tests are passed/failed, please leave a review right there.\r\n\r\n", "Regarding the flag, that was exactly what I was thinking. Happy that we agree on it.\r\n\r\nI'll look over #39216 then and be back with questions there.", "@vnvo2409, @mihaimaruseac This PR is in draft, any update on this? Please. Thanks!", "Close for smaller PR"]}, {"number": 38718, "title": "libstdc++.so.6: version `GLIBCXX_3.4.21' not found ", "body": "OS: Centos 6.2\r\nTensorflow installed from source\r\nTensorflow version: 2.1.0\r\nPython version: 3.5\r\nBazel version: 0.28\r\nGCC version: 6.3.0\r\nGPU support: NO.\r\n\r\nWhen i tried to compile tensorflow from source i get the following error:\r\n\r\nCOMMAND: bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\nERROR: /tmp/tensor/tensorflow-2.1.0/tensorflow/lite/python/optimize/BUILD:29:1: SWIGing tensorflow/lite/python/optimize/calibration_wrapper.i failed (Exit 1)\r\n/root/.cache/bazel/_bazel_root/install/aa7e5eb7da84c1e7540941e7c9d19262/_embedded_binaries/process-wrapper: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /root/.cache/bazel/_bazel_root/install/aa7e5eb7da84c1e7540941e7c9d19262/_embedded_binaries/process-wrapper)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 58.251s, Critical Path: 14.93s\r\nINFO: 231 processes: 231 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\nI tried to add the path of the libraries to the LD_LIBRARY_PATH but it always try to find it in /usr/lib64. \r\n\r\nAlso i tried with the following command:\r\n\r\nBAZEL_LINKOPTS=-static-libstdc++ BAZEL_LINKLIBS=-l%:libstdc++.a bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\nBut the issue is still there.\r\n\r\nThe directory where the library is installed is:  /share/apps/gcc-6.3.0/lib64/libstdc++.so.6\r\n\r\nThanks.\r\n\r\n", "comments": ["@soporteCluster \r\nplease refer tot his link and let us know if it helps: [link1](https://github.com/tensorflow/tensorflow/issues/20341) [link2](https://github.com/bazelbuild/bazel/issues/5348#issuecomment-397494217)", "Hi,\r\nThanks for the answer. I need a way to change the default path where the compilation is trying to find libstdc++.so.6. The version that i have in /usr/lib64/libstdc++.so.6 is too old so i have installed a new version in /share/apps/gcc-6.3.0/lib64/libstdc++.so.6.\r\nThanks.", "@soporteCluster \r\nplease refer to these links and let me know if it helps:\r\n[link1](https://github.com/mlapin/libsdca/issues/1) [link2](https://stackoverflow.com/questions/17177059/overriding-libstdc-search-path-at-runtime-on-linux) [link3](https://unix.stackexchange.com/questions/134266/how-to-specify-the-libstdc-so-6-to-use)", "I can't change the link of the library in /usr/lib64 because it is a cluster server and this could be worse than this problem. I have already set the LD_LIBRARY_PATH but bazel doesn't look around that variable when it compile.\r\nI need a way to say to bazel to find that library in another different path than /usr/lib64.", "@soporteCluster \r\nCan you please refer to these links and let us know if it helps:\r\n[link1](https://github.com/bazelbuild/bazel/issues/590#issuecomment-165811380)\r\n[link2](https://stackoverflow.com/questions/43220067/bazel-link-so-libraries-located-in-a-completely-different-very-remote-folder)\r\n[link3](https://github.com/tensorflow/tensorflow/issues/33108)", "@soporteCluster did you manage to solve your issue? I'm facing exactly same problem while trying to compile Tensorflow on SLURM cluster.", "> @soporteCluster did you manage to solve your issue? I'm facing exactly same problem while trying to compile Tensorflow on SLURM cluster.\r\n\r\nHi,\r\n\r\nI have tried with the following link:\r\nhttps://github.com/bazelbuild/bazel/issues/4137#issuecomment-610518610\r\nIt appears to pass that issue but now i have another problem:\r\n\r\nERROR: /tmp/tensor/tensorflow-2.1.0/tensorflow/lite/experimental/microfrontend/BUILD:44:1: Linking of rule '//tensorflow/lite/experimental/microfrontend:python/ops/_audio_microfrontend_op.so' failed (Exit 1)\r\n/usr/local/bin/ld: bazel-out/k8-py2-opt/bin/_solib_k8/_U_S_Stensorflow_Slite_Sexperimental_Smicrofrontend_Cpython_Sops_S_Uaudio_Umicrofrontend_Uop.so___Utensorflow/libtensorflow_framework.so.2: _edata: invalid version 21 (max 2)\r\n/usr/local/bin/ld: bazel-out/k8-py2-opt/bin/_solib_k8/_U_S_Stensorflow_Slite_Sexperimental_Smicrofrontend_Cpython_Sops_S_Uaudio_Umicrofrontend_Uop.so___Utensorflow/libtensorflow_framework.so.2: error adding symbols: bad value\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 10663.568s, Critical Path: 412.81s\r\nINFO: 18583 processes: 18583 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\nAnd i don't know how to fix it.\r\n\r\n", "Hi,\r\nI have already finished the installation. I have resolved the issue that I had written above by installing binutils-2.34.\r\n\r\nSo what you have to do is install bazel-0.28 and compile it with:\r\n\r\nenv EXTRA_BAZEL_ARGS=\"--host_javabase=@local_jdk//:jdk\" BAZEL_LINKOPTS=-static-libstdc++:-static-libgcc BAZEL_LINKLIBS=-l%:libstdc++.a:-lm  bash ./compile.sh\r\n\r\nInstall binutils-2.34.\r\n\r\nThen run the configure from TensorFlow-2.1.0 inside it. \r\n\r\nFinally build it with:\r\nenv BAZEL_LINKOPTS=-static-libstdc++:-static-libgcc BAZEL_LINKLIBS=-l%:libstdc++.a:-lm BAZEL_CXXOPTS=-std=gnu++0x bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\n", "@@soporteCluster \r\nAs the issue raised is resolved , please confirm if we may move this to closed status, in case of any new issues please raise a new ticket.", "Yes,\r\nI will close it.\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38718\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38718\">No</a>\n"]}, {"number": 38717, "title": "[Intel MKL] Fixes an issue with tensorflow bfloat16 scope that create\u2026", "body": "\u2026s node names with '//', which causes unknown node name problem when run inference from a trained checkpoint", "comments": ["This fails internal tests that have evolved to depend on the broken behavior. Hyrum's law and such. It is being reverted"]}, {"number": 38716, "title": "Add builtin len() support of tf.data.Dataset for autograph", "body": "\r\nWhile working on autograph was looking for calculating the average\r\nof a tf.data.Dataset, noticed that `len()` in autograph\r\nonly support tensor, tensorarray and tensorlist, but not tf.data.Dataset.\r\n\r\nI think it makes sense to add tf.data.Dataset as well as `len()` is too widely\r\nused in many cases.\r\n\r\nThis PR adds `len()` support of tf.data.Dataset for autograph.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["This is great! Please see the note about efficiency and dealing with infinite datasets.", "Thanks @mdanatg for the review! I have updated the PR to use cardinality as the default method to find out the length, and throw out error if INFINITE is encountered.\r\n\r\nIn case of UNKNOWN, the PR falls back to reduce. There is a risk of running into infinite as well. Though even in python's case a len() that causes the infinite is also possible:\r\n\r\n```\r\npython3\r\nPython 3.7.3 (default, Dec 13 2019, 19:58:14)\r\n[Clang 11.0.0 (clang-1100.0.33.17)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> def fib():\r\n...     a, b = 0, 1\r\n...     while True:\r\n...         a, b = b, a + b\r\n...         yield a\r\n...\r\n>>> len(fib())\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: object of type 'generator' has no len()\r\n>>> len(list(fib()))\r\n^CTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<stdin>\", line 4, in fib\r\nKeyboardInterrupt\r\n>>>\r\n\r\n```\r\n\r\nPlease take a look and let me know if there are any issues.", "Interesting! I think in our case, a dataset with unknown length would be the equivalent of the generator in the Pyhton example. Wrapping an infinite generator into a list is indeed problematic, but I think for datasets such operation doesn't exist yet - it would be something in the lines of a `dataset.stack()`-like operation. So I think it would be totally fine to raise an error for unknown as well.", "Thanks @mdanatg for the review. The PR has been updated with comment addressed. \r\n\r\nI also updated the PR to thrown out error in case of UNKNOWN (together with INFINITE case). Let me know if there are any other issues.", "Thanks @mdanatg for the review, please take a look and let me know if there are any other issues."]}, {"number": 38715, "title": "Update stale.yml", "body": "", "comments": []}, {"number": 38714, "title": "Ragged tensor input for keras.Model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nIf a ragged-tensor-input to a keras model e.g. by tensorflow.keras.layers.Input(ragged=True) or tensorflow.keras.Input(ragged=True) is not used or directly connected to the output, an error is raised (see below). This is may not be a problem since the ragged tensor is not used anyway, however, I encountered the same issue for a ragged tensor which is only used for indexing or reshaping. \r\n>ValueError: Layer input_5 does not support RaggedTensors as input. Inputs received: [tf.RaggedTensor(values=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:1\", shape=(None, 1), dtype=float32), row_splits=Tensor(\"RaggedFromVariant_1/RaggedTensorFromVariant:0\", shape=(None,), dtype=int64))]. You can try converting your input to an uniform tensor.\r\n\r\n\r\n**Describe the expected behavior**\r\nThe ragged-tensor-input is accepted as an input, even if it is not used in the model. Hopefully this will also resolve the issue in a more complex model with the same error message/behavior.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe code below shows model3 which does not work, although model and model2 work perfectly.\r\n\r\n```python3\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass DenseRagged(tf.keras.layers.Layer):\r\n    def __init__(self, \r\n        units,\r\n        use_bias=True,\r\n        activation = 'linear',\r\n        **kwargs):\r\n        super(DenseRagged, self).__init__(**kwargs)\r\n        self._supports_ragged_inputs = True \r\n        self.units = units\r\n        self.use_bias = use_bias\r\n        self.activation = tf.keras.activations.get(activation)\r\n    def build(self, input_shape):\r\n        last_dim = input_shape[-1]\r\n        self.kernel = self.add_weight(\r\n                'kernel',\r\n                shape=[last_dim, self.units],\r\n                trainable=True)\r\n        if self.use_bias:\r\n            self.bias = self.add_weight(\r\n                    'bias',\r\n                    shape=[self.units,],\r\n                    trainable=True)\r\n        else:\r\n            self.bias = None\r\n        super(DenseRagged, self).build(input_shape)\r\n    def call(self, inputs):\r\n        outputs = tf.ragged.map_flat_values(tf.matmul,inputs, self.kernel)\r\n        if self.use_bias:\r\n            outputs = tf.ragged.map_flat_values(tf.nn.bias_add,outputs, self.bias)\r\n        outputs =  tf.ragged.map_flat_values(self.activation,outputs)\r\n        return outputs    \r\n\r\nclass PoolingRagged(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(PoolingRagged, self).__init__(**kwargs)\r\n        self._supports_ragged_inputs = True \r\n    def build(self, input_shape):\r\n        super(PoolingRagged, self).build(input_shape)\r\n    def call(self, inputs):\r\n        node = inputs\r\n        out = tf.math.reduce_mean(node,axis=1)\r\n        return out\r\n\r\n\r\ndata_A = tf.ragged.constant([[[2.0],[ 2.0]], [[3.0]], [[4.0], [5.0],[ 6.0]]] ,ragged_rank=1) \r\ndata_B = tf.ragged.constant([[[4.0],[ 4.0]], [[6.0]], [[8.0], [10.0],[12.0]]],ragged_rank=1) \r\ndata_y = np.array([3.9,5.8,11])\r\nprint(data_A.shape,data_B.shape)\r\n\r\nin_A = tf.keras.Input(shape=(None,1),dtype =\"float32\",ragged=True)\r\nout = DenseRagged(1)(in_A)\r\nout = PoolingRagged()(out)\r\nmodel = tf.keras.models.Model(inputs=in_A, outputs=out)\r\n\r\noptimizer = tf.keras.optimizers.Adam(lr=1e-3)\r\nmodel.compile(loss='mean_squared_error',\r\n              optimizer=optimizer,\r\n              metrics=['mean_absolute_error', 'mean_squared_error'])\r\n\r\nmodel.fit(x=data_A,y=data_y,epochs=200)\r\nprint(\"this works\")\r\n\r\nin_A2 = tf.keras.Input(shape=(None,1),dtype =\"float32\",ragged=True)\r\nin_B2 = tf.keras.Input(shape=(None,1),dtype =\"float32\",ragged=True)\r\noutA2 = DenseRagged(1)(in_A2)\r\noutB2 = DenseRagged(1)(in_B2)\r\noutA2 = PoolingRagged()(outA2)\r\noutB2 = PoolingRagged()(outB2)\r\nout2 = tf.keras.layers.Add()([outA2,outB2])\r\nmodel2 = tf.keras.models.Model(inputs=[in_A2,in_B2], outputs=out2)\r\n\r\n\r\noptimizer = tf.keras.optimizers.Adam(lr=1e-3)\r\nmodel2.compile(loss='mean_squared_error',\r\n              optimizer=optimizer,\r\n              metrics=['mean_absolute_error', 'mean_squared_error'])\r\n\r\nmodel2.fit(x=[data_A,data_B],y=data_y,epochs=200)\r\nprint(\"this works,too\")\r\n\r\nin_A3 = tf.keras.Input(shape=(None,1),dtype =\"float32\",ragged=True)\r\nin_B3 = tf.keras.Input(shape=(None,1),dtype =\"float32\",ragged=True)\r\nout3 = DenseRagged(1)(in_A3)\r\nout3 = PoolingRagged()(out3)\r\nmodel3 = tf.keras.models.Model(inputs=[in_A3,in_B3], outputs=out3)\r\n\r\n\r\noptimizer = tf.keras.optimizers.Adam(lr=1e-3)\r\nmodel3.compile(loss='mean_squared_error',\r\n              optimizer=optimizer,\r\n              metrics=['mean_absolute_error', 'mean_squared_error'])\r\n\r\nmodel3.fit(x=[data_A,data_B],y=data_y,epochs=200)\r\nprint(\"this does not work\")\r\n```\r\n", "comments": ["@PatReis Thanks for the issue! \r\n\r\nThis should be fixed in the latest nightly. I tried with the nightly and `model3` works, can you `pip install -U tf-nightly` and confirm this works?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38714\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38714\">No</a>\n", "@omalleyt12 Thank you for the fast reply. I tested with the nightly version and the sample code as well as the more complex model, both work nicely. I noticed that the shape verification for the input with ragged=True seems less strict in nightly but that is fine by me. Thanks again!"]}, {"number": 38713, "title": "Online documentation missing python docs", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecayRestarts\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/LinearCosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/NoisyLinearCosineDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay\r\n\r\nMay be present on others, but I'm not going to scour the web site looking.\r\n\r\n## Description of issue (what needs changing):\r\nThe general documentation of these classes does not show up on the web site. This leads to confusion as many of them have argument documentation containing statements such as *\"See the decay computation above\"*, when there is no documented computation above.\r\n\r\nInstead you have to open the source code to see the documentation that is mentioned.\r\n\r\nHere's an example:\r\n![image](https://user-images.githubusercontent.com/1826947/79771096-4f2dea00-82fc-11ea-8373-ec3572b00f3b.png)\r\nAnd here's the missing documentation:\r\n![image](https://user-images.githubusercontent.com/1826947/79771213-77b5e400-82fc-11ea-9d0d-2dc9efc02232.png)\r\n", "comments": ["Check the nightly version, it has what you want.", "Ah, ok. Yeah, looks like this was fixed by a3d8081\r\n\r\nThanks. Will close"]}, {"number": 38712, "title": "Cannot build TF 2.2 rc2 or rc3 on Windows", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10 x64**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **source (git)**\r\n- TensorFlow version: **2.2.0-rc2 or rc3** (same issue)\r\n- Python version: **3.6.8**\r\n- Installed using virtualenv? pip? conda?: **venv and pip**\r\n- Bazel version (if compiling from source): **2.0.0**\r\n- GCC/Compiler version (if compiling from source): **VS build tools 2019** (I believe 14.25.28610)\r\n- CUDA/cuDNN version: **10.2 / 7.6**\r\n- GPU model and memory: **build machine does not have a supported GPU. Just using this machine to do builds. Building TF 2.1.0 was successful on this machine a week ago**.\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nPlenty of disk space available (> 400GB). Using a 6GB RAM system.\r\n\r\n- git clone of tensorflow\r\n- git checkout v2.2.0-rc2 (also tried rc3, same result)\r\n- bazel clean --expunge\r\n- python ./configure.py\r\n  ROCm: no\r\n  CUDA: yes\r\n  Compute Capability: 6.1\r\n  all other default options\r\n- bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\nThe error I get is :\r\n\r\nERROR: C:/users/....../tensorflow/tensorflow/core/kernels/BUILD:1321:1: C++ compilation of rule '//tensorflow/core/kernels:tile_ops_gpu' failed (Exit 2)\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["More log information below:\r\n\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(657): note: voir la r\u00e9f\u00e9rence \u00e0 l'instanciation classe mod\u00e8le 'Eigen::DenseBase<Derived>' en cours de compilation\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): error C2244: 'Eigen::DenseBase<Derived>::select'\u00a0: impossible de faire correspondre la d\u00e9finition de fonction avec une d\u00e9claration existante\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(153): note: voir la d\u00e9claration de 'Eigen::DenseBase<Derived>::select'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: d\u00e9finition\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,ElseDerived::ConstantReturnType,ElseDerived> Eigen::DenseBase<Derived>::select(const ElseDerived::Scalar &,const Eigen::DenseBase<OtherDerived> &) const'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: d\u00e9clarations existantes\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,std::_Select::_Apply<ElseDerived,ElseDerived>::ConstantReturnType,ElseDerived> Eigen::DenseBase<Derived>::select(const std::_Select::_Apply<ElseDerived,ElseDerived>::Scalar &,const Eigen::DenseBase<OtherDerived> &) const'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,ThenDerived,ThenDerived::ConstantReturnType> Eigen::DenseBase<Derived>::select(const Eigen::DenseBase<OtherDerived> &,const ThenDerived::Scalar &) const'\r\n> C:\\users\\fred\\_bazel_fred\\yhpkrwbv\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,ThenDerived,ElseDerived> Eigen::DenseBase<Derived>::select(const Eigen::DenseBase<OtherDerived> &,const Eigen::DenseBase<ElseDerived> &) const'", "It looks a little bit this like problem (not sure, though):\r\n\r\nhttps://github.com/pytorch/pytorch/issues/25393", "@fcunilim Could it be the issue of locating proper CUDA or VS build tools?\r\nBoth rc builds worked for my Windows setup.\r\nI'm doing something like this, I know it's very likely excessive but at least works. Ignore the cuda being 10.2. It also works with 10.1. There's also possibly a better flag instead of `TF_VC_VERSION` for now, to make sure the build time is reasonable. btw, to speed up the build you might want to tweak the .bazelrc (see https://github.com/tensorflow/tensorflow/issues/38174#issuecomment-613722488).\r\n```\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\nSET TF_NEED_CUDA=1\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\n\r\n# IMPORTANT TO KEEP BUILD TIME REASONABLE\r\nSET TF_VC_VERSION=16.4\r\n\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_cuda_10_2\r\n```\r\n\r\nEDIT: Ohh, just noticed your python version **3.6.8**. I've only built with 3.7 and 3.8.", "I wonder if disabling the eigen compilation speedup flag would help? There is an option which is set by default during configure (something about inlining).\r\n", "\"eigen compilation speedup\" flag is enabled/default for me and still builds fine. Would it be an option to migrate to python 3.7 or 3.8 to have less differences with my env? My MSVC is currently 14.24.28314 but can try with an upgraded version. How long it takes until you get to the failure?", "It takes about 3 hours, on a 4-core 2009 CPU.\r\nI see people speculate this bug could indeed be non-deterministic? It is odd I didn't get the issue before, I compiled TF 2.1 three times last week with no problem.", "I upgraded my MSVC to the latest, same as you have, 14.25.28610 (part of VS 16.5.4) and will see if it builds.", "I ran the build a second time, and got the same error.", "Is the `nvcc --version` output the following for CUDA 10.2?\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019\r\nCuda compilation tools, release 10.2, V10.2.89\r\n```\r\nFor CUDA 10.1 it would be:\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n```\r\n\r\n\r\nAny chance you could try with python 3.8 or 3.7? Not sure it matters much but for the sake of \"fun\".\r\n```\r\n\\python38\\python -m venv \\tmp\\venv-tf2build\r\n\\tmp\\venv-tf2build\\Scripts\\activate\r\npython -m pip install --upgrade pip\r\npip install six numpy wheel keras_applications keras_preprocessing --no-deps\r\n``` etc", "nvcc version is 10.2.89.\r\n\r\nThere is something else that I have noticed twice lately, which is suspicious. Somehow, when I build sometimes the build process is stuck, waiting for \"something\".\r\n\r\nI launched a build again a few minutes ago (just reissued the bazel build command showed above). I then switched to web browsing for a few minutes, then noticed the build process was stuck:\r\n\r\n```\r\n[260 / 2,084] 4 actions running\r\n    Compiling tensorflow/core/kernels/training_ops.cc; 128s local\r\n    Compiling tensorflow/core/kernels/scatter_nd_op_gpu.cu.cc; 96s local\r\n    Compiling tensorflow/core/kernels/inplace_ops_functor_gpu.cu.cc; 43s local\r\n    Compiling tensorflow/core/kernels/random_op_gpu.cu.cc; 16s local\r\n```\r\n\r\nBy stuck I mean, not making any kind of progress.\r\nYesterday the build was stuck at some point too.\r\n\r\nIn both instances, pressing the enter key triggered something, lots of things scroll through the console window, and the build resumes as normal.\r\n\r\nThis issue may not be related at all. Might have something to do with my internet connection or something... but I wonder if there is not something fishy with nvcc?\r\n", "\"Unfortunately\" my Windows build passed now with cuda 10.2.89, msvc 14.25.28610, pyton 3.8, so I don't know what else to check. My build machine does have a GPU but don't think it matters for the build process as long as the cuda and cudnn libs are available.\r\n```\r\nINFO: Elapsed time: 5546.311s, Critical Path: 379.29s\r\nINFO: 8671 processes: 8671 local.\r\nINFO: Build completed successfully, 12541 total actions\r\n```\r\n\r\nre: \"stuck\". It is possibly a different case as enter is doing something, but often the being \"stuck\" situation happens when TF_VC_VERSION=16.5 is not set and eigen inline is enabled (default). It can get \"stuck\" with different files each run, not a deterministic order. Also helps a lot if .bazelrc is optimal for the build hardware (basic example above).\r\n\r\nA bit random thought, make sure your python is 64-bit (`python -VV`).", "This could be because of the various flags and options.\r\nForgive my ignorance, but all I do right now is, from a Windows shell:\r\n\r\n- bazel clean --expunge\r\n- python ./configure.py\r\n- bazel build //tensorflow/ etc.\r\n\r\nWhat should I do exactly to apply your options?\r\nI am all a bit mixed up between environment variables, .bazelrc, explicit flags, etc.\r\nI fear I will do something incorrect (for your example above, do I have to type that in the shell? Do I still need to run configure.py? I would prefer to use configure.py)\r\n\r\nIf all of this doesn't work, I will install Python 3.7 (I can't install 3.8) and try again.\r\n\r\nEDIT: my Python indeed is 64-bit.", "All the `SET `-prefixed commands adjust the active cmd.exe process env. So you'd run `cmd.exe` to start up the Windows shell. Then adjust the env that remains active only within this cmd.exe process (good for testing etc, I prefer this method over using Windows global settings to override env vars):\r\n```\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\nSET TF_NEED_CUDA=1\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\n\r\n# IMPORTANT TO KEEP BUILD TIME REASONABLE\r\nSET TF_VC_VERSION=16.5\r\n```\r\nAfter the env is set, all is left is to activate your python env, making sure you have a good python that includes the required `six numpy wheel keras_applications keras_preprocessing` packages. See the last snippet in https://github.com/tensorflow/tensorflow/issues/38712#issuecomment-616665651 on how I manage python envs, this snippet also creates a new, so you can easily experiment with various python versions.\r\n\r\nAfter the proper python env is active, cd to your tensorflow 2.2rc3 dir, verify that you have a good  64-bit version of python.exe (`python -VV`) and run the usual `python configure.py` command followed by the build and pip wheel build. I'm using these:\r\n```\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package C:/tmp/tensorflow_cuda_10_2\r\n```\r\n\r\n.bazelrc tweak is just a nice to have if you want to speed up the build/allow more cores and higher cpu priority to be used.\r\n\r\nIs it more clear now?  It's just the env vars and python env to set.", "I've started the build with the following setup, we'll see how that goes.\r\n\r\nBazel version 2.0.0.\r\nPython 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]\r\n\r\n```\r\n\\python36\\python.exe -m venv \\tmp\\tf2build-env-py36\r\n\\tmp\\tf2build-env-py36\\Scripts\\activate\r\npython -m pip install --upgrade pip\r\npip install six numpy wheel keras_applications keras_preprocessing --no-deps\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\nSET TF_NEED_CUDA=1\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\nSET TF_VC_VERSION=16.5\r\ngit checkout v2.2.0-rc3\r\nbazel clean --expunge\r\npython ./configure.py\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n```", "Does not compile for me. Still using Python 3.6.8, but with your build method.\r\n\r\nNow I get the following error:\r\n\r\nERROR: C:/users/.../tensorflow/tensorflow/core/BUILD:2176:1: ProtoCompile tensorflow/core/protobuf/error_codes.pb.h failed (Exit -1073741795)\r\n", "How long into the build? Any chance you can provide full output? Any ideas what exactly from my tweaks caused the change in error?\r\n\r\nIt might be worth trying to move the tf checkout closer to the c:\\ root dir to make sure the c:/users/... is not triggering some Windows path length issues. Just a thought. I started the py3.6 build this morning and still runs, will update as it completes.", "py36 build for cuda 10.2, tf2.2rc3 was fine\r\n```\r\nINFO: Elapsed time: 2317.204s, Critical Path: 337.36s\r\nINFO: 3890 processes: 3890 local.\r\nINFO: Build completed successfully, 4394 total actions\r\n```\r\nAlso the built wheel works fine. The only warning with the wheel install is\r\n`tensorboard 2.2.1 has requirement setuptools>=41.0.0, but you'll have setuptools 40.6.2 which is incompatible.`\r\n\r\nI uploaded the wheel to https://drive.google.com/uc?id=1dpTFQcBl0AWMeo5zcCWv47tpeOegEeoB&export=download  (keeping it there for max 24h), use at your own risk.\r\n\r\nUnfortunately no idea what else to debug, if you have specific questions, feel free to ask, I can check with my setup.", "The ProtoCompile error is also referenced here (when building TF 2.1 on Windows), though it concerns another file:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/38413\r\n", "I tried with the MAX_PATH limit override, which was not active in my setup, and I get a slightly different error.\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/stream_executor/BUILD:425:1: ProtoCompile tensorflow/stream_executor/dnn.pb.h failed (Exit -1073741795)\r\n\r\nI am completely puzzled, completely.\r\n", "The difference between your configuration and mine is that I am using VS Build Tools 2019, not VS Community 2019. I see that with your environment variables. I did make the change to match my setup. Could this be an issue ?\r\n\r\nI am running a TF 2.1 build to see if this still builds fine, using bazel 0.27.1. That kind of build did succeed multiple times two weeks ago. This should rule out possible \"my setup changed in a bad way\" scenarios.\r\n\r\nOn a separate computer, will try building TF 2.2 rc3 in a short time with:\r\n\r\n- Python 3.7.7\r\n- VS Build Tools 2019\r\n- CUDA 10.2\r\n- bazel 2.0.0\r\n", "@fcunilim To add some color to your experiments, I did run an rc3 build now with the following in a dir `C:\\asers\\fred\\documents\\repos\\tf22rc3` using Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], CUDA 10.2 and Build Tools.\r\n\r\n```\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\r\nSET TF_VC_VERSION=16.5\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\nSET TF_NEED_CUDA=1\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\nbazel clean --expunge\r\npython configure.py\r\n```\r\n`bazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package` build completed successfully...\r\n```\r\nINFO: Elapsed time: 5108.775s, Critical Path: 350.36s\r\nINFO: 8671 processes: 8671 local.\r\nINFO: Build completed successfully, 12541 total actions\r\n```\r\n\r\nMight be not worth saying but also make sure your python env is as clean as possible.\r\nI can try this also on a laptop without a GPU, but not sure I can procrastinate with my other tasks to that extent :) If you find a solution then please keep this issue updated, would be good to know.\r\n\r\npip freeze:\r\n```\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nnumpy==1.18.3\r\nsix==1.14.0\r\n```", "On my build computer, I decided to uninstall Python 3.6.8, install version 3.7.7 and try a new build.\r\n\r\nThis time, the error I am getting is:\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/BUILD:1710:1: ProtoCompile tensorflow/core/protobuf/conv_autotuning.pb.h failed (Exit -1073741795)\r\n\r\nThings clearly look fishy, non-deterministic.\r\nWill have a look at the second machine in a little while.\r\n", "Being non-deterministic is normal, it's because of the multiple threads running the compilation in parallel.\r\n\r\nAny chance you could share longer log of that error?\r\n\r\nTo confirm, I presume you're running the build from a cmd.exe shell, not from msys or PowerShell.\r\n\r\nBtw, installing various python versions in parallel is perfectly fine in Win. Just install the other version without adjusting any of the paths and for \"all users\", so it can be installed to somewhere like c:\\python\\3.7 etc. After that creating a new venv based on that python version is as simple as `\\python\\3.7\\python -m venv c:\\whenevermynewenvis' followed by `c:\\whenevermynewenvis\\Scripts\\activate` to use it in an active cmd.exe.", "I ran the build again, from scratch, on the same machine:\r\n\r\n/usr/bin/bash: line 1:  1233 Illegal instruction     bazel-out/x64_windows-opt/bin/external/nasm/nasm -fwin64 -DWIN64 -D__x86_64__ -I $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/ -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/ -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/../../win/ -o $out $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: C:/users/fred/_bazel_fred/2h2pzguu/external/libjpeg_turbo/BUILD.bazel:347:1 Executing genrule @libjpeg_turbo//:simd_win_x86_64_assemble failed (Illegal instruction): bash.exe failed: error executing command", "Does your CPU support SSE2?\r\n\r\nEdit: this probably should not matter as you were able to build 2.1", "@fcunilim whats your output from `gcc -march=native -Q --help=target | grep enabled` ?", "My CPU is a Core i5 750. 6GB of RAM. Disk space is plentyful. Before I did a bazel clean --expunge, I had even deleted the _bazel_fred folder to be on the safe side.\r\n\r\nHow can I install gcc on msys2? pacman -S gcc?", "My CPU does not support AVX, and the default TF 2.2 build option is /arch:AVX it seems. Does this mean the computer doing the build needs to support AVX? Or just that the built wheel file will make use of AVX on the computer it is run on?\r\n", "Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nI am saying default here, so I believe /arch:AVX is used. Can that explain my error?\r\n", "Do you have SSE2 at least? Then that might help, see https://docs.microsoft.com/en-us/cpp/build/reference/arch-x86?view=vs-2019 for the options.", "Restarting a build with\r\n\r\n/arch:SSE2\r\n\r\nas optimization flag.", "@fcunilim my attempt with `\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\bin\\Hostx64\\x64\\cl.exe\" /arch:SSE2` is giving a warning for SSE2 being unknown (AVX and AVX2 are accepted), hope it's not the case for you and at least now it's clear where to dig.", "@ahtik how could I successfully compile TF 2.1? The default build option for TF 2.1 also is /arch:AVX", "The build on the other computer (with a CPU indeed supporting AVX) has made good progress. I will report back as soon as it either completes (which I hope) or fails.", "On the i5 750 machine the build is still not successful:\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/kernels/BUILD:1321:1: C++ compilation of rule '//tensorflow/core/kernels:tile_ops_gpu' failed (Exit 2)\r\ncl\u00a0: Ligne de commande warning D9002\u00a0: option '/arch:SSE2' inconnue ignor\u00e9e\r\nRemarque\u00e1: inclusion du fichier\u00e1:  bazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include\\cuda_runtime.h\r\n[...]\r\n\r\nNote the 'tile_ops_gpu' error again. (/arch:SSE2 is ignored as you said @ahtik , it does not look like it causes the error).\r\n\r\nOn the other machine, the build is still going on. Will have to see the outcome in the morning.", "Here is the outcome:\r\n\r\n- TF 2.2 rc3 build was successful on my i5-6300U laptop computer.\r\nUsing @ahtik build procedure, with bazel 2.0.0.\r\n\r\n- TF 2.1 build was successful on the i5 750 computer.\r\nUsing bazel 0.27.1\r\nBuild was performed the way documented on TensorFlow's page https://www.tensorflow.org/install/source_windows :\r\n(deletion of _bazel_fred folder, I did that, this is not mentionned on the page but I wanted to clean things up completely)\r\nbazel clean --expunge\r\npython ./configure.py\r\nbazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\nIn both cases:\r\n\r\n- Windows 10 x64, latest patches applied\r\n- VS BuildTools 2019\r\n- Python 3.7.7 (freshly uninstalled then reinstalled, MAX_PATH registry fix enabled)\r\n- CUDA 10.2\r\n\r\nThe real-time protection of Windows Defender was disabled before starting the builds.\r\n", "I confirm the TF 2.2 rc3 build fails again on the i5 750 computer, after about an hour (ProtoCompile error on yet another file, duration_pb2.py).\r\nI wanted to try yet another time to be sure Windows Defender was unrelated to the issue.\r\n\r\n", "So there is a regression. Can you try building rc0 too? We're trying to identify where the regression might have been introduced.", "Very quickly, I got a build issue with rc0.\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/lite/toco/logging/BUILD:23:1: ProtoCompile tensorflow/lite/toco/logging/toco_conversion_log_pb2.py failed (Exit -1073741795)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 504.213s, Critical Path: 19.76s\r\nINFO: 173 processes: 173 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\nEDIT: disregard the folder name 'tf22rc3', this is the tensorflow repo really, what I did:\r\n\r\ngit checkout v2.2.0-rc0\r\nthen applied @ahtik 's build procedure (including the bazel clean --expunge)\r\n", "-1073741795 / 0xc000001d / STATUS_ILLEGAL_INSTRUCTION errors seem to be all about \"Illegal instruction\", indicating arch instruction set issue somewhere, as also suspected by the @mihaimaruseac SSE2 comment...\r\n\r\nWhen I look at the 64-bit cl.exe /arch flag then there doesn't even seem to be an option for targeting anything lower than SSE2. https://docs.microsoft.com/en-us/cpp/build/reference/arch-x64?view=vs-2019 I couldn't find the minimum cpu requirements for the Visual Studio BuildTools cl.exe compiler, but maybe they expect SSE2 minimum now?", "One more check and then we should be done, for now: can you try building at commit 6094289d90e69533fae5964ea221e57a7a78570e and if that still fails at its parent?\r\n\r\nThis seems to be the only change inlite/toco/logging between 2.1 and 2.2 (not to say that the failure is localized there)", "(tf22p377) C:\\Users\\Fred\\Documents\\repos\\tf22rc3\\tensorflow>**git checkout 6094289**\r\nChecking out files: 100% (1936/1936), done.\r\nPrevious HEAD position was 3c1e8c0341 Merge pull request #37486 from tensorflow/mm-r2.2-debug-win-build\r\nHEAD is now at 6094289d90 [TF lite conversion logging] Implement a simple sanitizer to prune error message returned from MLIR.\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/framework/BUILD:1251:1: ProtoCompile tensorflow/core/framework/tensor_description_pb2.py failed (Exit -1073741795)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1386.651s, Critical Path: 20.23s\r\nINFO: 178 processes: 178 local.\r\nFAILED: Build did NOT complete successfully\r\n", "@mihaimaruseac might have proposed building from https://github.com/tensorflow/tensorflow/commit/f7896058b2c332bef81ed5860567b71c4f2ce10e as being 609... parent.  @fcunilim maybe also run from that? Although your latest error is already from another source.\r\n\r\nIs there a longer and more detailed error/stack available from that build console you could post?", "(tf22p377) C:\\Users\\Fred\\Documents\\repos\\tf22rc3\\tensorflow>git branch\r\n* (HEAD detached at f7896058b2)\r\n  master\r\n\r\nERROR: C:/users/fred/_bazel_fred/2h2pzguu/external/com_google_protobuf/BUILD:759:1: ProtoCompile external/com_google_protobuf/python/google/protobuf/empty_pb2.py failed (Exit -1073741795)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1331.164s, Critical Path: 19.87s\r\nINFO: 181 processes: 181 local.\r\nFAILED: Build did NOT complete successfully\r\n", "I did improve my build steps now by adding\r\n```\r\nset CC_OPT_FLAGS=\"/favor:INTEL64\"\r\n```\r\n(no idea how to pass an empty flag). This way `python configure.py` no longer asks for the compiler arg and defaults to using SSE2 instead of AVX.\r\n\r\nFor my cpu and also for your laptop i5-6300U, it's better to use `set CC_OPT_FLAGS=\"/arch:AVX2\"`. Just make sure to also use the wheel only on supported hardware.\r\n\r\ni5 750 supports SSE4.2, so the default arg using SSE2 in cl.exe should be alright. Not sure where the regression comes from.", "Using bazel build -s -c opt --config=opt ...\r\n\r\nI get\r\n\r\nSUBCOMMAND: # //tensorflow/core/profiler/protobuf:op_metrics_proto_genproto [action 'ProtoCompile tensorflow/core/profiler/protobuf/op_metrics.pb.h', configuration: 6610eac58701ff0155539c518aa44e6981931f5297dbadbfffee7021feb436ed]\r\ncd C:/users/fred/_bazel_fred/2h2pzguu/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\Windows;C:\\Windows\\System32;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Users/Fred/Documents/virtualenvs/tf22p377/Scripts/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/Fred/Documents/virtualenvs/tf22p377/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n  bazel-out/x64_windows-opt/bin/external/com_google_protobuf/protoc --cpp_out=bazel-out/x64_windows-opt/bin -I. -Iexternal/com_google_protobuf/src -Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src tensorflow/core/profiler/protobuf/op_metrics.proto\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/framework/BUILD:1251:1: ProtoCompile tensorflow/core/framework/tensor_description_pb2.py failed (Exit -1073741795)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1331.760s, Critical Path: 19.84s\r\nINFO: 172 processes: 172 local.\r\nFAILED: Build did NOT complete successfully", "@mihaimaruseac Could it be that the protobuf binary dependency got updated and that Windows build was built with AVX instructions enabled?", "@fcunilim Just noticed something at https://github.com/tensorflow/tensorflow/issues/22954#issuecomment-429595782\r\n\r\nMaybe try building without `--config=opt`. As I see, you started to add the 'opt' after my build description and that might have derailed something. This opt comment was for TF 1.1, not sure if even still relevant today.", "Not using --config=opt also results in /arch:AVX being proposed by default.\r\nGoing to try two more things:\r\n\r\n- try without --config=opt\r\n- if this fails, try with /arch:SSE2. This is not supported by VS Build Tools, but the compiler will ignore the option and revert to SSE2 anyway, which is the default architecture\r\n\r\nNote that /arch:AVX was used when I built TF 2.1...", "(tf22p377) C:\\Users\\Fred\\Documents\\repos\\tf22rc3\\tensorflow>git branch\r\n* (HEAD detached at f7896058b2)\r\n  master\r\n\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\nSET TF_NEED_CUDA=1\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\r\nSET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\nSET TF_VC_VERSION=16.5\r\nbazel clean --expunge\r\npython ./configure.py\r\nbazel build --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\nBuild is **successful** on the i5 750. Using Python 3.7.7. Default compiler option /arch:AVX used.\r\n", "Wonderful! What a ride, congrats. I'd presume also the rc3 build works fine now.\r\n\r\nLooks like the default compiler option (/arch:AVX) is used only when `--config=opt` is set: \"Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is %s]\". So the /arch:AVX was very likely ignored in this latest case.", "Not so sure, unfortunately.\r\n\r\nAt the top of this thread, I could not build TF 2.2 rc2/rc3, and I was not using --config==opt...\r\n\r\nTwo things have changed\r\n\r\n- Python 3.6.8 -> 3.7.7\r\n- setting the env variables above, and adding --define=no_tensorflow_py_deps=true as a build option.\r\n\r\nTomorrow I will try to build rc3 the same way I built f789605 today.\r\n", "I think we are building the official releases with `--define=no_tensorflow_py_deps=true` too.\r\n\r\nEdit; [confirmed](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/tools/ci_build/windows/gpu/pip/build_tf_windows.sh;l=141])", "Building rc3 the way described 4 messages above in this thread (no --config==opt, but with --define=no_tensorflow_py_deps=true) does not work. The error I get is:\r\n\r\nERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/kernels/BUILD:687:1: C++ compilation of rule '//tensorflow/core/kernels:split_lib_gpu' failed (Exit 2)\r\n\r\nI am now launching a rc0 build to see what this gives...", "rc0 fails to build:\r\n\r\n`ERROR: C:/users/fred/documents/repos/tf22rc3/tensorflow/tensorflow/core/kernels/BUILD:1321:1: C++ compilation of rule '//tensorflow/core/kernels:tile_ops_gpu' failed (Exit 2)`\r\n\r\nfurther down in the log:\r\n\r\n```\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(657): note: voir la r\u00e9f\u00e9rence \u00e0 l'instanciation classe mod\u00e8le 'Eigen::DenseBase<Derived>' en cours de compilation\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/DenseBase.h(541): error C2993: 'Derived'\u00a0: type non conforme pour le param\u00e8tre de mod\u00e8le sans type '__formal'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): error C2244: 'Eigen::DenseBase<Derived>::select'\u00a0: impossible de faire correspondre la d\u00e9finition de fonction avec une d\u00e9claration existante\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(153): note: voir la d\u00e9claration de 'Eigen::DenseBase<Derived>::select'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: d\u00e9finition\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,ElseDerived::ConstantReturnType,ElseDerived> Eigen::DenseBase<Derived>::select(const ElseDerived::Scalar &,const Eigen::DenseBase<OtherDerived> &) const'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: d\u00e9clarations existantes\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,std::_Select::_Apply<ElseDerived,ElseDerived>::ConstantReturnType,ElseDerived> Eigen::DenseBase<Derived>::select(const std::_Select::_Apply<ElseDerived,ElseDerived>::Scalar &,const Eigen::DenseBase<OtherDerived> &) const'\r\nC:\\users\\fred\\_bazel_fred\\2h2pzguu\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/Select.h(155): note: 'const Eigen::Select<Derived,ThenDerived,ThenDerived::ConstantReturnType> Eigen::DenseBase<Derived>::select(const Eigen::DenseBase<OtherDerived> &,const ThenDerived::Scalar &) const'\r\n\r\n```", "This would mean something changed between commit f789605 and rc0, which causes the build to no longer work on a particular type of CPU (i5 750).", "(tf22p377) C:\\Users\\Fred\\Documents\\repos\\tf22rc3\\tensorflow>git branch\r\n* (HEAD detached at 6094289d90)\r\n  master\r\n\r\nBuild was successful (no '--config=opt', but with py_deps=true)\r\n", "So it works on master but not on rc0?", "I quickly launched a build this morning and... building from the master branch works (indeed... LOL)\r\nCan't wait for the release then ;)", "@fcunilim There's also rc4 out now since Apr 30, could be a good checkpoint for you before the final TF 2.2 :)", "@fcunilim\r\nPlease confirm if this is still an issue or we may move this to closed status.", "@mihaimaruseac  \r\nWe need to have a doc that update windows built ( including tensorflow.dll) on a regular basis!\r\n\r\nI have been [asking something like this **since 6 months ago**](https://github.com/tensorflow/tensorflow/issues/35405). No progress for anything related to tensorflow2.*\r\n\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-windows-x86_64-2.0.0.zip\r\n\r\nAny chance if you can provide a link to your gpu version of libtensorflow?  \r\n", "The[ latest reason](https://github.com/tensorflow/tensorflow/issues/39905#issuecomment-641588284) why WINDOWS is poorly supported", "The latest commit to address this problem is to get more Windows developers to spend MORE TIME trying [new Bazel  (from 2.0 to 3.0)](https://github.com/tensorflow/tensorflow/commit/b4b83222d470afbf0b83d12b0824c0f056235655)\r\n", "Next step is to do DATA SCIENCE, how many TOTAL MONTHS, all windows developers HERE spent on (Attempting) building tensorlfow GPU DLL!", "@Saduf2019 \r\n\r\nBuilding v2.2.0 with bazel 2.0.0 did not complete successfully this morning, using the following script:\r\n\r\n```\r\ngit checkout v2.2.0\r\nSET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\nSET TF_NEED_CUDA=1\r\nSET BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\nSET BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\r\nREM SET CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nREM SET CUDA_TOOLKIT_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\r\nREM SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\\libnvvp;%PATH%\r\nSET TF_VC_VERSION=16.5\r\nbazel clean --expunge\r\npython ./configure.py (press ENTER for each option)\r\nbazel build --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nThe error I got was:\r\n\r\n`ERROR: C:/users/fred/documents/repos/tf22/tensorflow/tensorflow/core/kernels/BUILD:687:1: C++ compilation of rule '//tensorflow/core/kernels:split_lib_gpu' failed (Exit 2)\r\n`\r\n\r\nUsing Python 3.7.7 and a venv with pip freeze:\r\n\r\n```\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nnumpy==1.18.3\r\nsix==1.14.0\r\n\r\n```", "@fcunilim Any chance you could post the whole log between the Exit 2 line and \"Target //tensorflow/tools/pip_package:build_pip_package failed to build\"?\r\n\r\nLooking at the history of this issue it looks like after several back and forths a few builds from the latest \"master\" eventually did succeed for you. But **none** of the 2.2 release-candidate (incl the 2.2 final) builds succeed with the i5 750, no AVX available. Right?\r\n\r\nMy Windows build with v2.2.0 succeeds with similar settings, but with a more recent CPU, so this missing AVX support might be still the issue.", "> @fcunilim Any chance you could post the whole log between the Exit 2 line and \"Target //tensorflow/tools/pip_package:build_pip_package failed to build\"?\r\n> \r\n> Looking at the history of this issue it looks like after several back and forths a few builds from the latest \"master\" eventually did succeed for you. But **none** of the 2.2 release-candidate (incl the 2.2 final) builds succeed with the i5 750, no AVX available. Right?\r\n\r\nThat is correct. I once did a master build which succeeded.\r\n\r\n\r\n\r\n", "@fcunilim \r\n\r\nIs this still an issue, if not can we please move this to closed status", "There still is an issue.\r\n\r\nI cannot build TF 2.2.0 with my old CPU, not supporting AVX.\r\nI can build TF 2.2.0 with my recent CPU that does support AVX. (i5 6400)\r\n\r\nAt this point, I believe the safest path to take is that someone else tries to build TF 2.2.0 on a machine with a CPU not supporting AVX instructions, just like my i5 750. I wish there was another way, but I think this is the only valid option.\r\n", "@fcunilim The error log has been here pretty short to diagnose the source for SSE4.2 vs AVX compiler incompatibility issues. Could you attach the whole command.log from bazel?\r\n\r\n`cd %USERPROFILE%\\_bazel_%USERNAME%\\`\r\n\r\nChoose the cache dir relevant to the failing build, and look for the command.log file for the full output. Even better if multiple command.log from different failing builds can be uploaded.\r\n\r\nCan you confirm that both CPU builds have the same directory length (` C:/users/fred/documents/repos/tf22/tensorflow/`), or at least the `AVX/i5 6400` is not shorter? For MS Build Tools the global registry setting allowing longer paths is not enough, there are still internal limitations for some of the Win APIs. Might not be the case here but better to rule it out 100%.", "Can we close this?", "I'd say so, it stalled", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38712\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38712\">No</a>\n"]}, {"number": 38711, "title": "ResNeXt seems to be missing", "body": "[Keras applications](https://github.com/keras-team/keras-applications) has [ResNeXt nets](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnext.py) (since 17 months). TF2 does not seem to provide constructors for them.\r\n\r\nAlthough there are a couble to lines in TF2 that refer to ResNeXt:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L52\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L73\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L90\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L92\r\n\r\nWhat's up here? Did you forget them? Are they buggy?", "comments": ["@PhilipMay Sorry for the late response. \r\n\r\nPlease note that recently Keras development moved to [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository to focus on only keras. \r\n\r\nI see a related issue (below) to track the progress. Please follow the progress in that issue\r\nhttps://github.com/keras-team/keras/issues/15270", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38710, "title": "Training Loaded Models is MUCH slower", "body": "**System information**\r\nWindows 7\r\nPython 3.8\r\nTensorflow 2.1\r\n\r\n**Describe the current behaviour**\r\n\r\nWhen I create a model \"from scratch\" and train it, with some configs, and data. Each epoch takes around 3 minutes to terminate.\r\n\r\nIf I stop the training after the first epoch, and load the model to continue training (same data, same configs) instead of taking the 3 minutes, every epoch takes around 12 minutes (4x) to conclude.\r\n\r\nThis is how I am creating the model:\r\n\r\n```python\r\n\r\nmodel = Sequential()\r\nmodel.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\r\nmodel.add(Dropout(0.3))\r\nmodel.add(BatchNormalization())\r\n\r\n\r\nmodel.add(LSTM(128, return_sequences=True))\r\nmodel.add(Dropout(0.3))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(128))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(Dense(32, activation='relu'))\r\nmodel.add(Dropout(0.3))\r\n\r\nmodel.add(Dense(2, activation='softmax'))\r\n\r\n\r\nopt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\r\n\r\nfilepath = \"tf/checkpoints/RNN_Final-{epoch:02d}-{val_accuracy:.3f}.hdf5\"  # unique file name that will include the epoch and the validation acc for that epoch\r\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max') # saves only the best ones\r\n\r\nhistory = model.fit(\r\n    train_x, train_y,\r\n    batch_size=BATCH_SIZE,\r\n    epochs=EPOCHS,\r\n    validation_data=(validation_x, validation_y),\r\n    callbacks=[checkpoint,tensorboard],\r\n)\r\n```\r\n\r\nAfter the first Epoch, I am running the code like this:\r\n\r\n\r\n```python\r\n\r\nmodel = load_model(\"mymodel_1EPOCH. hdf5\")\r\n\r\nhistory = model.fit(\r\n    train_x, train_y,\r\n    batch_size=BATCH_SIZE,\r\n    epochs=EPOCHS,\r\n    initial_epoch = 1,\r\n    validation_data=(validation_x, validation_y),\r\n    callbacks=[checkpoint,tensorboard],\r\n)\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n**Describe the expected behaviour**\r\nI was expecting the loaded model, to run at the same speed as the new model. I am saving the models in _.hdf5_. Should I use any other file type?", "comments": ["@acegilz \r\n\r\nLooks like code is incomplete. Request you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38709, "title": "Input_shape changeable in some models but not in others.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): Tensorflow 2.2 / tf-nightly 2.3.0 (installing nightly didn't help solve the problem)\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI want to do transfer learning but change the input_shape of the model. I used code from a Udacity tutorial on transfer learning, in which I reduce the input size of the tfhub feature_vector by more than half and everything works fine. When I tried to to this with another network, it doesn't work. Why is this?\r\n**Describe the expected behavior**\r\nInput shape should be changeable and the model's summary should be outputted without a problem.\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1AIH9d-sqISB1BVi01g7Eqtv6nzBiiAnR\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n(Udacity)\r\n2020-04-20 15:27:55.636605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a3907cc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-20 15:27:55.636646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nModel: \"sequential\"\r\n...\r\nTotal params: 21,813,029\r\nTrainable params: 10,245\r\nNon-trainable params: 21,802,784\r\n_________________________________________________________________\r\n\r\n\r\nvs.\r\n\r\n(my code)\r\n2020-04-20 15:35:21.610011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82a0172350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-20 15:35:21.610056: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"network_model.py\", line 17, in <module>\r\n    tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')])\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py\", line 456, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py\", line 137, in __init__\r\n    self.add(layer)\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py\", line 456, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py\", line 210, in add\r\n    layer(x)\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 930, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow_hub/keras_layer.py:229 call  *\r\n        result = smart_cond.smart_cond(training,\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/load.py:486 _call_attribute  **\r\n        return instance.__call__(*args, **kwargs)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:695 __call__\r\n        result = self._call(*args, **kwds)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:737 _call\r\n        self._initialize(args, kwds, add_initializers_to=initializers)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:617 _initialize\r\n        *args, **kwds))\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2447 _get_concrete_function_internal_garbage_collected\r\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2775 _maybe_define_function\r\n        graph_function = self._create_graph_function(args, kwargs)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2665 _create_graph_function\r\n        capture_by_value=self._capture_by_value),\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/func_graph.py:981 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:528 wrapped_fn\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/function_deserialization.py:251 restored_function_body\r\n        \"\\n\\n\".join(signature_descriptions)))\r\n\r\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n      Positional arguments (4 total):\r\n        * Tensor(\"inputs:0\", shape=(None, 64, 64, 3), dtype=float32)\r\n        * False\r\n        * False\r\n        * 0.99\r\n      Keyword arguments: {}\r\n    \r\n    Expected these arguments to match one of the following 4 option(s):\r\n    \r\n    Option 1:\r\n      Positional arguments (4 total):\r\n        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')\r\n        * True\r\n        * True\r\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\r\n      Keyword arguments: {}\r\n    \r\n    Option 2:\r\n      Positional arguments (4 total):\r\n        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')\r\n        * True\r\n        * False\r\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\r\n      Keyword arguments: {}\r\n    \r\n    Option 3:\r\n      Positional arguments (4 total):\r\n        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')\r\n        * False\r\n        * False\r\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\r\n      Keyword arguments: {}\r\n    \r\n    Option 4:\r\n      Positional arguments (4 total):\r\n        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')\r\n        * False\r\n        * True\r\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\r\n      Keyword arguments: {}", "comments": ["@CRosero,\r\nThe issue you have reported seems to be related to TF-Hub. Could you please create a new issue in the TF-Hub repo from [this link](https://github.com/tensorflow/hub/issues/new), so we can track it there.\r\n\r\nAlso, please take a look at the [usage example](https://tfhub.dev/google/imagenet/mobilenet_v2_035_96/feature_vector/4) given in the module link. Thanks!", "Ok, thanks, will be opening it up in the TF-Hub repo and closing it here."]}, {"number": 38708, "title": "LSTM Keras conversion to tflite model work fine. But the MLkit firebase ml model interpreter error on loading model", "body": "**System information**\r\n- OS Platform: Google Colab, Android 9 (Poco F1)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.2.0-rc3\r\n- firebase ml model interpreter version: firebase-ml-model-interpreter:22.0.2\r\n\r\n**I used this following code to produce my LSTM model**\r\n```\r\nmodel = Sequential()\r\nmodel.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(128, input_shape=X.shape[1:]))\r\nmodel.add(Dropout(0.1))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(Dense(64, activation=\"relu\"))\r\nmodel.add(Dropout(0.2))\r\n\r\nmodel.add(Dense(1, activation=\"sigmoid\"))\r\n\r\nopt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\r\nmodel.compile(loss=\"binary_crossentropy\",\r\n             optimizer=opt,\r\n             metrics=[\"accuracy\"])\r\n```\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\n\r\n**Failure details**\r\nthe conversion run just fine, no error and I can download the TFlite model. However, when I tried to put this model into my android app, it shows error caused by `Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model`. \r\n\r\nI think if the conversion to tflite model is successful, we should be able to run it on the interpreter \r\n\r\n\r\n**Any other info / logs**\r\nhere is the full logs of the error\r\n```\r\nE/ModelResourceManager: Error preloading model resource\r\n    com.google.firebase.ml.common.FirebaseMLException: Local model load failed with the model options: Local model path: drowsy-detector-v21.tflite. Remote model name: unspecified. \r\n        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:36)\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111)\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107)\r\n        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53)\r\n        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7)\r\n        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24)\r\n        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32)\r\n        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6)\r\n        at android.os.Looper.loop(Looper.java:201)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n     Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createModelWithBuffer(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:59)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:207)\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zzb(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:174)\r\n        at com.google.android.gms.internal.firebase_ml.zzrl.zzc(Unknown Source:0)\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:170)\r\n        at com.google.android.gms.internal.firebase_ml.zzrk.zza(Unknown Source:6)\r\n        at com.google.firebase.ml.common.internal.modeldownload.zzj.zzb(com.google.firebase:firebase-ml-common@@22.1.0:61)\r\n        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:21)\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4)\u00a0\r\n        at android.os.Handler.handleCallback(Handler.java:873)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6)\u00a0\r\n        at android.os.Looper.loop(Looper.java:201)\u00a0\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\u00a0\r\n```\r\n", "comments": ["any update on this?", "@pascalisnala We also announced support for TF 2.0 Keras LSTM To fused TFLite LSTM. Please see\r\nhttps://groups.google.com/a/tensorflow.org/g/tflite/c/Ub4apUvblN8\r\n\r\nDo you want to try this out?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38708\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38708\">No</a>\n"]}, {"number": 38707, "title": "InternalError: Unsupported object type float", "body": "Getting this error even though there are no NaNs and X_train and y_train have relevant datatype.\r\n```\r\n    InternalError                             Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1366     try:\r\n-> 1367       return fn(*args)\r\n   1368     except errors.OpError as e:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1351       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\r\n-> 1352                                       target_list, run_metadata)\r\n   1353 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1444                                             fetch_list, target_list,\r\n-> 1445                                             run_metadata)\r\n   1446 \r\n\r\nInternalError: Unsupported object type float\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-69-24be0b0bc7db> in <module>\r\n----> 1 lin_reg.train(train_input_fn, steps=1000)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    372 \r\n    373       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 374       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    375       logging.info('Loss for final step: %s.', loss)\r\n    376       return self\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1162       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1163     else:\r\n-> 1164       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1165 \r\n   1166   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1196       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\r\n   1197                                              hooks, global_step_tensor,\r\n-> 1198                                              saving_listeners)\r\n   1199 \r\n   1200   def _train_model_distributed(self, input_fn, hooks, saving_listeners):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\r\n   1496       while not mon_sess.should_stop():\r\n   1497         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n-> 1498         any_step_done = True\r\n   1499     if not any_step_done:\r\n   1500       logging.warning('Training with estimator made no steps. '\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py in __exit__(self, exception_type, exception_value, traceback)\r\n    883     if exception_type in [errors.OutOfRangeError, StopIteration]:\r\n    884       exception_type = None\r\n--> 885     self._close_internal(exception_type)\r\n    886     # __exit__ should return True to suppress an exception.\r\n    887     return exception_type is None\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py in _close_internal(self, exception_type)\r\n    921         if self._sess is None:\r\n    922           raise RuntimeError('Session is already closed.')\r\n--> 923         self._sess.close()\r\n    924       finally:\r\n    925         self._sess = None\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py in close(self)\r\n   1188     if self._sess:\r\n   1189       try:\r\n-> 1190         self._sess.close()\r\n   1191       except _PREEMPTION_ERRORS as e:\r\n   1192         logging.warning(\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py in close(self)\r\n   1356       self._coord.join(\r\n   1357           stop_grace_period_secs=self._stop_grace_period_secs,\r\n-> 1358           ignore_live_threads=True)\r\n   1359     finally:\r\n   1360       try:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\coordinator.py in join(self, threads, stop_grace_period_secs, ignore_live_threads)\r\n    387       self._registered_threads = set()\r\n    388       if self._exc_info_to_raise:\r\n--> 389         six.reraise(*self._exc_info_to_raise)\r\n    390       elif stragglers:\r\n    391         if ignore_live_threads:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py in reraise(tp, value, tb)\r\n    690                 value = tp()\r\n    691             if value.__traceback__ is not tb:\r\n--> 692                 raise value.with_traceback(tb)\r\n    693             raise value\r\n    694         finally:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py in _run(self, sess, enqueue_op, feed_fn, coord)\r\n     92         try:\r\n     93           feed_dict = None if feed_fn is None else feed_fn()\r\n---> 94           sess.run(enqueue_op, feed_dict=feed_dict)\r\n     95         except (errors.OutOfRangeError, errors.CancelledError):\r\n     96           # This exception indicates that a queue was closed.\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    958     try:\r\n    959       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 960                          run_metadata_ptr)\r\n    961       if run_metadata:\r\n    962         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1181     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1182       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1183                              feed_dict_tensor, options, run_metadata)\r\n   1184     else:\r\n   1185       results = []\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1359     if handle is None:\r\n   1360       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1361                            run_metadata)\r\n   1362     else:\r\n   1363       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1384                     '\\nsession_config.graph_options.rewrite_options.'\r\n   1385                     'disable_meta_optimizer = True')\r\n-> 1386       raise type(e)(node_def, op, message)\r\n   1387 \r\n   1388   def _extend_graph(self):\r\n\r\nInternalError: Unsupported object type float\r\n\r\n\r\n```", "comments": ["@rohansharma777 \r\nplease share the tensorflow version and simple stand alone code for us to replicate the issue", "Tensorflow version is 2.1.0, \r\nHere's the code:\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\n\r\nsymbol = tf.feature_column.categorical_column_with_hash_bucket('Symbol', hash_bucket_size=500)\r\n\r\ncols = X_train.columns\r\n\r\nfeat_cols = []\r\nfor col in cols:\r\n    feat_cols.append(tf.feature_column.numeric_column(col, dtype=tf.float32))\r\n\r\nfeat_cols[0]=symbol\r\n\r\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(X_train, y_train, batch_size=32, num_epochs=1000, shuffle=True)\r\n\r\nlin_reg = tf.estimator.LinearRegressor(feat_cols)\r\n\r\nlin_reg.train(train_input_fn, steps=1000)\r\n\r\n```\r\nX_train is a pandas dataframe and y_train is a pandas Series.", "@rohansharma777 \r\ni ran the code shared by you, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/a5a97b612af3ed7ec7da6d4633dd8ae8/untitled152.ipynb)"]}, {"number": 38706, "title": "[TFLite] Introduce ruy_profiler to Makefile", "body": "TFLite can use [ruy_profiler](https://github.com/google/ruy/tree/master/ruy/profiler) to measure where code is spending time.\r\nHowever, it is only supported on bazel build, not by Makefile.\r\n\r\nThis PR introduces `BUILD_WITH_RUY_PROFILER` option to enable ruy_profiler.\r\n\r\n**Usage**\r\n```bash\r\nBUILD_WITH_RUY_PROFILER=true ./tensorflow/lite/tools/make/build_rpi_lib.sh\r\n```\r\n\r\n**Execution result**\r\n```bash\r\n$ ./rpi_armv7l/bin/benchmark_model --graph=../models/mobilenet_v2_1.0_224_quant/mobilenet_v2_1.0_224_quant.tflite\r\nSTARTING!\r\n...\r\n\r\nProfile (1 threads):\r\n\r\nThread 0 (5025 samples)\r\n\r\n* 76.78% Conv/8bit\r\n  * 71.22% cpu_backend_gemm::Gemm\r\n    * 70.55% cpu_backend_gemm::Gemm: general GEMM\r\n    * 0.68% cpu_backend_gemm::Gemm: CustomGemv\r\n  * 5.55% Im2col\r\n    * 3.70% ExtractPatchIntoBufferColumn\r\n    * 1.85% [other]\r\n* 21.85% DepthwiseConv\r\n  * 21.83% DepthwiseConv/8bit\r\n    * 21.83% DepthwiseConv/8bit/General\r\n      * 15.08% void tflite::optimized_ops::depthwise_conv::QuantizedDepthwiseConvAccumRow(int, int, int, int, const uint8*, int16, int, int, int, const uint8*, int16, int, int, int, int32*) [with bool kAllowStrided = true; int kFixedInputDepth = 0; int kFixedDepthMultiplier = 1; uint8 = unsigned char; int16 = short int; int32 = int]\r\n      * 4.60% downquantize+store\r\n      * 2.15% [other]\r\n  * 0.02% [other]\r\n* 1.35% Add/8bit\r\n  * 1.35% AddElementwise/8bit\r\n* 0.02% AveragePool/8bit\r\n```", "comments": []}, {"number": 38705, "title": "Support options(environment variable) to enable grpc reuse port.", "body": "ReusePort scenario: parent process occupies the port, then share\r\nthe port through service such as ZooKeeper, and then child\r\nprocess (TensorFlow process) reuse the port.", "comments": ["@liutongxuan Can you please fix build failures ? Thanks!", "> @liutongxuan Can you please fix build failures ? Thanks!\r\n\r\n@gbaned , fixed, thx.", "@liutongxuan have you tried enabling this flag and run a job with multi worker mirrored strategy? Mine got suck in `tensorflow::GrpcRemoteMaster::RunStep`:\r\n\r\n```\r\n#0  0x00007f579fa6e483 in epoll_wait () from /lib64/libc.so.6\r\n#1  0x00007f576b1eb0d0 in pollset_work ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007f576b20c825 in cq_pluck(grpc_completion_queue*, void*, gpr_timespec, void*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007f5767caf6e2 in grpc_impl::CompletionQueue::Pluck(grpc::internal::CompletionQueueTag*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007f5767cb5087 in grpc::internal::BlockingUnaryCallImpl<tensorflow::RunStepRequest, tensorflow::RunStepResponse>::BlockingUnaryCallImpl(grpc::ChannelInterface*, grpc::internal::RpcMethod const&, grpc_impl::ClientContext*, tensorflow::RunStepRequest const&, tensorflow::RunStepResponse*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007f5767cb52e0 in tensorflow::grpc::MasterService::Stub::RunStep(grpc_impl::ClientContext*, tensorflow::RunStepRequest const&, tensorflow::RunStepResponse*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007f57670e651b in tensorflow::Status tensorflow::GrpcRemoteMaster::CallWithRetry<tensorflow::RunStepRequest, tensorflow::RunStepResponse>(tensorflow::CallOptions*, tensorflow::RunStepRequest const*, tensorflow::RunStepResponse*, grpc::Status (tensorflow::grpc::MasterService::Stub::*)(grpc_impl::ClientContext*, tensorflow::RunStepRequest const&, tensorflow::RunStepResponse*), std::string) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007f57670e744d in tensorflow::GrpcRemoteMaster::RunStep(tensorflow::CallOptions*, tensorflow::RunStepRequestWrapper*, tensorflow::MutableRunStepResponseWrapper*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007f57670db077 in tensorflow::GrpcSession::RunProto(tensorflow::CallOptions*, tensorflow::MutableRunStepRequestWrapper*, tensorflow::MutableRunStepResponseWrapper*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007f57670dbdae in tensorflow::GrpcSession::RunHelper(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*, std::string const&) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00007f57670dc3d1 in tensorflow::GrpcSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#11 0x00007f57670b4692 in tensorflow::SessionRef::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#12 0x00007f576793bcc2 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#13 0x00007f576793c92a in TF_SessionRun ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#14 0x00007f57670b1024 in tensorflow::TF_SessionRun_wrapper_helper(TF_Session*, char const*, TF_Buffer const*, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<_object*, std::allocator<_---Type <return> to continue, or q <return> to quit---\r\nobject*> > const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*, TF_Status*, std::vector<_object*, std::allocator<_object*> >*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#15 0x00007f57670b11b2 in tensorflow::TF_SessionRun_wrapper(TF_Session*, TF_Buffer const*, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<_object*, std::allocator<_object*> > const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*, TF_Status*, std::vector<_object*, std::allocator<_object*> >*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#16 0x00007f576100d9c3 in void pybind11::cpp_function::initialize<pybind11_init__pywrap_tf_session(pybind11::module&)::{lambda(TF_Session*, TF_Buffer*, pybind11::handle const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*)#17}, pybind11::object, TF_Session*, TF_Buffer*, pybind11::handle const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*, pybind11::name, pybind11::scope, pybind11::sibling>(pybind11_init__pywrap_tf_session(pybind11::module&)::{lambda(TF_Session*, TF_Buffer*, pybind11::handle const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*)#17}&&, pybind11::object (*)(TF_Session*, TF_Buffer*, pybind11::handle const&, std::vector<TF_Output, std::allocator<TF_Output> > const&, std::vector<TF_Operation*, std::allocator<TF_Operation*> > const&, TF_Buffer*), pybind11::name const&, pybind11::scope const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tf_session.so\r\n#17 0x00007f5760ff9cc0 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) ()\r\n   from /grid/b/tmp/yarn/usercache/chren/appcache/application_1599079061958_19332/container_e54_1599079061958_19332_01_000002/tf-edge-azkaban_3cc86d1d69b5f2c657cdd2eeb09ef3c50c9f336187f5edbef17623efa53cb0ef/site-packages/tensorflow/python/_pywrap_tf_session.so\r\n#18 0x00007f57a093049b in _PyMethodDef_RawFastCallKeywords () from /export/apps/python/3.7.7/lib/libpython3.7m.so.1.0\r\n```"]}]