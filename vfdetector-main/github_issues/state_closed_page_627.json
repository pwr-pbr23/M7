[{"number": 34826, "title": "[Dask] [TF 2.0] ValueError: TypeError: len() of unsized object", "body": "**Describe the current behavior**\r\n```python\r\nIn [6]: tf.convert_to_tensor(value)                                                                                                                                                                                                                                                                                          \r\n2019-12-04 13:15:11.908174: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2019-12-04 13:15:12.647383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz\r\n2019-12-04 13:15:12.648044: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644649bc070 executing computations on platform Host. Devices:\r\n2019-12-04 13:15:12.648118: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-12-04 13:15:12.654239: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-6-cb9026824ca5> in <module>\r\n----> 1 tf.convert_to_tensor(value)\r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1240       name=name,\r\n   1241       preferred_dtype=dtype_hint,\r\n-> 1242       as_ref=False)\r\n   1243 \r\n   1244 \r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\r\n   1294 \r\n   1295     if ret is None:\r\n-> 1296       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1297 \r\n   1298     if ret is NotImplemented:\r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    284                                          as_ref=False):\r\n    285   _ = as_ref\r\n--> 286   return constant(v, dtype=dtype, name=name)\r\n    287 \r\n    288 \r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    225   \"\"\"\r\n    226   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 227                         allow_broadcast=True)\r\n    228 \r\n    229 \r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    233   ctx = context.context()\r\n    234   if ctx.executing_eagerly():\r\n--> 235     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    236     if shape is None:\r\n    237       return t\r\n\r\n/opt/anaconda/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     95   ctx.ensure_initialized()\r\n---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     97 \r\n     98 \r\n\r\nValueError: TypeError: len() of unsized object\r\nTraceback (most recent call last):\r\n\r\n  File \"/opt/anaconda/envs/tf/lib/python3.7/site-packages/dask/array/core.py\", line 1165, in __len__\r\n    raise TypeError(\"len() of unsized object\")\r\n\r\nTypeError: len() of unsized object\r\n```\r\n\r\n**Describe the expected behavior**\r\nShould just return a tf.EagerTensor\r\n\r\n**Code to reproduce the issue**\r\nI uploaded a Test-Dask-array which produces this error:\r\nhttps://drive.google.com/file/d/1NtKsv3P37MyYzs8OCbzxSVuL-hA79IPE/view?usp=sharing\r\nPlease `bunzip2` it before running the following code:\r\n```python\r\nimport pickle\r\nimport tensorflow as tf\r\nwith open('test.pkl', 'rb') as handle:\r\n        value = pickle.load(handle)\r\n\r\ntf.convert_to_tensor(value)\r\n```\r\n\r\n**_The part where it fails is `value[0, 0]`, which is a Dask scalar array.\r\nI have no idea why Tensorflow tries to fetch scalar values from a Dask array instead of just calling `np.asarray(value)` on it._**\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nCentos 7\r\n- TensorFlow installed from (source or binary):\r\nconda-forge\r\n- TensorFlow version (use command below):\r\nunknown 2.0.0\r\n- Python version:\r\n3.7.3", "comments": ["still a problem with latest versions", "I encountered the same problem using Cupy.\r\ntensorflow==1.15.0\r\ntensorflow-estimator==1.15.1\r\ntensorflow-gpu==2.1.0\r\ncupy==7.1.1 ", "I can reproduce in 2.1 with a simple\r\n\r\n```\r\nimport tensorflow as tf\r\nimport dask.array as da\r\n\r\ntf.convert_to_tensor(da.array(1.0))\r\n```\r\n", "This is fixed in 2.2.0-rc2. The problem was that TF 2.1 did not handle types that implemented `__array__` properly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34826\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34826\">No</a>\n"]}, {"number": 34825, "title": "Compiling tensorflow 2.0.0 on Jetson AGX Xavier", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): https://github.com/tensorflow/tensorflow/archive/v2.0.0.tar.gz\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: 10.0.326 / 7.5\r\n- GPU model and memory: Jetson AGX Xavier (512-core Volta GPU with Tensor Cores) 16GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm compiling tensorflow 2.0.0 on Jetson AGX Xavier.\r\nI'm following the tutorial on: https://jkjung-avt.github.io/build-tensorflow-2.0.0/\r\nbut compiling blaze fails with:\r\n```\r\nERROR: /mnt/nvme/tensorflow_install/jetson_nano/src/tensorflow-2.0.0/tensorflow/python/keras/api/BUILD:46:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/mnt/nvme/.cache/bazel/_bazel_nvidia/98cdf810b71446efc44591ffddb09367/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_2_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/mnt/nvme/.cache/bazel/_bazel_nvidia/98cdf810b71446efc44591ffddb09367/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_2_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/mnt/nvme/.cache/bazel/_bazel_nvidia/98cdf810b71446efc44591ffddb09367/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_2_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/core/framework/graph_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\nModuleNotFoundError: No module named 'google.protobuf'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 13210.120s, Critical Path: 451.46s\r\nINFO: 11876 processes: 11876 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\nbut on the other hand if I'm running that line alone it works no problem:\r\n```\r\n/mnt/nvme/tensorflow_install/jetson_nano$ python3\r\nPython 3.6.9 (default, Nov  7 2019, 10:44:02) \r\n[GCC 8.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from google.protobuf import descriptor as _descriptor\r\n>>> exit()\r\n```\r\n\r\nI'm assuming something wrong with my enviroment, but how can I check it?", "comments": ["@vladsqp, Please Provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "I've followed the exact sequence of commands from here: https://jkjung-avt.github.io/build-tensorflow-2.0.0/\r\nBut it seems the issue was solved:\r\nI've followed the solution 2 here: https://stackoverflow.com/a/57068827\r\n\r\nAnd also installed protobuf for all my python versions just in case bazel is using the wrong one at that stage.\r\nNow it works builds!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34825\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34825\">No</a>\n"]}, {"number": 34824, "title": "Fix typo in TFLite quantization spec", "body": "", "comments": []}, {"number": 34823, "title": "Profiler API and Service are not available", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#other_ways_for_profiling\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nThe guide presents the profiler API and service as other ways of profiling.\r\nBoth of these use modules inside the `tensorflow.python` package.\r\nHowever, this package does not seem to exist as exhibited by the error message:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-14-c7b3d51d1060> in <module>()\r\n----> 1 with tf.python.eager.profiler.Profiler('logdir_path'):\r\n      2   # do your training here\r\n      3   pass\r\n      4 \r\n      5 \r\n\r\nAttributeError: module 'tensorflow' has no attribute 'python'\r\n```\r\n\r\n### Submit a pull request?\r\n\r\nI would be pleased to submit a pull request, but do not know if there is any TF2.0 compatible way to use profile API or service.", "comments": ["Was able to reproduce the issue. Please find the gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/d2ddb1cfc3be57ae387be5fcabab8e92/copy-of-external-tensorboard_profiling_keras.ipynb). Thanks!", "@AlexisBRENON  Can you try:\r\n```python\r\nfrom tensorflow.python.eager import profiler\r\nwith profiler.Profiler('logdir_path'):\r\n  pass\r\n```\r\n", "@qiuminxu This seems to work. However, is it not fragile to import something from `tensorflow.python`?", "@AlexisBRENON, yes, ideally we want to have a tf.profiler public API, but that is not exposed yet.\r\nThe public API is under discussion, and hopefully we will have a version early next year.", "@qiuminxu Is there a place where I can follow the discussion and API progress?", "Hi @AlexisBRENON, sorry for the wait.\r\nThe public API is finally available in TF 2.2. https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/profiler/experimental\r\nThey are tf.profiler.experimental.xxx for now, for the first release, and will be moved to tf.profiler in the next release. \r\n\r\nfrom tensorflow.python.eager import profiler continues to work in this release, but will be deprecated and move to the new API. \r\n\r\nThe good news is the new API also comes with more tools and features: https://www.tensorflow.org/guide/profiler\r\nLooking forward to hear your experience trying out :)", "Thanks for the feedback. I'll try that ASAP.\r\nI suppose that I\u00a0can close this issue."]}, {"number": 34822, "title": "[r2.1 cherry-pick] Fix pip package API generation", "body": "This cherry picks #34629 onto the `r2.1` release branch.\r\n\r\nThis doesn't completely solve https://github.com/tensorflow/community/pull/182 but should get autocomplete working.\r\n\r\n/cc @annarev @mihaimaruseac", "comments": ["Unfortunately having this in in a pip package causes segfaults on `python -c \"import scipy; import tensorflow\"`. We will rollback for now, to investigate and then rollforward with a fix or provide more instructions.", "> Unfortunately having this in in a pip package causes segfaults on `python -c \"import scipy; import tensorflow\"`\r\n\r\nThat is very strange, I don't see why this change could cause a segfault.\r\nI cannot reproduce the segfault with macOS, Python 3.7.5, Tensorflow 2.1.0rc1, SciPy 1.4.0 and NumPy 1.17.4.\r\n", "That is indeed strange, we were able to reproduce it on Ubuntu, Python3.5, TF 2.1.0rc1, scipy 1.4.0.\r\n\r\nWe'll build a pip package with this rolledback and try it to see if the culprit finder was right. If not, we'll roll it forward again", "I can reproduce the failure on [Colab with `scipy==1.4.0`](https://colab.research.google.com/drive/1Dbi1LXzAhYbgWkrm_Km72GSY80CMCotU), but everything works fine on [Colab with `scipy==1.3.3`](https://colab.research.google.com/drive/1ok6NOHdx41xodpGN8DtkNFNwrNMGmkba).\r\n\r\nIt might be related to https://github.com/scipy/scipy/issues/11237, which now surfaces due to possible changes in import ordering.", "Rolling back the roll back in #35270. Indeed, the culprit was the scipy bug, not this PR. Apologies for the mistaken rollback", "Thanks for investigating."]}, {"number": 34821, "title": "MultiWorkerMirroredStategy cannot run", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (Linux Ubuntu 18.04.3 LTS):\r\n- TensorFlow installed from (binary):\r\n- TensorFlow version (2.0.0):\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Tesla P100\r\n\r\n**Describe the current behavior**\r\nWhen I run the tutorial code in [Multi worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras). Train fails after the first epoch. I guess that the `CollectiveOp` fails. `TF_CONFIG` was  generated by kubeflow, and I can assure that it is correct.\r\n\r\n**Describe the expected behavior**\r\nShould run normally.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nfrom absl import app, flags\r\nimport os\r\nimport json\r\n\r\ntfds.disable_progress_bar()\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_string('input_data_path', default='hdfs://30.78.5.52:9000/data/public/dataset/tensorflow_datasets', help='HDFS Input data path')\r\nflags.DEFINE_string('checkpoint_dir', default=None, help='HDFS checkpoint dir')\r\n\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 64\r\n\r\ndef make_datasets_unbatched():\r\n  # Scaling MNIST data from (0, 255] to (0., 1.]\r\n  def scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n    return image, label\r\n\r\n  datasets, info = tfds.load(name='mnist',\r\n                            with_info=True,\r\n                            as_supervised=True,\r\n                            download=False,\r\n                            data_dir=FLAGS.input_data_path)\r\n\r\n  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)\r\n\r\n\r\ndef build_and_compile_cnn_model():\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n      tf.keras.layers.MaxPooling2D(),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(10, activation='softmax')\r\n  ])\r\n  model.compile(\r\n      loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n  return model\r\n\r\ndef main(argv):\r\n  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\n  NUM_WORKERS = 2\r\n  # Here the batch size scales up by number of workers since\r\n  # `tf.data.Dataset.batch` expects the global batch size. Previously we used 64,\r\n  # and now this becomes 128.\r\n  GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\r\n  # Replace the `filepath` argument with a path in the file system\r\n  # accessible by all workers.\r\n  callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=FLAGS.checkpoint_dir)]\r\n  with strategy.scope():\r\n    # Creation of dataset, and model building/compiling need to be within\r\n    # `strategy.scope()`.\r\n    train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\r\n    multi_worker_model = build_and_compile_cnn_model()\r\n  multi_worker_model.fit(x=train_datasets, epochs=2, callbacks=callbacks)\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n  app.run(main)\r\n\r\n```\r\n\r\n**Other info / logs**\r\nAfter the first epoch, the following error occurred.\r\n```\r\n    469/Unknown - 10s 20ms/step - loss: 2.1859 - accuracy: 0.31432019-12-04 18:43:39.653487: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n2019-12-04 18:43:39.653688: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n2019-12-04 18:43:40.073912: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n2019-12-04 18:43:40.074084: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n2019-12-04 18:43:40.074306: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:234 : Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n2019-12-04 18:43:40.074408: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n         [[CollectiveReduce]]\r\n         [[CollectiveReduce/_2]]\r\n2019-12-04 18:43:40.074591: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n         [[CollectiveReduce]]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 668, in on_start\r\n    yield\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 372, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.6/contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 685, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 298, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 963, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 1012, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 975, in save\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 74, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py\", line 883, in save\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py\", line 164, in __init__\r\n    self.checkpoint_view.objects_ids_and_slot_variables())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 425, in objects_ids_and_slot_variables\r\n    object_names=object_names)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 96, in _serialize_slot_variables\r\n    or hasattr(trackable, \"_create_or_restore_slot_variable\")):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py\", line 389, in __getattr__\r\n    return getattr(self.get(), name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py\", line 322, in get\r\n    return self._get_cross_replica()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py\", line 1237, in _get_cross_replica\r\n    self, axis=None)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 805, in reduce\r\n    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1436, in _reduce\r\n    device_util.current() or \"/device:CPU:0\"))[0]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py\", line 490, in _reduce_to\r\n    reduce_op, value, destinations=destinations)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 282, in reduce\r\n    destinations)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1025, in reduce_implementation\r\n    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1091, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1120, in _do_batch_all_reduce_dense\r\n    \"Id\")\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 365, in build_collective_reduce\r\n    return collective_all_reduce()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 526, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.OutOfRangeError:  [_Derived_]End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Identity_4/_19]]\r\n         [[CollectiveReduce]]\r\n         [[CollectiveReduce/_2]] [Op:__inference_collective_all_reduce_2649]\r\n\r\nFunction call stack:\r\ncollective_all_reduce\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"multi_worker_mirrored_strategy_keras_mnist.py\", line 81, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"multi_worker_mirrored_strategy_keras_mnist.py\", line 76, in main\r\n    multi_worker_model.fit(x=train_datasets, epochs=2, callbacks=callbacks)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 789, in fit\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 776, in wrapper\r\n    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 853, in run_distribute_coordinator\r\n    task_id, session_config, rpc_layer)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 360, in _run_single_worker\r\n    return worker_fn(strategy)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 771, in _worker_fn\r\n    return method(model, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 372, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 671, in on_start\r\n    self.callbacks._call_end_hook(mode)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 258, in _call_end_hook\r\n    self.on_train_end()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 375, in on_train_end\r\n    callback.on_train_end(logs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 940, in on_train_end\r\n    self._training_state.delete_backup()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/multi_worker_training_state.py\", line 161, in delete_backup\r\n    tracking.AutoTrackable.__delattr__(self._model, CKPT_SAVED_EPOCH)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/tracking.py\", line 94, in __delattr__\r\n    super(AutoTrackable, self).__delattr__(name)\r\nAttributeError: _ckpt_saved_epoch\r\n2019-12-04 18:43:40.494701: W tensorflow/core/common_runtime/eager/context.cc:290] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.\r\n\r\n```", "comments": ["I ran into the same issue. The problem is with `multi_worker_model.fit(x=train_datasets, epochs=2, callbacks=callbacks)`\r\n\r\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy\r\n>Since MultiWorkerMirroredStrategy does not support last partial batch handling, pass the steps_per_epoch argument to model.fit() when dataset is imbalanced on multiple workers.\r\n\r\n--> You need to pass in steps_per_epoch", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34821\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34821\">No</a>\n"]}, {"number": 34820, "title": "[Bug] InternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found. On Cuda 10.0.130", "body": "**System information**\r\n- OS Platform and Distribution: (Windows 10)\r\n- TensorFlow installed from : Binary\r\n- TensorFlow version: TF-GIT: v2.0.0-rc2-26-g64c3d382ca  TF : 2.0.0\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.0.130\r\n- GPU model and memory:  GeForce Gtx 1070 \r\n\r\n\r\n**Describe the current behavior**\r\nsimilar to this issue just on CUDA 10.0.130:\r\n#https://github.com/tensorflow/tensorflow/issues/32381\r\n**Describe the expected behavior**\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n\r\n```\r\nNum GPUs Available:  1\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<ipython-input-2-187cc8e8751d> in <module>\r\n      9   tf.keras.layers.Dense(128, activation='relu'),\r\n     10   tf.keras.layers.Dropout(0.2),\r\n---> 11   tf.keras.layers.Dense(10, activation='softmax')\r\n     12 ])\r\n     13 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py in __init__(self, layers, name)\r\n    112       tf_utils.assert_no_legacy_layers(layers)\r\n    113       for layer in layers:\r\n--> 114         self.add(layer)\r\n    115 \r\n    116   @property\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py in _method_wrapper(self, *args, **kwargs)\r\n    455     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    456     try:\r\n--> 457       result = method(self, *args, **kwargs)\r\n    458     finally:\r\n    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py in add(self, layer)\r\n    194       # If the model is being built continuously on top of an input layer:\r\n    195       # refresh its output.\r\n--> 196       output_tensor = layer(self.outputs[0])\r\n    197       if len(nest.flatten(output_tensor)) != 1:\r\n    198         raise TypeError('All layers in a Sequential model '\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    815           # Build layer if applicable (if the `build` method has been\r\n    816           # overridden).\r\n--> 817           self._maybe_build(inputs)\r\n    818           cast_inputs = self._maybe_cast_inputs(inputs)\r\n    819 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in _maybe_build(self, inputs)\r\n   2139         # operations.\r\n   2140         with tf_utils.maybe_init_scope(self):\r\n-> 2141           self.build(input_shapes)\r\n   2142       # We must set self.built since user defined build functions are not\r\n   2143       # constrained to set self.built.\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py in build(self, input_shape)\r\n   1025         constraint=self.kernel_constraint,\r\n   1026         dtype=self.dtype,\r\n-> 1027         trainable=True)\r\n   1028     if self.use_bias:\r\n   1029       self.bias = self.add_weight(\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\r\n    520         collections=collections_arg,\r\n    521         synchronization=synchronization,\r\n--> 522         aggregation=aggregation)\r\n    523     backend.track_variable(variable)\r\n    524 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    742         dtype=dtype,\r\n    743         initializer=initializer,\r\n--> 744         **kwargs_for_getter)\r\n    745 \r\n    746     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    137       synchronization=synchronization,\r\n    138       aggregation=aggregation,\r\n--> 139       shape=variable_shape if variable_shape else None)\r\n    140 \r\n    141 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in __call__(cls, *args, **kwargs)\r\n    256   def __call__(cls, *args, **kwargs):\r\n    257     if cls is VariableV1:\r\n--> 258       return cls._variable_v1_call(*args, **kwargs)\r\n    259     elif cls is Variable:\r\n    260       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\r\n    217         synchronization=synchronization,\r\n    218         aggregation=aggregation,\r\n--> 219         shape=shape)\r\n    220 \r\n    221   def _variable_v2_call(cls,\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in <lambda>(**kwargs)\r\n    195                         shape=None):\r\n    196     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 197     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n    198     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    199       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2505         synchronization=synchronization,\r\n   2506         aggregation=aggregation,\r\n-> 2507         shape=shape)\r\n   2508   else:\r\n   2509     return variables.RefVariable(\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v2_call(*args, **kwargs)\r\n    261     else:\r\n--> 262       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    263 \r\n    264 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n   1404           aggregation=aggregation,\r\n   1405           shape=shape,\r\n-> 1406           distribute_strategy=distribute_strategy)\r\n   1407 \r\n   1408   def _init_from_args(self,\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\r\n   1535           with ops.name_scope(\"Initializer\"), device_context_manager(None):\r\n   1536             initial_value = ops.convert_to_tensor(\r\n-> 1537                 initial_value() if init_from_fn else initial_value,\r\n   1538                 name=\"initial_value\", dtype=dtype)\r\n   1539           if shape is not None:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py in <lambda>()\r\n    117           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\r\n    118         initializer = initializer()\r\n--> 119       init_val = lambda: initializer(shape, dtype=dtype)\r\n    120       variable_dtype = dtype.base_dtype\r\n    121   if use_resource is None:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py in __call__(self, shape, dtype)\r\n    435     else:\r\n    436       limit = math.sqrt(3.0 * scale)\r\n--> 437       return self._random_generator.random_uniform(shape, -limit, limit, dtype)\r\n    438 \r\n    439   def get_config(self):\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py in random_uniform(self, shape, minval, maxval, dtype)\r\n    798       op = random_ops.random_uniform\r\n    799     return op(\r\n--> 800         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\r\n    801 \r\n    802   def truncated_normal(self, shape, mean, stddev, dtype):\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py in random_uniform(shape, minval, maxval, dtype, seed, name)\r\n    235     maxval = 1\r\n    236   with ops.name_scope(name, \"random_uniform\", [shape, minval, maxval]) as name:\r\n--> 237     shape = tensor_util.shape_tensor(shape)\r\n    238     minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\r\n    239     maxval = ops.convert_to_tensor(maxval, dtype=dtype, name=\"max\")\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py in shape_tensor(shape)\r\n    962       # not convertible to Tensors becasue of mixed content.\r\n    963       shape = tuple(map(tensor_shape.dimension_value, shape))\r\n--> 964   return ops.convert_to_tensor(shape, dtype=dtype, name=\"shape\")\r\n    965 \r\n    966 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n   1182   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n   1183       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n-> 1184   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1185 \r\n   1186 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1240       name=name,\r\n   1241       preferred_dtype=dtype_hint,\r\n-> 1242       as_ref=False)\r\n   1243 \r\n   1244 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\r\n   1294 \r\n   1295     if ret is None:\r\n-> 1296       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1297 \r\n   1298     if ret is NotImplemented:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    284                                          as_ref=False):\r\n    285   _ = as_ref\r\n--> 286   return constant(v, dtype=dtype, name=name)\r\n    287 \r\n    288 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in constant(value, dtype, shape, name)\r\n    225   \"\"\"\r\n    226   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 227                         allow_broadcast=True)\r\n    228 \r\n    229 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    233   ctx = context.context()\r\n    234   if ctx.executing_eagerly():\r\n--> 235     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    236     if shape is None:\r\n    237       return t\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     93     except AttributeError:\r\n     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n---> 95   ctx.ensure_initialized()\r\n     96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     97 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tftestclean\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py in ensure_initialized(self)\r\n    490         if self._default_is_async == ASYNC:\r\n    491           pywrap_tensorflow.TFE_ContextOptionsSetAsync(opts, True)\r\n--> 492         self._context_handle = pywrap_tensorflow.TFE_NewContext(opts)\r\n    493       finally:\r\n    494         pywrap_tensorflow.TFE_DeleteContextOptions(opts)\r\n\r\nInternalError: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found..\r\n```\r\n", "comments": ["@Meerer, Please refer similar issue [#30726](https://github.com/tensorflow/tensorflow/issues/30726#issuecomment-511786440). Let us know if it helps. Thanks!", "@Meerer, Is this still an issue!", "Oh yeah sorry I fixed this by reinstalling cuda again."]}, {"number": 34819, "title": "Java: The result of  SavedModelBundle is different every time!", "body": "The model was trained by python and was saved using tf.train.Saver.\r\n\r\nI use the SavedModelBundle api to load and predict in java. However, the result is different every time. It seems some tensor was not loaded randomly. And in the same main programe\uff0cthe result is same notever how many times I load the model. But in different programs, the result may be different. \r\n\r\nPS: model maybe partial load. Because some median result was right, but unstable.\r\n\r\npython==1.14 java==1.14\r\n\r\nMy code:\r\n\r\n```\r\n//load model\r\n            String modelDir = \"/data/model\";\r\n            File file = new File(modelDir);\r\n            SavedModelBundle savedModelBundle = null;\r\n            if (file.exists() && file.isDirectory()) {\r\n                savedModelBundle = SavedModelBundle.load(modelDir, \"serve\");\r\n                System.out.println(\"load succ\");\r\n            } else {\r\n                System.out.println(\"load fail\");\r\n            }\r\n            Session session = savedModelBundle.session();\r\n//feed\r\n            ModelFeature modelFeature = new ModelFeature();\r\n            buildModelFeature(modelFeature);\r\n            Session.Runner tfrunner = session.runner();\r\n            for (FeatureItem item : modelFeature.featureItems) {\r\n                Tensor tensor;\r\n                if (item.getValue().getClass().equals(String[][].class)) {\r\n                    byte[][][] tmpString = new byte[1][1][1];\r\n                    tmpString[0][0] = ((String)item.getValue()[0][0]).getBytes();\r\n                    tensor = Tensor.create(tmpString, String.class);\r\n                } else {\r\n                    tensor = Tensor.create(item.getValue());\r\n                }\r\n                tfrunner = tfrunner.feed(item.getName(), tensor);\r\n                System.out.println(\"succ to create tensor name = \" + item.getName());\r\n            }\r\n//fetch\r\n            //List<Tensor<?>> tensorList = tfrunner.fetch(output).run();\r\n            List<Tensor<?>> tensorList = tfrunner.fetch(\"concat_input_layer_1/concat:0\").run();\r\n//print\r\n            for (int ade = 0; ade < tensorList.size(); ade++) {\r\n                Tensor out;\r\n                System.out.println(\"tensorList size is \" + tensorList.size());\r\n                out = tensorList.get(ade);\r\n                System.out.println(out);\r\n\r\n                final long[] shape = out.shape();\r\n                float[][] trans = new float[(int)shape[0]][(int)shape[1]];\r\n                out.copyTo(trans);\r\n                for (int i = 0; i < shape[0]; i++){\r\n                    for (int j = 0; j < shape[1]; j++){\r\n                        System.out.println(\"final result = \" + trans[i][j]);\r\n                    }\r\n                }\r\n                out.close();\r\n            }}         \r\n```", "comments": ["@gramce, Please post the Tensorflow version and also provide the complete code snippet including all supporting files to reproduce the reported issue. Thanks!", "> @gramce, Please post the Tensorflow version and also provide the complete code snippet including all supporting files to reproduce the reported issue. Thanks!\r\n\r\nSorry. The problem has been fixed. The problem is using the Object Float[] to init Tensor\\<float\\>. I fix this just by using float[]. However, I still think this is a problem.", "@gramce, Glad it fixed. Please provide the complete standalone code to reproduce the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34819\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34819\">No</a>\n"]}, {"number": 34818, "title": "[tflite] make TransposeConv on NNAPI work", "body": "NNAPI TransposeConv op should take tensor inputs from TFLite node.\r\nThis actually is from a0ae68c, which was overwritten by 22fcf5f.\r\n\r\nWithout this patch, delegating transpose convolution to NNAPI will fail.", "comments": []}, {"number": 34817, "title": "YOLOBOX ops, YoloNMS ops", "body": "Use tf2.0 project: yolov3-tf2\r\nI train the model, and want to covert it to .tflite file. Then I get error:\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.\r\n\r\n\r\nThe YoloBoxes and YoloNms ops is not supported.", "comments": ["Hi,\r\n\r\nIf you are trying to convert a model with custom ops, you will need to add the flag allow_custom_ops=True to the command line converter or by adding \r\n`converter.allow_custom_ops = True` before calling converter.convert() if you are using the Python API.\r\n\r\nIf you don't have the custom op implementation for the runtime, see this guide to adding custom ops to your runtime <https://www.tensorflow.org/lite/guide/ops_custom>", "@mengjiexu,\r\nIs this still an issue? Could you please check @daverim's comment and let us know if the issue is resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 34816, "title": "Usage example", "body": "I was working on another GCI task and noticed that keras.utils.to_categorical didn't have a usage example or a raise-error(which I happened to get) so I updated the doc", "comments": []}, {"number": 34815, "title": "[bug] Lambda multiple-layers-different-shapes (ValueError: Dimensions must be equal)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nY\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux tfbug 4.9.0-11-amd64 #1 SMP Debian 4.9.189-3+deb9u2 (2019-11-11) x86_64 GNU/Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n```bash\r\npip install --upgrade tf-nightly \r\n```\r\n- **TensorFlow version (use command below)**:\r\nv1.12.1-19580-gc397ed9 2.1.0-dev20191203\r\n(also tried in 2.0.0-stable)\r\n- **Python version**:\r\nPython 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\n```bash\r\npython lambda_bug.py\r\n```\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nWhen there are multiple layers wrapped in a Lambda, where the unit of the 1st layer is not the same as the inputs, error occurs (ValueError: Dimensions must be equal).\r\nIf there are multiple layers wrapped in a Lambda, where the unit of the 1st layer is the same as the inputs, no error occurs (refer to #bug#fine).\r\nIf there is only a single layer wrapped in a Lambda, no error occurs (refer to model_lambda_single).\r\nIf layer(s) are not wrapped in a Lambda, no error occurs (refer to model_function_,model_bare_).\r\nAs a prototype counterpart of subclassed layer, Lambda should be able to wrap multiple layers\r\nHence, it is convincing that Lambda is not relaying the shape correctly.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n>SOURCE CODE: lambda_bug.py\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import Input, layers\r\nD=123\r\nC=4\r\n#bare\r\ndef model_bare_single():\r\n    model_in = Input((D,),name='model_in')\r\n    model_out = layers.Dense(C,name='lyr_0')(model_in)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_bare_single')\r\n    return model\r\ndef model_bare_multiple():\r\n    model_in = Input((D,),name='model_in')\r\n    model_io = layers.Dense(C,name='lyr_0')(model_in)\r\n    model_out = layers.Dense(C,name='lyr_1')(model_io)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_bare_multiple')\r\n    return model\r\n#function\r\ndef function_single(ins):\r\n    outs = layers.Dense(C,name='lyr_0')(ins)\r\n    return outs\r\ndef model_function_single():\r\n    model_in = Input((D,),name='model_in')\r\n    model_out = function_single(model_in)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_function_single')\r\n    return model\r\ndef function_multiple(ins):\r\n    ios = layers.Dense(C,name='lyr_0')(ins)\r\n    outs = layers.Dense(C,name='lyr_1')(ios)\r\n    return outs\r\ndef model_function_multiple():\r\n    model_in = Input((D,),name='model_in')\r\n    model_out = function_multiple(model_in)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_function_multiple')\r\n    return model\r\n#lambda\r\ndef lambda_single(ins):\r\n    outs = layers.Dense(C,name='lyr_0')(ins)\r\n    return outs\r\ndef model_lambda_single():\r\n    model_in = Input((D,),name='model_in')\r\n    model_out = layers.Lambda(lambda_single,name='lambda_single')(model_in)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_lambda_single')\r\n    return model\r\ndef lambda_multiple(ins):\r\n    ios = layers.Dense(C,name='lyr_0',input_shape=(D,))(ins)#bug\r\n    #ios = layers.Dense(D,name='lyr_0')(ins)#fine\r\n    outs = layers.Dense(C,name='lyr_1')(ios)\r\n    return outs\r\ndef model_lambda_multiple():#bug\r\n    model_in = Input((D,),name='model_in')\r\n    model_out = layers.Lambda(lambda_multiple,name='lambda_multiple',output_shape=(C,))(model_in)\r\n    model = tf.keras.Model(inputs=model_in,outputs=model_out,name='model_lambda_multiple')\r\n    return model\r\ndef main():\r\n    model_bare_single().summary()\r\n    model_bare_multiple().summary()\r\n    model_function_single().summary()\r\n    model_function_multiple().summary()\r\n    model_lambda_single().summary()\r\n    model_lambda_multiple().summary()\r\n    print(tf.__version__)\r\n    return\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n>LOGS\r\n...\r\nTraceback (most recent call last):\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 1619, in _creat\r\ne_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 4 and 123 for 'lamb\r\nda_multiple/lyr_1/MatMul' (op: 'MatMul') with input shapes: [?,4], [123,4].\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"lambda_bug.py\", line 69, in <module>\r\n    main()\r\n  File \"lambda_bug.py\", line 65, in main\r\n    model_lambda_multiple().summary()\r\n  File \"lambda_bug.py\", line 56, in model_lambda_multiple\r\n    model_out = layers.Lambda(lambda_multiple,name='lambda_multiple',output_shape=(C,))(model_in)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 773, \r\nin __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/core.py\", line 827, in cal\r\nl\r\n    return self.function(inputs, **arguments)\r\n  File \"lambda_bug.py\", line 52, in lambda_multiple\r\n    outs = layers.Dense(C,name='lyr_1')(ios)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 773, \r\nin __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/core.py\", line 1089, in ca\r\nll\r\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 5626, in mat\r\n_mul\r\n    name=name)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742,\r\n in _apply_op_helper\r\n    attrs=attr_protos, op_def=op_def)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in \r\n_create_op_internal\r\n    compute_device)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 3314, in _creat\r\ne_op_internal\r\n    op_def=op_def)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 1786, in __init\r\n__\r\n    control_input_ops)\r\n  File \"/home/johnght/venv/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 1622, in _creat\r\ne_c_op\r\n    raise ValueError(str(e))\r\nValueError: Dimensions must be equal, but are 4 and 123 for 'lambda_multiple/lyr_1/MatMul' (op: 'MatMul') with inpu\r\nt shapes: [?,4], [123,4].", "comments": ["I could replicate the issue with Tensorflow 2.1. \r\nPlease see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/c2cbce7aaa916a5364f7f61b1ffdd293/untitled292.ipynb). Thanks!", "In 2.1, we explicitly disallow creating variables in Lambda layers, as it can lead to strange behavior like this. If you have complicated Lambda layers that need to create variables, please [subclass Layer](https://keras.io/layers/writing-your-own-keras-layers/) instead, as that is more robust to complicated logic. \r\n\r\nSee https://github.com/tensorflow/tensorflow/commit/153d1ad929fddb21c9910e8178e825af5601fd7e for more details on the restrictions placed on Lambda layers.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34815\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34815\">No</a>\n", "subclassing is powerful but lame becuase it lacks many auto features: model validation, visualization, serialization...\r\nLoves keras functional api very much ;(\r\n"]}, {"number": 34814, "title": "tflite load model failed use static library, how to get the error info, now only ok or error code?", "body": "i have a tflite model with two type float and float16, run with gpu(use c++ interface). float run ok and both model run ok use python, but float16 failed when use c++ code at code: auto iRetCode = m_pDeeplabInterp->ModifyGraphWithDelegate(m_pGPUDelegate); but this only return one error code 1, but no any other information, i can't find any way to do more thing to check whether is model has ops not support by tflite or my convert pipeline has error.", "comments": ["can you share the model and the way you initialize & invoke the interpreter?", "when use c++ to run tflite model<both c++ and python are tensorflow 2.1>, system has't any information or error message output, tflite::StderrReporter is not used for tflite system to output error information. so are there any way to output system error information like model load failed info, invoke error info, and any thing else.\r\n\r\ni used tensorflow/lite/tools/make scripts to compiled static library and call model by ndk in android app, float32 or quant model all run ok. but float16 can't run, failed at m_pDeeplabInterp->AllocateTensors(). so is there any micro define or flags to enable float16 feature of tflite?", "The error message may not be propagated in function definitions, but we print out details using `context->ReportError()` and this should be visible via `adb logcat`.  Well, at least that's how I get the details =/", "sad to get nothing from adb logcat", "@jdduke \r\n\r\nDo you have guidance on how one can retrieve the TFLite `context->ReportError()`?", "By default it should be routed to adb. Can you capture and send a bug report after you repro the issue? https://developer.android.com/studio/debug/bug-report"]}, {"number": 34813, "title": "gru convert tflite err(KeyError: 'kernel')", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10, notebook(anconda)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source):\r\ntensorflow2.0.0 (use pip install)\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert() # where is wrong\r\n\r\n Copy and paste here the exact command\r\n```python\r\ninput_tensor = tf.keras.Input(shape=(28, 28))\r\nx = tf.keras.layers.GRU(154)(input_tensor)\r\nx = tf.keras.layers.Flatten()(x)\r\nout_tensor = tf.keras.layers.Dense(10, activation=\"relu\")(x)\r\nmodel = tf.keras.Model(input_tensor, out_tensor)\r\nmodel.summary()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert() # where is wrong\r\nopen(\"converted_keras_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n**The output from the converter invocation**\r\nKeyError: 'kernel'\r\n```\r\nCopy and paste the output here.\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-7-b14fd83e63c7> in <module>()\r\n     13 \r\n     14 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n---> 15 tflite_model = converter.convert()\r\n     16 open(\"converted_keras_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\lite.py in convert(self)\r\n    403 \r\n    404     frozen_func = _convert_to_constants.convert_variables_to_constants_v2(\r\n--> 405         self._funcs[0], lower_control_flow=False)\r\n    406     input_tensors = [\r\n    407         tensor for tensor in frozen_func.inputs\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py in convert_variables_to_constants_v2(func, lower_control_flow)\r\n    412 \r\n    413   # Get mapping from function name to argument types.\r\n--> 414   function_data = _get_control_flow_function_data(node_defs, tensor_data)\r\n    415 \r\n    416   # Get variable data for all nodes in `node_defs`.\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py in _get_control_flow_function_data(node_defs, tensor_data)\r\n    260         if arg_types[idx] == dtypes.resource:\r\n    261           input_name = node.input[idx]\r\n--> 262           arg_types[idx] = get_resource_type(input_name)\r\n    263           output_shapes[idx] = get_resource_shape(input_name)\r\n    264 \r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py in get_resource_type(node_name)\r\n    226 \r\n    227   def get_resource_type(node_name):\r\n--> 228     numpy_type = tensor_data[node_name][\"data\"].dtype\r\n    229     return dtypes.as_dtype(numpy_type).as_datatype_enum\r\n    230 \r\n\r\nKeyError: 'kernel'\r\n\r\n\r\n\r\n**Failure details**\r\nconversion is  wrong.\r\n\r\n\r\n\r\n**Any other info / logs**\r\n\r\n", "comments": ["Hi Renjie, \r\n\r\nAny thoughts / guidance on the RNN stuff? ", "Hi Nupur, can you help take a look? thanks", "@mkz0930 When I added experimental flag, everything worked as expected. Please add one line to your code after `converter`.\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\nPlease check the gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/bbea3254d686cb5b2d32ffe9d43511a0/untitled685.ipynb). Thanks!\r\n\r\nPlease close the issue if it was resolved for you. Thanks!", "> @mkz0930 When I added experimental flag, everything worked as expected. Please add one line to your code after `converter`.\r\n> \r\n> ```python\r\n> converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n> converter.experimental_new_converter = True\r\n> tflite_model = converter.convert()\r\n> ```\r\n> \r\n> Please check the gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/bbea3254d686cb5b2d32ffe9d43511a0/untitled685.ipynb). Thanks!\r\n> \r\n> Please close the issue if it was resolved for you. Thanks!\r\n\r\n@jvishnuvardhan \r\nI'm sorry, it didn't work by adding the flag. The error is the same.\r\n\r\nMy version is 2.0.0, is your version 2.1rc?", "@mkz0930 The flag `experimental_new_converter` is not available in 2.0. Please use the `tf-nightly` (`pip install tf-nightly`).", "thanks very much ,it works@gargn", "This sounds familiar to me (see https://stackoverflow.com/questions/63303926/tfliteconverter-throws-keyerror-cond-1-input-1-0).\r\n\r\nI sometimes get `KeyError: 'cond_1_input_1_0'` or `KeyError: 'kernel'`. Not quite sure yet what exactly causes what but does anybody else know maybe?\r\n"]}, {"number": 34812, "title": "The checkpoint generated by tensorflow2.0 training does not have a meta file. How should it be converted to a pb file?", "body": "When T1, the meta file is converted to a pb file, and then the pb file is converted to a tflite file. Now T2 does not generate a meta file, what should I do? Can anyone help me?", "comments": ["You can try ```TFLiteConverter.from_saved_model()``` in TF 2.\r\nSee https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_\r\nFor other methods to convert to tflite, see https://www.tensorflow.org/lite/convert/python_api#python_api"]}, {"number": 34811, "title": "[ROCm] Fix for the broken ROCm CSB - 191203 - XLA", "body": "The following commit breaks the ROCm CSB\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/1c03f956c5851b60fe4fcf16fb4e50bed0fb653b\r\n\r\nIt leads to the following compile error\r\n\r\n```\r\nERROR: /root/tensorflow/tensorflow/compiler/xla/service/cpu/BUILD:225:1:\r\nC++ compilation of rule '//tensorflow/compiler/xla/service/cpu:cpu_executable' failed (Exit 1)\r\n\r\ntensorflow/compiler/xla/service/cpu/cpu_executable.cc:\r\nIn member function 'xla::StatusOr<std::tuple<std::vector<stream_executor::DeviceMemoryBase, std::allocator<stream_executor::DeviceMemoryBase> >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > > > > xla::cpu::CpuExecutable::CreateBufferTable(stream_executor::DeviceMemoryAllocator*, int, std::vector<xla::ShapeTree<xla::MaybeOwningDeviceMemory> >)':\r\n\r\ntensorflow/compiler/xla/service/cpu/cpu_executable.cc:151:39:\r\n\r\nerror: converting to 'std::tuple<std::vector<stream_executor::DeviceMemoryBase, std::allocator<stream_executor::DeviceMemoryBase> >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > > >'\r\n\r\nfrom initializer list would use explicit constructor 'constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...)\r\n[with _UElements = {std::vector<stream_executor::DeviceMemoryBase, std::allocator<stream_executor::DeviceMemoryBase> >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >}; <template-parameter-2-2> = void; _Elements = {std::vector<stream_executor::DeviceMemoryBase, std::allocator<stream_executor::DeviceMemoryBase> >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >, std::vector<stream_executor::ScopedDeviceMemory<unsigned char>, std::allocator<stream_executor::ScopedDeviceMemory<unsigned char> > >}]'\r\n            std::move(buffers_to_free)}};\r\n```\r\n\r\nThe break does not seem ROCm specific, it is very likley breaking other builds too.\r\n\r\nThe fix is to explicitly call `std::make_tuple` at the point of error.\r\n\r\n\r\n/cc @chsigg @whchung ", "comments": ["Thanks for the fix; the relevant change is in the process of being rolled back already.", "The problematic change has been rolled back. I've incorporated this change into the fixed version and will submit it there. Thanks for the PR!"]}, {"number": 34810, "title": "Using Dataset API gives different results than passing in data directly", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I started from a stock Keras example on https://keras.io/examples/mnist_siamese/ and changed the `from keras` to from `tensorflow.keras`   \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): NGC Tensorflow 19.11 docker Image (Also happens on pip install tensorflow-gpu)\r\n- TensorFlow version (use command below): 2.0.0 and 1.14\r\n- Python version: 3.6.8\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.2 and CUDA 10.1 / cudnn 7.6.5 and cudnn 7.6.3\r\n- GPU model and memory: Tesla V100\r\n\r\n**Describe the current behavior**\r\nWhen I run the example on https://keras.io/examples/mnist_siamese/ and changed the `from keras` to from `tensorflow.keras` it executes exactly how you'd expect and trains up to ~98% for training and validation. The fit portion of code passes in the data directly via \r\n\r\n```\r\nmodel.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\r\n          batch_size=128,\r\n          epochs=epochs,\r\n          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\r\n```\r\n\r\nIf I instead create a dataset using the following \r\n\r\n```\r\ntr_ds = tf.data.Dataset.from_tensor_slices(((tr_pairs[:, 0], tr_pairs[:, 1]), tr_y))\r\ntr_ds = tr_ds.batch(128)\r\nte_ds = tf.data.Dataset.from_tensor_slices(((te_pairs[:, 0], te_pairs[:, 1]), te_y))\r\nte_ds = te_ds.batch(128)\r\n```\r\n\r\nand then train by passing in the datasets into the model.fit. The training and validation loss and accuracy behave significantly worse.  \r\n\r\n**Describe the expected behavior**\r\n\r\nI'd expect the the Dataset API to give the same result as passing in the data directly.\r\n\r\n**Code to reproduce the issue**\r\n\r\n1. Copy code from example into a notebook or other python environment.\r\n2. Change `import keras` calls to `import tensorflow.keras`\r\n    2.1 If using TF 2.0 change tr_y and te_y to floats by adding `.astype(np.float32)` to the values in model.fit. If you don't do this you will get `TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.` \r\n3. Run to see expected good results\r\n4. Before the `rms = RMSProp()` line add the following\r\n```\r\ntr_ds = tf.data.Dataset.from_tensor_slices(((tr_pairs[:, 0], tr_pairs[:, 1]), tr_y))\r\ntr_ds = tr_ds.batch(128)\r\nte_ds = tf.data.Dataset.from_tensor_slices(((te_pairs[:, 0], te_pairs[:, 1]), te_y))\r\nte_ds = te_ds.batch(128)\r\n```\r\n5. Comment out the included `model.fit` and replace it with \r\n```\r\nmodel.fit(tr_ds,\r\n          epochs=epochs,\r\n          validation_data=te_ds\r\n     )\r\n```\r\n6. Train and watch val_loss and val_accuracy not behave as expected.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI've attached a txt file of the source I used to exhibit this behavior (it wouldn't let me upload the file as a .py)\r\n[pairs_mnist.txt](https://github.com/tensorflow/tensorflow/files/3918658/pairs_mnist.txt)", "comments": ["This probably something for stack overflow and not here.  ", "I'm getting this issue as well. The problem is with tf.keras, tensorflow 2.0.0 and only manifests if I pass the test data in as a dataset rather than a numpy array. It doesn't matter if the training data is in numpy or dataset form.", "I am getting the same issue. Did you find the resolution for this issue?", "Yes, I had my shuffle size to small. Ideally you would set the shuffle size\nto match the total size of all your data. This is obviously not possible in\nall cases but make sure you put thought into what data is getting shuffled.\nFor a simple example, let\u2019s say you have 128 items in your tfrecord, and\nyou set your shuffle size to 64. This would be fine if your data is already\nnormally distributed in the tfrecord, but let\u2019s assume the first 64 have a\nlabel of 0 and the second 64 have a label of 1. If you had a batch size of\n64 this would make the first batch be all 0 and the second batch be all 1.\nIf you have a batch size of 4, a training epoch will go through cycles of\nlearning everything is 0 and then back to 1.\n\nHope this helps.\n\nOn Fri, May 15, 2020 at 6:06 PM Sangeet Saurabh <notifications@github.com>\nwrote:\n\n> I am getting the same issue. Did you find the resolution for this issue?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/34810#issuecomment-629555332>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABISBAF5JJ23YLTJICQ2ZO3RRXKHVANCNFSM4JU6N2FA>\n> .\n>\n", "Thank you, Kyle! This was very helpful. Shuffling across entire data in the training set solved the problem."]}, {"number": 34809, "title": "Typo in tf.keras.layers.Attention docs example", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\r\n\r\n## Description of issue (what needs changing):\r\nIn the code example, it currently reads:\r\n```python\r\n# Variable-length int sequences.\r\nquery_input = tf.keras.Input(shape=(None,), dtype='int32')\r\nvalue_input = tf.keras.Input(shape=(None,), dtype='int32')\r\n\r\n# Embedding lookup.\r\ntoken_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\r\n# Query embeddings of shape [batch_size, Tq, dimension].\r\nquery_embeddings = token_embedding(query_input)\r\n# Value embeddings of shape [batch_size, Tv, dimension].\r\nvalue_embeddings = token_embedding(query_input)\r\n```\r\n\r\nThe last line should instead be:\r\n```\r\nvalue_embeddings = token_embedding(value_input)\r\n```", "comments": ["Fixed by 4b2f4f4d25a75593bdeaf993b8cdcfc7055a7a55.", "@lamberta I believe this can be closed now!", "Thank you all!"]}, {"number": 34808, "title": "grpc+verbs not being used", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N.A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.15\r\n- Python version: 3.5.2, 3.6.8 (different machines)\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): GCC 7.4\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\nRunning code with tf.estimator.RunConfig(...., protocol=\"grpc+verbs\") does not throw any error, but does not appear to use RDMA (logs do not show any mention of RDMA). Running the code without this protocol (i.e just on gRPC) appears to work fine, which leads me to think that it's a build / installation issue. We also observe no speed-up by using RDMA, which suggests that RDMA is not being used. We are using a 1x parameter server, 1x chief, 1x evaluator, 15x worker setup (Parameter server, chief, and evaluator are on the same node and share the same filesystem; the workers are on separate machines and do not share the same file system).\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI followed the guide [here](https://www.tensorflow.org/install/source) to compile from source. However, running the \"./configure\" step does **not** give an option to install with verbs support. Hence, I built Tensorflow with the following command:\r\n`bazel build --config=verbs //tensorflow/tools/pip_package:build_pip_package`. Everything else followed the given guide.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nSample parameter server logs:\r\n`2019-12-03 13:26:22.885842: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\n2019-12-03 13:26:22.899183: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job chief -> {0 -> 192.168.9.20:1235}\r\n2019-12-03 13:26:22.899214: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job ps -> {0 -> localhost:1236}\r\n2019-12-03 13:26:22.899232: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:258] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.9.16:1234, 1 -> 192.168.9.17:1234, 2 -> 192.168.9.18:1234, 3 -> 192.168.9.23:1234, 4 -> 192.168.9.24:1234, 5 -> 192.168.9.25:1234, 6 -> 192.168.9.26:1234, 7 -> 192.168.9.27:1234, 8 -> 192.168.9.28:1234, 9 -> 192.168.9.29:1234, 10 -> 192.168.9.30:1234, 11 -> 192.168.9.31:1234, 12 -> 192.168.9.32:1234, 13 -> 192.168.9.105:1234, 14 -> 192.168.9.106:1234}\r\n2019-12-03 13:26:22.903725: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:1236\r\n2019-12-03 13:26:22.903796: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:369] Server already started (target: grpc://localhost:1236)\r\n2019-12-03 13:26:28.930441: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:29.073805: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:29.308595: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:29.609207: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:29.994561: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:30.430739: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:30.971334: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:59.046948: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.\r\n2019-12-03 13:26:59.278155: I tensorflow/core/distributed_runtime/worker.cc:203] Cancellation requested for RunGraph.`", "comments": ["It seems your RDMA configuration is not in effective. Would you mind to check again with official TensorFlow package (without verbs support) and see if there is any error reported?", "Hmm. @byronyi do you have a basic RDMA test code that I could use? I want to rule out the possibility that it's a quirk with the code I'm using--it seems like estimators are a pretty new addition to distributed training.", "@limjingrong Back in the old days we use tensorflow/benchmarks, as shown in one of my old (and stale) issues: https://github.com/tensorflow/tensorflow/issues/23606\r\n\r\n```\r\npython benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\r\n  --ps_hosts=localhost:5000 \\\r\n  --worker_hosts=localhost:5001 \\\r\n  --job_name=worker \\\r\n  --task_index=0 \\\r\n  --server_protocol=grpc \\\r\n  --variable_update=parameter_server \\\r\n  --local_parameter_device=cpu \\\r\n  --model=resnet50 \\\r\n  --num_gpus=4 \\\r\n  --use_fp16 \\\r\n  --batch_size=256\r\n```\r\n\r\nJust change the server_protocol parameter from grpc to grpc+verbs to test it out.", "@byronyi Thanks for the suggestion! I ran the benchmarks from the branch cnn_tf_v1.12_compatible with \r\n`python3 benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\r\n  --ps_hosts=192.168.9.20:1236 \\\r\n  --worker_hosts=192.168.9.18:1234 \\\r\n  --job_name=worker \\\r\n  --task_index=0 \\\r\n  --server_protocol=grpc+verbs \\\r\n  --variable_update=parameter_server \\\r\n  --local_parameter_device=cpu \\\r\n  --model=resnet50 \\\r\n  --use_fp16 \\\r\n  --batch_size=256 \\\r\n  --device=cpu\r\n  --data_format=NHWC\r\n  --num_warmup_batches=1`\r\n\r\n(I ran into another unrelated problem, where the worker hangs while warming up, but that may be related to me using CPU only)\r\n\r\nThe parameter server in this set up outputs the line\r\n`2019-12-06 14:58:39.442051: I tensorflow/contrib/verbs/rdma_mgr.cc:130] Connected to remote node /job:worker/replica:0/task:0`, which verifies that RDMA is part of the build. I'm now wondering if grpc+verbs isn't fully supported by the new TF estimator framework--I'm using _tf.distribute.experimental.ParameterServerStrategy_\r\n\r\nOur code is as follows\r\n'\r\n    os.environ[\"TF_CONFIG\"]  = json.dumps({\r\n           \"cluster\": {\r\n               \"worker\": [\"192.168.9.18:1234\"],\r\n               \"chief\": [\"192.168.9.20:1235\"],\r\n               \"ps\": [\"192.168.9.20:1236\"],\r\n               \"evaluator\": [\"192.168.9.20:1237\"]\r\n       },\r\n          \"task\": {\"type\": \"chief\", \"index\": 0}\r\n    })\r\n\r\n    BUFFER_SIZE = 10000\r\n    BATCH_SIZE = 32\r\n    EPOCHS = 10\r\n\r\n    def input_fn(mode, input_context=None):\r\n        datasets, info = tfds.load(name=\"mnist\",\r\n                                    with_info=True,\r\n                                    as_supervised=True)\r\n        mnist_dataset = (datasets[\"train\"] if mode == tf.estimator.ModeKeys.TRAIN else\r\n                       datasets[\"test\"])\r\n\r\n        def scale(image, label):\r\n            image = tf.cast(image, tf.float32)\r\n            image /= 255\r\n            return image, label\r\n\r\n        if input_context:\r\n            mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\r\n                                            input_context.input_pipeline_id)\r\n        return mnist_dataset.map(scale).cache().repeat(EPOCHS).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n\r\n    datasets, info = tfds.load(name=\"mnist\",\r\n                                with_info=True,\r\n                                as_supervised=True)\r\n    mnist_dataset = (datasets[\"train\"])\r\n\r\n    def scale(image, label):\r\n        image = tf.cast(image, tf.float32)\r\n        image /= 255\r\n        return image, label\r\n\r\n    mnist_dataset.map(scale).cache().repeat(EPOCHS).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\n    LEARNING_RATE = 1e-1\r\n\r\n    def model_fn(features, labels, mode):\r\n        training = mode == tf.estimator.ModeKeys.TRAIN\r\n        model = tf.keras.Sequential([\r\n            tf.keras.layers.Flatten(),\r\n            tf.keras.layers.Dense(10)\r\n      ])\r\n        logits = model(features, training)\r\n\r\n        if mode == tf.estimator.ModeKeys.PREDICT:\r\n            predictions = {'logits': logits}\r\n            return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)\r\n\r\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\r\n        loss = tf.keras.losses.SparseCategoricalCrossentropy(\r\n          reduction=\"none\",\r\n          from_logits=True)(labels, logits)\r\n        loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)\r\n        if mode == tf.estimator.ModeKeys.EVAL:\r\n            metrics_dict = {\r\n                'accuracy': tf.metrics.accuracy(labels, tf.argmax(logits, axis=-1))\r\n            }\r\n            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics_dict)\r\n\r\n        train_op = optimizer.minimize(\r\n            loss, global_step=tf.train.get_or_create_global_step())\r\n\r\n        return tf.estimator.EstimatorSpec(\r\n          mode=mode,\r\n          loss=loss,\r\n          train_op=train_op)\r\n\r\n    strategy = tf.distribute.experimental.ParameterServerStrategy()\r\n    run_config = tf.estimator.RunConfig(\r\n        experimental_distribute=tf.contrib.distribute.DistributeConfig(\r\n           train_distribute=strategy,\r\n        ),\r\n        protocol=\"grpc+verbs\"\r\n    )\r\n    estimator = tf.estimator.Estimator(config=run_config, model_fn=model_fn, model_dir=\"/home/rdma_for_ml/model_dir\")\r\n\r\n    start = time.clock()\r\n    tf.estimator.train_and_evaluate(\r\n        estimator,\r\n        train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\r\n        eval_spec=tf.estimator.EvalSpec(input_fn=input_fn))\r\n    print(time.clock()-start)\r\n`", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34808\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34808\">No</a>\n"]}, {"number": 34807, "title": "Fix deprecation warnings in image_ops by replacing div with divide or floordiv", "body": "Using `tf.image.per_image_standardization` or certain calls (depending on arguments) to `tf.image.convert_image_dtype` will yield a deprecation warning, e.g.:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.image.per_image_standardization(tf.zeros((32, 32, 1)))\r\n# WARNING:tensorflow:From tensorflow_core/python/ops/image_ops_impl.py:1557: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n# Instructions for updating:\r\n# Deprecated in favor of operator or tf.math.divide.\r\n```\r\nor\r\n```python\r\nimport tensorflow as tf\r\ntf.image.convert_image_dtype(tf.zeros((32, 32, 1), dtype=tf.uint16), tf.uint8)\r\n# WARNING:tensorflow:From tensorflow_core/python/ops/image_ops_impl.py:1826: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n# Instructions for updating:\r\n# Deprecated in favor of operator or tf.math.divide.\r\n```\r\n\r\nThis PR addresses those two occurrences. In `per_image_standardization`, `div` is exchanged with `divide`, as within the function, it is ensured that the dtype is a floating point type; in `convert_image_dtype` on the other hand, the call comes in a branch ensuring the dtype is a integer type.\r\n\r\nIn general, there are quite some (`grep -R '\\.div(' | wc` => 40) usages of `div()`, which would all yield the deprecation warning, probably someone who is more familiar with the TensorFlow codebase should seek through them and replace them with the desired, current division call.", "comments": []}, {"number": 34806, "title": "build tensorflow/python.tools:optimize_for_inference failed", "body": "\\\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.26.0\r\n- GCC/Compiler version (if compiling from source):6.4.0\r\n- CUDA/cuDNN version:  cuda 10 cudnn 7 \r\n- GPU model and memory: p40\r\n\r\n\r\ni was trying to optimize tensorflow on cpu, that's why i followed a website to use tool: optimize_for_inference to decrease the size of my pb model.  I cloned tensorflow, get into the tensorflow directory,  used  \r\nbazel build tensorflow/python.tools:optimize_for_inference to build optimize_for_inference script\r\n.but i got some error like :\r\n![image](https://user-images.githubusercontent.com/51428350/70078703-0927f200-15b8-11ea-9917-18f9b2ddf6b6.png)\r\n\r\n![image](https://user-images.githubusercontent.com/51428350/70078751-20ff7600-15b8-11ea-94e6-a4a0dc874b32.png)\r\n\r\ni am not sure what these problems are, could anyone help me out? thanks so much\r\n\r\n", "comments": ["What OS Platform and Distribution are you using @652994331 ", "Hi\uff0cit\u2019s centos 7 linux&nbsp;\r\n\r\n\r\n\r\n\u53d1\u81ea\u6211\u7684iPhone\r\n\r\n\r\n------------------ Original ------------------\r\nFrom: gowthamkpr <notifications@github.com&gt;\r\nDate: Wed,Dec 4,2019 2:40 PM\r\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com&gt;\r\nCc: 652994331 <652994331@qq.com&gt;, Mention <mention@noreply.github.com&gt;\r\nSubject: Re: [tensorflow/tensorflow] build tensorflow/python.tools:optimize_for_inference failed (#34806)\r\n\r\n\r\n\r\n\r\nWhat OS Platform and Distribution are you using @652994331\r\n \r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or unsubscribe.", "@652994331 As mentioned [here](https://github.com/tensorflow/tensorflow/issues/29053#issuecomment-551907472), this is a purely bazel issue, where bazel has a problem autodetecting the toolchain on the system.\r\n\r\nI am closing this issue.You can reach out to bazel team, or try getting help through stackoverflow. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34806\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34806\">No</a>\n"]}, {"number": 34805, "title": "Please add Tested build configurations for Tensorflow 1.15 and Tensorflow 1.15-gpu", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: N/A\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing): Please add Tested build configurations for Tensorflow 1.15 and Tensorflow 1.15-gpu\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nI cannot find the test build configurations for Tensorflow 1.15. It is useful for someone who is trying to build Tensorflow 1.15. \r\n\r\n\r\n\r\n", "comments": ["Any update on this? Or what version of cudnn and CUDA are used in the pypi tensorflow 1.15 build?", "@gowthamkpr I am closing this as this was resolved already. Please check the update tested build configs [here](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34805\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34805\">No</a>\n"]}, {"number": 34804, "title": "Object detection evaluation done on only a subset of test images", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Google Colab**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **Default installation on Google Colab**\r\n- TensorFlow version (use command below): **v1.15.0-0-g590d6eef7e 1.15.0**\r\n- Python version: **Python 3.6.8**\r\n- Bazel version (if compiling from source): **N/A**\r\n- GCC/Compiler version (if compiling from source): **N/A**\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **Google Colab**\r\n\r\n**Describe the current behavior**\r\nEvaluation is done on precisely 496 images\r\nOn every evaluation i get this:\r\n    \r\n    I1129 04:00:20.238537 139729717991168 coco_evaluation.py:205] Performing evaluation on 496 images.\r\n\r\n**Describe the expected behavior**\r\nEvaluation is done on 1000 images\r\n\r\n**Code to reproduce the issue**\r\nTraining ssd_mobilenet_v2, using object_detection/model_main.py running the following:\r\n\r\n    !python3 object_detection/model_main.py --pipeline_config_path=pipeline.config --model_dir=ssd_mobilenet/ --num_train_steps=200000 --sample_1_of_n_eval_examples=1 --alsologtostderr\r\n\r\nInside pipeline.config:\r\n    \r\n    num_examples: 1000\r\n\r\nAlso inside test images directory there is precisely 1000 annotated images.\r\nI did not specify the number 496 anywhere and it seem to be changing according to how many images there actually is inside test directory.\r\n\r\n", "comments": ["@enorkus ,\r\nCan you share a standalone code/gist of code used to reproduce the error reported here?Thanks!", "Not really possible. You have to have 1000 labeled images inside test directory, any number of images inside train directory, set `num_examples` inside `pipeline.config` to 1000 and run the training via:\r\n`!python3 object_detection/model_main.py --pipeline_config_path=pipeline.config --model_dir=ssd_mobilenet/ --num_train_steps=200000 --sample_1_of_n_eval_examples=1 --alsologtostderr`", "Tried reproducing again after some time and cannot do it. Might have been a configuration problem after all.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34804\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34804\">No</a>\n"]}, {"number": 34803, "title": "Initial port of TF micro to synopsys ARC processors", "body": "This pull request contains the changes to the makefiles for the project generation for tensor flow micro to generate a make project for synopsys ARC processors. It also installs the hooks to download and compile the embarc_mli library either as sources or as pre-compiled binary.\r\nNext step will be the calling of embarc_mli functions from TF micro code.\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34803) for more info**.\n\n<!-- need_sender_cla -->", "@JaccovG please sign CLA", "@googlebot I signed it!", "Corporate CLA has been signed. probably still being processed.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34803) for more info**.\n\n<!-- ok -->"]}, {"number": 34802, "title": "Initial port of TF micro to synopsys ARC processors", "body": "This pull request contains the changes to the makefiles for the project generation for tensor flow micro to generate a make project for synopsys ARC processors. It also installs the hooks to download and compile the embarc_mli library either as sources or as pre-compiled binary.\r\nNext step will be the calling of embarc_mli functions from TF micro code.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34802) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 34801, "title": "Can not run tensorflow gpu 2.0 with cuda 10.0 on arm64 boards (jetson nano)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Linux Ubuntu 18.04.3 arm64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: Python 3.6.8\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: cuda=10.0.326-1/ cudnn=7.5.0.56-1+cuda10.0\r\n- GPU model and memory: nvidia jetson nano , 4GB of memory\r\n\r\n**Describe the current behavior**\r\nCan not run code on gpu as it stuck at libcublas then crashes\r\n```\r\n>>> tf.debugging.set_log_device_placement(True)\r\n>>> a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n2019-12-03 15:14:11.076714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.077411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: NVIDIA Tegra X1 major: 5 minor: 3 memoryClockRate(GHz): 0.9216\r\npciBusID: 0000:00:00.0\r\n2019-12-03 15:14:11.077849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-12-03 15:14:11.078090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-03 15:14:11.078270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-12-03 15:14:11.078453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-12-03 15:14:11.078617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-12-03 15:14:11.078793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-12-03 15:14:11.079122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-03 15:14:11.079542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.080004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.080247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-12-03 15:14:11.083934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.084130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: NVIDIA Tegra X1 major: 5 minor: 3 memoryClockRate(GHz): 0.9216\r\npciBusID: 0000:00:00.0\r\n2019-12-03 15:14:11.084244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-12-03 15:14:11.084317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-03 15:14:11.084378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-12-03 15:14:11.084443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-12-03 15:14:11.084501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-12-03 15:14:11.084567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-12-03 15:14:11.084623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-12-03 15:14:11.084836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.085143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.085284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-12-03 15:14:11.085383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-03 15:14:11.085441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-12-03 15:14:11.085484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-12-03 15:14:11.085724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.086047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:973] ARM64 does not support NUMA - returning NUMA node zero\r\n2019-12-03 15:14:11.086225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2270 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X1, pci bus id: 0000:00:00.0, compute capability: 5.3)\r\n>>> b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\n>>> c = tf.matmul(a, b)\r\n2019-12-03 15:14:16.993486: I tensorflow/core/common_runtime/eager/execute.cc:574] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2019-12-03 15:14:17.047313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-12-03 15:18:10.046885: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: unknown error\r\nAborted\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nIt should calculate the value of the tensor C.\r\n\r\n**Code to reproduce the issue**\r\nInstall tensorflow 2.0 on jetson nano\r\nI provide the python wheel here in my post here\r\nhttps://pythops.com/post/compile-deeplearning-libraries-for-jetson-nano\r\nthen run this\r\n```\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\nprint(c)\r\n```", "comments": ["Can you please verify that you can run some simple GEMMs through cuBLAS on the Jetson nano using the C++ cuBLAS API?\r\n\r\nAlso: I personally don't have much experience working with the Jetson nano so it would be nice to pull in someone from NVIDIA here. CC @nluehr ", "@pythops have you tried installing NVIDIA's TensorFlow package that is built specifically for the Jetson platforms? https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html \r\n\r\n@MattConley may have additional advice as well.", "How does the TF Jetson package differ from stock TF?  @nluehr ", "@nluehr I didn't cause I wanted TensorFlow 2.0 and it is not available from NVIDIA yet, that's why I complied it myself.", "The Jetson TF package is built from the same source branch as NVIDIA's NGC containers. The advantage relevant here is that it is built against the same libs available in specific Jetpack releases.\r\n\r\n@pythops a TF2 installer for Jetpack 4.2 is available in the 19.11 wheel which was posted today.\r\nhttps://developer.download.nvidia.com/compute/redist/jp/v42/tensorflow-gpu/", "@nluehr Thanks for the release.\r\nIs it possible that you updates the doc so you can explain the steps to build tf2 for those who want to compile it themselves ?", "@nluehr \r\nIs it possible to describe in more details how TF is compiled using NGC containers ? As I said before I followed the official doc from TensorFlow and at the end it didn't work as expected.\r\nI think it's very important for the community to able to compile TF without relying on the release cycles of Nvidia", "I have the same issue running the newest build iso with Jetpack 4.4, Going to try to downgrade tensorflow below 2.0 and see if this works", "For issues with TF on jetson, I recommend also posing in the [Jetson Nvidia Developer Forum](https://forums.developer.nvidia.com/c/agx-autonomous-machines/jetson-embedded-systems/70).", "I managed to get mine running by reducing the amount of GPU memory tensorflow is using. Just starting to run models on the Nano. It goes without saying that models that run well on RTX2080Tis wont work as well here.", "@pythops It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34801\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34801\">No</a>\n"]}, {"number": 34800, "title": "[ROCm] Add ROCm support for CSR Sparse Matrix Ops", "body": "This PR adds ROCm support for CSR Sparse Matrix Ops.\r\n\r\nThe PR has 6 commits which organize the changes as per functionality being changed. Please review the commits indidvidually.\r\n\r\nThe file `cuda_sparse.h` should ideally be renamed to `gpu_sparse.h` once this PR is taken. I have not made that change a part of this PR. I can add a commit to make that change, assuming the reviewers are okay with it...please let me know if that is needed.\r\n\r\n---------------------------\r\n\r\n/cc @whchung @chsigg ", "comments": ["@chsigg, please re-review.\r\n\r\nthanks as always :)", "@rthadur gentle ping", "@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned , rebased the PR to remove the merge-conflict. please merge. thanks", "@chsigg, please re-approve\r\n\r\n@gbaned,  gentle ping\r\n\r\nthanks", "bump.", "@gbaned, gentle ping", "@deven-amd here are some internal internal, can you please check once.\r\n\r\n`ERROR: /tmpfs/tensor_flow/tensorflow/core/kernels/BUILD:3479:1: no such target '@local_config_rocm//rocm:hipsparse': target 'hipsparse' not declared in package 'rocm' defined by /tmpfs/bazel_output/_bazel_kbuilder//external/local_config_rocm/rocm/BUILD and referenced by '//tensorflow/core/kernels:cuda_sparse'`", "@rthadur , can you post  the contents of then generated file `/tmpfs/bazel_output/_bazel_kbuilder//external/local_config_rocm/rocm/BUILD` ? That would help me understand the cause of the error better.\r\n\r\nthanks", "also please post the bazel build command that leads to this error", "@chsigg can you please assist ?"]}, {"number": 34799, "title": "tf custom model serialization issue", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Debian\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary using pip install tensorflow\r\n- TensorFlow version (use command below):  v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory:  NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nReconstructing custom model from json produces the following error\r\n\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1841, in reconstruct_from_config\r\n    for layer_data in config['layers']:\r\nKeyError: 'layers'\r\n\r\n**Describe the expected behavior**\r\n\r\nmodel should load without issues as this is a pretty trivial case\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python\r\nfrom tensorflow import keras\r\nimport numpy as np \r\n\r\nclass TM(keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        self.lm = self.add_weight(shape=[2,5], initializer=\"uniform\", name=\"wts\")\r\n        super().build(input_shape)\r\n\r\n    def call(self, x):\r\n        return x @ self.lm\r\n\r\n    def get_config(self):\r\n        return {}        \r\n\r\n# serialize arch to json and weights to h5\r\nx = np.random.rand(5,2)\r\nm = TM()\r\ny = m(x) #build\r\njson_config = m.to_json()\r\n\r\n# error on loading back\r\nm2 = keras.models.model_from_json(json_config, custom_objects= {\"TM\": TM})\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n  File \"training/test_model_class.py\", line 25, in <module>\r\n    m2 = keras.models.model_from_json(json_config, custom_objects= {\"TM\": TM})\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 96, in model_from_json\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 102, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 191, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 906, in from_config\r\n    config, custom_objects)\r\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1841, in reconstruct_from_config\r\n    for layer_data in config['layers']:\r\nKeyError: 'layers'", "comments": ["Note that \"build\" method is applied to a \"keras.layers.Layer\" subclass and not to a \"keras.Model\" subclass.\r\nYou have essentially written a custom layer code and not a custom model code.\r\nPlease refer : https://www.tensorflow.org/guide/keras/custom_layers_and_models", "Thanks, as I explored the documentation further, I realized that I can accomplish what I want with custom layers and still use the functional api to compose the custom layers into models. So I'd like to maybe request that the error message be improved when to_json() is invoked on a subclassed model suggesting that it is not supported. At least that way it will be easier to adapt and make use of custom layers instead\r\n\r\n> Note that \"build\" method is applied to a \"keras.layers.Layer\" subclass and not to a \"keras.Model\" subclass.\r\n> You have essentially written a custom layer code and not a custom model code.\r\n> Please refer : https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n\r\n"]}, {"number": 34798, "title": "added usage examples for tf.image", "body": "added usage examples for all the \"random\" operations under tf.image api doc", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34798) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34798) for more info**.\n\n<!-- ok -->", "Thanks for the PR @rpalakkal :tada: . Don't you think we should have a single commit for this PR? Having 3 commits where 2 commits are just about removing a few lines from the first commit doesn't make any sense. Can you convert this into a single commit? Feel free to ask if you face any problem :smile: .", "@rahul2240 Totally agree - just squashed the 3 commits into one(and learned about using git rebase!) Thanks\r\n\r\n", "@rpalakkal Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 34797, "title": "[ROCm] Fix for the broken ROCm CSB - 191203 - eigen", "body": "The following commit breaks the --config=rocm build\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/3bc9dd3b776c26fbd8d4eba7917fe873a5596e40\r\n\r\nThe above commit moves the eigen repo pointer to a commit that breaks the ROCm build. The fix for the ROCm errors has been merged into the Eigen repo ( https://bitbucket.org/eigen/eigen/commits/177c403a361be18ab9ce76594b0ece232f1c8da4 ). Until the eigen repo pointer in workspace.bzl is moved to a commit that includes the above fix, we need to apply the same fix via a patch file to make the ROCm build functional again.\r\n\r\n\r\n/cc @rmlarsen @whchung ", "comments": ["Closing this PR as it is no longer required. TF eigen pointer has moved past the commit which contains the fix being applied by this patch."]}]