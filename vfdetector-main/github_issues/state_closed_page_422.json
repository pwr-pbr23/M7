[{"number": 41235, "title": "Add ram test and remove unused header", "body": "@mihaimaruseac \r\nThis is the test for `ram_file_block_cache`. I keep almost everything so it should be fine. ( only `status` to `TF_Status` as usual)", "comments": []}, {"number": 41234, "title": "TF2 add a reduce or aggregation key to tf.scatter_nd", "body": "**System information**\r\n- TensorFlow version (you are using): `2.2.0`\r\n- Are you willing to contribute it (Yes/No): maybe\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tf.scatter_nd` currently sum the updates having the same indices.\r\n\r\nI would like to be able to provide a different tensor reduce or aggregation function.\r\nKeeping the current default to a sum :\r\n```python\r\nimport tensorflow as tf\r\n\r\nindices = tf.constant([[0], [0]], dtype=tf.int32)\r\nupdates = tf.constant([[0, 1], [1, 2]])\r\ntf.assert_equal(\r\n    tf.scatter_nd(indices, updates, (3, 2)), # default\r\n    tf.scatter_nd(indices, updates, (3, 2), reduce=lambda current, new: current + new),\r\n)\r\ntf.assert_equal(\r\n    tf.scatter_nd(indices, updates, (3, 2)), # default\r\n    tf.scatter_nd(indices, updates, (3, 2), agg=lambda batched_update: tf.reduce_sum(batched_update, axis=0)\r\n)\r\n```\r\n\r\n\r\n**Will this change the current api? How?**\r\nIt will add new key to `scatter_nd` and `scatter_nd_update`\r\n\r\n\r\n**Who will benefit with this feature?**\r\nPeople which will use `tf.scatter_nd`.\r\n\r\nI think it will be especially useful to implement some SotA detection algorithms.\r\nFor example, for yolo boxes `[N_boxes, (x, y, h, w, o, c1, c2, ..., cn)]` are scattered in a kind of sparse Tensor to mimic the network output `[batch_size, y_grid_index, x_grid_index, anchor_n, (x, y, h, w, o, c1, c2, ..., cn)]`.\r\nIn the current situation, if 2 objects / boxes are similar (same anchor) and positionned nearby, they will hit the same position on the output grid and be summed.\r\nThe sum does not make any sense in that case :\r\n- x, y, h, w are ~ summed. This signifies moving the boxe after positioning it : first or a mean will be better\r\n- o is summed. It should stay 1 : the value is a bolean indicating if there is one element or not. First or reduce_any will be better.\r\n- c1...cn are similar to o.\r\nThis happens for overlapping elements and may greatly improve the handling of this situation.\r\n\r\n**Any Other info.**\r\n\r\nReferenced here : https://github.com/tensorflow/tensorflow/issues/32235, without a need.\r\n`tf.scatter_nd_update` is probably impacted", "comments": ["@Wirg,\r\nSorry for the delayed response. Can you please let us know if [tf.tensor_scatter_nd_add](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_add) is what you are looking for? Thanks!\r\n ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41233, "title": "Keras 'Model' object has no attribute '_callable_losses'", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS inux release 7.6.1810\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: V9.1.85\r\n- GPU model and memory: Tesla K80 24C\r\n\r\nI have a class with a model and I want to add a custom loss with three arguments.  Upon building the model, the following error is raised:\r\n```\r\n<ipython-input-124-46b9e7f916ce> in _build(self)\r\n     50 \r\n     51         self.get_optimiser()\r\n---> 52         model = self.get_loss(inputs, x)\r\n     53 \r\n     54         return model\r\n\r\n<ipython-input-124-46b9e7f916ce> in get_loss(self, inputs, outputs)\r\n    151             model = Model(inputs=[inputs, y_true, is_weight], outputs=[outputs])\r\n    152 \r\n--> 153             model.add_loss(weighted_dice_loss(y_true, outputs, is_weight))\r\n    154             self._model.compile(optimizer = self._optimiser, loss = None, metrics = [dice_coef])\r\n    155 \r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in add_loss(self, losses, inputs)\r\n    899         eager_losses.append(_tag_unconditional(loss))\r\n    900 \r\n--> 901     self._callable_losses += callable_losses\r\n    902 \r\n    903     call_context = base_layer_utils.is_in_call_context()\r\n\r\nAttributeError: 'Model' object has no attribute '_callable_losses'\r\n```\r\nThe expected behaviour is, thus, that the model accepts this custom loss, since it has three arguments instead of two when calling unet._build() without getting thrown an error:\r\n```\r\nunet = UNet()\r\nunet._build()\r\n\r\n```\r\n\r\nThe minimum reproducible code is as follows:\r\n```\r\nclass UNet():\r\n\r\n    def __init__(self, **kwargs):\r\n        \r\n        self._input_shape = kwargs.get('input_shape', (12, 86, 98,1))\r\n        self._blocks = kwargs.get('blocks', 2)\r\n        self._layers = kwargs.get('layers', 8)\r\n        self._n_filters = kwargs.get('n_filters', 16)\r\n        self._patch = kwargs.get('patch', (3,3,3))\r\n        self._activation = kwargs.get('activation', 'elu')\r\n        self._activation_last = kwargs.get('activation_last', 'sigmoid')\r\n        self._kernel_initializer = kwargs.get('kernel_initializer', 'glorot_normal')\r\n        self._padding = kwargs.get('padding', 'same')\r\n        self._learnrate = kwargs.get('learnrate',0.001)\r\n        self._momentum = kwargs.get('momentum',0.99)\r\n        self._decay = kwargs.get('decay',0.0)\r\n        self._mode = kwargs.get('mode','train')\r\n           \r\n    def _build(self):\r\n        \r\n        # Initialise array to keep skip connections\r\n        self.skips = []\r\n        \r\n        inputs = Input(shape = self._input_shape)\r\n        \r\n        x = self.first_layers(inputs)\r\n        x = self.contractive_path(x)\r\n        x = self.middle_path(x)\r\n        x = self.expansive_path(x)\r\n        \r\n        self.get_optimiser()\r\n        model = self.get_loss(inputs, x)\r\n            \r\n        return model\r\n    \r\n    def first_layers(self, inputs):\r\n       \r\n        layer = Conv3D(filters = self._n_filters, kernel_size = self._patch, activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n                padding = self._padding)(inputs)\r\n        \r\n        return layer\r\n    \r\n    def contractive_path(self, layer):\r\n\r\n        for b in range(0,self._blocks):\r\n            for i in range(0,self._layers):\r\n                layer = Conv3D(filters = self._n_filters, kernel_size = self._patch, activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n                padding = self._padding)(layer)\r\n            \r\n            #append for later use in up-sampling\r\n            self.skips.append(layer)\r\n            \r\n            #downsampling (using patch(2,2,2) and stride of 2, similar to MaxPooling3D but uses less parameters)\r\n            layer = Conv3D(filters = self._n_filters, kernel_size = (2,2,2), strides = (2, 2, 2), activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n                padding = self._padding)(layer)\r\n\r\n            #post-pooling, double number of filters\r\n            self._n_filters = int(self._n_filters*2)\r\n     \r\n        return layer \r\n        \r\n    def middle_path(self, layer):\r\n   \r\n        for i in range(0,self._layers):\r\n            layer = Conv3D(filters = self._n_filters, kernel_size = self._patch, activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n                padding = self._padding)(layer)\r\n        \r\n        return layer\r\n\r\n    def expansive_path(self, layer):\r\n\r\n        for u in range(0,self._blocks):\r\n            layer = UpSampling3D(size = (2,2,2), data_format = None)(layer) \r\n            \r\n            # skip connection from DOWN_PATH\r\n            concat_lr = self.skips[-1]\r\n\r\n            layer, concat_lr = cropping_tensor(layer, concat_lr)\r\n            layer = Concatenate()([layer, concat_lr])\r\n            \r\n            for i in range(0,(self._layers)):\r\n                layer = Conv3D(filters = self._n_filters, kernel_size = self._patch, activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n                padding = self._padding)(layer)\r\n                \r\n            self._n_filters = int(self._n_filters/2)\r\n            #print('UpBlock',str(u),' : end_n_filters ', str(n_filters))\r\n            \r\n            self.skips = self.skips[:-1] # get rid of last skip connection \r\n            \r\n        ### output layer \r\n        y_pred = Conv3D(1, (1,1,1), activation = self._activation_last)(layer)    \r\n        \r\n        return y_pred\r\n    \r\n    def get_optimiser(self):\r\n            self._optimiser = SGD(lr = self._learnrate, momentum = self._momentum, decay = self._decay, nesterov = False)\r\n    \r\n    def get_loss(self, inputs, outputs):\r\n            \r\n            y_true = Input(self._input_shape, name = 'y_true')\r\n            is_weight = Input(self._input_shape, name = 'is_weight')\r\n\r\n            model = Model(inputs=[inputs, y_true, is_weight], outputs=[outputs])\r\n            \r\n            model.add_loss(weighted_dice_loss(y_true, outputs, is_weight))\r\n            self._model.compile(optimizer = self._optimiser, loss = None, metrics = [dice_coef])\r\n        \r\n        return self._model\r\n```\r\nThe weighted_dice_loss function is defined as follows:\r\n```\r\ndef weighted_dice_loss(y_true, y_pred, w):\r\n    \r\n    return -weighted_dice_coef(y_true, y_pred, w)\r\n```", "comments": ["Of note, I was importing tensorflow as follows:\r\n```\r\nimport tensorflow.v1.compat as tf\r\n```\r\nUpon updating tensorflow (v2.2.0) and doing the following imports,\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import Input, optimizers\r\nfrom tensorflow.keras.models import Sequential, load_model\r\n\r\n\r\nfrom keras.layers.convolutional import Conv3D, Conv3DTranspose\r\nfrom keras.layers.normalization import BatchNormalization\r\nfrom keras.layers import Cropping3D, UpSampling3D, AveragePooling3D\r\n```\r\nI run the code again I get thrown this:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-c4c292a59224> in <module>\r\n     11 \r\n     12 \r\n---> 13 unet_model = unet._build()\r\n\r\n<ipython-input-2-9245d04f54db> in _build(self)\r\n     44         inputs = Input(shape = self._input_shape)\r\n     45 \r\n---> 46         x = self.first_layers(inputs)\r\n     47         x = self.contractive_path(x)\r\n     48         x = self.middle_path(x)\r\n\r\n<ipython-input-2-9245d04f54db> in first_layers(self, inputs)\r\n     57 \r\n     58         layer = Conv3D(filters = self._n_filters, kernel_size = self._patch, activation = self._activation, kernel_initializer = self._kernel_initializer,\r\n---> 59                 padding = self._padding)(inputs)\r\n     60 \r\n     61         return layer\r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)\r\n     89                 warnings.warn('Update your `' + object_name + '` call to the ' +\r\n     90                               'Keras 2 API: ' + signature, stacklevel=2)\r\n---> 91             return func(*args, **kwargs)\r\n     92         wrapper._original_function = func\r\n     93         return wrapper\r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/keras/layers/convolutional.py in __init__(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\r\n    617             kernel_constraint=kernel_constraint,\r\n    618             bias_constraint=bias_constraint,\r\n--> 619             **kwargs)\r\n    620 \r\n    621     def get_config(self):\r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/keras/layers/convolutional.py in __init__(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\r\n    103                  bias_constraint=None,\r\n    104                  **kwargs):\r\n--> 105         super(_Conv, self).__init__(**kwargs)\r\n    106         self.rank = rank\r\n    107         self.filters = filters\r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/keras/engine/base_layer.py in __init__(self, **kwargs)\r\n    130         if not name:\r\n    131             prefix = self.__class__.__name__\r\n--> 132             name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\r\n    133         self.name = name\r\n    134 \r\n\r\n~/miniconda3/envs/segment/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in get_uid(prefix)\r\n     72     \"\"\"\r\n     73     global _GRAPH_UID_DICTS\r\n---> 74     graph = tf.get_default_graph()\r\n     75     if graph not in _GRAPH_UID_DICTS:\r\n     76         _GRAPH_UID_DICTS[graph] = defaultdict(int)\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'get_default_graph'\r\n```", "Hi, instead of using :\r\n```\r\nfrom keras.layers.convolutional import Conv3D, Conv3DTranspose\r\nfrom keras.layers.normalization import BatchNormalization\r\nfrom keras.layers import Cropping3D, UpSampling3D, AveragePooling3D\r\n```\r\nuse : \r\n```\r\nfrom tensorflow.keras.layers.convolutional import Conv3D, Conv3DTranspose\r\nfrom tensorflow.keras.layers.normalization import BatchNormalization\r\nfrom tensorflow.keras.layers import Cropping3D, UpSampling3D, AveragePooling3D\r\n```\r\n while working with tf2.0 or higher", "@mash2612 \r\nPlease refer to [this comment](https://github.com/keras-team/keras/issues/12379#issuecomment-486207178) with same error to resolve the issue.\r\n[link](https://github.com/keras-team/keras/issues/12783#issuecomment-499870218) [link1](https://stackoverflow.com/questions/55496289/how-to-fix-attributeerror-module-tensorflow-has-no-attribute-get-default-gr).\r\nand us know if it helps.", "@Saduf2019 this issue was raised by @danielfllaneza . I was just suggesting a way to solve this and I think the links also indicate a solution in the same direction.\r\n@danielfllaneza let us know if the solution helped you.", "@ danielfllaneza \r\nPlease update as per above comment.", "Thanks for the suggestions, It only worked when importing it like this:\r\n ```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras import Input\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import (AveragePooling3D,\r\n                                    BatchNormalization,\r\n                                    Concatenate, \r\n                                    Conv3D, \r\n                                    Conv3DTranspose,\r\n                                    Cropping3D,\r\n                                    UpSampling3D)\r\n```\r\n", "@danielfllaneza \r\nPlease confirm if the issue is resolved can we move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41233\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41233\">No</a>\n"]}, {"number": 41232, "title": "Patches to support linking of Tensorflow with oneDNN 1.4 on Aarch64.", "body": "Addresses upstream Tensorflow issue: https://github.com/tensorflow/tensorflow/issues/40771\r\nAdded new oneDNN1.x ifdefs (DENABLE_MKLDNN_V1) to bypass linking to MKL-ML header files.\r\n\r\nSigned-off-by: cfRod <crefeda.rodrigues@arm.com>", "comments": ["Hi @cfRod  thanks for the PR.  We are running into the same compilation issue when enabling oneDNN to use Eigen threads. I am working on a fix for it. The changes will also fix your issues. I hope to have this PR submitted this week. It might be better for you to wait for the PR and then test the ARM compilation.", "Hi @agramesh1,\r\n\r\n> I hope to have this PR submitted this week. It might be better for you to wait for the PR and then test the ARM compilation.\r\n\r\nI'd be inclined to agree.\r\n\r\nOut of curiosity, do you think your planned changes will have any chance of making it into a 2.3 RC, and the 2.3 release?", "@cfRod Thank you for the PR! And thank you @agramesh1 for reviewing!\r\n\r\n@nSircombe 2.3.0-rc1 is out and I don't know whether we will have an rc2 or not. I will update here when I know.", "@nSircombe There will be an rc2 soon. But the cherry-pick criteria is very strict. Since the fix from Intel side isn't ready either, I don't think this will be in release 2.3.0.", "Hi @penpornk, that's fair enough, thanks for letting me know. ", "@penpornk  @nSircombe sorry for the delay. We have the code changes to build Tensorflow without the binary blob,  we will be submitting a PR within the next few days.  The blob also contains the Intel openMP, so you will need to add another openMP  (libgomp?) to your build. ", "> @penpornk @nSircombe sorry for the delay. We have the code changes to build Tensorflow without the binary blob, we will be submitting a PR within the next few days. The blob also contains the Intel openMP, so you will need to add another openMP (libgomp?) to your build.\r\n\r\n@agramesh1 Thanks for the update and the upcoming PR. Yes, we have -fopenmp flag to our bazel build command.", "@agramesh1 Thank you for the update! Looking forward to the PR. :)", "@cfRod here is the PR https://github.com/tensorflow/tensorflow/pull/41645 --config=mkl_opensource_only will build with oneDNN 1.4 and without the binary blob. ", "> @cfRod here is the PR #41645 --config=mkl_opensource_only will build with oneDNN 1.4 and without the binary blob.\r\n\r\nHi @agramesh1 , Thanks for the patch, I am going through it. I wanted to also highlight that  the following file in tensorflow repo will have to be updated: third_party/mkl_dnn/mkl_dnn_v1.BUILD \r\n\r\nat line:\r\nhttps://github.com/Intel-tensorflow/tensorflow/blob/6d9afb6bf1710fea0122036fa7fd9704adadac03/third_party/mkl_dnn/mkldnn_v1.BUILD#L70\r\n\r\n```\r\ncc_library(\r\n    name = \"mkl_dnn\",\r\n    srcs = glob([\r\n        \"src/common/*.cpp\",\r\n        \"src/common/*.hpp\",\r\n        \"src/cpu/*.cpp\",\r\n        \"src/cpu/*.hpp\",\r\n        \"src/cpu/**/*.cpp\",\r\n        \"src/cpu/**/*.hpp\",\r\n        \"src/cpu/xbyak/*.h\",\r\n        \"src/cpu/jit_utils/jitprofiling/*.c\",\r\n        \"src/cpu/jit_utils/jitprofiling/*.h\",\r\n```\r\n\r\nThese folders (`src/cpu/jit_utils`,` src/cpu/xbyak` have been re-organized into a x64/ dir) and `src/cpu/**/ ` will again include x64 specific sources during the build step. Possibly we could update it with this PR? \r\n\r\n", "> > @cfRod here is the PR #41645 --config=mkl_opensource_only will build with oneDNN 1.4 and without the binary blob.\r\n> \r\n> Hi @agramesh1 , Thanks for the patch, I am going through it. I wanted to also highlight that the following file in tensorflow repo will have to be updated: third_party/mkl_dnn/mkl_dnn_v1.BUILD\r\n> \r\n> at line:\r\n> https://github.com/Intel-tensorflow/tensorflow/blob/6d9afb6bf1710fea0122036fa7fd9704adadac03/third_party/mkl_dnn/mkldnn_v1.BUILD#L70\r\n> \r\n> ```\r\n> cc_library(\r\n>     name = \"mkl_dnn\",\r\n>     srcs = glob([\r\n>         \"src/common/*.cpp\",\r\n>         \"src/common/*.hpp\",\r\n>         \"src/cpu/*.cpp\",\r\n>         \"src/cpu/*.hpp\",\r\n>         \"src/cpu/**/*.cpp\",\r\n>         \"src/cpu/**/*.hpp\",\r\n>         \"src/cpu/xbyak/*.h\",\r\n>         \"src/cpu/jit_utils/jitprofiling/*.c\",\r\n>         \"src/cpu/jit_utils/jitprofiling/*.h\",\r\n> ```\r\n> \r\n> These folders (`src/cpu/jit_utils`,` src/cpu/xbyak` have been re-organized into a x64/ dir) and `src/cpu/**/ ` will again include x64 specific sources during the build step. Possibly we could update it with this PR?\r\n\r\n@agramesh1 Thanks for the PR. I have tested it and it has built successfully. I will submit a separate PR for the other issue. ", "> @agramesh1 Thanks for the PR. I have tested it and it has built successfully. I will submit a separate PR for the other issue.\r\n\r\n@cfRod thanks. Let me know when you submit the PR to update third_party/mkl_dnn/mkl_dnn_v1.BUILD. \r\n\r\n", "@cfRod Thank you for testing #41645!", "@cfRod, @agramesh1, @penpornk  Any update on this PR? Please. Thank you!", "https://github.com/tensorflow/tensorflow/pull/41645 (which replaces this PR) has been merged.\r\n\r\n@cfRod Should we close this PR? You can open another one when your other PR is ready.", "> #41645 (which replaces this PR) has been merged.\r\n> \r\n> @cfRod Should we close this PR? You can open another one when your other PR is ready.\r\n\r\nHi @penpornk, Yes we can close this since the other one is merged. I will send the other PR when it is ready.\r\nThanks again.\r\n", "@cfRod Thank you for your contributions! :)"]}, {"number": 41231, "title": "missing comma in script", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tfx/guide/build_tfx_pipeline#build_a_custom_pipeline\r\n\r\n## Description of issue (what needs changing):\r\n\r\nA comma needs to be added to the script used in step 3 at the end of line: data_path=DATA_PATH\r\n\r\n### Submit a pull request?\r\nYES\r\n\r\nhttps://github.com/seyedrezamirkhani/tfx/pull/1\r\n\r\n", "comments": ["@seyedrezamirkhani \r\n\r\nThis issue is more suitable for TensorFlow TFX repo. Please post it on TFX repo from [here.](https://github.com/tensorflow/tfx/issues) Thanks!", "@ravikyram \r\n\r\nThanks for your guidance, I've created the issue with the TFX repo and will close this issue.", "Moved issue to https://github.com/tensorflow/tfx/issues/2121\r\n"]}, {"number": 41230, "title": "Error transforming entity <function Model.make_predict_function.<locals>.predict_function at 0x0000018A825705E8>", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but reproducible on example\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):                           Win 10\r\n- TensorFlow installed from (source or binary):                                             pip install\r\n- TensorFlow version (use command below):                                                v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version:                                                                                         3.7.7\r\n- Bazel version (if compiling from source):                                                    N/A\r\n- GCC/Compiler version (if compiling from source):                                      N/A\r\n- CUDA/cuDNN version:                                                                              V10.0.130 / v7.6.5.32\r\n- GPU model and memory:                                                                         GTX1050Ti, 4Gb\r\n\r\n**Describe the current behavior**\r\nDuring training and prediction I get an \"Error transforming entity\". The error is not fatal. Training completes and prediction accuracy on a validation set is comparable to prediction in TF2.1. Reporting this because tensorflow requests it in trace.\r\n\r\n**Describe the expected behavior**\r\nDuring training and prediction I get no \"Error transforming entity\". I get no errors in TF1.15 nor TF2.1.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe cats and dogs code example at https://www.tensorflow.org/tutorials/images/classification produces the message as well, I just changed epochs to 1\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nimport os\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nos.environ['AUTOGRAPH_VERBOSITY'] = '10'\r\n\r\ndef plotImages(images_arr):\r\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\r\n    axes = axes.flatten()\r\n    for img, ax in zip( images_arr, axes):\r\n        ax.imshow(img)\r\n        ax.axis('off')\r\n    plt.tight_layout()\r\n    plt.show()\r\n\r\n\r\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\r\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\r\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\r\n\r\ntrain_dir = os.path.join(PATH, 'train')\r\nvalidation_dir = os.path.join(PATH, 'validation')\r\ntrain_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\r\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\r\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\r\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\r\nnum_cats_tr = len(os.listdir(train_cats_dir))\r\nnum_dogs_tr = len(os.listdir(train_dogs_dir))\r\n\r\nnum_cats_val = len(os.listdir(validation_cats_dir))\r\nnum_dogs_val = len(os.listdir(validation_dogs_dir))\r\n\r\ntotal_train = num_cats_tr + num_dogs_tr\r\ntotal_val = num_cats_val + num_dogs_val\r\nprint('total training cat images:', num_cats_tr)\r\nprint('total training dog images:', num_dogs_tr)\r\n\r\nprint('total validation cat images:', num_cats_val)\r\nprint('total validation dog images:', num_dogs_val)\r\nprint(\"--\")\r\nprint(\"Total training images:\", total_train)\r\nprint(\"Total validation images:\", total_val)\r\nbatch_size = 128\r\nepochs = 15\r\nIMG_HEIGHT = 150\r\nIMG_WIDTH = 150\r\ntrain_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\r\nvalidation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\r\n\r\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                           directory=train_dir,\r\n                                                           shuffle=True,\r\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                           class_mode='binary')\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                              directory=validation_dir,\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='binary')\r\n\r\nsample_training_images, _ = next(train_data_gen)\r\n\r\nmodel = Sequential([\r\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\r\n    MaxPooling2D(),\r\n    Conv2D(32, 3, padding='same', activation='relu'),\r\n    MaxPooling2D(),\r\n    Conv2D(64, 3, padding='same', activation='relu'),\r\n    MaxPooling2D(),\r\n    Flatten(),\r\n    Dense(512, activation='relu'),\r\n    Dense(1)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\nmodel.summary()\r\n\r\nhistory = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)\r\n\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\n\r\nloss=history.history['loss']\r\nval_loss=history.history['val_loss']\r\n\r\nepochs_range = range(epochs)\r\n\r\nplt.figure(figsize=(8, 8))\r\nplt.subplot(1, 2, 1)\r\nplt.plot(epochs_range, acc, label='Training Accuracy')\r\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\nplt.legend(loc='lower right')\r\nplt.title('Training and Validation Accuracy')\r\n\r\nplt.subplot(1, 2, 2)\r\nplt.plot(epochs_range, loss, label='Training Loss')\r\nplt.plot(epochs_range, val_loss, label='Validation Loss')\r\nplt.legend(loc='upper right')\r\nplt.title('Training and Validation Loss')\r\nplt.show()\r\n\r\n\r\n\r\n**Other info / logs, error in bold** \r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B005E8>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B005E8>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B005E8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B005E8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B00438>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B00438>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B00438>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B00438>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B004C8>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B004C8>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B004C8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B004C8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B00558>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B00558>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B00558>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B00558>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x00000203638FB208>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x00000203638FB208>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Cache hit for entity <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x00000203638FBCC8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__train_function in tmproefnuih)\r\nCache hit for entity <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x00000203638FBCC8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__train_function in tmproefnuih)\r\nINFO:tensorflow:Error transforming entity <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\n**AssertionError\r\nError transforming entity <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert**\r\nINFO:tensorflow:Converted call: <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nConverted call: <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nWhitelisted <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B0F9D8>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B0F9D8>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B0F9D8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B0F9D8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}})\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'name': None}\r\n\r\nConverted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}})\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'name': None}\r\n\r\nINFO:tensorflow:Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}) with\r\n(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nForwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}) with\r\n(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nINFO:tensorflow:Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nConverted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nINFO:tensorflow:Whitelisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>: from cache\r\nWhitelisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>\r\n    args: (<tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B103A8>: from cache\r\nINFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000002038C6E5F08>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000002038C6E5F08>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>: from cache\r\nWhitelisted <function Model.make_train_function.<locals>.train_function at 0x0000020244B00798>: from cache\r\nINFO:tensorflow:Converted call: <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nConverted call: <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nWhitelisted <bound method Model.train_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B10CA8>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B10CA8>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B10CA8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function OptimizerV2._aggregate_gradients.<locals>.all_reduce_fn at 0x0000020244B10CA8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}})\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'name': None}\r\n\r\nConverted call: functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}})\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'name': None}\r\n\r\nINFO:tensorflow:Forwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}) with\r\n(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nForwarding call of partial functools.partial(<bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>, apply_state={('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}) with\r\n(<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n{'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nINFO:tensorflow:Converted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nConverted call: <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>\r\n    args: (<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x000002025A2D4388>, ((<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>, <tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>, <tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>, <tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>, <tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>, <tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>)))\r\n    kwargs: {'apply_state': {('/job:localhost/replica:0/task:0/device:GPU:0', tf.float32): {'lr_t': <tf.Tensor 'Adam/Identity:0' shape=() dtype=float32>, 'lr': <tf.Tensor 'Adam/mul:0' shape=() dtype=float32>, 'epsilon': <tf.Tensor 'Adam/Const:0' shape=() dtype=float32>, 'beta_1_t': <tf.Tensor 'Adam/Identity_1:0' shape=() dtype=float32>, 'beta_1_power': <tf.Tensor 'Adam/Pow:0' shape=() dtype=float32>, 'one_minus_beta_1_t': <tf.Tensor 'Adam/sub_2:0' shape=() dtype=float32>, 'beta_2_t': <tf.Tensor 'Adam/Identity_2:0' shape=() dtype=float32>, 'beta_2_power': <tf.Tensor 'Adam/Pow_1:0' shape=() dtype=float32>, 'one_minus_beta_2_t': <tf.Tensor 'Adam/sub_3:0' shape=() dtype=float32>}}, 'name': None}\r\n\r\nINFO:tensorflow:Whitelisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>: from cache\r\nWhitelisted <bound method OptimizerV2._distributed_apply of <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000020394F55B08>>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_24/kernel:0' shape=(3, 3, 3, 16) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/Conv2DBackpropFilter:0' shape=(3, 3, 3, 16) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_24/bias:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_24/BiasAdd/BiasAddGrad:0' shape=(16,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_25/kernel:0' shape=(3, 3, 16, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/Conv2DBackpropFilter:0' shape=(3, 3, 16, 32) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_25/bias:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_25/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_26/kernel:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'conv2d_26/bias:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/conv2d_26/BiasAdd/BiasAddGrad:0' shape=(64,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_16/kernel:0' shape=(20736, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/MatMul_1:0' shape=(20736, 512) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_16/bias:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_16/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_17/kernel:0' shape=(512, 1) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/MatMul_1:0' shape=(512, 1) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nINFO:tensorflow:Converted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nConverted call: <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>\r\n    args: (<tf.Variable 'dense_17/bias:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential_8/dense_17/BiasAdd/BiasAddGrad:0' shape=(1,) dtype=float32>)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\nWhitelisted <function OptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var at 0x0000020244B10CA8>: from cache\r\n15/15 [==============================] - ETA: 0s - loss: 0.9207 - accuracy: 0.5139INFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B10288>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B10288>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B10288>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.flat_map_fn at 0x0000020244B10288>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B10F78>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B10F78>\r\n    args: (<tf.Tensor 'args_0:0' shape=() dtype=int32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B10F78>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.get_iterator_id_fn at 0x0000020244B10F78>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B10558>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B10558>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B10558>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.generator_next_fn at 0x0000020244B10558>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B10D38>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B10D38>\r\n    args: (<tf.Tensor 'args_0:0' shape=<unknown> dtype=int64>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B10D38>: DoNotConvert rule for tensorflow\r\nWhitelisted: <function DatasetV2.from_generator.<locals>.finalize_fn at 0x0000020244B10D38>: DoNotConvert rule for tensorflow\r\nINFO:tensorflow:Converted call: <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x0000020244E66388>,)\r\n    kwargs: {}\r\n\r\nConverted call: <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8>\r\n    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x0000020244E66388>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Cache hit for entity <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x0000020244E667C8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__test_function in tmpqvpbtv4e)\r\nCache hit for entity <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x0000020244E667C8>, frozenset({'self'})): _ConvertedEntityFactoryInfo(tf__test_function in tmpqvpbtv4e)\r\nINFO:tensorflow:Error transforming entity <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\nError transforming entity <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8>\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000020244B10CA8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nINFO:tensorflow:Converted call: <bound method Model.test_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nConverted call: <bound method Model.test_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>\r\n    args: ((<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>),)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Whitelisted <bound method Model.test_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nWhitelisted <bound method Model.test_step of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000202440228C8>>: from cache\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 538, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 362, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 300, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\coumansFAW\\Miniconda3\\envs\\TF220\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\conversion.py\", line 94, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\n15/15 [==============================] - 16s 1s/step - loss: 0.9207 - accuracy: 0.5139 - val_loss: 0.6922 - val_accuracy: 0.5000", "comments": ["@frankcoumans,\r\nAll the messages are being logged as you have set the value of `AUTOGRAPH_VERBOSITY` to 10.\r\n\r\nTo disable these logs change the value of `os.environ['AUTOGRAPH_VERBOSITY']` to 0. Please check [this gist](https://colab.research.google.com/gist/amahendrakar/0535d5c7a9b7ae5d0e395ab2072cf27c/41230.ipynb) for reference. Thanks!", "@amahendrakar\r\nSetting the verbosity to 0 doesn't supress the error message. I hadn't touched the verbosity until I read the request in the error trace to report the bug to the tensorflow team and set the verbosity to 10. I'm just reporting the bug as requested by the error message. I'm not sure why you changed the type label to support.", "@frankcoumans,\r\nPlease set the `AUTOGRAPH_VERBOSITY` environment variable to 0 at the beginning of the program. A value of 0 means no logging, whereas the value 10 logs everything and is used while debugging errors.\r\n\r\nAlso, ignore these warnings. This issue has already been addressed here [#37144](https://github.com/tensorflow/tensorflow/issues/37144#issuecomment-600350256). \r\n\r\nPlease check these gist for a comparison between the outputs when verbosity is [set to 10](https://colab.research.google.com/gist/amahendrakar/dbab8e0ef2137610311320154a438e25/41230-verb10.ipynb#scrollTo=KSF2HqhDVrWk&line=5&uniqifier=1) vs when verbosity is [set to 0](https://colab.research.google.com/gist/amahendrakar/38327eafa1e5589619b05994fdc49317/41230-verb0.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41229, "title": "ImportError: impossible d'importer le nom 'export_saved_model' de 'tensorflow.python.keras.saving.saved_model' (F: \\ New folder \\ New folder \\ lib \\ site-packages \\ tensorflow \\ python \\ keras \\ Saving \\ Saved_model \\ __ init__.py) ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@ouzzane \r\nPlease share simple stand alone code with all dependencies and indentation such that we can replicate the issue faced, along with tf version.\r\nPlease follow [this link](https://stackoverflow.com/questions/61833301/error-on-tensorflow-cannot-import-name-export-saved-model) as per error shared.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41228, "title": "Quantization instruction problem after training", "body": "I have a problem with the instruction [integer quantization after training] in the official website.\r\nthis code:\r\n\r\nmnist_train, _ = tf.keras.datasets.mnist.load_data()\r\nimages = tf.cast(mnist_train[0], tf.float32) / 255.0\r\nmnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\r\ndef representative_data_gen():\r\n  for input_value in mnist_ds.take(100):\r\n    # Model has only one input so each data point has one element.\r\n    yield [input_value]\r\nconverter.representative_dataset = representative_data_gen\r\n\r\nMy question is the fifth itinerary [for input_value in mnist_ds.take(100): ], if I use my own data set, do I need to change this part of mnist_ds.take? There is also a question 100 what does it mean? \r\n", "comments": ["@LINYOUWEI0804 Yes, if you use your own data, then you need to update that part of the code. We need representative dataset to accurately estimate dynamic range of activations. Please check [this page](https://www.tensorflow.org/lite/performance/post_training_integer_quant).\r\n\r\n> Now, in order to create quantized values with an accurate dynamic range of activations, you need to provide a representative dataset. To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices.\r\n\r\n`100` in the code is to take 100 sets of training data and estimate statistics of the data to decide dynamic range of activations. \r\n\r\n\r\nPlease close the issue if this was resolved for you. Please post any support related questions in Stackoverflow so that there is a big community to get help. Thanks!\r\n", "Thanks @jvishnuvardhan . \r\nIt seems to me this is a usage question but not an issue, and it was fully answered. I'm closing this ticket. "]}, {"number": 41227, "title": "Can anyone give a C_api example with multiple inputs and multiple outputs, like object detection?", "body": "Hello,\r\n        Can anyone give a C_api example with multiple inputs and multiple outputs , like object detection,with one input and three outputs( detection boxes, detection classes and detection scores)?\r\n        With one input and one output, I can run without error. But for mutilple outputs, I do not know how to set \r\n[const TF_Output* outputs, TF_Tensor** output_values] the two parameter in TF_SessionRun(***) function.\r\n![image](https://user-images.githubusercontent.com/28335784/87021919-5c29ed80-c208-11ea-8756-6fd5f39f9163.png)\r\n\r\n\r\nThank you !", "comments": ["@xiaowenhe,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 41226, "title": "Error when running inference on CPU using C++ bindings: Not found: Container localhost does not exist", "body": "**System information**\r\n- Have I written custom code: **yes**\r\n- OS/Distro: **Arch Linux**\r\n- TensorFlow installed from: **virtualenv with pip, C/C++ bindings from source without CUDA support**\r\n- TensorFlow version virtualenv: **v1.12.1-34938-g99fea8da0d 2.3.0-rc0**\r\n- TensorFlow version C/C++ bindings: **v1.12.1-35361-ge89160d8d3 2.5.0-dev20200629**\r\n- Python version: **3.7**\r\n- Bazel version: **3.1.0- (@non-git)**\r\n- GCC/Compiler version: **10.1.0**\r\n- CUDA/cuDNN version: 10.2z (Error happens on CPU)\r\n- GPU model and memory: Nvidia RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nPredicting works fine in Python, however when I try to run inference on CPU by using the C++ bindings I get the following error:\r\n```\r\nFailed precondition: Error while reading resource variable dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/dense/kernel)\r\n\t [[{{node dense/Tensordot/ReadVariableOp}}]]\r\n```\r\n**Describe the expected behavior**\r\nBeing able to predict in C++ without issues.\r\n\r\n**Standalone code to reproduce the issue**\r\nCode is on pastebin.com to increase readability. Links:\r\n[Training the model in Python](https://pastebin.com/iFccjjnx)\r\n[C++ Header](https://pastebin.com/6mkwK5bX)\r\n[C++ Code](https://pastebin.com/eUrPt0YT)\r\n[cli_saved_model --dir ... --all output](https://pastebin.com/QGgX1UXr)\r\n\r\n**Other info / logs**\r\nA similar issue was already [posted on Stackoverflow](https://stackoverflow.com/questions/60059177/failed-precondition-errors-when-using-keras-model-in-c), however with no answers.\r\nIssue is persistent in TF2.2.", "comments": ["Might not be the same cause as for you, but I just had a very similar issue with a self-built TF2.2. In my case it was caused by trying to load a saved model from a folder where I only put a saved_model.pb, but not the `variables` subfolder. When I copied the `variables` there as well, it started working again.", "@TylerTheHumanCompiler \r\nPlease update as per above comment, there is a similar issue please refer and let us know if it helps.\r\n#28287 \r\n\r\nAlso i see you are using a very old version of tf, can you please upgrade to newer version and confirm if it helps resolve your issue.", "@Saduf2019 The variables folder exists and is populated. Can I provide you with additional information?\r\n\r\nAs for the tf update: I've compiled from source and now have:\r\n**v1.12.1-35409-ge085901e2c 2.4.0**\r\n\r\nand:\r\nlibtensorflow_cc.so.2.4.0", "@TylerTheHumanCompiler \r\nIs there any particular reason for using tf 1.12 when there are later versions available.\r\n\r\n Please upgrade the tf version and see if you still face the issue as this is a very old version that does not have support [please use 1.15 or 2.x versions].\r\nPlease refer to [this link](https://github.com/tensorflow/tensorflow/issues/40439#issuecomment-644274878).", "@Saduf2019 No, there isn't, because I'm not using tf 1.12, nor was I when I opened this issue. I don't know why `tf.version.GIT_VERSION` outputs this, but there are reports of it outputting a wrong version [here](https://github.com/tensorflow/tensorflow/issues/28628). Note that the hash above `ge085901e2c` does not match any commit, whereas `git rev-list -n 1 v1.12.1-35409-ge085901e2c` (as suggested in the linked issue) returns the hash of [this](https://github.com/tensorflow/tensorflow/commit/e085901e2cb41d8a5a4cb7283e1b6d719d0dc4b8) commit, which is 15 days old.\r\nFurther, `tf.version.VERSION` outputs 2.4.0, my libraries in _/usr/lib_ are named _libtensorflow_cc.so.2.4.0_, and _libtensorflow_framework.so.2.4.0_, and printing the tf version in C++ using `TF_VERSION_STRING` (defined in core/public/version.h) also gives me 2.4.0.\r\n\r\nI used the following code for installation:\r\n```\r\ngit clone git://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout master\r\n./configure\r\nbazel build -c opt --config=numa --config=v2 //tensorflow:libtensorflow_cc.so\r\nbazel build -c opt --config=numa --config=v2 //tensorflow:libtensorflow_framework.so\r\nbazel build --verbose_failures -c opt --config=numa --config=v2 //tensorflow/tools/pip_package:build_pip_package\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\nsudo pip install /tmp/tensorflow_pkg/tensorflow-2.4.0-cp38-cp38-linux_x86_64.whl\r\n```", "> Note that the hash above ge085901e2c does not match any commit\r\n\r\nThe 'g' at the start seems to mean \"git\" or \"group\", the hash itself is the following part: `e085901e2c` (matching what you found using `git rev-list`).", "@DouglasLivingstone thanks for shedding light on this.", "I don't work on TF anymore, sorry!", "Any updates on this?", "@TylerTheHumanCompiler Could you please try on latest stable version of tf 2.5 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41226\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41226\">No</a>\n"]}, {"number": 41224, "title": "migration problem from tensorflow 1.4.1 to tensorflow 2.0", "body": "I'm trying to implement a Vae model using tensorflow 2 through Google Colab. In order to do that, I need to start from a code wrote with tensorflow 1.4.1 and convert it in order to make it works. I report the original code wrote with TF1.4.1. Right now it works but unfortunately during the fit process the loss function deverges all the time, leaving me with a useless model ( the problem is related with TF version and not with the model itself, casuse I tried with TF1.4.1 and it perfectly worked.\r\n\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport keras\r\nfrom keras.layers import *\r\nfrom keras.models import Sequential,Model\r\nfrom keras import backend as K\r\n\r\ndef define_pre_encoder(data_dim,layers=2,units=512,dropout=0.0,BN=False): #define pre_encoder network\r\n    model = Sequential(name='pre-encoder')\r\n    model.add(InputLayer(input_shape=(data_dim,)))\r\n    for i in range(1,layers+1):\r\n        #model.add(Dense(int(units/i), activation='relu'))\r\n        model.add(Dense(units,activation='relu'))\r\n        if dropout != 0. and dropout != None:\r\n            model.add(Dropout(dropout))\r\n        if BN:\r\n            model.add(BatchNormalization())\r\n    return model\r\n\r\ndef define_generator(Nb,data_dim,layers=2,units=32,dropout=0.0,BN=False,exclusive=True):\r\n    model = Sequential(name='generator/decoder')\r\n    model.add(InputLayer(input_shape=(Nb,)))\r\n    for i in np.arange(layers,0,-1):\r\n        #model.add(Dense(int(units/i), activation='relu'))\r\n        model.add(Dense(units,activation='relu'))\r\n        if dropout != 0. and dropout != None:\r\n            model.add(Dropout(dropout))\r\n        if BN:\r\n            model.add(BatchNormalization())\r\n    if exclusive:\r\n        model.add(Dense(data_dim, activation='softmax')) #softmax generator\r\n    else:\r\n        model.add(Dense(data_dim, activation='sigmoid'))\r\n    return model\r\n\r\ndef traditional_VAE(data_dim,Nb,units,layers_e,layers_d,opt='adam',BN=True):\r\n    pre_encoder = define_pre_encoder(data_dim, layers=layers_e,units=units,BN=BN)\r\n    print(\"pre-encoder network:\")\r\n    pre_encoder.summary()\r\n    generator = define_generator(Nb,data_dim,layers=layers_d,units=units,BN=BN)\r\n    print(\"generator network:\")\r\n    generator.summary()\r\n\r\n    ## Encoder\r\n    x = Input(shape=(data_dim,))\r\n    hidden = pre_encoder(x)\r\n    z_mean = Dense(Nb,activation='linear', name='z-mean')(hidden)\r\n    z_log_var = Dense(Nb,activation='linear',name = 'z-log_var')(hidden)\r\n    encoder = Model(x, z_mean) # build a model to project inputs on the latent space\r\n\r\n    def sampling(args):\r\n        epsilon_std = 1.0\r\n        z_mean, z_log_var = args\r\n        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], Nb),mean=0., stddev=epsilon_std)\r\n        return z_mean + K.exp(0.5*z_log_var) * epsilon #+sigma (desvest)\r\n    \r\n    ## Decoder\r\n    z_sampled = Lambda(sampling, output_shape=(Nb,), name='sampled')([z_mean, z_log_var])\r\n    output = generator(z_sampled)\r\n\r\n    def vae_loss(x, x_hat):\r\n        reconstruction_loss = keras.losses.categorical_crossentropy(x, x_hat)*data_dim \r\n        #reconstruction_loss = keras.losses.binary_crossentropy(x, x_hat)*data_dim \r\n\r\n        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) #con varianza\r\n        return K.mean(reconstruction_loss  + kl_loss)\r\n\r\n    traditional_vae = Model(x, output)\r\n    traditional_vae.compile(optimizer=opt,loss=vae_loss)\r\n    return traditional_vae,encoder,generator\r\n```", "comments": ["@domizianostingi,\r\nI was not able to reproduce the issue from the given code. You have defined the functions but they are not being called anywhere. Could you please provide the complete code to reproduce the issue reported here?\r\n\r\nAlso, please take a look at [this guide](https://www.tensorflow.org/guide/migrate) to migrate your code from TF 1.x to TF 2.x and let us know if it helps. Thanks!", "Here there is the full code. As I said before this code is working, but during the fitting process, the loss function diverges and is no possible to use this model, while using the same script the loss didn't diverges\r\n````\r\ndef define_pre_encoder(data_dim,layers=2,units=512,dropout=0.0,BN=False): #define pre_encoder network\r\n    model = Sequential(name='pre-encoder')\r\n    model.add(InputLayer(input_shape=(data_dim,)))\r\n    for i in range(1,layers+1):\r\n        #model.add(Dense(int(units/i), activation='relu'))\r\n        model.add(Dense(units,activation='relu'))\r\n        if dropout != 0. and dropout != None:\r\n            model.add(Dropout(dropout))\r\n        if BN:\r\n            model.add(BatchNormalization())\r\n    return model\r\n\r\ndef define_generator(Nb,data_dim,layers=2,units=32,dropout=0.0,BN=False,exclusive=True):\r\n    model = Sequential(name='generator/decoder')\r\n    model.add(InputLayer(input_shape=(Nb,)))\r\n    for i in np.arange(layers,0,-1):\r\n        #model.add(Dense(int(units/i), activation='relu'))\r\n        model.add(Dense(units,activation='relu'))\r\n        if dropout != 0. and dropout != None:\r\n            model.add(Dropout(dropout))\r\n        if BN:\r\n            model.add(BatchNormalization())\r\n    if exclusive:\r\n        model.add(Dense(data_dim, activation='softmax')) #softmax generator\r\n    else:\r\n        model.add(Dense(data_dim, activation='sigmoid'))\r\n    return model\r\n\r\ndef traditional_VAE(data_dim,Nb,units,layers_e,layers_d,opt='adam',BN=True):\r\n    pre_encoder = define_pre_encoder(data_dim, layers=layers_e,units=units,BN=BN)\r\n    print(\"pre-encoder network:\")\r\n    pre_encoder.summary()\r\n    generator = define_generator(Nb,data_dim,layers=layers_d,units=units,BN=BN)\r\n    print(\"generator network:\")\r\n    generator.summary()\r\n    \r\n    ## Encoder\r\n    x = Input(shape=(data_dim,))\r\n    hidden = pre_encoder(x)\r\n    z_mean = Dense(Nb,activation='linear', name='z-mean')(hidden)\r\n    z_log_var = Dense(Nb,activation='linear',name = 'z-log_var')(hidden)\r\n    encoder = Model(x, z_mean) # build a model to project inputs on the latent space\r\n\r\n    def sampling(args):\r\n        epsilon_std = 1.0\r\n        z_mean, z_log_var = args\r\n        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], Nb),mean=0., stddev=epsilon_std)\r\n        return z_mean + K.exp(0.5*z_log_var) * epsilon #+sigma (desvest)\r\n    \r\n    ## Decoder\r\n    z_sampled = Lambda(sampling, output_shape=(Nb,), name='sampled')([z_mean, z_log_var])\r\n    output = generator(z_sampled)\r\n\r\n    def vae_loss(x, x_hat):\r\n        reconstruction_loss = keras.losses.categorical_crossentropy(x, x_hat)*data_dim \r\n        #reconstruction_loss = keras.losses.binary_crossentropy(x, x_hat)*data_dim \r\n\r\n        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) #con varianza\r\n        return K.mean(reconstruction_loss  + kl_loss)\r\n\r\n    traditional_vae = Model(x, output)\r\n    traditional_vae.compile(optimizer=opt,loss=vae_loss)\r\n    return traditional_vae,encoder,generator\r\n\r\n\r\ntraditional_vae,encoder_Tvae,generator_Tvae = traditional_VAE(X_train.shape[1],Nb=32,units=500,layers_e=2,layers_d=0)    \r\n\r\n\r\ntraditional_vae.fit(X_total_input, X_total, epochs=50, batch_size=batch_size,verbose=1)\r\n```", "@domizianostingi I am not able to reproduce this issue as the code provided is incomplete. Please find my gist [here](https://colab.research.google.com/gist/gowthamkpr/153cb6b18f5f25cfaa49810e0daa0359/untitled302.ipynb). Can you please provide the complete code with data for me to reproduce this issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41223, "title": "Add a new badge for nightly build on arm", "body": "Right now, Openlab providers 3 test job for daily build the whl package on aarch64 platform.\r\n1. Build the master(v2.2.0) branch of tensorflow package\r\n2. Build the v2.0.0 branch of tensoflow package\r\n3. Build the v2.1.0 branch of tensoflow package\r\nAll builds will provider the ready whl packages for test or other purpose. Here we give a sample about the package. see https://status.openlabtesting.org/builds/build/c830aacd2fc84c0db525f2a3abb28a46\r\n\r\nWe will be the responsibility to maintain the CI system and build packages, including the test resource and human resource. We will be very happy to get some requests from community. Follow the advices from community to maintain / update this CI system on aarch64.\r\n\r\nWe discuss in https://github.com/tensorflow/build/issues/9  and https://github.com/tensorflow/tensorflow/issues/40463", "comments": ["@bzhaoopenstack Any idea why http://openlabtesting.org:15000/badge?project=tensorflow%2Ftensorflow shows green, when the AArch64 nightly seems to failed yesterday? I see that TF 2.1 and 2.0 builds were successful. Is it picking up the output of the wrong build?"]}, {"number": 41222, "title": "Add SkipRecords to RecordReader", "body": "This is a PR from JIZHI Team & TaiJi AI platform in Tencent.\r\n\r\nThis pr add `SkipRecords(uint64* offset, int num_to_skip)` to `RecordReader`, which will skip `num_to_skip` number of records without reading them (using `SkipNBytes`). It will help to implement the `Skip` interface mentioned in #40963, where we are hoping to avoid unnecessary data IO and transformation in ops like `tf.data.Dataset.shard` and `tf.data.Dataset.skip`.\r\n\r\nThank you for your time on reviewing this pr.\r\n\r\nFYI, @aaudiber ", "comments": ["@aaudiber \r\nCould you take a look at this pr? Thank you :).", "@aaudiber \r\nThank you for your reviews! I've udpated the code based on them. Could you have another look?\r\nAs for the test, I added the test for out-of-range situation, but I'm not sure how to add one for truncated files. Shall I create a class like the `StringSource` in `recordio_test.cc`?", "Genly ping @aaudiber \r\nI've updated this pr according to the review comment. Could you have another look? \ud83d\ude04 "]}, {"number": 41221, "title": "Benchmark for @tf.function with retrace", "body": "Benchmark for `tf.function` with retrace for each Python object value.", "comments": []}, {"number": 41220, "title": "Uninstal TensorFlow with all it's packages *Windows 10", "body": "Hello, \r\nI uninstalled TensorFlow with `pip uninstall tensorflow` but there are still some packages that came with it when i installed it and now i have to uninstall them manually.\r\nIs there anyway to uninstall them all together not by one? \r\n\r\nThanks for any help in advanced. \r\n", "comments": ["@MohaDou \r\nCan you please try the below commands and confirm (for python3)\r\n\r\npython3 -m pip uninstall protobuf \r\npython3 -m pip uninstall tensorflow   \r\npython3 -m pip uninstall tensorflow-gpu\r\n\r\nPlease refer to these links:\r\n[link](https://github.com/tensorflow/tensorflow/issues/8785#issuecomment-289937786) [link1](https://stackoverflow.com/questions/11248073/what-is-the-easiest-way-to-remove-all-packages-installed-by-pip) [link2](https://github.com/tensorflow/tensorflow/issues/20416#issuecomment-401470771) [link3](https://www.roseindia.net/tensorflow/tensorflow2/uninstall-tensorflow-2.0-beta.shtml)", "protobuf are one of tens, Also i didn't install TensorFlow with gpu so that wouldn't help too \r\n\r\nhere are all the packages that came with the installation:\r\nThey came but didn't want to go \r\n![Screenshot (37)](https://user-images.githubusercontent.com/45735118/87068624-c42f0280-c20d-11ea-9593-bd326af5d358.png)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41220\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41220\">No</a>\n"]}, {"number": 41219, "title": "Add nearest fill mode for image projective transform", "body": "Closes https://github.com/tensorflow/tensorflow/issues/39177.", "comments": []}, {"number": 41217, "title": "[ROCm] Fix for ROCm Breakage - 200708", "body": "The XLA CI job for ROCm is running into the following compile failure\r\n\r\n```\r\ntensorflow/compiler/xla/service/sharding_propagation.cc: In static member function 'static tensorflow::Status xla::ShardingPropagation::NormalizeDomain(const xla::DomainMetadata::Domain&, const xla::DomainMetadata*)':\r\ntensorflow/compiler/xla/service/sharding_propagation.cc:1387:46: error: request for member 'exit_domains' in 'domain', which is of pointer type 'xla::HloInstruction*' (maybe you meant to use '->' ?)\r\n         for (HloInstruction* domain : domain.exit_domains) {\r\n                                              ^\r\n...\r\n```\r\n\r\nThe failure seems to be caused by the loop variable `domain` having the same name as another variable in the enclosing scope. Renaming the loop variable to something different fixes the failure.\r\n\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": []}, {"number": 41215, "title": "Added str_util fuzzers", "body": "Added fuzzers for ArgDefCase, ConsumeLeadingDigits, and ConsumeNonWhitespace @mihaimaruseac ", "comments": ["Hmm, Sanity now wants them in the other order. I'll import manually."]}, {"number": 41214, "title": "Resubmit: Fix distributed autocast variable assignment", "body": "This is a resubmission of #40564 and includes fixes and a unittest for https://github.com/tensorflow/tensorflow/pull/40564#issuecomment-651408361 which previously caused the merged to be rolled back in 8535dafb37ec4ce5c7272ffa4b8b4c491d44e999.\r\n\r\n/cc @reedwm @alextp ", "comments": ["@lgeiger Can you please check @reedwm's comments and keep us posted. Thanks!", "Sorry for the delay, I'll take a look at it later this week."]}, {"number": 41213, "title": "MirroredStrategy slows down training", "body": "My expectation was that the training time would be drastically reduced by using MirroredStrategy with multi-gpu (4 in my case). However I see the average step time gets increased significantly. Could you please advice on what is the problem?\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):('v1.12.1-35610-gd8c49c2fde', '2.4.0-dev20200701')\r\n  tf-estimator-nightly       2.4.0.dev2020063001\r\n  tf-nightly                 2.4.0.dev20200701\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: \r\n\r\n\r\n- GPU model and memory: \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\r\n| N/A   38C    P0    50W / 300W |  15450MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\r\n| N/A   37C    P0    54W / 300W |  15450MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\r\n| N/A   36C    P0    55W / 300W |  15522MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   37C    P0    55W / 300W |  15522MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.2/lib64/libcudart.so.9.2.148\r\n/usr/local/cuda-9.2/lib64/libcudart_static.a\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-10.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-10.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2.89\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-10.2/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-10.2/doc/man/man7/libcudart.7\r\n/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-10.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-10.0/lib64/libcudart.so.10.0.130\r\n/usr/local/cuda-10.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n\r\n== tensorflow installed from info ==================\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 6, 10, 'final', 0)\r\n**Describe the current behavior**\r\n\r\n#average step for single-gpu\r\nEpoch 2/50\r\n8/8 [==============================] - 0s 5ms/step - loss: 0.7215 - accuracy: 0.5620 - val_loss: 0.6550 - val_accuracy: 0.7213\r\n\r\n#average step for multi-gpu, is more than 10 times slower!!\r\nEpoch 2/50\r\n2/2 [==============================] - 0s 224ms/step - loss: 0.6756 - accuracy: 0.5702 - val_loss: 0.6435 - val_accuracy: 0.6885\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect the average step time to be reduced to 1/4, given that there are 4 gpu's doing data splitting and processing in parallel\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nsource code from: https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\r\nfrom tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\r\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\r\n\r\n#tf.debugging.set_log_device_placement(True)\r\n\r\nfile_url = \"https://storage.googleapis.com/applied-dl/heart.csv\"\r\ndataframe = pd.read_csv(file_url)\r\n\r\nval_dataframe = dataframe.sample(frac=0.2, random_state=1337)\r\ntrain_dataframe = dataframe.drop(val_dataframe.index)\r\n\r\nprint(\r\n    \"Using %d samples for training and %d for validation\"\r\n    % (len(train_dataframe), len(val_dataframe))\r\n)\r\n\r\ndef dataframe_to_dataset(dataframe):\r\n    dataframe = dataframe.copy()\r\n    labels = dataframe.pop(\"target\")\r\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\r\n    ds = ds.shuffle(buffer_size=len(dataframe))\r\n    return ds\r\n\r\n\r\ntrain_ds = dataframe_to_dataset(train_dataframe)\r\nval_ds = dataframe_to_dataset(val_dataframe)\r\n\r\nfor x, y in train_ds.take(1):\r\n    print(\"Input:\", x)\r\n    print(\"Target:\", y)\r\n\r\n\r\ndef encode_numerical_feature(feature, name, dataset):\r\n    normalizer = Normalization()\r\n\r\n    feature_ds = dataset.map(lambda x, y: x[name])\r\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\r\n\r\n    normalizer.adapt(feature_ds)\r\n\r\n    encoded_feature = normalizer(feature)\r\n    return encoded_feature\r\n\r\n\r\ndef encode_string_categorical_feature(feature, name, dataset):\r\n    index = StringLookup()\r\n\r\n    feature_ds = dataset.map(lambda x, y: x[name])\r\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\r\n\r\n    index.adapt(feature_ds)\r\n\r\n    encoded_feature = index(feature)\r\n\r\n    encoder = CategoryEncoding(output_mode=\"binary\")\r\n\r\n    feature_ds = feature_ds.map(index)\r\n\r\n    encoder.adapt(feature_ds)\r\n\r\n    encoded_feature = encoder(encoded_feature)\r\n    return encoded_feature\r\n\r\n\r\ndef encode_integer_categorical_feature(feature, name, dataset):\r\n    encoder = CategoryEncoding(output_mode=\"binary\")\r\n\r\n    feature_ds = dataset.map(lambda x, y: x[name])\r\n    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\r\n\r\n    encoder.adapt(feature_ds)\r\n\r\n    encoded_feature = encoder(feature)\r\n    return encoded_feature\r\n\r\ndef build_model():\r\n    sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\r\n    cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\r\n    fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\r\n    restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\r\n    exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\r\n    ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\r\n\r\n    thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\r\n\r\n    age = keras.Input(shape=(1,), name=\"age\")\r\n    trestbps = keras.Input(shape=(1,), name=\"trestbps\")\r\n    chol = keras.Input(shape=(1,), name=\"chol\")\r\n    thalach = keras.Input(shape=(1,), name=\"thalach\")\r\n    oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\r\n    slope = keras.Input(shape=(1,), name=\"slope\")\r\n\r\n    all_inputs = [\r\n        sex,\r\n        cp,\r\n        fbs,\r\n        restecg,\r\n        exang,\r\n        ca,\r\n        thal,\r\n        age,\r\n        trestbps,\r\n        chol,\r\n        thalach,\r\n        oldpeak,\r\n        slope,\r\n    ]\r\n\r\n\r\n    sex_encoded = encode_integer_categorical_feature(sex, \"sex\", train_ds)\r\n    cp_encoded = encode_integer_categorical_feature(cp, \"cp\", train_ds)\r\n    fbs_encoded = encode_integer_categorical_feature(fbs, \"fbs\", train_ds)\r\n    restecg_encoded = encode_integer_categorical_feature(restecg, \"restecg\", train_ds)\r\n    exang_encoded = encode_integer_categorical_feature(exang, \"exang\", train_ds)\r\n    ca_encoded = encode_integer_categorical_feature(ca, \"ca\", train_ds)\r\n\r\n    thal_encoded = encode_string_categorical_feature(thal, \"thal\", train_ds)\r\n\r\n    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\r\n    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\r\n    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\r\n    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\r\n    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\r\n    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\r\n\r\n    all_features = layers.concatenate(\r\n        [\r\n            sex_encoded,\r\n            cp_encoded,\r\n            fbs_encoded,\r\n            restecg_encoded,\r\n            exang_encoded,\r\n            slope_encoded,\r\n            ca_encoded,\r\n            thal_encoded,\r\n            age_encoded,\r\n            trestbps_encoded,\r\n            chol_encoded,\r\n            thalach_encoded,\r\n            oldpeak_encoded,\r\n        ]\r\n    )\r\n\r\n    x = layers.Dense(32, activation=\"relu\")(all_features)\r\n    x = layers.Dropout(0.5)(x)\r\n    output = layers.Dense(1, activation=\"sigmoid\")(x)\r\n    model = keras.Model(all_inputs, output)\r\n    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\r\n    return model\r\n\r\nmodel_single_gpu = build_model()\r\nmodel_single_gpu.fit(train_ds.batch(32), epochs=50, validation_data=val_ds.batch(32))\r\n\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\nwith mirrored_strategy.scope():\r\n    model_multi_gpu = build_model()\r\nmodel_multi_gpu.fit(train_ds.batch(32*4), epochs=50, validation_data=val_ds.batch(32*4))\r\n\r\n```", "comments": ["@guptapriya @nikitamaia I couldn't include the profile information you requested due to a bug in TF profiler that makes it crash when the model has a preprocessing layer to encode categorical string inputs. The code to reproduce the error is in https://github.com/tensorflow/tensorflow/issues/41244\r\n\r\nHaving said that, I observed the same behavior of slowness happening with MirroredStrategy when using the only-numerical model", "Hi @oscaralvaro, can you share your only-numerical model with profiler information? That could be a good place to start debugging if you were also seeing a slowdown with that model.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi @nikitamaia I will try to get some bandwidth this week to work in providing the example as you are requesting", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 41212, "title": "DataType error: DataType 6 is not recognized in Java (version 2.4.0)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: custom\r\n- TensorFlow installed from (source or binary):org.tensorflow:tensorflow-lite:0.0.0-nightly\r\n- TensorFlow version (use command below):version 2.4.0\r\n- Python version:\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source): Android SDK Java API 28\r\n- CUDA/cuDNN version: N/A - CPU\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nLoaded a TTS mel generator tflite model in java on the android target.\r\nrunForMultipleInputsOutputs function. The model takes 4 tensors as input with INT32 (1, 1), BOOL(1,1), INT32 and Float. \r\nTrying to print and feed input tensors with type boolean and dynamic size, however, it is crashing in printing and also later in \r\nIt is printing first input tensor details, however crashes while printing the seconds tensor details\r\n \r\nD/SnsTTS: input tensors count: 4\r\nD/SnsTTS: tensor[0] Shape: [1, 1] data type: INT32\r\njava.lang.IllegalArgumentException: DataType error: DataType 6 is not recognized in Java (version 2.4.0)\r\n        at org.tensorflow.lite.DataType.fromC(DataType.java:79)\r\n        at org.tensorflow.lite.Tensor.<init>(Tensor.java:484)\r\n        at org.tensorflow.lite.Tensor.fromIndex(Tensor.java:44)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.getInputTensor(NativeInterpreterWrapper.java:303)\r\n        at org.tensorflow.lite.Interpreter.getInputTensor(Interpreter.java:423)\r\n\r\n**Describe the expected behavior**\r\nIt should print the input tensor details, for boolean type and also accept it in the run function in java\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nprivate void printTensor(Tensor tensor, int index){\r\n        int[] shape = tensor.shape();\r\n        DataType dataType = tensor.dataType();\r\n        Log.d(Tag, \"tensor[\" + index + \"] Shape: \" + Arrays.toString(shape) + \" data type: \" + dataType.toString());\r\n    }\r\n\r\n    private void printInterpreterDetails(Interpreter interpreter){\r\n\r\n        int inputTensorCount = interpreter.getInputTensorCount();\r\n        Log.d(Tag, String.format(\"input tensors count: %d\", inputTensorCount));\r\n        for (int inputTensorIndex =0; inputTensorIndex<inputTensorCount; inputTensorIndex++) {\r\n            printTensor(interpreter.getInputTensor(inputTensorIndex), inputTensorIndex);\r\n        }\r\n}\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nHere is the link to python implementation\r\nhttps://github.com/TensorSpeech/TensorflowTTS", "comments": ["Java API's DataType enum should be updated. Team will work on this.", "Hi @ambujbansal Can you uploaded the model here so I can reproduce it quicker?", "\r\n[fastspeech_quant.zip](https://github.com/tensorflow/tensorflow/files/4893822/fastspeech_quant.zip)\r\n```\r\nprivate Interpreter loadModel(String modelpath){\r\n        try {\r\n            FileInputStream inputStream = new FileInputStream(modelpath);\r\n            FileChannel fileChannel = inputStream.getChannel();\r\n            MappedByteBuffer tfliteModel = fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileChannel.size());\r\n\r\n            Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n            tfliteOptions.setNumThreads(1);\r\n            Interpreter interpreter = new Interpreter(tfliteModel, tfliteOptions);\r\n            return interpreter;\r\n        } catch (Exception e) {\r\n            Log.e(Tag, \"Error loading model\", e);\r\n        }\r\n        return null;\r\n    }\r\n```", "It is supported at the master head.\r\nCould you give it a try.", "A fix is submitted at commit 11d919f0a51aeb835230dc3a0a36df10346eb493", "i meet the same problem:  \r\nmodel output: \r\n```  \r\noutput = tf.cast(output, tf.bool)\r\n```  \r\n\r\n\r\nproduce the error in Android Studio\r\n```  \r\nE/libc: Access denied finding property \"ro.hardware.chipname\"\r\nE/AndroidRuntime: FATAL EXCEPTION: CameraBackground\r\n    Process: android.example.com.tflitecamerademo_mobilenet2unet_KrzysztofV_9, PID: 6336\r\n    java.lang.IllegalArgumentException: DataType error: DataType 6 is not recognized in Java (version 2.4.0)\r\n        at org.tensorflow.lite.DataType.fromC(DataType.java:79)\r\n        at org.tensorflow.lite.Tensor.<init>(Tensor.java:484)\r\n        at org.tensorflow.lite.Tensor.fromIndex(Tensor.java:44)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.getOutputTensor(NativeInterpreterWrapper.java:326)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:170)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:343)\r\n        at org.tensorflow.lite.Interpreter.run(Interpreter.java:304)\r\n        at com.example.android.mobilenet2unet_KrzysztofV_9.ImageSegmentorFloatMobileUnet.runInference(ImageSegmentorFloatMobileUnet.java:148)\r\n        at com.example.android.mobilenet2unet_KrzysztofV_9.ImageSegmentor.segmentFrame(ImageSegmentor.java:134)\r\n        at com.example.android.mobilenet2unet_KrzysztofV_9.Camera2BasicFragment.segmentFrame(Camera2BasicFragment.java:1060)\r\n        at com.example.android.mobilenet2unet_KrzysztofV_9.Camera2BasicFragment.access$1100(Camera2BasicFragment.java:103)\r\n        at com.example.android.mobilenet2unet_KrzysztofV_9.Camera2BasicFragment$11.run(Camera2BasicFragment.java:943)\r\n        at android.os.Handler.handleCallback(Handler.java:883)\r\n        at android.os.Handler.dispatchMessage(Handler.java:100)\r\n        at android.os.Looper.loop(Looper.java:241)\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\r\n```  \r\n", "@AR-fan Can you specify the exact version of TFLite you are using?\r\nIf you are using nightly, what exact date is that nightly version? Otherwise, what is used in your gradle file?", "@thaink I also have the sane problem with tensorflow.\r\n\r\nException in thread \"main\" java.lang.IllegalArgumentException: DataType 20 is not recognized in Java (version 1.15.0)\r\n\tat org.tensorflow.DataType.fromC(DataType.java:85)\r\n\tat org.tensorflow.Tensor.fromHandle(Tensor.java:540)\r\n\tat org.tensorflow.Session$Runner.runHelper(Session.java:343)\r\n\tat org.tensorflow.Session$Runner.run(Session.java:276)\r\n\tat tftest3.main(tftest3.java:46)\r\n\r\nit has similar issue with tensflor-lite as well [#1079](https://github.com/xamarin/XamarinComponents/issues/1079)\r\n\r\nWhat are these DataType numbers, 6 and 20, etc? Is there a way to find out them? May this can help?\r\n\r\nHere is my original question;  (https://stackoverflow.com/questions/66654600/datatype-20-is-not-recognized-in-java-version-1-15-0)", "Here, I created the model by runing \"runMe.py\" in \"CreateModelWithPythonTensorflow\" and saved the model in \"model\".\r\nThe maven project is given. I get the same problem. I added all files that may help to solve this issue. Please see in: [ReportProblem.zip](https://github.com/tensorflow/tensorflow/files/6174838/ReportProblem.zip)\r\n\r\nHere is the output if you run the Java project:\r\n\r\n`test_images\\test_00001.png\r\n28-28\r\n1\r\n4\r\ninputTensor is: FLOAT tensor with shape [1, 28, 28, 1]\r\nFLOAT\r\n\r\n1.15.0\r\n2021-03-20 03:47:26.040919: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: CreateModelWithPythonTensorflow/model\r\n2021-03-20 03:47:26.042983: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n2021-03-20 03:47:26.046158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2021-03-20 03:47:26.058207: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\r\n2021-03-20 03:47:26.091805: I tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: CreateModelWithPythonTensorflow/model\r\n2021-03-20 03:47:26.099182: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 58246 microseconds.\r\npredicting...\r\n\r\nException in thread \"main\" java.lang.IllegalArgumentException: DataType 20 is not recognized in Java (version 1.15.0)\r\n\tat org.tensorflow.DataType.fromC(DataType.java:85)\r\n\tat org.tensorflow.Tensor.fromHandle(Tensor.java:540)\r\n\tat org.tensorflow.Session$Runner.runHelper(Session.java:343)\r\n\tat org.tensorflow.Session$Runner.run(Session.java:276)\r\n\tat TfDataTypeIssue.main(TfDataTypeIssue.java:43)\r\n`", "@micosacak TF 1.15 version is too old to be supported. Could you try upgrading to the recent TF version?", "I use tensorflow 2.2. in Python. In java, the latest version is 1.15.", "@micosacak could you file a separate issue? The original case is for the TensorFlow Lite library while your case is about TensorFlow java API. They are different and it would be better to address them separately.", "@ambujbansal It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5.0 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41212\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41212\">No</a>\n"]}, {"number": 41210, "title": "added priority function", "body": "added wrapper to kernel_builder for set_priority \r\n@annarev @bmzhao ", "comments": ["@dnguyen28061 Thank you for your contribution. Can you please sign CLA? Thanks!"]}, {"number": 41209, "title": "Summary op", "body": "Changes: Implemented ScalarSummary kernel in summary_op for C API. Also implemented tests for ScalarSummary. Added shape debug string to tf_tensor for use in summary_op. \r\n\r\n@annarev @bmzhao ", "comments": ["Can you add more to the PR description? Mention ScalarSummary since this is the op you are migrating.", "The latest sanity failures look very hard to tell:\r\n```\r\ntensorflow/c/kernels/BUILD:\r\n31a32\r\n>         \"//tensorflow/c:tf_status\",\r\n34d34\r\n<         \"//tensorflow/c:tf_status\",\r\n91d90\r\n<     deps = [ \"//tensorflow/c:tf_tensor\"],\r\n92a92\r\n>     deps = [\"//tensorflow/c:tf_tensor\"],\r\n99d98\r\n<         \"//tensorflow/core:framework\",\r\n100a100\r\n>         \"//tensorflow/core:framework\",\r\n117c117\r\n<         \"bitcast_op.cc\",\r\n---\r\n>         \"bitcast_op.cc\",\r\n126c126\r\n<         \"ops/bitcast.cc\",\r\n---\r\n>         \"ops/bitcast.cc\",\r\n```\r\n(I can't tell the difference in many of these)\r\nYou can setup buildifier: https://github.com/bazelbuild/buildtools/tree/master/buildifier to make it easier."]}, {"number": 41208, "title": "Premature end of JPEG file", "body": "Premature end of JPEG file\r\nthis is brain bug of tf team that can't imagine that if there is issue with image it should not be processed and should be skipped because after this error optimisation become some mess.\r\n\r\nI get this error frequently then I try to train on some basic dataset from images downloaded from internet\r\nImages are processed ad handled by OS and image software without problems and errors\r\nI am using TF2.1 on conda dor windows but my problem is not that it get errors from time to time, but that TF team are not smart enough to:\r\n1. print the path of file giving this error\r\n2. check file health before to use it for training and if it is bad to skip it!!! or better optionally move it to some debug folder from where people could get it and inspect and analyze it, then fix it and return it back\r\nAs you understand for this issue, it is not important reason, but is important issue handling that is completely missing\r\nerror message Premature end of JPEG file is not handling of anything especially because in this case for normal people it is clear what must be done on this error\r\n", "comments": ["@easy-and-simple,\r\nCould you please provide a sample code to reproduce the issue reported here, so that we can look into it. Thanks!", "Hi. At the time the error is encountered, we only have a binary representation of the file contents. PRs to change the architecture/pass in more information are welcome. Or RFCs proposing a better design.\r\n\r\nPlease be respectful, consider the [code of conduct](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md). We are all human and make design mistakes", "STRDYSs are realy JFGETRD\r\nBecause WTDPPR right?!", "> @easy-and-simple,\r\n> Could you please provide a sample code to reproduce the issue reported here, so that we can look into it. Thanks!\r\n\r\nI started with ML and AI about 2 months ago, I am new to all this, and I can't write complicated code, so I am using code that is from github project implementing yolo2 on tensorflow.\r\nThis is more detailed error message:\r\nError 1:\r\nModel.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use Model.fit, which supports generators.\r\n\r\nError 2:\r\nW tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\nPremature end of JPEG file\r\n\r\n\r\nCode implementing batch generator as whole project is for tensorflow v1, but is updated to tensorflow v2 using tensorflow v2 converter script and some manual changes. In general it is working but this JPEG issue is making problems because it obviously impact training algorithm by making big errors when problematic image is processed. I really doubt that problem is in image because windows process all images without errors and makes thumbnails for them\r\n\r\n`class BatchGenerator(Sequence):\r\n    def __init__(self,\r\n                 netin_gen,\r\n                 netout_gen,\r\n                 yolo_box,\r\n                 img_aug,\r\n                 annotations,\r\n                 batch_size,\r\n                 repeat_times):\r\n        \"\"\"\r\n        # Args\r\n            annotations : Annotations instance\r\n        \r\n        \"\"\"\r\n        self._netin_gen = netin_gen\r\n        self._netout_gen = netout_gen\r\n        self._img_aug = img_aug\r\n        self._yolo_box = yolo_box\r\n\r\n        self._batch_size = min(batch_size, len(annotations)*repeat_times)\r\n        self._repeat_times = repeat_times\r\n        self.annotations = annotations\r\n        self.counter = 0\r\n\r\n    def __len__(self):\r\n        return int(len(self.annotations) * self._repeat_times /self._batch_size)\r\n\r\n    def __getitem__(self, idx):\r\n        \"\"\"\r\n        # Args\r\n            idx : batch index\r\n        \"\"\"\r\n        x_batch = []\r\n        y_batch= []\r\n        for i in range(self._batch_size):\r\n            # 1. get input file & its annotation\r\n            fname = self.annotations.fname(self._batch_size*idx + i)\r\n            boxes = self.annotations.boxes(self._batch_size*idx + i)\r\n            labels = self.annotations.code_labels(self._batch_size*idx + i)\r\n            \r\n            # 2. read image in fixed size\r\n            img, boxes = self._img_aug.imread(fname, boxes)\r\n\r\n            # 3. grid scaling centroid boxes\r\n            norm_boxes = self._yolo_box.trans(boxes)\r\n            \r\n            # 4. generate x_batch\r\n            x_batch.append(self._netin_gen.run(img))\r\n            y_batch.append(self._netout_gen.run(norm_boxes, labels))\r\n\r\n        x_batch = np.array(x_batch)\r\n        y_batch = np.array(y_batch)\r\n        self.counter += 1\r\n        return x_batch, y_batch\r\n\r\n    def on_epoch_end(self):\r\n        self.annotations.shuffle()\r\n        self.counter = 0\r\n`", "@easy-and-simple, \r\n> Error 1:\r\n> Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Please use Model.fit, which supports generators.\r\n\r\nThis issue has already been addressed here [#38938](https://github.com/tensorflow/tensorflow/issues/38938) and has been fixed in TF v2.3.0rc1.\r\n\r\n\r\n> \r\n> Error 2:\r\n> W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n> Premature end of JPEG file\r\n> \r\nSimilarly, this _warning_ too has been addressed in multiple issues previously. Please take a look at these duplicates [#35100](https://github.com/tensorflow/tensorflow/issues/35100#issuecomment-603922186), [#37515](https://github.com/tensorflow/tensorflow/issues/37515#issuecomment-602901519), [#34156](https://github.com/tensorflow/tensorflow/issues/34156#issuecomment-638683792), [#37324](https://github.com/tensorflow/tensorflow/issues/37324#issuecomment-595869309).\r\n\r\nHope this helps. Please feel free to close the issue if resolved. Thanks!", "Are you in mind?!\r\n\r\nYou losers dont teach me and fix this bug!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\nIssue is with Premature end of JPEG file you dumb morons!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\nObviously for google work only morons!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\nI hope this farm for real morons google will bankrupt soon", "@easy-and-simple Please read [code of conduct](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md) before posting any queries and be respectful as advised in earlier post. The issue tracker is for Tensorflow feature requests or bug reports. Please refrain from posting inappropriate comments. If any functionality or feature does not work to your satisfaction, please let us know, as each feedback is valuable to us. Tensorflow team will be happy to address them. Were you able to go over the information provided by @amahendrakar. Again, we can only help if you restrict your posts to product issues and not personal rants. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41208\">No</a>\n", "Is this issue is fixed or not? If someone is asking a question you should provide the exact resolution not some reference link to other issue on which this issues is subpart of. M using TF-GPU 2.3.1 as object detection and I am having the same issue while training the model. So, is there exist any resolution of this issue or not ? If exist what is the changes i need to make in the TF package because i just created record file and fed it to the model and it pops me this error. ", "Please open new issue and fill in issue template, provide a minimal reproducer.", "This issue arises if your JPEG file isn't written or saved properly e.g. if your script is running and you interrupt it while cv2.imwrite or anything similar is being run at the moment and the image gets saved right before the script stops, you'll get this error if you use that image."]}, {"number": 41207, "title": "model.predict_generator & model.fit [Keras] don't give the same prediction for the same image !!", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nN/A (google colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nn/a\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n1.15.2\r\n- Python version:\r\n3.6.9\r\n- Keras version:\r\n2.1.6\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nHi everyone,\r\n\r\nI trained a model using Keras.model.fit_generator. However, when I use model.predict_generator(...) and model.predict(...), everything works well BUT I don't get the same predictions for the same image... I am aware of a similar problem [https://github.com/keras-team/keras/issues/3477](url) but I tried everything that was suggested (no augmentation used, shuffle=False, renamed my files,...) and still get different results... Anyone could help please?\r\n\r\n**Describe the expected behavior**\r\nI expect to have the same results...\r\n", "comments": ["@Delarti \r\nPlease share simple stand alone indented code for us to replicate the issue faced or if possible share colab gist with error faced.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41207\">No</a>\n"]}, {"number": 41206, "title": "TF-Lite Ops supported (available)", "body": "Is there a way to check what operations (list of all operators) are supported and distinguish CPU vs. GPU or other platform specifics?\r\nWhat is the best way to check their correction of operation and functionality?\r\n", "comments": ["Exhaustive list of CPU ops can be seen [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/versioning/runtime_version.cc).\r\n\r\nThe platform-specific ops that are supported with [TFLite Delegates](https://www.tensorflow.org/lite/performance/delegates) are usually found in the code for that delegate, for eg [GPU](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/operations.h#L33) & [Hexagon DSP](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/hexagon). Note that there might be certain restrictions on parameters that determine if it will get accelerated with that particular delegate.\r\n\r\nAssuming you have a model, you can compare performance on CPU vs platforms using the following tools:\r\n1. [Benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark) for latency performance.\r\n2. [Accuracy tasks](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks) to gauge correctness. There is also the [inference_diff](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff) tool that provides raw output errors for CPU vs delegate, as long as you know how to interpret the output tensors.", "Thank you for your answer. \r\nB.T.W: Do you somehow able to distinguish on OPs target for 8bit vs float?", "The individual delegate documentation (linked above) will usually describe what kind of models they support. A more consolidated chart is [here](https://www.tensorflow.org/lite/performance/model_optimization#quantization)."]}, {"number": 41205, "title": "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.", "body": "hello i keep getting error \r\n(The max number of people in your video.\r\nIf no input and press Enter, the number of be set to default: 1 person.\r\nThe max number of people in your video: 2\r\n--------------\r\nIf you want the detailed information of GIF, input yes.\r\nIf no input and press Enter, the generation setting of GIF will be set to default.\r\nwarn If you input warn, then no GIF will be generated.\r\nthe detailed information[yes/no/warn]: yes\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"src/openpose_3dpose_sandbox_vmd.py\", line 9, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\laris\\anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n(tensorflow) C:\\Users\\laris\\OneDrive\\Bureaublad\\OpenMMD_1.0\\3d-pose-baseline-vmd>) \r\n i trying to follow this video https://www.youtube.com/watch?v=hKx6jl9a5-I&t=293s\r\nbut i keep run problem after problem please someone help . i keep run into trials of errors \r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "can you please make it is easier what do i need to type ?  and what my issu is? \r\n i keep uninstall-install  ", "@shoujomami,\r\nPlease check [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) thread from a similar issue and let us know if it helps. \r\n\r\nAlso, please take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have all compatible dependencies installed. Thanks!", "@amahendrakar \r\n\r\nwell my GPU is Geforec GTX 960 and CPU is  I5 650 \" 3.20GHZ 3.19 GHZ \r\ni wonder if my CPUI support AVX instructions", "@shoujomami,\r\nIntel's product specification page for [i5-650](https://ark.intel.com/content/www/us/en/ark/products/43546/intel-core-i5-650-processor-4m-cache-3-20-ghz.html) doesn't mention support for AVX.\r\n\r\nIn this case as mentioned below, you can try building TensorFlow [from source](https://www.tensorflow.org/install/source_windows) or use [Google Colab](https://colab.research.google.com/) instead.\r\n\r\n\r\n> * Try Google Colab to use TensorFlow.\r\n>   \r\n>   * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use `pip install`  to install any other preferred TF version.\r\n>   * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\r\n>   * All you need is a good internet connection and you are all set.\r\n> * Try to build TF from sources by changing CPU optimization flags.\r\n\r\nThanks!", "@amahendrakar  \r\nis that will allow me to do what they did in that video above? \r\nor i will need new cpu in order to programming that application? \r\n", "and how do i use google colab?\r\n", "there files data in my system i want TensorFlow switching it to motion and all files i need it is in my system , so what i should? should i uploode my whole folder in google drive so google colab can use the files/data based in python codes? ", "Yes, you can transfer files easily with either 'Google Colab' or 'Kaggle'.\r\nThey use Cloud CPU. GPU. and TPU and not at your computer.\r\nhttps://www.kaggle.com/\r\nhttps://colab.research.google.com/\r\n", "@dailylifesking \r\nWell my file is 5GB and higher plus it is have bat files must open it in my process to transform date to 3D pose motion  success . does kaggle/google cloab support bat files? ", "OK i found out that i can run it for my GPU thank you  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41205\">No</a>\n"]}, {"number": 41204, "title": "\"Tensor is unhashable\" and \"too many values to unpack\" with transformers", "body": "**System information:**\r\n\r\n- OS: Ubuntu 20.04;\r\n- Tensorflow: v2.2.0-rc4-8-g2b96f3662b 2.2.0. Installed used pip3;\r\n- Tensorflow-gpu: 2.2.0. Installed used pip3;\r\n- Python: 3.8.2;\r\n- CUDA Version: 10.2;\r\n- cuDNN: 7.6.5;\r\n- GPU: GeForce GTX 1050 Ti;\r\n\r\n**Description:**\r\nI have successfully installed `tensorflow` and used it for a while. But now I want to use [transformers](https://github.com/huggingface/transformers) and I started getting problems, here is [my previous issues report](https://github.com/huggingface/transformers/issues/5555). But now I think that some of them are more related to the `tensorflow` then to the `transformers`. \r\nHere is my code:\r\n```\r\ndf = pd.DataFrame({'text': ['SOME ANGRY TEXT!!!', 'Some friendly text :)'], 'label': [1, 0]})\r\n\r\ndef create_model():\r\n    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-cased\")\r\n    \r\n    input_ids = tf.keras.layers.Input(shape=(10,), dtype=tf.int32, name='input_ids')\r\n    token_type_ids = tf.keras.layers.Input((10,), dtype=tf.int32, name='token_type_ids')\r\n    attention_mask = tf.keras.layers.Input((10,), dtype=tf.int32, name='attention_mask')\r\n    \r\n    # Use pooled_output(hidden states of [CLS]) as sentence level embedding\r\n    pooled_output = bert_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})[1]\r\n    x = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\r\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n    model = tf.keras.models.Model(inputs={'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids}, outputs=x)\r\n    return model\r\n\r\nbert_model = create_model()\r\nbert_tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-cased\")\r\n\r\nx = bert_tokenizer.batch_encode_plus(\r\n    df.text.values,\r\n    max_length=10,\r\n    pad_to_max_length=True, \r\n    return_tensors='tf'\r\n)\r\n\r\nbert_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Accuracy'])\r\n\r\nbert_history = bert_model.fit(\r\n    x=x,\r\n    y=df.label.values\r\n)\r\n```\r\n\r\nOutput:\r\n```\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __hash__(self)\r\n    724     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\r\n    725         (g is None or g.building_function)):\r\n--> 726       raise TypeError(\"Tensor is unhashable. \"\r\n    727                       \"Instead, use tensor.ref() as the key.\")\r\n    728     else:\r\n\r\nTypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.\r\n```\r\nAfter that I just tried to use [this working Kaggle notebook](https://www.kaggle.com/definedennis/pretrained-bert-with-huggingface-tensorflow-2-1/output)(it's working because it has output genarated on the Kaggle side, `train.csv` - [file from here](https://www.kaggle.com/c/nlp-getting-started/data)):\r\n```\r\n# This Python 3 environment comes with many helpful analytics libraries installed\r\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\r\n# For example, here's several helpful packages to load in \r\n\r\nimport numpy as np # linear algebra\r\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import classification_report\r\nfrom tqdm.notebook import tqdm\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.utils import plot_model\r\nfrom transformers import (\r\n    BertTokenizer,\r\n    TFBertForSequenceClassification,\r\n    TFBertModel,\r\n    BertConfig,\r\n)\r\ntf.__version__\r\n\r\nMAX_SEQUENCE_LENGTH = 255\r\nPRETRAINED_MODEL_NAME = 'bert-base-uncased'\r\nBATCH_SIZE = 32\r\n\r\ndf = pd.read_csv('train.csv')\r\n\r\ndf.head()\r\n\r\ndf['target'].value_counts()\r\n\r\ndf.isnull().sum()\r\n\r\ndata = df['text'].values\r\ntargets = df['target'].values\r\n\r\ndef create_model():\r\n    bert_model = TFBertModel.from_pretrained(PRETRAINED_MODEL_NAME)\r\n    \r\n    input_ids = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')\r\n    token_type_ids = layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='token_type_ids')\r\n    attention_mask = layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='attention_mask')\r\n    \r\n    # Use pooled_output(hidden states of [CLS]) as sentence level embedding\r\n    pooled_output = bert_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})[1]\r\n    x = layers.Dropout(rate=0.1)(pooled_output)\r\n    x = layers.Dense(1, activation='sigmoid')(x)\r\n    model = keras.models.Model(inputs={'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids}, outputs=x)\r\n    return model\r\n\r\ntokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\r\nmodel = create_model()\r\n\r\nmodel.summary()\r\n\r\nplot_model(model, to_file='model.png', expand_nested=True, show_shapes=True)\r\n\r\nopt = tf.keras.optimizers.Adam(learning_rate=3e-5)\r\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\r\n\r\nX_train, X_val, y_train, y_val = train_test_split(data, targets, test_size=0.33, random_state=42, stratify=targets)\r\n\r\nX_train = tokenizer.batch_encode_plus(X_train, max_length=MAX_SEQUENCE_LENGTH, pad_to_max_length=True, return_tensors='tf')\r\nX_val = tokenizer.batch_encode_plus(X_val, max_length=MAX_SEQUENCE_LENGTH, pad_to_max_length=True, return_tensors='tf')\r\n\r\nhistory = model.fit(\r\n    x=X_train,\r\n    y=y_train,\r\n    validation_data=(X_val, y_val),\r\n    epochs=3,\r\n    batch_size=BATCH_SIZE\r\n)\r\n```\r\n\r\nOutput:\r\n```\r\n/usr/lib/python3.8/_collections_abc.py in update(self, other, **kwds)\r\n    835                 self[key] = other[key]\r\n    836         else:\r\n--> 837             for key, value in other:\r\n    838                 self[key] = value\r\n    839         for key, value in kwds.items():\r\n\r\nValueError: too many values to unpack (expected 2)\r\n``` \r\n\r\nSo, what is the problem and how can I fix it?", "comments": ["@don-prog \r\nPlease share code with all dependencies for us to replicate it, i ran the code and face different error, please find [gist here](https://colab.research.google.com/gist/Saduf2019/1138485a529412b2c195a56262915965/untitled272.ipynb).\r\nAs per error please refer to below issues:\r\n#35673 #37497 #31758 ##35127 [link](https://makerspace.aisingapore.org/community/ai4i-7-deep-learning/typeerror-tensor-is-unhashable-instead-use-tensor-ref-as-the-key/)", "@Saduf2019 thanks, but I already checked the other answers, nothing helped me. You didn't installed the mentioned `transformer` dependency, so you face this error. \r\nPlease check [this](https://colab.research.google.com/drive/1DT6lSWRZ3CIIm9noaJxPYjtOavWQB23S?usp=sharing) and [this](https://colab.research.google.com/drive/125jJ0qrXGIe6goNrH_Ja7XPZtYp7nMXU?usp=sharing) gists for reproduction of the errors.\r\n", "@Saduf2019 do you have progress with these issues?", "@gowthamkpr please, can you provide a fix for these issues? I've been waiting a week.", "@Saduf2019 are you sure that @gowthamkpr knows about his assignment on this issue?", "@don-prog Please grant me the requests of your gists and also please make them public. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@gowthamkpr sorry, I thought that I changed access rules, now they are public.", "@don-prog This issue is not related to a bug/performance or feature request. Can you please post this in stackoverflow where there is a wider community to respond. Take a look at this fix [here](https://github.com/huggingface/transformers/pull/3683). Looks like this is a transformers issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41204\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41204\">No</a>\n"]}, {"number": 41203, "title": "Add expiring_lru_cache", "body": "@mihaimaruseac \r\nThis PR adds `expiring_lru_cache` will be used to cache `get_matching_path`, `get_childrens`, `stat`, ...\r\nI think this PR is good to go because I only copy the current implementation without any significant changes but only:\r\n- `status` to `TF_Status`\r\n- `\"absl/base/thread_annotations.h\"`\r\n- `absl::Mutex`\r\n- `absl::MutexLock`\r\n\r\nAbout the test, to make sure it works, I keep almost everything, only `status` to `TF_Status`.\r\n\r\nBut this won't be used until I refactor the GCS filesystem ( PR #41192 ).", "comments": ["@mihaimaruseac \r\n`Ubuntu Sanity` failed because of this.\r\n```\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\ntensorflow/c/experimental/filesystem/plugins/gcs/BUILD:\r\n96,99c96,99\r\n<          \"//tensorflow/c:tf_status\",\r\n<          \"//tensorflow/c:env\",\r\n<          \"@com_google_absl//absl/base\",\r\n<          \"@com_google_absl//absl/synchronization\",\r\n---\r\n>         \"//tensorflow/c:env\",\r\n>         \"//tensorflow/c:tf_status\",\r\n>         \"@com_google_absl//absl/base\",\r\n>         \"@com_google_absl//absl/synchronization\",\r\nexit status 1\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```\r\nCould you fix it for me when importing to the internal code, so we don't have to run the CI again.\r\nThank you.", "The two target to be sorted alphabetically.\r\n\r\nI'll do a manual import early tomorrow", "Thank you !", "I imported the change now, fixed the sanity issue. There is a coding style linter error that I also fixed, but we need to remember in the future:\r\n\r\nCoding style disallows `using namespace foo`, it only allows `using short=name_of_very_long_namespace` or reopening the namespace again. That's what I did.\r\n\r\nThere was also a build failure since the `absl` dependency as written does not include the `thread_annotations.h` header. I replaced `//third_party/absl/base` with `//third_party/absl/base:core_headers`.", "Actually, I had to fully qualify the class", "Thank you. I would like to ask why the outside `tf_cc_test` is success build but it failed internally with `absl`", "Internally the Bazel equivalent imposes a strict layering rule. If a C++ file includes a header H then the corresponding `BUILD` target should include as dependency a target that exposes H directly.\r\n\r\nExternally, this is not the case, transitive headers can be used freely in (almost) all conditions.\r\n\r\nActually, there are cases where the internal code works fine but exporting externally needs to add a few more dependencies too. Two build systems that are somewhat different.", "Thank you. I have fixed the namespace and header errors in #41235 so you dont have to import manually."]}, {"number": 41202, "title": "Dask and Tensorflow Compatibility", "body": "There was a package called dask_tensorflow which is currently archived but they stated there are many way to get dask to work with tensorflow. \r\nSo I thought I'd try it with the mnist model as follow:\r\n```\r\n%load_ext tensorboard\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport datetime\r\nimport matplotlib.pyplot as plt x\r\n\r\nEPOCHS = 50\r\nBATCH_SIZE = 128\r\nN_HIDDEN = 128\r\nVALIDATION_SPLIT = 0.2\r\nVERBOSE = 1\r\nDROPOUT= 0.3\r\nNB_CLASSES = 10\r\nRESHAPED = 784\r\n\r\nmnist = keras.datasets.mnist\r\n\r\n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\r\n\r\nY_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\r\nY_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\r\n\r\nimport dask.array as da\r\nimport numpy as np\r\nimport joblib\r\n\r\nX_train = X_train.reshape(60000, RESHAPED)\r\nX_test = X_test.reshape(10000, RESHAPED)\r\nX_train = X_train.astype('float32')\r\nX_test = X_test.astype('float32')\r\n\r\nX_train /= 255\r\nX_test /= 255\r\nprint(X_train.shape[0],'train samples')\r\nprint(X_test.shape[0], 'test samples')\r\n\r\nX_train = da.from_array(np.asarray(X_train))\r\nY_train = da.from_array(np.asarray(Y_train))\r\nX_test = da.from_array(np.asarray(X_test))\r\nY_test = da.from_array(np.asarray(Y_test))\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(keras.layers.Dense(NB_CLASSES,\r\n                             input_shape = (RESHAPED,),\r\n                             kernel_initializer = 'zeros',\r\n                             name = 'dense_layer',\r\n                             activation ='softmax'))\r\n\r\nmodel.compile(optimizer ='SGD',\r\n             loss= 'categorical_crossentropy',\r\n             metrics = ['accuracy'])\r\n\r\nwith joblib.parallel_backend('dask'):\r\n        model.fit(X_train,Y_train,\r\n                  batch_size = BATCH_SIZE,\r\n                  epochs = EPOCHS, \r\n                  verbose = VERBOSE, \r\n                  validation_split = VALIDATION_SPLIT)\r\n```\r\n\r\nBut I get an error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-28-2b3bc3bdb162> in <module>\r\n      4                   epochs = EPOCHS,\r\n      5                   verbose = VERBOSE,\r\n----> 6                   validation_split = VALIDATION_SPLIT)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1034           data_adapter.train_validation_split((x, y, sample_weight),\r\n   1035                                               validation_split=validation_split,\r\n-> 1036                                               shuffle=False))\r\n   1037 \r\n   1038     with self.distribute_strategy.scope(), \\\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py in train_validation_split(arrays, validation_split, shuffle)\r\n   1393     raise ValueError(\r\n   1394         \"`validation_split` is only supported for Tensors or NumPy \"\r\n-> 1395         \"arrays, found following types in the input: {}\".format(unsplitable))\r\n   1396 \r\n   1397   if all(t is None for t in flat_arrays):\r\n\r\nValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'dask.array.core.Array'>, <class 'dask.array.core.Array'>]\r\n\r\n```\r\nDoes this mean tensorflow 2.0 no longer supports working with Dask Arrays?", "comments": ["@vinhdiesal \r\nI have tried in colab with TF versions 2.2, 2.3-rc1 and i am seeing the error (`ValueError: To use Joblib with Dask first create a Dask Client`).Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/fcf5aa8a170b71be75fa41da3c66b820/untitled97.ipynb).Thanks!", "You need to connect to a client. \r\nTry inserting the following at the beginning\r\n\r\n```\r\nfrom dask.distributed import Client`\r\nclient = Client()\r\nclient\r\n```\r\n", "@vinhdiesal \r\n\r\nI tried adding above piece of code. I am seeing the error(`TimeoutError: Worker failed to start`).please, find the gist [here.](https://colab.research.google.com/gist/ravikyram/41ac680f26f1446b735d9b112839d678/untitled108.ipynb#scrollTo=MYqID9zZ-tQo)Thanks!"]}]