[{"number": 52585, "title": "Revert \"Disabling some tests as they fail with numpy 1.20\"", "body": "Reverts tensorflow/tensorflow#52582", "comments": []}, {"number": 52584, "title": "Fixes nightly breakage by falling back from a fast path to a slow pat\u2026", "body": "\u2026h in _assertAllCloseRecursive when NotImplementedError is raised. Also rolls back a previous fix on a upper level.\r\n\r\nPiperOrigin-RevId: 403213148\r\nChange-Id: I7e94aeb729d6a2351121156f8621e6f5d29e3d67", "comments": []}, {"number": 52583, "title": "Adding back setting quantization ranges for ConvertRelu6 ", "body": "Fixes accuracy regression with MobilenetV2 i.e. set relu6 output tensor dynamic range to (0, 6)\r\n\r\nAccuracy regression was introduced by https://github.com/tensorflow/tensorflow/commit/b4ae795b6b6f43249cdb72c33053652c9440b88e. \r\n\r\nThis was earlier part of https://github.com/tensorflow/tensorflow/pull/52342. Pulling the change early for TF 2.7.0.\r\n\r\nCC: @DEKHTIARJonathan, @meena-at-work,  and @bixia1\r\n", "comments": []}, {"number": 52582, "title": "Disabling some tests as they fail with numpy 1.20", "body": "PiperOrigin-RevId: 404397416\r\nChange-Id: Ia16b6e548edaa9c60a8807b378ddfedba606ca19", "comments": []}, {"number": 52581, "title": "Lowering dynamic case of tfl.split to tosa", "body": "In the dynamic case we can handle the split by using reshapes and splits. This\r\nallows splitting across the dynamic dimension though it assumes the dimension\r\ncan be legally split.", "comments": []}, {"number": 52580, "title": "Change test due to np.unique() changing behavior in 1.21.0+", "body": "PiperOrigin-RevId: 401110732\r\nChange-Id: Ida039b86a10aab92696efc192a325816d326ccc0", "comments": []}, {"number": 52579, "title": "Element-wise add and multiply operations are performed on CPU instead of GPU which bring about remarkable overhead", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.4.1**\r\n- Python version: **Python 3.6.9**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **11.4**\r\n- GPU model and memory: NVIDIA GeForce 1080Ti, 11176MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI built a model based on tf.function and its runtime inference performance is very important for us. While using Tensorboard to profile the model inference time on GPU, I found the element-wise add and multiply operations are performed on CPU instead of GPU, which cause a remarkable overhead. Here's the codes of element-wise operations in the model:\r\n```python\r\nstate = tf.gather(input_text, indices=indices, axis=1)\r\nstate = tf.math.add(state, byte_indices)\r\nbox = tf.gather(box, indices=state)\r\n# more tf.gather and bit-wise operations\r\n```\r\nTo run the model on GPU, I used:\r\n```python\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n          profile_inference()\r\n```\r\nWith Tensorboard, I got the profile UI as below. The state = tf.math.add(state, byte_indices) is done on CPU not GPU and it cause unexpected memory copy overhead.\r\n![profile_with_explaination](https://user-images.githubusercontent.com/39686450/137975832-d97f04f2-cdff-4d70-9fd2-80efedd7759e.png)\r\n\r\nIs there any way to force the element-wise operations, especially add and multiply, work on GPU?\r\n", "comments": ["After commenting the element-wise add operation, I got another profile UI as follows:\r\n![Untitled (1)](https://user-images.githubusercontent.com/39686450/137976007-2632730c-20fc-4a40-a0c0-6c28560bbd8d.png)\r\nAs you can see, the overhead of add operation disappears.", "What is the type of tensors being passed to tf.math.add? \r\n\r\n```\r\nstate = tf.math.add(state, byte_indices)\r\n```\r\n\r\ni.e. what is the dtype of state and byte_indices? If these are int32 or string etc., we run them on the CPU then.", "Both state and byte_indices are in tf.int32. They are 2D tensors.\r\n", "Sorry for this issue.  Unfortunately, TensorFlow today has a device placement logic issue that forces int32 computations to CPU.  We have a long term plan to address this but meantime, there are two workarounds:\r\n\r\n- Using int64 type instead\r\n- Using `@tf.functiom(jit_compile=True)`", "Thanks for the suggestions!"]}, {"number": 52578, "title": "r2.7 cherry-pick request: Fixing Mac build issue", "body": "Fix a Mac build issue that was caused by https://github.com/tensorflow/tensorflow/pull/52326.\r\nError message:\r\n```\r\ntensorflow/core/common_runtime/eager/execute.cc:1192:7: error: use of undeclared identifier 'IsMKLEnabled'; did you mean 'IsMklEnabled'?\r\n  if (IsMKLEnabled() && kernel != nullptr && !ctx.RunEagerOpAsFunction() &&\r\n      ^~~~~~~~~~~~\r\n      IsMklEnabled\r\n./tensorflow/core/util/port.h:45:6: note: 'IsMklEnabled' declared here\r\nbool IsMklEnabled();\r\n     ^\r\n```\r\n\r\nOriginal fix PR (merged into master): https://github.com/tensorflow/tensorflow/pull/52551", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52578) for more info**.\n\n<!-- need_author_consent -->", "Manually setting CLA to yes since the commit is from a PR (#52551) that is already merged into master."]}, {"number": 52577, "title": "r2.7 cherry-pick request: Update oneDNN version for aarch64 backend", "body": "Original PR (merged into master): https://github.com/tensorflow/tensorflow/pull/52518\r\n\r\n> Updates oneDNN version used for `--config=mkl_aarch64` to v2.4, enabling removal of the big patch file.\r\n> \r\n> Updates Compute Library (used as optimised oneDNN backend on AArch64) to the latest release (21.08).\r\n> \r\n> This enables support for SVE and BF16 kernels where\r\nhardware supports. It provides a performance uplift of between 1.4x and 3x\r\ndepending on the hardware support.\r\n> \r\n> NOTE: AArch64 build with --config=mkl_aarch64 requires GCC 10.\r\n\r\n", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52577) for more info**.\n\n<!-- need_author_consent -->", "Manually setting CLA to yes since the commit is from a PR (#52518) that is already merged into master.", "Hi @penpornk, @mihaimaruseac \r\n\r\nI notice the 2.7 RC1 is now out, and this cherry-pick didn't make the cut - as I understand it there's unlikely to be an RC2 (correct me if I'm wrong), so is there still a possibility of picking these changes up for the 2.7 release?", "Hi. The PR was too late for RC1, but will be merged now", "Excellent - thanks for your help @mihaimaruseac (and @penpornk, of course!)"]}, {"number": 52575, "title": "TF estimator train_and_evaluate: loss = None and model does not train", "body": "Hi guys, I am working on a premade estimator model of tensorflow (DNNRegressor) in an old tensorflow version. I already found some similar issues but their solution didnt work out for me (they said it would be solved by setting max_steps to None). \r\n\r\nTF version: 1.15.1\r\n\r\n```\r\ntrain_spec = tf.estimator.TrainSpec(\r\n    input_fn=lambda: read_train(data_folder, params),\r\n    max_steps=None)\r\n```\r\nmax_steps was 1400000 before and i tried now to set it to None, but it didnt work for me. My input pipeline looks like this:\r\n```\r\nclvf = CLVFeatures(ignore_crosses=True)\r\n\r\ndef parse_csv(csv_row):\r\n  columns = tf.decode_csv(csv_row, record_defaults = clvf.get_all_defaults())\r\n  features = dict(zip(clvf.get_all_names(), columns))\r\n  \r\n  for column_name in clvf.get_unused():\r\n    features.pop(column_name)\r\n\r\n  target = features.pop(clvf.get_target_name())\r\n\r\n  return features, target\r\n\r\n#@tf.function\r\ndef dataset_input_fn(data_folder, prefix=None, mode=None, params=None, count=None):\r\n  shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\r\n\r\n  filenames = tf.matching_files('{}{}*.csv'.format(data_folder, prefix))\r\n  dataset = tf.data.TextLineDataset(filenames)#skip(1)\r\n  dataset = dataset.map(parse_csv)\r\n  if shuffle:\r\n    dataset = dataset.shuffle(buffer_size=params.buffer_size)\r\n  dataset = dataset.repeat(count=count)\r\n  dataset = dataset.batch(params.batch_size)\r\n\r\n  iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)#tf.compat.v1.data.make_one_shot_iterator(dataset)/#tf.compat.v1.data.make_initializable_iterator(dataset)\r\n  \r\n  features, target = iterator.get_next()\r\n\r\n  return features, target\r\n\r\ndef read_train(data_folder, params):\r\n  return dataset_input_fn(\r\n      data_folder=data_folder,\r\n      prefix='train',\r\n      params=params,\r\n      mode=tf.estimator.ModeKeys.TRAIN)\r\n\r\n\r\ndef read_eval(data_folder, params):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='eval',\r\n                          params=params)\r\n\r\n\r\ndef read_test(data_folder, params):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='test',\r\n                          params=params,\r\n                          count=1)\r\n```\r\n\r\nI would appreciate some help, so much. This is for school haha thank you!", "comments": ["@timmy-ops ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to latest stable v2.6 or v2.5 and let us know if you are using same issue.Thanks!", "@tilakrayal ,\r\nHi! Thank you for your answer. I solved this issue last night, it was not the version of TF.\r\nI gave my data_folder to the model like this:\r\n```\r\ndata_folder = '{}'/.format(data_src)\r\n```\r\nand the data_src itself like this:\r\n```\r\ndata_src = '/content/DNNs_for_CLVs/'\r\n```\r\nwhich produced the path: /content/DNNs_for_CLVs//\r\nThat was the issue.\r\n\r\nThe thing is that I have to reproduce the following: [Google: Compute CLV with DNNs](https://cloud.google.com/architecture/clv-prediction-with-offline-training-train#cleaning_the_data)\r\nand it is a bit older, so in Tensorflow 1. I built it already in Tensorflow 2 in my own way but was facing the same results, like in this example here with Tensorflow 1:\r\n```\r\n'average_loss': 17710520.0,\r\n 'global_step': 12362,\r\n 'label/mean': 3189.7307,\r\n 'loss': 87154410.0,\r\n 'prediction/mean': 0.2885886,\r\n 'rmse': 4208.3867}\r\n```\r\nThe rmse is always like this, but should be about 900 in the end.\r\nI will reference in a new issue: \r\n\r\n[Following machine learning tutorial of Google gives wrong results #52590](https://github.com/tensorflow/tensorflow/issues/52590#issue-1031181072)\r\n", "@timmy-ops ,\r\nGlad the issue resolved for you.Please feel free to close this issue and #52590 will tracking there as another issue.It helps to reduce the duplicacy.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52575\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52575\">No</a>\n"]}, {"number": 52574, "title": "No tf-nightly pip packages for MacOS available after 2021/09/22", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 11.7\r\n- TensorFlow version: tf-nightly\r\n- Python version: 3.9.4\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n**Describe the problem**\r\n\r\ntf-nightly pip packages seem to be missing MacOS builds after 2021/09/22. Trying `pip install --upgrade tf-nightly` installs version 2.7.0.dev20210922.\r\n\r\nTrying to explicitly install a more recent version with `pip install --upgrade tf-nightly==2.8.0.dev20211019` fails as follows:\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tf-nightly==2.8.0.dev20211019 (from versions: 2.6.0.dev20210611, 2.6.0.dev20210612, 2.6.0.dev20210613, 2.6.0.dev20210614, 2.6.0.dev20210615, 2.6.0.dev20210616, 2.6.0.dev20210617, 2.6.0.dev20210618, 2.6.0.dev20210619, 2.6.0.dev20210622, 2.6.0.dev20210623, 2.6.0.dev20210624, 2.6.0.dev20210625, 2.7.0.dev20210626, 2.7.0.dev20210627, 2.7.0.dev20210628, 2.7.0.dev20210629, 2.7.0.dev20210630, 2.7.0.dev20210701, 2.7.0.dev20210702, 2.7.0.dev20210703, 2.7.0.dev20210704, 2.7.0.dev20210705, 2.7.0.dev20210706, 2.7.0.dev20210707, 2.7.0.dev20210708, 2.7.0.dev20210709, 2.7.0.dev20210710, 2.7.0.dev20210711, 2.7.0.dev20210712, 2.7.0.dev20210713, 2.7.0.dev20210714, 2.7.0.dev20210715, 2.7.0.dev20210716, 2.7.0.dev20210717, 2.7.0.dev20210718, 2.7.0.dev20210719, 2.7.0.dev20210720, 2.7.0.dev20210721, 2.7.0.dev20210722, 2.7.0.dev20210723, 2.7.0.dev20210724, 2.7.0.dev20210725, 2.7.0.dev20210726, 2.7.0.dev20210727, 2.7.0.dev20210728, 2.7.0.dev20210729, 2.7.0.dev20210730, 2.7.0.dev20210731, 2.7.0.dev20210801, 2.7.0.dev20210802, 2.7.0.dev20210803, 2.7.0.dev20210804, 2.7.0.dev20210805, 2.7.0.dev20210806, 2.7.0.dev20210819, 2.7.0.dev20210820, 2.7.0.dev20210821, 2.7.0.dev20210822, 2.7.0.dev20210823, 2.7.0.dev20210824, 2.7.0.dev20210825, 2.7.0.dev20210827, 2.7.0.dev20210828, 2.7.0.dev20210829, 2.7.0.dev20210830, 2.7.0.dev20210831, 2.7.0.dev20210901, 2.7.0.dev20210902, 2.7.0.dev20210903, 2.7.0.dev20210904, 2.7.0.dev20210905, 2.7.0.dev20210906, 2.7.0.dev20210907, 2.7.0.dev20210908, 2.7.0.dev20210909, 2.7.0.dev20210910, 2.7.0.dev20210911, 2.7.0.dev20210912, 2.7.0.dev20210913, 2.7.0.dev20210914, 2.7.0.dev20210915, 2.7.0.dev20210916, 2.7.0.dev20210917, 2.7.0.dev20210918, 2.7.0.dev20210920, 2.7.0.dev20210921, 2.7.0.dev20210922)\r\nERROR: No matching distribution found for tf-nightly==2.8.0.dev20211019\r\n```\r\n\r\n**Any other info / logs**\r\nManually checking the [tf-nightly release files for 2021/09/22](https://pypi.org/project/tf-nightly/2.7.0.dev20210922/#files) does show a MacOSX build that is missing on the [23rd](https://pypi.org/project/tf-nightly/2.7.0.dev20210923/#files) and onwards.", "comments": ["Hi @leandro-gracia-gil ! Did you try with below command . \r\n`pip install tf-nightly`", "@mohantym of course I did. And I also tried to uninstall and install it again, and I also made sure that pip was up to date.\r\n\r\nThis is unlikely a pip issue. If you check the bottom links I provided you can see that there's simply no macosx whl file available after that date. The real question is why they are missing.", "Hi @sachinprasadhs ! Could you look at this issue!", "Hi, It is a known issue on which team is working on it, till then you can use the version for which the MacOS .whl file is avaiable. Thank You.", "@sachinprasadhs I see, thanks for the reply.\r\n\r\nUnfortunately the last available macosx whl file seems to be missing support for multiple signatures in TFLite models, which I need. Are there any estimates on when 2.7.0 will be released? It has been on rc0 for a couple of weeks already.", "This is a known issue. Build was broken at that date and the build gardeners failed to notice this and react on it.\r\n\r\n#52598 is an attempt at fixing this but given the long time since the failure we might need weeks to fix this ", "We can close this https://pypi.org/project/tf-nightly/#files", "I can confirm I was able to get the latest version now from pip. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52574\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52574\">No</a>\n"]}, {"number": 52572, "title": "I Have this issue in Apple M1 ship that I can not run a training on GPU", "body": "\r\nI have MacBook Pro M1 ship and I face this issue when I start training with this as Benchmark \r\n\r\n\r\n\r\nmy code : \r\n```\r\n%%time\r\nimport tensorflow.compat.v2 as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntf.enable_v2_behavior()\r\n\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\ndisable_eager_execution()\r\n\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ndef normalize_img(image, label):\r\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n  return tf.cast(image, tf.float32) / 255., label\r\n\r\nbatch_size = 128\r\n\r\nds_train = ds_train.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(batch_size)\r\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nds_test = ds_test.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_test = ds_test.batch(batch_size)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n#   tf.keras.layers.Dropout(0.25),\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n#   tf.keras.layers.Dropout(0.5),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\nmodel.compile(\r\n    loss='sparse_categorical_crossentropy',\r\n    optimizer=tf.keras.optimizers.Adam(0.001),\r\n    metrics=['accuracy'],\r\n)\r\n\r\nmodel.fit(\r\n    ds_train,\r\n    epochs=12,\r\n    validation_data=ds_test,\r\n)\r\n\r\n```\r\n\r\n\r\n\r\nBug:\r\n\r\n```\r\n\r\nMetal device set to: Apple M1\r\nWARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-10-19 13:11:41.757046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-19 13:11:41.757319: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\nWARNING:tensorflow:AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function normalize_img at 0x14a760dc0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function normalize_img at 0x14a760dc0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-10-19 13:11:41.892468: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-10-19 13:11:41.892489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n2021-10-19 13:11:41.897826: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\n2021-10-19 13:11:41.980346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:41.991484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.018471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.032453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.095177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.110084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.132235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.149814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-10-19 13:11:42.168231: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n```", "comments": ["@araby123 , there is a separate repo for tensorflow version which you can run on GPU. You can read more about it [here](https://developer.apple.com/metal/tensorflow-plugin/).", "@araby123 ,\r\nCan you please provide the tensorflow version you are using.It helps to analyse the issue.Also please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/52055) with the similar error.Thanks!", "> @araby123 ,\r\n> Can you please provide the tensorflow version you are using.It helps to analyse the issue.Also please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/52055) with the similar error.Thanks!\r\n\r\nTry it and still the same the kernel crash with same error\r\n\r\nAM using TensorFlow version \r\n```\r\n\r\nTensor Flow Version: 2.6.0\r\nKeras Version: 2.6.0\r\n\r\nPython 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \r\n[Clang 11.1.0 ]\r\nPandas 1.3.4\r\nScikit-Learn 1.0\r\nGPU is available\r\n```\r\n\r\n\r\nwhat I do : \r\n```\r\n\r\n%%time\r\nimport tensorflow.compat.v2 as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntf.enable_v2_behavior()\r\ntf.autograph.set_verbosity(10)\r\n\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\ndisable_eager_execution()\r\n\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ndef normalize_img(image, label):\r\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n  return tf.cast(image, tf.float32) / 255., label\r\n\r\nbatch_size = 128\r\n\r\nds_train = ds_train.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(batch_size)\r\nds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nds_test = ds_test.map(\r\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\nds_test = ds_test.batch(batch_size)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\r\n                 activation='relu'),\r\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n#   tf.keras.layers.Dropout(0.25),\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n#   tf.keras.layers.Dropout(0.5),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\nmodel.compile(\r\n    loss='sparse_categorical_crossentropy',\r\n    optimizer=tf.keras.optimizers.Adam(0.001),\r\n    metrics=['accuracy'],\r\n)\r\n\r\nmodel.fit(\r\n    ds_train,\r\n    epochs=12,\r\n    validation_data=ds_test,\r\n)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">No</a>\n", "> @araby123 , there is a separate repo for tensorflow version which you can run on GPU. You can read more about it [here](https://developer.apple.com/metal/tensorflow-plugin/).\r\n\r\nYeah I use this steps to make it installed successfully even TensorFlow installed and you can train with it sometime it give some warnings  , but when you try to train with GPU it will say unavailable  so I use this step down I mention here and it give me GPU available \r\n\r\nas you see\r\n```\r\n\r\ngpu = len(tf.config.list_physical_devices('GPU'))>0\r\n>>> print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\r\nGPU is available\r\n```\r\n\r\nbut when you just try to train with GPU above bug will come up to you and crash the kernel\r\n\r\n[this step that I use to make GPU enable ](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb)\r\n", ">  sorry to close by mistake \r\n\r\n", "@araby123 ,\r\nIssues related to tensorflow_macos  Garden are tracked in [apple/tensorflow_macos](https://github.com/apple/tensorflow_macos/issues) repo.Could you please submit a new issue and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Done I do it there with this link https://developer.apple.com/forums/thread/693314", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">No</a>\n", "really until now am not able to solve this issue ", "@araby123 ,\r\nIssues related to tensorflow_macos Garden are tracked in apple/tensorflow_macos repo.Please post in respective repo.Thanks!", "> @araby123 ,\r\n> Issues related to tensorflow_macos Garden are tracked in apple/tensorflow_macos repo.Please post in respective repo.Thanks!\r\n\r\n@tilakrayal kindly I go as you mention its archived I can not post a issue there \r\n<img width=\"596\" alt=\"Screen Shot 2021-11-23 at 4 43 57 PM\" src=\"https://user-images.githubusercontent.com/7244313/143035394-9ce16729-e189-481e-a2f3-d5d42a6529ec.png\">\r\n\r\n", "@araby123 ,\r\nThis issue is not related tensorflow.Please re-visit the older related issues in macOS repo, Apple discussion [forum](https://developer.apple.com/forums/) .It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52572\">No</a>\n"]}, {"number": 52571, "title": "Indexing into tf.shape(...) is broken when operating on KerasTensors (i.e. during Functional model building)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 (also Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary (also Colab)\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.7.2\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):  N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nCalling tf.shape(...) on a tensor in a layer call, and then indexing into the shape (to get the inferred value at, e.g. the last dimension) returns None, even if the full shape is known.\r\n\r\n**Describe the expected behavior**\r\n\r\nWe should be able to index into shapes acquired this way.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n[Colab Link](https://colab.research.google.com/drive/1GmIBQegnYN2N03BIDFu7kUe0XSiYt-4L?usp=sharing)\r\n\r\n```\r\nimport sys\r\nprint(\"Python {}\".format(sys.version))\r\nimport tensorflow as tf\r\nprint(\"Tensorflow {}\".format(tf.__version__))\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.layers import Input\r\n\r\nX = Input(shape=(4,))\r\n\r\nx_shape = tf.shape(X)\r\nfeature_dim = tf.shape(X)[-1]\r\n# Other ways of calculating\r\nbackend_dim = K.shape(X)[-1]\r\nget_shape_dim = X.get_shape()[-1]\r\nas_list_dim = X.shape.as_list()[-1]\r\n\r\nprint(x_shape)\r\nprint(feature_dim)\r\nprint(x_shape[-1])\r\nprint(backend_dim)\r\nprint(get_shape_dim)\r\nprint(as_list_dim)\r\n```\r\n", "comments": ["Hi @wbeardall ,Could you check out this [thread](https://github.com/keras-team/keras/issues/5041) for getting  shape of keras tensors. ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52571\">No</a>\n"]}, {"number": 52570, "title": "[NNAPI]Fix error in axis of reduce_mean.", "body": "1. create TensorFlow model.\r\n```python\r\ntf.reduce_mean(x, 0)\r\n```\r\n1. convert to TensorFlow lite model.\r\n1. execute in NNAPI delegate.\r\n1. error occurred.\r\n   `E/tflite: NN API returned error ANEURALNETWORKS_BAD_DATA at line 1465 while setting new operand value from memory for tensor XXX.`", "comments": []}, {"number": 52569, "title": "AttributeError: 'Tensor' object has no attribute 'values' in TensorFlow version: 2.7.0-dev20210922", "body": "TensorFlow version: 2.7.0-dev20210922\r\n\r\nI was testing the code from : https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\r\n\r\nAfter this line: \r\n\r\ntrain_dataset = train_dataset.map(pack_features_vector)\r\nfeatures, labels = next(iter(train_dataset))\r\n\r\nI got this error: \r\n\r\nAttributeError: in user code:\r\n\r\n    File \"<ipython-input-11-b2720b65aaf7>\", line 3, in pack_features_vector  *\r\n        features = tf.stack(list(features.values()), axis=1)\r\n\r\n    AttributeError: 'Tensor' object has no attribute 'values'\r\n\r\nIt was okay with tf 2.6.0. \r\n\r\n", "comments": ["@maryamxasghari \r\nCould you please try this on colab and share a gist with us if you still face the issue.", "@Saduf2019 As I mentioned before It is okay with tf 2.6.0. So it is okay in colab since the tf version in colab is 2.6.0. But with TensorFlow version: 2.7.0-dev20210922 it will gave that error. ", "@Saduf2019 I uninstalled Tf-nightly but after that tf wasn't working anymore, So I installed tf-nightly again and this time with the new version :  TensorFlow version: 2.8.0-dev20211019 the error is gone. \r\n\r\nHow can I go back to regular tf 2.6.0 ? Uninstalling this tf-nightly wasn't helpful", "@maryamxasghari \r\nIs there any particular reason to use 2.6 as the issue is resolved in latest 2.8", "@Saduf2019 Not really but this wasn't my real issue. I was just testing a sample code to see how is everything working. I have a problem right now that I mentioned in https://github.com/tensorflow/tensorflow/issues/52366#issuecomment-945006275. I didn't update tf and I think this update happened when I updated the Cuda and cudnn. I still have the same problem and I don't know what to try to release the memory on the GPU. ", "@maryamxasghari \r\nWe cannot have two issues open for same issue, as gpu issue is tracked on  #52366, it will be addressed please move this to closed status as issue reported here is addressed.", "@Saduf2019 Sure. Thank you"]}, {"number": 52568, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": ["Fixing merge conflict in #52663"]}, {"number": 52567, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": ["Solving merge conflict in #52662"]}, {"number": 52566, "title": "Avoid buffer overflow when loading tensors with insufficient data fro\u2026", "body": "\u2026m checkpoints.\r\n\r\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\r\nprovide any bounds checking on its own, so the size is instead checked prior\r\nto passing unvalidated data to that function.\r\n\r\nPiperOrigin-RevId: 392971286\r\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "comments": ["Solving merge conflict in #52661"]}, {"number": 52565, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": ["Fixed conflict in #52659"]}, {"number": 52564, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": ["Solved conflict in #52658"]}, {"number": 52563, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": ["Merged in d44b1e34cd22ed234ce055635f6795211be62270"]}, {"number": 52562, "title": "prevent gpu memory allocation for MonitoredTrainingSession", "body": "I am trying to restrict GPU memory allocation in a MonitoredTrainingSession.\r\n\r\nThe methods of setting tf.GPUOptions as shown here: How to prevent tensorflow from allocating the totality of a GPU memory? do not work out in the case of MonitoredTrainingSession.\r\n\r\nI tried:\r\n`gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.1)\r\nconfig = tf.ConfigProto(allow_soft_placement=False,\r\n                        device_filters=filters,\r\n                        gpu_options=gpu_options)\r\n\r\nscaffold = tf.train.Scaffold(saver=tf.train.Saver(max_to_keep=100, keep_checkpoint_every_n_hours=.5))\r\n\r\nwith tf.train.MonitoredTrainingSession(\r\n                server.target,\r\n                is_chief=True,\r\n                checkpoint_dir=log_dir,\r\n                scaffold=scaffold,\r\n                save_checkpoint_secs=600,\r\n                save_summaries_secs=30,\r\n                log_step_count_steps=int(1e7),\r\n                config=config) as session:`\r\nDespite using tf.GPUOptions memory consumption is 10189MiB / 11175MiB", "comments": ["I have similar issue, Following here", "When I try to move following  code to the head of main function\uff0cthe problem could be fixed.\r\n`os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'\r\n os.environ['TF_LOCAL_DEVICE'] = f'/job:worker/task:{args.task_index}'\r\n os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(int(args.task_index)%8)`", "@BLue1881euLB ,\r\nAlso could you please try limiting GPU memory growth using any of the methods listed in this guide and check if it helps.\r\nhttps://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth.   Thanks!\r\n", "@BLue1881euLB I added this on top of my code but it didn't help\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\ngpu = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)", "> https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n\r\n@tilakrayal I have similar issue and I added on top of my code but it didn't help\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\ngpu = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n\r\nIs there any safe way to realize the GPU memory?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52562\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52562\">No</a>\n"]}, {"number": 52561, "title": "2.7.0rc1 build error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubnutu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.7.0rc1\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 4.2.1\r\n- GCC/Compiler version (if compiling from source):  gcc 9.3.0\r\n- CUDA/cuDNN version: 11.4/8.2\r\n- GPU model and memory: RTX3090 GDDR6X 24GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nconfigure with CUDA support\r\nbazel build --config=numa --config=nogcp //tensorflow/tools/pip_packages:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nERROR: /home/alan/.cache/bazel/_bazel_alan/166d89c2dc31e370baae784b1f517718/external/llvm-project/mlir/BUILD.bazel:2292:11: Compiling mlir/lib/Conversion/ShapeToStandard/ShapeToStandard.cpp failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/external/llvm-project/mlir/_objs/ShapeToStandard/ShapeToStandard.d ... (remaining 124 argument(s) skipped)\r\nIn file included from /usr/include/c++/9/bits/unique_ptr.h:37,\r\n                 from /usr/include/c++/9/memory:80,\r\n                 from external/llvm-project/mlir/include/mlir/Conversion/ShapeToStandard/ShapeToStandard.h:12,\r\n                 from external/llvm-project/mlir/lib/Conversion/ShapeToStandard/ShapeToStandard.cpp:9:\r\n/usr/include/c++/9/tuple: In instantiation of \u2018constexpr std::_Tuple_impl<_Idx, _Head, _Tail ...>::_Tuple_impl(std::_Tuple_impl<_Idx, _Head, _Tail ...>&&) [with long unsigned int _Idx = 0; _Head = mlir::Value; _Tail = {mlir::Value}]\u2019:\r\nexternal/llvm-project/mlir/lib/Conversion/ShapeToStandard/ShapeToStandard.cpp:85:53:   recursively required from \u2018constexpr std::tuple<_T1, _T2>::tuple(std::tuple<_T1, _T2>&&) [with _T1 = mlir::Value; _T2 = mlir::Value]\u2019\r\nexternal/llvm-project/mlir/lib/Conversion/ShapeToStandard/ShapeToStandard.cpp:85:53:   required from here\r\n/usr/include/c++/9/tuple:227:7: internal compiler error: in lookup_template_class_1, at cp/pt.c:9466\r\n  227 |       _Tuple_impl(_Tuple_impl&& __in)\r\n      |       ^~~~~~~~~~~\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "comments": ["another error without numa support\r\n```\r\nERROR: /mnt/data/repo/tensorflow/tensorflow/compiler/mlir/tensorflow/BUILD:436:15: Compiling tensorflow/compiler/mlir/tensorflow/ir/tf_ops_n_z.cc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_n_z/tf_ops_n_z.pic.d ... (remaining 226 argument(s) skipped)\r\nIn file included from tensorflow/compiler/mlir/tensorflow/ir/tf_ops_n_z.cc:3291:\r\nbazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/ir/tf_ops_n_z.cc.inc:22271:1: internal compiler error: Segmentation fault\r\n22271 | void ResourceApplyAdamOp::build(::mlir::OpBuilder &odsBuilder, ::mlir::OperationState &odsState, ::mlir::Value var, ::mlir::Value m, ::mlir::Value v, ::mlir::Value beta1_power, ::mlir::Value beta2_power, ::mlir::Value lr, ::mlir::Value beta1, ::mlir::Value beta2, ::mlir::Value epsilon, ::mlir::Value grad, bool use_locking, bool use_nesterov) {\r\n      | ^~~~\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "Hi @alanpurple !Did you check with  Python 3.6-3.9 and [tested configuration ](https://www.tensorflow.org/install/source_windows#gpu)for stable version 2.6 ?", "strangely I \"half\" succeeded building........\r\n\r\nevery time \"crosstool_wrapper_driver_is_not_gcc failed\" occurred, I then resumed building and build continued\r\n\r\nafter several resuming the build completed\r\n\r\n\r\n\r\nI think \"maybe\" this is not a problem of tensorflow itself\r\n\r\nmaybe ubuntu and cuda issue?", "Ok @alanpurple! Thanks for confirming the same. Attaching threads for reference for the above error . [Link1](https://github.com/tensorflow/tensorflow/issues/13481),[Link2](https://stackoverflow.com/questions/37313212/tensorflow-bazel-build-failing),[Link3](https://askubuntu.com/questions/749441/tensorflow-crosstool-wrapper-driver-is-not-gcc-failed-error-executing-command).Feel free to close this issue if it helped . Thanks!", "@mohantym \r\nnot at all...  those links are not related....", "Hi @sanatmpa1! Could you look at this issue!", "We don't yet have a tag for RC1. Can you check with the latest commit on the branch (or, if when you get to this there is a tag for rc1, use that tag please)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52561\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52561\">No</a>\n"]}, {"number": 52560, "title": "[TF-TRT] TrtGraphConverterV2 - Deprecating `conversion_params` in favor of direct arguments", "body": "@bixia1 @tfeher for review\r\n\r\nThis PR essentially deprecates: `TrtGraphConverterV2(conversion_params=params)` in favor of direct arguments like `TrtGraphConverterV2(precision_mode=TrtPrecisionMode.FP32,)`.\r\n\r\nEssentially this object `TrtConversionParams` was inherited from C++ and just complicates the API for no good reason.\r\n\r\nShall be removed. The change was made in a way that is backward compatible and shall not break any user code.", "comments": ["We will also need to add a release note to tensorflow/RELEASE.md\r\nAnd regenerate tools/api/golden/v2/tensorflow.experimental.tensorrt.-conversion-params.pbtxt", "@bixia1 how do you do this ?\r\n> And regenerate tools/api/golden/v2/tensorflow.experimental.tensorrt.-conversion-params.pbtxt\r\n", "PR updated, please review @bixia1 ", "Have you update RELEASE.md\r\nand follow instructions in tensorflow/tools/api/tests/README.txt to see if there is a need to update the test golden file ", "@DEKHTIARJonathan Can you please check @bixia1's comments and keep us posted ? Thanks!", "@bixia1 : I updated `tensorflow/RELEASE.md` and regenerated the golden API files.\r\n\r\nIf you prefer a different description for `tensorflow/RELEASE.md` please send me the exact message you would like.\r\n\r\nGood for final review", "@bixia1  I had to rebase due to a merge conflict. Can you re-approve ? Nothing has changed in this rebase.\r\nYou might need to ask kokoro to re-tag \"ready to pull\""]}, {"number": 52559, "title": "Use BuildTensorShapeBase when parsing unverified TensorShapes during \u2026", "body": "\u2026checkpoint loading.\r\n\r\nThis avoids crashing when the TensorShape has negative dimensions.\r\n\r\nPiperOrigin-RevId: 392769882\r\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4", "comments": []}, {"number": 52558, "title": "Use BuildTensorShapeBase when parsing unverified TensorShapes during \u2026", "body": "\u2026checkpoint loading.\r\n\r\nThis avoids crashing when the TensorShape has negative dimensions.\r\n\r\nPiperOrigin-RevId: 392769882\r\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4", "comments": []}, {"number": 52557, "title": "Issue created for Rollback of PR #52553: Update Readme - Test PR Notification Change", "body": "Merged PR #52553 is rolled back in 37e47aca9c5dcbb6d27093b9550d4f0b1cca3307.\n    Please follow up with the reviewer and close this issue once its resolved.", "comments": []}, {"number": 52556, "title": "Use BuildTensorShapeBase when parsing unverified TensorShapes during \u2026", "body": "\u2026checkpoint loading.\r\n\r\nThis avoids crashing when the TensorShape has negative dimensions.\r\n\r\nPiperOrigin-RevId: 392769882\r\nChange-Id: Id1f7ae7fcf8142193556af47abfda81b13d3cce4", "comments": []}, {"number": 52555, "title": "Issue created for Rollback of PR #52553: Update Readme - Test PR Notification Change", "body": "Merged PR #52553 is rolled back in e98b052c08e5d1e7906ac2f6caf95c51a1e04985.\n    Please follow up with the reviewer and close this issue once its resolved.", "comments": []}, {"number": 52554, "title": "Update version numbers for TensorFlow 2.7.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 7 -> 7\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.7.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"2.7.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:105:2.7.0rc0\ntensorflow/tools/pip_package/setup.py:108:2.7.0rc0\n```", "comments": []}]