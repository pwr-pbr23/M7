[{"number": 33932, "title": "Exif Orientation support tf.image.decode_jpeg()", "body": "Hi.\r\nI have large amounts of JPEG files uploaded by users on our service .\r\nThey use mainly smartphone camera, so most files contain **EXIF orientation metadata.**\r\n\r\nIt would seem that the **tf.image.decode_jpeg() ignores this information.** How about adding support for these meta informations, especially orientation ?\r\n\r\nThis issue is from \r\n> https://github.com/tensorflow/tensorflow/issues/8430#issue-214362114\r\n\r\n**But I found this problem is still existing. Anybody knows how to solve this probelm? I found opencv take the EXIF information into count, but it's hard to use opencv to replace tensorflow image processor.**\r\n```python\r\n        image_bgr = cv2.imread(file_name)\r\n        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\r\n        image = np.asarray(image_rgb)\r\n        # image_buffer = tf.read_file(file_name)\r\n        # image_rgb = tf.image.decode_jpeg(image_buffer)\r\n        # image = tf.cond(tf.equal(tf.shape(image_rgb)[2], 1), lambda: tf.image.grayscale_to_rgb(image_rgb), lambda: tf.identity(image_rgb))\r\n```", "comments": ["@wikiwen I added a `decode_jepg_exif` in [tensorflow/io](https://github.com/tensorflow/io) with PR  tensorflow/io#604 . This will allows you to obtain the orientation from JPEG, so that it is possible to do post-processing.\r\n\r\nIf there is enough further interest, I could add additional enhancement for\r\n1) Extract additional fields in EXIF than orientation\r\n2) Add another function (or a new kernel) to automatically adjust decoded JPEG with orientation.\r\n\r\nPlease take a look at the PR tensorflow/io#604", "@yongtang Nice work! Thanks~", "@wikiwen As PR  tensorflow/io#604 has been merged, you can give it a try and see if it fits you needs. I will close this issue for now.\r\n\r\nIf you want additional features such as automatically transformint the picture's orientation based on the EXIF's orientation value, can you open a new issue in [tensorflow/io](https://github.com/tensorflow/io) repo? We can continue the discussion there."]}, {"number": 33931, "title": " in tutorials/load_data/csv ,when trying twice, the test_data is different?", "body": "\r\n\r\n\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://tensorflow.google.cn/tutorials/load_data/csv\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nwhen run the last code :loop, retry it ,the result is different \r\n\r\nthen run the last code \r\n>>>list(test_data)[0][1][:10]\r\n>>>list(test_data)[0][1][:10]\r\nwhy the test_data is not shuffled,but result is different\r\n\r\nif this ,the actual label is not trustworthy\r\n![5I7`)`M@7HBT@04EG5~(5~6](https://user-images.githubusercontent.com/41684325/68068668-16bc4300-fd92-11e9-992b-9bf9fa743a8c.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["#\r\nDuplicate of #", "> Duplicate of #\r\n\r\nif duplicate,please tell me the original issue (\u0e51>\u25e1<\u0e51)", "@trembous ,\r\nHello, yes test data is different every time the last code is run. Its the intended behavior.\r\nIf you can see the section  `read the CSV data from the file and create a dataset` data with batch_size of 5 is imported every time. ", "> @trembous ,\r\n> Hello, yes test data is different every time the last code is run. Its the intended behavior.\r\n> If you can see the section `read the CSV data from the file and create a dataset` data with batch_size of 5 is imported every time.\r\n\r\nthanks, but  I remain want to know that how to accquire the started label 'actual outcome',\r\nso the example is not precise.\r\nif this,I suggest the example will like give a record of csv '(feature , label)' , then the test data is stable \r\notherwise,the actual label is not trustworthy", "@trembous This is intended behavior. I updated code to show the actual labels and corresponding features selected for prediction. When you run the last cell like this\r\n\r\n## Ran first time (last block)\r\n```\r\npredictions = model.predict(test_data)\r\nshow_batch(temp_dataset)\r\nprint(\"\")\r\n# Show some results\r\nfor prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\r\n  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\r\n        \" | Actual outcome: \",\r\n        (\"SURVIVED\" if bool(survived) else \"DIED\"))\r\n```\r\nThe result is something like this (not exactly same as yours as the dataset frame may be different)\r\n\r\n```\r\ntf.Tensor([1 1 1 0 0], shape=(5,), dtype=int32)\r\n\r\nage                 : [28. 19. 19. 28. 25.]\r\nn_siblings_spouses  : [1. 1. 0. 0. 0.]\r\nparch               : [0. 0. 2. 0. 0.]\r\nfare                : [146.521  26.     26.283   8.05    7.05 ]\r\n\r\nPredicted survival: 36.86%  | Actual outcome:  SURVIVED\r\nPredicted survival: 12.31%  | Actual outcome:  DIED\r\nPredicted survival: 41.52%  | Actual outcome:  DIED\r\nPredicted survival: 36.76%  | Actual outcome:  DIED\r\nPredicted survival: 5.32%  | Actual outcome:  SURVIVED\r\n```\r\n\r\nAfter that you are running code below `#Show some results` and not running the prediction code `predictions = model.predict(test_data)` again as follows\r\n\r\n## Ran second time (last block)\r\n```\r\nshow_batch(temp_dataset)\r\nprint(\"\")\r\n# Show some results\r\nfor prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\r\n  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\r\n        \" | Actual outcome: \",\r\n        (\"SURVIVED\" if bool(survived) else \"DIED\"))\r\n```\r\n\r\nI have added `show_batch(temp_dataset)` to show which batch was selected for the second time execution. \r\n\r\n```\r\n tf.Tensor([0 0 0 0 0], shape=(5,), dtype=int32)\r\n\r\nage                 : [26.  28.5 46.  28.  33. ]\r\nn_siblings_spouses  : [0. 0. 0. 0. 0.]\r\nparch               : [0. 0. 0. 0. 0.]\r\nfare                : [ 8.05   7.229 79.2    8.05  12.275]\r\n\r\nPredicted survival: 36.86%  | Actual outcome:  DIED\r\nPredicted survival: 12.31%  | Actual outcome:  SURVIVED\r\nPredicted survival: 41.52%  | Actual outcome:  DIED\r\nPredicted survival: 36.76%  | Actual outcome:  DIED\r\nPredicted survival: 5.32%  | Actual outcome:  DIED\r\n```\r\n\r\nIn the above two outputs, you could see that inputs (labels and features) are different between first execution and second execution. However, you didn't ran the prediction code  `predictions = model.predict(test_data)`, so the predictions are same after first and second executions. \r\n\r\n[Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/1b3f06da80aea817c51678a954f7fe79/csv.ipynb) is the gist for your reference.\r\n\r\nI am closing the issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!"]}, {"number": 33930, "title": "Update TensorFlow README: expand pip install guide, add Udacity courses to Resources", "body": "Hey @lamberta @MarkDaoust - randomly stumbled across README.md and thought I'd propose a few suggestions :\r\n\r\n- Clarifying that `pip install tensorflow-gpu` is for Ubuntu and Windows only - in line with [this pip install guide](https://www.tensorflow.org/install/pip) on tensorflow.org\r\n- Adding two courses from Udacity made with the TensorFlow team to \"Resources\":\r\n  - Intro to TensorFlow for Deep Learning\r\n    - This one is already under \"Resources\" -> \"[TensorFlow examples](https://github.com/tensorflow/examples)\" but the Coursera course is listed directly under \"Resources\"\r\n  - Introduction to TensorFlow Lite - a brand new course! \ud83d\ude80\r\n\r\nAny questions, suggestions, etc - let me know. Cheers ", "comments": []}, {"number": 33929, "title": "Optimizer clipvalue and clipnorm not working in Tensorflow 2.0", "body": "\r\n**System information**\r\n- Python 3 Google Compute Engine backend (GPU)\r\n\r\n**Describe the current behavior**\r\nclipvalue and clipnorm in Optimizers does nothing!\r\n\r\n**Describe the expected behavior**\r\nBy setting clipvalue=0 or clipnorm=0 no training should occur (gradients should be 0!), but the network still trains, and if using a large learning rate, loss goes to nan.\r\n\r\n**Code to reproduce the issue**\r\n![image](https://user-images.githubusercontent.com/567732/68066124-4d01b000-fd09-11e9-8e41-51ece3684869.png)\r\n**Gradient is clearly not zero since the network is getting modified at each iteration.**\r\n\r\n![image](https://user-images.githubusercontent.com/567732/68066145-7589aa00-fd09-11e9-8c94-1ae4bcf33e45.png)\r\n**Sanity check by setting lr=0**\r\n**No training occurs when lr=0, as expected.**\r\n", "comments": ["Looks like code is incomplete.Please provide a simple standalone code to reproduce the issue in our environment, then it is easy for localizing the issue faster. Thanks!", "@bloc97 \r\n\r\nAny update on this issue please. Thanks!", "I didn't think that standalone code would be needed as this unexpected behavior should be instantly caught by a unit test. But here you go:\r\n\r\nhttps://colab.research.google.com/drive/16gxaqBuY7NRYZaDqeV26yH7caLChTLY6", "Just for completeness' sake, here's the same code but on Tensorflow 1.x:\r\nhttps://colab.research.google.com/drive/1BylY2e43DLZRBkOdIDGJ_rBPDlbGo-Vm\r\n\r\nThis runs as expected, no training occurs, suggesting some problems within the Tensorflow 2.0 eager execution code.", "@bloc97 \r\nI tried in colab with TF 2.0 for learning rate 0 and 100 and i am able to see loss in output. However loss goes to nan if we use very large value `learning rate: 1e10`. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/af23720e98b0f655f794773c30cd486c/untitled371.ipynb). However with TF 1.15 version i am able to see loss for learning rate 0, 100 and 1e10 .Thanks!", "@bloc97,\r\nAgree that  `learning rate: 1e10` is resulting in `NaN` but can you please let me know why do you want to use such a Huge Value for Learning Rate. Thanks!", "Many research papers using high learning rate regimes will diverge if gradient clipping does not work. I simply provided a small example that shows the issue.\r\nFor example, in VDSR the authors use a learning rate of 0.1 with gradient clipping of 0.001. Since the network is extremely deep (20+ layers), it will diverge even on learning rates of 0.1 or 0.01 without gradient clipping.\r\n\r\nI discovered this issue when trying to run code that worked on TF 1.5, but as we are migrating to TF 2.0, it doesn't work anymore.", "Any updates on this matter? Or is there any workaround (manually clip the gradients before the update pass)?", "This should be fixed for 2.2 (If you're not using a distribution strategy). We're working on a longer-term change for optimizers that should fix this more fundamentally.", "I assume that this is the fix: https://github.com/tensorflow/tensorflow/commit/69da929ad4d5ba605507efa1f52b382a55b6a969\r\nMay I ask whether this fix is only relevant for eager execution or also graph execution?\r\nIn other words: For graph execution, did clipnorm already work correctly?\r\n\r\nFor me the situation is that I was able to train my models in TF2.0 with graph execution. Then I upgraded to 2.1 and enabled eager execution (and made some other changes), and since, my models cannot train properly anymore. So knowing whether this only relates to eager execution would allow me to pinpoint the problem.\r\nWhen upgrading to 2.2 (nightly) the problem seems to be fixed.", "Yes, norm clipping still worked correctly when eager execution was disabled in 2.0 and 2.1.\r\n\r\n", "> Yes, norm clipping still worked correctly when eager execution was disabled in 2.0 and 2.1.\r\n\r\nThanks for clearing that up.", "Oh man, I've just been debugging my NaN losses for over an hour now. How could this even go unnoticed...\r\n\r\nWill this be fixed for 2.1.x as well or is 2.2 the only way to get this working again? I can't disable eager mode because then I lose the cuDNN implementation of LSTMs.", "Hi Goldie, someone wants to know if a bug fix in 2.2 can be backported to\n2.1.x. What's our policy on minor release versions?\n\nBest,\nTomer\n\nOn Sun, Mar 22, 2020 at 9:35 AM jlherren <notifications@github.com> wrote:\n\n> Oh man, I've just been debugging my NaN losses for over an hour now. How\n> could this even go unnoticed...\n>\n> Will this be fixed for 2.1.x as well or is 2.2 the only way to get this\n> working again? I can't disable eager mode because then I lose the cuDNN\n> implementation of LSTMs.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33929#issuecomment-602236143>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAFFEBMU4OQKDECN2UCLUQTRIY45FANCNFSM4JICXMIA>\n> .\n>\n", "@tomerk Our policy about back-porting the code to previous versions is mentioned by  @mihaimaruseac [Here](https://github.com/tensorflow/tensorflow/issues/29624#issuecomment-610601027). Thanks!", "> This should be fixed for 2.2 (If you're not using a distribution strategy). We're working on a longer-term change for optimizers that should fix this more fundamentally.\r\n\r\nDoes it work for distribution strategy in 2.2 now? I get the same error when I use MultiWorkerMirroredStrategy in 2.2.0-dev20200508.", "@tomerk can you elaborate on why one shouldn't use gradient clipping with a distribution strategy?", "@karlhjm no, we still disable it in 2.2 w/ distribution strategies enabled.\r\n\r\n@zaccharieramzi yes, happy to elaborate:\r\nThere's two possible places to clip when you have distribution strategies enabled:\r\n- before gradients get aggregated (usually wrong)\r\n- after gradients get aggregated (usually right & what people expect)\r\n\r\nWe want it working w/ the second case (clipping after gradients are aggregated).\r\nThe issue is the optimizers are written with clipping happening in the code before aggregation does.\r\n\r\nWe looked into changing this, but it would have required either:\r\n1. api changes that break existing users of optimizer `apply_gradients`/other non-minimize methods\r\n2. changing the signatures of methods optimizer implementers need to implement, breaking existing custom optimizers\r\n\r\nSo rather than:\r\n* quietly doing clipping in the wrong place\r\n* increasing churn & breaking existing users or existing custom optimizers just for this individual feature\r\n\r\nWe instead decided to leave this disabled for now. We'll roll support for this into a larger optimizer refactoring that solves a larger set of issues.\r\n(RFC for that is at https://github.com/tensorflow/community/pull/234)", "Short of reducing the learning rate is there any way to workaround this issue?", "> Short of reducing the learning rate is there any way to workaround this issue?\r\n\r\nIn Ludwig I have implemented a workaround: A wrapper class that wraps the optimizer and clips the gradients before applying them: https://github.com/uber/ludwig/blob/tf2_porting/ludwig/models/modules/optimization_modules.py\r\nIt's still WIP but seems to work fine.", "@bloc97 \r\nI have tried the code on tf 2.3 and do not get any nan values as output, can you please refer to this gist and confirm if it resolves the issue.\r\nPlease find the [gist here](https://colab.research.google.com/gist/Saduf2019/0cc40cbbc833655d43a7b5567d5f212e/untitled321.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The issue has been fixed for me on Tensorflow v2.3.0 on google colab. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33929\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33929\">No</a>\n", "Yes, the optimizer RFC I mentioned above is now complete and this should be resolved :)", "One question seems still open though. TF provides `tf.clip_by_norm`, `tf.clip_by_value` and `tf.clip_by_global_norm`, while the current implementation only supports the first two, but not the global norm one. Should i open a new issue to have it included?", "> One question seems still open though. TF provides `tf.clip_by_norm`, `tf.clip_by_value` and `tf.clip_by_global_norm`, while the current implementation only supports the first two, but not the global norm one. Should i open a new issue to have it included?\r\n\r\nTHere is a `clip_globalnorm` with keras optimizer in nightly", "Still not resolved in conda tf 2.3.0"]}, {"number": 33928, "title": "How to add optimizer in tensorflow CNN", "body": "I wanna know how to add an optimizer such as Adam, or Nadam optimizer to the simple speech recognition example in this repository? Because I don't know where to or how to add it in the code such as to \"model.py\" file or where and how?", "comments": ["@chathuravithakshana ,\r\nPlease refer this [link](https://www.tensorflow.org/tutorials/images/cnn) and let us know if it was helpful.Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@chathuravithakshana ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33927, "title": "tf_upgrade_v2 can't work on windows", "body": "This is my command\r\n```\r\ntf_upgrade_v2 --infile model_train_testByreallydata.py --outfile model_train_testByreallydata_tf2.py\r\n```\r\n\r\nIt will get \r\n\r\n```\r\n(tensorflow2) C:\\Users\\63110\\OneDrive\\github-backup\\mhxy-captcha>tf_upgrade_v2 --infile model_train_testByreallydata.py --outfile model_train_testByreallydata_tf2.py\r\nTraceback (most recent call last):\r\n  File \"E:\\ProgramData\\Anaconda3\\envs\\tensorflow2\\Scripts\\tf_upgrade_v2-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"E:\\ProgramData\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\tools\\compatibility\\tf_upgrade_v2_main.py\", line 139, in main\r\n    args.input_file, output_file, upgrade)\r\n  File \"E:\\ProgramData\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\tools\\compatibility\\tf_upgrade_v2_main.py\", line 40, in process_file\r\n    upgrader.process_file(in_filename, out_filename)\r\n  File \"E:\\ProgramData\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\tools\\compatibility\\ast_edits.py\", line 900, in process_file\r\n    temp_file)\r\n  File \"E:\\ProgramData\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\tools\\compatibility\\ast_edits.py\", line 958, in process_opened_file\r\n    lines = in_file.readlines()\r\nUnicodeDecodeError: 'gbk' codec can't decode byte 0xa7 in position 300: illegal multibyte sequence\r\n\r\n```\r\n\r\nOs:\r\nwindows 10 \r\n\r\nPython Version:\r\n3.7 from Anaconda\r\n\r\n", "comments": ["Can you share your file model_train_testByreallydata.py if it doesn't have any sensitive data? I can try working with tweaks on my system. ", "```\r\n# -*- coding:utf-8 -*-\r\n# name: model_train.py\r\nimport os\r\n\r\nimport tensorflow as tf\r\nfrom datetime import datetime\r\nfrom util import get_next_batch, get_test_batch\r\nfrom captcha_gen import CAPTCHA_HEIGHT, CAPTCHA_WIDTH, CAPTCHA_LEN, CAPTCHA_LIST\r\n\r\n\r\ndef weight_variable(shape, w_alpha=0.01):\r\n    \"\"\"\r\n    \u521d\u59cb\u5316\u6743\u503c\r\n    :param shape:\r\n    :param w_alpha:\r\n    :return:\r\n   \"\"\"\r\n    initial = w_alpha * tf.random_normal(shape)\r\n    return tf.Variable(initial)\r\n\r\n\r\ndef bias_variable(shape, b_alpha=0.1):\r\n    \"\"\"\r\n    \u521d\u59cb\u5316\u504f\u7f6e\u9879\r\n    :param shape:\r\n    :param b_alpha:\r\n    :return:\r\n    \"\"\"\r\n    initial = b_alpha * tf.random_normal(shape)\r\n    return tf.Variable(initial)\r\n\r\n\r\ndef conv2d(x, w):\r\n    \"\"\"\r\n    \u5377\u57fa\u5c42 \uff1a\u5c40\u90e8\u53d8\u91cf\u7ebf\u6027\u7ec4\u5408\uff0c\u6b65\u957f\u4e3a1\uff0c\u6a21\u5f0f\u2018SAME\u2019\u4ee3\u8868\u5377\u79ef\u540e\u56fe\u7247\u5c3a\u5bf8\u4e0d\u53d8\uff0c\u5373\u96f6\u8fb9\u8ddd\r\n    :param x:\r\n    :param w:\r\n    :return:\r\n    \"\"\"\r\n    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\n\r\ndef max_pool_2x2(x):\r\n    \"\"\"\r\n    \u6c60\u5316\u5c42\uff1amax pooling,\u53d6\u51fa\u533a\u57df\u5185\u6700\u5927\u503c\u4e3a\u4ee3\u8868\u7279\u5f81\uff0c 2x2 \u7684pool\uff0c\u56fe\u7247\u5c3a\u5bf8\u53d8\u4e3a1/2\r\n    :param x:\r\n    :return:\r\n    \"\"\"\r\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\ndef cnn_graph(x, keep_prob, size, captcha_list=CAPTCHA_LIST, captcha_len=CAPTCHA_LEN):\r\n    \"\"\"\r\n    \u4e09\u5c42\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\r\n    :param x:   \u8bad\u7ec3\u96c6 image x\r\n    :param keep_prob:   \u795e\u7ecf\u5143\u5229\u7528\u7387\r\n    :param size:        \u5927\u5c0f (\u9ad8,\u5bbd)\r\n    :param captcha_list:\r\n    :param captcha_len:\r\n    :return: y_conv\r\n    \"\"\"\r\n    # \u9700\u8981\u5c06\u56fe\u7247reshape\u4e3a4\u7ef4\u5411\u91cf\r\n    image_height, image_width = size\r\n    x_image = tf.reshape(x, shape=[-1, image_height, image_width, 1])\r\n\r\n    # \u7b2c\u4e00\u5c42\r\n    # filter\u5b9a\u4e49\u4e3a3x3x1\uff0c \u8f93\u51fa32\u4e2a\u7279\u5f81, \u537332\u4e2afilter\r\n    w_conv1 = weight_variable([3, 3, 1, 32])  # 3*3\u7684\u91c7\u6837\u7a97\u53e3\uff0c32\u4e2a\uff08\u901a\u9053\uff09\u5377\u79ef\u6838\u4ece1\u4e2a\u5e73\u9762\u62bd\u53d6\u7279\u5f81\u5f97\u523032\u4e2a\u7279\u5f81\u5e73\u9762\r\n    b_conv1 = bias_variable([32])\r\n    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)  # rulu\u6fc0\u6d3b\u51fd\u6570\r\n    h_pool1 = max_pool_2x2(h_conv1)  # \u6c60\u5316\r\n    h_drop1 = tf.nn.dropout(h_pool1, keep_prob)  # dropout\u9632\u6b62\u8fc7\u62df\u5408\r\n\r\n    # \u7b2c\u4e8c\u5c42\r\n    w_conv2 = weight_variable([3, 3, 32, 64])\r\n    b_conv2 = bias_variable([64])\r\n    h_conv2 = tf.nn.relu(conv2d(h_drop1, w_conv2) + b_conv2)\r\n    h_pool2 = max_pool_2x2(h_conv2)\r\n    h_drop2 = tf.nn.dropout(h_pool2, keep_prob)\r\n\r\n    # \u7b2c\u4e09\u5c42\r\n    w_conv3 = weight_variable([3, 3, 64, 64])\r\n    b_conv3 = bias_variable([64])\r\n    h_conv3 = tf.nn.relu(conv2d(h_drop2, w_conv3) + b_conv3)\r\n    h_pool3 = max_pool_2x2(h_conv3)\r\n    h_drop3 = tf.nn.dropout(h_pool3, keep_prob)\r\n\r\n    \"\"\"\r\n    \u539f\u59cb\uff1a60*160\u56fe\u7247 \u7b2c\u4e00\u6b21\u5377\u79ef\u540e 60*160 \u7b2c\u4e00\u6c60\u5316\u540e 30*80\r\n    \u7b2c\u4e8c\u6b21\u5377\u79ef\u540e 30*80 \uff0c\u7b2c\u4e8c\u6b21\u6c60\u5316\u540e 15*40\r\n    \u7b2c\u4e09\u6b21\u5377\u79ef\u540e 15*40 \uff0c\u7b2c\u4e09\u6b21\u6c60\u5316\u540e 7.5*20 = > \u5411\u4e0b\u53d6\u6574 7*20\r\n    \u7ecf\u8fc7\u4e0a\u9762\u64cd\u4f5c\u540e\u5f97\u52307*20\u7684\u5e73\u9762\r\n    \"\"\"\r\n\r\n    # \u5168\u8fde\u63a5\u5c42\r\n    image_height = int(h_drop3.shape[1])\r\n    image_width = int(h_drop3.shape[2])\r\n    w_fc = weight_variable([image_height * image_width * 64, 1024])  # \u4e0a\u4e00\u5c42\u670964\u4e2a\u795e\u7ecf\u5143 \u5168\u8fde\u63a5\u5c42\u67091024\u4e2a\u795e\u7ecf\u5143\r\n    b_fc = bias_variable([1024])\r\n    h_drop3_re = tf.reshape(h_drop3, [-1, image_height * image_width * 64])\r\n    h_fc = tf.nn.relu(tf.matmul(h_drop3_re, w_fc) + b_fc)\r\n    h_drop_fc = tf.nn.dropout(h_fc, keep_prob)\r\n\r\n    # \u8f93\u51fa\u5c42\r\n    w_out = weight_variable([1024, len(captcha_list) * captcha_len])\r\n    b_out = bias_variable([len(captcha_list) * captcha_len])\r\n    y_conv = tf.matmul(h_drop_fc, w_out) + b_out\r\n    return y_conv\r\n\r\n\r\ndef optimize_graph(y, y_conv):\r\n    \"\"\"\r\n    \u4f18\u5316\u8ba1\u7b97\u56fe\r\n    :param y: \u6b63\u786e\u503c\r\n    :param y_conv:  \u9884\u6d4b\u503c\r\n    :return: optimizer\r\n    \"\"\"\r\n    # \u4ea4\u53c9\u71b5\u4ee3\u4ef7\u51fd\u6570\u8ba1\u7b97loss \u6ce8\u610flogits\u8f93\u5165\u662f\u5728\u51fd\u6570\u5185\u90e8\u8fdb\u884csigmod\u64cd\u4f5c\r\n    # sigmod_cross\u9002\u7528\u4e8e\u6bcf\u4e2a\u7c7b\u522b\u76f8\u4e92\u72ec\u7acb\u4f46\u4e0d\u4e92\u65a5\uff0c\u5982\u56fe\u4e2d\u53ef\u4ee5\u6709\u5b57\u6bcd\u548c\u6570\u5b57\r\n    # softmax_cross\u9002\u7528\u4e8e\u6bcf\u4e2a\u7c7b\u522b\u72ec\u7acb\u4e14\u6392\u65a5\u7684\u60c5\u51b5\uff0c\u5982\u6570\u5b57\u548c\u5b57\u6bcd\u4e0d\u53ef\u4ee5\u540c\u65f6\u51fa\u73b0\r\n    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_conv))\r\n    # \u6700\u5c0f\u5316loss\u4f18\u5316 AdaminOptimizer\u4f18\u5316\r\n    optimizer = tf.train.AdamOptimizer(1e-3).minimize(loss)\r\n    return optimizer\r\n\r\n\r\ndef accuracy_graph(y, y_conv, width=len(CAPTCHA_LIST), height=CAPTCHA_LEN):\r\n    \"\"\"\r\n    \u504f\u5dee\u8ba1\u7b97\u56fe\uff0c\u6b63\u786e\u503c\u548c\u9884\u6d4b\u503c\uff0c\u8ba1\u7b97\u51c6\u786e\u5ea6\r\n    :param y: \u6b63\u786e\u503c \u6807\u7b7e\r\n    :param y_conv:  \u9884\u6d4b\u503c\r\n    :param width:   \u9a8c\u8bc1\u7801\u9884\u5907\u5b57\u7b26\u5217\u8868\u957f\u5ea6\r\n    :param height:  \u9a8c\u8bc1\u7801\u7684\u5927\u5c0f\uff0c\u9ed8\u8ba4\u4e3a4\r\n    :return:    \u6b63\u786e\u7387\r\n    \"\"\"\r\n    # \u8fd9\u91cc\u533a\u5206\u4e86\u5927\u5c0f\u5199 \u5b9e\u9645\u4e0a\u9a8c\u8bc1\u7801\u4e00\u822c\u4e0d\u533a\u5206\u5927\u5c0f\u5199,\u6709\u56db\u4e2a\u503c\uff0c\u4e0d\u540c\u4e8e\u624b\u5199\u4f53\u8bc6\u522b\r\n    # \u9884\u6d4b\u503c\r\n    predict = tf.reshape(y_conv, [-1, height, width])  #\r\n    max_predict_idx = tf.argmax(predict, 2)\r\n    # \u6807\u7b7e\r\n    label = tf.reshape(y, [-1, height, width])\r\n    max_label_idx = tf.argmax(label, 2)\r\n    correct_p = tf.equal(max_predict_idx, max_label_idx)  # \u5224\u65ad\u662f\u5426\u76f8\u7b49\r\n    accuracy = tf.reduce_mean(tf.cast(correct_p, tf.float32))\r\n    return accuracy\r\n\r\n\r\ndef train(height=CAPTCHA_HEIGHT, width=CAPTCHA_WIDTH, y_size=len(CAPTCHA_LIST) * CAPTCHA_LEN):\r\n    \"\"\"\r\n    cnn\u8bad\u7ec3\r\n    :param height: \u9a8c\u8bc1\u7801\u9ad8\u5ea6\r\n    :param width:   \u9a8c\u8bc1\u7801\u5bbd\u5ea6\r\n    :param y_size:  \u9a8c\u8bc1\u7801\u9884\u5907\u5b57\u7b26\u5217\u8868\u957f\u5ea6*\u9a8c\u8bc1\u7801\u957f\u5ea6\uff08\u9ed8\u8ba4\u4e3a4\uff09\r\n    :return:\r\n    \"\"\"\r\n    # cnn\u5728\u56fe\u50cf\u5927\u5c0f\u662f2\u7684\u500d\u6570\u65f6\u6027\u80fd\u6700\u9ad8, \u5982\u679c\u56fe\u50cf\u5927\u5c0f\u4e0d\u662f2\u7684\u500d\u6570\uff0c\u53ef\u4ee5\u5728\u56fe\u50cf\u8fb9\u7f18\u8865\u65e0\u7528\u50cf\u7d20\r\n    # \u5728\u56fe\u50cf\u4e0a\u88652\u884c\uff0c\u4e0b\u88653\u884c\uff0c\u5de6\u88652\u884c\uff0c\u53f3\u88652\u884c\r\n    # np.pad(image,((2,3),(2,2)), 'constant', constant_values=(255,))\r\n    show = open(\"show.txt\", 'a')\r\n\r\n    acc_rate = 0.95  # \u9884\u8bbe\u6a21\u578b\u51c6\u786e\u7387\u6807\u51c6\r\n    # \u6309\u7167\u56fe\u7247\u5927\u5c0f\u7533\u8bf7\u5360\u4f4d\u7b26\r\n    x = tf.placeholder(tf.float32, [None, height * width])\r\n    y = tf.placeholder(tf.float32, [None, y_size])\r\n    # \u9632\u6b62\u8fc7\u62df\u5408 \u8bad\u7ec3\u65f6\u542f\u7528 \u6d4b\u8bd5\u65f6\u4e0d\u542f\u7528 \u795e\u7ecf\u5143\u4f7f\u7528\u7387\r\n    keep_prob = tf.placeholder(tf.float32)\r\n    # cnn\u6a21\u578b\r\n    y_conv = cnn_graph(x, keep_prob, (height, width))\r\n    # \u4f18\u5316\r\n    optimizer = optimize_graph(y, y_conv)\r\n    # \u8ba1\u7b97\u51c6\u786e\u7387\r\n    accuracy = accuracy_graph(y, y_conv)\r\n    # \u542f\u52a8\u4f1a\u8bdd.\u5f00\u59cb\u8bad\u7ec3\r\n    saver = tf.train.Saver(max_to_keep=3)\r\n    sess = tf.Session()\r\n    sess.run(tf.global_variables_initializer())  # \u521d\u59cb\u5316\r\n\r\n    # \u57fa\u4e8e\u5f53\u524d\u5df2\u6709\u6a21\u578b\u8bad\u7ec3\r\n    if os.path.exists(\"model/checkpoint\"):\r\n        model_file = tf.train.latest_checkpoint('model')\r\n        saver.restore(sess, model_file)\r\n    step = 0  # \u6b65\u6570\r\n\r\n    really_acc_max = 0\r\n\r\n    while 1:\r\n        batch_x, batch_y = get_next_batch(64)\r\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.75})\r\n        # \u6bcf\u8bad\u7ec3\u4e00\u767e\u6b21\u6d4b\u8bd5\u4e00\u6b21\r\n        if step % 100 == 0:\r\n            batch_x_test, batch_y_test = get_test_batch()\r\n            acc = sess.run(accuracy, feed_dict={x: batch_x_test, y: batch_y_test, keep_prob: 1.0})\r\n            show.writelines(\r\n                \"really\uff1a    \" + datetime.now().strftime('%c') + ' step:' + str(step) + ' accuracy:' + str(acc) + \"\\n\")\r\n            show.tell()\r\n            print(\"really\uff1a  \" + datetime.now().strftime('%c'), ' step:', step, ' accuracy:', acc)\r\n\r\n            if acc > really_acc_max:\r\n                really_acc_max = acc\r\n                model_path = \"./model/really_max/captcha.model\"\r\n                saver.save(sess, model_path, global_step=step)\r\n\r\n            batch_x_test, batch_y_test = get_next_batch(100)\r\n            acc = sess.run(accuracy, feed_dict={x: batch_x_test, y: batch_y_test, keep_prob: 1.0})\r\n            show.writelines(\r\n                \"moni\uff1a  \" + datetime.now().strftime('%c') + ' step:' + str(step) + ' accuracy:' + str(acc) + \"\\n\")\r\n            show.tell()\r\n            print(\"moni\uff1a    \" + datetime.now().strftime('%c'), ' step:', step, ' accuracy:', acc)\r\n\r\n            # \u51c6\u786e\u7387\u6ee1\u8db3\u8981\u6c42\uff0c\u4fdd\u5b58\u6a21\u578b\r\n            if acc > acc_rate:\r\n                model_path = \"./model/captcha.model\"\r\n                saver.save(sess, model_path, global_step=step)\r\n                acc_rate += 0.01\r\n                if acc_rate > 0.99:  # \u51c6\u786e\u7387\u8fbe\u523099%\u5219\u9000\u51fa\r\n                    pass\r\n        step += 1\r\n    sess.close()\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n\r\n```\r\n\r\n\r\nIt works fine on ubuntu.\r\n", "This error may be caused by the punctuation of the Chinese input method in the code and some Chinese characters, such as \u2018\u9700\u2019, \u2018\u4e3a\u2019, \u2018\u7b2c\u4e00\u5c42',etc. I deleted the Chinese characters in the code and replaced the Chinese punctuation with English punctuation.it works well.\r\nThe result:\r\n\r\n    INFO line 17:24: Renamed 'tf.random_normal' to 'tf.random.normal'\r\n    INFO line 27:24: Renamed 'tf.random_normal' to 'tf.random.normal'\r\n    INFO line 37:11: Added keywords to args of function 'tf.nn.conv2d'\r\n    INFO line 37:11: Renamed keyword argument for tf.nn.conv2d from filter to filters\r\n    INFO line 45:11: Added keywords to args of function 'tf.nn.max_pool'\r\n    INFO line 45:11: Renamed keyword argument for tf.nn.max_pool from value to input\r\n    INFO line 45:11: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\r\n    INFO line 65:14: Changing keep_prob arg of tf.nn.dropout to rate, and recomputing value.\r\n\r\n    INFO line 71:14: Changing keep_prob arg of tf.nn.dropout to rate, and recomputing value.\r\n\r\n    INFO line 77:14: Changing keep_prob arg of tf.nn.dropout to rate, and recomputing value.\r\n\r\n    INFO line 85:16: Changing keep_prob arg of tf.nn.dropout to rate, and recomputing value.\r\n\r\n    INFO line 100:11: Added keywords to args of function 'tf.reduce_mean'\r\n    INFO line 102:16: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\r\n    INFO line 116:22: Added keywords to args of function 'tf.argmax'\r\n    INFO line 119:20: Added keywords to args of function 'tf.argmax'\r\n    INFO line 121:15: Added keywords to args of function 'tf.reduce_mean'\r\n    INFO line 139:8: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\r\n    INFO line 140:8: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\r\n    INFO line 142:16: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\r\n    INFO line 150:12: Renamed 'tf.train.Saver' to 'tf.compat.v1.train.Saver'\r\n    INFO line 151:11: Renamed 'tf.Session' to 'tf.compat.v1.Session'\r\n    INFO line 152:13: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\r\n    WARNING line 176:16: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\r\n    WARNING line 187:16: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\r\n\r\n    TensorFlow 2.0 Upgrade Script\r\n    -----------------------------\r\n    Converted 1 files\r\n    Detected 2 issues that require attention\r\n    --------------------------------------------------------------------------------\r\n    --------------------------------------------------------------------------------\r\n    File: model_train_testByreallydata.py\r\n    --------------------------------------------------------------------------------\r\n    model_train_testByreallydata.py:176:16: WARNING: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\r\n    model_train_testByreallydata.py:187:16: WARNING: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\r\n\r\n\r\n    Make sure to read the detailed log 'report.txt'\r\n\r\nThe code:\r\n\r\n    # -*- coding:utf-8 -*-\r\n    # name: model_train.py\r\n    import os\r\n\r\n    import tensorflow as tf\r\n    from datetime import datetime\r\n    from util import get_next_batch, get_test_batch\r\n    from captcha_gen import CAPTCHA_HEIGHT, CAPTCHA_WIDTH, CAPTCHA_LEN, CAPTCHA_LIST\r\n\r\n\r\n    def weight_variable(shape, w_alpha=0.01):\r\n        \"\"\"\r\n        :param shape:\r\n        :param w_alpha:\r\n        :return:\r\n    \"\"\"\r\n        initial = w_alpha * tf.random_normal(shape)\r\n        return tf.Variable(initial)\r\n\r\n\r\n    def bias_variable(shape, b_alpha=0.1):\r\n        \"\"\"\r\n        :param shape:\r\n        :param b_alpha:\r\n        :return:\r\n        \"\"\"\r\n        initial = b_alpha * tf.random_normal(shape)\r\n        return tf.Variable(initial)\r\n\r\n\r\n    def conv2d(x, w):\r\n        \"\"\"\r\n        :param x:\r\n        :param w:\r\n        :return:\r\n        \"\"\"\r\n        return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\n\r\n    def max_pool_2x2(x):\r\n        \"\"\"\r\n        :param x:\r\n        :return:\r\n        \"\"\"\r\n        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\n    def cnn_graph(x, keep_prob, size, captcha_list=CAPTCHA_LIST, captcha_len=CAPTCHA_LEN):\r\n        \"\"\"\r\n        :param x:image x\r\n        :param keep_prob:\r\n        :param size:\r\n        :param captcha_list:\r\n        :param captcha_len:\r\n        :return: y_conv\r\n        \"\"\"\r\n\r\n        image_height, image_width = size\r\n        x_image = tf.reshape(x, shape=[-1, image_height, image_width, 1])\r\n\r\n        w_conv1 = weight_variable([3, 3, 1, 32])\r\n        b_conv1 = bias_variable([32])\r\n        h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\r\n        h_pool1 = max_pool_2x2(h_conv1)\r\n        h_drop1 = tf.nn.dropout(h_pool1, keep_prob)\r\n\r\n        w_conv2 = weight_variable([3, 3, 32, 64])\r\n        b_conv2 = bias_variable([64])\r\n        h_conv2 = tf.nn.relu(conv2d(h_drop1, w_conv2) + b_conv2)\r\n        h_pool2 = max_pool_2x2(h_conv2)\r\n        h_drop2 = tf.nn.dropout(h_pool2, keep_prob)\r\n\r\n        w_conv3 = weight_variable([3, 3, 64, 64])\r\n        b_conv3 = bias_variable([64])\r\n        h_conv3 = tf.nn.relu(conv2d(h_drop2, w_conv3) + b_conv3)\r\n        h_pool3 = max_pool_2x2(h_conv3)\r\n        h_drop3 = tf.nn.dropout(h_pool3, keep_prob)\r\n\r\n        image_height = int(h_drop3.shape[1])\r\n        image_width = int(h_drop3.shape[2])\r\n        w_fc = weight_variable([image_height * image_width * 64, 1024])\r\n        b_fc = bias_variable([1024])\r\n        h_drop3_re = tf.reshape(h_drop3, [-1, image_height * image_width * 64])\r\n        h_fc = tf.nn.relu(tf.matmul(h_drop3_re, w_fc) + b_fc)\r\n        h_drop_fc = tf.nn.dropout(h_fc, keep_prob)\r\n\r\n        w_out = weight_variable([1024, len(captcha_list) * captcha_len])\r\n        b_out = bias_variable([len(captcha_list) * captcha_len])\r\n        y_conv = tf.matmul(h_drop_fc, w_out) + b_out\r\n        return y_conv\r\n\r\n\r\n    def optimize_graph(y, y_conv):\r\n        \"\"\"\r\n        :param y:\r\n        :param y_conv:\r\n        :return: optimizer\r\n        \"\"\"\r\n\r\n        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_conv))\r\n\r\n        optimizer = tf.train.AdamOptimizer(1e-3).minimize(loss)\r\n        return optimizer\r\n\r\n\r\n    def accuracy_graph(y, y_conv, width=len(CAPTCHA_LIST), height=CAPTCHA_LEN):\r\n        \"\"\"\r\n        :param y:\r\n        :param y_conv:\r\n        :param width:\r\n        :param height:\r\n        :return:\r\n        \"\"\"\r\n\r\n        predict = tf.reshape(y_conv, [-1, height, width])  #\r\n        max_predict_idx = tf.argmax(predict, 2)\r\n\r\n        label = tf.reshape(y, [-1, height, width])\r\n        max_label_idx = tf.argmax(label, 2)\r\n        correct_p = tf.equal(max_predict_idx, max_label_idx)\r\n        accuracy = tf.reduce_mean(tf.cast(correct_p, tf.float32))\r\n        return accuracy\r\n\r\n\r\n    def train(height=CAPTCHA_HEIGHT, width=CAPTCHA_WIDTH, y_size=len(CAPTCHA_LIST) * CAPTCHA_LEN):\r\n        \"\"\"\r\n        cnn train\r\n        :param height:\r\n        :param width:\r\n        :param y_size:\r\n        :return:\r\n        \"\"\"\r\n\r\n        # np.pad(image,((2,3),(2,2)), 'constant', constant_values=(255,))\r\n        show = open(\"show.txt\", 'a')\r\n\r\n        acc_rate = 0.95\r\n\r\n        x = tf.placeholder(tf.float32, [None, height * width])\r\n        y = tf.placeholder(tf.float32, [None, y_size])\r\n\r\n        keep_prob = tf.placeholder(tf.float32)\r\n\r\n        y_conv = cnn_graph(x, keep_prob, (height, width))\r\n\r\n        optimizer = optimize_graph(y, y_conv)\r\n\r\n        accuracy = accuracy_graph(y, y_conv)\r\n\r\n        saver = tf.train.Saver(max_to_keep=3)\r\n        sess = tf.Session()\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        if os.path.exists(\"model/checkpoint\"):\r\n            model_file = tf.train.latest_checkpoint('model')\r\n            saver.restore(sess, model_file)\r\n        step = 0\r\n\r\n        really_acc_max = 0\r\n\r\n        while 1:\r\n            batch_x, batch_y = get_next_batch(64)\r\n            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.75})\r\n\r\n            if step % 100 == 0:\r\n                batch_x_test, batch_y_test = get_test_batch()\r\n                acc = sess.run(accuracy, feed_dict={x: batch_x_test, y: batch_y_test, keep_prob: 1.0})\r\n                show.writelines(\r\n                    \"really:\" + datetime.now().strftime('%c') + ' step:' + str(step) + ' accuracy:' + str(acc) + \"\\n\")\r\n                show.tell()\r\n                print(\"really:\" + datetime.now().strftime('%c'), ' step:', step, ' accuracy:', acc)\r\n\r\n                if acc > really_acc_max:\r\n                    really_acc_max = acc\r\n                    model_path = \"./model/really_max/captcha.model\"\r\n                    saver.save(sess, model_path, global_step=step)\r\n\r\n                batch_x_test, batch_y_test = get_next_batch(100)\r\n                acc = sess.run(accuracy, feed_dict={x: batch_x_test, y: batch_y_test, keep_prob: 1.0})\r\n                show.writelines(\r\n                    \"moni:\" + datetime.now().strftime('%c') + ' step:' + str(step) + ' accuracy:' + str(acc) + \"\\n\")\r\n                show.tell()\r\n                print(\"moni:\" + datetime.now().strftime('%c'), ' step:', step, ' accuracy:', acc)\r\n\r\n                if acc > acc_rate:\r\n                    model_path = \"./model/captcha.model\"\r\n                    saver.save(sess, model_path, global_step=step)\r\n                    acc_rate += 0.01\r\n                    if acc_rate > 0.99:\r\n                        pass\r\n            step += 1\r\n        sess.close()\r\n\r\n\r\n    if __name__ == '__main__':\r\n        train()\r\n\r\n", "@minemine1126 @Jinnrry , Looks like an encoding bug to me. The default encoding while using `open` to open a file is `unicode` so this method won't be compatible with `utf-8` characters as Chinese strings as @minemine1126 pointed out.\r\n@jvishnuvardhan , please see. ", "Add `, encoding='UTF-8'` in `...\\tensorflow_core\\tools\\compatibility\\ast_edits.py`, line 897 **and** line 898 as below:\r\n\r\n    # Write to a temporary file, just in case we are doing an implace modify.\r\n    # pylint: disable=g-backslash-continuation\r\n    with open(in_filename, \"r\", encoding='UTF-8') as in_file, \\\r\n        tempfile.NamedTemporaryFile(\"w\", delete=False, encoding='UTF-8') as temp_file:\r\n      ret = self.process_opened_file(in_filename, in_file, out_filename, temp_file)\r\n\r\nNote this is not a formal fix as it's hardcoded, but should be working in most caes for Chinese.\r\n\u6ce8\u610f\u4e24\u884c\u90fd\u8981\u6539\uff0c\u5426\u5219\u751f\u6210\u7684\u6587\u4ef6\u6709\u4e71\u7801\u3002", "It is an encoding bug related to Windows, not a TensorFlow issue. As such, we move to close the issue, especially given that there is a workaround in the comment above."]}, {"number": 33926, "title": "[Intel MKL] support MKL Quantized Matmul With Bias and Requantize Op", "body": "Add Support for MKL QuantizedMatMulWithBiasAndRequantize OP.\r\n\r\n@penpornk There is one more PR which is waiting for quite  while which needs some help. \r\nhttps://github.com/tensorflow/tensorflow/pull/32486 (related to the same model I am working on)", "comments": ["@penpornk @gbaned. friendly reminder and thank you.\r\nNote: This is \"NOT\" a part of 2.1.", "@penpornk THank you for the help with 2.1 Release. Just thought I will make a friendly reminder here.", "@penpornk @gbaned Any Updates on this please!", "@penpornk  done! ", "@gbaned @penpornk friendly ping.\r\nAdd Kokoro:force to rerun build? or merge?", "@penpornk Thank you! Update the API Golden files. Let's see what the CI gives us.", "@gbaned can you push the review please. :)\r\n"]}, {"number": 33925, "title": "RuntimeError: Quantization not yet supported for op: CUSTOM in Post Training Quantization", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): r1.15\r\n\r\nFollowing error occurs when implementing post training [full integer quantizati](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations)on of weights and activations. \r\nI am using [SSD Mobilenet 2](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz) model from TensorFlow model zoo.\r\n\r\nI am following exact steps given on TensorFlow website.\r\nI think it is due to [add_postprocessing_op](https://github.com/tensorflow/models/blob/9df6a3d6d09b360c8775426a8746783ad2d0d4a6/research/object_detection/export_tflite_ssd_graph.py#L39) parameter in export_tflite_ssd_graph.py. \r\nINT8 implementation is not available for that. \r\n\r\nHow this issue can be solved for post training quantization? Is there any temporary work around?\r\n \r\n**Any other info / logs**\r\nCode to Reproduce\r\n\r\n```\r\nimport tensorflow as tf\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\nTraceback (most recent call last):\r\n  File \"weight_quantize.py\", line 46, in <module>\r\n    tflite_quant_model = converter.convert()\r\n  File \"/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py\", line 993, in convert\r\n    inference_output_type)\r\n  File \"/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py\", line 239, in _calibrate_quantize_model\r\n    inference_output_type, allow_float)\r\n  File \"/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/optimize/calibrator.py\", line 78, in calibrate_and_quantize\r\n    np.dtype(output_type.as_numpy_dtype()).num, allow_float)\r\n  File \"/home/morrisc/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 115, in QuantizeModel\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)\r\nRuntimeError: Quantization not yet supported for op: CUSTOM\r\n\r\nHowever, if I don't enforce full integer quantization for all ops and use integer input and output. It works. But such model won't run Edge TPU\r\n", "comments": ["Try setting this flag in the converter:\r\nconverter.allow_custom_ops = True", "@liyunlu0618 I have already set up that flag but still get the error. \r\nIf I don't set the flag, the error is\r\nHere is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.\r\n\r\nWhen I set the flag, the error is\r\nRuntimeError: Quantization not yet supported for op: CUSTOM", "@liyunlu0618 any solution yet?", "Is there a solution for this? I encountered the same problem.", "I have the same error converting to tflite with the following code:\r\n\r\n```\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)\r\nconverter.allow_custom_ops = True\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_model = converter.convert()\r\n```\r\n\r\nTraceback (most recent call last):                                                                                                                                                                                 \r\n  File \"detect_object_lite_images_explicit_quantization_saved_from_frozen_graph.py\", line 225, in <module>                                                                                                         \r\n    tflite_model = converter.convert()                                                                                                                                                                             \r\n  File \"/home/vinorth/anaconda3/envs/coral_tf2/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 1018, in convert                                                                             \r\n    self.experimental_new_quantizer)                                                                                                                                                                               \r\n  File \"/home/vinorth/anaconda3/envs/coral_tf2/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 243, in _calibrate_quantize_model                                                            \r\n    inference_output_type, allow_float, enable_mlir_quantizer)                                                                                                                                                     \r\n  File \"/home/vinorth/anaconda3/envs/coral_tf2/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/calibrator.py\", line 81, in calibrate_and_quantize                                                 \r\n    enable_mlir_quantizer)                                                                                                                                                                                         \r\n  File \"/home/vinorth/anaconda3/envs/coral_tf2/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 115, in QuantizeModel                           \r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, *args)                                                                                                                 \r\nRuntimeError: Quantization not yet supported for op: CUSTOM   \r\n\r\nDo you have any update for this?", "I could not find any solution. Finally, I had to go for quantization aware training.\r\nAt the time, slim supported quantization aware training on single GPU only.  ", "I feel like I tried everything for post training quantization and nothing worked..\r\n\r\nSo, can you explain me how you performed quantization aware training?", "Facing the same issue unfortunately. The post training quantization on SSD models just doesn't work. And not all models available in the Object detection Model Zoo are quantize aware trained so can't use the older quantization method either.", "Sorry for the delayed response. Please remove this line:\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n\r\nThe custom op needs to be kept in float execution. This line is forcing quantization to happen which doesn't work.", "> I feel like I tried everything for post training quantization and nothing worked..\r\n> \r\n> So, can you explain me how you performed quantization aware training?\r\n\r\nI am on the same boat. Tried the newly launched API for Quantization Aware Training and it worked.\r\n[https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html](https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html)", "Try the combination of flags below. The lines commented out are flags that need to be removed.\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n#converter.inference_input_type = tf.uint8\r\n#converter.inference_output_type = tf.uint8\r\nconverter.allow_custom_ops = True\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.experimental_new_converter = False\r\ntflite_quant_model = converter.convert()", "Please are these two flags:\r\n#converter.inference_input_type = tf.uint8\r\n#converter.inference_output_type = tf.uint8\r\n\r\nnow supported in the tf-nightly 2.5.0 version? I am still getting the same error when I uncomment those flags\r\n ", "> Try the combination of flags below. The lines commented out are flags that need to be removed.\r\n> \r\n> converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\n> converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n> #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n> #converter.inference_input_type = tf.uint8\r\n> #converter.inference_output_type = tf.uint8\r\n> converter.allow_custom_ops = True\r\n> converter.representative_dataset = representative_dataset_gen\r\n> converter.experimental_new_converter = False\r\n> tflite_quant_model = converter.convert()\r\n\r\nThis worked for me. \r\n\r\nSSD_mobilenetV2 exported with export_graph_tf2.py\r\n\r\nThanks", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "I think my issue is resolved, thanks.\n\nBest,\n-Joseph\n\n________________________________\nFrom: Alfred Sorten Wolf <notifications@github.com>\nSent: Monday, February 1, 2021 9:10:51 AM\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Aribido, Oluwaseun Joseph <oja@gatech.edu>; Comment <comment@noreply.github.com>\nSubject: Re: [tensorflow/tensorflow] RuntimeError: Quantization not yet supported for op: CUSTOM in Post Training Quantization (#33925)\n\n\nHi There,\n\nWe are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help.\n\nThis issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F33925%23issuecomment-770884852&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792055669%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=ZXC3%2B8%2FQZMCJ8su9ma9klP9%2FHz3Fr5%2FzNaLCXCB9qQs%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAFMF2WJX433EPEPHWYXU65TS42Y6XANCNFSM4JIAIEAQ&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792065664%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=AiNX5PQB4GG7IAa0xGBjejHKbikH%2Bez5PEk2wvZ07kM%3D&reserved=0>.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33925\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33925\">No</a>\n", "> I think my issue is resolved, thanks. Best, -Joseph\r\n> [\u2026](#)\r\n> ________________________________ From: Alfred Sorten Wolf <notifications@github.com> Sent: Monday, February 1, 2021 9:10:51 AM To: tensorflow/tensorflow <tensorflow@noreply.github.com> Cc: Aribido, Oluwaseun Joseph <oja@gatech.edu>; Comment <comment@noreply.github.com> Subject: Re: [tensorflow/tensorflow] RuntimeError: Quantization not yet supported for op: CUSTOM in Post Training Quantization (#33925) Hi There, We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information. \u2014 You are receiving this because you commented. Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F33925%23issuecomment-770884852&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792055669%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=ZXC3%2B8%2FQZMCJ8su9ma9klP9%2FHz3Fr5%2FzNaLCXCB9qQs%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAFMF2WJX433EPEPHWYXU65TS42Y6XANCNFSM4JIAIEAQ&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792065664%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=AiNX5PQB4GG7IAa0xGBjejHKbikH%2Bez5PEk2wvZ07kM%3D&reserved=0>.\r\n\r\nhei, how you resolve that?", "> > I think my issue is resolved, thanks. Best, -Joseph\r\n> > [\u2026](#)\r\n> > ________________________________ From: Alfred Sorten Wolf [notifications@github.com](mailto:notifications@github.com) Sent: Monday, February 1, 2021 9:10:51 AM To: tensorflow/tensorflow [tensorflow@noreply.github.com](mailto:tensorflow@noreply.github.com) Cc: Aribido, Oluwaseun Joseph [oja@gatech.edu](mailto:oja@gatech.edu); Comment [comment@noreply.github.com](mailto:comment@noreply.github.com) Subject: Re: [tensorflow/tensorflow] RuntimeError: Quantization not yet supported for op: CUSTOM in Post Training Quantization (#33925) Hi There, We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information. \u2014 You are receiving this because you commented. Reply to this email directly, view it on GitHubhttps://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F33925%23issuecomment-770884852&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792055669%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=ZXC3%2B8%2FQZMCJ8su9ma9klP9%2FHz3Fr5%2FzNaLCXCB9qQs%3D&reserved=0, or unsubscribehttps://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAFMF2WJX433EPEPHWYXU65TS42Y6XANCNFSM4JIAIEAQ&data=04%7C01%7Coja%40gatech.edu%7C460a046d0bf14bc2a40d08d8c6bb3d68%7C482198bbae7b4b258b7a6d7f32faa083%7C0%7C0%7C637477854792065664%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=AiNX5PQB4GG7IAa0xGBjejHKbikH%2Bez5PEk2wvZ07kM%3D&reserved=0.\r\n> \r\n> hei, how you resolve that?\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset\r\n\r\nconverter.allow_custom_ops = True\r\n\r\nconverter.experimental_new_converter = False\r\ntflite_quant_model = converter.convert()\r\n\r\nFinally this gave me an output tflite file now...will update you on its correctness", "Just include the newest new quantizer. And try to use the saved model export without the preprocess inside it.\r\n```\r\nimport tensorflow as tf\r\n\r\n# Convert the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('/path/saved_model')\r\ndef representative_data_gen():\r\n    img = (np.clip(representative_image,-1,1).astype(np.float32)\r\n    yield [img]\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n# This ensures that if any ops can't be quantized, the converter throws an error\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n\r\n# \"\"\"comment next 4 lines if not quantize input\"\"\"\r\n\r\n# converter.quantized_input_stats = {'serving_default_input':[0,1]}\r\nconverter._experimental_new_quantizer = True\r\n# converter.inference_input_type = tf.uint8\r\n# converter.inference_output_type = tf.float32\r\n\r\nconverter.allow_custom_ops = True\r\n\r\nconverter.representative_dataset = representative_data_gen\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```", "tensorflow 2.6.0rc0 works for me"]}, {"number": 33924, "title": "Bidirectional LSTM fail on TF2.0", "body": "I tried to reproduce the \"Text classification with an RNN\" article from tensorflow main page (https://www.tensorflow.org/tutorials/text/text_classification_rnn), but it seems that the code is not running properly when it's executed on my local machine. Unfortunatly, I'm not able to reproduce the error on Colab.\r\n\r\nIt run for few iteration, but no more than 1 epochs..\r\n\r\n**System information**\r\n- Code is provided by TensorFlow\r\n- Running on Windows 10\r\n- TensorFlow installed from pip\r\n- TensorFlow version 2.0\r\n- Python version 3.6\r\n- CUDA 10.0 /cuDNN 7.6.4.38\r\n- GeForce GTX 1060\r\n\r\n\r\n****\r\n\r\n**I get the following error**\r\n\r\n2019-11-01 21:49:02.287950: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1915): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2019-11-01 21:49:02.289212: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1974, 64, 64] \r\n2019-11-01 21:49:02.289778: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1974, 64, 64] \r\n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\r\n2019-11-01 21:49:02.290428: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\n\t [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n2019-11-01 21:49:02.291354: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\n    313/Unknown - 40s 128ms/step - loss: 0.6864 - accuracy: 0.5492\r\n    313/Unknown - 40s 128ms/step - loss: 0.6864 - accuracy: 0.5492Traceback (most recent call last):\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm Community Edition 2019.2.3\\helpers\\pydev\\_pydevd_bundle\\pydevd_exec2.py\", line 3, in Exec\r\n    exec(exp, global_vars, local_vars)\r\n  File \"<string>\", line 4, in <module>\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_7835]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\nException ignored in: <bound method _RandomSeedGeneratorDeleter.__del__ of <tensorflow.python.data.ops.dataset_ops._RandomSeedGeneratorDeleter object at 0x000001D23EA44278>>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 3009, in __del__\r\nAttributeError: 'NoneType' object has no attribute 'device'\r\n\r\n****\r\nI tried to change the optimizer, use GRU or other RNN, but as soon as I get the Bidirectional wrapper, I get this error.\r\nTensorFlow-gpu is up to date, drivers are as well.\r\n\r\n****\r\n**The Code to reproduce the error is litterally the one from the webpage**\r\nhttps://www.tensorflow.org/tutorials/text/text_classification_rnn\r\n", "comments": ["Reducing the batch_size didn't solve the problem. However, it's working while running on a CPU.", "@PierrePivert ,\r\nI tried running tutorial for TF-2.0 and didn't face any error, can you please provide colab gist which you are trying to execute. Thanks!", "@oanush \r\n\r\nThe Colab link is [the TensorFlow tutorial](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb#scrollTo=SHRwRoP2nVHX)\r\n\r\nWhile running on Colab, it seems that there is no error. Is it due to any dependency ?\r\n\r\nWhen I run i locally, I always get the error while training, after calling model.fit()\r\nI train for few batches, sometime 1 or 2 epochs, and then it breaks.\r\n\r\n> 2019-11-04 14:27:03.014232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n2019-11-04 14:27:07.065064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-11-04 14:27:08.048310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2019-11-04 14:27:08.048631: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-11-04 14:27:08.051456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-04 14:27:08.054706: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-11-04 14:27:08.059675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2019-11-04 14:27:08.059965: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-11-04 14:27:08.061395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-04 14:27:09.740842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-04 14:27:09.741053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-11-04 14:27:09.741180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-11-04 14:27:09.743525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nVocabulary size: 8185\r\nEncoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\r\nThe original string: \"Hello TensorFlow.\"\r\n4025 ----> Hell\r\n222 ----> o \r\n6307 ----> Ten\r\n2327 ----> sor\r\n4043 ----> Fl\r\n2120 ----> ow\r\n7975 ----> .\r\nModel: \"sequential\"\r\nLayer (type)                 Output Shape              Param #   \r\n================================================================\r\nembedding (Embedding)        (None, None, 64)          523840    \r\nbidirectional (Bidirectional (None, 128)               66048     \r\ndense (Dense)                (None, 64)                8256      \r\ndense_1 (Dense)              (None, 1)                 65        \r\n================================================================\r\nTotal params: 598,209\r\nTrainable params: 598,209\r\nNon-trainable params: 0\r\nEpoch 1/10\r\n2019-11-04 14:27:13.925137: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_4281_4463' and '__inference___backward_cudnn_lstm_with_fallback_4281_4463_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_6315' both implement 'lstm_2f9c1fbb-3058-4776-b0dc-2b8cbedc4f81' but their signatures do not match.\r\n2019-11-04 14:27:14.146050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2019-11-04 14:27:14.838809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n      1/Unknown - 6s 6s/step - loss: 0.6989 - accuracy: 0.3906\r\n      2/Unknown - 6s 3s/step - loss: 0.6958 - accuracy: 0.4531\r\n      3/Unknown - 6s 2s/step - loss: 0.6950 - accuracy: 0.4688\r\n      4/Unknown - 6s 1s/step - loss: 0.6939 - accuracy: 0.5000\r\n      5/Unknown - 6s 1s/step - loss: 0.6932 - accuracy: 0.5188\r\n      6/Unknown - 6s 1s/step - loss: 0.6938 - accuracy: 0.5000\r\n      7/Unknown - 6s 883ms/step - loss: 0.6941 - accuracy: 0.4888\r\n      8/Unknown - 6s 791ms/step - loss: 0.6946 - accuracy: 0.4707\r\n      9/Unknown - 6s 715ms/step - loss: 0.6944 - accuracy: 0.4740\r\n     10/Unknown - 7s 653ms/step - loss: 0.6940 - accuracy: 0.4859\r\n     11/Unknown - 7s 604ms/step - loss: 0.6940 - accuracy: 0.4872\r\n     12/Unknown - 7s 562ms/step - loss: 0.6943 - accuracy: 0.4753\r\n     13/Unknown - 7s 527ms/step - loss: 0.6941 - accuracy: 0.4796\r\n     14/Unknown - 7s 497ms/step - loss: 0.6942 - accuracy: 0.4766\r\n     15/Unknown - 7s 472ms/step - loss: 0.6940 - accuracy: 0.4812\r\n     16/Unknown - 7s 449ms/step - loss: 0.6939 - accuracy: 0.4883\r\n     17/Unknown - 7s 431ms/step - loss: 0.6939 - accuracy: 0.4881\r\n     18/Unknown - 7s 413ms/step - loss: 0.6938 - accuracy: 0.4887\r\n     19/Unknown - 8s 396ms/step - loss: 0.6938 - accuracy: 0.4910\r\n     20/Unknown - 8s 383ms/step - loss: 0.6937 - accuracy: 0.4922\r\n     21/Unknown - 8s 370ms/step - loss: 0.6937 - accuracy: 0.4903\r\n     22/Unknown - 8s 359ms/step - loss: 0.6938 - accuracy: 0.4879\r\n     23/Unknown - 8s 349ms/step - loss: 0.6938 - accuracy: 0.4878\r\n     24/Unknown - 8s 338ms/step - loss: 0.6937 - accuracy: 0.4902\r\n     25/Unknown - 8s 330ms/step - loss: 0.6937 - accuracy: 0.4919\r\n     26/Unknown - 8s 322ms/step - loss: 0.6936 - accuracy: 0.4964\r\n     27/Unknown - 8s 314ms/step - loss: 0.6935 - accuracy: 0.4977\r\n     28/Unknown - 9s 307ms/step - loss: 0.6935 - accuracy: 0.4961\r\n     29/Unknown - 9s 300ms/step - loss: 0.6934 - accuracy: 0.4989\r\n     30/Unknown - 9s 294ms/step - loss: 0.6934 - accuracy: 0.5031\r\n     31/Unknown - 9s 289ms/step - loss: 0.6934 - accuracy: 0.5015\r\n     32/Unknown - 9s 284ms/step - loss: 0.6934 - accuracy: 0.5020\r\n     33/Unknown - 9s 278ms/step - loss: 0.6933 - accuracy: 0.5038\r\n     34/Unknown - 9s 274ms/step - loss: 0.6933 - accuracy: 0.5046\r\n     35/Unknown - 9s 269ms/step - loss: 0.6933 - accuracy: 0.5036\r\n     36/Unknown - 10s 265ms/step - loss: 0.6933 - accuracy: 0.5017\r\n     37/Unknown - 10s 261ms/step - loss: 0.6934 - accuracy: 0.5000\r\n     38/Unknown - 10s 256ms/step - loss: 0.6933 - accuracy: 0.5029\r\n     39/Unknown - 10s 253ms/step - loss: 0.6932 - accuracy: 0.5032\r\n     40/Unknown - 10s 249ms/step - loss: 0.6932 - accuracy: 0.5020\r\n     41/Unknown - 10s 245ms/step - loss: 0.6932 - accuracy: 0.5038\r\n     42/Unknown - 10s 242ms/step - loss: 0.6932 - accuracy: 0.5045\r\n     43/Unknown - 10s 238ms/step - loss: 0.6932 - accuracy: 0.5036\r\n     44/Unknown - 10s 236ms/step - loss: 0.6932 - accuracy: 0.5032\r\n     45/Unknown - 10s 233ms/step - loss: 0.6932 - accuracy: 0.5024\r\n     46/Unknown - 11s 230ms/step - loss: 0.6932 - accuracy: 0.5020\r\n     47/Unknown - 11s 227ms/step - loss: 0.6932 - accuracy: 0.5033\r\n     48/Unknown - 11s 225ms/step - loss: 0.6931 - accuracy: 0.5052\r\n     49/Unknown - 11s 224ms/step - loss: 0.6931 - accuracy: 0.5054\r\n     50/Unknown - 11s 221ms/step - loss: 0.6931 - accuracy: 0.5066\r\n     51/Unknown - 11s 219ms/step - loss: 0.6931 - accuracy: 0.5049\r\n     52/Unknown - 11s 217ms/step - loss: 0.6931 - accuracy: 0.5054\r\n     53/Unknown - 11s 215ms/step - loss: 0.6931 - accuracy: 0.5038\r\n     54/Unknown - 11s 213ms/step - loss: 0.6931 - accuracy: 0.5058\r\n     55/Unknown - 12s 211ms/step - loss: 0.6931 - accuracy: 0.5054\r\n     56/Unknown - 12s 209ms/step - loss: 0.6931 - accuracy: 0.5047\r\n     57/Unknown - 12s 207ms/step - loss: 0.6932 - accuracy: 0.5030\r\n     58/Unknown - 12s 206ms/step - loss: 0.6932 - accuracy: 0.5027\r\n     59/Unknown - 12s 204ms/step - loss: 0.6932 - accuracy: 0.5021\r\n     60/Unknown - 12s 202ms/step - loss: 0.6931 - accuracy: 0.5026\r\n     61/Unknown - 12s 201ms/step - loss: 0.6932 - accuracy: 0.5023\r\n     62/Unknown - 12s 200ms/step - loss: 0.6932 - accuracy: 0.5023\r\n     63/Unknown - 12s 198ms/step - loss: 0.6932 - accuracy: 0.5015\r\n     64/Unknown - 13s 196ms/step - loss: 0.6932 - accuracy: 0.5000\r\n     65/Unknown - 13s 195ms/step - loss: 0.6932 - accuracy: 0.4998\r\n     66/Unknown - 13s 194ms/step - loss: 0.6932 - accuracy: 0.5005\r\n     67/Unknown - 13s 192ms/step - loss: 0.6931 - accuracy: 0.5009\r\n     68/Unknown - 13s 191ms/step - loss: 0.6932 - accuracy: 0.4991\r\n     69/Unknown - 13s 190ms/step - loss: 0.6932 - accuracy: 0.5000\r\n     70/Unknown - 13s 189ms/step - loss: 0.6932 - accuracy: 0.4989\r\n     71/Unknown - 13s 188ms/step - loss: 0.6932 - accuracy: 0.4974\r\n     72/Unknown - 13s 187ms/step - loss: 0.6932 - accuracy: 0.4967\r\n     73/Unknown - 14s 186ms/step - loss: 0.6933 - accuracy: 0.4959\r\n     74/Unknown - 14s 185ms/step - loss: 0.6933 - accuracy: 0.4962\r\n     75/Unknown - 14s 184ms/step - loss: 0.6933 - accuracy: 0.4958\r\n     76/Unknown - 14s 183ms/step - loss: 0.6933 - accuracy: 0.4971\r\n     77/Unknown - 14s 182ms/step - loss: 0.6932 - accuracy: 0.4984\r\n     78/Unknown - 14s 181ms/step - loss: 0.6932 - accuracy: 0.4994\r\n     79/Unknown - 14s 181ms/step - loss: 0.6932 - accuracy: 0.5006\r\n     80/Unknown - 14s 180ms/step - loss: 0.6932 - accuracy: 0.5020\r\n     81/Unknown - 14s 179ms/step - loss: 0.6932 - accuracy: 0.5033\r\n     82/Unknown - 15s 178ms/step - loss: 0.6932 - accuracy: 0.5029\r\n     83/Unknown - 15s 177ms/step - loss: 0.6932 - accuracy: 0.5030\r\n     84/Unknown - 15s 176ms/step - loss: 0.6932 - accuracy: 0.5030\r\n     85/Unknown - 15s 176ms/step - loss: 0.6932 - accuracy: 0.5022\r\n     86/Unknown - 15s 175ms/step - loss: 0.6932 - accuracy: 0.5031\r\n     87/Unknown - 15s 175ms/step - loss: 0.6932 - accuracy: 0.5025\r\n     88/Unknown - 15s 174ms/step - loss: 0.6932 - accuracy: 0.5023\r\n     89/Unknown - 15s 173ms/step - loss: 0.6932 - accuracy: 0.5019\r\n     90/Unknown - 15s 172ms/step - loss: 0.6932 - accuracy: 0.5024\r\n     91/Unknown - 16s 171ms/step - loss: 0.6932 - accuracy: 0.5022\r\n     92/Unknown - 16s 171ms/step - loss: 0.6932 - accuracy: 0.5022\r\n     93/Unknown - 16s 170ms/step - loss: 0.6932 - accuracy: 0.5020\r\n     94/Unknown - 16s 169ms/step - loss: 0.6932 - accuracy: 0.5020\r\n     95/Unknown - 16s 168ms/step - loss: 0.6932 - accuracy: 0.5021\r\n     96/Unknown - 16s 168ms/step - loss: 0.6932 - accuracy: 0.5011\r\n     97/Unknown - 16s 167ms/step - loss: 0.6932 - accuracy: 0.5008\r\n     98/Unknown - 16s 167ms/step - loss: 0.6932 - accuracy: 0.5011\r\n     99/Unknown - 16s 166ms/step - loss: 0.6932 - accuracy: 0.5002\r\n    100/Unknown - 17s 165ms/step - loss: 0.6932 - accuracy: 0.5014\r\n    101/Unknown - 17s 164ms/step - loss: 0.6932 - accuracy: 0.5017\r\n    102/Unknown - 17s 164ms/step - loss: 0.6932 - accuracy: 0.5012\r\n    103/Unknown - 17s 163ms/step - loss: 0.6932 - accuracy: 0.5012\r\n    103/Unknown - 17s 163ms/step - loss: 0.6932 - accuracy: 0.50122019-11-04 14:27:27.704423: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1915): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2019-11-04 14:27:27.706061: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1255, 64, 64] \r\n2019-11-04 14:27:27.706782: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1255, 64, 64] \r\n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\r\n2019-11-04 14:27:27.707801: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\n\t [[Reshape_11/_38]]\r\n2019-11-04 14:27:27.708194: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Woody/Dropbox/Research/MachineLearning/AI.py\", line 2389, in <module>\r\n    Text_Classification_With_RNN()\r\n  File \"C:/Users/Woody/Dropbox/Research/MachineLearning/AI.py\", line 1179, in Text_Classification_With_RNN\r\n    validation_steps=30)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_41}}]]\r\n\t [[Reshape_11/_38]] [Op:__inference_distributed_function_6315]\r\nFunction call stack:\r\ndistributed_function\r\nException ignored in: <bound method _RandomSeedGeneratorDeleter.__del__ of <tensorflow.python.data.ops.dataset_ops._RandomSeedGeneratorDeleter object at 0x00000115D931FF98>>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Woody\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 3009, in __del__\r\nAttributeError: 'NoneType' object has no attribute 'device'\r\nProcess finished with exit code 1", "From what I see, it's all about the Bidirectional layer. When I use single LSTM, or replace by anything else, I don't get any error. What's different in Bidirectional layer from others ?", "aha, i meet the same error too! It will run error on my windows! But it can run fluently on Google colab! I think it maybe the multiprocessing or multithread difference between windows and linux\uff01\r\nthis is my test code:\r\n``` python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n(train_data, test_data), info = tfds.load(\r\n    'imdb_reviews/subwords8k', \r\n    split = (tfds.Split.TRAIN, tfds.Split.TEST), \r\n    with_info=True, as_supervised=True)\r\nencoder = info.features['text'].encoder\r\npadded_shapes = ([None],())\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\r\n\r\nembedding_dim=16\r\n\r\nmodel = keras.Sequential([\r\n    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=True),\r\n    layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit(\r\n    train_batches,\r\n    epochs=10,\r\n    validation_data=test_batches, validation_steps=20,verbose=2)\r\n```\r\nand this is my error information:\r\n```python\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-2-8f27353fef79> in <module>\r\n     31     train_batches,\r\n     32     epochs=10,\r\n---> 33     validation_data=test_batches, validation_steps=20,verbose=2)\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    485       # In this case we have created variables on the first call, so we run the\r\n    486       # defunned version which is guaranteed to never create variables.\r\n--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    488     elif self._stateful_fn is not None:\r\n    489       # Release the lock early so that multiple threads can perform the call\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_16087]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```", "I tried this code on jupyter \uff0cand it runs error, I suspect the Ipython. So i tried this code on  PyCharm, and run as a python file, it also run error!\r\nMy computer Version is Win10 1903, and with tensorflow2.0.\r\nI think this error turns out because this multiprocessing on windows >_<! it will run fluently in the first epoch in the little batchsize, but will turn out error in the first epoch every time. I try the same on Google colab, and it run without error. So i think it maybe the difference between windows and linux.\r\nThis is pycharm error information following:\r\n```python\r\n2019-11-09 14:20:45.864806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nWARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\r\n2019-11-09 14:20:48.822042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2019-11-09 14:20:48.847695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2019-11-09 14:20:48.847949: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-11-09 14:20:48.849004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-09 14:20:48.849487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-11-09 14:20:48.852594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2019-11-09 14:20:48.852792: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2019-11-09 14:20:48.853657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-09 14:20:49.462772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-09 14:20:49.462917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-11-09 14:20:49.463001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-11-09 14:20:49.463710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nEpoch 1/10\r\n2019-11-09 14:20:56.643344: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_15158_15757' and '__inference___backward_cudnn_lstm_with_fallback_12868_14345_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_15947' both implement 'lstm_f5708b4f-5dee-466e-99cd-f92ee26d050c' but their signatures do not match.\r\n2019-11-09 14:20:56.905324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2019-11-09 14:20:57.366456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\r\n      1/Unknown - 7s 7s/step - loss: 0.6934 - accuracy: 0.3000\r\n      2/Unknown - 7s 4s/step - loss: 0.6913 - accuracy: 0.5500\r\n      3/Unknown - 7s 2s/step - loss: 0.6942 - accuracy: 0.4333\r\n      4/Unknown - 7s 2s/step - loss: 0.6952 - accuracy: 0.4000\r\n      5/Unknown - 7s 1s/step - loss: 0.6957 - accuracy: 0.3800\r\n     ...............................................\r\n    234/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5197\r\n    235/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5196\r\n    236/Unknown - 21s 90ms/step - loss: 0.6912 - accuracy: 0.5191\r\n    237/Unknown - 21s 90ms/step - loss: 0.6913 - accuracy: 0.5177\r\n    238/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5185\r\n    239/Unknown - 21s 89ms/step - loss: 0.6910 - accuracy: 0.5192\r\n    240/Unknown - 21s 89ms/step - loss: 0.6910 - accuracy: 0.5192\r\n    241/Unknown - 21s 89ms/step - loss: 0.6908 - accuracy: 0.51952019-11-09 14:21:13.353816: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1887): 'cudnnRNNBackwardDataEx( cudnn.handle(), rnn_desc.handle(), output_desc.data_handle(), output_data.opaque(), output_desc.data_handle(), output_backprop_data.opaque(), nullptr, nullptr, output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.data_handle(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2019-11-09 14:21:13.354630: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n2019-11-09 14:21:13.354992: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n\t [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\r\n2019-11-09 14:21:13.364064: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\n\t [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n2019-11-09 14:21:13.364349: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\nTraceback (most recent call last):\r\n  File \"D:/Documents/Project/Python/2019/mission2/test2.py\", line 33, in <module>\r\n    validation_data=test_batches, validation_steps=20)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n\r\n    batch_outs = execution_function(iterator)\r\n    242/Unknown - 22s 90ms/step - loss: 0.6908 - accuracy: 0.5195\r\n    242/Unknown - 22s 90ms/step - loss: 0.6908 - accuracy: 0.5195  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_15947]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "I ran in jupyterlab on ubuntu18.04 and got the similar error.  \r\n\r\n```\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Embedding(vocab_size, 64))\r\nmodel.add(tf.keras.layers.Masking(mask_value=0.0))\r\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\r\n\r\n# One or more dense layers.\r\n# Edit the list in the `for` line to experiment with layer sizes.\r\nfor units in [64, 64]:\r\n  model.add(tf.keras.layers.Dense(units, activation='relu'))\r\n\r\n# Output layer. The first argument is the number of labels.\r\nmodel.add(tf.keras.layers.Dense(3, activation='softmax'))\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(train_data, epochs=3, validation_data=test_data)\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-44-6cda1377e0de> in <module>\r\n----> 1 model.fit(train_data, epochs=3, validation_data=test_data)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    485       # In this case we have created variables on the first call, so we run the\r\n    486       # defunned version which is guaranteed to never create variables.\r\n--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    488     elif self._stateful_fn is not None:\r\n    489       # Release the lock early so that multiple threads can perform the call\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n/opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_7/_30}}]] [Op:__inference_distributed_function_123616]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n```", "Is there a working solution? I am facing the same problems.  My model is constructed as below:\r\n\r\n```python\r\n    dense_layer = DensenetLayer(use_imagenet_weight=use_imagenet_weight, dense_net_name=dense_name, trainable=trainable)\r\n    forward_layer = keras.layers.LSTM(units=hidden_size, return_sequences=True, name=\"lstm-forward\")\r\n    backward_layer = keras.layers.LSTM(units=hidden_size, activation='relu', return_sequences=True,\r\n                                       go_backwards=True, name=\"lstm-backward\")\r\n    rnn = keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer, name=\"bidirectional-lstm\")\r\n    model = keras.Sequential([\r\n        dense_layer,\r\n        rnn,\r\n        keras.layers.Dense(hidden_size, activation='relu'),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.Dropout(rate=dropout),\r\n        keras.layers.Dense(output_shape[-1], activation=\"softmax\", name=\"predictions\"),\r\n    ])\r\n```\r\nI wrapped a DenseNet to process a sequence of images, and feeding the output to a Bidrectional LSTM, and it came out the same problem.\r\n\r\nAnd I follow the instructions provided [here](https://github.com/tensorflow/tensorflow/issues/33258#issuecomment-542931207), now it sucked,  nothing printed!", "> I tried this code on jupyter \uff0cand it runs error, I suspect the Ipython. So i tried this code on PyCharm, and run as a python file, it also run error!\r\n> My computer Version is Win10 1903, and with tensorflow2.0.\r\n> I think this error turns out because this multiprocessing on windows >_<! it will run fluently in the first epoch in the little batchsize, but will turn out error in the first epoch every time. I try the same on Google colab, and it run without error. So i think it maybe the difference between windows and linux.\r\n> This is pycharm error information following:\r\n> \r\n> ```python\r\n> 2019-11-09 14:20:45.864806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\n> WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\r\n> 2019-11-09 14:20:48.822042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n> 2019-11-09 14:20:48.847695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\n> name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\n> pciBusID: 0000:01:00.0\r\n> 2019-11-09 14:20:48.847949: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n> 2019-11-09 14:20:48.849004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n> 2019-11-09 14:20:48.849487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n> 2019-11-09 14:20:48.852594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\n> name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\n> pciBusID: 0000:01:00.0\r\n> 2019-11-09 14:20:48.852792: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n> 2019-11-09 14:20:48.853657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n> 2019-11-09 14:20:49.462772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-11-09 14:20:49.462917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n> 2019-11-09 14:20:49.463001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n> 2019-11-09 14:20:49.463710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n> Epoch 1/10\r\n> 2019-11-09 14:20:56.643344: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_15158_15757' and '__inference___backward_cudnn_lstm_with_fallback_12868_14345_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_15947' both implement 'lstm_f5708b4f-5dee-466e-99cd-f92ee26d050c' but their signatures do not match.\r\n> 2019-11-09 14:20:56.905324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n> 2019-11-09 14:20:57.366456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n> \r\n>       1/Unknown - 7s 7s/step - loss: 0.6934 - accuracy: 0.3000\r\n>       2/Unknown - 7s 4s/step - loss: 0.6913 - accuracy: 0.5500\r\n>       3/Unknown - 7s 2s/step - loss: 0.6942 - accuracy: 0.4333\r\n>       4/Unknown - 7s 2s/step - loss: 0.6952 - accuracy: 0.4000\r\n>       5/Unknown - 7s 1s/step - loss: 0.6957 - accuracy: 0.3800\r\n>      ...............................................\r\n>     234/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5197\r\n>     235/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5196\r\n>     236/Unknown - 21s 90ms/step - loss: 0.6912 - accuracy: 0.5191\r\n>     237/Unknown - 21s 90ms/step - loss: 0.6913 - accuracy: 0.5177\r\n>     238/Unknown - 21s 90ms/step - loss: 0.6911 - accuracy: 0.5185\r\n>     239/Unknown - 21s 89ms/step - loss: 0.6910 - accuracy: 0.5192\r\n>     240/Unknown - 21s 89ms/step - loss: 0.6910 - accuracy: 0.5192\r\n>     241/Unknown - 21s 89ms/step - loss: 0.6908 - accuracy: 0.51952019-11-09 14:21:13.353816: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\n> in tensorflow/stream_executor/cuda/cuda_dnn.cc(1887): 'cudnnRNNBackwardDataEx( cudnn.handle(), rnn_desc.handle(), output_desc.data_handle(), output_data.opaque(), output_desc.data_handle(), output_backprop_data.opaque(), nullptr, nullptr, output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.data_handle(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n> 2019-11-09 14:21:13.354630: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n> 2019-11-09 14:21:13.354992: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n> \t [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\r\n> 2019-11-09 14:21:13.364064: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n> \t [[{{node Reshape_11/_38}}]]\r\n> \t [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n> 2019-11-09 14:21:13.364349: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n> \t [[{{node Reshape_11/_38}}]]\r\n> Traceback (most recent call last):\r\n>   File \"D:/Documents/Project/Python/2019/mission2/test2.py\", line 33, in <module>\r\n>     validation_data=test_batches, validation_steps=20)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n>     total_epochs=epochs)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n> \r\n>     batch_outs = execution_function(iterator)\r\n>     242/Unknown - 22s 90ms/step - loss: 0.6908 - accuracy: 0.5195\r\n>     242/Unknown - 22s 90ms/step - loss: 0.6908 - accuracy: 0.5195  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n>     distributed_function(input_fn))\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n>     result = self._call(*args, **kwds)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\r\n>     return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\r\n>     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\r\n>     self.captured_inputs)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\r\n>     ctx, args, cancellation_manager=cancellation_manager)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\r\n>     ctx=ctx)\r\n>   File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n>     six.raise_from(core._status_to_exception(e.code, message), None)\r\n>   File \"<string>\", line 3, in raise_from\r\n> tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n> \t [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_15947]\r\n> \r\n> Function call stack:\r\n> distributed_function\r\n> \r\n> \r\n> Process finished with exit code 1\r\n> ```\r\n\r\nsame situation, same error", "Sorry for the late reply. The following log indicates some error within the cudnn kernel itself. Adding @houtoms from Nvidia for more inputs\r\n\r\n`\r\n241/Unknown - 21s 89ms/step - loss: 0.6908 - accuracy: 0.51952019-11-09 14:21:13.353816: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1887): 'cudnnRNNBackwardDataEx( cudnn.handle(), rnn_desc.handle(), output_desc.data_handle(), output_data.opaque(), output_desc.data_handle(), output_backprop_data.opaque(), nullptr, nullptr, output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.data_handle(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2019-11-09 14:21:13.354630: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n2019-11-09 14:21:13.354992: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32] \r\n\t [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\r\n2019-11-09 14:21:13.364064: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\n\t [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n2019-11-09 14:21:13.364349: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\n\r\n`", "> Sorry for the late reply. The following log indicates some error within the cudnn kernel itself. Adding @houtoms from Nvidia for more inputs\r\n> \r\n> `\r\n> 241/Unknown - 21s 89ms/step - loss: 0.6908 - accuracy: 0.51952019-11-09 14:21:13.353816: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\n> in tensorflow/stream_executor/cuda/cuda_dnn.cc(1887): 'cudnnRNNBackwardDataEx( cudnn.handle(), rnn_desc.handle(), output_desc.data_handle(), output_data.opaque(), output_desc.data_handle(), output_backprop_data.opaque(), nullptr, nullptr, output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.data_handle(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n> 2019-11-09 14:21:13.354630: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32]\r\n> 2019-11-09 14:21:13.354992: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1027, 10, 32]\r\n> [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\r\n> 2019-11-09 14:21:13.364064: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n> [[{{node Reshape_11/_38}}]]\r\n> [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n> 2019-11-09 14:21:13.364349: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n> [[{{node Reshape_11/_38}}]]\r\n> \r\n> `\r\n\r\nThank you for your reply! Then, how can i fix it?", "Seems that the issue only happens at the end of the epoch, which might relate to how cudnn handles the padded data or last partial batch with different shape. \r\n\r\nPlease update the input/test dataset with \"batch(batch_size, **drop_remainder=True**)\" to skip the last partial batch, which should walk around the issue.", "> Seems that the issue only happens at the end of the epoch, which might relate to how cudnn handles the padded data or last partial batch with different shape.\r\n> \r\n> Please update the input/test dataset with \"batch(batch_size, **drop_remainder=True**)\" to skip the last partial batch, which should walk around the issue.\r\n\r\nI try to use `train_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)`\r\n\r\nbut it still run error:\r\n```python\r\nWARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\r\nEpoch 1/10\r\n2500/2500 - 135s - loss: 0.4935 - accuracy: 0.7598 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\r\nEpoch 2/10\r\n---------------------------------------------------------------------------\r\nCancelledError                            Traceback (most recent call last)\r\n<ipython-input-4-2c0bcf168e8d> in <module>\r\n     24     train_batches,\r\n     25     epochs=10,\r\n---> 26     validation_data=test_batches, validation_steps=20,verbose=2)\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    485       # In this case we have created variables on the first call, so we run the\r\n    486       # defunned version which is guaranteed to never create variables.\r\n--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    488     elif self._stateful_fn is not None:\r\n    489       # Release the lock early so that multiple threads can perform the call\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\nc:\\users\\sha\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nCancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_5/_26}}]] [Op:__inference_distributed_function_19951]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n```\r\n\r\nThis is my code:\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n(train_data, test_data), info = tfds.load(\r\n    'imdb_reviews/subwords8k', \r\n    split = (tfds.Split.TRAIN, tfds.Split.TEST), \r\n    with_info=True, as_supervised=True)\r\nencoder = info.features['text'].encoder\r\npadded_shapes = ([None],())\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\n\r\nembedding_dim=16\r\n\r\nmodel = keras.Sequential([\r\n    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=True),\r\n    layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit(\r\n    train_batches,\r\n    epochs=10,\r\n    validation_data=test_batches, validation_steps=20,verbose=2)\r\n```\r\nBy the way\uff0cit will not appear on google cloab.\r\nThank you!", "Your stack trace didn't show much details about the error. The actual error log should appear above your log. I noticed that you are using masks in embedding layer. There is a similar issue reported for cudnn kernel that doesn't handle mask well. See https://github.com/tensorflow/tensorflow/issues/33148", "> Seems that the issue only happens at the end of the epoch, which might relate to how cudnn handles the padded data or last partial batch with different shape.\r\n> \r\n> Please update the input/test dataset with \"batch(batch_size, **drop_remainder=True**)\" to skip the last partial batch, which should walk around the issue.\r\n\r\nI run it on pycharm, and it run error, this is the information:\r\n```python\r\n2020-01-07 15:43:51.988666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nWARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\r\n2020-01-07 15:43:56.203098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-01-07 15:43:56.234766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2020-01-07 15:43:56.235037: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-07 15:43:56.235983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-01-07 15:43:56.236578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-01-07 15:43:56.239978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\n2020-01-07 15:43:56.240369: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\r\n2020-01-07 15:43:56.241117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-01-07 15:43:57.027702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-01-07 15:43:57.027885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-01-07 15:43:57.027989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-01-07 15:43:57.028895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nEpoch 1/10\r\n2020-01-07 15:44:10.623364: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_10649_12064' and '__inference___backward_cudnn_lstm_with_fallback_10649_12064_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_15537' both implement 'lstm_de7d1292-9970-4070-93be-96c64a2665bd' but their signatures do not match.\r\n2020-01-07 15:44:10.959726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\r\n2020-01-07 15:44:11.673193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n\r\n      1/Unknown - 12s 12s/step - loss: 0.6932 - accuracy: 0.6000\r\n     ................................................\r\n    147/Unknown - 19s 129ms/step - loss: 0.6930 - accuracy: 0.5068\r\n    148/Unknown - 19s 129ms/step - loss: 0.6929 - accuracy: 0.5081\r\n    149/Unknown - 19s 129ms/step - loss: 0.6928 - accuracy: 0.5081\r\n    150/Unknown - 19s 128ms/step - loss: 0.6928 - accuracy: 0.5073\r\n    151/Unknown - 19s 127ms/step - loss: 0.6928 - accuracy: 0.5066\r\n    152/Unknown - 19s 127ms/step - loss: 0.6928 - accuracy: 0.5066\r\n    153/Unknown - 19s 126ms/step - loss: 0.6927 - accuracy: 0.5065\r\n    154/Unknown - 19s 126ms/step - loss: 0.6927 - accuracy: 0.5071\r\n    155/Unknown - 19s 125ms/step - loss: 0.6924 - accuracy: 0.5103\r\n    156/Unknown - 19s 125ms/step - loss: 0.6924 - accuracy: 0.51032020-01-07 15:44:21.325024: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1776): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\r\n2020-01-07 15:44:21.325307: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\n2020-01-07 15:44:21.326013: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1498 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1368, 10, 32] \r\n2020-01-07 15:44:21.326287: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\n\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n\r\n```\r\n\r\ncode:\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n(train_data, test_data), info = tfds.load(\r\n    'imdb_reviews/subwords8k',\r\n    split = (tfds.Split.TRAIN, tfds.Split.TEST),\r\n    with_info=True, as_supervised=True)\r\nencoder = info.features['text'].encoder\r\npadded_shapes = ([None],())\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\n\r\nembedding_dim=16\r\n\r\nmodel = keras.Sequential([\r\n    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=True),\r\n    layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit(\r\n    train_batches,\r\n    epochs=10,\r\n    validation_data=test_batches, validation_steps=20)\r\n```", "> Your stack trace didn't show much details about the error. The actual error log should appear above your log. I noticed that you are using masks in embedding layer. There is a similar issue reported for cudnn kernel that doesn't handle mask well. See #33148\r\n\r\nok, i will try.\r\nThank you!", "> Your stack trace didn't show much details about the error. The actual error log should appear above your log. I noticed that you are using masks in embedding layer. There is a similar issue reported for cudnn kernel that doesn't handle mask well. See #33148\r\n\r\nHello, i try to cancel masks ,but is still run error, this time ,the error information changed:\r\n```python\r\n   2498/Unknown - 111s 44ms/step - loss: 0.5512 - accuracy: 0.7254\r\n   2499/Unknown - 111s 44ms/step - loss: 0.5512 - accuracy: 0.7254\r\n   2500/Unknown - 111s 44ms/step - loss: 0.5513 - accuracy: 0.72542020-01-07 15:59:04.621302: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[VariableShape/_22]]\r\n2020-01-07 15:59:04.621683: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2020-01-07 15:59:05.342733: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_14218' and '__inference_cudnn_lstm_with_fallback_14331_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_14583' both implement 'lstm_bdfe034e-44bd-4a41-97be-a5da9c2196ef' but their signatures do not match.\r\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\r\n2500/2500 [==============================] - 112s 45ms/step - loss: 0.5513 - accuracy: 0.7254 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\r\nEpoch 2/10\r\n\r\n   1/2500 [..............................] - ETA: 8:49 - loss: 0.4387 - accuracy: 0.8000\r\n   \r\n   \r\n   2497/2500 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.8075\r\n2499/2500 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.80742020-01-07 16:00:50.625796: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[sequential/embedding/embedding_lookup/_20]]\r\n2020-01-07 16:00:50.626171: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\r\n2500/2500 [==============================] - 105s 42ms/step - loss: 0.4387 - accuracy: 0.8074 - val_loss: 0.4840 - val_accuracy: 0.7950\r\nEpoch 3/10\r\n\r\n   1/2500 [..............................] - ETA: 6:56 - loss: 0.3542 - accuracy: 0.8000\r\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\r\n    218/2500 [=>............................] - ETA: 1:32 - loss: 0.3990 - accuracy: 0.8243\r\n 219/2500 [=>............................] - ETA: 1:33 - loss: 0.3985 - accuracy: 0.82472020-01-07 16:01:00.255144: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1915): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2020-01-07 16:01:00.255214: F tensorflow/stream_executor/cuda/cuda_dnn.cc:189] Check failed: status == CUDNN_STATUS_SUCCESS (7 vs. 0)Failed to set cuDNN stream.\r\n2020-01-07 16:01:00.\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n```\r\ncode\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n(train_data, test_data), info = tfds.load(\r\n    'imdb_reviews/subwords8k',\r\n    split = (tfds.Split.TRAIN, tfds.Split.TEST),\r\n    with_info=True, as_supervised=True)\r\nencoder = info.features['text'].encoder\r\npadded_shapes = ([None],())\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\n\r\nembedding_dim=16\r\n\r\nmodel = keras.Sequential([\r\n    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=False),\r\n    # layers.Masking(mask_value=0),\r\n    layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit(\r\n    train_batches,\r\n    epochs=10,\r\n    validation_data=test_batches, validation_steps=20)\r\n```", "> Your stack trace didn't show much details about the error. The actual error log should appear above your log. I noticed that you are using masks in embedding layer. There is a similar issue reported for cudnn kernel that doesn't handle mask well. See #33148\r\n\r\nthis time i try to cancel `drop_remainder=True` , it still run error, and appear more error information:\r\n```python\r\n   2499/Unknown - 111s 45ms/step - loss: 0.6574 - accuracy: 0.6043\r\n   2500/Unknown - 111s 45ms/step - loss: 0.6575 - accuracy: 0.60432020-01-07 16:08:06.369217: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[Shape/_14]]\r\n2020-01-07 16:08:06.369274: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2020-01-07 16:08:07.091887: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_14453' and '__inference_cudnn_lstm_with_fallback_14453_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_14705' both implement 'lstm_1a3c7f9f-21bc-4c88-844f-f891fc2df9ba' but their signatures do not match.\r\n\r\n2500/2500 [==============================] - 113s 45ms/step - loss: 0.6575 - accuracy: 0.6043 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\r\nEpoch 2/10\r\n\r\n   1/2500 [..............................] - ETA: 6:56 - loss: 0.6824 - accuracy: 0.5000\r\n   \r\n   \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\r\n   \r\n   2494/2500 [============================>.] - ETA: 0s - loss: 0.4804 - accuracy: 0.7777\r\n   2496/2500 [============================>.] - ETA: 0s - loss: 0.4804 - accuracy: 0.7777\r\n   2498/2500 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.77772020-01-07 16:09:56.090566: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[Shape/_14]]\r\n2020-01-07 16:09:56.090613: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\r\n2500/2500 [==============================] - 109s 44ms/step - loss: 0.4804 - accuracy: 0.7777 - val_loss: 0.5941 - val_accuracy: 0.7550\r\nEpoch 3/10\r\n\r\n   1/2500 [..............................] - ETA: 8:02 - loss: 0.3951 - accuracy: 0.9000\r\n   3/2500 [..............................] - ETA: 4:03 - loss: 0.6093 - accuracy: 0.7333\r\n   5/2500 [..............................] - ETA: 3:03 - loss: 0.6081 - accuracy: 0.7200\r\n      \r\n   \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\r\n   2066/2500 [=======================>......] - ETA: 19s - loss: 0.3776 - accuracy: 0.8465\r\n   2068/2500 [=======================>......] - ETA: 19s - loss: 0.3782 - accuracy: 0.8463\r\n   2069/2500 [=======================>......] - ETA: 19s - loss: 0.3781 - accuracy: 0.84642020-01-07 16:11:28.037220: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1915): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n   2020-01-07 16:11:28.038283: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cudnn_rnn_ops.cc:1899 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1198, 10, 32] \r\n   2020-01-07 16:11:28.038742: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 16, 32, 1, 1198, 10, 32] \r\n   \t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\r\n   2020-01-07 16:11:28.039252: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n   \t [[{{node Reshape_11/_38}}]]\r\n   \t [[Adam/Adam/update/AssignSubVariableOp/_41]]\r\n   2020-01-07 16:11:28.040280: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Cancelled: [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]]\r\nTraceback (most recent call last):\r\n  File \"D:/Documents/Project/Python/2019/mission2/test2.py\", line 34, in <module>\r\n    validation_data=test_batches, validation_steps=20)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 487, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\sha\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n\r\n2071/2500 [=======================>......] - ETA: 18s - loss: 0.3781 - accuracy: 0.8463    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.\r\n\t [[{{node Reshape_11/_38}}]] [Op:__inference_distributed_function_6169]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nthis is code:\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n(train_data, test_data), info = tfds.load(\r\n    'imdb_reviews/subwords8k',\r\n    split = (tfds.Split.TRAIN, tfds.Split.TEST),\r\n    with_info=True, as_supervised=True)\r\nencoder = info.features['text'].encoder\r\npadded_shapes = ([None],())\r\n# train_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\n# # test_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes, drop_remainder=True)\r\ntrain_batches = train_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\r\ntest_batches = test_data.shuffle(1000).padded_batch(10, padded_shapes = padded_shapes)\r\nembedding_dim=16\r\n\r\nmodel = keras.Sequential([\r\n    layers.Embedding(encoder.vocab_size, embedding_dim,mask_zero=False),\r\n    # layers.Masking(mask_value=0),\r\n    layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit(\r\n    train_batches,\r\n    epochs=10,\r\n    validation_data=test_batches, validation_steps=20)\r\n```\r\n\r\nThank you!", "@shazhongcheng, your latest error log is quite weird. Seems that the issue happens in the middle of epoch 3, and also I wasn't able to reproduce the issue you have on a gpu colab. Probably related to some local hardware based on your local env.", "> @shazhongcheng, your latest error log is quite weird. Seems that the issue happens in the middle of epoch 3, and also I wasn't able to reproduce the issue you have on a gpu colab. Probably related to some local hardware based on your local env.\r\n\r\nOK, Thank you. But on GTX 1060, the `Bidirectional` have some problem. And the problem caused by hardware\u2026\u2026\u2026\u2026\r\nI can`t handle it\u2026\u2026\r\nMaybe replace another GPU is a good choice for me o(\u2565\ufe4f\u2565)o.\r\nThank you! Hope one day i can solve it!", "Same issue on GTX 1050, Cuda 10.2, Tensorflow 2.1", "I think this might be a very specific cudnn kernel issue. Currently I can't reproduce it with TF nightly on a GPU colab. For any of you still facing the issue, could you try the TF nightly version as well?  ", "Yes, based on all comments/forums I have read it can't be reproduced on linux machine. It should be Windows one. I had this issue with TF 2.0 CUDA 10, TF 2.1 CUDA 10.1\r\n\r\nToday I found TF 2.1 CUDA 10.2 Python wheel and I decided to try with it but no success. \r\nI'll try to find nightly build with CUDA 10.2 but highly doubt that it will work. \r\n\r\nAs you said it should be very specific cudnn kerner issue.\r\n\r\nAlso, if this could be helpful, this error occurs \"randomly\". It could happen at the beginning of a batch, or in middle. Sometimes at the end of a batch.", "I'm not sure if it's related, but I get a similar error, but only in `predict`. During training all goes well.", "Can you have a try of the newer cuDNN? It seems the cuDNN 7.6.5 fixed a related issue: \r\n```Fixed a lack-of-synchronization issue when cudnnRNNBackwardData() and cudnnRNNBackwardDataEx() calls a kernel that is not synchronized back to the application's stream. This issue only appears when users are using bidirectional RNN using algo of CUDNN_RNN_ALGO_STANDARD. This issue affects cuDNN versions 5 through 7.6.4.```\r\n\r\nhttps://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_765.html#rel_765", "I'm not sure how to check the cuDNN version, but my CUDA version is 10.1.\r\n\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n```\r\n\r\nBy checking the actual dll, I see Product version: 6.14.11.10010, which is the latest from https://developer.nvidia.com/rdp/cudnn-download.", "Can you find your `cudnn.h` file? The version should be found there.\r\n\r\n> I'm not sure how to check the cuDNN version, but my CUDA version is 10.1.\r\n> \r\n> ```\r\n> nvcc: NVIDIA (R) Cuda compiler driver\r\n> Copyright (c) 2005-2019 NVIDIA Corporation\r\n> Built on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\r\n> Cuda compilation tools, release 10.1, V10.1.243\r\n> ```\r\n> \r\n> By checking the actual dll, I see Product version: 6.14.11.10010, which is the latest from https://developer.nvidia.com/rdp/cudnn-download.\r\n", "Where in the file would the version be?\r\nI found this:\r\n```\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 6\r\n#define CUDNN_PATCHLEVEL 5\r\n```", "It looks you have the correct cudnn version. @rodrigoruiz  Can you send me a repro?", "Yeah, but now not even training is working... (I updated TensorFlow)", "@houtoms \r\nOk, so, I'm not sure what's going on, I did train a model with this exact same code (except for the fake data) and now it's not working anymore. The weird part is it does start the training and works for some batches, but after a random number of batches (sometimes 2, sometimes 25, all on the first epoch), it restarts my kernel (running on Jupyter Notebook).\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Bidirectional, concatenate, Dense, Embedding, Input, LSTM\r\nfrom tensorflow.keras.models import Model, Sequential\r\nfrom functools import reduce\r\nimport tensorflow as tf\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], enable = True)\r\nprecision = tf.keras.metrics.Precision()\r\nrecall = tf.keras.metrics.Recall()\r\n\r\nn = 3000\r\nmaximum_sequence_length = 500\r\n\r\nd = (\r\n    [\r\n        np.random.randint(10, size = (n, maximum_sequence_length)),\r\n        np.random.randint(10, size = (n, maximum_sequence_length))\r\n    ],\r\n    np.random.randint(2, size = (n, 1))\r\n)\r\n\r\nvocabulary_size = 10000\r\n\r\ninput_1 = Input(shape = (maximum_sequence_length,))\r\ninput_2 = Input(shape = (maximum_sequence_length,))\r\n\r\nfeature_model = Sequential([\r\n    Embedding(vocabulary_size, 128),\r\n    Bidirectional(LSTM(\r\n        units = 128,\r\n        return_sequences = True\r\n    )),\r\n    Bidirectional(LSTM(\r\n        units = 128,\r\n        return_sequences = True\r\n    )),\r\n    Bidirectional(LSTM(\r\n        units = 128\r\n    ))\r\n])\r\n\r\nfeatures_1 = feature_model(input_1)\r\nfeatures_2 = feature_model(input_2)\r\n\r\noutput = reduce(lambda output, layer: layer(output), [\r\n    concatenate([features_1, features_2]),\r\n    Dense(\r\n        units = 128,\r\n        activation = 'relu'\r\n    ),\r\n    Dense(\r\n        units = 128,\r\n        activation = 'relu'\r\n    ),\r\n    Dense(\r\n        units = 1,\r\n        activation = 'sigmoid'\r\n    )\r\n])\r\n\r\nmodel = Model(inputs = [input_1, input_2], outputs = [output])\r\n\r\nmodel.compile(\r\n    loss = 'binary_crossentropy',\r\n    optimizer = 'adam',\r\n    metrics = ['accuracy', precision, recall]\r\n)\r\n\r\nhistory = model.fit(\r\n    x = d[0],\r\n    y = d[1],\r\n    batch_size = 16,\r\n    epochs = 1,\r\n    verbose = 1,\r\n    validation_data = d\r\n)\r\n```", "@rodrigoruiz Thx for providing the repro script. I just ran your script, but I didn't encounter any errors in my local machine (TF1/TF2+GV100) and Colab with TF1/TF2+GPU. Btw, Colab with TF1+GPU was extremely slow and I think it didn't use cuDNN. \r\nLogs from Colab + TF2 + GPU\r\n```\r\nTrain on 3000 samples, validate on 3000 samples\r\n3000/3000 [==============================] - 101s 34ms/sample - loss: 0.6947 - accuracy: 0.5007 - precision_3: 0.4962 - recall_3: 0.4382 - val_loss: 0.6927 - val_accuracy: 0.5380 - val_precision_3: 0.5244 - val_recall_3: 0.7379\r\n``` \r\nLogs from Colab + TF1 + GPU\r\n```\r\nThe default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.\r\nWe recommend you upgrade now or ensure your notebook will continue to use TensorFlow 1.x via the %tensorflow_version 1.x magic: more info.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nTrain on 3000 samples, validate on 3000 samples\r\n3000/3000 [==============================] - 2289s 763ms/sample - loss: 0.6942 - acc: 0.5060 - precision: 0.5048 - recall: 0.6596 - val_loss: 0.6943 - val_acc: 0.4997 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\r\n```", "> @houtoms\r\n\r\nI try on pycharm with gtx1060, tensorflow2.1+cuda10.1.\r\nIt run fluently! So strange. I try run Bidirectional with another code, it run error.\r\nAnd i can`t handle it.\r\n[link](https://github.com/tensorflow/tensorflow/issues/34094)\r\n", "@shazhongcheng Could you provide your cudnn verison pls? I am running into the exact same problem><\r\n", "@Zhengnan97  cudnn-10.1-windows10-x64-v7.6.5.32.zip", "@shazhongcheng I tried with 940MX, tf2.0.0, cuda 10.0.130 and cudnn 7.6.5, it still cannot run. I'll try to change the versions and see whether it will help.", "@houtoms I'm using an RTX 2080 Ti. What should I do to fix it?\r\nI already tried uninstalling everything and reinstalling everything but Anaconda, including TensorFlow and Cuda.", "ubuntu 18.04\r\nRTX2048 Ti\r\nBidirectional GRU has the the same error\r\nAfter I used Masking layer instead of setting mask_zero=True in Embedding layer,  the training works.\r\nBut the predict failed with the same error.", "@xuxingya , let me find a ubuntu with RTX2080ti. Is the failed case using the same code in https://github.com/tensorflow/tensorflow/issues/33924#issuecomment-586770425? What changes should I make to repro the issue?", "@rodrigoruiz Did you by any chance try your code in ubuntu?", "@houtoms No, I haven't, only Windows.", "@rodrigoruiz Then, could you please try this \r\n```\r\nexport CUDNN_LOGINFO_DBG=1\r\nexport CUDNN_LOGDEST_DBG=\"/tmp/cudnn_api_log.%i\"\r\n``` \r\nsuggested here https://github.com/tensorflow/tensorflow/issues/34094#issuecomment-591088834", "@houtoms `export` is not a recognized command in Windows, but I tried adding this:\r\n\r\n> !set CUDNN_LOGINFO_DBG=1\r\n> !set CUDNN_LOGDEST_DBG=\"/tmp/cudnn_api_log.%i\"\r\n\r\nTo the beginning of my jupyter notebook cell, and I get the same error.", "@rodrigoruiz Was any log file generated in `/tmp`?", "@houtoms \r\nBtw, if you'd like, we can setup a call to try figuring this out.\r\n\r\nAnd excuse my ignorance (I'm terrible when it comes to that low level stuff and infrastructure), but where would that be?\r\nShould I just type `/tmp` in explorer? Or `cd /tmp` on a terminal window?\r\n\r\nIn any case, I tried searching for `cudnn_api_log` on explorer and nothing was found.", "Basically, the first env variable is to tell the cuDNN to generate the call logs and the second env variable specify where the logs should go.\r\n\r\nIn your case, maybe you don't have access to `/tmp`. So please try a local one that you do have access to.", "@houtoms \r\nI tried:\r\n```\r\n!set CUDNN_LOGINFO_DBG=1\r\n!set CUDNN_LOGDEST_DBG=\"C:/temp/cudnn_api_log.%i\"\r\n```\r\nAnd still no file.", "@rodrigoruiz , I am not familiar with colab, but I just played with it and I can get the log with, for example: https://colab.research.google.com/drive/1ERNMTEAboXG4EE2nx2L-8BTXgyOq_pHm", "@houtoms I don't use colab either, I'm using jupyter notebook.\r\nUsing those two lines I was able to generate the log file.\r\n\r\n[cudnn_api_log.txt](https://github.com/tensorflow/tensorflow/files/4259905/cudnn_api_log.txt)\r\n", "@rodrigoruiz Thanks. By the way, was this log for the failed training on your machine? ", "Yes, but I'm not sure it contains the error information.", "@houtoms Any updates on this?", "@rodrigoruiz Sorry for the late reply. I checked your log but I didn't see anything wrong.\r\n\r\nJust one more thing to confirm, you also got the `CUDNN_STATUS_INTERNAL_ERROR` error from cudnnRNNBackwardData() API?", "To be honest, I have no idea what that is.\r\nDo you mean in those logs? I don't really know how to interpret them.\r\nFor me, Jupyter notebook just crashes and restarts (no other error messages).\r\nSometimes I do get this log from Jupyter notebook before crashing:\r\n\r\n```\r\n...\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInternalError:  [_Derived_]  Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 512, 256, 1, 400, 14, 256] \r\n\t [[{{node CudnnRNN}}]]\r\n\t [[model/sequential_1/bidirectional_2/forward_lstm_2/StatefulPartitionedCall]] [Op:__inference_distributed_function_75608]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function\r\n```\r\n\r\nAnd that was when I was getting the error on `predict` method.\r\nNow I don't even get to the part, because it crashes in the middle of a training.", "I ran the colab on with latest nightly again, and didn't see any error. I suspect this is an issue only happens in certain env config. For any of you still facing the issue, please try with some clean env, and also include the version information when u report the issue.", "@qlzh727 I'm running TensorFlow 2.1.0.\r\nAlso, I did try to re-install everything again.\r\nI also tried with and without the nightly thing.\r\n\r\n@houtoms any news on this?", "This might provide a solution for some of you https://github.com/tensorflow/tensorflow/issues/37942", "@FunkyGibbon I tried the proposed solution with the `batch_input_shape` if that's what you meant.\r\nIt doesn't crash anymore, but doesn't even start training... it's just stuck before starting the first epoch. i.e., still running, but nothing is actually happening.", "Hi, I'm sorry to bother with this again, but is there an expected time frame for a fix?\r\nI've been stuck because of this for a while (my masters is depending on it).", "@rodrigoruiz sorry for a late response. One way I found that worked intermittently was to significantly increase the batch size. I used a batch size of 2800. But apart from that I couldn't find another way to fix it. I ended up changing my whole model in the end because this error happens with all types of recurrent networks, not just LSTMs. I'm sorry I don't have the link, but I found the suggestion to increase batch size in the Nvidia developer forums. You could try asking there", "@FunkyGibbon how do you not run out of memory with such a huge batch size?", "@houtoms do you have any update on this?", "@rodrigoruiz to be fair if I go any higher than that I run out of memory, my model had four layers. So it wasn't too deep", "@FunkyGibbon I found something really weird...\r\nIf I increase the batch size and train my model with 10 epochs, it works for the whole training.\r\nIf I set it to 100 epochs, it fails on epoch 7.\r\n\r\nHow is that possible?", "@rodrigoruiz I'm really not sure why it happens. All I know is that recurrent networks work best sequentially. Because if you run a standard LSTM it runs faster on a CPU than on GPU. Using a cudnn LSTM breaks down the sequential operations into many concurrent operations so that they learn faster. I think its some kind of synchronisation error caused by the concurrent operations getting out of sync. The fact you have it working for 10 epochs, perhaps you could end training after 10 epochs, then load the weights and train again in sets of 10. But its a bit messy", "@FunkyGibbon Yeah, I am doing that with another network (in image recognition), but for this project, it won't even run the first batch. The one I told you that is working for a few epochs is a simplified version of the one I need to run.\r\nAlso, do you know how it works for the TensorFlow team to fix those issues?\r\nI mean, it's been a while since this started and no one seems to be working on it.", "@rodrigoruiz, I don't know exactly how all of this works. I think the error may be in CUDA. In tensorflow the error is generated in tensorflow/stream_executor/stream.cc. This calls a function in tensorflow/stream_executor/dnn.h. If the problem is in Tensorflow I expect that is where it will be. Its essentially a wrapper which lets you target CUDA with parallel kernals", "Running into same issue. It really does seem that CUDA is the source. \r\n\r\n    [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, \r\n    rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, \r\n    batch_size, cell_num_units]: [1, 128, 64, 1, 1000, 100, 64] \r\n    \t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\r\n    \t [[StatefulPartitionedCall]] [Op:__inference_distributed_function_5734]\r\n\r\n    Function call stack:\r\n    distributed_function -> distributed_function -> distributed_function\r\n\r\n\r\n", "@GSonderlio and what would be the fix?\r\nI tried upgrading Cida, but TensorFlow doesn't accept version 10.2.", "@rodrigoruiz \r\nQuick hack that worked for me is tweaking the batch_size/steps combo. But that isn't workable for every situation. So I think it comes down to Tensorflow getting fixed. Since it seems to depend on batch size I think it might be something with memory allocation. But it's just a guess.", "@rodrigoruiz I did read that someone reverted back to tensorflow 1.14 and downloaded the relevant CUDA and it worked for them, you will then have to switch to using the cudnnLSTM, but that could work.", "I think there is some issue randomly happening the cudnn kernel, and yet I still don't have a stable way to reproduce the issue.\r\n\r\n@kaixih, could u check this more on Nvidia side? I don't have much action to take on my end.", "I got the same issue running on cuda 10.1 and CUdnn 7.6.5 on a RTX 2080ti, once i removed the LSTM layer from the model given on the TF website tutorial it trained perfectly. is there a fix incoming soon?", "@rodrigoruiz TF OSS has been building with cuDNN 8 for couple of months now. So can you please try with tf-nightly?", "> I got the same issue running on cuda 10.1 and CUdnn 7.6.5 on a RTX 2080ti, once i removed the LSTM layer from the model given on the TF website tutorial it trained perfectly. is there a fix incoming soon?\r\n\r\n\r\ni got RTX 2070, had same issue with BI-LSTM, i changed to  normal LSTM works fine for now.\r\n\r\n\r\nEDIT: BI-LSTM works fine with CuDNNLSTM", "same issue in 2080ti tf1.14 cuda 10.0 cudnn 7.6.5,and tf2.1, 2.2, 2.3 with cuda 10.1 cudnn 7.6.5. Still don't work fine.\r\n\r\nEdit: i have no issue after i found it's my problem. I use matplotlib to save figure, but i didn't close those figure after training, it seems cause memory occupied too much, so i fix them and this issue(crush training) didn't happen again. So, i think the primary problem is the memory usage. \r\n", "Was able to run successfully in colab without any error in Tensorflow GPU 2.5, is this still an issue in your system?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33924\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33924\">No</a>\n"]}, {"number": 33923, "title": "Insert Windows command line in the tutorials", "body": "## URL(s) with the issue:\r\n\r\nExample: https://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\n## Description of issue (what needs changing):\r\n \r\nThe tutorial uses POSIX commands like:\r\n\r\n`!ls {checkpoint_dir}`\r\n\r\nUnfortunately I am on Windows so those commands does not work. Is there no way to condition the command on the OS?\r\n\r\n`!dir {checkpoint_dir}`\r\n\r\nThe alternative way would be to use Python straightaway:\r\n\r\n```\r\nonlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\r\nprint(onlyfiles)\r\n```", "comments": ["The ! system commands are just used because they're convienient, and work in colab which we see as the primary execution platform for these. there's no good way to switch these based on the OS. \r\n\r\nAs you say probably the most platform independent way is to just do it in python. \r\n\r\nI'd probably go with:\r\n```\r\nmypath = pathlib.Path(...)\r\nlist(mypath.glob('*'))\r\n```\r\n\r\nI'm unable to prioritize this right now. \r\n\r\n@raffaem I would welcome any PR you can send to tensorflow/docs making this sort of change.", "Hi, this is my first time contributing to the TensorFlow community. Since no one is taking this task, can I volunteer to take this task? \r\n\r\nOne more question - since the doc you mentioned is in here: https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/keras/save_and_load.ipynb. To update this doc on the website, I just need to change the `ipynb` file, right?\r\n\r\nThank you! I am happy to contribute to this issue :)"]}, {"number": 33922, "title": "tf.compat purpose may be misstated", "body": "## URL(s) with the issue\r\nhttps://www.tensorflow.org/api_docs/python/tf/compat\r\n\r\n## Description of issue (what needs changing):\r\nDocs say\r\n\r\n> Functions for Python 2 vs. 3 compatibility.\r\n\r\nBut on [StackOverflow they told me that](https://stackoverflow.com/questions/58631390/what-is-the-purpose-of-tf-compat)\r\n\r\n> The documentation for the module about Python should actually be changed. Originally, tf.compat only held functions for that purpose (and it was like that until 1.13, see all module documentation). However, it was later repurposed for TensorFlow version compatibility.", "comments": ["Good catch, thanks.\r\nShould probably also point to the migration guide: https://www.tensorflow.org/guide/migrate\r\n"]}, {"number": 33921, "title": "Fix the progress bar of keras.Model.evaluate()", "body": "Fix #32320 and #32286\r\n\r\nI also wrote a simple test case to check the value of `params.['samples']` after `model.evaluate()`.\r\n```python\r\nimport numpy as np\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.keras import keras_parameterized\r\nfrom tensorflow.python.keras import testing_utils\r\nfrom tensorflow.python.keras.callbacks import Callback\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass TestCase(keras_parameterized.TestCase):\r\n  def test_callback_params_samples(self):\r\n    x, y = np.ones((64, 3)), np.ones((64, 2))\r\n    model = testing_utils.get_small_sequential_mlp(\r\n        num_hidden=10, num_classes=2, input_dim=3)\r\n    model.compile('sgd', 'mse')\r\n    callback = Callback()\r\n    model.evaluate(x, y, callbacks=[callback])\r\n    self.assertEqual(callback.params['samples'], 64)\r\n\r\n\r\nif __name__ == '__main__':\r\n  test.main()\r\n```\r\nWhere should I put this test case?\r\n\r\nThe test output before this PR:\r\n```\r\n64/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 845us/sample - loss: 0.3011\r\n[  FAILED  ] TestCase.test_callback_params_samples\r\n[ RUN      ] TestCase.test_session\r\n[  SKIPPED ] TestCase.test_session\r\n======================================================================\r\nFAIL: test_callback_params_samples (__main__.TestCase)\r\ntest_callback_params_samples (__main__.TestCase)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"d.py\", line 17, in test_callback_params_samples\r\n    self.assertEqual(callback.params['samples'], 64)\r\nAssertionError: True != 64\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.240s\r\n\r\nFAILED (failures=1, skipped=1)\r\n```\r\nThe test output after this PR:\r\n```\r\n64/64 [==============================] - 0s 1ms/sample - loss: 0.3011\r\n[       OK ] TestCase.test_callback_params_samples\r\n[ RUN      ] TestCase.test_session\r\n[  SKIPPED ] TestCase.test_session\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.261s\r\n\r\nOK (skipped=1)\r\n```", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33921) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33921) for more info**.\n\n<!-- ok -->", "@mihaimaruseac do you want to take this change ?"]}, {"number": 33920, "title": "Collective AllReduce ops cannot run with variables shared across tasks in between-graph replication", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): installed by `pip install tensorflow-gpu`\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0 and cudnn 7.6\r\n- GPU model and memory:   Tesla V100, ~16Gb\r\n\r\n**Describe the current behavior**\r\nThe collective ops executor will fail with the following program.\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is that the program should run correctly in a between-graph replication as if the graph does not contain collective ops everything will run correctly.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport threading\r\nfrom multiprocessing import Process\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.core.protobuf import config_pb2\r\nfrom tensorflow.python import ops\r\nfrom tensorflow.python.client.session import Session\r\nfrom tensorflow.python.ops import collective_ops\r\n\r\ncluster_spec = {\r\n    \"worker\": [\r\n        \"localhost:14286\",\r\n        \"localhost:14287\"\r\n    ]\r\n}\r\ninputs = [0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1]\r\ngroup_size = 4\r\ngroup_key = 1\r\ninstance_key = 1\r\nuse_nccl = False\r\nnum_gpus_per_node = 2\r\n\r\n\r\ndef _configure(group_size):\r\n    gpu_options = config_pb2.GPUOptions(\r\n        visible_device_list='0,1',\r\n        per_process_gpu_memory_fraction=0.7 / (group_size))\r\n    experimental = config_pb2.ConfigProto.Experimental(collective_nccl=use_nccl)\r\n    experimental.collective_group_leader = '/job:worker/replica:0/task:0'\r\n    return config_pb2.ConfigProto(gpu_options=gpu_options, experimental=experimental)\r\n\r\n\r\nclass TFCluster(object):\r\n    def __init__(self, cluster_spec):\r\n        self._cluster_spec = cluster_spec\r\n        self._num_worker = 0\r\n        self._tf_servers = []\r\n\r\n    def start(self):\r\n        def server(job_name: str, task_index: int):\r\n            server = tf.distribute.Server(self._cluster_spec,\r\n                                          job_name=job_name,\r\n                                          task_index=task_index,\r\n                                          config=_configure(group_size))\r\n            server.join()\r\n\r\n        self._num_worker = len(cluster_spec.get(\"worker\", []))\r\n        assert self._num_worker >= 1\r\n        for i in range(self._num_worker):\r\n            self._tf_servers.append(Process(target=server,\r\n                                            args=(\"worker\", i), daemon=True))\r\n        for proc in self._tf_servers:\r\n            proc.start()\r\n\r\n    def stop(self):\r\n        for proc in self._tf_servers:\r\n            proc.terminate()\r\n\r\n\r\ndef between_graph_test():\r\n    def run_between_graph_clients(client_fn, cluster_spec, num_gpus, *args,\r\n                                  **kwargs):\r\n        threads = []\r\n        for task_type in ['chief', 'worker']:\r\n            for task_id in range(len(cluster_spec.get(task_type, []))):\r\n                t = threading.Thread(\r\n                    target=test_reduction,\r\n                    args=(task_type, task_id, num_gpus) + args,\r\n                    kwargs=kwargs)\r\n                t.start()\r\n                threads.append(t)\r\n        for t in threads:\r\n            t.join()\r\n\r\n    def test_reduction(task_type,\r\n                       task_id,\r\n                       num_gpus):\r\n        worker_device = \"/job:%s/task:%d\" % (task_type, task_id)\r\n        master_target = \"grpc://\" + cluster_spec[task_type][0]\r\n        with ops.Graph().as_default(), Session(target=master_target) as sess:\r\n            collectives = []\r\n            for i in range(num_gpus):\r\n                with ops.device('/job:worker/task:0/device:CPU:0'):  # make sure all use the same variable\r\n                    t = tf.Variable(inputs)\r\n                with ops.device(worker_device + '/device:GPU:' + str(i)):\r\n                    collectives.append(collective_ops.all_reduce(\r\n                        t, group_size, group_key, instance_key, 'Add', 'Div'))\r\n            run_options = config_pb2.RunOptions()\r\n            run_options.experimental.collective_graph_key = 6\r\n            sess.run(tf.compat.v1.global_variables_initializer())\r\n            res_m = sess.run(collectives, options=run_options)\r\n            print(res_m)\r\n\r\n    run_between_graph_clients(\r\n        test_reduction,\r\n        cluster_spec,\r\n        num_gpus_per_node)\r\n\r\n# launch in-process clusters\r\ncluster = TFCluster(cluster_spec)\r\ncluster.start()\r\n\r\n# run between graph execution\r\nbetween_graph_test()\r\ncluster.stop()\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\n```\r\n2019-11-01 18:37:48.066477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14286\r\n2019-11-01 18:37:48.066556: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:14287\r\n2019-11-01 18:37:48.733123: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:161] Skipping rendezvous re-initialization.\r\n2019-11-01 18:37:50.385293: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Aborted: [_Derived_]Cleanup 95609632845199527\r\n\t [[{{node CollectiveReduce}}]]\r\n2019-11-01 18:37:50.385319: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 95609632845199527\r\n[array([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1], dtype=float32), array([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1], dtype=float32)]\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.AbortedError: From /job:worker/replica:0/task:0:\r\n[_Derived_]Cleanup 95609632845199527\r\n\t [[{{node CollectiveReduce}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/ubuntu/pycharm/examples/allreduce/test_collective.py\", line 91, in test_reduction\r\n    res_m = sess.run(collectives, options=run_options)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/home/ubuntu/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.AbortedError: From /job:worker/replica:0/task:0:\r\n[_Derived_]Cleanup 95609632845199527\r\n\t [[node CollectiveReduce (defined at /arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n\r\nOriginal stack trace for 'CollectiveReduce':\r\n  File \"/anaconda3/lib/python3.6/threading.py\", line 884, in _bootstrap\r\n    self._bootstrap_inner()\r\n  File \"/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/anaconda3/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/pycharm/examples/allreduce/test_collective.py\", line 87, in test_reduction\r\n    t, group_size, group_key, instance_key, 'Add', 'Div'))\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/ops/collective_ops.py\", line 58, in all_reduce\r\n    subdiv_offsets=subdiv_offsets)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_collective_ops.py\", line 349, in collective_reduce\r\n    name=name)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3360, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/arion/arion-env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n```\r\n", "comments": ["I believe this issue is related to https://github.com/tensorflow/tensorflow/issues/33469, where the fix there was to simply lower the log level to avoid repeatedly logging `Skipping rendezvous re-initialization`.\r\n\r\nIt seems that the collective executor cannot correctly interpret a shared variable (declared with the same name and device placement string) across two tasks in between-graph replication (as the example shown above).", "I hope @dubey can take a look at this issue, thanks!", "Is this still an issue with latest tf version 2.2? ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33920\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33920\">No</a>\n"]}, {"number": 33919, "title": "parallel_for: No converter defined for SpaceToBatchND", "body": "Computation of jacobian with ```pfor``` does not work for ``` tf.keras.layers.Convolution2D``` with ```dilation_rate>1``` because there is no converter implemented for ```SpaceToBatchND```\r\n\r\ntf-version: 2.1.0-dev20191030\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nNlat=10\r\nNlon=20\r\nn_channels_in = 1\r\nx = tf.ones((1,Nlat,Nlon,n_channels_in))\r\nlayer1 = tf.keras.layers.Convolution2D(32, kernel_size=3, dilation_rate=1)\r\nlayer2 = tf.keras.layers.Convolution2D(32, kernel_size=3, dilation_rate=2)\r\n\r\n\r\nwith tf.GradientTape(persistent=True) as gt:\r\n    gt.watch(x)\r\n    y1 = layer1(x)\r\n    y2 = layer2(x)\r\n\r\nJ = gt.jacobian(y1, x)  # works\r\nJ2 = gt.jacobian(y2, x) # fails with following error:\r\n```\r\n\r\n```python\r\nValueError                                Traceback (most recent call last)\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\r\n   1112         output = pfor_ops.pfor(loop_fn, target_size,\r\n-> 1113                                parallel_iterations=parallel_iterations)\r\n   1114       except ValueError as err:\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)\r\n    188     f = function.defun(f)\r\n--> 189   return f()\r\n    190 \r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2340     with self._lock:\r\n-> 2341       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2342     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2675       self._function_cache.missed.add(call_context_key)\r\n-> 2676       graph_function = self._create_graph_function(args, kwargs)\r\n   2677       self._function_cache.primary[cache_key] = graph_function\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2565             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2566             capture_by_value=self._capture_by_value),\r\n   2567         self._function_attributes,\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    957 \r\n--> 958       func_outputs = python_func(*func_args, **func_kwargs)\r\n    959 \r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    947             if hasattr(e, \"ag_error_metadata\"):\r\n--> 948               raise e.ag_error_metadata.to_exception(e)\r\n    949             else:\r\n\r\nValueError: in converted code:\r\n    relative to /pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for:\r\n\r\n    control_flow_ops.py:183 f  *\r\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\r\n    control_flow_ops.py:256 _pfor_impl\r\n        outputs.append(converter.convert(loop_fn_output))\r\n    pfor.py:1280 convert\r\n        output = self._convert_helper(y)\r\n    pfor.py:1460 _convert_helper\r\n        (y_op.type, y_op, converted_inputs))\r\n\r\n    ValueError: No converter defined for SpaceToBatchND\r\n    name: \"loop_body/SpaceToBatchND\"\r\n    op: \"SpaceToBatchND\"\r\n    input: \"loop_body/Reshape_2\"\r\n    input: \"loop_body/SpaceToBatchND/block_shape\"\r\n    input: \"loop_body/SpaceToBatchND/paddings\"\r\n    attr {\r\n      key: \"T\"\r\n      value {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n    attr {\r\n      key: \"Tblock_shape\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    }\r\n    attr {\r\n      key: \"Tpaddings\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    }\r\n    \r\n    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/Reshape_2/pfor/Reshape:0' shape=(3072, 1, 6, 16, 32) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/block_shape:0' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/paddings:0' shape=(2, 2) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]. \r\n    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-29-dd023aa8e2b5> in <module>\r\n----> 1 J2 = gt.jacobian(y2, x) # fails\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\r\n   1119                 \"jacobian computation. Vectorization can be disabled by setting\"\r\n   1120                 \" experimental_use_pfor to False.\"),\r\n-> 1121             sys.exc_info()[2])\r\n   1122     else:\r\n   1123       if context.executing_eagerly() and not self._persistent:\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)\r\n    690                 value = tp()\r\n    691             if value.__traceback__ is not tb:\r\n--> 692                 raise value.with_traceback(tb)\r\n    693             raise value\r\n    694         finally:\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\r\n   1111       try:\r\n   1112         output = pfor_ops.pfor(loop_fn, target_size,\r\n-> 1113                                parallel_iterations=parallel_iterations)\r\n   1114       except ValueError as err:\r\n   1115         six.reraise(\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, parallel_iterations)\r\n    187   if context.executing_eagerly() or _is_under_xla_context():\r\n    188     f = function.defun(f)\r\n--> 189   return f()\r\n    190 \r\n    191 \r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2339     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   2340     with self._lock:\r\n-> 2341       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2342     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2343 \r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2674 \r\n   2675       self._function_cache.missed.add(call_context_key)\r\n-> 2676       graph_function = self._create_graph_function(args, kwargs)\r\n   2677       self._function_cache.primary[cache_key] = graph_function\r\n   2678       return graph_function, args, kwargs\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2564             arg_names=arg_names,\r\n   2565             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2566             capture_by_value=self._capture_by_value),\r\n   2567         self._function_attributes,\r\n   2568         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    956                                           converted_func)\r\n    957 \r\n--> 958       func_outputs = python_func(*func_args, **func_kwargs)\r\n    959 \r\n    960       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    946           except Exception as e:  # pylint:disable=broad-except\r\n    947             if hasattr(e, \"ag_error_metadata\"):\r\n--> 948               raise e.ag_error_metadata.to_exception(e)\r\n    949             else:\r\n    950               raise\r\n\r\nValueError: in converted code:\r\n    relative to /pfs/nobackup/home/s/sebsc/miniconda3/envs/tf2-env/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for:\r\n\r\n    control_flow_ops.py:183 f  *\r\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\r\n    control_flow_ops.py:256 _pfor_impl\r\n        outputs.append(converter.convert(loop_fn_output))\r\n    pfor.py:1280 convert\r\n        output = self._convert_helper(y)\r\n    pfor.py:1460 _convert_helper\r\n        (y_op.type, y_op, converted_inputs))\r\n\r\n    ValueError: No converter defined for SpaceToBatchND\r\n    name: \"loop_body/SpaceToBatchND\"\r\n    op: \"SpaceToBatchND\"\r\n    input: \"loop_body/Reshape_2\"\r\n    input: \"loop_body/SpaceToBatchND/block_shape\"\r\n    input: \"loop_body/SpaceToBatchND/paddings\"\r\n    attr {\r\n      key: \"T\"\r\n      value {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n    attr {\r\n      key: \"Tblock_shape\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    }\r\n    attr {\r\n      key: \"Tpaddings\"\r\n      value {\r\n        type: DT_INT32\r\n      }\r\n    }\r\n    \r\n    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/Reshape_2/pfor/Reshape:0' shape=(3072, 1, 6, 16, 32) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/block_shape:0' shape=(2,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/SpaceToBatchND/paddings:0' shape=(2, 2) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]. \r\n    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n\r\nEncountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.\r\n```\r\n", "comments": ["@sipposip \r\nI tried reproducing the issue using colab, however i am seeing the below error.`UnrecognizedFlagError: Unknown command line flag 'f'`.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/66529b5afdb793dc273f35c1a47d4ae4/untitled325.ipynb). Is this the expected behavior?.Thanks!", "The expected behaviour is to get the same result as when not using pfor:\r\n```J2 = gt.jacobian(y2, x, experimental_use_pfor=False) # expected behaviour```\r\nwhich gives a tensor of shape ```[1, 6, 16, 32, 1, 10, 20, 1]``` (filled with random numbers since the network in this minimal example has random weights)", "I have tried on colab with TF version 2.1.0-dev20191103 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/1cf3040cd25084f0414ff1385820fe58/untitled325.ipynb). Thanks!", "There is now a converter for SpaceToBatchND.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33919\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33919\">No</a>\n"]}, {"number": 33918, "title": "Could not find any cupti.h in any subdirectory when running Configure in Tensorflow", "body": "I'm using Ubuntu and have CUDA 7.5 installed according to `nvcc --version`\r\n\r\nI git cloned Tensorflow and attempted `./configure` and got the below:\r\n\r\n    Please specify the location of python. [Default is /home/me/anaconda3/bin/python]: \r\n    \r\n    \r\n    Found possible Python library paths:\r\n      /home/me/anaconda3/lib/python3.6/site-packages\r\n    Please input the desired Python library path to use.  Default is [/home/me/anaconda3/lib/python3.6/site-packages]\r\n    \r\n    Do you wish to build TensorFlow with XLA JIT support? [Y/n]: \r\n    XLA JIT support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\n    No OpenCL SYCL support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with ROCm support? [y/N]: \r\n    No ROCm support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with CUDA support? [y/N]: y\r\n    CUDA support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with TensorRT support? [y/N]: \r\n    No TensorRT support will be enabled for TensorFlow.\r\n\r\nIt then shows the error:\r\n\r\n    Could not find any cupti.h in any subdirectory:\r\n\r\nIt then asks for the CUDA Version:\r\n\r\n    Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 7.5\r\n    \r\n    \r\n    Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: \r\n    \r\n    \r\n    Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: \r\n    \r\n    \r\n    Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]:\r\n\r\n \r\nBut it shows the same error: `Could not find any cupti.h in any subdirectory:`", "comments": ["@za13, Did you set the proper CUDA path in `./configure`. Thanks!", "how do I do that?", "@za13, While running `./configure`, specify the CUDA installed path. Thanks! ", "@za13, Please follow the instructions mentioned [here](https://www.tensorflow.org/install/source). Thanks!", "I don't see how I can specify the CUDA installed path when running `./configure`\r\n\r\nAs soon as I enter `./configure`, it shows\r\n\r\n```\r\nPlease specify the location of python. [Default is /home/me/anaconda3/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/me/anaconda3/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/me/anaconda3/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: \r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n```\r\n\r\nwhen it then gets to\r\n\r\n`Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: \r\n`\r\n\r\nand I enter `9.1` since `sudo find / -name nvcc` showed `/usr/local/cuda-9.1/bin/nvcc`\r\n\r\nIt shows `could not find any cuda.h matching version 9.1 in any subdirectory`", "@za13,\r\nUse CUDA 9.0 and cuDNN 7.\r\nPlease specify the path CUDA path in ./configure\r\n```\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: Y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.0\r\n\r\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7.0\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n```\r\nLet us know how it progresses. Thanks!\r\n", "when I tried CUDA 9.0 and cuDNN 7.0 as you suggested, it says `could not find any cuda.h matching version 9.0 in any subdirectory`", "can anyone help?", "Apologies for the delay in response. You need to add ```CUPTI``` to the ```$LD_LIBRARY_PATH```environment variable path.\r\nSee https://www.tensorflow.org/install/gpu#linux_setup", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33918\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33918\">No</a>\n", "adding `CUPTI` to the `$LD_LIBRARY_PATH` gave the same error of `could not find any cuda.h matching version 9.0 in any subdirectory`"]}, {"number": 33917, "title": "Math ops don't work on SparseTensors", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (Bionic Beaver)\r\n- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: Python 3.6.8\r\n\r\n**Describe the current behavior**\r\nSome basic math ops like `tf.math.exp` and `tf.math.pow` don't work on SparseTensors.\r\n\r\n**Describe the expected behavior**\r\nMath ops perform similarly to when they have dense Tensor inputs but returning a Sparse format, e.g. `tf.math.exp(tf.sparse.to_dense(d))`\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nd = tf.SparseTensor(\r\nindices=[(x,y) for x, y in zip(range(10), range(10))],\r\nvalues=tf.random.poisson((10,), lam=3),\r\ndense_shape=[10,10]\r\n)\r\n\r\ntf.math.exp(d)\r\n\r\n# Can also be reproduced like:\r\ntf.math.pow(2.71, d)\r\n```\r\n\r\n**Other info / logs**\r\n>>> tf.math.exp(d)\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 3951, in exp\r\n    name, _ctx._post_execution_callbacks, x)\r\ntensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 3956, in exp\r\n    x, name=name, ctx=_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 4001, in exp_eager_fallback\r\n    _attr_T, (x,) = _execute.args_to_matching_eager([x], _ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 257, in args_to_matching_eager\r\n    t, dtype, preferred_dtype=default_dtype, ctx=ctx))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1296, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 286, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 235, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: Attempt to convert a value (<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fd24746d5c0>) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.\r\n", "comments": ["I have tried on colab with TF version 2.0 ,2.1.0-dev20191103 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/2b980fdac2192b702fbbc44d4d0e5a99/untitled326.ipynb). Thanks!", "This is working as intended.\r\n\r\ntf.math.exp is a great example, where it's not at all obvious that you'd want it to apply to just the nonzero elements of the sparse tensor, as exp(0) = 1.\r\n\r\nInstead if you want to apply an elementwise operation just to the nonzeros you can apply it to sp.values and then build another sparse tensor out of it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33917\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33917\">No</a>\n", "@alextp I'm not sure the default behavior should be to raise an Exception, do you think that is better than returning either 1. the exponentiated dense Tensor or 2. the exponentiated Sparse Tensor (even though it is dense) to preserve the type of Tensor?", "I don't think either of these two options is obviously correct (making a\nvery sparse tensor silently dense will wreak havoc on someone's performance\nand memory usage, and preserving sparsity will wreak havoc on someone\nelse's math) so we need to leave the decision up to the call site.\n\nOn Wed, Nov 6, 2019 at 6:21 AM TimPepsiCo <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> I'm not sure the default behavior\n> should be to raise an Exception, do you think that is better than returning\n> either 1. the exponentiated dense Tensor or 2. the exponentiated Sparse\n> Tensor (even though it is dense) to preserve the type of Tensor?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33917?email_source=notifications&email_token=AAABHRPDQSUKYWCDKLSGE4LQSLHFVA5CNFSM4JH4LFQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDGVJYI#issuecomment-550327521>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMCWHU4AMQ3CG2CCQLQSLHFVANCNFSM4JH4LFQQ>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 33916, "title": "InternalError: Blas SGEMM launch failed : m=10, n=1, k=4 [Op:Conv2D] thrown when training Keras model with train_on_batch()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n\r\n    - `Yes`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n    - `Linux Ubuntu 18.04`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n\r\n    - Docker image, `tensorflow/tensorflow:2.0.0-gpu-py3`\r\n- TensorFlow version (use command below):\r\n\r\n     - `v2.0.0-rc2-26-g64c3d38 2.0.0`\r\n\r\n- Python version:\r\n\r\n    - `3.6.8`\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n```\r\n\r\n- GPU model and memory:\r\n\r\n    - `GeForce GTX 960M, 2004MiB`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen training a keras model with `train_on_batch()`, an InternalError is thrown (see stacktrace). Training the same model with `fit()` works.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo InternalError thrown and the attached code successfully executing.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nmkdir tf_issue\r\ncp run.py tf_issue\r\ndocker run --gpus all -it  -v $(pwd)/tf_issue:/tf_issue tensorflow/tensorflow:2.0.0-gpu-py\r\npython3 /tf_issue/run.py\r\n```\r\n\r\n(On my machine the above takes a few minutes when \"setting up\" Tensorflow, which is a bit ridiculous. But that's another issue)\r\n\r\n```\r\n## run.py ##\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Input, Conv2D\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\n#tf.keras.backend.set_image_data_format(\"channels_first\")\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2, input_shape=(224, 224, 3)))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=3, strides=2))\r\nmodel.add(tf.keras.layers.Conv2D(filters=1, kernel_size=2, strides=1, activation='sigmoid'))\r\n\r\nmodel.compile( optimizer=Adam(), loss='binary_crossentropy')\r\n\r\nmodel.summary()\r\n\r\ngpu = tf.test.is_gpu_available()\r\nprint(\"GPU is available:\", gpu)\r\nassert(gpu)\r\n\r\nbatch_size = 10\r\nx = np.random.random((batch_size, 224, 224, 3))\r\ny = np.random.random((batch_size, 1, 1, 1))\r\n\r\nprint(\"x\", x.shape)\r\nprint(\"y\", y.shape)\r\n\r\ny_pred = model.predict(x)\r\nprint(\"Predict successful: \", y_pred.shape)\r\n\r\nprint(\"Begin training with fit\")\r\nmodel.fit(x, y, epochs=10)\r\nprint(\"Fit successful\")\r\n\r\nprint(\"Begin training with train_on_batch\")\r\nfor i in range(10):\r\n    model.train_on_batch(x, y)\r\nprint(\"On batch successful\")\r\n```\r\n\r\n**Other info / logs**\r\n\r\nOutput and stack trace:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d (Conv2D)              (None, 111, 111, 1)       28        \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 55, 55, 1)         10        \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 27, 27, 1)         10        \r\n_________________________________________________________________\r\nconv2d_3 (Conv2D)            (None, 13, 13, 1)         10        \r\n_________________________________________________________________\r\nconv2d_4 (Conv2D)            (None, 6, 6, 1)           10        \r\n_________________________________________________________________\r\nconv2d_5 (Conv2D)            (None, 2, 2, 1)           10        \r\n_________________________________________________________________\r\nconv2d_6 (Conv2D)            (None, 1, 1, 1)           5         \r\n=================================================================\r\nTotal params: 83\r\nTrainable params: 83\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nGPU is available: True\r\nx (10, 224, 224, 3)\r\ny (10, 1, 1, 1)\r\nPredict successful:  (10, 1, 1, 1)\r\nBegin training with fit\r\nTrain on 10 samples\r\nEpoch 1/10\r\n\r\n10/10 [==============================] - 1s 82ms/sample - loss: 0.6654\r\nEpoch 2/10\r\n\r\n10/10 [==============================] - 0s 870us/sample - loss: 0.6633\r\nEpoch 3/10\r\n\r\n10/10 [==============================] - 0s 882us/sample - loss: 0.6613\r\nEpoch 4/10\r\n\r\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6594\r\nEpoch 5/10\r\n\r\n10/10 [==============================] - 0s 979us/sample - loss: 0.6574\r\nEpoch 6/10\r\n\r\n10/10 [==============================] - 0s 902us/sample - loss: 0.6555\r\nEpoch 7/10\r\n\r\n10/10 [==============================] - 0s 872us/sample - loss: 0.6536\r\nEpoch 8/10\r\n\r\n10/10 [==============================] - 0s 960us/sample - loss: 0.6517\r\nEpoch 9/10\r\n\r\n10/10 [==============================] - 0s 905us/sample - loss: 0.6498\r\nEpoch 10/10\r\n\r\n10/10 [==============================] - 0s 1ms/sample - loss: 0.6479\r\nFit successful\r\nBegin training with train_on_batch\r\n not compiled to use: AVX2 FMA\r\n2019-11-01 13:45:13.958471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2592000000 Hz\r\n2019-11-01 13:45:13.959294: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4595560 executing computations on platform Host. Devices:\r\n2019-11-01 13:45:13.959336: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-11-01 13:45:14.000846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.001574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45973c0 executing computations on platform CUDA. Devices:\r\n2019-11-01 13:45:14.001596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0\r\n2019-11-01 13:45:14.001719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.002377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975\r\npciBusID: 0000:01:00.0\r\n2019-11-01 13:45:14.002406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-01 13:45:14.002417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-01 13:45:14.002427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-01 13:45:14.002444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-01 13:45:14.002454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-01 13:45:14.002463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-01 13:45:14.002473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-01 13:45:14.002522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.003154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.003750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-01 13:45:14.003777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-01 13:45:14.004647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-01 13:45:14.004660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-11-01 13:45:14.004667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-11-01 13:45:14.004779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.005421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:14.006043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1742 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2019-11-01 13:45:15.207106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:15.207755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975\r\npciBusID: 0000:01:00.0\r\n2019-11-01 13:45:15.207787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-01 13:45:15.207801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-01 13:45:15.207813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-01 13:45:15.207824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-01 13:45:15.207836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-01 13:45:15.207847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-01 13:45:15.207859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-01 13:45:15.207910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:15.208535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:15.209130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2019-11-01 13:45:15.209154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-01 13:45:15.209161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2019-11-01 13:45:15.209168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2019-11-01 13:45:15.209276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:15.209931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-01 13:45:15.210556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 1742 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2019-11-01 13:45:15.339203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-01 13:45:17.264840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-01 13:45:17.421437: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2019-11-01 13:45:17.421474: W tensorflow/stream_executor/stream.cc:1919] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"test_sample_weights.py\", line 41, in <module>\r\n    model.train_on_batch(x, y)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 973, in train_on_batch\r\n    class_weight=class_weight, reset_metrics=reset_metrics)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 264, in train_on_batch\r\n    output_loss_metrics=model._output_loss_metrics)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 311, in train_on_batch\r\n    output_loss_metrics=output_loss_metrics))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 252, in _process_single_batch\r\n    training=training))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 127, in _model_loss\r\n    outs = model(inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 891, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\", line 256, in call\r\n    return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 708, in call\r\n    convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 860, in _run_internal_graph\r\n    output_tensors = layer(computed_tensors, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 891, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 197, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 1134, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 639, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 238, in __call__\r\n    name=self.name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1031, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1130, in conv2d_eager_fallback\r\n    ctx=_ctx, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=10, n=1, k=4 [Op:Conv2D]\r\n```\r\n\r\nDocker version:\r\n\r\n```\r\nClient: Docker Engine - Community\r\n Version:           19.03.4\r\n API version:       1.40\r\n Go version:        go1.12.10\r\n Git commit:        9013bf583a\r\n Built:             Fri Oct 18 15:54:09 2019\r\n OS/Arch:           linux/amd64\r\n Experimental:      false\r\n\r\nServer: Docker Engine - Community\r\n Engine:\r\n  Version:          19.03.4\r\n  API version:      1.40 (minimum version 1.12)\r\n  Go version:       go1.12.10\r\n  Git commit:       9013bf583a\r\n  Built:            Fri Oct 18 15:52:40 2019\r\n  OS/Arch:          linux/amd64\r\n  Experimental:     false\r\n containerd:\r\n  Version:          1.2.10\r\n  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339\r\n runc:\r\n  Version:          1.0.0-rc8+dev\r\n  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657\r\n docker-init:\r\n  Version:          0.18.0\r\n  GitCommit:        fec3683\r\n```\r\n", "comments": ["After some research into the error message `2019-11-01 13:45:17.421437: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED`, I tried adding the following to the start of `run.py` as specified in the [docs](https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth):\r\n\r\n```\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\nassert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n```\r\n\r\nThe script then behaves as expected. But I suppose this still is an issue due to the different behaviours of `fit` and `train_on_batch`?", "@johan-andersson01 ,\r\nCan you please check this [comment](https://github.com/tensorflow/tensorflow/issues/27820#issuecomment-491014072) and let me know if it helps ?Thanks!", "@oanush My laptop only has one GPU, so does that apply?", "[Limiting gpu memory growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth), switching to single tensorflow process (avoid multiple tf process that consume gpu memory) is a good practice in situations like these. I will close this issue since this resolves your issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33916\">No</a>\n", "Blas SGEMM launch failed : m=25600, n=16, k=32 [Op:Conv2D]\r\n\r\nDid anyone solve the problem? \r\n\r\n_win10-gtx1660ti-python3.8-tf2.4-cuda11.0-cudnn8.1_\r\n\r\nThe all shell promt is:\r\n\r\nC:\\Users\\KAYA\\Desktop\\Traffic Signs\\RealTimeObjectDetection-main>python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000\r\n2021-02-25 19:49:24.499158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-25 19:49:28.301297: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-25 19:49:28.302373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-02-25 19:49:28.334219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n2021-02-25 19:49:28.334365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-25 19:49:28.345828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-25 19:49:28.345948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-02-25 19:49:28.350673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-02-25 19:49:28.352197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-02-25 19:49:28.362088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-02-25 19:49:28.365249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-02-25 19:49:28.366105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-25 19:49:28.366283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-25 19:49:28.367151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-02-25 19:49:28.369254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n2021-02-25 19:49:28.369432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-02-25 19:49:28.369884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-25 19:49:28.370665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-02-25 19:49:28.371257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-02-25 19:49:28.371741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-02-25 19:49:28.372278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-02-25 19:49:28.372908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-02-25 19:49:28.373341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-25 19:49:28.374574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-02-25 19:49:28.871044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-02-25 19:49:28.871193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-02-25 19:49:28.872214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-02-25 19:49:28.875582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4741 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2021-02-25 19:49:28.876902: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI0225 19:49:28.875259  1588 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nINFO:tensorflow:Maybe overwriting train_steps: 10000\r\nI0225 19:49:28.875259  1588 config_util.py:552] Maybe overwriting train_steps: 10000\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI0225 19:49:28.875259  1588 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.078698  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.080653  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.084666  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.085664  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.125950  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.129824  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.145821  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.146779  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.148811  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0225 19:49:29.149771  1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n2021-02-25 19:49:30.502358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-02-25 19:49:31.485765: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n\r\n2021-02-25 19:49:31.550024: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n\r\n2021-02-25 19:49:31.566173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-02-25 19:49:31.985767: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2021-02-25 19:49:31.996015: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n2021-02-25 19:49:31.996148: W tensorflow/stream_executor/stream.cc:1455] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 113, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 104, in main\r\n    model_lib_v2.train_loop(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 523, in train_loop\r\n    dummy_prediction_dict = detection_model.predict(dummy_image, dummy_shapes)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 570, in predict\r\n    feature_maps = self._feature_extractor(preprocessed_inputs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 251, in call\r\n    return self._extract_features(inputs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 219, in _extract_features\r\n    image_features = self.classification_backbone(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 424, in call\r\n    return self._run_internal_graph(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 560, in _run_internal_graph\r\n    outputs = node.layer(*args, **kwargs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\r\n    return convolution_internal(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\r\n    return op(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\r\n    return gen_nn_ops.conv2d(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 935, in conv2d\r\n    return conv2d_eager_fallback(\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1024, in conv2d_eager_fallback\r\n    _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n  File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=25600, n=16, k=32 [Op:Conv2D]\r\n", "I had a similar issue.\r\n\r\n> Blas SGEMM launch failed : m=25600, n=16, k=32 [Op:Conv2D]\r\n> \r\n> Did anyone solve the problem?\r\n> \r\n> _win10-gtx1660ti-python3.8-tf2.4-cuda11.0-cudnn8.1_\r\n> \r\n> The all shell promt is:\r\n> \r\n> C:\\Users\\KAYA\\Desktop\\Traffic Signs\\RealTimeObjectDetection-main>python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000\r\n> 2021-02-25 19:49:24.499158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n> 2021-02-25 19:49:28.301297: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n> 2021-02-25 19:49:28.302373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n> 2021-02-25 19:49:28.334219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\n> pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\n> coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n> 2021-02-25 19:49:28.334365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n> 2021-02-25 19:49:28.345828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n> 2021-02-25 19:49:28.345948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n> 2021-02-25 19:49:28.350673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n> 2021-02-25 19:49:28.352197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n> 2021-02-25 19:49:28.362088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n> 2021-02-25 19:49:28.365249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n> 2021-02-25 19:49:28.366105: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n> 2021-02-25 19:49:28.366283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n> 2021-02-25 19:49:28.367151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2\r\n> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n> 2021-02-25 19:49:28.369254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\n> pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5\r\n> coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s\r\n> 2021-02-25 19:49:28.369432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n> 2021-02-25 19:49:28.369884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n> 2021-02-25 19:49:28.370665: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n> 2021-02-25 19:49:28.371257: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n> 2021-02-25 19:49:28.371741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n> 2021-02-25 19:49:28.372278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n> 2021-02-25 19:49:28.372908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n> 2021-02-25 19:49:28.373341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n> 2021-02-25 19:49:28.374574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n> 2021-02-25 19:49:28.871044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2021-02-25 19:49:28.871193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n> 2021-02-25 19:49:28.872214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n> 2021-02-25 19:49:28.875582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4741 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n> 2021-02-25 19:49:28.876902: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n> INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\n> I0225 19:49:28.875259 1588 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\n> INFO:tensorflow:Maybe overwriting train_steps: 10000\r\n> I0225 19:49:28.875259 1588 config_util.py:552] Maybe overwriting train_steps: 10000\r\n> INFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n> I0225 19:49:28.875259 1588 config_util.py:552] Maybe overwriting use_bfloat16: False\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.078698 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.080653 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.084666 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.085664 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.125950 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.129824 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.145821 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.146779 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.148811 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> I0225 19:49:29.149771 1588 cross_device_ops.py:563] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n> 2021-02-25 19:49:30.502358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n> 2021-02-25 19:49:31.485765: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n> \r\n> 2021-02-25 19:49:31.550024: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n> \r\n> 2021-02-25 19:49:31.566173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n> 2021-02-25 19:49:31.985767: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n> 2021-02-25 19:49:31.996015: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\r\n> 2021-02-25 19:49:31.996148: W tensorflow/stream_executor/stream.cc:1455] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\n> Traceback (most recent call last):\r\n> File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 113, in\r\n> tf.compat.v1.app.run()\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n> _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n> _run_main(main, args)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n> sys.exit(main(argv))\r\n> File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 104, in main\r\n> model_lib_v2.train_loop(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 523, in train_loop\r\n> dummy_prediction_dict = detection_model.predict(dummy_image, dummy_shapes)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 570, in predict\r\n> feature_maps = self._feature_extractor(preprocessed_inputs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in **call**\r\n> outputs = call_fn(inputs, *args, **kwargs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 251, in call\r\n> return self._extract_features(inputs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 219, in _extract_features\r\n> image_features = self.classification_backbone(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in **call**\r\n> outputs = call_fn(inputs, *args, **kwargs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 424, in call\r\n> return self._run_internal_graph(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 560, in _run_internal_graph\r\n> outputs = node.layer(*args, **kwargs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1012, in **call**\r\n> outputs = call_fn(inputs, *args, **kwargs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\r\n> outputs = self._convolution_op(inputs, self.kernel)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\r\n> return target(*args, **kwargs)\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\r\n> return convolution_internal(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\r\n> return op(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\r\n> return gen_nn_ops.conv2d(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 935, in conv2d\r\n> return conv2d_eager_fallback(\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1024, in conv2d_eager_fallback\r\n> _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n> File \"C:\\Users\\KAYA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n> tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n> tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=25600, n=16, k=32 [Op:Conv2D]\r\n\r\nHey @Alperen-KY , I had a similar issue and using this comment mentioned above helped me:\r\n`physical_devices = tf.config.experimental.list_physical_devices('GPU')`\r\n`assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"`\r\n`tf.config.experimental.set_memory_growth(physical_devices[0], True)`", "> After some research into the error message `2019-11-01 13:45:17.421437: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED`, I tried adding the following to the start of `run.py` as specified in the [docs](https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth):\r\n> \r\n> ```\r\n> physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n> assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n> ```\r\n> \r\n> The script then behaves as expected. But I suppose this still is an issue due to the different behaviours of `fit` and `train_on_batch`?\r\n\r\nThank you very much, this solved the problem for me", "\r\n\r\nThank you very much. I haven't been able to try again but I will. ", "Yes, that sorted it for me as well. Thanks, @skogsbrus for the original code snippet."]}, {"number": 33915, "title": "Have a default value for monitor on Early Stopping callback?", "body": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping", "comments": ["```val_loss``` is the default value for monitor.\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping#__init__"]}, {"number": 33914, "title": "Writing tflite file from Keras model throws \"Cycle found! We already encountered that input array\"", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): v1.12.1-7396-g12481e7e74 1.15.0-dev20190730\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.1, 10.0, 10.1\r\n- GPU model and memory: GTX 1050ti 4GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to write convert a (pure) Keras model to .pb file in order to write it to tflite. It's a few conv layers and some end logic. In order to do so, I freeze it with `convert_variables_to_constants` and reload it using the `TFLiteConverter.from_frozen_graph()`. However, I get the following error: \r\n```\r\nF tensorflow/lite/toco/tooling_util.cc:1182] Cycle found! We already encountered that input array, decoded_predictions/loop_over_batch/while/NextIteration, earlier in the above trace! We expect graphs to be acyclic, even RNNs. Let us know if some graph actually needs to have cycles, but first, please check if it really is an *inference* graph. *Training* graphs are out-of-scope for toco.\r\nFatal Python error: Aborted\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect `convert_variables_to_constants` to write a frozen graph readable by the `from_frozen_graph` method and simply convert my model. I've tried many things, like writing it with different methods, setting learning phase, changing the final layer (which is causing the problem), etc.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\ndef freeze_session(session, model, keep_var_names=None, clear_devices=None):\r\n    graph = session.graph\r\n    with graph.as_default():\r\n        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\r\n        output_names = [out.op.name for out in model.outputs]\r\n        output_names += [v.op.name for v in tf.global_variables()]\r\n        input_graph_def = graph.as_graph_def()\r\n        if clear_devices:\r\n            for node in input_graph_def.node:\r\n                node.device = \"\"\r\n        frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names)#, freeze_var_names)\r\n        return frozen_graph\r\n\r\ndef save_model(model, iteration):\r\n    # K.clear_session()\r\n    K.set_learning_phase(0)\r\n    new_model = get_out_model(model)\r\n    \r\n    frozen_graph = freeze_session(K.get_session(), new_model)\r\n    with tf.gfile.GFile('./model/model.pb', \"wb\") as f:\r\n        f.write(frozen_graph.SerializeToString())\r\n    # path = tf.train.write_graph(frozen_graph, './model', 'model' + str(iteration) + '.pb')\r\n\r\n    \r\n    converter = tf.lite.TFLiteConverter.from_frozen_graph('./model/model.pb',\r\n                                                          input_arrays=new_model.input_names,\r\n                                                          # output_arrays=['predictions/concat'])\r\n                                                          output_arrays=['decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3'])\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_spec.supported_ops = set([tf.lite.OpsSet.SELECT_TF_OPS])\r\n    converter.allow_custom_ops = True\r\n    converter.drop_control_dependency = False\r\n    tflite_model = converter.convert()\r\n    with open(\"./model.tflite\", 'wb') as tfile:\r\n        tfile.write(tflite_model)\r\n        \r\n    K.set_learning_phase(1)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nCurrent thread 0x00007f8956f0f740 (most recent call first):\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/home/oliver/.local/bin/toco_from_protos\", line 11 in <module>\r\nAborted (core dumped)\r\n\r\n\r\n\r\nNone\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 189, in <module>\r\n    loss = train_saved_model(model, socket)\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 168, in train_saved_model\r\n    save_model(model, i)\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 121, in save_model\r\n    tflite_model = converter.convert()\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n```", "comments": ["I should probably mention I've also tested `optimize_for_inference` to make sure there are no training ops in my frozen graph:\r\n```\r\nfrozen_graph = optimize_for_inference_lib.optimize_for_inference(frozen_graph,\r\n                                                                         [input],\r\n                                                                         [output],\r\n                                                                         tf.float32.as_datatype_enum)\r\n```", "I've now tried updating to tf 2.0, updating the keras code in the process (new version output: v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1) and saving/loading a saved_model instead, and the same issue persists:\r\n```\r\nCycle found! We already encountered that input array, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_126, earlier in the above trace! We expect graphs to be acyclic, even RNNs. Let us know if some graph actually needs to have cycles, but first, please check if it really is an *inference* graph. *Training* graphs are out-of-scope for toco.\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f2196587740 (most recent call first):\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/oliver/.local/bin/toco_from_protos\", line 11 in <module>\r\nAborted (core dumped)\r\n\r\n\r\n\r\nNone\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 202, in <module>\r\n    loss = train_saved_model(model, socket)\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 181, in train_saved_model\r\n    save_model(model, i)\r\n  File \"/home/oliver/Projects/DataGen/Retrainer/Retrainer.py\", line 134, in save_model\r\n    tflite_model = converter.convert()\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 392, in convert\r\n    **converter_kwargs)\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/oliver/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n```\r\n\r\nAdditionally, I'm having some issues with dimensions in the model summary (some dimensions are None instead of defined now), and when inspecting the model with e.g. Netron it looks very weird. Not sure if that's just a tf2.0 thing? As far as I can tell it works the same as before, so it's not an urgent issue, but I will keep looking into it. [Here](https://imgur.com/44GmEX3) is a screenshot of the model.", "I managed to get a much longer trace for some reason. I've noticed that the input to a specific layer, the output of a conv2d layer, would arrive as a list of 4 tensors instead of a 4D tensor, so I added a tf.to_tensor and printed the output. Following that, I got this long error message:\r\n```\r\n2019-11-04 13:09:22.642720: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.642729: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.642737: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.642746: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.642756: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.642764: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.642773: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.642783: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.642791: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.642799: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.642808: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MaxPool\r\n2019-11-04 13:09:22.642819: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.642831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.642841: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.642852: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.642861: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MaxPool\r\n2019-11-04 13:09:22.642874: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.642885: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.642894: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.642905: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.642915: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.642927: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MaxPool\r\n2019-11-04 13:09:22.642939: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.642949: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.642960: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.642971: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.642986: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.642996: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643030: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643039: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643048: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643072: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643081: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643091: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.643102: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643112: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643123: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643133: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.643143: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643154: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643164: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643174: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643186: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MaxPool\r\n2019-11-04 13:09:22.643198: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643209: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643219: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643228: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643236: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643247: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643257: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643266: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643274: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Tile\r\n2019-11-04 13:09:22.643283: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643291: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643300: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643308: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643316: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643324: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643333: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643342: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643351: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.643362: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643372: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643382: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643395: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643406: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.643416: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643427: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643438: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643447: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643458: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643469: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: MaxPool\r\n2019-11-04 13:09:22.643480: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643491: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643500: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643509: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643526: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643537: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643547: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643556: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643564: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Tile\r\n2019-11-04 13:09:22.643573: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643582: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643592: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643600: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643609: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643617: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643626: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643644: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNorm\r\n2019-11-04 13:09:22.643655: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643664: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643675: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643687: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643696: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Elu\r\n2019-11-04 13:09:22.643706: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643717: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643727: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643736: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643746: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643758: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Conv2D\r\n2019-11-04 13:09:22.643769: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643779: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643787: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643805: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643814: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: BiasAdd\r\n2019-11-04 13:09:22.643822: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.643831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Tile\r\n2019-11-04 13:09:22.643839: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643847: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643864: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643872: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Transpose\r\n2019-11-04 13:09:22.643881: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.643889: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643899: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643907: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: DataFormatVecPermute\r\n2019-11-04 13:09:22.643917: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643929: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643939: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643951: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.643961: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643969: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643978: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643988: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.643997: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.644006: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.644014: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.644022: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Tile\r\n2019-11-04 13:09:22.644031: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.644040: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.644049: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.644058: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Max\r\n2019-11-04 13:09:22.644068: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644078: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Sub\r\n2019-11-04 13:09:22.644086: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.644094: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exp\r\n2019-11-04 13:09:22.644103: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.644111: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Sum\r\n2019-11-04 13:09:22.644121: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.644130: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: RealDiv\r\n2019-11-04 13:09:22.644139: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.644149: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644159: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644170: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644180: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644191: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644202: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644212: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644223: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644233: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644244: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644254: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644265: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644275: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644285: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644296: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644306: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644316: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ArgMax\r\n2019-11-04 13:09:22.644325: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Max\r\n2019-11-04 13:09:22.644334: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644342: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644350: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644358: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644366: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Cast\r\n2019-11-04 13:09:22.644375: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644383: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exp\r\n2019-11-04 13:09:22.644391: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644399: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exp\r\n2019-11-04 13:09:22.644407: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644415: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.644423: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644431: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.644439: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644447: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644455: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644462: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644470: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644478: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Sub\r\n2019-11-04 13:09:22.644486: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.644494: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Sub\r\n2019-11-04 13:09:22.644502: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.644509: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.644518: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.644526: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.644534: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.644542: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644550: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644558: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644566: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644574: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644582: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644590: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644598: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644606: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644614: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644623: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644631: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644639: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644647: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644656: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Mul\r\n2019-11-04 13:09:22.644664: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644672: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644681: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644689: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644697: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644705: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644713: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644721: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.644729: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644737: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644744: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644752: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644760: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644767: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644775: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644783: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644790: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644798: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644806: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644814: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644821: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644831: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.644840: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.644850: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.644858: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.644866: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644874: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644881: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644889: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.644898: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.644907: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorListFromTensor\r\n2019-11-04 13:09:22.644916: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.644923: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.644931: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-11-04 13:09:22.644938: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.644947: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.644956: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.644964: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.644970: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-11-04 13:09:22.644979: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorListReserve\r\n2019-11-04 13:09:22.644986: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.644993: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-11-04 13:09:22.645001: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.645010: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Enter\r\n2019-11-04 13:09:22.645017: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645024: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.645032: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645041: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.645048: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645054: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645062: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Less\r\n2019-11-04 13:09:22.645070: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Less\r\n2019-11-04 13:09:22.645077: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LogicalAnd\r\n2019-11-04 13:09:22.645085: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645093: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645100: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: LoopCond\r\n2019-11-04 13:09:22.645108: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645116: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645124: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645133: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645140: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645145: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645151: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645161: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645168: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645172: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645179: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645188: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645198: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645206: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645214: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645222: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645230: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645237: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645243: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645250: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645257: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645263: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645271: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645279: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645286: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Exit\r\n2019-11-04 13:09:22.645294: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645300: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645306: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645314: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645322: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorListStack\r\n2019-11-04 13:09:22.645330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645338: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645346: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645354: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645361: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645367: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645375: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645381: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645387: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645456: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645466: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645484: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645499: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645511: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645519: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645526: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645534: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645540: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645546: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645555: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorListGetItem\r\n2019-11-04 13:09:22.645563: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.645571: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Add\r\n2019-11-04 13:09:22.645579: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645587: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.645594: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.645602: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.645609: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.645615: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.645621: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.645629: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645637: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645646: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645655: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645665: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645674: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645685: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645696: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645705: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NotEqual\r\n2019-11-04 13:09:22.645714: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Prod\r\n2019-11-04 13:09:22.645723: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.645733: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Where\r\n2019-11-04 13:09:22.645742: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.645751: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Squeeze\r\n2019-11-04 13:09:22.645761: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.645770: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.645778: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GatherV2\r\n2019-11-04 13:09:22.645788: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n2019-11-04 13:09:22.645796: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Equal\r\n2019-11-04 13:09:22.645804: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645813: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645821: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.645829: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645837: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645849: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645857: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645864: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645893: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.645913: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645924: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.645932: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645940: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645948: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.645957: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645968: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.645978: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.645989: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646000: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646009: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Less\r\n2019-11-04 13:09:22.646018: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Prod\r\n2019-11-04 13:09:22.646027: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.646038: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Where\r\n2019-11-04 13:09:22.646046: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.646055: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Squeeze\r\n2019-11-04 13:09:22.646064: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.646073: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Reshape\r\n2019-11-04 13:09:22.646082: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GatherV2\r\n2019-11-04 13:09:22.646091: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646099: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646107: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.646115: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646123: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Size\r\n2019-11-04 13:09:22.646131: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Equal\r\n2019-11-04 13:09:22.646139: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646148: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646156: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646164: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646172: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646185: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646192: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646199: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646243: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646258: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646268: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646277: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646288: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646299: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646309: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646320: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646330: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.646339: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.646349: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.646357: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.646366: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ExpandDims\r\n2019-11-04 13:09:22.646375: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: ConcatV2\r\n2019-11-04 13:09:22.646384: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NonMaxSuppressionV3\r\n2019-11-04 13:09:22.646394: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GatherV2\r\n2019-11-04 13:09:22.646402: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646410: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646418: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.646426: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646434: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.646444: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646453: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GreaterEqual\r\n2019-11-04 13:09:22.646461: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646469: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646478: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Switch\r\n2019-11-04 13:09:22.646486: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646493: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646505: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646513: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646523: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646531: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646562: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646571: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646585: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646596: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NoOp\r\n2019-11-04 13:09:22.646603: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Shape\r\n2019-11-04 13:09:22.646613: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646623: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.646634: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646643: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TopKV2\r\n2019-11-04 13:09:22.646652: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646662: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646670: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646678: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Sub\r\n2019-11-04 13:09:22.646687: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GatherV2\r\n2019-11-04 13:09:22.646695: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646703: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646711: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646719: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.646727: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646735: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.646743: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.646750: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.646759: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pack\r\n2019-11-04 13:09:22.646767: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646775: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Pad\r\n2019-11-04 13:09:22.646785: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: StridedSlice\r\n2019-11-04 13:09:22.646795: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TopKV2\r\n2019-11-04 13:09:22.646804: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: GatherV2\r\n2019-11-04 13:09:22.646813: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646821: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646829: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Merge\r\n2019-11-04 13:09:22.646837: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646845: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorListSetItem\r\n2019-11-04 13:09:22.646853: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.646860: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646866: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.646872: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: Identity\r\n2019-11-04 13:09:22.646879: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.646884: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: NextIteration\r\n2019-11-04 13:09:22.646891: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-04 13:09:22.649570: E tensorflow/lite/toco/tooling_util.cc:1136] No viable ordering of operators was found. Here is a 'backtrace' of at least one part of the graph that is problematic. It starts with the first operator that has as problematic input array, and then walks back the graph to the operator that produced that input array, etc., until we find the root cause:\r\n2019-11-04 13:09:22.649578: E tensorflow/lite/toco/tooling_util.cc:1143] BEGIN TRACE OF OPERATOR WITH BAD INPUT\r\n2019-11-04 13:09:22.649583: E tensorflow/lite/toco/tooling_util.cc:1144] Here is the first-encountered operator with a bad input: \r\n2019-11-04 13:09:22.649591: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: Merge) : [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/enter/_94, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134 ] -> [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104:1 ]\r\n2019-11-04 13:09:22.649596: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134\r\n2019-11-04 13:09:22.649603: E tensorflow/lite/toco/tooling_util.cc:1195] And that array is the output of the following operator:\r\n2019-11-04 13:09:22.649609: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: NextIteration) : Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/output/_188 -> StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134\r\n2019-11-04 13:09:22.649614: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/output/_188\r\n2019-11-04 13:09:22.649620: E tensorflow/lite/toco/tooling_util.cc:1195] And that array is the output of the following operator:\r\n2019-11-04 13:09:22.649625: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: Identity) : Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/input/_179 -> Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/output/_188\r\n2019-11-04 13:09:22.649630: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/input/_179\r\n2019-11-04 13:09:22.649636: E tensorflow/lite/toco/tooling_util.cc:1195] And that array is the output of the following operator:\r\n2019-11-04 13:09:22.649641: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: Identity) : StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/Func/StatefulPartitionedCall/input/_65_switch/_114:1 -> Func/StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/body/_85/input/_179\r\n2019-11-04 13:09:22.649646: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/Func/StatefulPartitionedCall/input/_65_switch/_114:1\r\n2019-11-04 13:09:22.649652: E tensorflow/lite/toco/tooling_util.cc:1195] And that array is the output of the following operator:\r\n2019-11-04 13:09:22.649658: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: Switch) : [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/LoopCond/_105 ] -> [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/Func/StatefulPartitionedCall/input/_65_switch/_114, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/Func/StatefulPartitionedCall/input/_65_switch/_114:1 ]\r\n2019-11-04 13:09:22.649662: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104\r\n2019-11-04 13:09:22.649667: E tensorflow/lite/toco/tooling_util.cc:1195] And that array is the output of the following operator:\r\n2019-11-04 13:09:22.649672: E tensorflow/lite/toco/tooling_util.cc:1149] (Unsupported TensorFlow op: Merge) : [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/enter/_94, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134 ] -> [ StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/merge/_104:1 ]\r\n2019-11-04 13:09:22.649676: E tensorflow/lite/toco/tooling_util.cc:1163] The bad input here is: StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134\r\n2019-11-04 13:09:22.649681: F tensorflow/lite/toco/tooling_util.cc:1165] Cycle found! We already encountered that input array, StatefulPartitionedCall/model_1/decoded_predictions/loop_over_batch/while/next_iteration/_134, earlier in the above trace! We expect graphs to be acyclic, even RNNs. Let us know if some graph actually needs to have cycles, but first, please check if it really is an *inference* graph. *Training* graphs are out-of-scope for toco.\r\nFatal Python error: Aborted\r\n```\r\n\r\nYou can see it ends the same way, but with a much longer error message before it. Is there any reason the input during conversion might be faulty - combined with the missing output dimensions that I had previously? I'm asking since the trace seems to go all the way back, but then again it does not explain why it didn't work on 1.15.", "It seems like your model has control flow in it. There are two ways you can try converting your model:\r\n\r\n1. [`OpHint`](https://www.tensorflow.org/lite/convert/rnn) based conversion. This is recommended for TensorFlow 1.X.\r\n2. MLIR-based converter (which only supports TensorFlow 2.0 control flow). To try it out you can use the `tf-nightly` pip package and then try:\r\n\r\n```\r\nlstm_model = tf.keras.Sequential(...)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```", "@gargn thanks for the suggestion. But surely it shouldn't be complaining about cycles then, when my model is not an RNN, it only has a final map_fn call in the end logic. That's the weird part here.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33914\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33914\">No</a>\n"]}, {"number": 33913, "title": "Setting inputs tf.keras.Model", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes  \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (see link below)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -  \r\n- TensorFlow installed from (source or binary): binary  \r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nInput shapes are not determined automatically which leads to impossibility to save a custom keras model.\r\n\r\n**Describe the expected behavior**\r\nInput shapes should be derived automatically. And it should be possible to save custom keras model. \r\n\r\n**Code to reproduce the issue**\r\n[Gist](https://gist.github.com/RomanSteinberg/c4a47470ab1c06b0c45fa92d07afe2e3) which is the part of  [Colab example](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/custom_layers_and_models.ipynb).\r\n\r\n**Other info / logs**\r\nThere is an [Colab example](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/custom_layers_and_models.ipynb) which demonstrates the problem. The part \"Putting it all together\" demonstrates the training of VAE. If you try to save model `vae.save('vae')` you obtain an error\r\n```\r\nValueError: Model <__main__.VariationalAutoEncoder object at 0x7fde216170f0> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).\r\n```\r\nBut it is impossible to add such line to `__init__` or `call` method. The only workaround I found is to add\r\n```\r\nif step == 0 and epoch == 0:\r\n     vae._set_inputs(x_batch_train)\r\n```\r\nin the training loop. It is not straight forward. Anyway, input shapes should be determined while training without this code.", "comments": ["@RomanSteinberg I tried running the example and then saved model (`vae.save(\"./my_model\")`) without any issue. Please check [the gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/bd3e400db9d5dbfaa328a6f41ffc9b89/custom_layers_and_models.ipynb). Please elaborate on what is missing and what feature you are requesting. Thanks ", "@RomanSteinberg did you had a chance to look at my gist. Please close the issue if it was resolved already. Thanks!", "@jvishnuvardhan sorry, for being out of github. I checked your gist and it uses nightly build and version tf 2.1.0. I specified tf 2.0.0 in my starting post. Tomorrow I'll check more carefully and if this problem is resolved in tf 2.1.0 I will close the issue.", "@jvishnuvardhan your gist hasn't solved this issue. \r\nI ran first cell of your gist. It install tf 2.1.0-dev20191201 and asked me to restart runtime. I did it and ran all cells before section 'Putting it all together' and trained vae for 1 epoch. I've got [the same issue](http://i.imgur.com/6FhueIr.png). \r\n\r\nSecond experiment. I restarted runtime and ran all cells including section 'Putting it all together' cells. There are two training processes. First uses loops which causes the error I mentioned earlier and second uses `vae.fit` method. It overwrites variable `vae` and I tried to save this new variable. It [succeeds with warning](http://i.imgur.com/8JgLtqJ.png). So, it means that the problem is in the training process which uses loops instead of `fit` method.\r\n", "@jvishnuvardhan it seems that a month has passed without any activity. I think that possibility to save model is a core requirement to train a model. May be it is time to raise the priority. What do you think?", "@omalleyt12 the status of this issue is _awaiting tensorflower_. Is it about you? May be you need to change status or something? ", "@RomanSteinberg Thanks for the issue!\r\n\r\nThis is fixed in the latest nightly: `pip install -U tf-nightly`"]}, {"number": 33912, "title": "Support dynamic shapes for IndexedSlices in the _num_elements function", "body": "Fixes #33681.", "comments": ["@alexeyr is it possible to write some test cases around these changes ?", "@rthadur Can you say where should I look for the current tests of this functionality? ", "@alexeyr tensorflow/python/eager/backprop_test.py contains the tests for backprop.py", "@alexeyr can you please fix the build failures ?", "Out of work for family reasons, I'll look into it tomorrow.", "@rthadur Well, that... sure was an error, should be fixed now. Still trying to write a proper test.", "@alexeyr thank you , should i mark this as WIP till test cases are done ?", "Oh, #34093 can provide a test. I'll try it on Monday, if not earlier. @rthadur Yes.", "@alexeyr: Yes, but I think ideally we'll want something a bit more isolated to this change if possible.", "Ok, so I need to somehow make sure `InitialGradients` \r\nhttps://github.com/tensorflow/tensorflow/blob/0250bfdb8c8f0dce3e11c91f5969c994660d21d9/tensorflow/c/eager/tape.h#L566-L573\r\nfills an entry in its `result` with more than `kMinAggregateCount` (i.e. 4) values. Can't figure out how to make it happen yet :(", "@jaingaurav Can you please take a look on this PR? Thanks!", "@alexeyr Can you please resolve conflicts? Thanks!\r\n", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 33911, "title": "tf.keras (tf 2) much slower than tf 1.14", "body": "I try to train a simple dense feedforward network consisting of:\r\n\r\n- input layer of size 8\r\n- 3 hidden layers, each with 40 neurons and ReLU activations\r\n- output layer of size 9\r\n\r\nfor a regression.\r\n\r\nThe performance of keras using tensorflow 1.14 is about 3 times faster than using a freshly installed tensorflow 2.0.0... Is this to be expected, or might this be a bug?\r\nI am training on a CPU.\r\n", "comments": ["@renatobellotti Can you please provide a standalone code to reproduce the issue? Thanks!", "I cannot reproduce it anymore... Probably something with my setup was wrong. Thanks for your interest anyway!"]}, {"number": 33910, "title": "build tensorflow from source failed on Linux", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.14\r\n- Python version: Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0] :: Anaconda, Inc. on linux\r\n- Installed using virtualenv? pip? conda?: NA\r\n- Bazel version (if compiling from source): 0.25.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; nvcc release 9.1, V9.1.85\r\n- CUDA/cuDNN version: 9.1/7.3.0\r\n- GPU model and memory: Nvidia Titan XP with 12 GB memory\r\n\r\n**Describe the problem**\r\nbuild tensorflow from source on branch r1.14 on ubuntu 16.04 with GPU and XLA support failed. Errors related to undefiend symbols in cublas occured. I can ensure the cublas library has been installed in the $CUDA_HOME/lib64 (/usr/local/cuda/lib64) which has been added to $LD_LIBRARY_PATH. I also print the symbols in the installed cublas.so and the two undefined symbols can be found:\r\n\r\n> dongxiao@178-ubuntu ~/working/tensorflow                                                                                                                                  \r\n> (base) > $ nm -D /usr/local/cuda/lib64/libcublas.so | grep \"cublasGemmStridedBatchedEx\"                                                                                   \r\n> 0000000000398e70 T cublasGemmStridedBatchedEx\r\n> dongxiao@178-ubuntu ~/working/tensorflow                                                                                                                                  \r\n> (base) > $ nm -D /usr/local/cuda/lib64/libcublas.so | grep \"cublasGemmBatchedEx\"                                                                                          \r\n> 0000000000399e20 T cublasGemmBatchedEx\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ngit checkout r1.14\r\n./configure  #only enable GPU and XLA support\r\nbazel build --verbose_failures --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka --config=nonccl --action_env=LD_LIBRARY_PATH=/usr/local/cuda/lib64/ --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n> ERROR: /home/dongxiao/working/tensorflow/tensorflow/contrib/ffmpeg/BUILD:100:1: Linking of rule '//tensorflow/contrib/ffmpeg:gen_decode_video_op_py_py_wrappers_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n>   (cd /home/dongxiao/.cache/bazel/_bazel_dongxiao/09108a4ee4f3be79160332645b3550ec/execroot/org_tensorflow && \\\r\n>   exec env - \\\r\n>     LD_LIBRARY_PATH=/usr/local/cuda/lib64: \\\r\n>     PATH=/home/dongxiao/anaconda3/bin:/home/dongxiao/anaconda3/condabin:/usr/local/cuda/bin:/home/dongxiao/tools/login/node-v8.2.1-linux-x64/bin:/home/dongxiao/tools/llvm-4.0.0.src/build/bin:/home/dongxiao/tools/cfe-4.0.1.src/build/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\r\n>     PWD=/proc/self/cwd \\\r\n>   external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/contrib/ffmpeg/gen_decode_video_op_py_py_wrappers_cc '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow' -Lbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow -Wl,-ldl '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -pthread -pthread -pthread -Wl,-S -Wl,-no-as-needed -pie -Wl,-z,relro,-z,now '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -no-canonical-prefixes -fno-canonical-system-headers -B/usr/bin -Wl,--gc-sections -Wl,@bazel-out/host/bin/tensorflow/contrib/ffmpeg/gen_decode_video_op_py_py_wrappers_cc-2.params)\r\n> Execution platform: @bazel_tools//platforms:host_platform\r\n> bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.1: undefined reference to `cublasGemmBatchedEx'\r\n> bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sffmpeg_Cgen_Udecode_Uvideo_Uop_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.1: undefined reference to `cublasGemmStridedBatchedEx'\r\n> collect2: error: ld returned 1 exit status\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> INFO: Elapsed time: 348.727s, Critical Path: 79.30s\r\n> INFO: 1621 processes: 1621 local.\r\n> FAILED: Build did NOT complete successfully\r\n\r\nIt seems the cublas linking options are not added in the command properly, which should be '-lcublas -L/usr/local/cuda/lib64'. But I'm not sure about that. I have not found propoer place to add these options to try.", "comments": ["any comments?", "@dongxiao92 \r\n\r\nCan you please let us know the output of `./configure.py.` Thanks!", "@ravikyram \r\nhello, the output of ./configure is listed below.\r\n\r\n> \r\n> dongxiao@178-ubuntu ~/working/tensorflow                                                                 [16:59:53] \r\n> (base) > $ ./configure                                                                                   [\u00b1r1.14 \u25cf]\r\n> WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\n> You have bazel 0.25.0 installed.\r\n> Please specify the location of python. [Default is /home/dongxiao/anaconda3/bin/python]: \r\n> \r\n> \r\n> Found possible Python library paths:\r\n>   /home/dongxiao/anaconda3/lib/python3.7/site-packages\r\n> Please input the desired Python library path to use.  Default is [/home/dongxiao/anaconda3/lib/python3.7/site-packages]\r\n> \r\n> Do you wish to build TensorFlow with XLA JIT support? [Y/n]: Y\r\n> XLA JIT support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\n> No OpenCL SYCL support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with ROCm support? [y/N]: N\r\n> No ROCm support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with CUDA support? [y/N]: y  \r\n> CUDA support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with TensorRT support? [y/N]: N\r\n> No TensorRT support will be enabled for TensorFlow.\r\n> \r\n> Found CUDA 9.1 in:\r\n>     /usr/local/cuda/lib64\r\n>     /usr/local/cuda/include\r\n> Found cuDNN 7 in:\r\n>     /usr/local/cuda/lib64\r\n>     /usr/local/cuda/include\r\n> \r\n> \r\n> Please specify a list of comma-separated CUDA compute capabilities you want to build with.\r\n> You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\n> Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: \r\n> \r\n> \r\n> Do you want to use clang as CUDA compiler? [y/N]: N\r\n> nvcc will be used as CUDA compiler.\r\n> \r\n> Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n> \r\n> \r\n> Do you wish to build TensorFlow with MPI support? [y/N]: N\r\n> No MPI support will be enabled for TensorFlow.\r\n> \r\n> Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n> \r\n> \r\n> Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\n> Not configuring the WORKSPACE for Android builds.\r\n> \r\n> Preconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n> \t--config=mkl         \t# Build with MKL support.\r\n> \t--config=monolithic  \t# Config for mostly static monolithic build.\r\n> \t--config=gdr         \t# Build with GDR support.\r\n> \t--config=verbs       \t# Build with libverbs support.\r\n> \t--config=ngraph      \t# Build with Intel nGraph support.\r\n> \t--config=numa        \t# Build with NUMA support.\r\n> \t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n> Preconfigured Bazel build configs to DISABLE default on features:\r\n> \t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n> \t--config=nogcp       \t# Disable GCP support.\r\n> \t--config=nohdfs      \t# Disable HDFS support.\r\n> \t--config=noignite    \t# Disable Apache Ignite support.\r\n> \t--config=nokafka     \t# Disable Apache Kafka support.\r\n> \t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\n> Configuration finished\r\n> ", "guys, any updates?", "I suspect that TF1.14 and cuda 9.1 are not compatible. I have the same issue currently, and I am trying to switch to 10.1 to see if it builds. I think this issue is actually why I have been using TF 1.13.", "@dongxiao92, Tensorflow 1.14 supports CUDA 10.0 and cuDNN 7.4.\r\nPlease take a look at [tested build configuration](https://www.tensorflow.org/install/source#gpu).", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33910\">No</a>\n"]}, {"number": 33909, "title": "Create temp", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33909) for more info**.\n\n<!-- need_sender_cla -->", "Please don't spam PRs"]}, {"number": 33908, "title": "tf.keras.layers.SimpleRNN train with batch data  like original keras API", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):conda\r\n- TensorFlow version (use command below):1.14.0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:16G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI can not train my image with shape (None,256,256)\r\n\r\n**Describe the expected behavior**\r\nI need a interface from the new api like this:\r\n# RNN cell\r\nmodel.add(SimpleRNN(\r\n    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.\r\n    # Otherwise, model.evaluate() will get error.\r\n    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),  # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,\r\n    output_dim=CELL_SIZE,\r\n    unroll=True,\r\n))\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nclass Simple_IRNN(tf.keras.layers.Layer):\r\n    def __init__(self,in_channels,scope='simpleirnn',alpha=1.0):\r\n        super(Simple_IRNN,self).__init__()\r\n        self.num_outputs=in_channels\r\n        self.batch_size=8\r\n        self.num_outputs=256\r\n        self.alpha=alpha\r\n    \r\n\r\n        self.left=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',\r\n        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True) # (batch_size, timesteps,input_features)\r\n        self.right=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',\r\n        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)\r\n        self.up=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',\r\n        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)\r\n        self.down=tf.keras.layers.SimpleRNN(self.num_outputs,activation='relu',\r\n        recurrent_initializer=tf.keras.initializers.Identity(gain=self.alpha),return_sequences=True)\r\n\r\n\r\n\r\n    def call(self,inputs):\r\n   \r\n\r\n        inputs=tf.nn.relu(inputs)\r\n        inputs=tf.reduce_sum(inputs,axis=-1)\r\n  \r\n        mask=tf.cast(tf.ones(shape=(256,256),dtype=tf.int32),dtype=tf.bool)\r\n\r\n        temp=tf.image.flip_up_down(inputs)\r\n        temp=tf.image.rot90(temp,k=1)\r\n\r\n        print(\"inputs shape:\",inputs.shape)\r\n        self.up.get_initial_state(inputs=temp)   \r\n        self.right.get_initial_state(inputs=inputs)\r\n\r\n        output_up=self.up(temp)\r\n        output_right=self.right(inputs)\r\n\r\n        temp=tf.image.rot90(inputs,k=1)\r\n\r\n        self.down.get_initial_state(inputs=temp)\r\n        output_down=self.down(temp)\r\n       \r\n\r\n        temp=tf.image.flip_left_right(inputs)\r\n        self.left.get_initial_state(inputs=temp)\r\n  \r\n        output_left=self.left(temp)\r\n\r\n\r\n        output_right=tf.reshape(output_right,(self.batch_size,256,256,1))\r\n        output_up=tf.reshape(output_up,(self.batch_size,256,256,1))\r\n        output_down=tf.reshape(output_down,(self.batch_size,256,256,1))\r\n        output_left=tf.reshape(output_left,(self.batch_size,256,256,1))\r\n\r\n        \r\n        return output_up,output_right,output_down,output_left\r\n\r\n\r\nhere is my selfdefine layer ,it can run,but I found change to my selflayer my eval loss and acc don't change anymore \r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sunzhe09 Can you please provide a standalone code to reproduce the issue? Also, mention about TF version. Thanks!", "@jvishnuvardhan I can run my code ,because my batchsize is None in the Old code,but when I train ,my loss didn't change", "@sunzhe09 Can you please provide a standalone code to reproduce the issue? Thanks!", "@jvishnuvardhan sorry for my late response,I have pass the code ,it't my fault.when I set a new model with Input layer and set the input shape then, the code can run .The rnn return sequence can't process tensor with None batch"]}, {"number": 33907, "title": "Init node Adam/iter/Assign doesn't exist in graph", "body": " model = keras.Sequential([\r\n\r\n        layers.Flatten(input_shape=(image_h, image_h, 1)),\r\n    ])\r\nmodel.compile(optimizer='adam',\r\n                      loss='sparse_categorical_crossentropy',\r\n                      metrics=['accuracy'])\r\nmodel.save(\"model_right_error.h5\")\r\n\r\n--------------\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(\"model_right_error.h5\")\r\ntflite_model = converter.convert()\r\nopen(\"model2.tflite\", \"wb\").write(tflite_model)\r\n\r\ntensorflow/core/grappler/grappler_item_builder.cc:637] Init node Adam/iter/Assign doesn't exist in graph\r\n\r\n\r\nhow to fix?\r\n\r\n", "comments": ["\r\nandroid\r\ndoes not encode a valid TensorFlowLite model: The model is not a valid Flatbuffer file", "@dizhanbin ,\r\nHello, can you please refer this similar [Stackoverflow](https://stackoverflow.com/questions/56256478/converted-model-tflite-does-not-encode-a-valid-tensorflowlite-model-could-not-o) issue and let us know if it helped.Thanks!", "fixed it ,removed anaconda and installed package by pycharm."]}, {"number": 33906, "title": "Update sample session for build from source instruction docs", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/source_windows\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing):\r\nThe sample sessions given in the docs are old (Bazel 0.15.1, TensorFlow 1.11, python 2.7)\r\nA new session-copy with the more recent TensorFlow 2.x with Bazel 0.26.1 would be more helpful.\r\nAlso, python 2.7 is reaching end-of-life in Jan 2020.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? Yes. \r\n", "comments": ["@nikochiko Are you saying the instructions to install TF from source uses Bazel 0.15.1? I see [here](https://www.tensorflow.org/install/source_windows#setup_for_windows) Bazel 0.24.1. Am I missing something here. Can you please describe with little more details? Thanks!", "@jvishnuvardhan I don't mean in the text instructions. There is a sample configuration session on the instructions page. It drops down with a '+' button. \r\n![Capture](https://user-images.githubusercontent.com/37668193/68988565-8d137780-085f-11ea-9ca9-ce65db0abd28.PNG)\r\n\r\nIt is very outdated. Having a newer version can help with installation since many users are facing build failures.", "@nikochiko I agree that the sample configuration is with an older version but it an example to any user how to configure. It is difficult to update this configuration every time when a dependency (python/CUDA/Bazel etc) is changed. Thanks!\r\n\r\n@MarkDaoust Can you Please take a look at it. Are we updating this in the near future? Thanks! ", "I am closing this issue as I think this issue was resolved. There is another `sample configuration` with newer versions in the build-from-source for linux/MacOS [page](https://www.tensorflow.org/install/source). Thanks!\r\n\r\n<img width=\"882\" alt=\"Screen Shot 2020-11-05 at 7 57 36 PM\" src=\"https://user-images.githubusercontent.com/46058173/98324483-3b4c8b80-1fa1-11eb-9154-69cc20fd5fad.png\">\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33906\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33906\">No</a>\n"]}, {"number": 33905, "title": "'Copy link to this section' feature not working for certain sections.", "body": "## URL(s) with the issue:\r\n- https://www.tensorflow.org/install/source_windows\r\n- https://www.tensorflow.org/install/source\r\n\r\n## Browser used:\r\nTried on Microsoft Edge and Mozilla Firefox up-to-date versions.\r\n\r\n## Description of issue (what needs changing):\r\nThe 'Copy link to this section' feature is not working for the `View sample configuration session` sections for the Linux and Windows build-from-source instruction docs.\r\n### Clear description:\r\nThe issue-causing sections are located under these sections: \r\n- https://www.tensorflow.org/install/source#sample_session (Linux)\r\n- https://www.tensorflow.org/install/source_windows#configure_the_build (Windows)\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?:  Yes, I can fix the markdown to correct the issue.\r\n", "comments": ["@lamberta From where should this issue be fixed? It doesn't look like a markdown issue. \r\nThank you in advance. ", "Possibly related to internal bug: b/115916696\r\nWill wait and see", "> The 'Copy link to this section' feature is not working for the `View sample configuration session` sections for the Linux and Windows build-from-source instruction docs.\r\n\r\n@nikochiko,\r\nLooks like this issue is fixed. Links for `View sample configuration session` section works for both Windows and Linux.\r\n\r\n- Windows : https://www.tensorflow.org/install/source_windows#expandable-1\r\n- Linux : https://www.tensorflow.org/install/source#expandable-1\r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33905\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33905\">No</a>\n"]}, {"number": 33904, "title": "Hopefully can solve issue #33811", "body": "Hopefully can solve issue #33811", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33904) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "@googlebot I fixed it.\r\n\r\n", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33904) for more info**.\n\n<!-- cla_yes -->", "@qlzh727 Can you please take a look at this? We expect that Sequence and Generator data adapters should not overlap no?", "Yea, Sequence and Generator data adapter shouldn't overlap. From the name of ImageDataGenerator, it will return a generator? ", "Signed CLA, but still got the error. Can't get any clue...\n\n[image: image.png]\n\nRajeshwar Reddy T <notifications@github.com> \u4e8e2019\u5e7411\u67082\u65e5\u5468\u516d \u4e0a\u53483:48\u5199\u9053\uff1a\n\n> @gekowa <https://github.com/gekowa> please sign CLA ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33904?email_source=notifications&email_token=AAH42ERNOKIRA7BYX6CGPQDQRSBZHA5CNFSM4JHWSHZ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEC364XA#issuecomment-548925020>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAH42EXHH5RO3IJKMW7QPCLQRSBZHANCNFSM4JHWSHZQ>\n> .\n>\n", "@omalleyt12 @qlzh727 What should I do next? Several pending checks pending for days...", "Thanks for sending this PR. We wasn't expecting the overlapping the usage of data adapter in the first place, but now if this doesn't holds any more, we want to be thoughtful when there are multiple adapter can be used, and also which one should take priority. \r\n\r\nThis PR so far only mitigate the immediate error, but we probably want to put more updates into this issue. I will take the issue from here and fix it. Thanks for the contribution anyway.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33904) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 33903, "title": "tensorflow 2.0, tf.keras can't place model with tf.device('/device:GPU:0')?", "body": "\r\nI have 2 different models and I want to train multitasks by loading those models to different GPUs respectively. I think this is so-called model parallelism. For example, one model is about 8GB, another is 12GB, I use the following code to load model to the respective device, however, it just doesn't work, the TensorFlow trying to load the whole model into same GPU(PC with 2 RTX Titan 24GB). Is this the problem with namescope?\r\n\r\nSystem information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\nTensorFlow version (use command below): 2.0.0-stable version\r\nPython version: 3.7.4\r\nCUDA/cuDNN version: 10.0\r\nGPU model and memory: RTX Titan x2 \r\n\r\n```\r\nwith tf.device('/device:GPU:0'):\r\n     model_1 = K.models.load_model(model_path1)\r\nwith tf.device('/device:GPU:1'):\r\n     model_2 = K.models.load_model(model_path2)\r\n```\r\n\r\nCan I have some support with this?\r\n\r\nI have been asked this problem in [stackoverflow](https://stackoverflow.com/questions/58448034/tensorflow-2-0-how-to-train-mutliple-model-with-mutliple-gpu) but no body answer my question.\r\n", "comments": ["Can you please go through the [link](https://www.tensorflow.org/guide/gpu#using_multiple_gpus) and see if it helps you. Thanks!", "@luvwinnie \r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}]