[{"number": 16933, "title": "Converting numpy array to TFRecord is slow", "body": "### FloatList and Feature is slow for numpy array.\r\nSaving numpy arrays with np.load and np.save is much faster than Converting to TFRecord and reading it back.\r\nwhile profiling the code, I found that half of the time is spent in _floats_feature.\r\ntf.train.FloatList is taking 1/3 of the time.\r\nHow to speed this up? \r\n\r\n### System information\r\n- **Below snippet of code to convert numpy array is much slow compared  np.save, np.load**:\r\n- **OS Platform and Distribution: Linux Ubuntu 16.04\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 2.7.12\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\n\r\ndef floatme(value):\r\n    return tf.train.FloatList(value=value)\r\n\r\ndef _floats_feature(value):\r\n    return tf.train.Feature(float_list=floatme(value))\r\n\r\ntfr_filename = \"deleteme.tfr\"\r\ndata = [\" \".join(np.random.randint(0, 1000, size=4005).astype(str)) for i in range(10000)]\r\nwith tf.python_io.TFRecordWriter(tfr_filename) as writer:\r\n    print('Converting to vectors')\r\n    vectors = [np.fromstring(line, dtype=int, sep=' ', count=4004+1) for line in data]\r\n    print('Converting to examples')\r\n    for i, vec in enumerate(vectors):\r\n        # Create an example protocol buffer\r\n        example = tf.train.Example(features=tf.train.Features(feature={\r\n            'label': _floats_feature([vec[4004], vec[4004]<1.0]),\r\n            'data' : _floats_feature(vec[:4004]),\r\n            }))\r\n        writer.write(example.SerializeToString())\r\n\r\n\r\n```\r\n\r\n\r\nncalls | tottime | percall | cumtime | percall | filename:lineno(function)\r\n-- | -- | -- | -- | -- | --\r\n232810 | 49.887 | 0 | 49.887 | 0 | convert_train_dataset_tfrecord.py:76(floatme)\r\n116405 | 20.095 | 0 | 20.095 | 0 | {numpy.core.multiarray.fromstring}\r\n232810 | 13.328 | 0 | 63.216 | 0 | convert_train_dataset_tfrecord.py:79(_floats_feature)\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I'd like to add to this, it seems as though the instantiation of a `tf.train.Features` object takes a tremendous amount of time. A very simple example of timings on my machine:\r\n\r\n```python\r\nstart = time.perf_counter()\r\n\r\nfor i in range(2000000):\r\n    example = tf.train.Example()\r\n\r\ntime.perf_counter() - start\r\n```\r\n\r\nThe instantiation of *2,000,000* examples with no features takes *.76* seconds.\r\n\r\n```python\r\nstart = time.perf_counter()\r\n\r\nfor i in range(2000000):\r\n    example = tf.train.Example()\r\n    feature_1 = tf.train.Int64List(value=[10])\r\n    feature_2 = tf.train.Int64List(value=[10])\r\n        \r\ntime.perf_counter() - start\r\n```\r\n\r\nThe instantiation of *2,000,000* examples and two `tf.train.Int64List` objects takes *5* seconds.\r\n\r\n```python\r\nstart = time.perf_counter()\r\n\r\nfor i in range(2000000):\r\n    example = tf.train.Example()\r\n    feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[10]))\r\n    label = tf.train.Feature(int64_list=tf.train.Int64List(value=[10]))\r\n        \r\ntime.perf_counter() - start\r\n```\r\n\r\nThe instantiation of *2,000,000* examples and two `tf.train.Int64List` features takes *11* seconds.\r\n\r\n```python\r\nstart = time.perf_counter()\r\n\r\nfor i in range(2000000):\r\n    example = tf.train.Example(features = tf.train.Features(\r\n            feature={\r\n                'src': tf.train.Feature(int64_list=tf.train.Int64List(value=[10])),\r\n                'dst': tf.train.Feature(int64_list=tf.train.Int64List(value=[10])),\r\n            }\r\n        )\r\n    )\r\n        \r\ntime.perf_counter() - start\r\n```\r\n\r\nThe instantiation of *2,000,000* examples with two `tf.train.Int64List` features takes *41* seconds.\r\n\r\nAnd finally, when I put it all together with a TFRecordWriter:\r\n\r\n```python\r\nstart = time.perf_counter()\r\n\r\nwith tf.python_io.TFRecordWriter('/mnt/data/repository/test.tfrecord') as writer:\r\n    for i in range(2000000):\r\n        example = tf.train.Example(features = tf.train.Features(\r\n                feature={\r\n                    'src': tf.train.Feature(int64_list=tf.train.Int64List(value=[10])),\r\n                    'dst': tf.train.Feature(int64_list=tf.train.Int64List(value=[10])),\r\n                }\r\n            )\r\n        )\r\n\r\n        serialized = example.SerializeToString()\r\n        writer.write(serialized)\r\n        \r\ntime.perf_counter() - start\r\n```\r\n\r\nThe final timing is *64* seconds for *2,000,000* records.\r\n\r\nUnfortunately when you have a dataset that's got 1 billion rows it means that it takes 8.8 hours just to convert to tfrecord files.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 50 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I can confirm the timing results of mbrio, i wonder if there is any way to speed this up besides performing the computation in parallel? \r\n\r\nSetup: \r\nOS: Ubuntu 18.04\r\nTensorflow-GPU running on CPU i7-7700HQ\r\nTensorflow version: 1.12.0 (installed via pip install) ", "@lxkarthi @mbrio @bstadlbauer \r\n\r\n\r\nThe SIG I/O under TensorFlow:\r\n\r\nhttps://github.com/tensorflow/community/blob/master/sigs/io/CHARTER.md\r\n\r\nhas a focus on data and streaming processing for tensorflow. We are working on improving the data input output (likely with tf.data API).\r\n\r\nThe SIG I/O google group is:\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!forum/io\r\n\r\nYou could consider joining the google group to explain your use case so that we could fine a way to resolve the performance issue you are encountering, or create an issue in https://github.com/tensorflow/io\r\n", "@shivaniag We've never hear back from the tensorflow team on this issue. Could you give us an update on whether this is recognized as a problem or not?", "@jsimsa do you have an update on this.", "Just want to say that my team suffers from the same issue @mbrio mentions. Using `tf.train.Feature` and `tf.train.Example` to generate serialized examples is convenient, but prohibitively slow.\r\n\r\nA solution could be to implement native tensorflow ops for this that don't have to be wrapped in a `tf.py_function`?", "@harahu Are you looking for reading numpy files (on disk) into tf.data, or converting numpy array (in memory managed by python process) into tf.data (in memory and managed by tf process)?\r\n\r\nThe former might be easier to implement than the latter. The underlying tensorflow (including tf.data) is implemented in C++ and interacting with python's memory is not very straightforward (hence the not so convenient `tf.py_function`).", "@yongtang I am looking to serialize data in order to write to tfrecord files. The origin of my data is numpy arrays, but the solution doesn't need to be a direct mapping from numpy arrays to serialized strings, as I don't mind turning said arrays into tensors before serialization. We have `tf.serialize_tensor` already, which is efficient, but it is very limited in what it can serialize (one tensor at a time). A `tf.data.Dataset` can have quite complex structure. For instance, I have a time series dataset structured something like this:\r\n```python\r\ndataset.output_types\r\n>>> {'feature0': tf.float32, 'feature1': tf.int64, 'lable': tf.int64, 'timestamp': tf.int64}\r\n```\r\n\r\nI would love to have a tf op with the efficiency of `tf.serialize_tensor`, but the usability and flexibility of `tf.Feature` and `tf.Example`. Some operation where I could map the  dictionary structure above directly to a single `tf.string`, ready to write to file.", "@rohan100jain and @frankchn are working on a mechanism for persisting the outputs of (a prefix of) an input pipeline which needs to solve the same problem (efficiently serializing elements of a tf.data.Dataset).\r\n\r\nI believe that their solution could be extended to provide \"save\" and \"load\" functionality, but I also expect that it might take some time to settle on a format for which backwards compatibility is provided (i.e. it might initially be only possible to \"load\" data which was \"save\" using the same version of TensorFlow).", "@jsimsa I also assume that some serialization happens when you cache a dataset to file:\r\n```python\r\ndataset = dataset.cache(filename='somecachefile')\r\n```\r\nBut I don know if or how this might be usable in solving the issues mentioned here.", "@jsimsa This sounds very promising, but just want to mention that one use-case for efficient serialization   of tf.data is handling a dataset that is too large to fit in memory. If there is only a simple \"save\" and \"load\" command that attempts to load everything into memory that use is not covered. For me, the ideal solution would be something that can save/load batch by batch or similar so that I can avoid memory issues. Not implying you didn't already think of this, just trying to show interest for the specific part of the feature I would find most helpful.", "@harahu The `cache(filename=...)` transformation could indeed by used as a stop gap solution for serializing and deserializing data.\r\n\r\n@areeh the prospective \"save\" and \"load\" functionality would work similar to the rest of tf.data transformations (in that it would support streaming of elements). In other words, it would not require that all of the data can fit into memory.", "Functionality similar to the rest of tf.data was exactly what I was hoping for, thank you", "@jsimsa It could, in a way, but to be able to read from the cached file you would need a dataset instance configured exactly like the one that was used to write the cache. This seems fairly restrictive. My thinking was more that you, or rather @rohan100jain and/or @frankchn, could maybe gain some inspiration (in a very broad sense) from the cache implementation. I don't know the details of it, but it seems it uses protocol buffers at least.", "The current `cache` implementation uses ~~TFRecords~~ TensorBundles, which are not great (performance-wise) for data reading and writing ~~(and also doesn't support other things like indexing into a specific record, etc...)~~. We are still thinking through a better file format internally and will provide updates when we think we have a better solution.", "@frankchn Will [HDF5](https://support.hdfgroup.org/about/hdf_technologies.html) be a potential format? It supports various data types, index, chunking, compression and efficient I/O. "]}, {"number": 16932, "title": "Clarify RNNCell documentation on state_size and zero_state", "body": "## TF Version\r\nDocumentation of current head r1.5\r\n\r\n### Describe the problem\r\nIn the [RNNCell documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/RNNCell#zero_state) for `zero_state` it is unclear if the state returned from an RNNCell should always be a 1-D Tensor or if it can be an N-D Tensor. The second is actually the case.\r\n\r\nThe current documentation says\r\n> If state_size is an int or TensorShape, then the return value is a N-D tensor of shape [batch_size, state_size] filled with zeros.\r\n\r\nThis is mostly true, however if Rank(TensorShape) is > 1 then it should say `[batch_size] + state_size.shape.as_list()` or some variant, to properly inform the user that arbitrary dimensioned Tensors can be passed through.\r\n\r\nThis is contradicted in the next sentence with:\r\n> If state_size is a nested list or tuple, then the return value is a nested list or tuple (of the same structure) of 2-D tensors with the shapes [batch_size, s] for each s in state_size.\r\n\r\nHere 2-D tensors should be N-D tensors and `[batch_size, s]`  should be `[batch_size] + s.shape.as_list()`.\r\n\r\nFailure to understand that N-D states can be passed back might force some users to flatten and then reshape states, which will result in performance penalties. An example where such N-D states are required might be for RNNCell's with external memory devices (like the DNC from Deepmind).\r\nThe documentation for `state_size` is adequate but could be made to explicitly mention N-D states are allowed.\r\n\r\n### Proof\r\nExample RNNCell with structure state tuple containing N-D state\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.ops import rnn_cell_impl\r\n\r\nclass NDState(rnn_cell_impl.RNNCell):\r\n    def __init__(self,\r\n            output_size):\r\n        self._output_size=output_size\r\n\r\n    @property\r\n    def state_size(self):\r\n       return (1, (tf.TensorShape([4,4]), 2) )\r\n    @property\r\n    def output_size(self):\r\n        return self._output_size\r\n\r\n\r\n    \r\n    def __call__(self, inputs, state):\r\n        \"\"\"\r\n        inputs : batch_size x input_size\r\n        state : tuple of 2D [batch_size x s]\r\n        \"\"\"\r\n        print(\"State:\",state)\r\n\r\n        return tf.layers.dense(inputs,self.output_size), state\r\n        \r\n\r\n\r\ndef test():\r\n    test_kwargs = { 'output_size':1}\r\n\r\n    inputs = tf.random_normal(shape=(100,10,2),dtype=tf.float32)\r\n    cell = NDState(**test_kwargs)\r\n    zero_state = cell.zero_state(10, tf.float32)\r\n    print(\"Zero_state:\",zero_state)\r\n    output,state = tf.nn.dynamic_rnn(cell,inputs, time_major=True,dtype=tf.float32)\r\n    \r\n\r\n    \r\nif __name__ == \"__main__\":\r\n    test()\r\n```\r\n\r\nPrints:\r\n```\r\nZero_state: (<tf.Tensor 'NDStateZeroState/zeros:0' shape=(10, 1) dtype=float32>, (<tf.Tensor 'NDStateZeroState/zeros_1:0' shape=(10, 4, 4) dtype=float32>, <tf.Tensor 'NDStateZeroState/zeros_2:0' shape=(10, 2) dtype=float32>))\r\nState: (<tf.Tensor 'rnn/while/Identity_3:0' shape=(10, 1) dtype=float32>, (<tf.Tensor 'rnn/while/Identity_4:0' shape=(10, 4, 4) dtype=float32>, <tf.Tensor 'rnn/while/Identity_5:0' shape=(10, 2) dtype=float32>))\r\n```\r\n\r\n## Template\r\nHave I written custom code: N/A\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: git master\r\nTensorFlow version: r1.5 and previous\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to inactivity"]}, {"number": 16931, "title": "how do `TensorFlowInferenceInterface` process image whose height not equal to width", "body": "I'm writing a java service using Spring boot and my tensorflow predict model was trained by python Tensorflo Object Detection API. The model is FasterRCNN (coco-resnet),the model can accept any shape(whose height not equal to width,such as  600x800,1280x720) of image in python while thing cannot be done like this in Java. \r\n\r\nI read an example code written in Java from [TensorFlowImageClassifier.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowImageClassifier.java),the pre-allocate buffers is  $inputSize \\* inputSize$. If i changed that to **inputHeight\\*inputWidth** and some other nessary code, the inference process still went fine but recognize accuracy decrease dramatically.\r\n\r\nCan anybody give some tips?\r\n\r\nHere is my coding envirnoment:\r\n\r\n+ Window 10\r\n+ Tensorflow 1.5 build from whl \r\n+ CUDA 8.0 with cudnn 5.1\r\n+ GPU  nvidia 1080 ti \r\n+ 16GB Memory\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Not an issue anymore,i got some idea from  tensorflow offical examples.Thank you."]}, {"number": 16930, "title": "Gradient function of tile operator failed with sparse Tensor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4/1.5\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI found an issue when I use a _tile_ operator followed by a _gather_ operator. It seems that there is a `isinstance(grad, ops.Tensor)` assert in the gradient function of _tile_ operator, while _gather_ operator will result in a sparse gradient with the type of IndexedSlices.\r\n\r\nPlease see below example for details.\r\n\r\n### Source code / logs\r\nHere is a small example to re-produce this issue:\r\n```python\r\nx = tf.Variable([[0.0], [1.0], [2.0], [3.0], [4.0]], name='x')\r\nx = tf.tile(x, [1, 2])\r\ni = tf.Variable(list(range(0, 5)), name='i')\r\nx = tf.gather(x, i)\r\ns = tf.reduce_sum(x)\r\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\r\ntrain_op = optimizer.minimize(s)\r\n```\r\n\r\nYou will get below errors:\r\n```\r\nValueError: No attr named '_XlaCompile' in name: \"Tile\"\r\nop: \"Tile\"\r\ninput: \"x/read\"\r\ninput: \"Tile/multiples\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"Tmultiples\"\r\n  value {\r\n    type: DT_INT32\r\n  }\r\n}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback\r\n (most recent call last):\r\n  File \"D:/test/test_gather.py\", line 12, in <module>\r\n    train_op = optimizer.minimize(s)\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 355, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 456, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 375, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 609, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"D:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\", line 552, in _TileGrad\r\n    assert isinstance(grad, ops.Tensor)\r\nAssertionError\r\n```\r\n\r\nI think this is caused by the assertion in gradient function of _tile_ operator:\r\n```python\r\n@ops.RegisterGradient(\"Tile\")\r\ndef _TileGrad(op, grad):\r\n  \"\"\"Sum reduces grad along the tiled dimensions.\"\"\"\r\n  assert isinstance(grad, ops.Tensor)\r\n  input_shape = array_ops.shape(op.inputs[0])\r\n```\r\n\r\nCould we remove this assert or change the type to ops._TensorLike?", "comments": ["@augusterodin to clarify, do you think that the assertion is currently overly strict, and that removing the assertion or changing the assertion to ops._TensorLike will work correctly? \r\n\r\nOr are you asking that we both change the assertion and update the functionality to handle a wider set of cases? ", "@cy89 I tried to remove this assertion or change it to ops._TensorLike, it looks worked correctly for my case, except below warning:\r\n\r\n```\r\nD:\\PyEnv\\tf1.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:97:` UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n```\r\n\r\nIt will introduce a force conversion from sparse Tensor to dense Tensor. It's fine for a small sparse Tensor, but may be not suitable for large sparse Tensor. Do you think we need special logic for sparse Tensor here, or just such conversion is fine?", "@mrry not sure if you're the right one to bug about this feature request; please feel free to forward. \r\n@augusterodin 's experiment suggests that removing or weakening the current assert might be safe. How do we feel about that?", "From a quick look, since the gradient of tile is a reduce sum, it seems plausible to make a specialized version that works with IndexedSlices and is much, much more efficient than expanding the incoming gradient out to a dense tensor. (AFAICT it\u2019d be the same reduce_sum applied to IndexedSlices.values, plus some logic for the indices that depends on whether the original input was tiled in the batch dimension or not.) I\u2019d welcome such a contribution, along with tests using the gradient checker.", "@mrry @cy89 Hi, could you take a look at #17083 since it has been a long time. Thanks."]}, {"number": 16929, "title": "Tensorflow Lite toco convert a quantized model to tflite format crash error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: r1.5 / r1.6\r\n- **Python version**: python2.7 / python 3.6\r\n- **Bazel version (if compiling from source)**: bazel release 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: GCC/G++ 7.2.0, \r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: detail description in below\r\n\r\n### Describe the problem\r\n\r\nI use facenet framework which base on Inception_resnet_v1 to recognize face, and i use below command to quantize and convert a freeze graph pb file to tflite format:\r\n\r\nquantize cmd:\r\n\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n   --in_graph=/home/andy/datasets/facenet/facenet_model.pb \\\r\n   --out_graph=/home/andy/datasets/facenet/facenet_model_quantized.pb \\\r\n   --inputs=input:0 \\\r\n   --outputs=embeddings:0 \\\r\n   --transforms='strip_unused_nodes(type=float, shape=\"1,160,160,3\")\r\n    remove_nodes(op=Identity, op=CheckNumerics)\r\n    fold_old_batch_norms\r\n    quantize_weights\r\n    strip_unused_nodes \r\n    sort_by_execution_order'\r\n\r\ntoco convert cmd:\r\n\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --input_file=/home/andy/datasets/facenet/facenet_model_quantized.pb \\\r\n  --output_format=TFLITE \\\r\n  --output_file=/home/andy/datasets/facenet/facenet_model_quantized.lite \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --inference_input_type=QUANTIZED_UINT8 \\\r\n  --input_arrays=input \\\r\n  --output_arrays=embeddings \\\r\n  --input_shapes=1,160,160,3\\\r\n  --mean_values=128 \\\r\n  --std_values=128 \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6\r\n\r\nI sure facenet_model.pb and facenet_model_quantized.pb can be run normal, but when toco convert the quantized model to tensorflow lite format it crash below error:\r\n\r\n`2018-02-11 16:52:44.901519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 16:52:44.901544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 16:52:44.906789: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\r\n2018-02-11 16:52:45.171561: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized)\r\n2018-02-11 16:52:45.309297: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 16:52:45.486937: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 16:52:45.489630: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] Check failed: predicate_array.data_type == ArrayDataType::kBool \r\nAborted (core dumped)\r\n`\r\n\r\nfor resolve the issue i add some debug code before the line of resolve_tensorflow_switch.cc:48, it's like that:\r\n\r\nLOG(INFO) << \"###### predicate_name: \" << LogName(*switch_op);\r\nLOG(INFO) << \"###### predicate_name: \" << predicate_name;\r\nswitch (predicate_array.data_type) {\r\ncase ArrayDataType::kBool:\r\n  LOG(INFO) << \"###### predicate_array.data_type kBool\";\r\n  break;\r\ncase ArrayDataType::kFloat:\r\n  LOG(INFO) << \"###### predicate_array.data_type kFloat\";\r\n  break;\r\ncase ArrayDataType::kUint8:\r\n  LOG(INFO) << \"###### predicate_array.data_type kUint8\";\r\n  break;\r\ncase ArrayDataType::kInt32:\r\n  LOG(INFO) << \"###### predicate_array.data_type kInt32\";\r\n  break;\r\ncase ArrayDataType::kInt64:\r\n  LOG(INFO) << \"###### predicate_array.data_type kInt64\";\r\n  break;\r\ncase ArrayDataType::kNone:\r\n  LOG(INFO) << \"###### predicate_array.data_type kNone\";\r\n  break;\r\ndefault:\r\n  LOG(INFO) << \"###### predicate_array.data_type not know\";\r\n}\r\n\r\nthen, i rebuild the toco, and rerun the convert cmd, log show that:\r\n\r\n`2018-02-11 17:01:34.481749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Dequantize\r\n2018-02-11 17:01:34.486969: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform\r\n2018-02-11 17:01:34.752556: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3003 operators, 5620 arrays (0 quantized)\r\n2018-02-11 17:01:34.888735: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 17:01:35.063875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2890 operators, 5394 arrays (0 quantized)\r\n2018-02-11 17:01:35.066550: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:48] ###### predicate_name: {TensorFlowSwitch operator with output InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4}\r\n2018-02-11 17:01:35.066558: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:49] ###### predicate_name: Const_1\r\n2018-02-11 17:01:35.066562: I tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:67] ###### predicate_array.data_type kNone\r\n2018-02-11 17:01:35.066565: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:72] Check failed: predicate_array.data_type == ArrayDataType::kBool \r\nAborted (core dumped)\r\n`\r\n\r\ni don't know why the \"predicate_name: Const_1\" of op \"InceptionResnetV1/Bottleneck/BatchNorm/cond/FusedBatchNorm_1/Switch_4\" it's data type is KNone, but the function ResolveTensorFlowSwitch::Run request it's data type should be KBool. The Inception_resnet_v1 Bottleneck is in a fully connect layer, and relation code show below:\r\n \r\n`\r\nend_points = {}\r\n  \r\n    with tf.variable_scope(scope, 'InceptionResnetV1', [inputs], reuse=reuse):\r\n        with slim.arg_scope([slim.batch_norm, slim.dropout],\r\n                            is_training=is_training):\r\n            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\r\n                                stride=1, padding='SAME'):\r\n      \r\n                # 149 x 149 x 32\r\n                net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\r\n                                  scope='Conv2d_1a_3x3')\r\n                end_points['Conv2d_1a_3x3'] = net\r\n                # 147 x 147 x 32\r\n                net = slim.conv2d(net, 32, 3, padding='VALID',\r\n                                  scope='Conv2d_2a_3x3')\r\n                end_points['Conv2d_2a_3x3'] = net\r\n                # 147 x 147 x 64\r\n                net = slim.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')\r\n                end_points['Conv2d_2b_3x3'] = net\r\n                # 73 x 73 x 64\r\n                net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\r\n                                      scope='MaxPool_3a_3x3')\r\n                end_points['MaxPool_3a_3x3'] = net\r\n                # 73 x 73 x 80\r\n                net = slim.conv2d(net, 80, 1, padding='VALID',\r\n                                  scope='Conv2d_3b_1x1')\r\n                end_points['Conv2d_3b_1x1'] = net\r\n                # 71 x 71 x 192\r\n                net = slim.conv2d(net, 192, 3, padding='VALID',\r\n                                  scope='Conv2d_4a_3x3')\r\n                end_points['Conv2d_4a_3x3'] = net\r\n                # 35 x 35 x 256\r\n                net = slim.conv2d(net, 256, 3, stride=2, padding='VALID',\r\n                                  scope='Conv2d_4b_3x3')\r\n                end_points['Conv2d_4b_3x3'] = net\r\n                \r\n                # 5 x Inception-resnet-A\r\n                net = slim.repeat(net, 5, block35, scale=0.17)\r\n                end_points['Mixed_5a'] = net\r\n        \r\n                # Reduction-A\r\n                with tf.variable_scope('Mixed_6a'):\r\n                    net = reduction_a(net, 192, 192, 256, 384)\r\n                end_points['Mixed_6a'] = net\r\n                \r\n                # 10 x Inception-Resnet-B\r\n                net = slim.repeat(net, 10, block17, scale=0.10)\r\n                end_points['Mixed_6b'] = net\r\n                \r\n                # Reduction-B\r\n                with tf.variable_scope('Mixed_7a'):\r\n                    net = reduction_b(net)\r\n                end_points['Mixed_7a'] = net\r\n                \r\n                # 5 x Inception-Resnet-C\r\n                net = slim.repeat(net, 5, block8, scale=0.20)\r\n                end_points['Mixed_8a'] = net\r\n                \r\n                net = block8(net, activation_fn=None)\r\n                end_points['Mixed_8b'] = net\r\n                \r\n                with tf.variable_scope('Logits'):\r\n                    end_points['PrePool'] = net\r\n                    #pylint: disable=no-member\r\n                    net = slim.avg_pool2d(net, net.get_shape()[1:3], padding='VALID',\r\n                                          scope='AvgPool_1a_8x8')\r\n                    net = slim.flatten(net)\r\n          \r\n                    net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\r\n                                       scope='Dropout')\r\n          \r\n                    end_points['PreLogitsFlatten'] = net\r\n                \r\n                net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \r\n                        scope='Bottleneck', reuse=False)\r\n  \r\n    return net, end_points\r\n`\r\n\r\nhow can i solve the issue, and which step of convert cmd is it wrong?\r\ni hold someone can help me, thanks!\r\n", "comments": ["@aselle  can you please take a look? Thanks", "@tensorflowbutler ", "you can delete dropout   and try again", "@trjoker thanks for your answer\uff0cwhy dropout function impact toco convert inception resnet v1 to tflite format\uff1f", "I also have the a  problem when using dropout. \r\nThe log info is:\r\n`Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: RandomUniform) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).`\r\n\r\nwhen I comment out code which looks like`net = slim.dropout(net,keep_prob=0.5,is_training=is_training)`,  the toco converter works fine.\r\n\r\nI am really confused.\r\n\r\n\r\n\r\n", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@coutner @xsr-ai `dropout` function uses the operation: `RandomUniform`, to ignore some of the weights. \r\nAs this operation has not been implemented for TFLite, it raises the flag of `Unsupported TensorFlow op`\r\n\r\nWhen you remove the dropout function, the model does not use the `RandomUniform` operation. As a result of which the conversion completes successfully. \r\n\r\nI hope that solves it. ", "Thanks @ranka47 \r\n\r\nI'll close this one for now. Hopefully RandomUniform will be fully supported soon.", "Removing dropout function works, but it's not a good solution...\r\n\r\nAny news on toco supporting dropout ?", "Why doesn't optimizer for inference remove the dropout operation??"]}, {"number": 16928, "title": "[MSVC] Use explicit func pointer to static method instead of lambda func", "body": "MSVC cannot decide the common type to accept two lambda functions even though they are non-capturing and have the same function signatures.\r\n\r\nSince they just pass parameters to static methods, just use function pointers to these static methods.\r\n\r\n`using EqShapeFuncType = bool (*)(const Shape&, const Shape&)` is really just for readability. I just thought that reader might not be able to figure out the function signature if I just use `auto eq_shapes = layout_sensitive ? ShapeUtil::Equal : ShapeUtil::Compatible`.\r\n\r\n/cc @thefiddler\r\n\r\n#16911", "comments": ["@rongjiecomputer  yep, seems to fix this issue."]}, {"number": 16927, "title": "image_retraining/retrain.py warning: Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization()", "body": "If I download https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py and run it I get the following warning:\r\n\r\n`2018-02-10 20:48:38.928435: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\framework\\op_def_util.cc:343] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().`\r\n\r\nHere is a screenshot if that helps:\r\n\r\n![untitled](https://user-images.githubusercontent.com/5672876/36068513-456022f4-0e8c-11e8-8b81-d0d5fb5199b0.png)\r\n\r\nAfter looking at some old TensorFlow issues, for example these:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/2164\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/4128\r\n\r\nIt seems that this concern has existed for quite a while and that it seems likely related to using the Inception model from 2015:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L893\r\n\r\nCan anybody update this to resolve this warning please?\r\n\r\n-- Edit ------------------------\r\n\r\nprovided additional requested information in separate response below", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code:\r\nNo custom code, I ran retrain.py with no modifications\r\n\r\nOS Platform and Distribution:\r\nWindows 10\r\n\r\nTensorFlow installed from:\r\npip\r\n\r\nTensorFlow version:\r\n1.5\r\n\r\nBazel version:\r\nnot sure\r\n\r\nCUDA/cuDNN version:\r\nn/a (using CPU version of TensorFlow)\r\n\r\nGPU model and memory:\r\nn/a (using CPU version of TensorFlow)\r\n\r\nExact command to reproduce:\r\nshown in screenshot above", "Thanks for your input. We will migrate to tf.nn.batch_normalization shortly.", "@bignamehyp Was the example ported to use  tf.nn.batch_normalization? I'm still getting this warning with the latest."]}, {"number": 16926, "title": "Dataset to TFRecord", "body": "The dataset API is excellent, I am even using it to perform data augmentation before training. However, I notice that when converting my dataset to tfrecord I follow a pattern that might easily be automated as a `to_records` method, in fact I think this is somewhat similar to using the `cache` method. Anyway, it would make it very straight forward for dataset users to create tfrecords.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This is a fine suggestion, and something we have been discussing internally. I'm assigning this issue to @jsimsa, who has expressed interest in developing it.\r\n\r\n@cgarciae There are a lot of possible designs for a feature like this. Have you had any thoughts on what your ideal API would look like for this task?", "@mrry Very glad you are thinking about this!\r\n\r\nThe signature could be `to_records(self, features, filepath, ...)` where:\r\n\r\n1. It follows the same API of `tf.parse_example` so you can reuse the same concepts/structures. \r\n2. Should only work on dict-based datasets so you can match the structure in the `features` dict to the structure on the dataset dict when creating the `tf.Example`. People who use the tuple-based datasets can just `map` to a dict beforehand.\r\n3. Create an `tf.ImageFeature` class that indicates you want to convert the ndarray of an image to bytes encoded in a certain format like jpeg or png.\r\n\r\nBtw: I find that tuple-based datasets are harder to maintain when you have many features/columns, the documentation should switch to dict-based approach, or you should even provide a `Row` class like pyspark does so we can access the columns as fields.", "I guess this functionality would simplify a lot and encourage the usage of TFRecord files. Furthermore, the general documentation on creating/writing to TFRecord files is still sparse.\r\n\r\nWas there some progress on this feature request?", "@cgarciae Could you post an example of how you convert a Dataset to TFRecords?", "@mattiasarro here is roughly how I do it right now but not how I would propose:\r\n```python\r\ndef create_example(row):\r\n    # create tf.Example(...)\r\n\r\ndef dataset_generator(ds, sess):\r\n    iterator = ds.make_one_shot_iterator()\r\n    next_row = iterator.get_next()\r\n   \r\n    try:\r\n        while True:\r\n            yield sess.run(next_row)\r\n\r\n    except tf.errors.OutOfRangeError:\r\n        pass\r\n\r\ndef create_records(ds, record_path):\r\n    \r\n    with tf.Session() as sess, tf.python_io.TFRecordWriter(record_path) as writer:\r\n\r\n        generator = dataset_generator(ds, sess)\r\n        \r\n        for row in generator:\r\n\r\n            example = create_example(row)\r\n            writer.write(example.SerializeToString())\r\n```", "@cgarciae thanks for that, I'm using it!\r\n\r\nI suppose one could pass `parse_fn` as an argument:\r\n\r\n```\r\ndef to_tfrecord(ds, parse_fn, record_path):\r\n    with tf.Session() as sess, tf.python_io.TFRecordWriter(record_path) as writer:\r\n        generator = dataset_generator(ds, sess)\r\n        \r\n        for row in generator:\r\n            example = parse_fn(row)\r\n            writer.write(example.SerializeToString())\r\n```", "Nagging Assignee @jsimsa: It has been 179 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "On a related note that the [updated tf.Example tutorial](https://github.com/tensorflow/docs/pull/188) illustrates how to use tf.data for both reading and writing TFRecord files, which is recommended over using `tf.python_io`.", "To add to @cgarciae's reply, this is what my `create_example` looks like\r\n```python\r\ndef _tensor_to_feature(tensor):\r\n  \"\"\"Transforms (non-)scalar tensor to bytestring and \r\n     stores it as BytesList in a Feature.\"\"\"\r\n\r\n  serialized_tensor = tf.serialize_tensor(tensor)\r\n  bytes_string = serialized_tensor.numpy()\r\n  bytes_list = tf.train.BytesList(value=[bytes_string])\r\n\r\n  return tf.train.Feature(bytes_list=bytes_list)\r\n\r\n\r\ndef create_example(row):\r\n  features = {\r\n    'PUT_FEATURE_NAME_HERE': _tensor_to_feature(row['PUT_FEATURE_NAME_HERE']),\r\n    ...\r\n  }\r\n\r\n  return tf.train.Example(features=tf.train.Features(feature=features))\r\n```", "Hi,\r\nWhy this issue closed? I did not see the problem solved, if not could anyone point me to the API?\r\n@jppgks \r\nYour solution is really good, write once use anywhere. It looks like your solution is only worked for eage execution.\r\n\r\nI try hard to bypass creating tf records for cloud TPU, but failed. So looks I must do. I hope I can have a solution work well for different projects when building different models, generally speaking, when I build a model, I will create list of input features(named tuple). It work well for the TF API tf.parse_single_example, I can create the record_spec like below:      \r\n```\r\nfor fea in self._input_features:\r\n     record_spec[fea.name] = tf.FixedLenFeature(fea.shape, fea.dtype). \r\ntf.parse_single_example(tfrecord, record_spec)\r\n```\r\nSo it would be great if TF have an API like tf.data.Dataset.to_tfrecords(record_spec, fpath) and automatically map the tensorflow datatype(like tf.int32, tf.float32) in record_spec to the proper feature type used for tf records. \r\n\r\nFollow jppgks, I can create a function like below.\r\n```\r\ndef ds2tfrecord(ds, filepath):\r\n    with tf.python_io.TFRecordWriter(filepath) as writer:\r\n        feat_dict = ds.make_one_shot_iterator().get_next()\r\n        serialized_dict = {name: tf.serialize_tensor(fea) for name, fea in feat_dict.items()}\r\n        with tf.Session() as sess:\r\n            try:\r\n                while True:\r\n                    features = {}\r\n                    for name, serialized_tensor in serialized_dict.items():\r\n                        bytes_string = sess.run(serialized_tensor)\r\n                        bytes_list = tf.train.BytesList(value=[bytes_string])\r\n                        features[name] = tf.train.Feature(bytes_list=bytes_list)\r\n                    # Create a Features message using tf.train.Example.\r\n                    example_proto = tf.train.Example(features=tf.train.Features(feature=features))\r\n                    example_string = example_proto.SerializeToString()\r\n                    # Write to TFRecord\r\n                    writer.write(example_string)\r\n            except tf.errors.OutOfRangeError:\r\n                pass\r\n```\r\n\r\n\r\n\r\n\r\n", "You can track https://github.com/tensorflow/tensorflow/issues/38483"]}, {"number": 16925, "title": "Using bidirectional_dynamic_rnn with Grid3LSTMCell Gives Outputs with Different Shapes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMicrosoft Windows 8.1\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.4 cpu\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n\r\n### Describe the problem\r\nI'm not sure if that's how using `bidirectional_dynamic_rnn` with Grid3LSTMCell works but it's giving outputs that are of different shapes: the first one has three dimensions and the second one has four dimensions.\r\n\r\n### Source code / logs\r\nHere's the code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import grid_rnn\r\n\r\nclass BidirectionalGridRNNCellTest(tf.test.TestCase):\r\n    def setUp(self):\r\n        self.num_features = 1\r\n        self.time_steps = 1\r\n        self.batch_size = 1\r\n        tf.reset_default_graph()\r\n        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])\r\n        self.cell_fw = grid_rnn.Grid3LSTMCell(num_units=8)\r\n        self.cell_bw = grid_rnn.Grid3LSTMCell(num_units=8)\r\n\r\n    def test_bidirectional_dynamic_grid_rnn(self):\r\n        outputs, output_states = tf.nn.bidirectional_dynamic_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)\r\n        print(outputs)\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.test.main()\r\n```\r\n\r\nAnd here's the output of the print statement:\r\n\r\n`((<tf.Tensor 'bidirectional_rnn/fw/fw/transpose:0' shape=(1, 1, 8) dtype=float32>,), <tf.Tensor 'ReverseV2:0' shape=(1, 1, 1, 8) dtype=float32>)`", "comments": ["Actually, this is also applicable to `Grid1LSTMCell`, and `Grid2LSTMCell`.", "Does it work without XLA?", "What do you mean by XLA?", "I can reproduce this issue. @nealwu can you please take a look or redirect? Thanks.\r\n", "Closing this issue due to staleness. Please test with latest version of TF and reopen this issue if necessary. Thanks!"]}, {"number": 16924, "title": "typeid broken across shared boundary makes a271c36b5ead4686b72d972b193bf1f534a92ffd not work ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom shared object linking to \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: a271c36b5ead4686b72d972b193bf1f534a92ffd\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: 9.0/7.0.5\r\n- **GPU model and memory**: P4000 (8 GB)\r\n- **Exact command to reproduce**: This is a little involved.\r\n\r\n### Describe the problem\r\n\r\n@mrry First of all, thanks for quickly responding to my issue #16682, and for following up with the fixes in a271c36b5ead4686b72d972b193bf1f534a92ffd without my even mentioning the problem to you. Very impressive.\r\n\r\nI know that in that commit, you mention \"A subsequent change will move `tf.contrib.data` kernel implementations to a custom op library.\" When you say custom op library, I assume you mean a  distinct shared object file.\r\n\r\nUnfortunately, unless you use --config=monolithic to build, this will not work because the typeid of DatasetVariantWrapper will be different between libtensorflow_framework.so and the custom op library shared object, because they are loaded with RTLD_LOCAL. --config=monolithic avoids the problem because _python_framework_internal.so is loaded with RTLD_GLOBAL in that case. This will override the custom op library's \"weak\" (I am talking about weak linkage of symbols here) typeid of DatasetVariantWrapper. Otherwise, `variant::get<DatasetVariantWrapper>()` will fail in dataset.cc's GetDatasetFromVariantTensor, because the two typeids that get compared have two separate pointers.\r\n\r\nI first found this problem documented [here](https://svn.boost.org/trac10/ticket/754). [This](https://stackoverflow.com/questions/23383102/dynamic-cast-troubles-over-shared-libraries) stack overflow answer was also helpful.\r\n\r\nI'm not sure what the right solution is to this yet. It seems it may be possible to change from pointer equality for type info to checking the equality of mangled strings with strcmp, based on my reading of libstdc++'s typeinfo header file.\r\n\r\nHappy to answer any questions,s ince this is rather involved.\r\n\r\n### Source code / logs\r\n\r\n```\r\n2018-02-10 13:53:14.169478: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2018-02-10 13:53:14.422106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Found device 0 with properties:\r\nname: Quadro P4000 major: 6 minor: 1 memoryClockRate(GHz): 1.48\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 7.91GiB freeMemory: 6.98GiB\r\n2018-02-10 13:53:14.422134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Adding visible gpu devices: 0\r\n2018-02-10 13:54:11.579203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-02-10 13:54:11.579230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:912]      0\r\n2018-02-10 13:54:11.579254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:925] 0:   N\r\n2018-02-10 13:54:11.579420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1016] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6740 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2018-02-10 13:54:11.619971: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:827 : Invalid argument: Tensor must be a Dataset object.\r\n```", "comments": ["Thanks for reporting this. There is a forthcoming change (submitted internally, but not yet merged into the Git master) that moves the `DatasetOpKernel` implementation for `tf.contrib.data.ignore_errors()` into a shared library. As far as I can tell from the presubmits, that code is working, but it's possible that there's a gap in test coverage for this case. We may have to wait a few days until the code is merged into Git to confirm this.\r\n\r\nIn the meantime, I'm a little confused about why the `typeid` has to cross the shared object boundary at all. As far as I understand, the `DatasetVariantWrapper` class and code that manipulates it should be entirely internal to dataset.cc, and hence libtensorflow_framework.so; and the symbol should neither be visible to nor used in the custom op library. Do you have some example code that exhibits the problem?  ", "Interesting that you apparently got this to work successfully.\r\n\r\nI don't have a small reproducible test case for this right now, unfortunately, so I spotted it in a sizable code base which uses cmake and has a non-trivial dependency, but I'm sure I can make one.\r\n\r\nYour point about `DatasetVariantWrapper` not needing to be in the custom op library is a good one. Thanks for pointing that out. I'll look into this some more.", "I can just confirm that I was able to build the internal version (with the `IgnoreErrorsDatasetOp` moved to a separate .so) as a PIP package and run `tensorflow/contrib/data/python/kernel_tests/map_dataset_op_test.py`, which invokes that op.\r\n\r\nI suspect there is something different in the way the custom op .so is built in our Bazel build, and how it is built in your CMake build. (Are you building TensorFlow using Bazel and then building the external library with CMake?) I'll follow up on this thread with more details when the code is available in the master branch.", "That's good to hear.\n\nI am building tensorflow using Bazel, and the building the external library\nusing CMake. A reasonable thing for me to do is to link against the latest\nnightly build, rather than building from source. (I built from source only\nbecause I was changing the error message to understand the problem better.)\n\nThe appropriate linker flags and so on are acquired via tf.sysconfig.*\nfunctions.\n\nI'll build a small test case myself (in progress right now...) and get back\nto this issue with the results I see.\n\nOn Sat, Feb 10, 2018 at 5:28 PM, Derek Murray <notifications@github.com>\nwrote:\n\n> I can just confirm that I was able to build the internal version (with the\n> IgnoreErrorsDatasetOp moved to a separate .so) as a PIP package and run\n> tensorflow/contrib/data/python/kernel_tests/map_dataset_op_test.py, which\n> invokes that op.\n>\n> I suspect there is something different in the way the custom op .so is\n> built in our Bazel build, and how it is built in your CMake build. (Are you\n> building TensorFlow using Bazel and then building the external library with\n> CMake?) I'll follow up on this thread with more details when the code is\n> available in the master branch.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16924#issuecomment-364710874>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEi_UAB1v3m0CI1Y663pRATV52s17rgSks5tTkItgaJpZM4SBGlS>\n> .\n>\n\n\n\n-- \nDaniel Galvez\nhttp://danielgalvez.me\nhttps://github.com/galv\n", "Okay, this bug is my mistake, it turns out. It appears I was loading an extra stale copy of a shared object, form what I can tell.\r\n\r\nFor those curious, I did make a tiny sample project, which helped me realize the issue was certainly on my side. If anyone ends up on this page looking for a how-to on creating a new dataset op, you can check out this [repo](https://github.com/galv/tensorflow-dataset-op-lib).\r\n\r\nThanks for the help @mrry!", "Thanks for confirming, and for being a trailblazer with this new feature! Please don't hesitate to get in touch if you run into other problems."]}, {"number": 16923, "title": "Add documentation for s3 usage with TensorFlow", "body": "This fix adds a very preliminary documentation for s3 usage with TensorFlow, as an attempt to address the comment https://github.com/tensorflow/tensorflow/pull/11089#issuecomment-364682030.\r\n\r\nIdeally I think it would be good if usage with GCS could be added to the doc page as well.", "comments": ["@jhseu The PR has been updated. Please take a look."]}, {"number": 16922, "title": "Add reduction parameter to mean_pairwise_squared_error loss", "body": "Also increased clarify of the documentation for the function", "comments": ["Could you please let me know where I can add unit tests? Thanks.", "(Fine for API change)", "@ispirmustafa Could you please let me know where I can add unit tests? Thank you.", "You can add tests here: python/kernel_tests/losses_test.py", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'll close this for now, please reopen if you find time to add tests."]}, {"number": 16921, "title": "Improve formatting of shapes in tf.losses documentation", "body": "", "comments": []}, {"number": 16920, "title": "Add S3 plugin to the list of file system plugin in doc (add_filesys.md)", "body": "This fix adds S3 plugin to the list of file system plugin in doc (add_filesys.md).\r\n", "comments": []}, {"number": 16919, "title": "libhdfs3 instead of libhdfs", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see diff below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nCurrent HDFS support in TensorFlow is based on [`libhdfs`](https://wiki.apache.org/hadoop/LibHDFS), a JNI wrapper for the HDFS client implemented in Java. Due to this design choice, users of `libhdfs` (and transitively TensorFlow) \r\n\r\n* need to keep in mind an implicit dependency on the JVM runtime,\r\n* have to do quite a bit of [trickery](https://www.tensorflow.org/deploy/hadoop) to setup the environment expected by `libhdfs`.\r\n\r\n[`libhdfs3`](http://pivotal-data-attic.github.io/attic-c-hdfs-client) is a native implementation of an HDFS client, which could potentially free the users from the two issues mentioned above. The documentation of `libhdfs3` claims that its C API is \"almost the same\" as that of `libhdfs`. I've verified this on the `master` version of TensorFlow and the diff is indeed negligible:\r\n\r\n```diff\r\nindex 5f2b222622..0f168fe0dd 100644\r\n--- a/tensorflow/core/platform/hadoop/hadoop_file_system.h\r\n+++ b/tensorflow/core/platform/hadoop/hadoop_file_system.h\r\n@@ -19,8 +19,8 @@ limitations under the License.\r\n #include \"tensorflow/core/platform/env.h\"\r\n\r\n extern \"C\" {\r\n-struct hdfs_internal;\r\n-typedef hdfs_internal* hdfsFS;\r\n+struct HdfsFileSystemInternalWrapper;\r\n+typedef HdfsFileSystemInternalWrapper* hdfsFS;\r\n }\r\n```\r\n\r\nWhat do you think?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "This is strange, I've added all the necessary fields yet the label is still `awaiting response`.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi @cy89, I can submit a PR making the HDFS backend configurable at compile-time, wdyt?", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@jhseu can you chime in on this?\r\n\r\n@superbobry Please feel free to prepare a PR!", "I'm happy with a configuration option. I considered using libhdfs3 with the initial implementation, but I was uncertain how much development it had left. Feel free to send a PR.", "Nagging Assignees @jhseu, @cy89: It has been 19 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "FYI I'm working on a patch to support libhdfs3. The implementation is complicated by the fact that libhdfs3 is not binary compatible with libhdfs. I will submit a PR once I got a minimal working diff :)", "Nagging Assignees @jhseu, @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Marking this as contributions welcome because @superbobry is working on a PR for it. Thanks!", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "@superbobry Could you please let us know if we can close this issue with this closed [PR](https://github.com/apache/hawq/pull/1376) ? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/16919\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/16919\">No</a>\n"]}, {"number": 16918, "title": "TensorFlow demo keeps stopping for flowers_images on Android TFlite", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:NA\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:1080Ti 11gb\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI am following Tensorflow for poets 2(https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#7) session8(Run the customised app).So far, I have successfully ran the demo by Google for Android, but when I train custom flowers data and try to run the demo again by following session 8 in the tutorial in which I replace output name by final result as follows: private static final String OUTPUT_NAME = \"final_result\";\r\n\r\n### Source code / logs\r\n02/08 20:48:30: Launching tfmobile\r\n$ adb install-multiple -r -t C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_7.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_2.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_6.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_8.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_9.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\dep\\dependencies.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_5.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_4.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_3.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_1.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\intermediates\\split-apk\\debug\\slices\\slice_0.apk C:\\Users\\Ajinkya\\Tensorflow_for_poets\\tensorflow-for-poets-2\\android\\tfmobile\\gradleBuild\\outputs\\apk\\debug\\tfmobile-debug.apk \r\nSplit APKs installed\r\n$ adb shell am start -n \"org.tensorflow.demo/org.tensorflow.demo.ClassifierActivity\" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER\r\nClient not ready yet..Connected to process 32013 on device motorola-moto_g__4_-ZY223WW626\r\nCapturing and displaying logcat messages from application. This behavior can be disabled in the \"Logcat output\" section of the \"Debugger\" settings page.\r\nI/InstantRun: starting instant run server: is main process\r\nD/tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@3c0dd38\r\nD/tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@3c0dd38\r\nD/tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@3c0dd38\r\nI/Adreno: QUALCOMM build                   : 7d18700, I8ee426a9a2\r\n          Build Date                       : 10/07/16\r\n          OpenGL ES Shader Compiler Version: XE031.09.00.03\r\n          Local Branch                     : mybranch22308589\r\n          Remote Branch                    : quic/LA.BR.1.3.6_rb1.6\r\n          Remote Branch                    : NONE\r\n          Reconstruct Branch               : NOTHING\r\nI/OpenGLRenderer: Initialized EGL, version 1.4\r\nD/OpenGLRenderer: Swap behavior 1\r\nI/CameraManagerGlobal: Connecting to camera service\r\nI/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480\r\nI/tensorflow: CameraConnectionFragment: Valid preview sizes: [1280x960, 1280x720, 960x720, 960x540, 864x480, 720x480, 640x480]\r\nI/tensorflow: CameraConnectionFragment: Rejected preview sizes: [768x432, 320x240, 176x144]\r\nI/tensorflow: CameraConnectionFragment: Exact size match found.\r\nI/TensorFlowImageClassifier: Reading labels from: labels.txt\r\nI/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded\r\nE/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\nI/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\nI/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\nD/AndroidRuntime: Shutting down VM\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n                  Process: org.tensorflow.demo, PID: 32013\r\n                  java.lang.RuntimeException: Failed to load model from 'file:///android_asset/graph.pb'\r\n                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:100)\r\n                      at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103)\r\n                      at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:130)\r\n                      at org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(CameraActivity.java:159)\r\n                      at org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:421)\r\n                      at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:428)\r\n                      at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:64)\r\n                      at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:95)\r\n                      at android.view.TextureView.getHardwareLayer(TextureView.java:387)\r\n                      at android.view.TextureView.draw(TextureView.java:325)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16065)\r\n                      at android.view.View.draw(View.java:16849)\r\n                      at android.view.ViewGroup.drawChild(ViewGroup.java:3768)\r\n                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3554)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16060)\r\n                      at android.view.View.draw(View.java:16849)\r\n                      at android.view.ViewGroup.drawChild(ViewGroup.java:3768)\r\n                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3554)\r\n                      at android.view.View.draw(View.java:17086)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16065)\r\n                      at android.view.View.draw(View.java:16849)\r\n                      at android.view.ViewGroup.drawChild(ViewGroup.java:3768)\r\n                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3554)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16060)\r\n                      at android.view.View.draw(View.java:16849)\r\n                      at android.view.ViewGroup.drawChild(ViewGroup.java:3768)\r\n                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3554)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16060)\r\n                      at android.view.View.draw(View.java:16849)\r\n                      at android.view.ViewGroup.drawChild(ViewGroup.java:3768)\r\n                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3554)\r\n                      at android.view.View.draw(View.java:17086)\r\n                      at com.android.internal.policy.DecorView.draw(DecorView.java:751)\r\n                      at android.view.View.updateDisplayListIfDirty(View.java:16065)\r\n                      at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:657)\r\n                      at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:663)\r\n                      at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:771)\r\n                      at android.view.ViewRootImpl.draw(ViewRootImpl.java:2808)\r\n                      at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2616)\r\n                      at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2223)\r\n                      at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1258)\r\n                      at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6348)\r\n                      at android.view.Choreographer$CallbackRecord.run(Choreographer.java:871)\r\n                      at android.view.Choreographer.doCallbacks(Choreographer.java:683)\r\n                      at android.view.Choreographer.doFrame(Choreographer.java:619)\r\n                      at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:857)\r\n                      at android.os.Handler.handleCallback(Handler.java:751)\r\n                      at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                      at android.os.Looper.loop(Looper.java:154)\r\n                      at android.app.ActivityThread.main(ActivityThread.java:6123)\r\n                      at java.lang.reflect.Method.invoke(Native Method)\r\n                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\r\n                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\r\nE/AndroidRuntime: Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]>; NodeDef: MobilenetV1/MobilenetV1/Conv2d_0/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](input, MobilenetV1/Conv2d_0/weights). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392)\r\n                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)\r\n                        ... 52 more\r\nApplication terminated.\r\n\r\nAnd the application is terminated, what should I do to resolve this\r\n", "comments": ["@ajinkya933 do you have any more information aside from the title of the bug? We really can't do much without reproduction instructions, platform information, etc.\r\n\r\nPlease provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "@cy89 Hi, I resolved the error, here's what was happening: the Tensorflow for poets - 2 tutorial has all steps to get flowers_data  running. But if you don't set correct version of Tensorflow to 1.5.0 in the android studio the demo keeps on stopping. The only way to get the flowers_data running is to set dependencies in the build.gradle folder to tensorflow 1.5.0, by default it is set to tensorflow 1.2.0 (you must change the default version to the version you are using).", "Yay! I'm glad you were able to fix it.", "I am facing this issue on custom dataset, I followed the instructions [here](https://hackernoon.com/building-an-insanely-fast-image-classifier-on-android-with-mobilenets-in-tensorflow-dc3e0c4410d4). Although the model is built successfully and the prediction works on my laptop, but when I load it on virtual phone or real phone it crashes complaining 'Tensorflow Demo Keeps Stopping\". \r\n\r\nAlso, if i try to use the model built as in the [article](https://hackernoon.com/building-an-insanely-fast-image-classifier-on-android-with-mobilenets-in-tensorflow-dc3e0c4410d4), I do not have any issue at all. \r\n\r\n Tensorflow version is 1.7.0, MacOS Darwin Kernel Version 17.5.0. \r\n\r\n\r\n\r\n4-25 21:35:55.768 22435-22435/org.tensorflow.demo I/TensorFlowImageClassifier: Read 6 labels, output layer size is 6\r\n04-25 21:35:55.773 22435-22435/org.tensorflow.demo I/tensorflow: ClassifierActivity: Camera orientation relative to screen canvas: 90\r\n04-25 21:35:55.774 22435-22435/org.tensorflow.demo I/tensorflow: ClassifierActivity: Initializing at size 640x480\r\n04-25 21:35:55.776 22435-22435/org.tensorflow.demo E/zygote: No implementation found for void org.tensorflow.demo.env.ImageUtils.convertYUV420SPToARGB8888(byte[], int[], int, int, boolean) (tried Java_org_tensorflow_demo_env_ImageUtils_convertYUV420SPToARGB8888 and Java_org_tensorflow_demo_env_ImageUtils_convertYUV420SPToARGB8888___3B_3IIIZ)\r\n04-25 21:35:55.776 22435-22435/org.tensorflow.demo W/tensorflow: ImageUtils: Native YUV420SP -> RGB implementation not found, falling back to Java implementation\r\n04-25 21:35:56.043 22435-22435/org.tensorflow.demo V/StudioProfiler: StudioProfilers agent attached.\r\n04-25 21:35:56.051 22435-22452/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.demo, PID: 22435\r\n    java.lang.IllegalArgumentException: No Operation named [input] in the Graph\r\n        at org.tensorflow.Session$Runner.operationByName(Session.java:356)\r\n        at org.tensorflow.Session$Runner.feed(Session.java:142)\r\n        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.addFeed(TensorFlowInferenceInterface.java:577)\r\n        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.feed(TensorFlowInferenceInterface.java:318)\r\n        at org.tensorflow.demo.TensorFlowImageClassifier.recognizeImage(TensorFlowImageClassifier.java:145)\r\n        at org.tensorflow.demo.ClassifierActivity$2.run(ClassifierActivity.java:166)\r\n        at android.os.Handler.handleCallback(Handler.java:819)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:164)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n04-25 21:35:56.117 22435-22533/org.tensorflow.demo V/StudioProfiler: Acquiring Application for Events\r\n04-25 21:35:56.368 22435-22435/org.tensorflow.demo V/StudioProfiler: Transformed class: java/net/URL\r\n04-25 21:35:56.369 22435-22435/org.tensorflow.demo W/org.tensorflow.demo: Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it!\r\n04-25 21:35:56.383 22435-22435/org.tensorflow.demo V/StudioProfiler: Memory control stream started.\r\n04-25 21:35:56.596 22435-22435/org.tensorflow.demo D/tensorflow: CameraActivity: onPause org.tensorflow.demo.ClassifierActivity@159ac24\r\n04-25 21:35:56.887 22435-22540/org.tensorflow.demo V/StudioProfiler: Live memory tracking disabled.\r\n04-25 21:35:56.895 22435-22540/org.tensorflow.demo V/StudioProfiler: Live memory tracking enabled.\r\n    JNIEnv not attached\r\n04-25 21:35:57.267 22435-22540/org.tensorflow.demo V/StudioProfiler: Loaded classes: 5299\r\n04-25 21:35:57.420 22435-22540/org.tensorflow.demo V/StudioProfiler: Tracking initialization took: 524632000ns\r\n", "How can I change the default version of TensorFlow on android to the version I am using?", "@fernandofks you can find this option in \"build.gradle\" its default value is 1.2.0. Change this value to the system version of tensorflow that you have installed (you can check this system version by ) typing \r\n\r\n```\r\npython -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 2\r\npython3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3\r\n```\r\non your terminal"]}, {"number": 16917, "title": "ValueError: No attr named '_XlaCompile' in name: \"while/attention/cond/fw/CudnnRNN/Enter\" and AttributeError: 'NoneType' object has no attribute 'back_prop'", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: 1.4.1\r\n- **Python version**: 3.5.2\r\n- **Bazel version:** Not compiled from source\r\n- **GCC/Compiler version**: Not compiled from source\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GeForce GTX 1080 (8GB x 4)\r\n- **Exact command to reproduce**: N/A\r\n\r\nI have a similar issue faced in [this thread](https://github.com/tensorflow/tensorflow/issues/12420) since I've started using tf.while_loop and the error is causing on `grads = self.opt.compute_gradients(self.loss)`\r\n\r\nI'm initializing a class for gru layers outside the `tf.while_loop` since I can't initialize variables within the `tf.while_loop` without using `tf.get_variable` and then use the `__call__` of the class variable multiple times to use it within the `tf.while_loop` fn body. The sample codes are provided as per below:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/search/snetP/snet/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\",\r\n line 348, in _MaybeCompile\r\n    xla_compile = op.get_attr(\"_XlaCompile\")\r\n  File \"/home/search/snetP/snet/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line\r\n 2003, in get_attr\r\n    raise ValueError(\"No attr named '\" + name + \"' in \" + str(self._node_def))\r\nValueError: No attr named '_XlaCompile' in name: \"while/attention/cond/fw/CudnnRNN/Enter\"\r\nop: \"Enter\"\r\ninput: \"Variable_14/read\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"frame_name\"\r\n  value {\r\n    s: \"while/while_context\"\r\n  }\r\n}\r\nattr {\r\n  key: \"is_constant\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\nattr {\r\n  key: \"parallel_iterations\"\r\n  value {\r\n    i: 10\r\n  }\r\n}\r\n\r\n# also, error in the same line while handling the above error:\r\n\r\nAttributeError: 'NoneType' object has no attribute 'back_prop'\r\n```\r\n\r\nThe Cudnn_gru custom class:\r\n```\r\nclass cudnn_gru:\r\n\tdef __init__(self, num_layers, num_units, batch_size, input_size, keep_prob=1.0, is_train=None, scope=None):\r\n\t\tself.num_layers = num_layers\r\n\t\tself.grus = []\r\n\t\tself.params = []\r\n\t\tself.inits = []\r\n\t\tself.dropout_mask = []\r\n\t\tfor layer in range(num_layers):\r\n\t\t\tinput_size_ = input_size if layer == 0 else 2 * num_units\r\n\t\t\tgru_fw = tf.contrib.cudnn_rnn.CudnnGRU(\r\n\t\t\t\tnum_layers=1, num_units=num_units, input_size=input_size_)\r\n\t\t\tgru_bw = tf.contrib.cudnn_rnn.CudnnGRU(\r\n\t\t\t\tnum_layers=1, num_units=num_units, input_size=input_size_)\r\n>>>>>>>>>>>Error over the following 4 lines for initializing within the while_loop\r\n\t\t\tparam_fw = tf.Variable(tf.random_uniform(\r\n\t\t\t\t[gru_fw.params_size()], -0.1, 0.1), validate_shape=False)\r\n\t\t\tparam_bw = tf.Variable(tf.random_uniform(\r\n\t\t\t\t[gru_bw.params_size()], -0.1, 0.1), validate_shape=False)\r\n\t\t\tinit_fw = tf.Variable(tf.zeros([1, batch_size, num_units]))\r\n\t\t\tinit_bw = tf.Variable(tf.zeros([1, batch_size, num_units]))\r\n\t\t\tmask_fw = dropout(tf.ones([1, batch_size, input_size_], dtype=tf.float32),\r\n\t\t\t\t\t\t\t  keep_prob=keep_prob, is_train=is_train, mode=None)\r\n\t\t\tmask_bw = dropout(tf.ones([1, batch_size, input_size_], dtype=tf.float32),\r\n\t\t\t\t\t\t\t  keep_prob=keep_prob, is_train=is_train, mode=None)\r\n\t\t\tself.grus.append((gru_fw, gru_bw, ))\r\n\t\t\tself.params.append((param_fw, param_bw, ))\r\n\t\t\tself.inits.append((init_fw, init_bw, ))\r\n\t\t\tself.dropout_mask.append((mask_fw, mask_bw, ))\r\n\r\n\tdef __call__(self, inputs, seq_len, keep_prob=1.0, is_train=None, concat_layers=True):\r\n\t\toutputs = [tf.transpose(inputs, [1, 0, 2])]\r\n\t\tfor layer in range(self.num_layers):\r\n\t\t\tgru_fw, gru_bw = self.grus[layer]\r\n\t\t\tparam_fw, param_bw = self.params[layer]\r\n\t\t\tinit_fw, init_bw = self.inits[layer]\r\n\t\t\tmask_fw, mask_bw = self.dropout_mask[layer]\r\n\t\t\twith tf.variable_scope(\"fw\"):\r\n\t\t\t\tout_fw, _ = gru_fw(outputs[-1] * mask_fw, init_fw, param_fw)\r\n\t\t\twith tf.variable_scope(\"bw\"):\r\n\t\t\t\tinputs_bw = tf.reverse_sequence(\r\n\t\t\t\t\toutputs[-1] * mask_bw, seq_lengths=seq_len, seq_dim=0, batch_dim=1)\r\n\t\t\t\tout_bw, _ = gru_bw(inputs_bw, init_bw, param_bw)\r\n\t\t\t\tout_bw = tf.reverse_sequence(\r\n\t\t\t\t\tout_bw, seq_lengths=seq_len, seq_dim=0, batch_dim=1)\r\n\t\t\toutputs.append(tf.concat([out_fw, out_bw], axis=2))\r\n\t\tif concat_layers:\r\n\t\t\tres = tf.concat(outputs[1:], axis=2)\r\n\t\telse:\r\n\t\t\tres = outputs[-1]\r\n\t\tres = tf.transpose(res, [1, 0, 2])\r\n\t\treturn res\r\n```\r\nand the model:\r\n```\r\nclass Model(object):\r\n        def __init__(...):\r\n            ....\r\n            ....\r\n            self.ready()\r\n            if trainable:\r\n\t\t\tself.lr = tf.get_variable(\r\n\t\t\t\"lr\", shape=[], dtype=tf.float32, trainable=False)\r\n\t\t\tself.opt = tf.train.AdadeltaOptimizer(\r\n\t\t\t\tlearning_rate=self.lr, epsilon=1e-6)\r\n>>>>>>>>>>>Compile time ERROR over this line:\r\n                \tgrads = self.opt.compute_gradients(self.loss)\r\n\t\t\tgradients, variables = zip(*grads)\r\n\t\t\tcapped_grads, _ = tf.clip_by_global_norm(gradients, config.grad_clip)\r\n\t\t\tself.train_op = self.opt.apply_gradients(zip(capped_grads, variables), global_step=self.global_step)\r\n\r\n\tdef get_vP(self,i):\r\n\t\t....\r\n\t        ....\r\n\t\twith tf.variable_scope(\"encoding\"):\r\n>>>>>>>>>>> def f1():\r\n                # used to initialize the cudnn_gru class over here,\r\n                # but shifted outside the tf.while_loop\r\n                # due to initializing errors in tf.Variable in cudnn_gru __init__\r\n                return self.rnn1(c_emb, seq_len=self.c_len)\r\n            def f2():\r\n                return self.rnn1(c_emb, seq_len=self.c_len)\r\n            c = tf.cond(tf.equal(i, zero), f1, f2)\r\n            q = self.rnn1(q_emb, seq_len=self.q_len)\r\n            self.q_enc = q\r\n        with tf.variable_scope(\"attention\"):\r\n                qc_att = dot_attention(c, q, mask=self.q_mask, hidden=d,\r\n                    keep_prob=config.keep_prob, is_train=self.is_train,\r\n\t\tname_scope=\"attention_layer\")\r\n>>>>>>>>>>> def f3():\r\n                # same situation as f1()\r\n                return self.rnn2(qc_att, seq_len=self.c_len)\r\n            def f4():\r\n\t\t\t\treturn self.rnn2(qc_att, seq_len=self.c_len)\r\n            att = tf.cond(tf.equal(self.i, zero), f3, f4)\r\n            def f5():\r\n                return att\r\n            def f6():\r\n                return tf.concat([att, att], axis=1)\r\n            self.att_vP = tf.cond(tf.equal(i, zero), f5, f6)\r\n\r\n            return tf.add(i,tf.constant(1, dtype=tf.int64))\r\n\t\r\n\tdef condition(self,i):\r\n\t\treturn tf.less(i, self.para_count[0])\r\n\t\r\n\tdef ready(self):\r\n\t\tconfig = self.config\r\n\t\tN, PL, QL, CL, d, dc, dg = config.batch_size, self.c_maxlen, self.q_maxlen, \\\r\n\t\t\tconfig.char_limit, config.hidden, config.char_dim, config.char_hidden\r\n\t\tgru = cudnn_gru if config.use_cudnn else native_gru\r\n\r\n\t\tself.cell_fw = tf.contrib.rnn.GRUCell(dg)\r\n\t\tself.cell_bw = tf.contrib.rnn.GRUCell(dg)\r\n\r\n>>>>>>>># initializing here instead of within tf.while_loop body\r\n\t\tself.rnn1 = gru(num_layers=3, num_units=150, batch_size=N, input_size=500,\\\r\n\t\t\tkeep_prob=config.keep_prob, is_train=self.is_train)\r\n\t\tself.rnn2 = gru(num_layers=1, num_units=d, batch_size=N, input_size=1800,\\\r\n\t\t\tkeep_prob=config.keep_prob, is_train=self.is_train)\r\n\t\t\r\n\t\tresult = tf.while_loop(self.condition, self.get_vP, loop_vars=[self.i])\r\n\r\n                ....\r\n                ....", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce", "Done.", "Still an issue when XLA is off?", "its solved, turns out the while loop wasn't configured properly for backpropagation purposes"]}, {"number": 16916, "title": "Fix the profiler python docstring link", "body": "This fix fixes the python docstring link of the profiler:\r\n`profilerg3doc` -> `profiler/g3doc`\r\n", "comments": []}, {"number": 16915, "title": "Update version string to 1.6.0-rc1", "body": "", "comments": ["tensorflow/contrib/data/python/kernel_tests/interleave_dataset_op_test.py might be flaky on Windows."]}, {"number": 16914, "title": "Bazel can't find cudnn.h, ignores cudnn directory specified in configuration", "body": "\r\n[cuda-inst.txt](https://github.com/tensorflow/tensorflow/files/1713644/cuda-inst.txt)\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27 x64\r\n- **TensorFlow installed from (source or binary)**: Source/Release\r\n- **TensorFlow version (use command below)**: 1.6.0-rc0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 1.10\r\n- **GCC/Compiler version (if compiling from source)**: 6.4.0\r\n- **CUDA/cuDNN version**: CUDA 9.1, cudNN 7.0.5\r\n- **GPU model and memory**: GTX 1060\r\n- **Exact command to reproduce**:\r\n\r\n`bazel build --config=opt --config=cuda  --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nRelevant cudnn files are located at:\r\n```\r\n/usr/include/cuda/cudnn.h\r\n/usr/lib64/libcudnn.so\r\n/usr/lib64/libcudnn.so.7\r\n/usr/lib64/libcudnn.so.7.0.5\r\n```\r\nand should be included:\r\n`export LD_LIBRARY_PATH=\"/usr/include/cuda/cupti:/usr/include/cuda:/usr/lib64\"`\r\n\r\n### Describe the problem\r\n```\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\r\n\t\t_get_cuda_config(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\r\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\r\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\r\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\r\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: Cannot find cudnn.h under /lib64\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 1063\r\n\t\t_create_local_cuda_repository(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 917, in _create_local_cuda_repository\r\n\t\t_get_cuda_config(repository_ctx)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 672, in _get_cuda_config\r\n\t\t_cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 397, in _cudnn_version\r\n\t\t_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 646, in _find_cudnn_header_dir\r\n\t\tauto_configure_fail((\"Cannot find cudnn.h under %s\" ...))\r\n\tFile \"/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl\", line 152, in auto_configure_fail\r\n\t\tfail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: Cannot find cudnn.h under /lib64\r\nINFO: Elapsed time: 0.060s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n```\r\nI have tried specifying `/usr`, `/usr/include` and `/usr/include/cuda` as cudnn-path when running `./configure`. The configurator detects `cudnn.h` and does not complain.\r\nIf I specify `/usr`, bazel complains it can't find cudnn.h under `/usr`.\r\nIf I specify anything else, bazel seems intent to look under `lib64` for whatever reason and does not find it. I did bazel clean between reconfigurations. Have also tried bazel with `--action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"`\r\n\r\nHave attached full install paths for cuda, cudnn, cupti (rpm -ql):\r\n[cuda-inst.txt](https://github.com/tensorflow/tensorflow/files/1713645/cuda-inst.txt)\r\n\r\nConfiguration log:\r\n```\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 0.10.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/lib/python3.6/site-packages\r\n  /usr/lib64/python3.6/site-packages\r\n  /usr/local/lib/python3.6/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.6/site-packages]\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y\r\njemalloc as malloc support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n\r\nNo Amazon S3 File System support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with GDR support? [y/N]: n\r\nNo GDR support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\r\nNo VERBS support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1\r\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr]:/usr/include/cuda\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.1\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/cuda-gcc\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=tensorrt    \t# Build with TensorRT support.\r\nConfiguration finished\r\n```", "comments": ["https://github.com/tensorflow/tensorflow/pull/16319 in conjunction with https://github.com/tensorflow/tensorflow/issues/16165 solved my issue. "]}, {"number": 16913, "title": "Eager: tf.linalg.inv(tf.transpose(mat)) has undefined shape in function with tfe.defun", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.6.0dev20180126(GPU)\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Source code / logs\r\n* No problem in graph mode\r\n```Python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()\r\n@tfe.defun\r\ndef test(rect):\r\n    rect_T = tf.transpose(rect)\r\n    print(rect_T.shape)\r\n    print(tf.linalg.inv(rect_T).shape)\r\n    print(tf.linalg.inv(rect).shape)\r\n    print(tf.linalg.inv(tf.transpose(rect)).shape)\r\nrect_tf = tf.constant(np.random.uniform(size=[4, 4]))\r\ntest(rect_tf)\r\n```\r\nOutput:\r\n```\r\n(4, 4)\r\n(?, ?)\r\n(4, 4)\r\n(?, ?)\r\n```", "comments": ["Thanks for the report. This is indeed a bug, will send out a fix.\r\n"]}, {"number": 16912, "title": "Fix Intel compiler build break", "body": "Fix Intel compiler build break\r\n\r\nWindows 10 1709\r\n\r\nMicrosoft Visual Studio 2017 15.4.0\r\n\r\nIntel Parallel Studio XE Cluster Edition for Windows 2018 Update 1\r\n", "comments": []}, {"number": 16911, "title": "VS2017 / Windows build error tfcompile: no user-defined conversion for 'xla::HloInstruction::Identical::<lambda_6c9857087f6484280d6d6ec01ce267b9>", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64bit\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: afc30a0dc00e13d5f0ed522e98ba7074f21d2813\r\n- **Python version**: Python 3.6.2 :: Anaconda, Inc.\r\n- **Bazel version (if compiling from source)**: 0.10\r\n- **GCC/Compiler version (if compiling from source)**: Microsoft (R) C/C++ Optimizing Compiler Version 19.12.25835 for x64\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: `bazel build --config=opt //tensorflow/compiler/aot:tfcompile`\r\n\r\n### Describe the problem\r\nAfter applying #16904 to fix #16882 compilation continues until it fails with:\r\n```bash\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(579): error C2446: ':': no conversion from 'xla::HloInstruction::Identical::<lambda_6c9857087f6484280d6d6ec01ce267b9>' to 'xla::HloInstruction::Identical::<lambda_687e181a7b8d05356bae3b6704b3fe49>'\r\n```\r\n\r\n### Source code / logs\r\nFull error log\r\n```bash\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(579): error C2446: ':': no conversion from 'xla::HloInstruction::Identical::<lambda_6c9857087f6484280d6d6ec01ce267b9>' to 'xla::HloInstruction::Identical::<lambda_687e181a7b8d05356bae3b6704b3fe49>'\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(579): note: No user-defined-conversion operator available that can perform this conversion, or the operator cannot be called\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(580): error C3536: 'eq_shapes': cannot be used before it is initialized\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(580): error C2064: term does not evaluate to a function taking 2 arguments\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(595): error C2664: 'bool xla::HloInstruction::IdenticalSlowPath(const xla::HloInstruction &,const std::function<bool (const xla::HloComputation *,const xla::HloComputation *)> &,const std::function<bool (const xla::Shape &,const xla::Shape &)> &) const': cannot convert argument 3 from 'int' to 'const std::function<bool (const xla::Shape &,const xla::Shape &)> &'\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(595): note: Reason: cannot convert from 'int' to 'const std::function<bool (const xla::Shape &,const xla::Shape &)>'\r\n.\\tensorflow/compiler/xla/service/hlo_instruction.h(595): note: No constructor could take the source type, or constructor overload resolution was ambiguous\r\nTarget //tensorflow/compiler/aot:tfcompile failed to build\r\n```\r\n\r\nSee [attached file](https://github.com/tensorflow/tensorflow/files/1713411/build.log) for the complete build log.\r\n", "comments": ["#16928 is merged, closing."]}, {"number": 16910, "title": "Saver is saving empty .meta and .data files", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu\r\n- **TensorFlow installed from (source or binary)**: I don't know , it's on google colaboratory\r\n- **TensorFlow version (use command below)**:1.4.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: i don't know, it's on google colaboratory\r\n- **GPU model and memory**: Tesla K40 12 gb\r\n- **Exact command to reproduce**: summarize_K40.py\r\nI'm saving my model using:\r\n```\r\nsaver = tf.train.Saver()\r\nsaver.save(sess,checkpoint + str(round(update_loss / update_check, 3)) + '_e' +str(epoch_i),global_step=epoch_i)\r\n```\r\nbut tensorflow creates all the files, but they are always empty i.e. 0 bytes\r\nI'm attaching the source code, but I don't think it's my fault since once every 200 runs it actually creates non-empty files. I'm using google colaboratory\r\n[summarize_K40 (copy).py.txt](https://github.com/tensorflow/tensorflow/files/1713321/summarize_K40.copy.py.txt)\r\n", "comments": []}, {"number": 16909, "title": "Add doc on the order of eigenvalues returned by tf.self_adjoint_eig", "body": "Resolves #16747 \r\nAs discussed in #16747, I think we can add doc on the order of eigenvalues returned by tf.self_adjoint_eig. But further discussion may be required. Any opinions will be appreciated.\r\n\r\nEigen doc says:\r\n> The eigenvalues are repeated according to their algebraic multiplicity, so there are as many eigenvalues as rows in the matrix. The eigenvalues are sorted in increasing order.\r\n> https://eigen.tuxfamily.org/dox/classEigen_1_1SelfAdjointEigenSolver.html#a3df8721abcc71132f7f02bf9dfe78e41\r\n\r\nAnd CUDA doc says:\r\n> a real array of dimension n. The eigenvalue values of A, in ascending order ie, sorted so that W(i) <= W(i+1).\r\n> http://docs.nvidia.com/cuda/cusolver/#cuds-lt-t-gt-syevd\r\n\r\nThe key point is whether we should add this order constraint to TensorFlow itself. Will tf.self_adjoint_eig move to other implementation that does not guarantee ascending order one day?", "comments": ["Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 16908, "title": "Fix typo", "body": "", "comments": []}, {"number": 16907, "title": "Multi-GPU could not provide performance improve with dataset API", "body": "I just wrote a small piece of code in tensorflow to test its multi-gpu performance, with dataset API.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\nimport os\r\n\r\n#dataset with 1000 vectors\r\ndataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([1000,4], maxval=4, dtype=tf.int32))\r\n          \r\nprint(dataset.output_types)\r\nprint(dataset.output_shapes)\r\n\r\niterator = dataset.make_initializable_iterator()\r\n#next_element = iterator.get_next()\r\n\r\ntensor_results = []\r\n\r\n\r\nfor i in range(500):\r\n    for j in range(2):\r\n        with tf.device(\"/gpu:%d\" % j):\r\n            with tf.name_scope(\"Tower_%d\" % j) as scope:\r\n                operand = iterator.get_next()\r\n                tensor_result = tf.matmul(tf.reshape(operand,shape=[1,4]), tf.reshape(operand,shape=[4,1]))\r\n                tensor_results.append(tensor_result)\r\n\r\n\r\ntfconfig = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\ntfconfig.gpu_options.allow_growth=True\r\n\r\nsess = tf.Session(config=tfconfig)\r\n\r\nsess.run(iterator.initializer)\r\nt0 = time.time()\r\n\r\nresults = sess.run(tensor_results)\r\n\r\nt1 = time.time()\r\n\r\nelapsed_time = t1 - t0\r\nprint(elapsed_time)\r\nresults\r\n```\r\nI have 2 GPUs and this program takes 0.68 seconds to finish.\r\nWhen I change to a single GPU execution mode:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\nimport os\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([1000,4], maxval=4, dtype=tf.int32))\r\n          \r\nprint(dataset.output_types)\r\nprint(dataset.output_shapes)\r\n\r\niterator = dataset.make_initializable_iterator()\r\n#next_element = iterator.get_next()\r\n\r\ntensor_results = []\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n    for i in range(1000):\r\n        operand = iterator.get_next()\r\n        tensor_result = tf.matmul(tf.reshape(operand,shape=[1,4]), tf.reshape(operand,shape=[4,1]))\r\n        tensor_results.append(tensor_result)\r\n\r\n\r\ntfconfig = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\ntfconfig.gpu_options.allow_growth=True\r\n\r\nsess = tf.Session(config=tfconfig)\r\n\r\nsess.run(iterator.initializer)\r\nt0 = time.time()\r\n\r\nresults = sess.run(tensor_results)\r\n\r\nt1 = time.time()\r\n\r\nelapsed_time = t1 - t0\r\nprint(elapsed_time)\r\nresults\r\n```\r\n\r\nIt takes the same time to finish (actually single GPU is even faster perhaps due to overhead reasons). Do anyone know where does the problem come from?\r\n\r\npython version: Python 2.7.12\r\ntensorflow version: 1.4.0\r\nCUDA version: 8.0\r\nUbuntu version: Ubuntu 16.04 LTS\r\n\r\nThanks!\r\n", "comments": ["@mrry \r\nexpert of distributed tensorflow", "You may check installed model of the tensorflow", "@huangwei2013 Hi thanks for the reply! Do you mean the Cifar10 multi_gpu_train one? That's a queue based approach. I would like to try the dataset here", "It could be interesting to understand also if the dataset api is ready to work on the shelf with `tf.keras.utils.multi_gpu_model` or we still have the same problem [already described on keras](https://medium.com/rossum/towards-efficient-multi-gpu-training-in-keras-with-tensorflow-8a0091074fb2).", "/cc @fchollet", "A few comments:\r\n1) [Shard your dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard)\r\n2) Move the _i_ loop to around a sess.run;\r\n             Here you are expanding your graph to a huge size, probably resulting in some minor contention (applies to both single and multi gpu).", "There was also some recent update in models using dataset api but not strictly related to the multi gpu keras interface. See https://github.com/tensorflow/models/pull/3332.", "@joeyearsley raises a good point about the loop structure here, which isn't representative of a real training job. In particular, it builds a huge graph that performs every iteration using a different `tf.matmul()` node, whereas it is more common to build a graph that works on a single mini-batch and then calls `sess.run()` multiple times in a loop. The `tf.matmul()` operations multiply two four-element vectors, which is a computation that is too small to benefit from GPU acceleration: the cost to copy the operands to the GPU would be much larger than the time to multiply them... which could potentially be achieved with a couple of SSE instructions. Finally, the code only measures the first time to execute the graph, which I expect will be dominated by the costs of building the large graph in both cases, and not substantially different based on how many GPUs you are using.\r\n\r\nI'd recommend that you take a look at the [`tf_cnn_benchmarks.py`](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py) code for an example of how to write a well-optimized multi-GPU trainer using `tf.data`. In addition, @karmel has just augmented the official MNIST example with support for [multi-GPU processing](https://github.com/tensorflow/models/blob/fd7b6887fb294e90356d5664724083d1f61671ef/official/mnist/mnist.py#L158), and that example shows some of the easier-to-use library support that has been added for multi-GPU processing. We're continuing to develop this to improve performance and usability together.", "@mrry Is `tf.keras.utils.multi_gpu_model` working with estimators and dataset api?", "@bhack I'm not sure: I haven't tried it. If not, we'd appreciate a feature request for that in a new issue!", "@mrry Probably not cause I've got a segmentation fault with the exactly the same working code just adding `tf.keras.utils.multi_gpu_mode`", "I don't know how model to estimator converter is in shape. See https://github.com/tensorflow/tensorflow/issues/16468", "Seems also that the distributed version was not working with the converter. See https://github.com/tensorflow/tensorflow/issues/14504.\r\n"]}, {"number": 16906, "title": "python 3.6 + latest tf = infinity of \"msgpack_numpy.py:142 PendingDeprecationWarning: encoding is deprecated.\" ", "body": "Symptom, trying to train resnet-50 imagenet @ppwwyyxx 's [imagenet-resnet.py](https://github.com/ppwwyyxx/tensorpack/blob/master/examples/ResNet/imagenet-resnet.py) script fails to start after 5 minutes, because of some thread being blocked trying to flush a gazillion of warning messages above\r\n\r\nSince this problem is solved by downgrading from \"tf-nightly-gpu\" (`1.7.0-dev20180208`) to tensorflow-gpu 1.5, TensorFlow must be blame for introducing a new usage of this deprecated method. Unfortunately the warning messages are quite uninformative, with no indication of who is calling this :/\r\n\r\nNote that Python 3.6 is the only Python 3 version supported on Amazon Deep Learning conda AMI images.\r\n\r\nWarning messages look like this:\r\n\r\n```\r\n/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/msgpack_numpy.py:142: PendingDeprecationWarning: encoding is deprecated.\r\n  use_bin_type=use_bin_type)\r\n/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/msgpack_numpy.py:142: PendingDeprecationWarning: encoding is deprecated.\r\n  use_bin_type=use_bin_type)\r\n/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/msgpack_numpy.py:142: PendingDeprecationWarning: encoding is deprecated.\r\n  use_bin_type=use_bin_type)\r\n\r\n```", "comments": ["Oops actually I think this one is on me. I did make calls to msgpack with use_bin_type. If you have pip installed pyarrow, it will not use msgpack then.\r\nBut not sure why downgrading tensorflow will help you.", "hm, I may have done something else in addition to tensorflow downgrade, will close for now"]}, {"number": 16905, "title": "[Windows] Copy NominalCPUFrequency from Abseil", "body": "Attempt to fix Bazel build on Windows. https://ci.tensorflow.org/job/tf-master-win-bzl/ is all red since https://github.com/tensorflow/tensorflow/commit/09138338ed81b56aeaff88b9ee5a11c3f6d77b70\r\n\r\nCopy from https://github.com/abseil/abseil-cpp/blob/4972c72c5cf2f27e2a0846ce9ff5d377d3f2b7af/absl/base/internal/sysinfo.cc#L74\r\n\r\nDo not ever use anything from `absl::*_internal` as it violates Abseil's compatibility contract.\r\n\r\n/cc @meteorcloudy @benoitsteiner ", "comments": ["@gunan This PR is also needed for fixing the Windows build, PTAL.", "Can we merge this?"]}, {"number": 16904, "title": "[MSVC] Workaround MSVC template/lambda parsing bug", "body": "#16882 #15213", "comments": []}]