[{"number": 115, "title": "Incorrect matrix math in tutorial at:  http://www.tensorflow.org/tutorials/mnist/beginners/index.md", "body": "On the [generally wonderful beginner's documentation](http://www.tensorflow.org/tutorials/mnist/beginners/index.md), there is the following incorrect matrix math ![matrix math](http://api.tensorflow.org/system/image/body/1707/softmax-regression-scalarequation.png)\n\n---\n\nThe x's are incorrect.  Each element should include x{sub}1, x{sub}2, and x{sub}3.  This will be obvious upon looking at the correct vector representation on that same page immediately underneath.  Overall the documentation seems awesome so far!  :smiley: \n", "comments": ["D'oh. I think I was half asleep when I made that. Here's a fixed image:\n\n![softmax-regression-scalarequation](https://cloud.githubusercontent.com/assets/61658/11082384/5f4fb1ca-87d9-11e5-93d6-4130585466b8.png)\n\nThe repo should be fixed shortly.\n", "colah just fixed this in f6d5a2caedd3982a1e6dcaa99bfafe0539527144.  Will take some time to push to the website though. Thanks for the report!\n", "Thanks for the super fast response!  (And all the great work!)\n"]}, {"number": 114, "title": "Matrix multiplication in softmax documentation carried out incorrectly", "body": "In the softmax documentation on page:\n\nhttp://tensorflow.org/tutorials/mnist/beginners/index.md\n\nThere is a set of images showing an example of what the function is doing:\n\n![image](https://cloud.githubusercontent.com/assets/5950006/11081692/e3c5dc3c-87ec-11e5-8e9a-6ed0b0ace7c6.png)\n\nThen the \"xs\" are pulled out so that we have the vectors Wx. But the coefficients in the image above is incorrect. If the image below, also take form the docs, shows the true form then the equations in the above image should be:\n\ny1 = W1,1**x1** + W1,2**x2** + W1,3**x3** + b1\n\ninstead of:\n\ny1 = W1,1**x1** + W1,2**x1** + W1,3**x1** + b1\n\n![image](https://cloud.githubusercontent.com/assets/5950006/11081715/38e3fdb6-87ed-11e5-8621-ac80926f2c03.png)\n", "comments": ["Thanks for the report!  We have a pending fix this, will be updated soon.  De-duping with https://github.com/tensorflow/tensorflow/issues/78\n", "No problem, sorry for reporting a duplicate! I didn't see that one when I searched for the issue.\n"]}, {"number": 113, "title": "AlexNet with FC layers: backward is very slow?", "body": "(I know PRs are not the way to contribute to TensorFlow -- I'm just posting this for discussion, though I'm happy to submit this patch via the official means if desired.)\n\nI modified `alexnet_benchmark.py` to compute activations for the fully-connected layers (fc6-fc8) where the original only computes through `pool5`.  Using a Titan X with the original code that only goes through `pool5`, I see roughly the expected result:\n\n```\n2015-11-10 16:29:54.760793: step 10, duration = 0.098\n2015-11-10 16:29:55.746638: step 20, duration = 0.099\n2015-11-10 16:29:56.734163: step 30, duration = 0.099\n2015-11-10 16:29:57.720769: step 40, duration = 0.098\n2015-11-10 16:29:58.708402: step 50, duration = 0.099\n2015-11-10 16:29:59.697522: step 60, duration = 0.100\n2015-11-10 16:30:00.687530: step 70, duration = 0.099\n2015-11-10 16:30:01.677052: step 80, duration = 0.099\n2015-11-10 16:30:02.669677: step 90, duration = 0.099\n2015-11-10 16:30:03.563315: Forward across 100 steps, 0.098 +/- 0.010 sec / batch\n2015-11-10 16:30:10.385117: step 10, duration = 0.321\n2015-11-10 16:30:13.613230: step 20, duration = 0.322\n2015-11-10 16:30:16.840772: step 30, duration = 0.322\n2015-11-10 16:30:20.068794: step 40, duration = 0.322\n2015-11-10 16:30:23.308556: step 50, duration = 0.326\n2015-11-10 16:30:26.558616: step 60, duration = 0.323\n2015-11-10 16:30:30.260454: step 70, duration = 0.325\n2015-11-10 16:30:33.939707: step 80, duration = 0.324\n2015-11-10 16:30:37.797578: step 90, duration = 0.326\n2015-11-10 16:30:41.159575: Forward-backward across 100 steps, 0.340 +/- 0.052 sec / batch\n```\n\nWith this modified version, I get expected computation speed for the forward-only version (only epsilon longer than the pool5 version), but very slow speeds doing forward-backward (stopped after 60 iterations due to slowness):\n\n```\n2015-11-10 15:54:39.231156: step 10, duration = 0.101\n2015-11-10 15:54:40.235104: step 20, duration = 0.100\n2015-11-10 15:54:41.238807: step 30, duration = 0.100\n2015-11-10 15:54:42.241662: step 40, duration = 0.100\n2015-11-10 15:54:43.245950: step 50, duration = 0.100\n2015-11-10 15:54:44.251555: step 60, duration = 0.100\n2015-11-10 15:54:45.255560: step 70, duration = 0.100\n2015-11-10 15:54:46.260286: step 80, duration = 0.101\n2015-11-10 15:54:47.268687: step 90, duration = 0.101\n2015-11-10 15:54:48.172288: Forward across 100 steps, 0.099 +/- 0.010 sec / batch\n2015-11-10 15:55:30.047371: step 10, duration = 13.337\n2015-11-10 15:58:34.855597: step 20, duration = 11.968\n2015-11-10 16:01:40.070674: step 30, duration = 19.707\n2015-11-10 16:04:30.698742: step 40, duration = 13.459\n2015-11-10 16:07:15.900770: step 50, duration = 20.028\n2015-11-10 16:10:11.997452: step 60, duration = 12.357\n^C^C^CTraceback (most recent call last):\n```\n\nDuring the forward-backward part of the benchmark, looking at GPU utilization using `nvidia-smi` while running this shows 0% utilization most of the time.\n\nFor reference, I ran more or less the equivalent timing on the same GPU using out-of-the-box Caffe (_no_ CuDNN) using [this prototxt](https://gist.github.com/jeffdonahue/9193b3c88e4262128fe8), and see Forward-Backward times of ~413 ms.  (And for the record the comparison is still a little unfair to Caffe as `caffe time`, unlike `caffe train`, computes all gradients, including w.r.t. the input image.)\n\n```\n$ caffe time -model alexnet_dummydata_nolrn.prototxt -gpu 0\n[...]\nI1110 16:37:19.770344  6275 caffe.cpp:366] Average Forward pass: 176.546 ms.\nI1110 16:37:19.770350  6275 caffe.cpp:368] Average Backward pass: 237.147 ms.\nI1110 16:37:19.770356  6275 caffe.cpp:370] Average Forward-Backward: 413.773 ms.\n```\n\nPlease let me know if anyone has any idea what might be going on, or if something is wrong with my implementation (which I wouldn't doubt!).  Thanks!\n", "comments": ["Maybe try other GPUs and other network architectures for ablative analysis?\n", "Hey Jeff - your implementation looks all right. I'll take a look at that tomorrow when I am in office. From the face of it, seems like the automatic device placement put some of the backward ops on the CPU for some reason.\n", "Seems likely that could be the issue.  Yangqing asked offline if I might have had busy CPUs at the time -- rerunning this again on the same machine now, with only a couple of processes with high CPU util. running (might have been building Caffe with `make -j` during the run I quoted originally...), I get much better forward-backward times (but still ~3x longer than Caffe's):\n\n```\n2015-11-10 22:11:35.540247: step 10, duration = 0.100\n2015-11-10 22:11:36.542970: step 20, duration = 0.101\n2015-11-10 22:11:37.546989: step 30, duration = 0.101\n2015-11-10 22:11:38.553355: step 40, duration = 0.101\n2015-11-10 22:11:39.560323: step 50, duration = 0.101\n2015-11-10 22:11:40.568854: step 60, duration = 0.101\n2015-11-10 22:11:41.575478: step 70, duration = 0.101\n2015-11-10 22:11:42.582592: step 80, duration = 0.100\n2015-11-10 22:11:43.587321: step 90, duration = 0.101\n2015-11-10 22:11:44.493066: Forward across 100 steps, 0.100 +/- 0.010 sec / batch\n2015-11-10 22:12:33.809496: step 10, duration = 1.616\n2015-11-10 22:12:47.661195: step 20, duration = 1.347\n2015-11-10 22:13:01.331951: step 30, duration = 1.385\n2015-11-10 22:13:15.189127: step 40, duration = 1.341\n2015-11-10 22:13:29.213192: step 50, duration = 1.633\n2015-11-10 22:13:42.824959: step 60, duration = 1.342\n2015-11-10 22:13:56.128193: step 70, duration = 1.317\n2015-11-10 22:14:09.408324: step 80, duration = 1.321\n2015-11-10 22:14:22.658480: step 90, duration = 1.321\n2015-11-10 22:14:37.811581: Forward-backward across 100 steps, 1.420 +/- 0.408 sec / batch\n```\n", "That means the open source implementation is different from the internal version.\n", "Hi Jeff - it turns out that there is an implicit memcpy going on when the session is run. Basically, when session.run(target) is called, we also fetch all the targets into numpy arrays (which is a feature that is not very well documented...). Since the gradients are on GPU and the numpy arrays are going to be on CPU, a memcpy is triggered that causes a nontrivial amount time.\n\nThe reason we started to see this performance hit after adding FC layers is - as one may expect - because FC layers. I've added a proposed change to the code for experimentation on your side.\n\nI'll let the guys know and add these notes to the documentation. Thanks for digging into this!\n", "Thanks for looking into this and posting the fix @Yangqing! The performance (see below) is now similar to what @soumith reported at https://github.com/soumith/convnet-benchmarks/issues/66.  I'm a bit confused as to why he didn't have to use the group trick in [his implementation](https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py) to get these speeds -- when I run his script I get the previous slow speeds.  But the issue I raised here is resolved and I guess is not technically a bug so I'll close it.  Thanks again @Yangqing, and to the whole TensorFlow team for open-sourcing this.\n\n```\n2015-11-11 12:48:04.346213: step 10, duration = 0.326\n2015-11-11 12:48:07.607321: step 20, duration = 0.326\n2015-11-11 12:48:10.873735: step 30, duration = 0.326\n2015-11-11 12:48:14.139584: step 40, duration = 0.327\n2015-11-11 12:48:17.405379: step 50, duration = 0.328\n2015-11-11 12:48:20.676191: step 60, duration = 0.326\n2015-11-11 12:48:23.941887: step 70, duration = 0.326\n2015-11-11 12:48:27.229217: step 80, duration = 0.329\n2015-11-11 12:48:30.514869: step 90, duration = 0.329\n2015-11-11 12:48:33.473680: Forward-backward across 100 steps, 0.324 +/- 0.033 sec / batch\n```\n", "Yeah, I was surprised too, although with a follow-up discussion it seems that the control flow was needed there as well. Sent a fix to Soumith for that earlier today.\n\nThanks Jeff for initiating the investigation! I really appreciate it.\n"]}, {"number": 112, "title": "EC2 g2.2xlarge: Ignoring gpu device (GRID K520) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.", "body": "I got this error while running on an Amazon EC2 g2.2xlarge instance:\n\n```\ntensorflow/core/common_runtime/gpu/gpu_device.cc:611\n Ignoring gpu device (device: 0, name: GRID K520, pci bus id: 0000:00:03.0) \nwith Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\nInvalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0'\n [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device=\"/gpu:0\"]()]])\n```\n", "comments": ["De-duping with https://github.com/tensorflow/tensorflow/issues/25\n"]}, {"number": 111, "title": "configure script hardcodes location of cuda that makes it fail on OSX", "body": "Cuda installation on OSX is at $CUDA_TOOLKIT_PATH/lib (not lib64), and on OSX the shared libraries are end in .dylib (not .so).\n\n```\n  if [ -e \"$CUDA_TOOLKIT_PATH/lib64/libcudart.so.7.0\" ]; then\n    break\n  fi\n  echo \"Invalid path to CUDA 7.0 toolkit. ${CUDA_TOOLKIT_PATH}/lib64/libcudart.so.7.0 cannot be found\"\n```\n", "comments": ["Hey @delip, we currently don't have support for GPUs on Mac OS X.\n\nOut of curiosity, what GPU are you trying to get working with TensorFlow?\n", "I'm not OP, but in my case, it would be the D700 and D500 as found on Mac Pro (Late 2013) models (which require OpenCL, of course).\n", "We don't support OpenCL right now. You need a NV GPU with at least compute 3.0 capability.\n", "I understand. I was just replying to @vrv's question about GPUs people are using on OS X.\n", "Hey @vrv, I'm on a Mac Pro (late 2013) like Drew. Also, a lot of my friends\ndevelop on their macbook pros.\n\nOn Wed, Nov 11, 2015 at 1:03 AM, Drew Hess notifications@github.com wrote:\n\n> I understand. I was just replying to @vrv https://github.com/vrv's\n> question about GPUs people are using on OS X.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/111#issuecomment-155678060\n> .\n", "@delip: so do you also have AMD GPUs?\n", "That's correct. I also tried this on the latest iMac 5K which also contains\na AMD GPU (AMD Radeon R9 M290X)\n\nOn Wed, Nov 11, 2015 at 5:24 PM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> @delip https://github.com/delip: so do you also have AMD GPUs?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/111#issuecomment-155928487\n> .\n", "Gotcha, so that would require OpenCL support, which we're tracking here: https://github.com/tensorflow/tensorflow/issues/22.  I'll de-dupe with that feature request.\n"]}, {"number": 110, "title": "Support for Redhat, Centos and many superclusters", "body": "Many clusters system using module with Redhat or Centos < 7 which is **glibc 2.12**\n\nSince, **bazel** requires **glibc 2.14** and the prebuilt version for linux requires **glibc 2.17**. It is hopeless to make tensorflow run on clusters.\n\nReferred to this issue reported on bazel: https://github.com/bazelbuild/bazel/issues/583\n", "comments": ["Since we depend on bazel, this sounds like a bazel issue.\n\nFeel free to re-open if bazel ends up supporting 2.12 or lower, and we can see what we can do.\n", "Am I right that you depend on bazel only at build-time? If this is true then it can be viewed as something you could do something about too... You could also release static-linked packages that would be very useful to people stuck on clusters with old libraries...\n", "So did anyone find some way past this problem? I'm using redhat 6.4, as is my entire corporation. We're stuck on redhat 6.4. I'm not sure how to end up running tensorflow on such a machine...\n", "I managed to have it running on a CentOS 6.7 : http://stackoverflow.com/a/34897674/1990516 :)\nTell me if it works for you.\n\nEdit: I proposed an alternative solution also: http://stackoverflow.com/a/34900471/1990516\n", "Thanks man! I'll look into it as soon as I can. \n\nSent from my IPhone\n\n> On Jan 20, 2016, at 2:41 AM, Th\u00e9o Trouillon notifications@github.com wrote:\n> \n> I managed to have it running on a CentOS 6.7 : http://stackoverflow.com/a/34897674/1990516 :)\n> Tell me if it works for you\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "Could you let me know if this worked? I can't seem to get any of these other solutions working. \n", "Since @ttrouill only says he got it working on 6.7 so I didn't check whether this works on 6.4 actually...\n", "Both solutions seem to work, but they're not optimal. TensorFlow and Python seem to run okay, but if I try and run IPython, then with the first solution I get an Invalid ELF error, and with the second solution there is a memory leak and IPython continues to absorb all memory with time. I believe that this can also happen with other Python imports that rely on libraries that were compiled using the older libc.\n\nI'd love to see a straightforward how-to-compile-bazel-with-old-glibc guide, but I haven't come across one yet.\n", "Also https://github.com/bazelbuild/bazel/issues/760 is relevant, but it's far from straightforward and my attempt to build bazel using this guide failed. Hopefully within the next few weeks I can give it some more time and continue that thread with the errors I end up getting.\n", "Compiling on CentOS still isn't all that straightforward, but I figured I'd give an overview here for now. This works for me with `CentOS 6.7` and `gcc 4.8.2`, with GPU support (Cuda 7.0, cuDNN 4.0.7). A `bazel` modification for building with a custom `gcc` is in the works (https://github.com/bazelbuild/bazel/issues/760) and should help streamline this later on.\n\nThe instructions here are specific to my base `gcc` path of `/cm/shared/apps/gcc/4.8.2`, but it should work for other configurations just by modifying the base path.\n\nPaths for reference:\n`gcc path`: `/cm/shared/apps/gcc/4.8.2/bin/gcc`\n`cpp path`: `/cm/shared/apps/gcc/4.8.2/bin/cpp`\n`lib64 path`: `/cm/shared/apps/gcc/4.8.2/lib64`\n`include1 dir`: `/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include`\n`include2 dir`: `/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include-fixed`\n`include3 dir`: `/cm/shared/apps/gcc/4.8.2/include/c++/4.8.2`\n\n## Bazel\n1. `git clone https://github.com/bazelbuild/bazel.git && cd bazel`\n2. Edit `tools/cpp/CROSSTOOL`\n   - Replace all occurrences of `/usr/bin/gcc` with `gcc path`\n   - Replace all occurrences of `/usr/bin/cpp` with `cpp path`\n   - After the toolpath containing `gcc path`, add the lines\n     - linker_flag: \"-Wl,-R`lib64 path`\"\n     - cxx_builtin_include_directory: \"`include1 dir`\"\n     - cxx_builtin_include_directory: \"`include2 dir`\"\n     - cxx_builtin_include_directory: \"`include3 dir`\"\n3. Edit `scripts/bootstrap/buildenv.sh`\n   - Comment out `atexit \"rm -fr ${DIR}\"`\n4. `export EXTRA_BAZEL_ARGS='-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'`\n5. `./compile.sh`\n\n## TensorFlow\n1. `git clone --recurse-submodules https://github.com/tensorflow/tensorflow && cd tensorflow`\n2. Edit `third_party/gpus/crosstool/CROSSTOOL`, making the same changes we made for Bazel. (`/usr/bin/gcc` etc. likely won't need to be replaced, though.)\n3. Edit `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`\n   - Replace all `/usr/bin/gcc` with `gcc path`.\n   - Undo the temporary \"fix\" to find `as` by commenting out the line `cmd = 'PATH=' + PREFIX_DIR + ' ' + cmd`. (For me, this is necessary to find `as`.)\n4. `./configure`\n5. `export EXTRA_BAZEL_ARGS='-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'`\n6. `bazel build -c opt --config=cuda --linkopt '-lrt' --copt=\"-DGPR_BACKWARDS_COMPATIBILITY_MODE\" --conlyopt=\"-std=c99\" //tensorflow/tools/pip_package:build_pip_package`\n   - Why the strange flags? Because otherwise, after building with the older `libc`, we'll get an error about `secure_getenv`.\n7. `bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg`\n8. `pip install ~/tensorflow_pkg/*`\n", "Update: Previous process was for a commit after release 7.\n\nHere are necessary changes for commit 1d4fd06, which is after release 8:\n1. You need Bazel 0.2.x. As of this writing, with appropriate environment variables, Bazel at HEAD compiles simply with `./compile.sh`. Thank you @damienmg !\n2. You still need to make the above changes to the TensorFlow files, including the changes to `CROSSTOOL` etc. (For some reason the bazel auto config doesn't work here.)\n3. Edit `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`\n   and replace `#!/usr/bin/env python2.7` with\n   `#!/usr/bin/env /full/path/to/python2.7`. This is a hack to avoid bazel's confined environment from failing to pick up our custom Python location.\n4. Edit `bazel-out/host/bin/tensorflow/swig` and add\n   `export LD_LIBRARY_PATH=custom:paths:$LD_LIBRARY_PATH`\n   before `swig` is run. Otherwise `swig` won't find libraries that exist in our `LD_LIBRARY_PATH`. This is another hack to get around the confined environment.\n5. Use the same `bazel build` command from above: `bazel build -c opt --config=cuda --linkopt '-lrt' --copt=\"-DGPR_BACKWARDS_COMPATIBILITY_MODE\" --conlyopt=\"-std=c99\" //tensorflow/tools/pip_package:build_pip_package`\n6. `cd bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles` and `cp -r __main__/* .`. This is a hack associated with https://github.com/tensorflow/tensorflow/issues/2040.\n7. Finally we can `bazel-bin/tensorflow/tools/pip_package/build_pip_package ~/tensorflow_pkg`, and\n8. `pip install ~/tensorflow_pkg/*`\n", "Our administrator managed to run pip installed tensorflow package on RHEL 6.7 server (without building bazel and tensorflow source), the core idea is get separated newer version of GLIBC version:\n- mkdir glibc\n- cd $! \n- wget http://launchpadlibrarian.net/137699828/libc6_2.17-0ubuntu5_amd64.deb\n- wget http://launchpadlibrarian.net/137699829/libc6-dev_2.17-0ubuntu5_amd64.deb\n- ar p libc6_2.17-0ubuntu5_amd64.deb data.tar.gz | tar zx\n- ar p libc6-dev_2.17-0ubuntu5_amd64.deb data.tar.gz | tar zx\n- libcroot=/path/to/glibc/lib/x86_64-linux-gnu\n- **LD_LIBRARY_PATH=$libcroot:$LD_LIBRARY_PATH**  _$libcroot/ld-2.17.so_  **$(which python)**\n\nFast test:\n\n``` python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))\na = tf.constant(10)\nb = tf.constant(32)\nprint(sess.run(a + b))\n```\n\n**Note**: this approach is only for running python scripts, remember that, every time you add $libcroot to your path all the shell commands are corrupted (i.e you cannot use _ls_, _cd_ ...). You might use **bash -l**, or screen, or byobu before you try this so you don't mess up your own session.\n", "Yeah that was described [here](http://stackoverflow.com/questions/33655731/error-while-importing-tensorflow-in-python2-7-in-ubuntu-12-04-glibc-2-17-not-f) a while back, but as you mention, it's not ideal. For example if you run Jupyter it'll lead to a memory leak / crash (at least on the system I tried it with).\n", "@rdipietro \n\n> Edit tools/cpp/CROSSTOOL\n> After the toolpath containing gcc path, add the lines\n> linker_flag: \"-Wl,-Rlib64 path\"\n> cxx_builtin_include_directory: \"include1 dir\"\n> cxx_builtin_include_directory: \"include2 dir\"\n> cxx_builtin_include_directory: \"include3 dir\"\n\nShould these lines be added after every occurence of the toolpath containing gcc path- i.e. twice wherever i changed the usr/bin/gcc ?\n", "I don't know what you mean by twice. I'm pretty sure I only inserted those lines once, although if you were to insert them in multiple places it probably wouldn't do any harm.\n", "@kskp @rdipietro : is that still needed with latest version of Bazel? If yes then we have an issue in the C++ detection code.\n", "Bazel compiles out of the box as long as I set `CC` correctly. I haven't tried with TensorFlow 0.9, but as of 0.8, I still had to make manual changes on CentOS.\n", "You mean change to the cuda crosstool file?\n\nOn Fri, Jun 24, 2016 at 2:30 PM Robert DiPietro notifications@github.com\nwrote:\n\n> Bazel compiles out of the box as long as I set CC correctly. I haven't\n> tried with TensorFlow 0.9, but as of 0.8, I still had to make manual\n> changes on CentOS.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/110#issuecomment-228333271,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ADjHf_Ij539IWtrDlTebMajjTTI87GSBks5qO83SgaJpZM4Gf6Qp\n> .\n", "Yes. My May 17 comment above includes everything I needed to do. Specifically, needed to edit CROSSTOOL and needed to introduce two hacks to get bazel to find things outside of its isolated environment.\n", "@rdipietro Thanks for your reply. Sorry for my ignorance, but could you please tell me what toolpath is? I am assuming it is the block of code where the gcc path had to be changed. I did that twice in the entire file (Since it said to replace all occurences of /usr/bin/gcc). So do I have to add those lines after the block of code where I changed the /usr/bin/gcc path??\n", "@rdipietro @damienmg I am not using the latest version of Bazel. I need the 0.2.2b version. I ultimately have to run Syntaxnet on Cent OS 6.7.\n", "0.2.2b should work too.\n\nOn Fri, Jun 24, 2016 at 2:55 PM kskp notifications@github.com wrote:\n\n> @rdipietro https://github.com/rdipietro @damienmg\n> https://github.com/damienmg I am not using the latest version of Bazel.\n> I need the 0.2.2b version. I ultimately have to run Syntaxnet on Cent OS\n> 6.7.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/110#issuecomment-228337683,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ADjHf4sjm971bfucsyRzcsZk_rgAUo8qks5qO9ObgaJpZM4Gf6Qp\n> .\n", "Oh, I tried a couple of weeks ago but it did not work. Will do it again today. Thanks for your reply.\n", "note that you still have to do the CUDA CROSSTOOL modification for doing it with --config cuda\n", "Oops, I am not configuring it with CUDA support. Is it a must?\n", "You need to update tensorflow's CROSSTOOL for CUDA support. @davidzchen is\nmaking the change to TF to have the same support but it has not yet landed.\n\nOn Fri, Jun 24, 2016 at 3:12 PM kskp notifications@github.com wrote:\n\n> Oops, I am not configuring it with CUDA support. Is it a must?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/110#issuecomment-228341016,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ADjHf4akIOCd-PCi8YNs-P7aoopVOUV2ks5qO9ejgaJpZM4Gf6Qp\n> .\n", "FYI Here is the tracking bug for CUDA autoconfiguration: #2873.\n\nIt is partially working, but I still need to fix the remaining path issues, such as getting the Python SWIG wrapper to find the tensorflow library correctly.\n", "@damienmg @rdipietro Bazel still does not compile.\n\nJust for your information, my system info:\n\n[sree@ds1 bazel]$ gcc -v\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-15) (GCC)\n\n[sree@ds1 bazel]$ ldd --version\nldd (GNU libc) 2.12\n\n[sree@ds1 bazel]$ which gcc\n/usr/bin/gcc\n\n[sree@ds1 bazel]$ g++ -v\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-15) (GCC)\n\n[sree@ds1 bazel]$ which g++\n/usr/bin/g++\n\nTo build bazel, I do the following:\n1.  git clone https://github.com/bazelbuild/bazel.git\n2. cd bazel\n3. git rag -l\n4. git checkout tags/0.2.2b\n5. ./compile.sh\n\n./compile.sh gives;\n[sree@ds1 bazel]$ ./compile.sh\nINFO: You can skip this first step by providing a path to the bazel binary as second argument:\nINFO:    ./compile.sh compile /path/to/bazel\n\ud83c\udf43  Building Bazel from scratch......\n\ud83c\udf43  Building Bazel with Bazel.\nINFO: Found 1 target...\nERROR: /home/sree/bazel/src/main/cpp/util/BUILD:24:1: C++ compilation of rule '//src/main/cpp/util:md5' failed: gcc failed: error executing command\n  (cd /tmp/bazel.NO5ObMNe/out/bazel && \\\n  exec env - \\\n    PATH=/home/sree/anaconda2/bin:/home/sree/bazel:/opt/jdk1.8.0_91/bin:/opt/jdk1.8.0_91/jre/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/sree/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer '-std=c++0x' -iquote . -iquote bazel-out/local-fastbuild/genfiles -iquote external/bazel_tools -iquote bazel-out/local-fastbuild/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local-fastbuild/bin/src/main/cpp/util/_objs/md5/src/main/cpp/util/md5.pic.o' -MD -MF bazel-out/local-fastbuild/bin/src/main/cpp/util/_objs/md5/src/main/cpp/util/md5.pic.d -fPIC -c src/main/cpp/util/md5.cc -o bazel-out/local-fastbuild/bin/src/main/cpp/util/_objs/md5/src/main/cpp/util/md5.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\nTarget //src:bazel failed to build\nINFO: Elapsed time: 3.147s, Critical Path: 0.07s\n\nBuilding output/bazel\n\nAm I even doing it right? I did not make any changes to tools/cpp/CROSSTOOL file.\n", "What does `echo | gcc -E -xc++ - -v` returns?\n", "@damienmg \n\nUsing built-in specs.\nCOLLECT_GCC=gcc\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/opt/rh/devtoolset-2/root/usr --mandir=/opt/rh/devtoolset-2/root/usr/share/man --infodir=/opt/rh/devtoolset-2/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --enable-languages=c,c++,fortran,lto --enable-plugin --with-linker-hash-style=gnu --enable-initfini-array --disable-libgcj --with-isl=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/isl-install --with-cloog=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/cloog-install --with-mpc=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/mpc-install --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-15) (GCC)\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\n cc1plus -E -quiet -v -iprefix /usr/bin/../lib/gcc/x86_64-redhat-linux/4.8.2/ -D_GNU_SOURCE - -mtune=generic -march=x86-64\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\n", "Also, I installed gcc 4.8.2 using the instructions given at: http://superuser.com/questions/381160/how-to-install-gcc-4-7-x-4-8-x-on-centos.\nAnd since nothing happened, I did the following:\n\nsudo mv /usr/bin/gcc /usr/bin/gcc.bak\nsudo cp /opt/rh/devtoolset-2/root/usr/bin/gcc /usr/bin/gcc\nsudo mv /usr/bin/g++ /usr/bin/g++.bak\nsudo cp /opt/rh/devtoolset-2/root/usr/bin/g++ /usr/bin/g++\n", "```\nexport CC=/opt/rh/devtoolset-2/root/usr/bin/gcc\n./compile.sh\n```\n\nshould work (at least it works in our integration test).\n\nI believe the cp made gcc a bit confused.\n", "Thanks, Now I have different errors:\n\n[sree@ds1 bazel]$ ./compile.sh\nINFO: You can skip this first step by providing a path to the bazel binary as second argument:\nINFO:    ./compile.sh compile /path/to/bazel\n\ud83c\udf43  Building Bazel from scratch......\n\ud83c\udf43  Building Bazel with Bazel.\nINFO: Found 1 target...\nERROR: /home/sree/bazel/src/main/tools/BUILD:3:1: C++ compilation of rule '//src/main/tools:network-tools' failed: gcc failed: error executing command\n  (cd /tmp/bazel.7v8MzbLT/out/bazel && \\\n  exec env - \\\n    PATH=/home/sree/anaconda2/bin:/home/sree/bazel:/opt/jdk1.8.0_91/bin:/opt/jdk1.8.0_91/jre/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/sree/bin \\\n  /opt/rh/devtoolset-2/root/usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/opt/rh/devtoolset-2/root/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -iquote . -iquote bazel-out/local-fastbuild/genfiles -iquote external/bazel_tools -iquote bazel-out/local-fastbuild/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 '-std=c99' -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local-fastbuild/bin/src/main/tools/_objs/network-tools/src/main/tools/network-tools.pic.o' -MD -MF bazel-out/local-fastbuild/bin/src/main/tools/_objs/network-tools/src/main/tools/network-tools.pic.d -fPIC -c src/main/tools/network-tools.c -o bazel-out/local-fastbuild/bin/src/main/tools/_objs/network-tools/src/main/tools/network-tools.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ncc1: error: unrecognized command line option '-quiet'\ncc1: error: bazel-out/local-fastbuild/bin/src/main/tools/_objs/network-tools/src/main/tools/network-tools.pic.d: No such file or directory\ncc1: error: unrecognized command line option '-quiet'\ncc1: error: unrecognized command line option '-auxbase-strip bazel-out/local-fastbuild/bin/src/main/tools/_objs/network-tools/src/main/tools/network-tools.pic.o'\nTarget //src:bazel failed to build\nINFO: Elapsed time: 3.917s, Critical Path: 0.31s\n", "What does `echo | /opt/rh/devtoolset-2/root/usr/bin/gcc -E -xc++ - -v` says?\n\nIt seems like your compiler doesn't like your own installation. Can you try to restore /usr/bin/gcc and /usr/bin/g++ to the default value?\n", "[sree@ds1 ~]$ echo | /opt/rh/devtoolset-2/root/usr/bin/gcc -E -xc++ - -v\nUsing built-in specs.\nCOLLECT_GCC=/opt/rh/devtoolset-2/root/usr/bin/gcc\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/opt/rh/devtoolset-2/root/usr --mandir=/opt/rh/devtoolset-2/root/usr/share/man --infodir=/opt/rh/devtoolset-2/root/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --enable-languages=c,c++,fortran,lto --enable-plugin --with-linker-hash-style=gnu --enable-initfini-array --disable-libgcj --with-isl=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/isl-install --with-cloog=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/cloog-install --with-mpc=/dev/shm/home/centos/rpm/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/mpc-install --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-15) (GCC)\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\n /opt/rh/devtoolset-2/root/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/cc1plus -E -quiet -v -D_GNU_SOURCE - -mtune=generic -march=x86-64\nignoring nonexistent directory \"/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/include-fixed\"\nignoring nonexistent directory \"/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../x86_64-redhat-linux/include\"\n#include \"...\" search starts here:\n#include <...> search starts here:\n /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2\n /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2/x86_64-redhat-linux\n /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2/backward\n /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/include\n /usr/local/include\n /opt/rh/devtoolset-2/root/usr/include\n /usr/include\nEnd of search list.\n\n# 1 \"<stdin>\"\n\n# 1 \"<command-line>\"\n\n# 1 \"<stdin>\"\n\nCOMPILER_PATH=/opt/rh/devtoolset-2/root/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/:/opt/rh/devtoolset-2/root/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/:/opt/rh/devtoolset-2/root/usr/libexec/gcc/x86_64-redhat-linux/:/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/:/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/\nLIBRARY_PATH=/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/:/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../lib64/:/lib/../lib64/:/usr/lib/../lib64/:/opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../:/lib/:/usr/lib/\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\n\nSeems what you said is right. I will restrore both the files to default values.\n", "My which gcc says: /usr/bin/gcc\nBut echo $CC says: /opt/rh/devtoolset-2/root/usr/bin/gcc\n\nAnd hence even after restoring older gcc, I still get gcc version as 4.8.2.\n\nDid I ruin everything?\nI was super nervous that I might break the core by making changes to gcc on centos 6. \n\nIs there a way I can rollback all the changes or can you point me to where I can get a good gcc latest version?\n", "`gcc -v` still says 4.8.2?\n\nWhat does `./compile.sh` result in now?\n", "gcc -v is still 4.8.2\n\n./compile.sh still results in an error:\n\n[sree@ds1 bazel]$ ./compile.sh\nINFO: You can skip this first step by providing a path to the bazel binary as second argument:\nINFO:    ./compile.sh compile /path/to/bazel\n\ud83c\udf43  Building Bazel from scratch......\n\ud83c\udf43  Building Bazel with Bazel.\nINFO: Found 1 target...\nERROR: /home/sree/bazel/src/main/cpp/BUILD:53:1: C++ compilation of rule '//src/main/cpp:blaze_abrupt_exit' failed: gcc failed: error executing command\n  (cd /tmp/bazel.HegZ1Mxo/out/bazel && \\\n  exec env - \\\n    PATH=/home/sree/anaconda2/bin:/home/sree/bazel:/opt/jdk1.8.0_91/bin:/opt/jdk1.8.0_91/jre/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/sree/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer '-std=c++0x' -iquote . -iquote bazel-out/local-fastbuild/genfiles -iquote external/bazel_tools -iquote bazel-out/local-fastbuild/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local-fastbuild/bin/src/main/cpp/_objs/blaze_abrupt_exit/src/main/cpp/blaze_abrupt_exit.pic.o' -MD -MF bazel-out/local-fastbuild/bin/src/main/cpp/_objs/blaze_abrupt_exit/src/main/cpp/blaze_abrupt_exit.pic.d -fPIC -c src/main/cpp/blaze_abrupt_exit.cc -o bazel-out/local-fastbuild/bin/src/main/cpp/_objs/blaze_abrupt_exit/src/main/cpp/blaze_abrupt_exit.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\nTarget //src:bazel failed to build\nINFO: Elapsed time: 3.592s, Critical Path: 0.12s\n\nBuilding output/bazel\n", "Tensorflow is built successfully on CPU, however, it is failed on GPU.\n\nI keep getting this error, even though I modified all path in CROSSTOOL and crosstool_wrapper... from /usr/bin to my gcc path\n\n```\nERROR: /homeappl/home/trungnt/.cache/bazel/_bazel_trungnt/07601e513c2336fd42387644d3f95e2b/external/protobuf/BUILD:331:1: Linking of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /homeappl/home/trungnt/.cache/bazel/_bazel_trungnt/07601e513c2336fd42387644d3f95e2b/execroot/tensorflow && \\\n  exec env - \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/external/protobuf/protoc bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o bazel-out/host/bin/external/protobuf/libprotoc_lib.a bazel-out/host/bin/external/protobuf/libprotobuf.a bazel-out/host/bin/external/protobuf/libprotobuf_lite.a -lpthread -lstdc++ -B/appl/opt/gcc/4.9.1/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ncollect2: fatal error: cannot find 'ld'\ncompilation terminated.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 71.231s, Critical Path: 56.80s\n```\n", "Hello,\n@rdipietro :  I am trying to install tensorflow/0.9.0 on a cluster running CentOS 6.7. I have bazel installed already. Here is the error I am getting.\n`ERROR: /gpfs_home/mdave/.cache/bazel/_bazel_mdave/541ff47a1a214f62e91d090e1e816e43/external/highwayhash/BUILD:17:1: C++ compilation of rule '@highwayhash//:sip_hash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.\n/gpfs/runtime/opt/python/2.7.3/bin/python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build`\n\nI suppose the fix for this, as mentioned by you in the step-wise directions is:\n4. Edit `bazel-out/host/bin/tensorflow/swig` and add `export LD_LIBRARY_PATH=custom:paths:$LD_LIBRARY_PATH` before `swig` is run. Otherwise `swig`won't find libraries that exist in our `LD_LIBRARY_PATH`. This is another hack to get around the confined environment.\n\nThis should add the python library path while setting up the build but I do not seem to find a file such as `bazel-out/host/bin/tensorflow/swig` in the source tree, while the `bazel-out/host/bin/tensorflow` directory does exist. If I create a file named `swig` myself and add the command to export the paths, it still does not work. Any ideas? I have followed all other steps as mentioned.\n\nThank you for the help. Your responses here have already been very helpful. :)\n", "Hi @mukul1992 \n\nSorry, I'm still working with 0.8, so haven't battled with the 0.9 changes yet.\n\nHere is a suggestion:\n\nUse `--verbose_failures` with bazel, so that error messages aren't truncated. Then sift through the failure to find out which script ends up causing the issue. Then try putting `export LD_LIBRARY_PATH=your:custom:paths:$LD_LIBRARY_PATH` at the top of that file.\n\nHopefully that might help. I don't think I'll have the time to get around to compiling 0.9 for a while. If that doesn't work, I suggest shooting back to 0.8 for now (assuming you don't need something that's cutting edge?).\n", "Hi @rdipietro , thanks for replying.\n\nSo, I switched back to 0.8. I am now using Bazel 0.3.0 (any previous version which would work better?).\nHere is the output. I am just including the ERROR part which is in Bold. Again, I did complete other steps. I cannot figure out where to add the LD_LIBRARY_PATH thing so that it picks up the libpython library.\n\n## Output:\n\n[mdave@login001 tensorflow]$ bazel build -c opt --config=cuda --linkopt '-lrt' --copt=\"-DGPR_BACKWARDS_COMPATIBILITY_MODE\" --conlyopt=\"-std=c99\" //tensorflow/tools/pip_package:build_pip_package -s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone\nWarning: ignoring LD_PRELOAD in environment.\n\nINFO: Found 1 target...\n\n # @re2//:re2 [action 'Compiling external/re2/re2/compile.cc [for host]']\n.(cd /gpfs_home/mdave/.cache/bazel/_bazel_mdave/c9818020e0087a4155dff2f5c73aa150/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/gpfs/runtime/opt/git/2.2.1/bin:/gpfs/runtime/opt/gcc/4.9.2/bin:/gpfs/runtime/opt/java/8u66/bin:/gpfs/runtime/opt/bazel/0.3.0/bin:/gpfs/runtime/opt/matlab/R2014a/bin:/gpfs/runtime/opt/perl/5.18.2/bin:/gpfs/runtime/opt/python/2.7.3/bin:/gpfs/runtime/opt/intel/2013.1.106/bin:/gpfs/runtime/opt/centos-updates/6.3/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/gpfs/runtime/bin:/users/mdave/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.o' -iquote external/re2 -iquote bazel-out/host/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/host/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.d -c external/re2/re2/compile.cc -o bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.o)\n\n**ERROR: /gpfs_home/mdave/.cache/bazel/_bazel_mdave/c9818020e0087a4155dff2f5c73aa150/external/re2/BUILD:9:1: C++ compilation of rule '@re2//:re2' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /gpfs_home/mdave/.cache/bazel/_bazel_mdave/c9818020e0087a4155dff2f5c73aa150/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/gpfs/runtime/opt/git/2.2.1/bin:/gpfs/runtime/opt/gcc/4.9.2/bin:/gpfs/runtime/opt/java/8u66/bin:/gpfs/runtime/opt/bazel/0.3.0/bin:/gpfs/runtime/opt/matlab/R2014a/bin:/gpfs/runtime/opt/perl/5.18.2/bin:/gpfs/runtime/opt/python/2.7.3/bin:/gpfs/runtime/opt/intel/2013.1.106/bin:/gpfs/runtime/opt/centos-updates/6.3/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/gpfs/runtime/bin:/users/mdave/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.o' -iquote external/re2 -iquote bazel-out/host/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/host/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.d -c external/re2/re2/compile.cc -o bazel-out/host/bin/external/re2/_objs/re2/external/re2/re2/compile.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.\n/gpfs/runtime/opt/python/2.7.3/bin/python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory**\n\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 13.883s, Critical Path: 5.22s\n", "@rdipietro Hi, I have tried everything you gave here- changed the CROSSTOOL files and everything but it does not work. I started fresh again and believe I have bazel working. Can you please look at my description [here](https://github.com/tensorflow/models/issues/276) and suggest something. Thanks a lot!\n", "I really don't know what to suggest. Other than perhaps asking TensorFlow\nto build binaries for CentOS 6.7. I think this would save a lot of people a\nlot of trouble and would repeatedly save all this trouble each new release,\nbut I don't know if they're willing to do it.\n\nOn Thu, Jul 21, 2016 at 11:21 AM, kskp notifications@github.com wrote:\n\n> @rdipietro https://github.com/rdipietro Hi, I have tried everything you\n> gave here- changed the CROSSTOOL files and everything but it does not work.\n> I started fresh again and believe I have bazel working. Can you please look\n> at my description here https://github.com/tensorflow/models/issues/276\n> and suggest something. Thanks a lot!\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/110#issuecomment-234287228,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AE6XX5jGX-7ZS0arN1p7eyvJNSGB4QLjks5qX46DgaJpZM4Gf6Qp\n> .\n", "@rdipietro  Sorry, but didn't you mention you had tensorflow running on centos 6.7 and gcc 4.8.2? Were you able to run Syntaxnet also? I am stuck with the Centos 6.6 cluster and need to get Syntaxnet running on this. It works fine on Centos 7. :(\n", "@kskp I created a Dockerfile that compiles TensorFlow 0.9 CPU for CentOS 6, I tested in CentOS 6 and RedHat EL 6.5. You can use a standalone machine to generate the TensorFlow Package and test in you site. (your standalone machine will need to have Docker, I tested in linux and macOS with Docker for Mac installed)\n\nhttps://github.com/cirocavani/tensorflow-poc/tree/master/tensorflow_centos6\n\n(main.sh is the procedure script)\n\nI did also an installer for TensorFlow with miniconda2 to run in Red Hat 6.5 without any pre-requirement software.\n\nhttps://github.com/cirocavani/tensorflow-poc/tree/master/tensorflow_installer\n\n(main.sh is the procedure script)\n\nThis procedure creates the installer file `tensorflow.sh` with Miniconda2, TensorFlow 0.9, deps and python program (executing this files will install Miniconda, install TensorFlow and run the training script).\n\nMy main case is to run TensorFlow in Hadoop (Red Hat EL 6.5), there is another POC for this:\n\nhttps://github.com/cirocavani/tensorflow-poc/tree/master/yarn_training\n\nWith this setup, I am running the TF Learn's Wide and Deep Example in Hadoop.\n", "I have succeeded in compiling a GPU, Python 3.5 version of TensorFlow 0.10.0 on a CentOS 6 Docker, and it ran well on our university's CentOS 6 cluster. Check https://github.com/leelabcnbc/DevOps/tree/master/Docker/tensorflow/0.10.0/centos6/py35. Basically, it's replacing some hardcoded lines in CROSSTOOL-related items, and adding `-lm` to everything to prevent errors like #2291. I think Google can make compiling TensorFlow on CentOS less frustrating, if they make some hardcoded stuff link to correct locations.\n", "I've just managed to build tensorflow 0.12rc0 on CentOS6.5, which only had gcc-4.4.7 compiler by default, without having root privileges. (At least, it's successfully passing most simple tests, like [this one](https://github.com/tensorflow/tensorflow/issues/110#issuecomment-220009120)).\r\n\r\nIn short, I had to:\r\n1. Build newer gcc, [hardcoding paths](http://stackoverflow.com/questions/39095577/tensorflow-build-failure-with-gcc-error-as/39181639#39181639) to `as`,`ld` and `nm` (a workaround for `gcc: error trying to exec 'as': execvp: No such file or directory`)\r\n\r\n2. Since I've used gcc, installed to my own `$HOME`, I had to [explicitly specify correct linker library directories](https://github.com/bazelbuild/bazel/issues/649#issuecomment-166710509) [here](https://github.com/tensorflow/tensorflow/blob/v0.11.0/third_party/gpus/crosstool/CROSSTOOL.tpl#L59) (a workaround for `version 'GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)`)\r\n\r\n3. Add `-lrt` and `-lm` linker flags to the same place (just like [suggested](https://github.com/tensorflow/tensorflow/issues/2291#issuecomment-250025095) by @zym1010)\r\n\r\n[Same story, with **few more details**](http://stackoverflow.com/a/41003023/1032586).", "I built the latest Tensorflow (github master branch) with GPU support on a supercomputing center (CentOS 6.7 with gcc 4.9.2/Generally with a customized cc tool chain). I pointed out some of environment variables settings that are necessary for a success built. Just to document here for future reference:\r\n\r\nhttp://biophysics.med.jhmi.edu/~yliu120/tensorflow.html", "Thanks @rdipietro ! I have been able to successfully install r0.12 with Bazel 0.4.3 on a cluster. Some of your suggestions needed to be modified to cater to the changes in the new version of TF and Bazel. But, your suggestions provided a solid starting point. When I get the time, I will write up the changes that I had to make.", "You're welcome @VittalP :)\r\n\r\nI have an updated set of notes that works as of 1.0.0 alpha:\r\n\r\nFirst of all Bazel finally just works. Can download the newest 0.4.x source code (dist zip version), run `./compile.sh`, then add the printed output path to `PATH`.\r\n\r\nTensorFlow unfortunately still doesn't just work. So (replacing my paths with yours):\r\n\r\n1) In `configure`, replace `bazel clean --expunge` with `bazel clean --expunge_async`\r\n\r\n2) In `third_party/gpus/crosstool/CROSSTOOL.tpl`, replace all occurrences of `/usr/bin/cpp` with `/cm/shared/apps/gcc/4.8.2/bin/cpp`\r\n\r\n3) In `third_party/gpus/crosstool/CROSSTOOL.tpl`, after the line `-B/usr/bin/`, add the lines\r\n\r\n  linker_flag: \"-Wl,-R/cm/shared/apps/gcc/4.8.2/lib64\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include-fixed\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/include/c++/4.8.2\"\r\n\r\n4) In `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl`, replace `NVCC_PATH = CURRENT_DIR + '/../../../cuda/bin/nvcc'` with `NVCC_PATH = ('/cm/shared/apps/cuda/7.5/bin/nvcc')`\r\n\r\n5) In `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl`, replace `LLVM_HOST_COMPILER_PATH = ('/usr/bin/gcc')` with `LLVM_HOST_COMPILER_PATH = ('/cm/shared/apps/gcc/4.8.2/bin/gcc')`\r\n\r\n6) In `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl`, comment out the line `cmd = 'PATH=' + PREFIX_DIR + ' ' + cmd`\r\n\r\nI configured with cuda 7.5, cudnn 5, compute compatibility 3.5 and built with `bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`", "@rdipietro @VittalP I have wrote an explanation on the installation of the latest Tensorflow right before @VittalP 's post. But you guys just simply ignored my post... As a jhuer, I kindly note that I have sent my instructions to MARCC's guy and there is already a tensorflow module on MARCC.\r\n\r\nIf you like to read my post to see where is different. http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html\r\n\r\nIf something needs to be updated, please inform me of that.", "Sorry! I didn't notice that you had posted here. But note that you are making changes that I didn't need to make. Probably depends on specific versions of TF / cuda / gcc / whatever.\r\n\r\nSide note: I still compile on MARCC because they only installed TF for Python 2.x, whereas I'm using 3.x.", "I have updated my webpage for building tensorflow 1.0.0 with python 3.5.2. I provided two wheels on the webpage as well.\r\n\r\nPlease refer to:\r\nhttp://biophysics.med.jhmi.edu/~yliu120/tensorflow.html", "For whoever wants to compile TensorFlow 1.0 on RedHat 6 and with Python 2.7, I provide a detailed step-by-step guide here: https://www.linkedin.com/pulse/compiling-tensorflow-10-python-27-redhat-6-florian-raudies", "And here we go again for r1.2. (Note: since r1.0, the Bazel configuration file organization has been mucked with.)\r\n\r\nBazel: Need new ish version. 0.4.3 did not work, 0.4.5 did. Again, Bazel now compiles easily even with older CentOS / glibc, so this is straightforward.\r\n\r\nRequired edits for TensorFlow:\r\n\r\nvim third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n`%s~/usr/bin/cpp~/cm/shared/apps/gcc/4.8.2/bin/cpp~g`\r\nAnd after `linker_flag: \"-B/usr/bin/\"` add\r\n```\r\n  linker_flag: \"-Wl,-R/cm/shared/apps/gcc/4.8.2/lib64\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include-fixed\"\r\n  cxx_builtin_include_directory: \"/cm/shared/apps/gcc/4.8.2/include/c++/4.8.2\"\r\n```\r\n\r\nvim third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl\r\n`NVCC_PATH = '/cm/shared/apps/cuda/7.5/bin/nvcc'`\r\n\r\nFinal notes: Wouldn't work with Cuda 7.5, CuDNN 5 (cuda compilation errors). Success with Cuda 8.0, CuDNN 5.", "I am working on a CentOS 6 cluster which uses Lustre filesystem. I am unable to make Bazel work on it since it can't use file locking. [Refer this issue](https://github.com/bazelbuild/bazel/issues/2647). So would it be possible for tensorflow to support other build tools?\r\n\r\nEdit : Error: unexpected result from F_SETLK: Function not implemented. Also refer the hyper-link above", "@JoyChopra1298\r\nUp in this thread, lots of people built bazel and tf on CentOS 6. I am sure it can be built. Since you didn\u2019t paste any error message, I am not sure what is your problem. But if you said Bazel can\u2019t work with Lustre, you can move bazel \u2018s output_user_root to /tmp/bazel. Usually the tmpfs is a locally mounted fs on a single node.\r\n", "@yliu120 Thank you using bazel's output_user_root option worked.", "**I have some similar problem here, in step2 for TF specifically.\r\nMy cluster on campus uses module with Redhat which is glibc 2.12. \r\nI successfully installed bazel 0.15.0. But when I tried to move forward to bazel build TF, I got a long log, a part of which appears as:**\r\n\r\n/home2/my_name/.cache/bazel/_bazel_my_name/b9c3b9594c932d1e804df44467c1c0d2/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S: Assembler messages:\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:37: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:80: Error: no such instruction: `vpbroadcastq .Land_mask(%rip),%ymm15'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:91: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:92: Error: no such instruction: `vpbroadcastq 0-128(%rsi),%ymm10'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:93: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:95: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:97: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:99: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:101: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:103: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:105: Error: suffix or operands invalid for `vpaddq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:107: Error: suffix or operands invalid for `vpxor'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:110: Error: suffix or operands invalid for `vpmuludq'\r\nexternal/boringssl/linux-x86_64/crypto/fipsmodule/rsaz-avx2.S:111: Error: no such instruction: `vpbroadcastq 32-128(%rsi),%ymm11' \r\n...\r\n\r\n**And when I used --verbose_failures to monitor the building process, I obtained the output organized in error_records.txt**\r\n[error_records.txt](https://github.com/tensorflow/tensorflow/files/2196114/error_records.txt)\r\n\r\n\r\n\r\nCan anyone help with this issue?", "@owenyoung75 Did you solve this problem? I'm facing similar situation."]}, {"number": 109, "title": " C++ compilation of rule '//tensorflow/python:tf_session_helper' failed", "body": "I am trying to compile build_pip_package on Ubuntu 12.04 with gcc 4.8, but it gives an error during compilation:\n\n```\n$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\n\ntensorflow/python/client/tf_session_helper.cc:418:41: error: 'PyArray_SHAPE' was not declared in this scope\n   dims.push_back(PyArray_SHAPE(array)[i]);\n\nERROR: /home/local/ANT/x/tensorflow/tensorflow/python/BUILD:666:1: C++ compilation of rule '//tensorflow/python:tf_session_helper' failed: gcc failed: error executing command \n  (cd /home/local/ANT/x/.cache/bazel/_bazel_x/29843df2d2b24eaae7acd7ee881b7bec/tensorflow && \\\n  exec env - \\\n    INTERCEPT_LOCALLY_EXECUTABLE=1 \\\n    PATH=/home/local/ANT/x/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -I/usr/include/python2.7 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.d -fPIC -c tensorflow/python/client/tf_session_helper.cc -o bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command \n  (cd /home/local/ANT/x/.cache/bazel/_bazel_x/29843df2d2b24eaae7acd7ee881b7bec/tensorflow && \\\n  exec env - \\\n    INTERCEPT_LOCALLY_EXECUTABLE=1 \\\n    PATH=/home/local/ANT/x/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin:/home/local/ANT/x/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -I/usr/include/python2.7 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.d -fPIC -c tensorflow/python/client/tf_session_helper.cc -o bazel-out/local_linux-opt/bin/tensorflow/python/_objs/tf_session_helper/tensorflow/python/client/tf_session_helper.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 3.223s, Critical Path: 2.46s\n```\n", "comments": ["I can compile that particular source file after adding this to the gcc command:\n\n```\n-I/usr/local/lib/python2.7/dist-packages/numpy/core/include/\n```\n\nBut when I rerun the bazel command it tries to compile it again without the needed include path and fails.\n", "@markusdr: what version of numpy do you have installed, by any chance?  I have a suspicion that it's probably earlier than numpy 1.8.2 :)\n", "I believe it's numpy 1.9.2.\n", "Gotcha -- that version does have PyArray_SHAPE.  Do you have any other numpy directories installed on your machine that might be interfering somehow?\n\nIf not, can you try changing tf_session_helper.cc to switch from PyArray_SHAPE to PyArray_DIMS ? (That one is available in earlier versions of numpy and apparently PyArray_SHAPE is an alias)\n", "Right, the installation is using /usr/include/python2.7/, which doesn't have PyArray_SHAPE. \n\nBut PyArray_SHAPE is defined in /usr/**local**/lib/python2.7/dist-packages/numpy/core/include.\n\nHow can I tell bazel to use the latter python installation path?\n", "When I add the correct numpy include path to the tensorflow/python/BUILD file it seems to compile, but at the end it complains:\n\n```\n$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package \ntensorflow/python/BUILD:666:1: in cc_library rule //tensorflow/python:tf_session_helper: \nThe include path '/usr/local/lib/python2.7/dist-packages/numpy/core/include' references \na path outside of the execution root..  \n```\n", "OK, this workaround gets it to compile:\n\n```\ncd third_party\nln -s /usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy .\n```\n\nThen add `-Ithird_party` to the includes in `tensorflow/python/BUILD` and `tensorflow/tensorflow.bzl` \n", "There may be a way to infer the numpy header  location at compile time. I'll take a look.\n", "@markusdr \nhow to add `-Ithird_part` to `tensorflow/python/BUILD` and `tensorflow/tensorflow.bzl`\nthanks\n", "@auroua Here is the diff:\n\n```\ndiff --git a/tensorflow/python/BUILD b/tensorflow/python/BUILD\n-    copts = numpy_macosx_include_dir + [\"-I/usr/include/python2.7\"],\n+    copts = numpy_macosx_include_dir + [\"-Ithird_party\", \"-I/usr/include/python2.7\"],\n\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\n-                    ] + [\"-I/usr/include/python2.7\"],\n+                    ] + [\"-Ithird_party\", \"-I/usr/include/python2.7\"],\n```\n\nAlternatively, I could have symlinked `/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy` into `/usr/include/python2.7`, but I didn't have root access.\n", "@markusdr \nI have a problem in #251. Can you help me to solve this problems.\nI tried you method but it not working.\nthanks \n", "Do @markusdr 's changes still apply? I don't think that the diff corresponds to the current version of tensorflow/python/BUILD anymore. Suggestions?\n", "Symlinking the numpy headers in util/python worked for me. python_config took care of the rest.\n", "If you sync to HEAD you should be able to use ./configure to select which python to use.\n", "@vrv Is configure auto detecting the location of numpy headers now (from distconfig possibly?) ?. If not, this issue will still exist. \n", "I believe so:  ./configure will call python_config.sh (https://github.com/tensorflow/tensorflow/blob/master/configure#L25) which gets the numpy headers from https://github.com/tensorflow/tensorflow/blob/master/util/python/python_config.sh#L64\n", "Confirmed. python_config auto detects the location of numpy. None of the changes suggested in this thread are needed anymore as long as python has access to the correct numpy location. Thanks, @vrv.\n"]}, {"number": 108, "title": "Building a shared libary", "body": "Is there a way to ask the build system to build a shared library that one can link a program written using the C++ API against? My apologies for this simple question, but I am very unfamiliar with this build system.\n", "comments": ["Bazel has an option to build a shared object out of a binary: http://bazel.io/docs/be/c-cpp.html ,namely linkshared. It can be done, but I'm a little unsure if the Tensorflow build system can do it out of the box.\n\nI'm currently running experiments on Travis with Tensorflow to see how it reacts/accommodates to C shared object.\n", "This naive build rule produces a shared library that seemingly made it as far as loading the inception model (via the C API), before crashing.\n\n```\ncc_binary(\n    name = \"libtensorflow.so\",\n    copts = tf_copts(),\n    linkshared = 1,\n    linkopts = [\n        \"-lpthread\",\n        \"-lm\",\n    ],\n    deps = [\n        \":cc_ops\",\n        \"//tensorflow/core:kernels\",\n        \"//tensorflow/core:tensorflow\",\n    ],\n)\n```\n\n```\nProgram received signal SIGSEGV, Segmentation fault.\ntensorflow::NodeBuilder::NodeOut::NodeOut (i=0, n=0x23c1620, \n    this=0x7fffffffc3d0)\n    at tensorflow/tensorflow/core/graph/node_builder.h:39\n#0  tensorflow::NodeBuilder::NodeOut::NodeOut (i=0, n=0x23c1620, \n    this=0x7fffffffc3d0)\n    at tensorflow/tensorflow/core/graph/node_builder.h:39\n```\n", "I pieced together a lot of the scattered information on compiling for C++ and wrote it up: https://medium.com/@jimfleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f\n\nHopefully it will be helpful for someone here. I'm going to try a shared library next to see if I can reduce the build size.\n", "I'm more looking at Tensorflow as a shared library to make it more code / platform agnostic to talk to (my platform of choice being PHP/HHVM). There's already bindings for Go here: https://github.com/chai2010/tensorflow which seems similar to your ideas @jimfleming \n\nSo I think we might be able to get there. Just may take a bit of rework\n", "@jimfleming  have you gotten a shared library working?  I tried @aliasaila's suggestion and also got seg fault when trying to run my program.  When compiling with the cc_library option, I do get a .so file, but it is very small, and when compiling I have undefined references.  So  I know something isn't set up correctly. thanks\n", "@nbenhaim Tensorflow:core has some dependencies set as libstatic in the Bazel build file (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/BUILD) which would explain why you're missing references (http://bazel.io/docs/be/c-cpp.html) :\n\n> The linkstatic attribute has a different meaning if used on a cc_library() rule. For a C++ library, linkstatic=1 indicates that only static linking is allowed, so no .so will be produced.\n", "@nbenhaim Yes and no. I can compile the .so using `cc_binary` + `linkshared` and I can load the graph from the host language using the C API and an FFI interface. The values I get back from the graph don't make sense though. I'll be playing with it over Thanksgiving and will definitely publish my results here.\n", "@nbenhaim Initially I was following the label_image example and using tensorflow::ops::ReadFile to load the image file. Unfortunately I couldn't pinpoint the issue (the debug version of the shared lib was too big to load). To bypass the issue I added code to load and populate the input Tensor outside of TensorFlow, and that was successful.\n", "FYI, there is a similar discussion on building a shared library in #5. Perhaps you can combine efforts?\n", "@jimfleming how are you linking your compiled so file with your project?  I am able to compile executables and .so files from within the tensorflow build environment, but when I take the compiled so file and link it into my project with my own cmake build environment, the resulting program does compile but crashes on startup at some Tensorflow Kernel related method.  How can I see what compile options bazel is using?  I suspect there is some sort of incompatibility there.  Thanks\n", "I'm building the .so as I described above\u2014now I don't need the TensorFlow environment. Then renaming the .so to .dylib (they're different but the host language doesn't know that and I'm on a Mac). Then using the host language's C FFI interface I'm calling into the shared library.\n", "@nbenhaim I've managed to load and execute TensorFlow graphs using TensorFlow's C API (I'm not a fan of SWIG). Hopefully this will be useful to you: https://medium.com/jim-fleming/loading-tensorflow-graphs-via-host-languages-be10fd81876f\n", "Nice work @jimfleming!\n\n\"This comment in the TensorFlow source makes it sound like it\u2019s optional but it\u2019s not:\" -- want to send us a change to fix it, or suggest an improvement?  Should we switch 'can' to 'must' ?\n", "Thanks!\n\nSure, I can do that. It'll be a good exercise in learning the contribution process anyways. Yah, it's the \"can\" that was unclear, \"must\" would be better.\n\nEDIT: https://tensorflow-review.googlesource.com/1180\n", "I would love if @jimfleming's libtensorflow.so rule were included in the TensorFlow repo.  Can we do that?  Patching source locally is less than ideal, and setting up a new Bazel workspace that depends on the TensorFlow one is nearly impossible because of several Bazel bugs/missing features.\n", "If someone sends us a PR, I'd be very happy to merge it. \n", "the shared library was added a while ago, yay!\n", "@jimfleming Thanks for your blog \"loading-a-tensorflow-graph-with-the-c-api\". I build a static lib on macOS not using bazel. When linking my custom c++ prediction code, some errors occur. Can you give me some helps? https://github.com/tensorflow/tensorflow/issues/13306"]}, {"number": 107, "title": "Truncated backprop docs are confusing", "body": "The docs (http://tensorflow.org/tutorials/recurrent/index.md) imply that to truncate backprop, you feed blocks of fixed (time) length (`num_steps`) to `RNNCell`.  \n\nDoes this mean that if I have sentences of length 100 and I want to truncate by 20 time steps, I would send tensors of shape `batch_size x 20`?\n\nIf I'm right and you are supposed to feed blocks of fixed length inputs in an inner loop, don't I need to initialize the initial state from the previous block for the forward pass to be right.  But if I do use the final hidden state of the previous block as the next initial state, won't the autograd backpropagate all the way through.  In other words, looping over blocks of intervals and then within each in block while connecting the previous block's hidden state to the next block's initial state seems equivalent to just looping over time in the first place.\n\nAm I missing something?\n", "comments": ["A guess:\n\nIf you look at line224-230 of ptb_word_lm.py, the initial state is in the data feeder dictionary, which is set as the state from the previous batch.\n", "Thanks, I get it now.\n\nFor other Theano users reading this, here is an explanation.  In Theano, you build the graph iterating all the way through time, but making sure to set `truncate=num_steps` in `scan()`.  In TensorFlow, you literally construct the graph for `num_steps` and pass in data with length equal to num_steps while making sure to initialize the state to the previous iteration's final hidden state.  \n"]}, {"number": 106, "title": "Ubuntu installation error using pip", "body": "Hi,\n\nI am using Ubuntu 12.04 amd64 with Python 2.7.3. I have used the following command to want to install tensorflow :\n\npip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n\nI get the following error :\n### \n\n/usr/bin/pip run on Wed Nov 11 07:00:36 2015\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n  Downloading from URL https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n    Traceback (most recent call last):\n      File \"<string>\", line 14, in <module>\n    IOError: [Errno 2] No such file or directory: '/tmp/pip-k5gImY-build/setup.py'\n    Complete output from command python setup.py egg_info:\n    Traceback (most recent call last):\n\n  File \"<string>\", line 14, in <module>\n\nIOError: [Errno 2] No such file or directory: '/tmp/pip-k5gImY-build/setup.py'\n\nCommand python setup.py egg_info failed with error code 1\nException information:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 126, in main\n    self.run(options, args)\n  File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 223, in run\n    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)\n  File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 980, in prepare_files\n    req_to_install.run_egg_info()\n  File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 216, in run_egg_info\n    command_desc='python setup.py egg_info')\n  File \"/usr/lib/python2.7/dist-packages/pip/**init**.py\", line 255, in call_subprocess\n    % (command_desc, proc.returncode))\nInstallationError: Command python setup.py egg_info failed with error code 1\n### \n\nThe output of \"sudo pip --version\" is \"pip 1.0 from /usr/lib/python2.7/dist-packages (python 2.7)\".\n\nI want to know that is my pip version too low. What else should I try ? Any idea ?\n\nThanks for any suggestion.\n\nLawrence\n", "comments": ["Likely a dupe of https://github.com/tensorflow/tensorflow/issues/56: let us know if it isn't (answer is to upgrade pip).  Re-open if that's not the case!\n"]}, {"number": 105, "title": "Can't build from source?", "body": "I followed the instructions [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md) but failed at this step.\n\n```\n\u279c  tensorflow git:(master) bazel build -c opt //tensorflow/cc:tutorials_example_trainer\n..........\nINFO: Elapsed time: 2.016s\njava.lang.NoClassDefFoundError: com/jcraft/jsch/JSchException\n        at org.eclipse.jgit.transport.JschConfigSessionFactory.getSession(JschConfigSessionFactory.java:109)\n        at org.eclipse.jgit.transport.SshTransport.getSession(SshTransport.java:136)\n        at org.eclipse.jgit.transport.TransportGitSsh$SshFetchConnection.<init>(TransportGitSsh.java:262)\n        at org.eclipse.jgit.transport.TransportGitSsh.openFetch(TransportGitSsh.java:161)\n        at org.eclipse.jgit.transport.FetchProcess.executeImp(FetchProcess.java:136)\n        at org.eclipse.jgit.transport.FetchProcess.execute(FetchProcess.java:122)\n        at org.eclipse.jgit.transport.Transport.fetch(Transport.java:1138)\n        at org.eclipse.jgit.api.FetchCommand.call(FetchCommand.java:130)\n        at org.eclipse.jgit.api.CloneCommand.fetch(CloneCommand.java:193)\n        at org.eclipse.jgit.api.CloneCommand.call(CloneCommand.java:133)\n        at com.google.devtools.build.lib.bazel.repository.GitCloneFunction.compute(GitCloneFunction.java:124)\n        at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:725)\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$2.run(AbstractQueueVisitor.java:436)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ClassNotFoundException: com.jcraft.jsch.JSchException\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n        ... 16 more\n```\n\nMy environment is Ubuntu 14.04 LTS without  GPU.\n", "comments": ["From the stack trace, it seems likely that this is either:\n\n1) A bazel problem\n2) A connection problem\n\nCan you validate that just plain 'bazel' is working properly?  If not, that's probably something to ask the bazel team.\n", "(Please re-open if you find this is TensorFlow related)\n", "Yes, plain `bazel` works.\n\n```\n\u279c  tensorflow git:(master) bazel\n..........\n                                                 [bazel release head (@125b349)]\nUsage: bazel <command> <options> ...\n\nAvailable commands:\n  analyze-profile     Analyzes build profile data.\n  build               Builds the specified targets.\n  canonicalize-flags  Canonicalizes a list of bazel options.\n  clean               Removes output files and optionally stops the server.\n  dump                Dumps the internal state of the bazel server process.\n  fetch               Fetches external repositories that are prerequisites to the targets.\n  help                Prints help for commands, or the index.\n  info                Displays runtime info about the bazel server.\n  mobile-install      Installs targets to mobile devices.\n  query               Executes a dependency graph query.\n  run                 Runs the specified target.\n  shutdown            Stops the bazel server.\n  test                Builds and runs the specified test targets.\n  version             Prints version information for bazel.\n\nGetting more help:\n  bazel help <command>\n                   Prints help and options for <command>.\n  bazel help startup_options\n                   Options for the JVM hosting bazel.\n  bazel help target-syntax\n                   Explains the syntax for specifying targets.\n  bazel help info-keys\n                   Displays a list of keys used by the info command.\n\u279c  tensorflow git:(master) bazel build\nINFO: Found 0 targets...\nINFO: Elapsed time: 2.310s, Critical Path: 0.01s\n```\n\nI'll cross post this issue to `bazel`.\n", "Could you please leave this open? If it's not clear that the problem is only `bazel` then I suggest keeping the issue open on both repos.\n\nIf I `git checkout master` then I can get pass the Java exception state but would get into another issue (already reported by someone else [here](https://github.com/tensorflow/tensorflow/issues/119))\n", "I can't install from binaries, nor from source. Bazel said that [it's a problem with the tensorflow documentation](https://github.com/bazelbuild/bazel/issues/586#issuecomment-156053152). Please reopen.\n", "I see that the [instructions have changed](https://github.com/tensorflow/tensorflow/commit/72a5a60dd4664a7caa4611344364ac7851464a60), but for some reason the site is still out of date.\n", "Following the new installation instructions I still seem to hit the same problem:\n\n```\n$ bazel version\n.......\nBuild label: 0.1.1-jdk7\nBuild target: bazel-out/local_linux-fastbuild/bin/src/main/java/bazel-main_deploy.jar\nBuild time: Thu Oct 15 20:35:27 2015 (1444941327)\nBuild timestamp: 1444941327\nBuild timestamp as int: 1444941327\n$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nINFO: Elapsed time: 1.092s\njava.lang.NoClassDefFoundError: com/jcraft/jsch/JSchException\n    at org.eclipse.jgit.transport.JschConfigSessionFactory.getSession(JschConfigSessionFactory.java:109)\n    at org.eclipse.jgit.transport.SshTransport.getSession(SshTransport.java:136)\n    at org.eclipse.jgit.transport.TransportGitSsh$SshFetchConnection.<init>(TransportGitSsh.java:262)\n    at org.eclipse.jgit.transport.TransportGitSsh.openFetch(TransportGitSsh.java:161)\n    at org.eclipse.jgit.transport.FetchProcess.executeImp(FetchProcess.java:136)\n    at org.eclipse.jgit.transport.FetchProcess.execute(FetchProcess.java:122)\n    at org.eclipse.jgit.transport.Transport.fetch(Transport.java:1138)\n    at org.eclipse.jgit.api.FetchCommand.call(FetchCommand.java:130)\n    at org.eclipse.jgit.api.CloneCommand.fetch(CloneCommand.java:193)\n    at org.eclipse.jgit.api.CloneCommand.call(CloneCommand.java:133)\n    at com.google.devtools.build.lib.bazel.repository.GitCloneFunction.compute(GitCloneFunction.java:124)\n    at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:810)\n    at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$2.run(AbstractQueueVisitor.java:439)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ClassNotFoundException: com.jcraft.jsch.JSchException\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:366)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    ... 16 more\n```\n"]}, {"number": 104, "title": "Support for python 3", "body": "It would be nice to have support for python 3 \n", "comments": ["See issue #1 ...\n"]}, {"number": 103, "title": "Alpine Linux: __isnanf: symbol not found ", "body": "I build tensorflow in alpine Linux in docker successfully, but when run the test, I got below error. Anything I missed?\n\n```\n$ python\n>>> import tensorflow as tf\n...\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: Error relocating /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: __isnanf: symbol not found\n>>> exit()\n\n/ # nm /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so |grep isnanf\n                 U __isnanf@@GLIBC_2.2.5\n/ #\n```\n\nHow to fix the issue `__isnanf: symbol not found`\n\n`Dockerfile` for your reference: https://github.com/BWITS/Docker-builder/blob/master/tensorflow/alpine/Dockerfile\n", "comments": ["From quick searches on that error message, it looks like this is Alpine specific: alpine seems to use a different c library than glibc, which we probably don't support. :(\n", "Thanks @vrv .\n\nYour answer gives me hints, that I can install glibc in alpine:\n\nhttps://github.com/jeanblanchard/docker-alpine-glibc/blob/master/Dockerfile\n\nhttps://github.com/gliderlabs/docker-alpine/issues/11\n", "ticket can be closed, I have built it in alpine with `miniconda` which has Python compiled for glibc\n", "It should also be possible to build the C components from source so that they're linked to the correct libc rather than installing binaries from a foreign (glibc-based) system. This would be a less drastic solution.\n"]}, {"number": 102, "title": "Fix 'Fetches' example in basic_usage", "body": "need \u2018as sess\u2019 to be executed.\n", "comments": ["Thanks for the PR!  I think this was independently fixed in a commit earlier this week -- we appreciate the effort.\n"]}, {"number": 101, "title": "Neural Translation Model example fails due to missing EN tokens ", "body": "The S2S Neural Translation example (tensorflow/models/rnn/translate)  runs into this error:\n\n> tensorflow.python.platform.default._gfile.FileError: [Errno 2] No such file or directory: 'data/giga-fren.release2.ids40000.en'\n\nThe issue seems to be in prepare_wmt_data of data_utils.py. Here, instead of creating a new file for the EN tokens, the FR tokens are overwritten by EN tokens:\n\n> data_to_token_ids(train_path + \".en\", fr_train_ids_path, fr_vocab_path)\n\nThe fix seems to be as simple as changing that line to:\n\n> data_to_token_ids(train_path + \".en\", en_train_ids_path, en_vocab_path)\n", "comments": ["Yes, sorry, this will soon be fixed.\n", "Fixed in a recent commit, thanks!\n", "@rameshdom  thanks.\n"]}, {"number": 100, "title": "Installing from source - problem with bazel", "body": "I was following the instructions for installing from source. However, installing bazel from the specified checkout, however I encountered the error from this issue:\nhttps://github.com/bazelbuild/bazel/issues/321\nThis was fixed by editing the compile.sh and changing the `c++0x` to `c++11`. However now I'm getting the following issue, which unfortunately did not find any relevant information from google:\n\n```\nINFO: You can skip this first step by providing a path to the bazel binary as second argument:\nINFO:    ./compile.sh build /path/to/bazel\n\ud83c\udf43  Building Bazel from scratch............\n\ud83c\udf43  Building Bazel with Bazel.\n.Extracting Bazel installation...\nSending SIGTERM to previous Bazel server (pid=23336)... done.\n.................\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nINFO: Found 1 target...\nINFO: From Compiling src/main/cpp/blaze_util_posix.cc:\ngcc: unrecognized option '-no-canonical-prefixes'\nsrc/main/cpp/blaze_util_posix.cc: In function 'void blaze::ExecuteProgram(const std::string&, const std::vector<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::basic_string<char, std::char_traits<char>, std::allocator<char> > > >&)':\nsrc/main/cpp/blaze_util_posix.cc:35: error: expected initializer before ':' token\nsrc/main/cpp/blaze_util_posix.cc:40: warning: the address of 'cwd' will always evaluate as 'true'\nsrc/main/cpp/blaze_util_posix.cc:41: error: expected primary-expression before 'if'\nsrc/main/cpp/blaze_util_posix.cc:41: error: expected ')' before 'if'\nsrc/main/cpp/blaze_util_posix.cc:45: error: 'cwd' was not declared in this scope\nAt global scope:\ncc1plus: warning: unrecognized command line option \"-Wno-free-nonheap-object\"\nERROR: /home/ucl/eisuc212/python_modules/bazel/src/main/cpp/BUILD:22:1: C++ compilation of rule '//src/main/cpp:client' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer '-std=c++0x' -DBLAZE_OPENSOURCE -iquote . ... (remaining 20 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //src:bazel failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 11.004s, Critical Path: 1.36s\n```\n\nDo you know for any workarounds or at least idea how to fix it. \n", "comments": ["Hi @Botev, it appears as if this is a bazel compile issue, I would recommend following up with at the bazel issues page, since they are better suited to help you :)\n\n(Feel free to re-open if you think this is TensorFlow specific)\n", "I understand, just was hoping that someone encountered it before (as there is no google group atm for TensorFlow). If I get it fixed will update here.\n", "Great, please let us know!  We can update our documentation if this ends up being a common problem.  Thanks!\n"]}, {"number": 99, "title": "Fix when installation on OSX", "body": "Update the instruction to fix installation on OSX for exception like below\n\nOSError: [Errno 1] Operation not permitted: '/tmp/pip-LA3gmg-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info' \n", "comments": ["On my instance I'm getting error:\n\nIOError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/six.py'\n\nI've fixed it by running sudo pip <etc>\n", "You can also install in a virtualenv; six will then be installed locally.\n", "Thank you for this suggestion.  We are not currently accepting pull requests via github.  We will update the [common problems](http://tensorflow.org/get_started/os_setup.md#common_install_problems) section of our Get Started guide appropriately.\n"]}, {"number": 98, "title": "MAC pip install operation not permitted", "body": "MBP 2014. Intel CPU.\n\nAny thoughts? Below was running with sudo\n\nException:\nTraceback (most recent call last):\n  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 211, in main\n    status = self.run(options, args)\n  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 311, in run\n    root=options.root_path,\n  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 640, in install\n    requirement.uninstall(auto_confirm=True)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 716, in uninstall\n    paths_to_remove.remove(auto_confirm)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_uninstall.py\", line 125, in remove\n    renames(path, new_path)\n  File \"/Library/Python/2.7/site-packages/pip/utils/**init**.py\", line 315, in renames\n    shutil.move(old, new)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 302, in move\n    copy2(src, real_dst)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 131, in copy2\n    copystat(src, dst)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 103, in copystat\n    os.chflags(dst, st.st_flags)\nOSError: [Errno 1] Operation not permitted: '/tmp/pip-bX2I_b-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'\n", "comments": ["Hi there, we've seen quite a few configurations where it's been difficult to upgrade the `six` library shipped with OS X to the appropriate version. The most successful approach so far has been to use [HomeBrew](http://brew.sh/), and `brew install python` to get a clean Python setup.\n\nAlternatively, some people have had luck using `sudo easy_install -U six` to upgrade `six` before installing TensorFlow.\n\nCan you try one of these approaches and let us know if it works? Thanks!\n", "(Please re-open if that does not solve the problem, or if our documentation here does not help: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#common_install_problems)\n"]}, {"number": 97, "title": "How to extract predictions", "body": "Hi, can someone either point to code example or documentation how to extract final predictions after the training the model. For example, it would be nice to complement existing tutorials, e.g. mnist, and show additional (final) step to get prediction out of the trained model.\n", "comments": ["```\nprediction=tf.argmax(y,1)\nprint prediction.eval(feed_dict={x: mnist.test.images})\n```\n\nin the fully_connected_feed.py mnist example:\n\n```\n        prediction=tf.argmax(logits,1)\n        best = sess.run([prediction],feed_dict)\n        print(best)\n```\n", "+1\n", "Hi,\nwell I see that step, but if I print the correct_prediction I got\nTensor(\"Equal:0\", shape=TensorShape([Dimension(None)]), dtype=bool) which is\n<class 'tensorflow.python.framework.ops.Tensor'>\n\nand I want to get array of numbers (probabilities). My question is how to get\nit from Tensor then?\n\nOn  0, pannous notifications@github.com wrote:\n\n> # Test trained model\n> \n> correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/tensorflow/tensorflow/issues/97#issuecomment-155491827\n", "Check this response on stackoverflow: https://stackoverflow.com/questions/33633370/how-to-check-the-contents-of-a-tensor-object-in-tensorflow\n", "the array of numbers is returned by eval / run method:\n\n```\nprediction=tf.argmax(y,1)\nprint prediction.eval(feed_dict={x: mnist.test.images})\n```\n", "Thanks, this works if I pass session to eval too.\nHere is working example for those who are interested:\n\n```\nimport input_data\nimport tensorflow as tf\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nx = tf.placeholder(\"float\", shape=[None, 784])\nW = tf.Variable(tf.zeros([784,10]))\nb = tf.Variable(tf.zeros([10]))\ny = tf.nn.softmax(tf.matmul(x,W) + b)\ny_ = tf.placeholder(\"float\", shape=[None, 10])\ncross_entropy = -tf.reduce_sum(y_*tf.log(y))\ntrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n# train data and get results for batches\ninit = tf.initialize_all_variables()\nsess = tf.Session()\nsess.run(init)\n# train the data\nfor i in range(10):\n    batch_xs, batch_ys = mnist.train.next_batch(100)\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\nprint \"accuracy\", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\nprediction=tf.argmax(y,1)\nprint \"predictions\", prediction.eval(feed_dict={x: mnist.test.images}, session=sess)\n```\n\nOn  0, pannous notifications@github.com wrote:\n\n> the array of numbers is returned by eval / run method:\n> \n> ```\n> prediction=tf.argmax(y,1)\n> print prediction.eval(feed_dict={x: mnist.test.images})\n> ```\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/tensorflow/tensorflow/issues/97#issuecomment-155518360\n", "My next question is how to get probabilities of predictions?\n", "just y or y/sum(y) \n\n[per row, see below]\n", "thanks, it works\n\n```\nprobabilities=y\nprint \"probabilities\", probabilities.eval(feed_dict={x: mnist.test.images}, session=sess)\n```\n\nOn  0, pannous notifications@github.com wrote:\n\n> just y or y/sum(y)\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/tensorflow/tensorflow/issues/97#issuecomment-155525064\n", "hold on, we need to norm it per dimension\ni.e.\ny=[[0.8,0.5,0.1],[0.1,0.2,0.4]]\nprobabilities=y/[1.4,0.7]\nlets see how we can use reduce_sum for that ...\ndef reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None):\n...\nprobabilities=y/tf.reduce_sum(y,0)\n", "The output of the tf.nn.softmax(.) should already be normalized so it should just work\n", "In this case yes, but it doesn't harm if we put the general solution here.\n", "Expanding on the above question, when I try the above suggestion (which works fine for the mnist softmax example) on the mnist convnet example I get the following error:\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n```\n\nI have just copied the code from http://www.tensorflow.org/tutorials/mnist/pros/index.md and added the following four lines:\n\n```\n...\nprediction=tf.argmax(y_conv,1)\nprint \"predictions\", prediction.eval(feed_dict={x: mnist.test.images}, session=sess)\n\nprobabilities=y_conv\nprint \"probabilities\", probabilities.eval(feed_dict={x: mnist.test.images}, session=sess)\n```\n\nAnyone knows what this is?\n", "I can answer my own question\n\nThe convnet example has an additional variable in the feed_dict, I missed to add that. In this case the feed_dict should look like this: `feed_dict = {x: [your_image], keep_prob: 1.0}`\n", "Closing -- looks like these issues are resolved.  Please re-open if there's something else to do here.\n", "I have read all the threads here and got another question. I am currently using \n\n`with tf.Graph().as_default():\n    ...\n    probability = tf.nn.softmax(logits)\n`\n\nIn this case how shall I print out or save the probability value in csv format?\n\nThank you in advance!\n", "i have some code like this\r\n> run_fc.py\r\n\r\n```\r\n# Define input placeholders\r\nimages_placeholder = tf.placeholder(tf.float32, shape=[None, IMAGE_PIXELS],  name='images')\r\nlabels_placeholder = tf.placeholder(tf.int64, shape=[None], name='image-labels')\r\n\r\n# Operation for the classifier's result\r\nlogits = two_layer_fc.inference(images_placeholder, IMAGE_PIXELS,\r\n  FLAGS.hidden1, CLASSES, reg_constant=FLAGS.reg_constant)\r\n\r\n# Operation for the loss function\r\nloss = two_layer_fc.loss(logits, labels_placeholder)\r\n\r\n# Operation for the training step\r\ntrain_step = two_layer_fc.training(loss, FLAGS.learning_rate)\r\n\r\n# Operation calculating the accuracy of our predictions\r\naccuracy = two_layer_fc.evaluation(logits, labels_placeholder)\r\n\r\n```\r\n\r\n> two_layer_fc.py:\r\n\r\n\r\n```\r\ndef evaluation(logits, labels):\r\n  '''Evaluates the quality of the logits at predicting the label.\r\n\r\n  Args:\r\n    logits: Logits tensor, float - [batch size, number of classes].\r\n    labels: Labels tensor, int64 - [batch size].\r\n\r\n  Returns:\r\n    accuracy: the percentage of images where the class was correctly predicted.\r\n  '''\r\n\r\n  with tf.name_scope('Accuracy'):\r\n    # Operation comparing prediction with true label\r\n    correct_prediction = tf.equal(tf.argmax(logits,1), labels)\r\n\r\n    # Operation calculating the accuracy of the predictions\r\n    accuracy =  tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n    # Summary operation for the accuracy\r\n    tf.summary.scalar('train_accuracy', accuracy)\r\n\r\n  return accuracy\r\n\r\n```\r\ni want when evaluation funtion that is in \r\n\r\n> two_layer_fc.py file\r\n\r\n find out correct_prediction  after that it will show the predicted label and label that is in labels (original label)\r\n\r\ni tried this adding this:\r\n\r\n> prediction=tf.argmax(y,1)\r\n> print prediction.eval(feed_dict={x: mnist.test.images})\r\n\r\nit only gives me error.\r\n\r\n", "Hi, Can you please check this issue ? https://stackoverflow.com/questions/45225071/exporting-tensorflow-prediction-to-csv-but-the-result-contains-all-zeros", "Hi, I am following the Tensorflow's \"Layer Module\" from this tutorial link https://www.tensorflow.org/tutorials/layers. I find the code here different from the one you have mentioned above. You might be able to help me how can I get the results of the predictions and its respective probabilities.\r\nI need to see it for further understanding the model. And if there is a way I can save the results - predictions and probabilities to csv.\r\n\r\nThank you so much for your time.", "Using the Estimator API, I figured out how to extract the predictions and create a confusion matrix. Maybe it will help someone else out.\r\n\r\nhttps://github.com/knowm/HelloTensorFlow/blob/master/src/iris_DNN_classifier.py\r\n\r\n```\r\npredicted_classes = [p[\"class_ids\"][0] for p in predictions]\r\nprint(\r\n    \"Test Samples, Class Predictions:    {}\\n\"\r\n    .format(predicted_classes))\r\n```\r\n", "Thank you, very helpful.\r\n\r\nFor the DNNLinearCombinedClassifier, I used this:\r\n\r\n`# predicted class`\r\n`predictions = model.predict(input_fn=input_fn)`\r\n`y_pred = [p[\"class_ids\"][0] for p in predictions] `\r\n\r\n`# probability of being predicted as 1`\r\n`predictions = model.predict(input_fn=input_fn)`\r\n`y_prob = [p[\"probabilities\"][1] for p in predictions]`\r\n\r\n\r\nWeirdly, I need to re-compute predictions every time to get the lists \r\n(y_prob would return [] if I don't re-run predictions before running y_prob)\r\n", " y_output = vqa_model.predict([question_features, image_features])\r\nNameError: name 'question_features' is not defined\r\n\r\nwhat would be the solution", "probabilities= []\r\n****in the prediction loop\r\n        probabilities.append(np.max(y.eval(feed_dict={x: [test_set]}, session=sess), axis=1)[0])\r\n\r\n"]}, {"number": 96, "title": "tensorflow-0.5.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.", "body": "Hello,I got the error when i  execute:\"pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\"--------[ tensorflow-0.5.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.].\n", "comments": ["Can you provide more information about your machine, version of python, etc?\n", "The output of the following would be helpful:\n\n``` bash\nuname -a\n```\n\nOur built pip packages are only for 64-bit platforms: I suspect you're either on a 32-bit platform or you're trying to install the linux package on a non-linux machine.\n", "Thanks,i try to install the linux package on a 32-bit platform,so i falled.  @vrv    \n", "I also have the same issue.\nThis is the output of the uname -a\nhaejongs@sclasic02:~/Downloads$ uname -a\nLinux sclasic02 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:18:00 UTC 2015 i686 i686 i686 GNU/Linux\n", "I have upgraded my system,here is the log when i  execute:  `uname -a`  \n  [Linux chenfuduo 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux],and this solve the problem.  @siwonadaddy \n", "Hi @vrv,\n\nI guess it would be helpful to mention in the documentation about the 64-bit dependency of the built package. I almost spent an hour trying to debug the issue. Also, is the installation from source supported on 32-bit machine?\n", "As far as I can tell, we do not support 32-bit machines at all.\n", "I updated the docs to mention Linux 64-bit -- updated in git repo and website should be updated today.\n", "Thanks @ebrevdo and @vrv :-)\n", "I still got this problem when install on my Kali box (4.0.0-kali1-amd64) with this below version\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\nI tried many times but failed, then I have to go with Virtualenv. I don't know it's because TensorFlow doesn't support Kali or not, and I don't have chance to test with Ubuntu. But I don't think that if TensorFlow supports Ubuntu then not with Kali. :)\n", "similar issue solved here by renaming\n\n```\nmv tensorflow-0.7.0-py2-none-linux_x86_64.whl tensorflow-0.7.0-cp27-none-linux_x86_64.whl or \nmv tensorflow-0.7.0-py2-none-linux_x86_64.whl tensorflow-0.7.0-py2-none-any.whl\nsudo pip2 install --upgrade tensorflow-0.7.0-cp27-none-linux_x86_64.whl\n```\n"]}, {"number": 95, "title": "Greedy heuristics may not find the optimal node placement", "body": "The nodes have computational costs and the edges have communication costs making the placement problem very similar to finding the [minimum cost flow](https://en.wikipedia.org/wiki/Minimum-cost_flow_problem) of the computation graph. There are very [simple implementations](https://github.com/search?o=desc&q=Min+cost+flow&ref=searchresults&s=forks&type=Repositories&utf8=%E2%9C%93) to get the global optimal solution(s).\n", "comments": ["@iveney, would you like to take a look at the section 3.2.1 of the [TensorFlow whitepaper](http://download.tensorflow.org/paper/whitepaper2015.pdf) [1] and evaluate the applicability?\n\n[1] Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,\nZhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis,\nJeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,\nAndrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz, Yangqing Jia,\nLukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man\u00e9, Mike Schuster,\nRajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens,\nBenoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,\nVincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas,\nOriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke,\nYuan Yu, and Xiaoqiang Zheng.\nTensorFlow: Large-scale machine learning on heterogeneous systems,\n2015. Software available from tensorflow.org.\n", "I believe the problem is a bit more complicated once you introduce memory constraints and scheduling :).  Regardless, this type of question is probably better suited to the [tensorflow discussion mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss) rather than a github issue.  \n\nThanks for your interest!\n"]}, {"number": 94, "title": "Abandon gerrit and use github for everything", "body": "Gerrit review workflow is very hard to maintain and follow. A lot of project abandoned it and turns to github finally.\n\nReally hope tensorflow will use github for all the cooperation workflow. Google [Kubernetes](https://github.com/kubernetes/kubernetes) and [Docker](https://github.com/docker/docker) are all excellent examples  for how to use github maintain a huge and global scale open source project successfully.\n\ngithub + travis CI + slack is awesome.  Just make everything be a PR :)\n", "comments": [":+1:\n", "+1\n", ":+1: \n", ":+1:\n", "+1\n", "+1\n", "We hear you all -- the current workflow is not ideal and is a pain for us too.  There are several reasons why we can't just switch solely to github today, but since it _is_ a pain for us, we're motivated to try to make things better :).\n\nWe'll keep this bug open to track the request.\n", "+1\n", "@vrv Thanks. btw, if you guys need any help, please fire up related issues, add \"help-needed\" and area label, and I think all the guys here are eager to fix them :)\n", ":+1:\n", "+1\n", "+1\n", "De-duping with https://github.com/tensorflow/tensorflow/issues/26\n", "In my opinion doing code review on GitHub is horrible except for very small fixes / tweaks. In addition, all those merge commits from \"pull requests\" really clutter up the git log.\n\nBlaze (Bazel) uses both Gerrit and GitHub. All external pull requests are not merged directly, but committed through the Gerrit repo. As a result, their commit history looks much cleaner: https://github.com/bazelbuild/bazel/commits/master.\n\nWould you consider keeping a Gerrit mirror and possibly using the Gerrrit-GitHub plugin https://gerrit.googlesource.com/plugins/github/+/master/README.md?\n"]}, {"number": 93, "title": " build failed!  File \"/usr/lib/python2.7/encodings/__init__.py\", line 123       raise CodecRegistryError,\\", "body": "ubgpu@ubgpu:~/github/tensorflow$ PYTHONPATH=/usr/lib/python2.7 bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nFatal Python error: Py_Initialize: Unable to get the locale encoding\n  File \"/usr/lib/python2.7/encodings/**init**.py\", line 123\n    raise CodecRegistryError,\\\n                            ^\nSyntaxError: invalid syntax\nAborted (core dumped)\nubgpu@ubgpu:~/github/tensorflow$ \n", "comments": ["I would recommend trying to unset PYTHONPATH. It is generally not needed, and it causes things to break like this. I do not work for Google, just thought that it may help you as I have read about this problem before. :smiley: \n", "ubgpu@ubgpu:~/github/tensorflow$ echo $PYTHONPATH\n\nubgpu@ubgpu:~/github/tensorflow$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nFatal Python error: Py_Initialize: Unable to get the locale encoding\nImportError: No module named 'encodings'\nAborted (core dumped)\nubgpu@ubgpu:~/github/tensorflow$ \n", "solved.\n\nI forget set the bazel path, also , I install multi version of python\n", "@andyyuan78 hi\uff0cWhat was the solution to this? I'm facing the same issue.what\u2018s the bazel path?", "I met the same error. Please show the solution."]}, {"number": 92, "title": "do we have plans for java api?", "body": "I can see there is only python and C++ api, do we have any plans for java api? or workarounds?\n", "comments": ["Somebody has to write a swig interface file that allow to call C/C++ functions in another language like Java. This is what was done to support python I think If you want you can look into swig documentation and to the current swig interface files to create a Java interface\n", "Please follow:\nhttps://github.com/tensorflow/tensorflow/issues/5\nhttps://github.com/tensorflow/tensorflow/issues/3\n", " Guys, please let me know if you plan to implement java 'wrapper' classes which will call c++ code. \n I can assist with it. Unfortunately i have no time to discover the library by myself but i can spend some time writing implementations.\n", "+1 for java\n", "++ for java! It would be really helpful if someone can do that! \n", "+1 for java! \n", "+1 for java\n", "+1 for java\n", "+1 for java\n", "+1 for java\n", "+1 for java\n", "+1 for java\n", "desperately need a java interface to use tensorflow in enterprise web server\n", "+1 for java\n", "+1 for java\n", "+1 for java\n", "Please use Github reactions on the root post to register your votes.  Thanks!\n"]}, {"number": 91, "title": "import six.moves.copyreg as copyreg error", "body": "ENV: Mac OS X 10.10, System shipped Python 2.7, six 10.10.0\nIn this file, I need to replace `import six.moves.copyreg as copyreg` with `from six.moves import copyreg`\n/Library/Python/2.7/site-packages/google/protobuf/internal/python_message.py\n", "comments": ["Our current suggestion for dealing with incompatible versions of six is to either use a brew install of python, or install the tensorflow package inside a virtualenv.  The virtualenv will guarantee that you install and see the correct version of six.  See [common problems](http://tensorflow.org/get_started/os_setup.md#common_install_problems)\n", "Thanks for your advice. :D\n", "When I try to run the classify_image.py file, it shows an error that six.moves module is not found, even though I have the latest version of the module 'six' installed.\r\nCan anyone help?"]}, {"number": 90, "title": "Fix #89", "body": "", "comments": ["Please note that according to the [README](https://github.com/tensorflow/tensorflow#tensorflow):\n\n```\nNote: Currently we do **not** accept pull requests on github -- see CONTRIBUTING.md for information on how to contribute code changes to TensorFlow through tensorflow.googlesource.com\n\nWe use github issues for tracking requests and bugs, but please see Community for general questions and discussion.\n```\n", "Yeah, sorry about that.  We're working on the better contribution flow.  On the bright side, we already had a few bug reports about this and we've already fixed it -- we'll be pushing out the fix later today.\n"]}, {"number": 89, "title": "Typo in `/tutorials/mnist/beginners/index.md`", "body": "```\nFirst, `tf.log` computes the logarithm of each element of `y`. Next, we multiply each element of `y_` with the corresponding element of `tf.log(y_)`\n```\n\nshould be\n\n```\nFirst, `tf.log` computes the logarithm of each element of `y`. Next, we multiply each element of `y_` with the corresponding element of `tf.log(y)`\n```\n", "comments": ["@brendan-rius, this was apparently fixed in b4629c0 (specifically, [here](https://github.com/tensorflow/tensorflow/commit/b4629c0e9f2b2bfab50ed7a705763421950234d4#diff-4bd18281d0b6ca190e6bec8a175c4706R313))\n"]}, {"number": 88, "title": "Unable to run tensorboard", "body": "Hi all,\nI'm trying to use tensorboard but I can't find the tensorboard executable in my path. I installed tensorflow with pip.\nWhen trying to run it from source I got the following error \n\n```\nWARNING:root:IOError [Errno 2] No such file or directory: '/../tensorflow/external/paper-toggle-button/paper-toggle-button.html' on path /.../tensorflow/external/paper-toggle-button/paper-toggle-button.html\n```\n", "comments": ["I forgot to run --recurse-submodules.\n"]}, {"number": 87, "title": "fixed link to tutorial and some typos", "body": "", "comments": ["Please note that according to the [README](https://github.com/tensorflow/tensorflow#tensorflow):\n\n```\nNote: Currently we do **not** accept pull requests on github -- see CONTRIBUTING.md for information on how to contribute code changes to TensorFlow through tensorflow.googlesource.com\n\nWe use github issues for tracking requests and bugs, but please see Community for general questions and discussion.\n```\n", "@mnemonicflow ok cool done, closing this pull request.\n", "@vrv can you kindly have a look at:\n\nhttps://tensorflow-review.googlesource.com/#/c/1081/\n\nthanks!\n"]}, {"number": 86, "title": "GPU implementations for more ops", "body": "1. Loads of operations in the embedding example are not supported on GPU. Some documentation   detailing this would be good.\n2. I tried to get around the problem by using 'tf.ConfigProto(allow_soft_placement=True)'. However now I get 'Executor failed to create kernel. Invalid argument: AttrValue must not have reference type value of float_ref for attr 'tensor_type'\n\nThanks\nAbhishek\n", "comments": ["Same issue here. tried both word2vec_basic.py and the word2vec code shipped with source. Can anyone share some insight?\n", "I did get it working by forcing TensorFlow to use GPU for only matrix multiplication. It was posted here:\n\nhttp://stackoverflow.com/questions/33624048/fail-to-run-word-embedding-example-in-tensorflow-tutorial-with-gpus\n\nI hoping it will be fixed soon.\n", "@abhishekpatnia Thanks! let me give it a try. Not sure how this will affect performance :(\n", "Is there being work done to support these ops on GPU? Would be happy to chip in if individual efforts are being assigned and tracked somewhere.\n", "We're working on making more kernels runnable on GPUs. In the code, you can tell which kernels support GPU by going to the core/kernels directory to see which ops have .cu.cc cuda files. If you want to help out, pick a CPU only kernel and write a GPU capable version either by using Eigen (for example, see the argmax or the adjust_contrast kernels), or write a plain cuda kernel (for example, see the check_numerics_op).\n\nIn order to avoid duplicating work, I would create an issue called \"XX_op does not have a GPU kernel\", and then leave a comment that you're starting work on this. Then we won't do that internally without checking in with you first.\n\nFinally, when you have something written, you have to submit a patch through tensorflow.googlesource.com (instructions are [here](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md)). \n", "This is too broad of a request, finer grained issues for individual ops are probably better.\n", "The problem still seems to exist. Has there been any progress on this or related issues? \n\nI also wonder if there are \"finer grained issues\"? Just to be able to follow the progress...  \n", "For me, using `GradientDescentOptimizer` instead of ada grad seems to solve the issue - now it runs on gpu (although it doesn't seem to be any faster than cpu) \n", "Please file finer grained issues. It's clear that we need more GPU ops, but we'd love to understand which ones people are actually running into.\n"]}]