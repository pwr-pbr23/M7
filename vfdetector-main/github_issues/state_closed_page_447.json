[{"number": 40435, "title": "neural structured learning for NLP text classification", "body": "I like the idea of neural structured learning, would like to use the adversarial concept on NLP. I'm using bidirection LSTM model to classify a text input and sequence of the words is important. I want it to be able to identify similarity of the sequence of text\r\n\r\ncan I used neural structured learning so that it can generate 'textual perturbation' for training purpose for the given sentence to increase the accuracy of prediction?\r\n\r\n", "comments": ["This is not a question for the Tensorflow source code repository? More something for stackoverflow?", "I'm not sure where to get support for 'how to' or feature question.\n\nOn Sat, Jun 13, 2020, 11:57 AM TheNewSound <notifications@github.com> wrote:\n\n> This is not a question for the Tensorflow source code repository? More\n> something for stackoverflow?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/40435#issuecomment-643663715>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJMGGBS4ZRE5WDORXFN3WFLRWPD2HANCNFSM4N5BVFFA>\n> .\n>\n", "@jazlielee \r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40434, "title": "zsdonghao / u-net-brain-tumor", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I need to implement this code. Please help. I am getting error on train.py module.\r\nTypeError: zoom_multi() got an unexpected keyword argument 'is_random'", "@biswajit310,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/ask) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40433, "title": "Please somebody help me......", "body": " I tried MUNIT-Tensorflow and I have this problem \r\n\r\nsomebody help me please, \r\n\r\nenvironment = python 3.7 \r\ntensorflow version = 1.4 \r\n\r\n\r\nWARNING:tensorflow:From main.py:91: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\r\n\r\nWARNING:tensorflow:From main.py:94: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2020-06-13 21:57:38.695873: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-06-13 21:57:38.711357: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\r\n##### Information #####\r\n gan type :  lsgan\r\n dataset :  summer2winter\r\n max dataset number :  0\r\n batch_size :  1\r\n epoch :  10\r\n iteration per epoch :  100000\r\n style in test phase :  3\r\n\r\n##### Generator #####\r\nresidual blocks :  4\r\n Style dimension :  8\r\n MLP dimension :  256\r\n Down sample :  2\r\n Up sample :  2\r\n\r\n##### Discriminator #####\r\n Discriminator layer :  4\r\n Multi-scale Dis :  3\r\nWARNING:tensorflow:From C:\\Users\\Lee Jong Ann\\Desktop\\study\\Machine Learning\\MUNIT-Tensorflow-master\\MUNIT-Tensorflow-master\\MUNIT.py:236: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\Lee Jong Ann\\Desktop\\study\\Machine Learning\\MUNIT-Tensorflow-master\\MUNIT-Tensorflow-master\\utils.py:19: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 527, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1224, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1018, in _TensorTensorConversionFunction\r\n    (dtype.name, t.dtype.name, str(t)))\r\nValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(\"args_0:0\", shape=(), dtype=float32)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 138, in <module>\r\n    main()\r\n  File \"main.py\", line 98, in main\r\n    gan.build_model()\r\n  File \"C:\\Users\\Lee Jong Ann\\Desktop\\study\\Machine Learning\\MUNIT-Tensorflow-master\\MUNIT-Tensorflow-master\\MUNIT.py\", line 244, in build_model\r\n    trainA = trainA.prefetch(self.batch_size).shuffle(self.dataset_num).map(Image_Data_Class.image_processing, num_parallel_calls=8).apply(batch_and_drop_remainder(self.batch_size)).repeat()\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1776, in map\r\n    self, map_func, num_parallel_calls, preserve_cardinality=False))\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3228, in __init__\r\n    use_legacy_function=use_legacy_function)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2555, in __init__\r\n    self._function = wrapper_fn._get_concrete_function_internal()\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1355, in _get_concrete_function_internal\r\n    *args, **kwargs)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1349, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1652, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1545, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 715, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2549, in wrapper_fn\r\n    ret = _wrapper_helper(*args)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2489, in _wrapper_helper\r\n    ret = func(*nested_args)\r\n  File \"C:\\Users\\Lee Jong Ann\\Desktop\\study\\Machine Learning\\MUNIT-Tensorflow-master\\MUNIT-Tensorflow-master\\utils.py\", line 19, in image_processing\r\n    x = tf.read_file(filename)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 625, in read_file\r\n    \"ReadFile\", filename=filename, name=name)\r\n  File \"C:\\Users\\Lee Jong Ann\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 550, in _apply_op_helper\r\n    (prefix, dtypes.as_dtype(input_arg.type).name))\r\nTypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.", "comments": ["@LeeJongAnn \r\nPlease refer to issues with similar error:\r\n#36456 #30748 #31102 [link](https://stackoverflow.com/questions/56820327/the-name-tf-session-is-deprecated-please-use-tf-compat-v1-session-instead)  [link1](https://github.com/ipazc/mtcnn/issues/40) [Link2](https://github.com/tensorflow/tensorflow/issues/35550)\r\nCan you please upgrade to later version of tensor flow and let us know if you are facing any issues.\r\n", "\r\n> Can you please upgrade to later version of tensor flow and let us know if you are facing any issues.\r\n\r\nThank you , Originally version 2.0 was used , but It doesn't work.. \u3160\u3160", "@LeeJongAnn\r\nPlease let us know if you have referred the links shared and was it helpful.", "> @LeeJongAnn\r\n> Please let us know if you have referred the links shared and was it helpful.\r\n\r\nThanks for trying to help ,I am student and It's final exam period (June 18~ 24) so , \r\nI'll definitely try and let you know ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @LeeJongAnn\r\n> Please let us know if you have referred the links shared and was it helpful.\r\n\r\nI gave up because I couldn't. I'm going to erase it and try it again.\r\n\r\nThank you for trying to help me"]}, {"number": 40432, "title": "Slow computation when no gradients exist w.r.t a layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to train a barebone Neural Machine Translation model with Luong attention (`dot` for calculating the alignment scores). I have gone for a custom training loop and I am getting the following warning which does make sense to me since gradients are not calculated for Embedding layers as far as I know:\r\n\r\n![image](https://user-images.githubusercontent.com/22957388/84569556-35ad9980-ada5-11ea-9540-68137de72532.png)\r\n\r\nIt also slows the computation and one immediate workaround I could imagine was to wrap the single training step within a function and decorate with `tf.function`. But I really could not figure a way out. \r\n\r\n**Describe the expected behavior**\r\n\r\nA workaround to enhance the computation or the overall training loop in general. \r\n\r\n**Standalone code to reproduce the issue**\r\n[Colab Notebook](https://colab.research.google.com/drive/1GpMiXVonmQKQdiOTcDW9XgDnp9K0iL0b?usp=sharing)\r\n\r\n", "comments": ["I have tried in colab with TF version 2.2 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/38cf90d8d3cbe7257fc9843047922038/untitled21.ipynb).Thanks!", "Hi. Any updates on this? "]}, {"number": 40431, "title": "Please Remove Keyword check by append **kwargs in the tf.keras.Model", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): over 2.0 \r\n- Are you willing to contribute it (Yes/No): Tes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n```python\r\nmodel(tensor, any_keyword=anyvalue_such_as_word)\r\n# => TypeError: call() got an unexpected keyword argument 'any_keyword'\r\n```\r\n**Will this change the current api? How?**\r\nYes.\r\nAppend one \"**kwargs\" in this line \r\nhttps://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/engine/network.py#L695\r\n\r\n**Who will benefit with this feature?**\r\nI don't know the benefit of this argument constraint.\r\nAnd also, close the gap between the subclass model and the Functional API.\r\nSo this update will benefit the whole TF user, and developer.\r\n**Any Other info.**\r\nhttps://colab.research.google.com/gist/MokkeMeguru/887eb223d770551ecccb0f09c51fe2e4/please-remove-the-keyword-checker.ipynb", "comments": ["The code file which you are looking for no longer exists in the master branch, it could have been moved to different file. under [keras/engine](https://github.com/keras-team/keras/tree/master/keras/engine), could you please check if the intended changes have been made in the updated code files. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40430, "title": "the document description  of tensorflow java api  is not detailed enough.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@zhaojc001 \r\nPlease provide with details on why are you claiming there is an issue with the documentation", "Tensorflow's Java API does not specify how to use GPU acceleration. The following content is configured in maven, but it has no effect:\r\n<dependency>\r\n  <groupId>org.tensorflow</groupId>\r\n  <artifactId>tensorflow</artifactId>\r\n  <version>1.8.0</version>\r\n</dependency>\r\n<dependency>\r\n  <groupId>org.tensorflow</groupId>\r\n  <artifactId>libtensorflow</artifactId>\r\n  <version>1.8.0</version>\r\n</dependency>\r\n<dependency>\r\n  <groupId>org.tensorflow</groupId>\r\n  <artifactId>libtensorflow_jni_gpu</artifactId>\r\n  <version>1.8.0</version>\r\n</dependency>", "Please tell me how maven is configured, how to set GPU in the code, and how to specify GPU number.", "Please give an example of Java tensorflow API using GPU acceleration, including Maven and code parts, such as image classification.", "@zhaojc001 \r\nPlease refer to [this link](https://medium.com/google-cloud/how-to-invoke-a-trained-tensorflow-model-from-java-programs-27ed5f4f502d) and let us know if it helps.\r\n[Link1](https://eicweb.phy.anl.gov/EIC/tensorflow-for-eic/blob/9bd0e0e06874b558a07a7cb5ae87753bd17dd9d5/tensorflow/docs_src/install/install_java.md)\r\n[Link1](https://www.inspirisys.com/objectdetection_in_tensorflowdemo.pdf)", "when i use maven project,i run java -jar target/tensorflow-test-1.0-SNAPSHOT.jar\uff0cit occurs the following error,please help me,how to solve it:\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: /tmp/tensorflow_native_libraries-1592366046358-0/libtensorflow_jni.so: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory", "Hi, \r\n\r\nSIG-JVM is taking over a lot of TensorFlow's java work.\r\n\r\nYou can contact them them at: jvm@tensorflow.org \r\nTheir repository is: https://github.com/tensorflow/java\r\n\r\nThey may be able to help more than me."]}, {"number": 40429, "title": "Can't load subclassed model 's architecture from keras.layers.serialize(model)", "body": "According to the [guide](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects), I defined a subclass model with get_config method:\r\n\r\n```python\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\nclass ThreeLayerMLP(keras.Model):\r\n    def __init__(self, hidden_units):\r\n        super().__init__()\r\n        self.hidden_units = hidden_units\r\n        self.dense_layers = [layers.Dense(u) for u in hidden_units]\r\n\r\n    def call(self, inputs):\r\n        x = inputs\r\n        for layer in self.dense_layers:\r\n            x = layer(x)\r\n        return x\r\n\r\n    def get_config(self):\r\n        config = {\"hidden_units\": self.hidden_units}\r\n        return config\r\n\r\nmodel = ThreeLayerMLP([64, 64, 10])\r\nserialized_model = keras.layers.serialize(model)\r\nnew_model = keras.layers.deserialize(\r\n    serialized_model, custom_objects={'ThreeLayerMLP': ThreeLayerMLP})\r\n```\r\n\r\nAfter serialized the model, I tried to load it but failed with errors:\r\n\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"demo14.py\", line 35, in <module>\r\n    serialized_model, custom_objects={'ThreeLayerMLP': ThreeLayerMLP})\r\n  File \"D:\\Program Files\\anaconda3\\envs\\tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\", line 109, in deserialize\r\n    printable_module_name='layer')\r\n  File \"D:\\Program Files\\anaconda3\\envs\\tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\", line 373, in deserialize_keras_object\r\n\r\n    list(custom_objects.items())))\r\n  File \"D:\\Program Files\\anaconda3\\envs\\tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\", line 987, in from_config\r\n    config, custom_objects)\r\n  File \"D:\\Program Files\\anaconda3\\envs\\tf2.2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\", line 2018, in reconstruct_from_config\r\n    for layer_data in config['layers']:\r\nKeyError: 'layers'\r\n```\r\n\r\nSo I want to know how to safely load a subclassed model's architecture? Thanks~", "comments": ["I have tried in colab with TF version 2.2, nightly versions(`2.3.0-dev20200614`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0f40a7e00bf059c154086323eee7ef94/untitled19.ipynb).Thanks!", "@AlexanderJLiu If you are looking for serializing a subclass layer, then please follow [this guidie](https://www.tensorflow.org/guide/keras/save_and_serialize#defining_the_config_methods) on TF website. If you want to serialize, a subclassed model then you could you `model.save` and `tf.keras.models.load_model` to load the model. Another approach is to use `save_weights` and instantiate the model, call predict and then use `load_weights`. Please let me know what you think. Thanks!", "@jvishnuvardhan Yes, I've read this [guide](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects) for several  times, \r\nand subclassed layers could be serialized and deserialized correctly.\r\n\r\nThe method `model.save` you provide would save the **whole model** including weights and optimizer state etc. And `save/load weights` just use the weights info with reinstantiating the model.\r\n\r\nWhat I want to know is that is there a way to  just save the **subclassed model's architecture** just like Sequential of Functional models' `get_config method` do?  \r\n\r\nAlso I don't understand that why **subclassed layer** could be serialized/deserialized by that way but **subclassed model** couldn't?\r\n\r\nThanks~", "According to the newest(2020-06-19) update guide [here](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects), It seems that there is no way just to save a subclassed model's architecture **util now**.\r\n\r\nBut We could just load the tensorflow graph of subclassed model using `tf.saved_model.load(\"path_to_my_model\")`. The graph is not a keras object, so we can't use methods like predict or fit.\r\n\r\nAnyway, I'm just curious about the reason, some convincing explanations would be nice for me.\r\n\r\nThanks~", "`tf.saved_model.load(\"path_to_my_model\")` doesn't restore a Keras model (e.g. this is used by Tensroflow Hub to restore their own Layer object). If you want to use the Keras APIs, load with `tf.keras.models.load_model`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40429\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40429\">No</a>\n"]}, {"number": 40428, "title": "Wrong batch size reported when using TPUStrategy", "body": "In the summary, batch size is reported as 4 but I specified it as 32:\r\n```python\r\nfrom os import environ\r\nfrom tensorflow.config import experimental_connect_to_cluster\r\nfrom tensorflow.distribute.cluster_resolver import TPUClusterResolver\r\nfrom tensorflow.distribute.experimental import TPUStrategy\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.tpu.experimental import initialize_tpu_system\r\nimport tensorflow as tf\r\n\r\ntpu_addr = environ.get('COLAB_TPU_ADDR')\r\nresolver = TPUClusterResolver('grpc://' + tpu_addr)\r\nexperimental_connect_to_cluster(resolver)\r\ninitialize_tpu_system(resolver)\r\nstrategy = TPUStrategy(resolver)\r\n\r\nwith strategy.scope():\r\n    source = Input(shape = (320,),\r\n                   batch_size = 32,\r\n                   dtype = tf.int32)\r\n    embedding = Embedding(input_dim = 49, output_dim = 100)(source)\r\n    lstm_1 = LSTM(700,\r\n                  return_sequences = True,\r\n                  dropout = 0.3)(embedding)\r\n    y_pred = TimeDistributed(\r\n        Dense(49, activation = 'softmax'))(lstm_1)\r\n    m = Model(inputs = [source], outputs = [y_pred])\r\n    m.compile(optimizer = 'rmsprop',\r\n              loss = 'sparse_categorical_crossentropy',\r\n              metrics = ['sparse_categorical_accuracy'])\r\n    m.summary()\r\n```\r\nI suppose it is dividing the batch size I gave with the number of replicas available. But shouldn't that be transparent to the user? I want the code I write to work the same no matter what hw I have available (CPU, GPU or TPU). ", "comments": ["Was able to reproduce the issue with TF v2.2. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/cdb487d23951c4590be18bf54c77d1fb/40428.ipynb#scrollTo=sxxO4Lyy5dp-). Thanks!", "Each batch of the given input is divided equally among the multiple replicas\r\n@bjourne In this case you may want to limit the number of replicas to 1.\r\n```python\r\n#strategy = TPUStrategy(resolver)\r\ntopology = tf.tpu.experimental.initialize_tpu_system(resolver)\r\ndevice_assignment = tf.tpu.experimental.DeviceAssignment.build(topology, num_replicas=1)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver, device_assignment=device_assignment)\r\n```\r\nBy default TF maps all available cores for faster performance. ", "I understand how it works and of course I want to use all replicas. But it is very surprising to me that the strategy would modify the model definition automatically. That is very unexpected.", "Hi @bjourne, as @ymodak mentioned, when using TPUStrategy with keras, the input dataset is assumed to be batched by the global batch size, and each batch will get divided across all the replicas. This is also the case for MirroredStrategy, and you can find [this noted in the docs here](https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_tfkerasmodelfit).\r\n\r\nOne way to think about this is to first consider the case of training on a single device, where one step is a pass through a batch, which is 32 examples in your case. In your case with TPUStrategy (or MirroredStrategy with GPUs), each replica receives 4 examples on a single step. Variables are mirrored across your devices, and the updates are calculated by aggregating the gradients calculated on each device (ie across all 32 examples). So even in the distributed case, for a single step, updates are calculated from 32 examples, as is also the case of training on a single device. Note that each epoch will then train faster as you add more devices, and typically, you would want to increase your batch size as you add more accelerators so you can make effective use of the extra computing power.", "Closing this issue now since it is not a bug.", "I guess it is not. You could make it clearer though because the behavior is surprising.", "Thanks for the feedback. I agree with you that it would be useful to make it clearer how batches are being divided across the replicas. It is explained in the guide, but it can still be a bit confusing."]}, {"number": 40427, "title": "when support tflite op: SparseFillEmptyRows", "body": "why not support SparseFillEmptyRows in tflite, and when support?", "comments": ["@hellozmz \r\nPlease provide details on the mentioned requirement. ", "> @hellozmz\r\n> Please provide details on the mentioned requirement.\r\n\r\nnow tf support op:SparseFillEmptyRows, but not support the op in tflite, so I want to know when can you support the op in tflite.", "Do you have a link to a model that requires this? Are you sure this is the only op that is needed? You can try using the following approach to integrate this op, though it will come at the cost of binary size: https://www.tensorflow.org/lite/guide/ops_select", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40426, "title": "Codelab: Recognize Flowers with TensorFlow Lite on Android - emulator crashes", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/#7\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\nAdding clear requirements for running the app on an emulator.\r\n\r\n### Clear description\r\n\r\nI was unable to get the app to fully run on an emulator in Android Studio. It loads once, then when I click 'Allow' on the camera permissions window, it crashes and cannot restart. \r\n\r\nI tried running both the app after following the codelab, and the prebuilt one in the finish directory (having moved the tf model file to its assets directory). I tried various emulator configurations in the AVD manager, including what was shown on screen. There may be some incompatible configuration in the emulator or another requirement that isn't being specified.\r\n\r\n\r\n\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["This codelab is now updated and uses TF Lite Model Maker module  https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android#0\r\nPlease give it a try and let us know if you have any questions.\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40426\">No</a>\n"]}, {"number": 40425, "title": "How to create data generator that outputs a dict?", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04\r\n- TensorFlow version (use command below): tensorflow1.15.2 eager mode\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 8G\r\n\r\n\r\nHow to create a tensorflow data generator that outputs a dict? This generator fetches data from disk (since my data can NOT be loaded to Memory once a time) and send it to my NN. (I am using tensorflow 1.15.2 in eager mode.)\r\n\r\nEach term of my data is a array.\r\nMy training sample like this:\r\n```\r\nJ_2d_0\r\n(1, 25, 3)\r\nJ_2d_1\r\n(1, 25, 3)\r\nJ_2d_2\r\n(1, 25, 3)\r\nJ_2d_3\r\n(1, 25, 3)\r\nJ_2d_4\r\n(1, 25, 3)\r\nJ_2d_5\r\n(1, 25, 3)\r\nJ_2d_6\r\n(1, 25, 3)\r\nJ_2d_7\r\n(1, 25, 3)\r\nJ_2d_8\r\n(1, 25, 3)\r\nJ_2d_9\r\n(1, 25, 3)\r\nimage_0\r\n(1, 720, 720, 3)\r\nimage_1\r\n(1, 720, 720, 3)\r\nimage_2\r\n(1, 720, 720, 3)\r\nimage_3\r\n(1, 720, 720, 3)\r\nimage_4\r\n(1, 720, 720, 3)\r\nimage_5\r\n(1, 720, 720, 3)\r\nimage_6\r\n(1, 720, 720, 3)\r\nimage_7\r\n(1, 720, 720, 3)\r\nimage_8\r\n(1, 720, 720, 3)\r\nimage_9\r\n(1, 720, 720, 3)\r\npose_0\r\n(1, 24, 3, 3)\r\npose_1\r\n(1, 24, 3, 3)\r\npose_2\r\n(1, 24, 3, 3)\r\npose_3\r\n(1, 24, 3, 3)\r\npose_4\r\n(1, 24, 3, 3)\r\npose_5\r\n(1, 24, 3, 3)\r\npose_6\r\n(1, 24, 3, 3)\r\npose_7\r\n(1, 24, 3, 3)\r\npose_8\r\n(1, 24, 3, 3)\r\npose_9\r\n(1, 24, 3, 3)\r\noffset\r\n(1, 27554, 3)\r\nbetas\r\n(1, 1, 10)\r\ntrans_0\r\n(1, 1, 3)\r\ntrans_1\r\n(1, 1, 3)\r\ntrans_2\r\n(1, 1, 3)\r\ntrans_3\r\n(1, 1, 3)\r\ntrans_4\r\n(1, 1, 3)\r\ntrans_5\r\n(1, 1, 3)\r\ntrans_6\r\n(1, 1, 3)\r\ntrans_7\r\n(1, 1, 3)\r\ntrans_8\r\n(1, 1, 3)\r\ntrans_9\r\n(1, 1, 3)\r\n```\r\nI just learnt from \r\nhttps://stackoverflow.com/questions/51136862/creating-a-tensorflow-dataset-that-outputs-a-dict\r\n\r\n```\r\ndef data_gen():\r\n    begin_index = 10\r\n    feeding_size = 1000\r\n    for i in range(begin_index, begin_index + feeding_size):  # range(1): #range(len(gen)):\r\n        print(\"data_generator, yielding. %d\" %i)\r\n        train_dat = pkl.load(open(\r\n            'Training_pairs/shuffled_input_data/shuffle_input_dat270_510_%d.pkl' % i,\r\n            \"rb\"), encoding=\"latin1\") \r\n        yield train_dat\r\n```\r\nTo set the 'output_types' and 'output_shapes' in function  **tf.data.Dataset.from_generator** , I use one specific sample 'st_gt_dat': \r\n```\r\n\r\nst_train_dat = pkl.load(open(\r\n        'training_pairs/shuffled_input_data/shuffle_input_dat270_510_%d.pkl' % 10,\r\n            \"rb\"), encoding=\"latin1\")  \r\n```\r\n\r\n```\r\n dataset = tf.data.Dataset.from_generator(\r\n                data_gen,\r\n                output_types={k: tf.float32 for k in st_train_dat},\r\n                output_shapes={\r\n                               'J_2d_0': (25, 3),\r\n                               'J_2d_1': (25, 3),\r\n                               'J_2d_2': (25, 3),\r\n                               'J_2d_3': (25, 3),\r\n                               'J_2d_4': (25, 3),\r\n                               'J_2d_5': (25, 3),\r\n                               'J_2d_6': (25, 3),\r\n                               'J_2d_7': (25, 3),\r\n                               'J_2d_8': (25, 3),\r\n                               'J_2d_9': (25, 3),\r\n                               'image_0': (720, 720, 3),\r\n                               'image_1': (720, 720, 3),\r\n                               'image_2': (720, 720, 3),\r\n                               'image_3': (720, 720, 3),\r\n                               'image_4': (720, 720, 3),\r\n                               'image_5': (720, 720, 3),\r\n                               'image_6': (720, 720, 3),\r\n                               'image_7': (720, 720, 3),\r\n                               'image_8': (720, 720, 3),\r\n                               'image_9': (720, 720, 3),\r\n                               'pose_0': (24, 3, 3),\r\n                               'pose_1': (24, 3, 3),\r\n                               'pose_2': (24, 3, 3),\r\n                               'pose_3': (24, 3, 3),\r\n                               'pose_4': (24, 3, 3),\r\n                               'pose_5': (24, 3, 3),\r\n                               'pose_6': (24, 3, 3),\r\n                               'pose_7': (24, 3, 3),\r\n                               'pose_8': (24, 3, 3),\r\n                               'pose_9': (24, 3, 3),\r\n                               'offset': (27554, 3),\r\n                               'betas': (1, 10),\r\n                               'trans_0': (1, 3),\r\n                               'trans_1': (1, 3),\r\n                               'trans_2': (1, 3),\r\n                               'trans_3': (1, 3),\r\n                               'trans_4': (1, 3),\r\n                               'trans_5': (1, 3),\r\n                               'trans_6': (1, 3),\r\n                               'trans_7': (1, 3),\r\n                               'trans_8': (1, 3),\r\n                               'trans_9': (1, 3)}\r\n            )\r\n            iter = dataset.make_one_shot_iterator()\r\n            next_elem = iter.get_next()\r\n```\r\n\r\nBut I got error:\r\n```\r\n2020-06-13 12:26:09.452497: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was {'J_2d_0': tf.float32, 'J_2d_1': tf.float32, 'J_2d_2': tf.float32, 'J_2d_3': tf.float32, 'J_2d_4': tf.float32, 'J_2d_5': tf.float32, 'J_2d_6': tf.float32, 'J_2d_7': tf.float32, 'J_2d_8': tf.float32, 'J_2d_9': tf.float32, 'image_0': tf.float32, 'image_1': tf.float32, 'image_2': tf.float32, 'image_3': tf.float32, 'image_4': tf.float32, 'image_5': tf.float32, 'image_6': tf.float32, 'image_7': tf.float32, 'image_8': tf.float32, 'image_9': tf.float32, 'pose_0': tf.float32, 'pose_1': tf.float32, 'pose_2': tf.float32, 'pose_3': tf.float32, 'pose_4': tf.float32, 'pose_5': tf.float32, 'pose_6': tf.float32, 'pose_7': tf.float32, 'pose_8': tf.float32, 'pose_9': tf.float32, 'offset': tf.float32, 'betas': tf.float32, 'trans_0': tf.float32, 'trans_1': tf.float32, 'trans_2': tf.float32, 'trans_3': tf.float32, 'trans_4': tf.float32, 'trans_5': tf.float32, 'trans_6': tf.float32, 'trans_7': tf.float32, 'trans_8': tf.float32, 'trans_9': tf.float32}, but the yielded element was {'J_2d_0': array([[[-0.09427154,  0.41095256,  1.12688104],\r\n        [-0.07444732,  0.25008842,  1.02317508],\r\n        [-0.21482247,  0.25017677,  1.02420145],\r\n        [-0.26052661,  0.05423561,  1.06400284],\r\n        [-0.26534972, -0.11140927,  1.05493748],\r\n        [ 0.06103492,  0.24529497,  1.02426877],\r\n        [ 0.12145394,  0.04935052,  0.96026634],\r\n        [ 0.11658443, -0.12146067,  0.97616193],\r\n        [-0.08933849, -0.14170642,  0.90027466],\r\n        [-0.16977977, -0.14160274,  0.88860529],\r\n        [-0.18017883, -0.42792061,  1.032287  ],\r\n        [-0.22021453, -0.72938154,  1.01864192],\r\n        [-0.00411502, -0.14650323,  0.87453262],\r\n        [-0.01932905, -0.43304803,  1.02202842],\r\n        [-0.0493427 , -0.70912272,  1.03996616],\r\n        [-0.10472216,  0.42129188,  1.11642875],\r\n        [-0.05930027,  0.42130201,  1.15048719],\r\n        [-0.13954859,  0.40598681,  1.07391484],\r\n        [-0.01432628,  0.4059807 ,  1.15703653],\r\n        [-0.00895683, -0.76950105,  0.86484523],\r\n        [ 0.02103647, -0.74940092,  1.0036266 ],\r\n        [-0.06430062, -0.73434386,  0.88763042],\r\n        [-0.25539206, -0.78477752,  0.89525851],\r\n        [-0.28537308, -0.7794058 ,  0.89097358],\r\n        [-0.21487881, -0.74964443,  0.92956732]]]), 'J_2d_1': array([[[-0.14470528,  0.40098775,  1.09027753],\r\n        [-0.08938661,  0.25512539,  1.09985149],\r\n        [-0.1898756 ,  0.25497139,  1.04048552],\r\n        [-0.25517899,  0.05418177,  1.0721085 ],\r\n        [-0.28041397, -0.10633208,  1.06210644],\r\n        [ 0.02589675,  0.25526819,  1.08489046],\r\n        [ 0.08125689,  0.03915851,  0.98820583],\r\n        [ 0.05113377, -0.13659981,  1.00071059],\r\n        [-0.11454961, -0.14654698,  0.8583964 ],\r\n        [-0.18490882, -0.14161643,  0.89889107],\r\n        [-0.2200103 , -0.42274546,  1.05879945],\r\n        [-0.25524315, -0.70927703,  1.07121558],\r\n        [-0.03920179, -0.14673024,  0.83556936],\r\n        [-0.02928373, -0.43793617,  0.94163382],\r\n        [-0.05420431, -0.6940558 ,  0.99540918],\r\n        [-0.15488508,  0.42095556,  1.09184622],\r\n        [-0.12452737,  0.42098428,  1.13112115],\r\n        [-1.        ,  1.        ,  0.        ],\r\n        [-0.04914441,  0.41088668,  1.09895583],\r\n        [-0.07442048, -0.74964099,  0.92894744],\r\n        [-0.03919271, -0.7493945 ,  0.94314416],\r\n        [-0.05922171, -0.7042432 ,  0.86520933],\r\n        [-0.35079933, -0.75939488,  0.91472051],\r\n        [-0.35075437, -0.74451482,  0.92261895],\r\n        [-0.22524563, -0.74429478,  1.00488518]]]), 'J_2d_2': array([[[-0.18007061,  0.40089064,  1.57988512],\r\n        [-0.06942193,  0.26048028,  1.41631738],\r\n        [-0.12455843,  0.2653055 ,  1.24171661],\r\n        [-0.14980594,  0.06440445,  1.0687979 ],\r\n        [-0.21493249, -0.09619188,  1.45641825],\r\n        [-0.02414887,  0.26028943,  1.44538322],\r\n        [-0.01417119,  0.04917884,  1.4911557 ],\r\n        [-0.07438143, -0.14151838,  1.44140335],\r\n        [-0.12463207, -0.14665676,  1.15797935],\r\n        [-0.174891  , -0.14165133,  1.20497881],\r\n        [-0.19992997, -0.41780427,  1.3514439 ],\r\n        [-0.22037526, -0.69424658,  1.42331727],\r\n        [-0.06435296, -0.15173715,  1.11622622],\r\n        [-0.05439563, -0.42811827,  1.50000748],\r\n        [-0.05932742, -0.71433716,  1.45640498],\r\n        [-0.1798271 ,  0.42119778,  0.20291102],\r\n        [-0.16965293,  0.42096863,  1.62150611],\r\n        [-1.        ,  1.        ,  0.        ],\r\n        [-0.08957527,  0.41106622,  1.63782675],\r\n        [-0.15477217, -0.75457873,  1.3277638 ],\r\n        [-0.12454928, -0.77448042,  1.21634246],\r\n        [-0.04423719, -0.74935678,  1.35899541],\r\n        [-0.3408351 , -0.72440123,  1.16838346],\r\n        [-0.3358094 , -0.70921662,  1.2223608 ],\r\n        [-0.21003629, -0.72430655,  1.45245355]]]), 'J_2d_3': array([[[-0.18008392,  0.38077087,  2.02785423],\r\n        [-0.06454006,  0.28027766,  1.44454568],\r\n        [-0.04927219,  0.29521328,  1.28410468],\r\n        [ 0.06589895,  0.17465382,  0.31654373],\r\n        [ 0.06635327,  0.14971188,  0.25575968],\r\n        [-0.09464573,  0.26533813,  1.74140177],\r\n        [-0.13451585,  0.05445549,  1.7655285 ],\r\n        [-0.18508168, -0.11650477,  1.68718063],\r\n        [-0.0944325 , -0.1215602 ,  1.36114065],\r\n        [-0.08451241, -0.12145738,  1.00634772],\r\n        [-0.13489544, -0.42298553,  1.7404709 ],\r\n        [-0.16969479, -0.66922294,  1.65285767],\r\n        [-0.09939567, -0.12655366,  1.40371122],\r\n        [-0.08440387, -0.42815458,  1.65241455],\r\n        [-0.08439801, -0.70905433,  1.77061931],\r\n        [-1.        ,  1.        ,  0.        ],\r\n        [-0.1751137 ,  0.41097099,  2.00782743],\r\n        [-1.        ,  1.        ,  0.        ],\r\n        [-0.12960182,  0.41097291,  1.945956  ],\r\n        [-0.1899828 , -0.74443344,  1.84536047],\r\n        [-0.15979638, -0.75455385,  1.68852475],\r\n        [-0.05924096, -0.74434048,  1.85598338],\r\n        [-0.23519866, -0.70409061,  1.27245307],\r\n        [-0.23017727, -0.68417812,  1.14763897],\r\n        [-0.14990367, -0.70405117,  1.17151459]]]), 'J_2d_4': array([[[-1.        ,  1.        ,  0.        ],\r\n        [-0.05937093,  0.255393  ,  1.91558444],\r\n        [ 0.03615684,  0.25536264,  1.74137026],\r\n.........\r\n```\r\nIt seems like we are using an array but the output_types is tf.float. How can I fix this?\r\n```\r\n                output_types={k: tf.float32 for k in st_train_dat},\r\n\r\n```\r\nAnyone can help?\r\n\r\nThanks in advance!\r\n\r\n", "comments": ["@OOF-dura,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Hey @OOF-dura and @amahendrakar  ,\r\nI am actually stuck with an exactly similar error, just the change in data is there. Otherwise, the whole error is same. Have you solved the error? If so, I would really appreciate if you can share the solution here. Thanks in advance!"]}, {"number": 40424, "title": "How to bind the tensor data for some node?", "body": "HI :\r\n    I use some other distributed-train-framework got a model include meta_graph.pb and param data separate\uff0c and the checkpoint format is different  from tensorflow,  In order to speed the online predict service, avoid build some tensor frequently, I want to bind some param data in some tensor-node, like bias and layer. Could you show me how to do this?\r\n", "comments": ["@haolujun \r\n\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40423, "title": "CUDNN8 + CUDA 10.2 build?", "body": "Hi,\r\nsimilar to issue requesting a CUDA 11 build:\r\nhttps://github.com/tensorflow/tensorflow/issues/40227\r\nI think the most important of CUDA+CUDNN updates in relation to performance is CUDNN library updates..\r\nseeing that CUDNN 8 ships with a library with CUDA 10.2 support and Tensorflow already supports CUDA 10.x, just asking if should be possible to integrate CUDNN 8 support faster than CUDA 11 and ship some nighlty build with CUDA 10.x+CUDNN 8 to test performance updates brought by this version..\r\nthanks..\r\n\r\n", "comments": ["Hi Oscar, it's not really much less work to set up nightly releases for cuDNN 8 with CUDA 10.2 than going straight to CUDA 11. So I would rather do the latter, but it means that TF 2.3 will be released for CUDA 10.1 and cuDNN 7.\r\n\r\nThat said, the code is ready and you should be able to build TF for any combination of CUDA and cuDNN today. Is that an option for you?", "Hi @chsigg,\r\ngood to know code is ready.. but lazy to build by myself.. will wait for TF 2.4 nightly builds, once 2.3 is branched, then this should be using CUDNN 8, right? I say because seems TF 2.3 branching seems coming next week anyway..\r\nthanks..", "I was able to use these for CUDA 10.2 with cuDNN 7.6.5:  https://github.com/fo40225/tensorflow-windows-wheel.\r\n", "> good to know code is ready.. but lazy to build by myself.. will wait for TF 2.4 nightly builds,\r\n\r\n@oscarbg,\r\nThe stable version of TF v2.4 is released it is compatible with CUDA 11.0 with cuDNN 8.0.\r\n\r\nCould you please let us know if this is still an issue? Thanks!", "it\u2019s OK.. thanks..", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40423\">No</a>\n"]}, {"number": 40422, "title": "AttributeError: module 'tensorflow' has no attribute 'compat'", "body": "---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-1-1e914dd8c3aa> in <module>\r\n      1 get_ipython().run_line_magic('matplotlib', 'inline')\r\n      2 import matplotlib.pyplot as plt\r\n----> 3 import tensorflow as tf\r\n      4 import numpy as np\r\n      5 import pandas as pd\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     99 \r\n    100 # We still need all the names that are toplevel on tensorflow_core\r\n--> 101 from tensorflow_core import *\r\n    102 \r\n    103 # These should not be visible in the main tf module.\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\__init__.py in <module>\r\n     44 from . _api.v2 import autograph\r\n     45 from . _api.v2 import bitwise\r\n---> 46 from . _api.v2 import compat\r\n     47 from . _api.v2 import config\r\n     48 from . _api.v2 import data\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py in <module>\r\n     37 import sys as _sys\r\n     38 \r\n---> 39 from . import v1\r\n     40 from . import v2\r\n     41 from tensorflow.python.compat.compat import forward_compatibility_horizon\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py in <module>\r\n     30 from . import autograph\r\n     31 from . import bitwise\r\n---> 32 from . import compat\r\n     33 from . import config\r\n     34 from . import data\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py in <module>\r\n     37 import sys as _sys\r\n     38 \r\n---> 39 from . import v1\r\n     40 from . import v2\r\n     41 from tensorflow.python.compat.compat import forward_compatibility_horizon\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py in <module>\r\n     27 \r\n     28 from . import compat\r\n---> 29 from tensorflow._api.v2.compat.v1 import app\r\n     30 from tensorflow._api.v2.compat.v1 import audio\r\n     31 from tensorflow._api.v2.compat.v1 import autograph\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py in <module>\r\n     37 import sys as _sys\r\n     38 \r\n---> 39 from . import v1\r\n     40 from . import v2\r\n     41 from tensorflow.python.compat.compat import forward_compatibility_horizon\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py in <module>\r\n     30 from . import autograph\r\n     31 from . import bitwise\r\n---> 32 from . import compat\r\n     33 from . import config\r\n     34 from . import data\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py in <module>\r\n     37 import sys as _sys\r\n     38 \r\n---> 39 from . import v1\r\n     40 from . import v2\r\n     41 from tensorflow.python.compat.compat import forward_compatibility_horizon\r\n\r\n~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py in <module>\r\n    665 _current_module = _sys.modules[__name__]\r\n    666 try:\r\n--> 667   from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n    668   _current_module.__path__ = (\r\n    669       [_module_util.get_parent_dir(estimator)] + _current_module.__path__)\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\__init__.py in <module>\r\n      8 import sys as _sys\r\n      9 \r\n---> 10 from tensorflow_estimator._api.v1 import estimator\r\n     11 \r\n     12 del _print_function\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py in <module>\r\n      8 import sys as _sys\r\n      9 \r\n---> 10 from tensorflow_estimator._api.v1.estimator import experimental\r\n     11 from tensorflow_estimator._api.v1.estimator import export\r\n     12 from tensorflow_estimator._api.v1.estimator import inputs\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py in <module>\r\n      8 import sys as _sys\r\n      9 \r\n---> 10 from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n     11 from tensorflow_estimator.python.estimator.canned.kmeans import KMeansClustering as KMeans\r\n     12 from tensorflow_estimator.python.estimator.canned.linear import LinearSDCA\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py in <module>\r\n     31 from tensorflow.python.keras.utils import losses_utils\r\n     32 from tensorflow.python.util.tf_export import estimator_export\r\n---> 33 from tensorflow_estimator.python.estimator import estimator\r\n     34 from tensorflow_estimator.python.estimator.canned import head as head_lib\r\n     35 from tensorflow_estimator.python.estimator.canned import optimizers\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py in <module>\r\n     51 from tensorflow_estimator.python.estimator import model_fn as model_fn_lib\r\n     52 from tensorflow_estimator.python.estimator import run_config\r\n---> 53 from tensorflow_estimator.python.estimator import util as estimator_util\r\n     54 from tensorflow_estimator.python.estimator.export import export_lib\r\n     55 from tensorflow_estimator.python.estimator.mode_keys import ModeKeys\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py in <module>\r\n     73 \r\n     74 \r\n---> 75 class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\n     76   \"\"\"Creates a SessionRunHook that initializes the passed iterator.\"\"\"\r\n     77 \r\n\r\nAttributeError: module 'tensorflow' has no attribute 'compat'", "comments": ["Hi everyone\r\nafter a long attempt to install tensorflow gpu version by following this tutorial:\r\nhttps://www.youtube.com/watch?v=qrkEYf-YDyI&t=295s\r\nI always find myself facing the above error. Can someone please help me?", "What is the TF version you are trying to install? Also what steps did you follow?", "You can try uninstalling and re-installing TensorFlow. Also, check this link https://www.tensorflow.org/guide/migrate ", "> \r\n> \r\n> What is the TF version you are trying to install? Also what steps did you follow?\r\n\r\nAt first I uninstalled anaconda and all the NVIDIA programs I had before, to start over from scratch. \r\nThen I followed every step of this tutorial in detail:\r\nhttps://www.youtube.com/watch?v=qrkEYf-YDyI\r\nStep 1: I have NVIDIA Geforce GTX 1050 Ti, I installed the GTX 1650 driver\r\nStep 2: I downloaded the updated Setup Script provided in https://github.com/jeffheaton/t81_558_deep_learning\r\nTo search for compatible version of Tensorflow 2.1.0:  https://www.tensorflow.org/install/gpu?hl=fr\r\nStep 3: I installed CUDA Toolkit 10.1\r\nStep 4: I installed cuDNN  7.6.5 for Cuda 10.1\r\nI've added  all the necessary paths in my path environment \r\nStep 5: I installed TensorRT 6.0\r\nStep 6: Once I installed miniconda,  i did the following setup commands using my command prompt:\r\n-conda\r\n-conda install jupyter\r\n-Once jupyter installation is done, I run the installaton script downloaded in step 2 using this command dir *.yml.\r\nThen, i run this command: conda env create -v -f tensorflow-gpu.yml, It took me a long time. \r\nLater I used \"conda env create -f tensorflow-gpu.yml\". Again, several things have been installed.\r\nJust after i run: python -m ipykernel install --user --name tensorflow --display-name \"Python 3.7 (tensorflow)\" . Then python\r\nOnce tensorflow activated using \"conda activate tensorflow\", I get the error on top when I try to import Tensorflow as tf\r\n\r\n \r\n\r\n\r\n\r\n", "> \r\n> \r\n> You can try uninstalling and re-installing TensorFlow. Also, check this link https://www.tensorflow.org/guide/migrate\r\n\r\nI'm still getting the same error, even with the reinstallation of tensorflow using pip. ", "You can follow the steps mentioned in the article below and check if it works.  \r\nhttps://towardsdatascience.com/tensorflow-gpu-installation-made-easy-use-conda-instead-of-pip-52e5249374bc\r\n\r\nIf it does not work, try pip install tensorflow==2.1. Found this here: https://github.com/tensorflow/tensorflow/issues/37525. \r\n\r\n> > You can try uninstalling and re-installing TensorFlow. Also, check this link https://www.tensorflow.org/guide/migrate\r\n> \r\n> I'm still getting the same error, even with the reinstallation of tensorflow using pip.\r\n\r\n", "> \r\n> \r\n> You can follow the steps mentioned in the article below and check if it works.\r\n> https://towardsdatascience.com/tensorflow-gpu-installation-made-easy-use-conda-instead-of-pip-52e5249374bc\r\n> \r\n> If it does not work, try pip install tensorflow==2.1. Found this here: #37525.\r\n> \r\n> > > You can try uninstalling and re-installing TensorFlow. Also, check this link https://www.tensorflow.org/guide/migrate\r\n> > \r\n> > \r\n> > I'm still getting the same error, even with the reinstallation of tensorflow using pip.\r\n\r\nSame problem even with pip install tensorflow==2.1  ! Sorry, i already saw that issue ", "> the steps mentioned in the article\r\n\r\nThank you for this article. I will follow these steps", "Please properly fill in issue template and use the proper Markdown formatting around errors and code blocks.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I have the same exact issue Here is my post I cant find a working solution for this issue\r\n[https://stackoverflow.com/questions/62622704/attributeerror-module-tensorflow-has-no-attribute-compat-when-loading-tf-co](url)\r\nIn google I see post to install MV C++ i already have VS 2019 installed", "Same issue for us.\r\nWe have installed the same combo on another machine ,,, it works.\r\nHere we have a notebook with internal graphics card and one additional GTX 1650\r\nGTX driver: 442.70\r\nCUDA 10.1\r\ncuDNN 7.6.5.32\r\nTensorRT 6.0\r\nsystem path changed like specified\r\nWe are using anaconda for test purpose.\r\npackages installed all via conda install - no pip.\r\n", "ISSUE FIXED for me\r\n\r\nIndeed the command \"conda install tensorflow-gpu==2.1.0\" installed version 2.2.0 of tensorflow-estimator.\r\nAfter \"conda install tensorflow-estimator==2.1.0\" everything works fine", "> This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\r\n\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40422\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40422\">No</a>\n", "After \"conda install tensorflow-estimator==2.1.0\", everything works fine for me too . ", "> ISSUE FIXED for me\r\n> \r\n> Indeed the command \"conda install tensorflow-gpu==2.1.0\" installed version 2.2.0 of tensorflow-estimator.\r\n> After \"conda install tensorflow-estimator==2.1.0\" everything works fine\r\n\r\nThanks for your solution! It works for me too."]}, {"number": 40420, "title": "'tf.Dilation2D' op is neither a custom op nor a flex op", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab, python 3.6\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source): \r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\r\n\r\n---------------------------------------------------------------------------\r\n\r\nConverterError                            Traceback (most recent call last)\r\n\r\n<ipython-input-6-6ce9f2d0000a> in <module>()\r\n      6                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n      7 \r\n----> 8 tflite_model = converter.convert()\r\n      9 \r\n     10 # Save the TF Lite model.\r\n\r\n2 frames\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-06-12 18:51:22.076900: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.\r\n2020-06-12 18:51:22.076954: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.\r\n2020-06-12 18:51:22.626844: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\r\n2020-06-12 18:51:22.954133: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n2020-06-12 18:51:23.172150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000134999 Hz\r\n2020-06-12 18:51:23.172487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-12 18:51:23.172520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-12 18:51:23.180594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-12 18:51:23.271482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.271997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-12 18:51:23.272026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\r\n2020-06-12 18:51:23.272188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.272524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\r\ncoreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-12 18:51:23.272923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-12 18:51:23.274901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-12 18:51:23.276599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-12 18:51:23.277233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-12 18:51:23.279053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-12 18:51:23.279837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-12 18:51:23.283468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-12 18:51:23.283603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.284015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.285247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-06-12 18:51:23.288818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-12 18:51:23.293809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-12 18:51:23.293841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-06-12 18:51:23.293870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-06-12 18:51:23.297246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.297674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-12 18:51:23.298025: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-06-12 18:51:23.298071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5523 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\r\n2020-06-12 18:51:30.236028: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.\r\nloc(\"Dilation2D\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_1\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_2\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_3\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_4\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_5\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_6\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_7\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_8\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_9\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_10\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_11\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_12\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_13\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_14\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_15\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_16\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_17\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_18\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_19\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_20\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_21\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_22\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_23\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_24\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_25\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_26\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_27\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_28\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_29\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_30\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_31\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nloc(\"Dilation2D_32\"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main'\r\nOps that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"Dilation2D\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_1\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_2\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_3\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_4\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_5\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_6\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_7\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_8\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_9\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_10\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_11\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_12\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_13\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_14\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_15\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_16\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_17\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_18\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_19\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_20\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_21\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_22\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_23\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_24\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_25\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_26\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_27\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_28\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_29\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_30\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_31\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(\"Dilation2D_32\"): 'tf.Dilation2D' op is neither a custom op nor a flex op\r\n<unknown>:0: error: failed while converting: 'main'\r\nOps that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nFirst download this saved model\r\nhttps://drive.google.com/file/d/136KmfVwBT2htxPDZeYw4-TXmxPYe7Vsa/view?usp=sharing\r\nSecond run:\r\n```\r\nimport tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('saved')\r\nconverter.target_spec.supported_types = [tf.float16]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n```\r\n\r\nI am posting this to request the Dilation2D op for tflite. Thanks.", "comments": ["@thaink could you help adding tf.Dilation2D op to flex?", "Sure. let me make a PR.", "> \r\n> \r\n> Sure. let me make a PR.\r\n\r\nAny updates?", "The op is added at the head of master. Could you check?", "> \r\n> \r\n> The op is added at the head of master. Could you check?\r\n\r\nWow, thank you. I didn't get a notification of this comment. I'll check it out right now!", "> Sure. let me make a PR.\r\n\r\nerror: 'tf.ConcatV2' op is neither a custom op nor a flex op\r\nerror: 'tf.All' op is neither a custom op nor a flex op\r\n\r\ncould you please fixed similar op tf.ConcatV2 and tf.All for tflite convert ?", "@AloneGu Both `tf.ConcatV2` and `tf.All` ops can be supported via Select TF ops. Please convert your model with the Select TF op set.\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\nhttps://www.tensorflow.org/lite/guide/reduce_binary_size", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40420\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40420\">No</a>\n"]}, {"number": 40419, "title": "ValueError: we need atleast 1 value to plot word cloud,  got 0", "body": "\r\nnormal_words = ' '.join([text for text in combi['tidy_tweet'][combi['label'] == 0]]) wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words) plt.figure(figsize=(10, 7)) plt.imshow(wordcloud, interpolation=\"bilinear\") plt.axis('off') plt.show()\r\n\r\nValueError: we need atleast 1 word to plot word cloud, got 0.", "comments": ["@AasthaNagpal,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40418, "title": "Building Tensorflow from the source for the second time fails", "body": "I am trying to build Tensorflow from the source (master branch) to get **AVX2** problem solved and get training faster, on my \r\n- **windows 10** machine \r\n-  intel(R) cpu Core i78650U 1.90GHz 2.11  which apparently doesn't have GPU support.\r\n- **Python 3.7.4**.\r\nFirst time I set my mavx2 and mavx flags when running configure.py and then I tried this command:\r\n`bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nIt ran quite fast and built successfully though I could read in the log:\r\n\r\n> cl : Command line warning D9002 : ignoring unknown option '-mavx'\r\n> cl : Command line warning D9002 : ignoring unknown option '-mavx2'\r\n> cl : Command line warning D9002 : ignoring unknown option '-mfma'\r\n> cl : Command line warning D9002 : ignoring unknown option '-mfpmath=both'\r\n> cl : Command line warning D9002 : ignoring unknown option '-msse4.2'\r\n> cl : Command line warning D9002 : ignoring unknown option '-fno-strict-aliasing'\r\n> cl : Command line warning D9002 : ignoring unknown option '-fexceptions' so these options aren't known\r\n\r\nI made a wheel anyway and I could run the train command, however I am getting this warning:\r\n\r\n>  This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\n> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n\r\nand it doesn't run any faster.\r\nI decided to manipulate the flags and run the bazel build again but now it fails! I cannot compile it anymore and I don't know if the previous build is failing this one or what?\r\nHow should I clean the previous build/installation? Should I checkout the code again?\r\n\r\nAnd by the way what should I set my flags to, to get it right this time?\r\n\r\n", "comments": ["@shilan \r\nPlease refer to this [link](https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u) and let us know if it helps.\r\n#37876 #35052 #35056\r\n\r\n", "`bazel clean --expunge`", "@Saduf2019 I had seen this stackoverflow ticket and this one [this one](https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions?rq=1) too. As a matter of fact I ran the command from their suggestions. Otherwise the one suggested by **Intel** or **tensorflow document** gets stuck somewhere and doesn't continue from there.\r\n\r\n@mihaimaruseac thanks for the clean command, I am going to a mini vacation but I will give it a try when I am back.", "@shilan \r\nIn that case can we please close this issue and in case you still face an issue after your vacation you can open an issue.", "I will be back next week, but closing this might be a false indication that it solved the problem, which it didn't. I ran the commands they had suggested and none worked for me. The only thing I haven't tried though is the downloading the windows compiled wheel that @King has suggested. However that doesn't solve my problem entirely. What if I need to change the tensorflow code and compile it again. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I ran the command provided by Intel. It doesn't set any flags for avx2 or avx but it also got stock for 2 days and I just stopped it.\r\nIt is so weird that there is no clear command or flag to build tensorflow with **avx2** flags on **windows** platform in tensorflow documents or anywhere! \r\nI just cannot believe there is no certain or tested way of doing this! ", "I am gonna close this issue, but it doesn't mean that it is resolved. It just means I gave up on tensorflow and intel poor documentation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40418\">No</a>\n"]}, {"number": 40417, "title": "ValueError: Unable to fit model on a built graph. ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n\r\n\r\n\r\n**Hello, I am trying to build a model that relies on the concept of virtual adversarial training for text classification. The model involves the functional API of Keras and I have been to build a model graph. However, there is something wrong when I try to fit my training dataset on the model. Please suggest to me where I might be going wrong in the process.\r\n\r\nVirtual Adversarial Training involves calculating KL DIvergence between two probability distribution. The shape of train data is displayed as well to get a better understanding about the problem. The code has been inspired from the following link but I have changed the domain to text preprocessing and is more advanced.\r\n\r\nMore information: \r\nCode: [https://gist.github.com/divamgupta/c778c17459c1f162e789560d5e0b2f0b]\r\nTheory: [https://divamgupta.com/unsupervised-learning/semi-supervised-learning/2019/05/31/introduction-to-virtual-adversarial-training.html]\r\n\r\nGoogle Colab link for below code: [https://colab.research.google.com/drive/1sdv-sGE80HwdPKkl_p3gakhkxgKO-zRv?usp=sharing]\r\n**\r\n\r\n**\r\nCODE\r\n**\r\n\r\n\r\n`\r\nimport numpy as np\r\nimport random\r\nimport time\r\n#------------------- Tensorflow\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Model, Sequential\r\nfrom tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Bidirectional\r\n\r\nMAX_VOCAB_SIZE = len(word_index) + 1 # maximum no of unique words\r\nMAX_DOC_LENGTH = 500 # maximum no of words in each sentence\r\nEMBEDDING_DIM = 300 # Embeddings dimension from Glove directory\r\n\r\ndef compute_kld(p_logit, q_logit):\r\n  p = tf.nn.softmax(p_logit)\r\n  q = tf.nn.softmax(q_logit)\r\n  kl_score = tf.reduce_sum( p * (tf.math.log(p+1e-16) - tf.math.log(q+1e-16)), axis = 1)\r\n  return kl_score # lower kl means closer the distributions are\r\n\r\ninputs = Input(shape=(MAX_DOC_LENGTH,), name=\"Seq_Input\") # Text Sequence is the first input\r\n#inputs = tf.Variable(tf.zeros(shape=(MAX_DOC_LENGTH,)))\r\n\r\ndef createEmbd(inputs): # Creates Embeddings for a sequence of words\r\n  return layers.Embedding(input_dim=MAX_VOCAB_SIZE,\r\n                    output_dim=EMBEDDING_DIM,\r\n                    input_length = MAX_DOC_LENGTH,\r\n                    trainable=True,\r\n                    mask_zero=True,\r\n                    name=\"Keras_Embedding\")(inputs)\r\n\r\ninput_emb = createEmbd(inputs)\r\nnoise_emb = tf.random.uniform(shape=tf.shape(input_emb)) # Idea is to add noise to these embeddings\r\n#noise_emb = tf.math.add(input_emb, noise_emb)\r\nnoise_emb = input_emb + noise_emb\r\n\r\ninput_h1 = layers.LSTM(units=128,name=\"Input_h1\")(input_emb)\r\nnoise_h1 = layers.LSTM(units=128,name=\"Noise_h1\")(noise_emb)\r\n\r\np_logit = layers.Dense(units=16, activation='relu', name=\"p_logit\")(input_h1)\r\np_logit_r = layers.Dense(units=16, activation='relu', name=\"p_logit_r\")(noise_h1)\r\n\r\nwith tf.GradientTape(watch_accessed_variables=False) as tape:\r\n    tape.watch(noise_emb)\r\n    kl_score = compute_kld(p_logit, p_logit_r)\r\n    kl_score = tf.convert_to_tensor(kl_score, dtype=tf.float32)\r\ngrads = tape.gradient(kl_score, noise_emb) # Differentiate kl_score with respect to noise_embd\r\n\r\n.#p_logit = tf.stop_gradient(p_logit)\r\n.#p_logit_r = tf.stop_gradient(p_logit_r)\r\n\r\n.# Due to some reason the first execution returned \"None\" for gradients so manually added the shape to be able to build the model\r\nif grads is None:\r\n  grads = tf.random.uniform(shape=tf.shape(noise_emb)) \r\n\r\nvadv_emb = tf.math.add(input_emb, grads)\r\nvadv_h1 = layers.LSTM(units=128,name=\"vadv_h1\")(vadv_emb)\r\nq_logit = layers.Dense(units=16, activation='relu', name=\"q_logit\")(vadv_h1)\r\n\r\nvat_loss = compute_kld(p_logit, q_logit) # I need to add this vat loss(Scalar) to the final cost function\r\n\r\n.# logits = layers.average([p_logit, p_logit_r, q_logit])\r\noutputs = layers.Dense(units=1, activation='softmax', name=\"output\")(p_logit)\r\nmodel = keras.Model(inputs, outputs)\r\n\r\nmodel.add_loss(vat_loss)\r\n\r\n.# Not sure if this graph has any problem\r\nkeras.utils.plot_model(model, show_shapes=True, show_layer_names=True)\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss= 'binary_crossentropy',metrics=['accuracy','precision'])\r\n\r\n# Shuffle data random before splitting\r\nindices = np.arange(sequences.shape[0])\r\nrandom.Random(1).shuffle(indices)\r\ndata = sequences[indices]\r\nlabels = y[indices]\r\n\r\nnum_test_samples = int(0.2 * data.shape[0])\r\nx_train = data[:-num_test_samples]\r\ny_train = labels[:-num_test_samples]\r\nx_test = data[-num_test_samples:]\r\ny_test = labels[-num_test_samples:]\r\nprint(x_train.shape, y_train.shape)\r\nprint(x_train[0].shape, y_train[0].shape)\r\n\r\nOutput:\r\n(400, 500) (400,)\r\n(500,) ()\r\n`\r\n`train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\ntrain_dataset.take(1)\r\n# output <TakeDataset shapes: ((500,), ()), types: (tf.int32, tf.int64)>\r\n\r\n**model.fit(train_dataset,** epochs=2, batch_size=40)\r\n#model.fit(x_train, y_train, epochs=2, validation_split=0.2, shuffle=True, batch_size=32)\r\n\r\n`\r\n\r\n\r\n\r\n\r\n**Any other info/logs**\r\nError: \r\nEpoch 1/2\r\nWARNING:TensorFlow:Model was constructed with shape (None, 500) for input Tensor(\"Seq_Input:0\", shape=(None, 500), dtype=float32), but it was called on an input with incompatible shape (500, 1).\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-113-cdea0e86cd74> in <module>()\r\n----> 1 model.fit(train_dataset, epochs=2, batch_size=40)\r\n      2 #model.fit(x_train, y_train, epochs=2, validation_split=0.2, shuffle=True, batch_size=32)\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step  **\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:213 __call__\r\n        batch_dim = array_ops.shape(y_t)[0]\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:984 _slice_helper\r\n        name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1150 strided_slice\r\n        shrink_axis_mask=shrink_axis_mask)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:10179 strided_slice\r\n        shrink_axis_mask=shrink_axis_mask, name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\r\n        attrs=attr_protos, op_def=op_def)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\r\n        compute_device)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\r\n        op_def=op_def)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1817 __init__\r\n        control_input_ops, op_def)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\r\n        raise ValueError(str(e))\r\n\r\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.**\r\n", "comments": ["@lokesharma-dev \r\n\r\nRequest you to share TF version you are using?.Please, share colab link or simple standalone code with proper indentation and supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram \r\nTensorflow 2.2.0\r\nColab link: [https://colab.research.google.com/drive/1sdv-sGE80HwdPKkl_p3gakhkxgKO-zRv?usp=sharing](url)\r\n\r\nThe files required are attached. In case anything is not accessible. Kindly notify.\r\nThanks for your time.\r\n\r\n[npy_files.zip](https://github.com/tensorflow/tensorflow/files/4778628/npy_files.zip)\r\n", "I have tried in colab with TF version 2.2, nightly (`2.3.0-dev20200614`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d94285436c4b8a589cc958d4757482e6/untitled20.ipynb).Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40417\">No</a>\n"]}, {"number": 40416, "title": "TFLite model not working with png images", "body": "Hello,\r\n\r\nI have trained a semantic segmentation model using VGG16 and unet. The model displayed good results before (irrelevant of image type). \r\n\r\nWhen I converted the model to tflite, I noticed that it does not work with png files. Here is an example : \r\n\r\n![image](https://user-images.githubusercontent.com/47783157/84525079-57424e80-acdb-11ea-9ac1-d1f1c2269b2f.png)\r\n\r\n![image](https://user-images.githubusercontent.com/47783157/84525095-61fce380-acdb-11ea-9f92-f012c0c75ade.png)\r\n\r\n\r\nWhen trying with a jpg however, the results seem fine compared to the original model. An example:\r\n\r\n![image](https://user-images.githubusercontent.com/47783157/84525036-44c81500-acdb-11ea-9371-9015339cf568.png)<!-- .element height=\"20%\" width=\"20%\" -->\r\n\r\n![image](https://user-images.githubusercontent.com/47783157/84525018-3e399d80-acdb-11ea-92ad-f65261f10e1a.png)\r\n\r\nHope someone have the answer because I do the same preprocessing to both images. And the original model as I said work fine with both types.\r\n\r\n\ud83d\ude03\ud83d\ude03\ud83d\ude03\r\n\r\n", "comments": ["Can you provide a Google Colab gist reproducing the problem? can you try to compare the performance on the same image but with different encoding(.png and .jpg)? also, check out how many channels of the png images are you passing through the model? .jpg have only 3 channels but png by default have 4, maybe you trained your model only on 3-channel images and when the models perceive 4-channels, that screw everything.", "No I did print the dimensions every time. Both are the same. Here is a code part: \r\n\r\n![image](https://user-images.githubusercontent.com/47783157/84556792-5cc48680-ad25-11ea-93fa-30cd19e20196.png)\r\n![image](https://user-images.githubusercontent.com/47783157/84556799-6cdc6600-ad25-11ea-9b2d-1fbd4422fad2.png)\r\n![image](https://user-images.githubusercontent.com/47783157/84556807-78c82800-ad25-11ea-94c3-cf2331dadd7c.png)\r\n", "@UcefMountacer,\r\nIn order to expedite the trouble-shooting process, could you please provide the `.py` file or the Python Notebook you are running along with all the supporting files. Thanks!", "Also, please mention the TensorFlow version you are using. Thanks!", "Hi @amahendrakar,\r\n\r\nSorry for the late response. \r\nI am using the 2.2.0 version\r\n\r\nThe code I use to run the result that I have shown you is this (in TXT) : \r\n[main_code.txt](https://github.com/tensorflow/tensorflow/files/4808180/main_code.txt)\r\n\r\n", "@UcefMountacer It looks like the preprocessed input in case of png file is not the same as jpg. Could you try comparing (maybe elementwise) the `image` tensors you get from a jpg vs png file after this line:\r\n\r\n```\r\nimage = imagenet_utils.preprocess_input(image.astype(np.float32), data_format='channels_last', mode='torch')\r\n```\r\n\r\nI am guessing that the value of `image` elements isn't what the model was trained with, in case of png source.\r\n", "Update : \r\n\r\nSorry It took me so much time to get back on the project. I verified and there is problem not only with the tflite model, but with the original keras model. So the problem was necessarily because of preprocessing. After debugging, I found that using matplotlib to read images is not good (Yes, I don't know why I went in that direction). Using img = PIL.Image.open(path) and using np.array(img) solved the problem.\r\n\r\nI guess this issue should be closed but another issue is risen with matplotlib.\r\n\r\nThanks to you all\r\n\r\n\ud83e\udd19", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40416\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40416\">No</a>\n"]}, {"number": 40415, "title": "AbstractRNNCell documentation", "body": "# Documentation for state in AbstractRNNCell could be more clear.\r\n\r\nIn the documentation for the `AbstractRNNCell` it does not make it clear that the state is a tuple. https://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell\r\n\r\nThis was a gotcha for me when I defined a custom RNN cell that had a single state. It kept adding an axis to that state whenever I performed an operation on it.\r\n\r\nFor example, the code within the call method the class implementing `AbstractRNNCell`\r\n```logging.info(f'states: {states}')\r\nlogging.info(f'state_update: {state_update}')\r\nnew_states = tf.math.add(states, state_update)\r\nlogging.info(f'new_states: {new_states}')\r\n```\r\n\r\nleads to the confusing output\r\n\r\n```06-12 12:28 root         INFO     states: (<tf.Tensor 'Placeholder_3:0' shape=(32, 4) dtype=float32>,)\r\n06-12 12:28 root         INFO     state_update: Tensor(\"add_1:0\", shape=(32, 4), dtype=float32)\r\n06-12 12:28 root         INFO     new_states: Tensor(\"Add_2:0\", shape=(1, 32, 4), dtype=float32)\r\n```\r\n\r\nUpon implementing the state as a tuple of length one, the issue was solved. I think this could be made more clear in the documentation.\r\n\r\nMany thanks.", "comments": ["@AlecBG Is this still an issue for you? The updated doc clearly mentions about `state_size`\r\n\r\n\r\n\r\nstate_size | size(s) of state(s) used by this cell.It can be represented by an Integer, a TensorShape or a tuple of Integers or TensorShapes.\r\n-- | --\r\n\r\n\r\n\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40414, "title": "Bug in tf.linalg.matmul on complex matrices", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **binary x64**\r\n- TensorFlow version (use command below): **v2.2.0-rc4-8-g2b96f3662b 2.2.0**\r\n- Python version: **python --version**\r\n- CUDA/cuDNN version: **10.1**\r\n- GPU model and memory: **2080 Ti, 1050 Ti**\r\n\r\n**Describe the current behavior**\r\nIn `tf.linalg.matmul` setting `adjoint_a=True` throws an error. This worked fine in tf2.1, started erroring after upgrading to tf2.2. The minimal repro is below. \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\na = tf.constant([[1,0],[0,1]], dtype=tf.complex64)\r\ntf.linalg.matmul(a, a, adjoint_a=True)\r\n```\r\n\r\n**Other info / logs** \r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-1-85e3daa5daeb>\", line 3, in <module>\r\n    tf.linalg.matmul(a, a, adjoint_a=True)\r\n\r\n  File \"C:\\Users\\qulab\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n\r\n  File \"C:\\Users\\qulab\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2984, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n\r\n  File \"C:\\Users\\qulab\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5577, in mat_mul\r\n    _ops.raise_from_not_ok_status(e, name)\r\n\r\n  File \"C:\\Users\\qulab\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6653, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n\r\n  File \"<string>\", line 3, in raise_from\r\n\r\nInternalError: Blas GEMM launch failed : a.shape=(2, 2), b.shape=(2, 2), m=2, n=2, k=2 [Op:MatMul]\r\n```\r\n", "comments": ["@v-sivak \r\n\r\nI have tried in colab with TF-GPU version, 2.2.0, nightly version(`2.3.0-dev20200614`) and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d3ec007333a543a8dcc5bf6c6221315d/untitled17.ipynb).Thanks!", "Thanks! I got it to work with tf2.2, but it's not using the GPU. Can you confirm which version of cuda/cudnn is compatible with tf2.2 and 2080ti GPU? Looks like this error is not related to `tf.linalg.matmul` but it's caused by some incompatibility in my installation. I have `cudnn-7.6.5-cuda10.1_0` which worked fine with tf2.1", "@v-sivak \r\n\r\nPlease, see the tested build configurations from [here](https://www.tensorflow.org/install/source_windows#gpu).Hope this helps.As issue is nor related to bug in tf.linalg.matmul, please confirm whether we can close this issue?.Thanks!", "Thanks! Yes you can close this. ", "Closing the issue since the query is been answered.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40414\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40414\">No</a>\n", "Hello, I'd like to re-open this issue as I am encountering the same issue on TF 2.3.0:\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10.0.18362**\r\n- TensorFlow installed from (source or binary): **Binary (pip)**\r\n- TensorFlow version (use command below): **2.3.0 (v2.3.0-rc2-23-gb36436b087)**\r\n- Python version: **3.8.5**\r\n- CUDA/cuDNN version: **10.1.120/7.6.5 (also tried 10.1.243/7.6.5)**\r\n- GPU model and memory: **GeForce RTX 2080 Ti, 11265 MB**\r\n\r\n**Describe the current behavior**\r\n\r\nMultiplying two complex matrices with either `adjoint_a=True` or `adjoint_b=True` results in the following crash. This was reproduced on both TF 2.3.0 and 2.2.0, but works on 2.1.0. It also seems to be working on Linux.\r\n\r\nI tried doing a fresh install of CUDA with CUDA 10.1.120 and 10.1.243. In both cases the [MNIST tutorial example](https://www.tensorflow.org/tutorials/quickstart/beginner) runs with no problems.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\na = tf.constant([[1, 0], [0, 1]], dtype=tf.complex64)\r\ntf.linalg.matmul(a, a)  # No issues\r\ntf.linalg.matmul(a, a, adjoint_a=True)  # Crash\r\n```\r\n\r\n**Other info / logs**:\r\n\r\n```\r\n>>> tf.linalg.matmul(a, a)\r\n2020-08-25 18:30:03.799456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n<tf.Tensor: shape=(2, 2), dtype=complex64, numpy=\r\narray([[1.+0.j, 0.+0.j],\r\n       [0.+0.j, 1.+0.j]], dtype=complex64)>\r\n>>> tf.linalg.matmul(a, a, adjoint_a=True)\r\n2020-08-25 18:30:07.982835: E tensorflow/stream_executor/cuda/cuda_driver.cc:951] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure :: 0x00007FF991B9B115     tensorflow::CurrentStackTrace\r\n0x00007FF9918E989E      tensorflow::CostGraphDef_Node::set_is_final\r\n0x00007FF991A91D7E      stream_executor::StreamExecutor::SetDeviceSharedMemoryConfig\r\n0x00007FF98F622C16      tensorflow::StepStats::internal_default_instance\r\n0x00007FF98F634444      google::protobuf::RepeatedPtrField<tensorflow::InterconnectLink>::Add\r\n0x00007FF9774EF867      std::vector<tensorflow::DtypeAndPartialTensorShape,std::allocator<tensorflow::DtypeAndPartialTensorShape> >::operator=\r\n0x00007FF9774CA7AB      absl::lts_2020_02_25::Span<tensorflow::Tensor const >::end\r\n0x00007FF9774431BF      TFE_TensorHandleResolve\r\n0x00007FF9773E0A33      TFE_Py_TensorShapeSlice\r\n0x00007FF9773DE29A      std::_Tree<std::_Tmap_traits<std::array<std::basic_string<char,std::char_traits<char>,std::allocator<char> >,0>,tensorflow::monitoring::CounterCell,std::less<std::array<std::basic_string<char,std::char_traits<char>,std::allocator<char>\r\n0x00007FF9A51CA3D6      PyList_New\r\n0x00007FF9A51F5626      Py_CheckFunctionResult\r\n0x00007FF9A51F7954      PyEval_EvalFrameDefault\r\n0x00007FF9A51F596E      Py_CheckFunctionResult\r\n0x00007FF9A51F7954      PyEval_EvalFrameDefault\r\n0x00007FF9A51F2EF8      PyEval_EvalCodeWithName\r\n0x00007FF9A51F5C66      Py_CheckFunctionResult\r\n0x00007FF9A51F801E      PyEval_EvalFrameDefault\r\n0x00007FF9A51F3D7D      PyFunction_Vectorcall\r\n0x00007FF9A525FAF9      PyEval_GetFuncDesc\r\n0x00007FF9A525F8DD      PyEval_GetFuncDesc\r\n0x00007FF9A51E7DE4      PyObject_Repr\r\n0x00007FF9A5181E2F      PyFile_WriteObject\r\n0x00007FF9A5181B1B      PyFile_WriteString\r\n0x00007FF9A51EB200      PyFloat_AsDouble\r\n0x00007FF9A51E401E      PyObject_CallFunctionObjArgs\r\n0x00007FF9A51F9E70      PyEval_EvalFrameDefault\r\n0x00007FF9A51F2EF8      PyEval_EvalCodeWithName\r\n0x00007FF9A52038DF      PyEval_EvalCodeEx\r\n0x00007FF9A520383D      PyEval_EvalCode\r\n0x00007FF9A5203526      PyArena_New\r\n0x00007FF9A52034B5      PyArena_New\r\n0x00007FF9A5365760      PyRun_InteractiveOneObject\r\n0x00007FF9A5365373      PyRun_InteractiveLoopFlags\r\n0x00007FF9A53651B1      PyRun_AnyFileExFlags\r\n0x00007FF9A52F917D      Py_FatalError\r\n0x00007FF9A526428F      Py_RunMain\r\n0x00007FF9A5264141      Py_RunMain\r\n0x00007FF9A5264126      Py_Main\r\n0x00007FF9A52640DD      Py_Main\r\n0x00007FF7C5F41268      (unknown)\r\n0x00007FF9F1B57BD4      BaseThreadInitThunk\r\n0x00007FF9F324CE51      RtlUserThreadStart\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\qulab\\Anaconda3\\envs\\tf2-3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1009, in __repr__\r\n    self.shape, self.dtype.name, numpy_text(self, is_repr=True))\r\n  File \"C:\\Users\\qulab\\Anaconda3\\envs\\tf2-3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 225, in numpy_text\r\n    text = repr(tensor._numpy()) if is_repr else str(tensor._numpy())\r\n  File \"C:\\Users\\qulab\\Anaconda3\\envs\\tf2-3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1031, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: GPU sync failed\r\n```\r\n"]}, {"number": 40413, "title": "GPU sudden explosion during training.", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Nvidia 2080 8G\r\n\r\nWhen I train the network,  for the first 25 samples of training, usage of memory and GPU were unchanged: \r\n![image](https://user-images.githubusercontent.com/55009565/84515230-c3827980-acfe-11ea-8241-9c96c3108e7e.png)\r\n![image](https://user-images.githubusercontent.com/55009565/84515258-cd0be180-acfe-11ea-9fa0-400001686f1a.png)\r\n\r\n\r\nBut when it comes to 46-th sample, I got:\r\n![image](https://user-images.githubusercontent.com/55009565/84515433-0b090580-acff-11ea-9edc-d93fc2398526.png)\r\nAnd the usage of GPU and memory added:\r\n![image](https://user-images.githubusercontent.com/55009565/84515495-1eb46c00-acff-11ea-9780-9413a69546dc.png)\r\n![image](https://user-images.githubusercontent.com/55009565/84515535-31c73c00-acff-11ea-91a2-f207d6f6e472.png)\r\n\r\n\r\nAnd when to comes to 96-th sample.\r\n\r\n```\r\nLimit:                  7012814029\r\nInUse:                  4755516416\r\nMaxInUse:               5347089664\r\nNumAllocs:                  624595\r\nMaxAllocSize:           2055250688\r\n\r\n2020-06-12 22:52:55.958865: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ****************__********************************************************************___***********\r\n2020-06-12 22:52:55.959733: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at aggregate_ops.cc:70 : Resource exhausted: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\", line 553, in _aggregate_grads\r\n    return gen_math_ops.add_n(gradients)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 428, in add_n\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/reconstruction_test.py\", line 634, in <module>\r\n    train_model()\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/reconstruction_test.py\", line 538, in train_model\r\n    lo = m.train(train_dat, gt_dat, loss_dict)\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/reconstruction_NN.py\", line 498, in train\r\n    grad = gtape.gradient(loss_, self.trainable_variables)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\", line 946, in gradient\r\n    unconnected_gradients=unconnected_gradients)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\", line 72, in imperative_grad\r\n    compat.as_str(unconnected_gradients.value))\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\", line 126, in _gradient_function\r\n    mock_op = _MockOp(attr_tuple, inputs, outputs, op_name)\r\nSystemError: <class 'tensorflow.python.eager.backprop._MockOp'> returned a result with an error set\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\nIt seems like something wrong with\r\n![image](https://user-images.githubusercontent.com/55009565/84515981-c2058100-acff-11ea-98e6-4da5084f951a.png)\r\n\r\nAnyone can help?\r\nThanks!\r\n\r\nBest,\r\nFrank\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["And when I switch to tf1.15.2, the GPU memory **suddenly** explode at the 68th sample.\r\n```\r\n...\r\n\r\n2020-06-12 23:25:31.318690: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ***************_***************************___*****_********___*************************************\r\n2020-06-12 23:25:31.319571: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at aggregate_ops.cc:70 : Resource exhausted: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"reconstruction_test.py\", line 634, in <module>\r\n    train_model()\r\n  File \"reconstruction_test.py\", line 538, in train_model\r\n    lo = m.train(train_dat, gt_dat, loss_dict)\r\n  File \"/home/frank/PycharmProjects/reconstruction_NN/reconstruction_NN.py\", line 493, in train\r\n    grad = gtape.gradient(loss_, self.trainable_variables)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\", line 1015, in gradient\r\n    unconnected_gradients=unconnected_gradients)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\", line 76, in imperative_grad\r\n    compat.as_str(unconnected_gradients.value))\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\", line 601, in _aggregate_grads\r\n    return gen_math_ops.add_n(gradients)\r\n  File \"/home/frank/anaconda3/envs/smpl/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 469, in add_n\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[129675,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]\r\n```", "@Frank-Dz,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, please take a look at [this similar](https://stackoverflow.com/a/46067469) StackOverflow issue and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40412, "title": "tensorflow.keras slower than keras for repetitive calls to Model.predict()", "body": "**System information**\r\n- google colab notebook: [https://colab.research.google.com/drive/17PCkA9z5i8Yj9qd4QREYOSoaz8JFjk0C?usp=sharing](https://colab.research.google.com/drive/17PCkA9z5i8Yj9qd4QREYOSoaz8JFjk0C?usp=sharing)\r\n\r\n**Describe the current behavior**\r\ntensorflow.keras is significantly slower than keras when using repetitive calls to Model.predict().\r\n\r\n**Describe the expected behavior**\r\nShould be about the same no?\r\n", "comments": ["I am able to replicate the issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/e3fcf08b38ac343e851b48aa6e51646a/untitled229.ipynb)", "This stackoverflow post give a lot of information related to this problem : [https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1)\r\n\r\nI think it boil down to the fact that tf.keras is in eager mode by default. I disabled it in this [notebook](https://colab.research.google.com/drive/17PCkA9z5i8Yj9qd4QREYOSoaz8JFjk0C?usp=sharing) and speed is on par with keras. I don't really know the implication of doing this though.", "Please try using TF 2.3 I noticed it runs faster ([trained on colab gpu](https://colab.research.google.com/gist/ymodak/3d76e547dcdca9c6843c8f300949ab7e/untitled229.ipynb)). The repetitive calls are are faster than the first `Model.predict()` too. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40411, "title": "Seq2Seq using copy mechanism(such as pointer-generator network)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):tf 2.1\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI am using the template in tutorial 'Machine translation using Seq2Seq with attention'. \r\nHowever, nowadays, copy mechanism(pointer-generator and copynet) is really important when we train seq2seq model.\r\n\r\nCould you please provide an API that Machine translation using pointer-generator network?\r\n\r\n**Will this change the current API? How?**  it may need a new API or old API with new parameters that can let us use pointer-generator.\r\n\r\n**Who will benefit with this feature?**\r\nThe researcher who focus on machine translation and chatbot would be benefited with this feature\r\n\r\n**Any Other info.**\r\n", "comments": ["@yanglei-github \r\n\r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40410, "title": "Export tf.math.reduce_all first", "body": "This makes it consistent with other `reduce_*` symbols.", "comments": ["@guillaumekln: I believe you might need to update the goldens for this API change:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/api/tests", "It was merged already. Should I open a separate PR with the updated goldens?", "@guillaumekln: No need. Seems like the goldens update was not needed."]}, {"number": 40409, "title": "Tensorflow not working after installing tensorflow-gpu", "body": "### System information\r\n\r\n-   i used a stock example\r\n-   OS Platform and Distribution: Windows 8, with JetBrains Pycharm\r\n-   **TensorFlow installed from (source or binary)**: pip\r\n-   **TensorFlow version: 2.0 upgraded to 2.2\r\n-   **Python version**: 3.6\r\n-   **CUDA/cuDNN version**: 11\r\n-   **GPU model and memory**: NVIDIA Geforce 970\r\n-   **Exact command to reproduce**:\r\n```\r\nfrom keras import backend as K\r\nprint(K.tensorflow_backend._get_available_gpus())\r\n```\r\n\r\n### Describe the problem\r\nI wanted to start using Keras on my GPU as so far i only used the CPU, and it is rather slow.\r\nHowever once i downloaded the tensorflow-gpu package the simple \r\n```\r\nfrom keras import backend as K\r\n```\r\nproduces the following error messages.\r\nI tried upgrading my tensorflow installation from 2.0 to 2.2 but it did not help.\r\nI am a bit helpless and would love to know how to continue.\r\nI have CUDA installed.\r\nBefore i installed the tensorflow-gpu package, \r\n`from tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n`\r\nprinted my CPU correctly as a device. NOw it gives the same error message.\r\nSo i am assuming the problem is in the installatiuon of tensorflow.\r\nThank you so musch for your help!\r\n\r\n### Source code / logs\r\n`C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\Scripts\\python.exe C:/Users/OM/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/scratch.py\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/OM/AppData/Roaming/JetBrains/PyCharmCE2020.1/scratches/scratch.py\", line 1, in <module>\r\n    from keras import backend as K\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\OM\\PycharmProjects\\intromljolo\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nProcess finished with exit code 1\r\n`", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@busssard,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it helps. Thanks!", "@amahendrakar i know that my CPU does not support AVX2 \r\nsomething python mentioned to me every time i let it run.\r\nBut as it was still running on my CPU i did not even consider that it would not be possible to use my GPU..\r\nIs there a workaround? Or is my PC only able to use the CPU :( \r\nShould i deinstall the tensorflow-gpu package and give up?\r\n", "the answer:\r\n\r\n- deinstall all of tensorflow\r\n- instsll tensorflow-gpu 2.0 (2.2 doesnt work maybe a windows 8 bug?)\r\n- install cuda 10 (cuda 11 has no support yet)\r\n- install CuDNN 7.6 for windows 7 (CuDNN 8 has no support yet)\r\n- Set environment variable CUDA_PATH to path of the v10 folder of the CUDA installation\r\n- restart the computer\r\n- magic\r\n\r\nfor future reference this post helped me figure out the version mix\r\nhttps://stackoverflow.com/questions/50622525/which-tensorflow-and-cuda-version-combinations-are-compatible", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40409\">No</a>\n"]}, {"number": 40408, "title": "Calling predict with a keras.Sequence on a keras.saved_model fail if no previous call on numpy", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Python 3.6.9 (default, Mar 13 2020, 17:02:25) \r\n[GCC 4.2.1 Compatible Apple LLVM 11.0.0 (clang-1100.0.33.17)] on darwin\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.1.1\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nTensorflow raises an error when calling the loaded model onto a keras.Sequence. Calling model.build does not solve the issue\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should be possible to call the model onto a keras.Sequence as it works with tf.data.Dataset\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\r\nfrom tensorflow.keras.models import Sequential, load_model\r\nfrom tensorflow.keras.utils import Sequence\r\n\r\n#%% Create dummy Sequential\r\nmodel = Sequential([Input((224, 224, 3)), GlobalAveragePooling2D(), Dense(1)])\r\nmodel.summary()\r\nassert model.built\r\nmodel.input_shape\r\ntf.saved_model.save(model, \"model\")\r\n\r\n#%% Make prediction with loaded model and Sequence\r\ntf_model = load_model(\"model\")\r\nclass DataGen(Sequence):\r\n    def __init__(self, data, batch_size):\r\n        self.data = data\r\n        self.batch_size = batch_size\r\n\r\n    def __getitem__(self, index):\r\n        return self.data[index * self.batch_size : (index + 1) * self.batch_size]\r\n\r\n    def __len__(self):\r\n        return len(self.data) // self.batch_size\r\n\r\n\r\nX = np.random.rand(16, 224, 224, 3)\r\ntf_model.predict(DataGen(X, batch_size=2))\r\n# ValueError: Please provide model inputs as a list or tuple of 2 or 3 elements: (input, target) or (input, target, sample_weights) Received tf.Tensor(...)\r\n\r\n#%% Manual build does not fix the issue\r\nassert not tf_model.built\r\ntf_model.build((None, 224, 224, 3))\r\nassert tf_model.built\r\ntf_model.predict(DataGen(X, batch_size=2))\r\n\r\n#%% Try with tf.data.Dataset instead: OK\r\ntf_model.predict(tf.data.Dataset.from_tensor_slices(X).batch(2))\r\n\r\n#%% Call first on np.array does fix the issue\r\ntf_model.predict(X[:2])\r\ntf_model.predict(DataGen(X, batch_size=2))\r\n\r\n#%% But model still does not have input_shape and has \"multiple\" in summary\r\ntf_model.inputs\r\ntf_model.input_shape\r\ntf_model.summary()\r\n```\r\n", "comments": ["@ClementWalter \r\nI ran the code shared by you and face this error, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/87d1cb1e22902f78346944ad9df181c1/untitled.ipynb)", "Hi, I have just rerun exactly your notebook and found the expected error, see this [gist](https://colab.research.google.com/gist/ClementWalter/581e1bf23cfdf591ec7b4b77732fa5e0/untitled.ipynb)", "@ClementWalter I think this was resolved in recent TF versions. I tried in `tf-nightly` and I cannot reproduce the error you were facing with `tf2.1` version.\r\n\r\nI noticed that you are trying to save a keras (Sequential) model using tensorflow saved_model `tf.saved_model.save(model, \"model\")`. However, best approach is to use keras `model.save` like `model.save(\"model\", save_format='tf')`.\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40408\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40408\">No</a>\n"]}, {"number": 40407, "title": "tensorboard --logdir=runs not working: Abort trap: 6", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: pip3\r\n- CUDA/cuDNN version: -\r\n\r\nI am trying to run tensorboard: `tensorboard --logdir=runs`.  \r\nI have also tried: `tensorboard --logdir=runs --host=127.0.0.1`.  \r\nI am running the command from the terminal from within the the directory, which contains the `runs` folder.\r\n\r\nI get the following error:\r\n```[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:393] Invalid file descriptor data passed to EncodedDescriptorDatabase::Add().\r\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1367] \r\nCHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nlibc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: \r\nCHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nAbort trap: 6\r\n```\r\n\r\nMy Python code contains the following lines:\r\n```\r\ntb_path = './runs/SimpleLSTM_MNIST'\r\nif os.path.isdir(tb_path):\r\n    shutil.rmtree(tb_path)\r\n\r\nwriter = tb.SummaryWriter(log_dir=tb_path)\r\n```\r\nMy `runs` folder contains the folder `SimpleLSTM_MNIST`, which contains `events.out.tfevents.1591953948.computername.local.29440.0`.\r\n\r\nI also tried installing `protobuf version 3.8.0`, as suggested [here](https://stackoverflow.com/questions/60028929/failing-to-launch-tensorboard-from-jupyter), but still get the same issue. ", "comments": ["As mentioned in this [comment](https://github.com/tensorflow/tensorflow/issues/35573#issuecomment-596863684), try using latest version of protobuf and lt me know if it works. Thanks!", "[This](https://stackoverflow.com/questions/62342221/tensorboard-logdir-runs-not-working-abort-trap-6) is how I resolved the issue.", "@asmitapoddar I am glad this issue has been resolved. Please go ahead and close this issue. Thanks!", "@gowthamkpr resolving this issue required downgrading `tensorflow` to version 2.0.0 as well as `protobuf` to version 3.8.0. Is it possible to have `tensorboard` to be compatible on macOS with `tensorflow 2.2.2`?", "Based on https://github.com/tensorflow/tensorflow/issues/35573 this sounds like a generic issue with importing TensorFlow at all, when using a certain combination of TF versus protobuf versions.  But in that issue it sounds mostly like newer versions of protobuf might fix it.\r\n\r\nFWIW, I can't reproduce the issue myself (on macOS Catalina, with TF 2.2.0, it installs protobuf 3.12.2, and it all seems to work fine).\r\n\r\nSo my advice would be to try updating TF to 2.2.0, and you should also get protobuf 3.12.2, and see if you still have the issue.  If so, I would try `python -c import tensorflow` to confirm if it's a generic TF issue, and if that results in the same error I would follow up on #35573 directly instead of here.\r\n\r\nIf you do see this happening again with tensorboard but _not_ with tensorflow generally, then please launch `tensorboard` with `--verbosity=1` so we can pinpoint at what point TensorBoard hits this issue, and please provide as much detail as you can about how you installed TF/TB and their dependencies to trigger the issue (i.e. ideally commands you ran from scratch to get to that point, or at least the output of `pip freeze`).\r\n\r\nI'm going to close proactively since this looks a lot like a duplicate, but if you can trace this back to tensorboard just leave a comment and we can revisit.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40407\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40407\">No</a>\n"]}, {"number": 40406, "title": "y shape and y_pred shape not same ", "body": "why those two are different \r\n\r\n![tfp](https://user-images.githubusercontent.com/26671669/84497611-f3b32380-acd0-11ea-9538-6e1f60f32c19.png)\r\n", "comments": ["@imrankhan441,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "### **Note: I Use TPU Accelerator**\r\n### **And I don't face any problem with CPU and GPU Accelerator**\r\n\r\n\r\n```\r\nfrom tensorflow.distribute import get_strategy\r\nfrom tensorflow.distribute.experimental import TPUStrategy\r\nfrom tensorflow.config import experimental_connect_to_cluster\r\nfrom tensorflow.tpu.experimental import initialize_tpu_system\r\nfrom tensorflow.distribute.cluster_resolver import TPUClusterResolver\r\n\r\n\r\nfrom tensorflow.keras.layers import LSTM\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Embedding\r\nfrom tensorflow.keras.models import Sequential\r\n\r\n\r\nfrom tensorflow.keras.datasets import imdb\r\n\r\nnumber_of_words = 20000\r\nmax_len = 100\r\n\r\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = number_of_words)\r\n\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\nX_train = pad_sequences(X_train, maxlen = max_len)\r\nX_test = pad_sequences(X_test, maxlen = max_len)\r\n\r\n\r\n\r\ntry:\r\n    tpu = TPUClusterResolver()\r\n    print('Running on TPU ', tpu.master())\r\nexcept:\r\n    tpu = None\r\n\r\nif tpu:\r\n    experimental_connect_to_cluster(tpu)\r\n    initialize_tpu_system(tpu)\r\n    strategy = TPUStrategy(tpu)\r\n\r\nelse:\r\n    strategy = get_strategy()\r\n\r\nwith strategy.scope():\r\n    embedding_rnn = Sequential()\r\n    embedding_rnn.add(Embedding(number_of_words, 10, input_shape = (X_train.shape[1], )))\r\n    embedding_rnn.add(LSTM(units = 10, return_sequences = True, activation = \"tanh\"))\r\n    embedding_rnn.add(LSTM(units = 20, return_sequences = True, activation = \"tanh\"))\r\n    embedding_rnn.add(LSTM(units = 30, return_sequences = True, activation = \"tanh\"))\r\n    embedding_rnn.add(LSTM(units = 40, activation = \"tanh\"))\r\n\r\n    embedding_rnn.add(Dense(units = 1, activation = \"sigmoid\", name = \"output_layer\"))\r\n    embedding_rnn.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\r\n    \r\nembedding_rnn.fit(X_train, y_train, batch_size = 20 * strategy.num_replicas_in_sync, epochs = 50)\r\n\r\ny_pred = embedding_rnn.predict_classes(X_test)\r\ny_pred.shape\r\n\r\n\r\n```", "Works fine with CPU and GPU. Was able to reproduce the issue with TPU, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/f06bac5b647b95b26f9e6d6614bbe8dc/40406.ipynb#scrollTo=yxeH6LVBVNvL). Thanks!", "This looks similar to a bug that @tf-marissaw is looking at.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I can reproduce this using the above colab but I cannot reproduce this bug on the most recent internal version of TensorFlow. It looks like its root cause was already fixed. The bug I am looking into appears to be unrelated to this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40406\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40406\">No</a>\n"]}, {"number": 40405, "title": "[tf.data] Add grappler pass to hoist data-discarding ops", "body": "This is a PR from JIZHI, the AI platform in Tencent.\r\n\r\nThis pr adds a tf.data grappler pass which is used to hoist the data-discarding ops like `shard`, `skip` and `take`. In this way there will be less unnecessary calculation or cache.\r\nFor example, this pass will turn this code:\r\n```python\r\ndef parse_and_preprocessing(x):\r\n  # very slow\r\n\r\nds = tf.data.Dataset.TFRecordDataset(\"example.tfrecord\")\r\nds = ds.map(parse_and_preprocessing, num_parallel_calls=10)\r\nds = ds.cache()\r\nds = ds.skip(100)\r\nds = ds.take(1000)\r\nds = ds.repeat()\r\n```\r\ninto\r\n```python\r\n# ...\r\n\r\nds = tf.data.Dataset.TFRecordDataset(\"example.tfrecord\")\r\nds = ds.skip(100)\r\nds = ds.take(1000)\r\nds = ds.map(parse_and_preprocessing, num_parallel_calls=10)\r\nds = ds.cache()\r\nds = ds.repeat()\r\n```\r\nThis transformation will enable the `cache` and avoid some unnecessary background calculation in `map`. Also, this pass will help to make a consistently processing map possible (in other words, let the `MapDataset` continue to process whenever there is a empty thread instead of scheduling a element only after a `GetNext` call.). Both of these problems are partially discussed in #39992 . \r\n\r\nThe design of this pass is basically the same as `noop_elimination` or `inject_prefetch` and its inner logic is:\r\n1. Find a node that will discard data. (Right now there are `take`, `skip` and `shard`).\r\nLet's use the above code as an example:\r\n```\r\nTFRecord -> ParallelMap -> Cache -> | Skip | -> Take -> Repeat\r\n```\r\n2. Find the chain of ops that will not change the order of the input and is connected to the node in step 1. (Right now there are `map`, `prefetch` and `cache`.)\r\n```\r\nTFRecord -> { ParallelMap -> Cache } -> | Skip | -> Take -> Repeat\r\n```\r\n3. Move the node from the end of the chain to the start.\r\n```\r\nTFRecord -> | Skip | -> { ParallelMap -> Cache } -> Take -> Repeat\r\n```\r\n4. If there is an update of the graph, repeat 1 - 3. (For the example, `take` will be moved in the second round).\r\n\r\ngently ping @jsimsa \r\n\r\nThank you for your time on reviewing this pr.", "comments": ["@jsimsa \r\nThank you for your quick review! I've added the python test and updated the code according to the review. Could you have a second look?", "@aaudiber \r\nThank you for your reviews. I've changed the code according to them. Could you have a second look?", "For @tensorflow/api-owners :\r\n\r\nWe have a number of questions about this new option; can we make sure that the docstrings address:\r\n\r\n1. What exactly is hoisting in this context? What are things hoisted into, and how does this affect the data pipeline in question? (Looking at the one-line example, this seems to be a reordering.)\r\n2. What is the full set of transformations that is hoisted? Do these eventually get run somewhere else?\r\n3. Can you add examples to the docstrings so that users will understand how to use this?\r\n\r\nMore broadly, should this be turned on by default? What would we have to test/ensure first?", "@karmel \r\nThank you for your questions :).\r\n> 1. What exactly is hoisting in this context? What are things hoisted into, and how does this affect the data pipeline in question? (Looking at the one-line example, this seems to be a reordering.)\r\n\r\nI'm a little confused about the terms reordering and hoisting. Should hoisting have loop involve? In that case, we may rename it to reordering. I was just imitating the pass `hoist_random_uniform`.\r\n\r\n> 2. What is the full set of transformations that is hoisted? Do these eventually get run somewhere else?\r\n\r\nThe transformation should involve moving `skip`, `take`, `shard` to the front of `map`, `cache`, `prefetch` so that no unnecessary calculation or cache will take place. I think it will only involve tf.data ops.\r\n\r\n> 3. Can you add examples to the docstrings so that users will understand how to use this?\r\n\r\nI'd love to. Could you tell me how specific the docstrings should be? And should the extra docstrings be added in `optimization_options.py`?\r\n\r\n> More broadly, should this be turned on by default? What would we have to test/ensure first?\r\n\r\nI believe there will be no harm turning it on by default. And I'll be glad if it does.\r\n\r\n@aaudiber @jsimsa Could you share your opinions on these questions? Thank you.", "> 1. What exactly is hoisting in this context? What are things hoisted into, and how does this affect the data pipeline in question? (Looking at the one-line example, this seems to be a reordering.)\r\n\r\nI agree that reordering is a better term. Hoisting usually means moving to a different scope, as happens with `hoist_random_uniform`. How about calling it `reorder_data_discarding_ops`?\r\n\r\n> 2. What is the full set of transformations that is hoisted? Do these eventually get run somewhere else?\r\n\r\n@zhuzilin please update the docstring in optimization_options.py to specify the exact list of which transformations will be reordered, and also to make it clear that the optimization is only for performance, and will not affect the output of the dataset.\r\n\r\n> 3. Can you add examples to the docstrings so that users will understand how to use this?\r\n> \r\n> More broadly, should this be turned on by default? What would we have to test/ensure first?\r\n\r\nIt makes sense to turn this on by default, since it is almost always a strict improvement. I see two risks: (1) The user relies on a side-effect of applying their map function to discarded elements and (2) the user expects their entire dataset to be cached to disk, but with the re-ordering only part of the dataset is cached.\r\n\r\n(1) is unlikely, and the user would be relying on undefined behavior.\r\n(2) is more problematic - I think we should avoid applying the reordering to `cache` transformations which cache to a file instead of in-memory.\r\n\r\nOnce we've addressed the file-caching issue, lets turn the optimization by default, and I will run extra internal tests to make sure nothing is broken.", "@aaudiber \r\nI've renamed the pass to `reorder_data_discarding_ops` and modified the doc. Could you have another look? As for the file-caching issue, I think we should maintain the optimization to it and tell user the consequence of it. Because in my opinion, using file cache to save the whole dataset while discarding some of it is not likely a common usage.\r\n@karmel \r\nCould you also check the updated doc to see if it has the information we need?", "@zhuzilin Regarding cache-to-file, I think a common use case while debugging could be to add a `take()` after the call to `cache(filename)` to inspect some example data. For example, the user builds a dataset with\r\n\r\n```\r\nds = create_dataset()\r\nds = ds.cache(filename)\r\n```\r\n\r\nThen they append `.take(3)` to make sure their data looks correct:\r\n\r\n```\r\nds = create_dataset()\r\nds = ds.cache(filename)\r\nfor element in ds.take(3):\r\n  print(element)\r\n```\r\n\r\nThen they remove the printing and run their training:\r\n\r\n```\r\nds = create_dataset()\r\nds = ds.cache(filename)\r\ntrain_on_dataset(ds)\r\n```\r\n\r\nThe user will be surprised and unhappy that their dataset now produces only 3 elements.", "@aaudiber \r\nThank you for the information! I haven't thought about this use case before. However, it's hard to distinguish file cache and memory cache because `filename` is an input instead of a attribute, which means we can't known whether it will be empty or not in grappler... If we need to preserve the use case you mentioned, maybe we have to remain this optimization as default false?", "@zhuzilin \r\nI think it's important for the optimization to be on by default, so that it can have more impact. If we leave it off by default, not many users will be aware of it, and there will be very little usage. What do you think of removing the interaction with `cache` for now, and only re-ordering `map` and `prefetch`? Then later on we can split `CacheDataset` into separate `MemoryCacheDataset` and `FileCacheDataset` ops, so that we can include `MemoryCacheDataset` in this optimization.", "@aaudiber \r\nSure. I'll remove the `cache` for now if we will separate memory and file cache ops.", "@aaudiber \r\nI've removed `cache` and updated the docstring. Could you have another look? :).", "@aaudiber \r\nThere was a lint error (one line was longer than 80 characters after renaming to reorder_data_discarding_ops). I've fix it and could you help aprove this pr again? Thank you!", "@aaudiber \r\nIt is strange that Linux CPU test has failed... All I did last commit was adding a newline in python code to make it shorter than 80 characters, but the Linux CPU test turns from passed to failed...\r\nThe error is about vectorizer registry:\r\n```\r\ntensorflow/core/grappler/optimizers/data/vectorization/vectorizer_registry_test.cc:46\r\nExpected equality of these values:\r\n  ::tensorflow::Status::OK()\r\n    Which is: OK\r\n  (s)\r\n    Which is: Not found: Op type not registered '' in binary running on localhost.\r\n  Make sure the Op and Kernel are registered in the binary running in this process.\r\n  Note that if you are loading a saved graph which used ops from tf.contrib, accessing\r\n  (e.g.) `tf.contrib.resampler` should be done before importing the graph,\r\n  as contrib ops are lazily registered when the module is first accessed.\r\n```\r\nIs there any reason this new optimization may influence it?", "@zhuzilin That test is currently broken, unrelated to your PR. There is an outstanding change to disable the test while it is fixed.", "Genlty ping @aaudiber. I wonder if we are going to merge this pass? Thank you :).", "@aaudiber \r\nThe building failure is at `tensorflow/python/kernel_tests:cast_op_test`, which should have nothing to do with tf.data. Is there anything else I can help with this pr?", "@aaudiber \r\nIt seems that random building errors keep on happening \ud83d\ude02.", "@aaudiber The tests are finally passed! \ud83d\ude02  Thank you so much for your help in this pr!", "@gbaned @aaudiber Could you help to merge this pr? Thank you!", "@zhuzilin This should merge soon, I just need to fix up a couple internal tests"]}]