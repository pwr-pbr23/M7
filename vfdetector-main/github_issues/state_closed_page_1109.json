[{"number": 19982, "title": "Can't allocate memory for the interpreter in tflite", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Nope, using tensorflow-for-poets\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.1\r\n- **Python version**: Python 2.7.10\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: I added a custom tflite model (converted .pb using TOCO) and replaced graph.lite with the new custom model and built the app, but it crashes on runtime.\r\n\r\n### Detailed Description\r\nI created a custom TensorFlow model and converted it to TOCO (as described in the tensorflow-for-poets tutorial) and I replaced the old graph.lite file with my custom model and changed nothing else in the code. When I run the app, I get the following runtime error:\r\n\r\n```\r\nProcess: android.example.com.tflitecamerademo, PID: 29160\r\n    java.lang.RuntimeException: Unable to start activity ComponentInfo{android.example.com.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}: java.lang.NullPointerException: Can not allocate memory for the interpreter\r\n```\r\n\r\n### Fixes Already Tried\r\n- Ensuring that Android Studio/Gradle pick up on tensorflow-lite:0.1.7 changes (#19051). Currently, my build.gradle file says `compile 'org.tensorflow:tensorflow-lite:+'`, but changing it to `compile 'org.tensorflow:tensorflow-lite:0.1.7'` doesn't resolve the issue either.\r\n- Running TOCO with the `--change_concat_input_ranges=false` flag.", "comments": ["Hey Sayan, thanks for following up on this. \r\n\r\nCould you possibly update the build.gradle file to 'org.tensorflow:tensorflow-lite:0.0.0-nightly' and see if it fixes your issue? It contains a much more recent version of the TFLite library (built every day). Let me know if it does. I have a fix coming up that makes that the default.", "Hey Alan, thanks for taking up the issue!\r\nWhen I make the change you suggested, I get the following error message: `Multiple dex files define Lorg/tensorflow/lite/NativeInterpreterWrapper;`, but I am not sure if this has something to do with the fact that I am running the nightly build.", "I'll try to reproduce it locally - it could have something to do with updating the Gradle file.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/7470 seems relevant", "I tried compiling and running the app again today with the nightly build and I get the following error message now:\r\n`java.lang.RuntimeException: Unable to start activity ComponentInfo{android.example.com.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/conv.cc:191 input->dims->size != 4 (0 != 4)`", "Hey Sayan! There seems to have been a problem in the model conversion process (ex: TOCO) as opposed to the demo app.\r\n\r\nAs the error message indicates, one of your conv operators is provided with an input tensor with no dimensions.\r\n\r\n**Some Background for Debugging**\r\nFor ops with dynamic inputs, we call the Prepare function (that your error appeared in) right before calling its Eval function. Suppose op A feeds its output into op B through tensor C. The Prepare call in dynamic op A will resize tensor C.\r\n\r\nNo we can suppose in your model, the conv op that's failing is op B. For some reason, op A has not resized tensor C and the conv op is seeing an input tensor with no dims. \r\n\r\nUnfortunately, I don't currently have cycles to help debug a model-specific issue. If it's ok for you to share your frozen graph file, that'd be great for when someone gets cycles to look into it.\r\n\r\n", "Nagging Assignee @alanchiao: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm also having the issue", "Nagging Assignee @alanchiao: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "with the same problem.", "@karlzheng: could you provide more details?\r\nWhich one of the issues that Sayan ran into are you running into? \r\n1. \"Can't allocate memory for the interpreter in tflite.\" \r\n-> Are you using the nightly build as suggested above? Please see if it fixes your issue. \r\n2. \"Multiple dex files define Lorg/tensorflow/lite/NativeInterpreterWrapper\". \r\n-> See my response above.\r\n3. \"java.lang.RuntimeException: Unable to start activity ComponentInfo{android.example.com.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/conv.cc:191 input->dims->size != 4 (0 != 4)\"\r\n\r\nIf it's a separate error message, please create a separate issue. Thanks!", "I had the same issue (Nr. 3). Its probably because you retrained you modell with a modified retrain.py script. To complete the tutorial I had to give a variable called input_layer another value (to solve a different issue).\r\nWhen converting your model with toco you have to make sure to use the same value as parameter for input_array.\r\nSolved the problem for me.", "Thank you @bayan100 for sharing how you resolved Nr. 3!\r\n\r\nClosing this issue since the original reporter hasn't responded for a while. @Whiteseeker and @karlzheng, feel free to create a separate issue and link to this one for context. If what Bayan said is true (you'd modified retrain.py), it'd be great if you mentioned it here so others know that that's the cause.", "java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/conv.cc:191 input->dims->size != 4 (1 != 4)Node 0 failed to prepare.\r\n\r\nhow to solve?", "@luolugithub : there isn't sufficient information from just that error. Does bayan100's comment apply to you?\r\n\r\nWe'd need the .tflite model file at a minimum (or something the reproduces the error), and if it's generated from a working model (e.g. via retraining via retrain.py), it'd be useful to see both the original model and the generation code. Thanks!", "[Same issue encountered. And I attached a converted model file at another issue](https://github.com/tensorflow/tensorflow/issues/21336#issuecomment-423027401)\r\n", "Having the same issue when trying to run on Android.\r\n`Internal error: Unexpected failure when preparing tensor allocations: tensorflow/contrib/lite/kernels/conv.cc:225 input->dims->size != 4 (0 != 4)Node number 0 (CONV_2D) failed to prepare.`\r\nI used the last retrain.py from https://www.tensorflow.org/hub/tutorials/image_retraining with my own dataset.\r\nThen converting using TOCO `./toco --input_file=\"$HOME/tensorflow-master/output_graph.pb\" --output_file=\"$HOME/output_graph.tflite\" --input_arrays=Placeholder --output_arrays=final_result`\r\nThen putted in the android lite demo next to mobilenet_quant.tflite.\r\nAnd i don't understand what @bayan100 said with the input_layer\r\n\r\nEdit : Tried to use mobilenet_v2_140_224 model, still the same error on my phone", "The .pb model looks good because still have 4 dimension with Placeholder but when i try to open .tflite converted mode, it doesn't find any input array. Still working on it, may be a problem with toco", "Same error here but only when Im trying to use the post-training quantization.\r\n\r\n`converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file('models/mobilenet_tune.h5')`\r\n`converter.post_training_quantize = True --> Without this line is Ok`\r\n`tflite_model = converter.convert()`\r\n`open(\"mobilenet_quantize_model.tflite\", \"wb\").write(tflite_model)`", "@damhurmuller I'm doing the same thing as you and running into issues. Did you manage to find a solution?", "@SreehariRamMohan I was using an old version 1.10.* I guess. Now I'm using the nightly version and is ok.", "@damhurmuller I switched to compiling the tf nightly version but I still get the following error:\r\n\r\n`Caused by: com.google.firebase.ml.common.FirebaseMLException: Internal error has occurred when executing Firebase ML tasks\r\nW/System.err:     at com.google.android.gms.internal.firebase_ml.zzhg.zza(Unknown Source)\r\nW/System.err: \t... 5 more\r\nW/System.err: Caused by: java.lang.NullPointerException: Can not allocate memory for the interpreter\r\nW/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)\r\nW/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)\r\nW/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:51)\r\nW/System.err:     at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:90)\r\nW/System.err:     at com.google.android.gms.internal.firebase_ml.zzif.zzfm(Unknown Source)\r\nW/System.err:     at com.google.android.gms.internal.firebase_ml.zzhr.zzfp(Unknown Source)\r\nW/System.err:     at com.google.android.gms.internal.firebase_ml.zzhr.call(Unknown Source)\r\nW/System.err:     at com.google.android.gms.internal.firebase_ml.zzhg.zza(Unknown Source)\r\nW/System.err: \t... 5 more`", "@alanchiao, what version of TFLite is required to use post_training_quant?", "E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.trp.develop.tflitetrp, PID: 3763\r\n    java.lang.RuntimeException: Unable to start activity ComponentInfo{com.trp.develop.tflitetrp/com.trp.develop.tflitetrp.MainActivity}: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/concatenation.cc:67 t->dims->size != t0->dims->size (3 != 2)Node number 4 (CONCATENATION) failed to prepare.\r\n    \r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2778)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2856)\r\n        at android.app.ActivityThread.-wrap11(Unknown Source:0)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1589)\r\n        at android.os.Handler.dispatchMessage(Handler.java:106)\r\n        at android.os.Looper.loop(Looper.java:164)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6494)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807)\r\n     Caused by: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/concatenation.cc:67 t->dims->size != t0->dims->size (3 != 2)Node number 4 (CONCATENATION) failed to prepare.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)\r\n\r\n\r\n\r\nI use tflite convert because it support multi inputs \r\n\r\nbelow is the command:\r\ntflite_convert   --graph_def_file=/home/xqp/Desktop/model1/frozen_purecnn.pb   --output_file=//home/xqp/Desktop/model1/purecnn.tflite   --input_arrays=cnn_input,pcs_1level_input --output_arrays=predictions/Softmax --input_shapes=1,500:1,7\r\n\r\n\r\n\r\nif  i use toco it will report this error\r\n2018-12-11 09:58:57.163903: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1091] Check failed: indices_shape.dimensions_count() == 1 (2 vs. 1)\r\n\r\nbelow is the command:\r\ntoco --input_file=/home/xqp/Desktop/model12/frozen_purecnn.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=/home/xqp/Desktop/model12/purecnn.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=cnn_input,pcs_1level_input --output_arrays=predictions/Softmax --input_shapes=1,500:1,7\r\n", "@mstc-xqp : please create a separate issue. While the error message is the same, the underlying cause is different.\r\n\r\n@damhurmuller : that makes sense. I don't think the post_training_quantize was ready for use until the 1.11 release", "I am having the same problem. Has anyone worked out a solution to this problem.\r\n", "@MATTYGILO : could you please create a separate issue (and CC mstc-xqp if the error is exactly the same).\r\n\r\nNote that for mstc's case, the error is for the concatenation.cc , whereas for Pierre, it's for the conv.cc. These are all model-specific and op-specific issues", "same problem here", "I encountered a similar problem when trying to convert pb to tflite using the toco converter (via bazel). I managed to get rid of the problem by passing in the `input_shape `argument in the command line, e.g., `--input_shape=1,224,224,3.` Just adding here as a reference. ", "> I tried compiling and running the app again today with the nightly build and I get the following error message now:\r\n> `java.lang.RuntimeException: Unable to start activity ComponentInfo{android.example.com.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/conv.cc:191 input->dims->size != 4 (0 != 4)`\r\n\r\nIn my case, I used multiple inputs. I solved a similar problem with the below instruction. Then trained the model from scratch changing input shape and training data shape.\r\n![image](https://user-images.githubusercontent.com/30307587/109982482-4cd25400-7d45-11eb-93e6-746e80d13e00.png)\r\n\r\n"]}, {"number": 19981, "title": "Feature Request: erosion and dilation such as scipy.ndimage.grey_erosion and scipy.ndimage.grey_dilation", "body": "tf.image.erosion and tf.image.dilation. I find tf.nn.dilation2d is too slow when the kernel size is [20,20,1].", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I solved the problem by using other ways. For now, it works well. Thanks!", "@KeyKy,\r\n\r\nCan you share your code? thanks", "@pribadihcr you can use py_func and do it in python"]}, {"number": 19980, "title": "Space handling in equation parameter of tf.einsum", "body": "This is a copy of PR #19859 into `master`, instead of `tf1.8`. /cc @drpngx ", "comments": ["Rerun for unrelated failed tpu test."]}, {"number": 19979, "title": "fix spelling errors in doc of python/framework/ops.py", "body": "fix spelling errors in doc!", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@777ki Thanks for sending the PR. However, 'iff' means 'if and only if' in these comments. So they look correct to me. I will close this PR."]}, {"number": 19978, "title": "[XLA] Change the visibility of the graph builder", "body": "The hlo_tfgraph_builder isn't directly used by the xla/tools package, so it doesn't seem to need to be limited to only the service module and the tools module.\r\n\r\nI have brought it in line with the rest of the service module, which means it can be used by other parts of the XLA system - specifically the Graphcore backend, which resides in the compiler/plugins directory.\r\n\r\n", "comments": ["This test failure appears to be an unrelated flaky test. https://source.cloud.google.com/results/invocations/f753d4f0-749a-4574-9698-1d51a15521fa/log\r\n\r\nTo confirm that, I will star the tests again.", "wow - that was fast - nice one chaps."]}, {"number": 19977, "title": "r1.9-rc2 cherry-pick request: Documentation for Raspberry Pi installation", "body": "If this isn't included, the tensorflow.org documentation will not reflect the new Raspberry Pi support.", "comments": []}, {"number": 19976, "title": "BestExporter cherry-pick request for r1.9: Only calls compare function if values were read from event file", "body": "I would like to suggest this cherry-pick for r1.9.\r\n\r\nFixes #19877.", "comments": []}, {"number": 19975, "title": "Runtime Error on TFLite Sample App", "body": "### System information\r\n* Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4 LTS\r\n* TensorFlow installed from (source or binary): pip/binary\r\n* TensorFlow version (use command below): 1.8.0\r\n* Python version: 3.5.2\r\n* Bazel version (if compiling from source): N/A\r\n* CUDA/cuDNN version: N/A\r\n* GPU model and memory: N/A\r\n* Exact command to reproduce: Please see the description.\r\n\r\n### Describe the problem\r\nI'm developing an android application based on the tensorflow-lite [object detection examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android\r\n).\r\n\r\nI trained `ssd_mobilenet_v1` and converted that model by following [this instructions](https://github.com/tensorflow/tensorflow/issues/15633#issuecomment-377652630).\r\n\r\nNow I modified some lines which are shown the folloing before building and deploying the app.\r\n\r\n### Source code\r\n\r\n```diff\r\ndiff --git a/tensorflow/contrib/lite/examples/android/BUILD b/tensorflow/contrib/lite/examples/android/BUILD\r\nindex 5700007..85b58fc 100644\r\n--- a/tensorflow/contrib/lite/examples/android/BUILD\r\n+++ b/tensorflow/contrib/lite/examples/android/BUILD\r\n@@ -34,7 +34,8 @@ android_binary(\r\n         \"@tflite_mobilenet//:mobilenet_quant_v1_224.tflite\",\r\n         \"@tflite_conv_actions_frozen//:conv_actions_frozen.tflite\",\r\n         \"//tensorflow/contrib/lite/examples/android/assets:conv_actions_labels.txt\",\r\n-        \"@tflite_mobilenet_ssd//:mobilenet_ssd.tflite\",\r\n+        # \"@tflite_mobilenet_ssd//:mobilenet_ssd.tflite\",\r\n+        \"//tensorflow/contrib/lite/examples/android/assets:ssd.tflite\",\r\n         \"//tensorflow/contrib/lite/examples/android/assets:box_priors.txt\",\r\n         \"//tensorflow/contrib/lite/examples/android/assets:coco_labels_list.txt\",\r\n     ],\r\ndiff --git a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java\r\nindex de997e4..95710ff 100644\r\n--- a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java\r\n+++ b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java\r\n@@ -50,7 +50,8 @@ public class DetectorActivity extends CameraActivity implements OnImageAvailable\r\n\r\n   // Configuration values for the prepackaged SSD model.\r\n   private static final int TF_OD_API_INPUT_SIZE = 300;\r\n-  private static final String TF_OD_API_MODEL_FILE = \"mobilenet_ssd.tflite\";\r\n+  // private static final String TF_OD_API_MODEL_FILE = \"mobilenet_ssd.tflite\";\r\n+  private static final String TF_OD_API_MODEL_FILE = \"ssd.tflite\";\r\n   private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/coco_labels_list.txt\";\r\n\r\n   // Which detection model to use: by default uses Tensorflow Object Detection API frozen\r\ndiff --git a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java\r\nindex bfb4a0a..b21e753 100644\r\n--- a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java\r\n+++ b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java\r\n@@ -47,8 +47,8 @@ public class TFLiteObjectDetectionAPIModel implements Classifier {\r\n\r\n   // Only return this many results.\r\n   private static final int NUM_RESULTS = 1917;\r\n-  private static final int NUM_CLASSES = 91;\r\n-\r\n+  // private static final int NUM_CLASSES = 91;\r\n+  private static final int NUM_CLASSES = 22;\r\n   private static final float Y_SCALE = 10.0f;\r\n   private static final float X_SCALE = 10.0f;\r\n   private static final float H_SCALE = 5.0f;\r\n```\r\n\r\n### logs\r\nUnder those conditions, I faced the following Runtime Error.\r\n```JAVA\r\n06-13 15:38:39.120 21951-21971/org.tensorflow.lite.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.lite.demo, PID: 21951\r\n    java.lang.IllegalArgumentException: Output error: Shape of output target [1, 1917, 4] does not match with the shape of the Tensor [1, 1917, 1, 4].\r\n        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:44)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:178)\r\n        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:222)\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:243)\r\n        at android.os.Handler.handleCallback(Handler.java:761)\r\n        at android.os.Handler.dispatchMessage(Handler.java:98)\r\n        at android.os.Looper.loop(Looper.java:156)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n```\r\n\r\nActually I applied another dataset to the model (`ssd.tflite`), but I just used [train.py](https://github.com/tensorflow/models/blob/master/research/object_detection/train.py) as is, so I'm wondering why it was happened.\r\n\r\nI hope someone would help me.\r\n\r\nThank you.", "comments": ["Hello @yasuhitotsu.\r\nI'm having the same problem. \r\nDid you solve it? ", "Hello.\r\nIn [#15633](https://github.com/tensorflow/tensorflow/issues/15633), @Haijunlv give two ways to solve this problem. \r\nI have tried way 2 and success to run model in mobile. \r\nMany thanks to Haijunlv.", "Hi\uff0c @MengAjin \r\nI'm having the same problem.\r\nDo you means revise python script box_predictor.py, and bazel build a new apk? Or revise TFLiteObjectDetectionAPIModel.java file? Would you share your revise, thanks.", "@issac8huxley\r\nAfter revise the box_predictor.py, you should train the model from scratch. There is no need to revise TFLiteObjectDetectionAPIModel.java file.", "@MengAjin although it can work, the spped in mobile is still very slow. I am not focusing on this problem during this period. Did you find the method to accelerate the speed? I think this is a big problem", "Hello @Haijunlv.\r\nMaybe NNAPI? Did you tried NNAPI?\r\nI don't know much about it yet. And now, I don't have a Android device supporting NNAPI.^^", "@MengAjin No. I didnot try NNAPI. I only have iphone. You are right. It is need to  try tflite with apple CoreML or to Andriod with NNAPI. Maybe the spped is different. ", "@MengAjin  @Haijunlv \r\nThanks. With your advise, I can run model in mobile at present.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, \r\nWe have just published a set of instructions that should allow you to run Mobilenet SSD at least on Pixel 2 at 15fps. \r\nPlease try the following and let us know if it works:\r\nhttps://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\r\n", "@achowdhery your article talks about quantized model  \r\n\r\n`mobilenet_ssd.tflite` isn't quantized! \r\n\r\nchange `detect.tflite` to `mobilenet_ssd.tflite` https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo/DetectorActivity.java#L54\r\n\r\nand `true` to `false` for https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo/DetectorActivity.java#L53\r\n\r\nit's not going to work...\r\n\r\n> 2019-04-25 14:25:24.087 26208-26537/org.tensorflow.lite.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n>     Process: org.tensorflow.lite.demo, PID: 26208\r\n>     java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 1917, 4] and a Java object with shape [1, 10, 4].\r\n\r\nthis model is being downloaded by https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/download-models.gradle#L13"]}, {"number": 19974, "title": "profiler op view: how to interpret the two numbers of (xx%, xx%) in the output", "body": "Hi! I'm using the tf profiler, a typical output for the `op` view with the code:\r\n```\r\nprofiler.profile(\r\n    tf.get_default_graph(),\r\n    run_meta=run_metadata,\r\n    cmd='op',\r\n    options=opts)\r\n```\r\nwould be \r\n```\r\nProfile:\r\nnode name | # float_ops\r\nMatMul                   81.40m float_ops (100.00%, 96.29%)\r\nMean                     795.12k float_ops (3.71%, 0.94%)\r\nMul                      648.40k float_ops (2.77%, 0.77%)\r\nAdd                      548.00k float_ops (2.00%, 0.65%)\r\nSub                      397.51k float_ops (1.36%, 0.47%)\r\nSquare                   397.51k float_ops (0.89%, 0.47%)\r\nRealDiv                  200.00k float_ops (0.42%, 0.24%)\r\nSum                      100.79k float_ops (0.18%, 0.12%)\r\nNeg                      50.00k float_ops (0.06%, 0.06%)\r\nArgMax                     900 float_ops (0.00%, 0.00%)\r\nEqual                      102 float_ops (0.00%, 0.00%)\r\nGreater                      1 float_ops (0.00%, 0.00%)\r\n\r\n======================End of Report==========================\r\n```\r\nbut I really cannot figure out what the two percent numbers in the output means, I googled it a while, no lucky, when I tried to read the source code of profiler, I find it wrapped too heavy...", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce"]}, {"number": 19973, "title": "How to add a threshold in softmax scores", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.8\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen doing multi-classcification usually I got a softmax score and predictoins with below,\r\n```\r\nsoftmax_scores = tf.nn.softmax(logits=self.scores, dim=-1)\r\nprediction=tf.argmax(self.scores, 1, name=\"predictions\")\r\n```\r\nIf the softmax_socres I got is [0.5,0.2,0.3].The prediction is [0]. Now I want to add thresholds 0.6 to softmax_socres.Which means the prediction expected here is [4] which means others.\r\nThe only way that I can figure out is to convert softmax_scores to numpy and handle it. Which is out of the model defination.\r\n\r\n### Source code / logs\r\nThis is only a demo, the full code is too long.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\na=tf.constant(np.arange(6),shape=(3,2))\r\nb=tf.reduce_max(a,1)\r\nc=tf.to_int32(a>3)\r\nd=tf.argmax(c,1)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(c.eval(),d.eval())\r\n```\r\nHere the result I expect is [4,4,2]", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 19972, "title": "Removed unnecessary copying of dict", "body": "", "comments": []}, {"number": 19971, "title": "Pd turns tflite to report all kinds of errors. Have you done the test?", "body": "Download the network model\r\n\r\nMobileNet_v1_1.0_224_quant\r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\r\nTurn tflite error\r\n\r\nbazel run toco -- \r\n--input_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenet_v1_1.0_224_quant_frozen.pb \r\n--output_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenetnew.tflite \r\n--input_format=TENSORFLOW_GRAPHDEF \r\n--inference_type=FLOAT \r\n--output_format=TFLITE \r\n--input_shapes=1,224,224,3 \r\n--input_arrays=input \r\n--output_arrays=MobilenetV1/Predictions/Reshape_1\r\n--inference_type=QUANTIZED_UINT8\r\n--std_values=128\r\n--mean_values=128\r\n------------------------\r\n\r\nSystem information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):NO\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac os 10.13.5\r\n\r\nTensorFlow installed from (source or binary):pip\r\n\r\nTensorFlow version (use command below):'1.8.0\r\n\r\nPython version: 3.6.4\r\n\r\nBazel version (if compiling from source):\r\nBuild label: 0.14.0-homebrew\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Jun 1 14:26:58 2018 (1527863218)\r\nBuild timestamp: 1527863218\r\nBuild timestamp as int: 1527863218\r\n\r\nGCC/Compiler version (if compiling from source):no\r\n\r\nCUDA/cuDNN version:no\r\n\r\nGPU model and memory:no\r\n\r\nExact command to reproduce:no\r\n\r\nEnd of run log:\r\n\r\n./tensorflow/contrib/lite/builtin_op_data.h:122:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:125:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:161:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:164:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:203:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n5 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/model.cc:\r\nIn file included from tensorflow/contrib/lite/model.cc:25:\r\n./tensorflow/contrib/lite/builtin_op_data.h:122:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:125:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:161:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:164:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n./tensorflow/contrib/lite/builtin_op_data.h:203:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n^\r\n5 warnings generated.\r\nINFO: From Linking external/protobuf_archive/libprotobuf.a:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf.a(gzip_stream.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf.a(error_listener.o) has no symbols\r\nINFO: From Linking external/protobuf_archive/libprotobuf_lite.a:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(arenastring.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(atomicops_internals_x86_msvc.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(io_win32.o) has no symbols\r\nINFO: From Compiling tensorflow/core/lib/strings/numbers.cc:\r\ntensorflow/core/lib/strings/numbers.cc:394:34: warning: format specifies type 'unsigned long ' but the argument has type 'uint64_t ' (aka 'unsigned long long ') [-Wformat]\r\nif (sscanf(s.c_str(), \"%lx%c\", &result, &junk) == 1) {\r\n~~~ ^~~~~~~\r\n%llx\r\n1 warning generated.\r\nINFO: From Linking tensorflow/core/liblib_internal_impl.a:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/liblib_internal_impl.a(android_armv7a_cpu_utils_helper.o) has no symbols\r\nINFO: From Compiling tensorflow/core/util/command_line_flags.cc:\r\ntensorflow/core/util/command_line_flags.cc:73:37: warning: format specifies type 'long ' but the argument has type 'int64_t ' (aka 'long long ') [-Wformat]\r\nif (sscanf(arg.data(), \"%ld%c\", &parsed_int64, &extra) != 1) {\r\n~~~ ^~~~~~~~~~~~~\r\n%lld\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/util/strided_slice_op.cc:\r\ntensorflow/core/util/strided_slice_op.cc:270:33: warning: lambda capture 'i' is not used [-Wunused-lambda-capture]\r\nauto canonical = [stride_i, i, dim_i, masks, valid_range](int64 x, int c) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_default_min_max.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_default_min_max.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/dump_graphviz.cc:\r\nIn file included from tensorflow/contrib/lite/toco/dump_graphviz.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/dump_graphviz.h:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_stack.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_stack.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_activation_function_into_constants.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_activation_function_into_constants.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_merge.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_merge.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_slice_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_slice_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_array_data_types.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_array_data_types.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tooling_util.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tooling_util.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tooling_util.h:31:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_binary.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_binary.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_addn_to_add.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_addn_to_add.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_fake_quant.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_fake_quant.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_slice.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_slice.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\ntensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:51:6: warning: unused function 'Filter' [-Wunused-function]\r\nvoid Filter(std::vector vec, int value) {\r\n^\r\n3 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_strided_slice.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_strided_slice.cc:18:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_assert.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_assert.cc:19:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/experimental_shuffle_fc_weights.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/experimental_shuffle_fc_weights.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_following_affine.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_following_affine.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/drop_im2col_arrays.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/drop_im2col_arrays.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_activation_func.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_activation_func.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_multiply_by_zero.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_multiply_by_zero.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fill.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fill.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_shape_or_rank.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_shape_or_rank.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation_input.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation_input.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_l2_pool.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_l2_pool.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_squeeze_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_squeeze_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_range.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_range.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/merge_reshape_into_preceding_transpose.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/merge_reshape_into_preceding_transpose.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_binary.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_binary.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unroll_batch_matmul.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/unroll_batch_matmul.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_to_space_nd_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_to_space_nd_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_reshape.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_split_inputs.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_split_inputs.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_stack_to_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_stack_to_reshape.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/make_initial_dequantize_operator.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/make_initial_dequantize_operator.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_reshape.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_passthrough.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_passthrough.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/quantization_util.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/quantization_util.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_transpose.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_transpose.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_final_dequantize_op.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_final_dequantize_op.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_slice.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_slice.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.h:22:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_reorder_axes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_reorder_axes.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc:19:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_mean_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_mean_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/read_fake_quant_min_max.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/read_fake_quant_min_max.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/create_im2col_arrays.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/create_im2col_arrays.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_concat.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_concat.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/drop_fake_quant.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/drop_fake_quant.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:18:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_reshape_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_reshape_attributes.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_l2_normalization.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_l2_normalization.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_merge_inputs.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_merge_inputs.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_prelu.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_prelu.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_relu1.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_relu1.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_unused_op.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_unused_op.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unfuse_activation_functions.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/unfuse_activation_functions.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_activation_functions.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_activation_functions.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_fake_quant_num_bits.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_fake_quant_num_bits.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_pad_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_pad_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc:19:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_gather.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_gather.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc:17:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_space_to_batch_nd_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_space_to_batch_nd_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_matmul.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_matmul.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_padv2_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_padv2_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_squeeze_to_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_squeeze_to_reshape.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_concatenation.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_concatenation.cc:22:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_tile.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_tile.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_identity.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_identity.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/ensure_bias_vectors.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/ensure_bias_vectors.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:24:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_transpose_attributes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_transpose_attributes.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:18:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_expanddims_to_reshape.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_expanddims_to_reshape.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_reorder_axes.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/convert_reorder_axes.cc:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_min_max.cc:\r\nIn file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_min_max.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.h:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.h:22:\r\nIn file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.h:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.h:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tflite/types.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tflite/types.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tflite/types.h:19:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tflite/import.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tflite/import.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tflite/import.h:19:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\ntensorflow/contrib/lite/toco/tflite/import.cc:168:6: warning: unused function 'Verify' [-Wunused-function]\r\nbool Verify(const void buf, size_t len) {\r\n^\r\n3 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tflite/export.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tflite/export.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tflite/export.h:18:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tflite/operator.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tflite/operator.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tflite/operator.h:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/priority_queue.cc:\r\nIn file included from tensorflow/core/kernels/priority_queue.cc:25:\r\nIn file included from ./tensorflow/core/kernels/priority_queue.h:27:\r\n./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::deque& sq) {\r\n^\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/fifo_queue.cc:\r\nIn file included from tensorflow/core/kernels/fifo_queue.cc:26:\r\nIn file included from ./tensorflow/core/kernels/fifo_queue.h:26:\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/padding_fifo_queue.cc:\r\nIn file included from tensorflow/core/kernels/padding_fifo_queue.cc:26:\r\nIn file included from ./tensorflow/core/kernels/padding_fifo_queue.h:27:\r\nIn file included from ./tensorflow/core/kernels/fifo_queue.h:26:\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/framework/reader_base.cc:\r\ntensorflow/core/framework/reader_base.cc:205:17: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\ncontext, [this, context, &n, &work](const QueueInterface::Tuple& tuple) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/initializable_lookup_table.cc:\r\nIn file included from tensorflow/core/kernels/initializable_lookup_table.cc:16:\r\n./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nStatus ExportValues(OpKernelContext context) {\r\n^\r\n./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here\r\nvirtual Status ExportValues(OpKernelContext ctx) = 0;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/lookup_util.cc:\r\nIn file included from tensorflow/core/kernels/lookup_util.cc:16:\r\nIn file included from ./tensorflow/core/kernels/lookup_util.h:21:\r\n./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nStatus ExportValues(OpKernelContext context) {\r\n^\r\n./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here\r\nvirtual Status ExportValues(OpKernelContext ctx) = 0;\r\n^\r\n1 warning generated.\r\nINFO: From Linking tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo(fused_batch_norm_op.cu.o) has no symbols\r\nwarning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo the table of contents is empty (no object file members in the library define global symbols)\r\nINFO: From Compiling tensorflow/core/kernels/boosted_trees/prediction_ops.cc:\r\ntensorflow/core/kernels/boosted_trees/prediction_ops.cc:115:41: warning: lambda capture 'batch_size' is not used [-Wunused-lambda-capture]\r\n&output_node_ids, batch_size,\r\n^\r\ntensorflow/core/kernels/boosted_trees/prediction_ops.cc:225:21: warning: lambda capture 'batch_size' is not used [-Wunused-lambda-capture]\r\nbatch_size, latest_tree](int32 start, int32 end) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/collective_ops.cc:\r\ntensorflow/core/kernels/collective_ops.cc:143:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]\r\nauto actual_done = [c, col_exec, done](const Status& s) {\r\n^\r\ntensorflow/core/kernels/collective_ops.cc:197:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]\r\nauto actual_done = [c, col_exec, done](const Status& s) {\r\n^\r\ntensorflow/core/kernels/collective_ops.cc:247:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]\r\nauto actual_done = [c, col_exec, done](const Status& s) {\r\n^\r\n3 warnings generated.\r\nINFO: From Linking tensorflow/core/kernels/libself_adjoint_eig_v2_op.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libself_adjoint_eig_v2_op.lo(self_adjoint_eig_v2_op_gpu.o) has no symbols\r\nINFO: From Linking tensorflow/core/kernels/libcudnn_rnn_kernels.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libcudnn_rnn_kernels.lo(cudnn_rnn_ops.o) has no symbols\r\nwarning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libcudnn_rnn_kernels.lo the table of contents is empty (no object file members in the library define global symbols)\r\nINFO: From Compiling tensorflow/contrib/tensorboard/db/summary_db_writer.cc:\r\ntensorflow/contrib/tensorboard/db/summary_db_writer.cc:812:22: warning: private field 'meta_' is not used [-Wunused-private-field]\r\nRunMetadata* const meta_;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/sdca_internal.cc:\r\ntensorflow/core/kernels/sdca_internal.cc:49:9: warning: suggest braces around initialization of subobject [-Wmissing-braces]\r\nEigen::IndexPair(1, 0)};\r\n^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n{ }\r\ntensorflow/core/kernels/sdca_internal.cc:210:11: warning: suggest braces around initialization of subobject [-Wmissing-braces]\r\nEigen::IndexPair(1, 1)};\r\n^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n{ }\r\n2 warnings generated.\r\nINFO: From Linking tensorflow/core/kernels/libgather_functor.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libgather_functor.lo(gather_functor.o) has no symbols\r\nwarning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libgather_functor.lo the table of contents is empty (no object file members in the library define global symbols)\r\nINFO: From Compiling tensorflow/core/kernels/adjust_saturation_op.cc:\r\ntensorflow/core/kernels/adjust_saturation_op.cc:196:12: warning: lambda capture 'channel_count' is not used [-Wunused-lambda-capture]\r\n[channel_count, &input_data, &output_data, scale_h](\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/adjust_hue_op.cc:\r\ntensorflow/core/kernels/adjust_hue_op.cc:219:12: warning: lambda capture 'channel_count' is not used [-Wunused-lambda-capture]\r\n[channel_count, &input_data, &output_data, delta_h](\r\n^\r\n1 warning generated.\r\nINFO: From Linking tensorflow/core/kernels/libconcat_lib.a:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libconcat_lib.a(concat_lib_gpu.o) has no symbols\r\nINFO: From Linking tensorflow/core/kernels/libscatter_functor.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_functor.lo(scatter_functor.o) has no symbols\r\nwarning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_functor.lo the table of contents is empty (no object file members in the library define global symbols)\r\nINFO: From Linking tensorflow/core/kernels/libscatter_nd_op.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_nd_op.lo(scatter_nd_op_cpu_impl_0.o) has no symbols\r\nINFO: From Compiling tensorflow/core/common_runtime/collective_rma_local.cc:\r\nIn file included from tensorflow/core/common_runtime/collective_rma_local.cc:15:\r\n./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nvoid StartAbort(const Status& s);\r\n^\r\n./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here\r\nvirtual void StartAbort(const Status& s) = 0;\r\n^\r\ntensorflow/core/common_runtime/collective_rma_local.cc:40:13: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\nkey, [this, to_tensor, to_device_ctx, to_device, to_alloc_attr, done](\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/executor.cc:\r\ntensorflow/core/common_runtime/executor.cc:2082:19: warning: calling function 'ActivateNodes' requires holding mutex 'output_frame->mu' exclusively [-Wthread-safety-precise]\r\noutput_frame->ActivateNodes(item, is_dead, output_iter, outputs, ready);\r\n^\r\ntensorflow/core/common_runtime/executor.cc:2082:19: note: found near match 'input_frame->mu'\r\ntensorflow/core/common_runtime/executor.cc:2147:21: warning: calling function 'ActivateNodes' requires holding mutex 'output_frame->mu' exclusively [-Wthread-safety-precise]\r\noutput_frame->ActivateNodes(item, is_dead, output_iter, outputs, ready);\r\n^\r\ntensorflow/core/common_runtime/executor.cc:2147:21: note: found near match 'input_frame->mu'\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/ring_reducer.cc:\r\nIn file included from tensorflow/core/common_runtime/ring_reducer.cc:17:\r\n./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nvoid StartAbort(const Status& s);\r\n^\r\n./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here\r\nvirtual void StartAbort(const Status& s) = 0;\r\n^\r\ntensorflow/core/common_runtime/ring_reducer.cc:166:19: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\noutput_, [this, &note, &status](const Status& s) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/accumulate_n_optimizer.cc:\r\ntensorflow/core/common_runtime/accumulate_n_optimizer.cc:77:31: warning: lambda capture 'g' is not used [-Wunused-lambda-capture]\r\nauto base_make_node = [n, g, &n_attrs](const string& op,\r\n^\r\ntensorflow/core/common_runtime/accumulate_n_optimizer.cc:89:30: warning: lambda capture 'n_attrs' is not used [-Wunused-lambda-capture]\r\nauto make_node = [n, g, &n_attrs, &base_make_node](string op) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/broadcaster.cc:\r\nIn file included from tensorflow/core/common_runtime/broadcaster.cc:17:\r\n./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nvoid StartAbort(const Status& s);\r\n^\r\n./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here\r\nvirtual void StartAbort(const Status& s) = 0;\r\n^\r\ntensorflow/core/common_runtime/broadcaster.cc:148:25: warning: lambda capture 'recv_from_rank' is not used [-Wunused-lambda-capture]\r\n[this, recv_from_rank, &mu, &note](const Status& s) {\r\n^\r\ntensorflow/core/common_runtime/broadcaster.cc:166:18: warning: lambda capture 'target_rank' is not used [-Wunused-lambda-capture]\r\n[this, target_rank, &mu, &pending_count, &all_done](const Status& s) {\r\n^\r\n3 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/parallel_concat_optimizer.cc:\r\ntensorflow/core/common_runtime/parallel_concat_optimizer.cc:53:33: warning: lambda capture 'g' is not used [-Wunused-lambda-capture]\r\nauto base_make_node = [n, g, &n_attrs](const string& op,\r\n^\r\ntensorflow/core/common_runtime/parallel_concat_optimizer.cc:63:32: warning: lambda capture 'n_attrs' is not used [-Wunused-lambda-capture]\r\nauto make_node = [n, g, &n_attrs, &base_make_node](string op) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/collective_executor_mgr.cc:\r\nIn file included from tensorflow/core/common_runtime/collective_executor_mgr.cc:19:\r\n./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nvoid StartAbort(const Status& s);\r\n^\r\n./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here\r\nvirtual void StartAbort(const Status& s) = 0;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/function.cc:\r\ntensorflow/core/common_runtime/function.cc:911:12: warning: lambda capture 'item' is not used [-Wunused-lambda-capture]\r\n[item, frame, exec_args](DoneCallback done,\r\n^\r\ntensorflow/core/common_runtime/function.cc:911:18: warning: lambda capture 'frame' is not used [-Wunused-lambda-capture]\r\n[item, frame, exec_args](DoneCallback done,\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/collective_param_resolver_local.cc:\r\ntensorflow/core/common_runtime/collective_param_resolver_local.cc:534:47: warning: lambda capture 'gr' is not used [-Wunused-lambda-capture]\r\nirec->init_waiters.push_back([this, gr, cp, done](InstanceRec* irec) {\r\n^\r\ntensorflow/core/common_runtime/collective_param_resolver_local.cc:534:51: warning: lambda capture 'cp' is not used [-Wunused-lambda-capture]\r\nirec->init_waiters.push_back([this, gr, cp, done](InstanceRec* irec) {\r\n^\r\ntensorflow/core/common_runtime/collective_param_resolver_local.cc:669:50: warning: reading variable 'source_rank' requires holding mutex 'ir->out_mu' [-Wthread-safety-precise]\r\nsource_rank = ir->source_rank;\r\n^\r\ntensorflow/core/common_runtime/collective_param_resolver_local.cc:669:50: note: found near match 'irec->out_mu'\r\ntensorflow/core/common_runtime/collective_param_resolver_local.cc:662:29: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\n[this, ir, device, cp, done](InstanceRec* irec) {\r\n^\r\n4 warnings generated.\r\nINFO: From Linking tensorflow/core/libcore_cpu_impl.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_cpu_allocator.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_layout_pass.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_tfconversion_pass.o) has no symbols\r\nINFO: From Compiling tensorflow/core/common_runtime/gpu/process_state.cc:\r\ntensorflow/core/common_runtime/gpu/process_state.cc:56:6: warning: unused function 'useCudaMallocAllocator' [-Wunused-function]\r\nbool useCudaMallocAllocator() {\r\n^\r\ntensorflow/core/common_runtime/gpu/process_state.cc:62:6: warning: unused function 'useCudaMemoryGuardAllocator' [-Wunused-function]\r\nbool useCudaMemoryGuardAllocator() {\r\n^\r\n2 warnings generated.\r\nINFO: From Linking tensorflow/core/libgpu_runtime_impl.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device_factory.o) has no symbols\r\nINFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_util.cc:\r\nIn file included from tensorflow/contrib/lite/toco/tensorflow_util.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/tensorflow_util.h:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/export_tensorflow.cc:\r\nIn file included from tensorflow/contrib/lite/toco/export_tensorflow.cc:25:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\ntensorflow/contrib/lite/toco/export_tensorflow.cc:1731:6: warning: unused function 'ConvertSparseToDenseOperator' [-Wunused-function]\r\nvoid ConvertSparseToDenseOperator(const Model& model,\r\n^\r\n3 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:\r\nIn file included from tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:23:\r\nIn file included from ./tensorflow/contrib/lite/toco/allocate_transient_arrays.h:18:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/toco_tooling.cc:\r\nIn file included from tensorflow/contrib/lite/toco/toco_tooling.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/toco_tooling.h:21:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/contrib/lite/toco/import_tensorflow.cc:\r\nIn file included from tensorflow/contrib/lite/toco/import_tensorflow.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/toco/import_tensorflow.h:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/grappler/optimizers/remapper.cc:\r\nIn file included from tensorflow/core/grappler/optimizers/remapper.cc:16:\r\n./tensorflow/core/grappler/optimizers/remapper.h:42:26: warning: private field 'opt_level' is not used [-Wunused-private-field]\r\nRewriterConfig::Toggle opt_level;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/grappler/optimizers/shape_optimizer.cc:\r\nIn file included from tensorflow/core/grappler/optimizers/shape_optimizer.cc:16:\r\n./tensorflow/core/grappler/optimizers/shape_optimizer.h:48:26: warning: private field 'opt_level' is not used [-Wunused-private-field]\r\nRewriterConfig::Toggle opt_level;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/data/parallel_map_dataset_op.cc:\r\ntensorflow/core/kernels/data/parallel_map_dataset_op.cc:343:24: warning: lambda capture 'result_index' is not used [-Wunused-lambda-capture]\r\n[result, result_index](Status ret_status) {\r\n^\r\n1 warning generated.\r\nINFO: From Linking tensorflow/core/libsycl_runtime.a:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_allocator.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device_context.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device_factory.o) has no symbols\r\nwarning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a the table of contents is empty (no object file members in the library define global symbols)\r\nINFO: From Compiling tensorflow/core/kernels/fifo_queue_op.cc:\r\nIn file included from tensorflow/core/kernels/fifo_queue_op.cc:26:\r\nIn file included from ./tensorflow/core/kernels/fifo_queue.h:26:\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/random_shuffle_queue_op.cc:\r\nIn file included from tensorflow/core/kernels/random_shuffle_queue_op.cc:28:\r\n./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::deque& sq) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/padding_fifo_queue_op.cc:\r\nIn file included from tensorflow/core/kernels/padding_fifo_queue_op.cc:27:\r\nIn file included from ./tensorflow/core/kernels/padding_fifo_queue.h:27:\r\nIn file included from ./tensorflow/core/kernels/fifo_queue.h:26:\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/tensor_array_ops.cc:\r\ntensorflow/core/kernels/tensor_array_ops.cc:330:21: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\nauto creator = [this, key, tensor_array, array_size, marked_size,\r\n^\r\ntensorflow/core/kernels/tensor_array_ops.cc:332:21: warning: lambda capture 'output_handle' is not used [-Wunused-lambda-capture]\r\noutput_handle](TensorArray** ret) -> Status {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/priority_queue_op.cc:\r\nIn file included from tensorflow/core/kernels/priority_queue_op.cc:25:\r\nIn file included from ./tensorflow/core/kernels/priority_queue.h:27:\r\n./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::deque& sq) {\r\n^\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/barrier_ops.cc:\r\ntensorflow/core/kernels/barrier_ops.cc:512:33: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\nComputeAsync(ctx, barrier, this, callback, barrier {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManyEigen::half' requested here\r\nbarrier->TryInsertMany(keys, component_index_, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOpEigen::half::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOpEigen::half::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::bfloat16' requested here\r\nbarrier->TryInsertMany(keys, component_index_, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::bfloat16::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::bfloat16::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(keys, component_index_, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(keys, component_index_, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::complex >' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::complex >' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::_1::complex >::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::basic_string >' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::basic_string >::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::1::basic_string >::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::ResourceHandle' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::ResourceHandle::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::ResourceHandle::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]\r\nthis, ctx, callback, component_index {\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::Variant' requested here\r\nbarrier->TryInsertMany(*keys, component_index, values, ctx, callback);\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::Variant::ComputeAsync' requested here\r\nexplicit InsertManyOp(OpKernelConstruction context)\r\n^\r\ntensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::Variant::InsertManyOp' requested here\r\nTF_CALL_ALL_TYPES(REGISTER_INSERTMANY);\r\n^\r\nIn file included from tensorflow/core/kernels/barrier_ops.cc:28:\r\nIn file included from ./tensorflow/core/kernels/priority_queue.h:27:\r\n./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::deque& sq) {\r\n^\r\n./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]\r\nint64 SizeOf(const std::vector& sq) {\r\n^\r\n19 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/lookup_table_init_op.cc:\r\nIn file included from tensorflow/core/kernels/lookup_table_init_op.cc:17:\r\nIn file included from ./tensorflow/core/kernels/lookup_table_init_op.h:19:\r\n./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nStatus ExportValues(OpKernelContext context) {\r\n^\r\n./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here\r\nvirtual Status ExportValues(OpKernelContext ctx) = 0;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/generate_vocab_remapping_op.cc:\r\nIn file included from tensorflow/core/kernels/generate_vocab_remapping_op.cc:23:\r\nIn file included from ./tensorflow/core/kernels/lookup_table_init_op.h:19:\r\n./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nStatus ExportValues(OpKernelContext context) {\r\n^\r\n./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here\r\nvirtual Status ExportValues(OpKernelContext ctx) = 0;\r\n^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/kernels/lookup_table_op.cc:\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\nIn file included from ./tensorflow/core/kernels/lookup_table_op.h:25:\r\nIn file included from ./tensorflow/core/kernels/lookup_util.h:21:\r\n./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]\r\nStatus ExportValues(OpKernelContext* context) {\r\n^\r\n./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here\r\nvirtual Status ExportValues(OpKernelContext* ctx) = 0;\r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle_' requires holding mutex 'mu_' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle_.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, double>, std::__1::basic_string, double>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:815:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, double>, std::1::basic_string, double>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, double);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:816:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, int>, std::__1::basic_string, int>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:817:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, int>, std::1::basic_string, int>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, int32);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:818:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, int64);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, std::1::basic_string >, long long, std::1::basic_string >::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:819:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, string);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, long long>, long long, long long>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:820:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, long long>, long long, long long>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, int64);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, float>, long long, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:821:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, float>, long long, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, std::__1::basic_string >, std::__1::basic_string, std::__1::basic_string >::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:822:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, std::__1::basic_string >, std::_1::basic_string, std::1::basic_string >::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, string);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:823:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, bool);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<int, int>, int, int>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:824:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<int, int>, int, int>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int32, int32);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:845:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:846:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::_1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, int64);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, std::__1::basic_string >, long long, std::__1::basic_string >::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:847:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, string);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:848:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, bool);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, float>, long long, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:849:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, float>, long long, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, tensorflow::Variant>, long long, tensorflow::Variant>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:850:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, tensorflow::Variant>, long long, tensorflow::Variant>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, Variant);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:871:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:872:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::_1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, int64);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<long long, std::_1::basic_string >, long long, std::1::basic_string >::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:873:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, string);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:874:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, bool);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, long long>, long long, long long>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:895:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, long long>, long long, long long>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, int64);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, float>, long long, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:896:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, float>, long long, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, double>, long long, double>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:897:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, double>, long long, double>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, double);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:898:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, float);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::__1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:899:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here\r\nREGISTER_KERNEL(string, bool);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, bool>, long long, bool>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:900:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, bool>, long long, bool>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, bool);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\nIn file included from tensorflow/core/kernels/lookup_table_op.cc:16:\r\n./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]\r\ncontainer->MemoryUsed() + table_handle.AllocatedBytes());\r\n^\r\n./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, tensorflow::Variant>, long long, tensorflow::Variant>::Compute' requested here\r\nexplicit LookupTableOp(OpKernelConstruction* ctx)\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:901:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, tensorflow::Variant>, long long, tensorflow::Variant>::LookupTableOp' requested here\r\nREGISTER_KERNEL(int64, Variant);\r\n^\r\ntensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'\r\nLookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, \r\n^\r\n28 warnings generated.\r\n[1,781 / 2,012] 4 actions running\r\nCompiling tensorflow/core/kernels/sparse_tensors_map_ops.cc; 13s local\r\nINFO: From Compiling tensorflow/core/kernels/deep_conv2d.cc:\r\ntensorflow/core/kernels/deep_conv2d.cc:1005:30: warning: lambda capture 'tile_rows' is not used [-Wunused-lambda-capture]\r\nout_depth, tile_rows, tile_cols, out_tile_rows, out_tile_cols,\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:1154:26: note: in instantiation of member function 'tensorflow::functor::DeepConv2D<Eigen::ThreadPoolDevice, float>::operator()' requested here\r\ntemplate struct functor::DeepConv2D<CPUDevice, float>;\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:1005:41: warning: lambda capture 'tile_cols' is not used [-Wunused-lambda-capture]\r\nout_depth, tile_rows, tile_cols, out_tile_rows, out_tile_cols,\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:436:55: warning: lambda capture 'out_depth' is not used [-Wunused-lambda-capture]\r\n&num_filters_transform, &in_depth, &out_depth,\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:974:5: note: in instantiation of member function 'tensorflow::TransformFilters::operator()' requested here\r\nTransformFilters()(ctx, args, transform.get(), filter_shards_row,\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:535:20: warning: lambda capture 'tile_spatial_size' is not used [-Wunused-lambda-capture]\r\n&tile_spatial_size, &in_depth, &out_depth, &filter_shards_row,\r\n^\r\ntensorflow/core/kernels/deep_conv2d.cc:979:5: note: in instantiation of member function 'tensorflow::PackFilters::operator()' requested here\r\nPackFilters()(ctx, args, tile_spatial_size, filter_shards_row,\r\n^\r\n4 warnings generated.\r\nINFO: From Linking tensorflow/core/kernels/libpooling_ops.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libpooling_ops.lo(cudnn_pooling_gpu.o) has no symbols\r\nINFO: From Compiling tensorflow/core/kernels/topk_op.cc:\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, long long>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, long long>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, long long>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, int>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, int>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, int>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned short>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned short>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned short>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, short>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, short>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, short>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned char>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned char>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned char>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, signed char>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, signed char>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, signed char>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::half>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, Eigen::half>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, Eigen::half>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, float>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, float>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, float>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\ntensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]\r\nauto SortIndices = [&, context](int start_batch, int limit_batch) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, double>::Compute' requested here\r\nStatus s = functor::TopKFunctor<Device, T>::Compute(\r\n^\r\ntensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, double>::Compute' requested here\r\nexplicit TopK(OpKernelConstruction* context) : OpKernel(context) {\r\n^\r\ntensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, double>::TopK' requested here\r\nTF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);\r\n^\r\n10 warnings generated.\r\nINFO: From Linking tensorflow/core/kernels/libconv_ops.lo:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libconv_ops.lo(conv_ops_using_gemm.o) has no symbols\r\nINFO: From Compiling tensorflow/contrib/lite/toco/toco.cc:\r\nIn file included from tensorflow/contrib/lite/toco/toco.cc:20:\r\nIn file included from ./tensorflow/contrib/lite/toco/model.h:26:\r\nIn file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]\r\nc128 = _mm_set1_epi8 (128);\r\n~~~~~~~~~~~~~ ^~~\r\n2 warnings generated.\r\nINFO: From Compiling tensorflow/core/kernels/batch_kernels.cc:\r\ntensorflow/core/kernels/batch_kernels.cc:979:10: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]\r\n[this](UnbatchGradResource** r) {\r\n^\r\n1 warning generated.\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\nbazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 2814.103s, Critical Path: 164.73s\r\nINFO: 2000 processes, local.\r\nINFO: Build completed successfully, 2012 total actions\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/dchealth/Desktop/mobilenet/frozen_graph.pb' '--output_file=/Users/dchealth/Desktop/mobilenet/mobilenetnew.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--inference_type=FLOAT' '--output_format=TFLITE' '--input_type=FLOAT' '--input_shapes=1,224,224,3' '--input_arrays=input' '--output_arrays=MobilenetV1/PredINFO: Build completed successfully, 2012 total actions\r\n2018-06-13 10:34:42.340286: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:251] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\r\n2018-06-13 10:34:42.460038: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 416 operators, 583 arrays (0 quantized)\r\n2018-06-13 10:34:42.470369: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 416 operators, 583 arrays (0 quantized)\r\n2018-06-13 10:34:42.507758: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 31 operators, 89 arrays (0 quantized)\r\n2018-06-13 10:34:42.508374: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 31 operators, 89 arrays (0 quantized)\r\n2018-06-13 10:34:42.508942: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 6422528 bytes, theoretical optimal value: 4816896 bytes.\r\n2018-06-13 10:34:42.509181: I tensorflow/contrib/lite/toco/toco_tooling.cc:373] Estimated count of arithmetic ops: 1.14264 billion (note that a multiply-add is counted as 2 ops).\r\nDCHealthdeMac-mini:toco dchealth$ --inference_type=QUANTIZED_UINT8\r\n-bash: --inference_type=QUANTIZED_UINT8: command not found\r\nDCHealthdeMac-mini:toco dchealth$ --std_values=128\r\n-bash: --std_values=128: command not found\r\nDCHealthdeMac-mini:toco dchealth$ --mean_values=128\u3002", "comments": ["Nagging Assignee @rohan100jain: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "What is the exact reported issue here?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 19970, "title": "Install OSError: [Errno 13] Permission denied:", "body": "I'm trying to install tensorflow on my ubuntu os. The configuration of my machine is ubuntu14.04LTS ,NVIDIA K40*8 gpu,cuda8.0 with cudnn6.0.First,I install with Virtualenv,I follow the instructions on **https://www.tensorflow.org/install/install_linux#installing_with_virtualenv** step by step,\r\nbut after the last step,I got the error:\r\n_\r\n\r\n> Exception:\r\n> Traceback (most recent call last):\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 215, in main\r\n>     status = self.run(options, args)\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 324, in run\r\n>     requirement_set.prepare_files(finder)\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 380, in prepare_files\r\n>     ignore_dependencies=self.ignore_dependencies))\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_set.py\", line 554, in _prepare_file\r\n>     require_hashes\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/req/req_install.py\", line 281, in populate_link\r\n>     self.link = self._wheel_cache.cached_wheel(self.link, self.name)\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 68, in cached_wheel\r\n>     self._cache_dir, link, self._format_control, package_name)\r\n>   File \"/usr/lib/python2.7/dist-packages/pip/wheel.py\", line 129, in cached_wheel\r\n>     wheel_names = os.listdir(root)\r\n> OSError: [Errno 13] Permission denied: '/home/cs/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6'\r\n\r\n_\r\nWhat's the matter?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Well,I install tensorflow with virtualenv,just follow the instructions in https://www.tensorflow.org/install/install_linux#installing_with_virtualenv.The step5 and step6 fails with the same error code:OSError: [Errno 13] Permission denied: '/usr/lib/python2.7/dist-packages/numpy/distutils/tests/gen_ext/__init__.pyc'\r\nMy OS is ubuntu14.04 ,the details are Linux node4 3.16.0-33-generic #44~14.04.1-Ubuntu SMP Fri Mar 13 10:33:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux,\r\nCUDA Version 8.0.44\r\nand cuDNN is\r\n#define CUDNN_MAJOR      6\r\n#define CUDNN_MINOR      0\r\n#define CUDNN_PATCHLEVEL 21\r\n#define CUDNN_VERSION    (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n#include \"driver_types.h\"\r\n\r\nGPU:Tesla K80 ,with NVIDIA-SMI 390.48  \r\nand the error occurs when\r\nSuccessfully installed absl-py-0.2.2 astor-0.6.2 backports.weakref-1.0.post1 bleach-1.5.0 enum34-1.1.6 funcsigs-1.0.2 futures-3.2.0 gast-0.2.0 grpcio-1.12.1 html5lib-0.9999999 markdown-2.6.11 mock-2.0.0 numpy-1.14.3 pbr-4.0.2 protobuf-3.5.2.post1 setuptools-39.1.0 six-1.11.0 tensorboard-1.8.0 tensorflow-gpu-1.8.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.31.0\r\nException:\r\nTraceback (most recent call last):\r\n  File \"/home/cs/TF-Workspace/local/lib/python2.7/site-packages/pip-10.0.1-py2.7.egg/pip/_internal/basecommand.py\", line 228, in main\r\n    status = self.run(options, args)\r\n  File \"/home/cs/TF-Workspace/local/lib/python2.7/site-packages/pip-10.0.1-py2.7.egg/pip/_internal/commands/install.py\", line 381, in run\r\n    options.target_dir, target_temp_dir, options.upgrade\r\n  File \"/home/cs/TF-Workspace/local/lib/python2.7/site-packages/pip-10.0.1-py2.7.egg/pip/_internal/commands/install.py\", line 432, in _handle_target_dir\r\n    shutil.rmtree(target_item_dir)\r\n  File \"/usr/lib/python2.7/shutil.py\", line 247, in rmtree\r\n    rmtree(fullname, ignore_errors, onerror)\r\n  File \"/usr/lib/python2.7/shutil.py\", line 247, in rmtree\r\n    rmtree(fullname, ignore_errors, onerror)\r\n  File \"/usr/lib/python2.7/shutil.py\", line 247, in rmtree\r\n    rmtree(fullname, ignore_errors, onerror)\r\n  File \"/usr/lib/python2.7/shutil.py\", line 252, in rmtree\r\n    onerror(os.remove, fullname, sys.exc_info())\r\n  File \"/usr/lib/python2.7/shutil.py\", line 250, in rmtree\r\n    os.remove(fullname)\r\nOSError: [Errno 13] Permission denied: '/usr/lib/python2.7/dist-packages/numpy/distutils/tests/gen_ext/__init__.pyc'\r\n\r\n\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 19969, "title": "Is there a way to load a TF graph just once, and run it multiple times?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nWindows 10 Home, running TF on Colab and on VM on GCP.\r\n\r\n- **TensorFlow installed from (source or binary)**: \r\n\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n\r\n1.8.0\r\n- **Python version**: \r\n\r\n3.6.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: Tesla K80, 12 GB\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nI have a TF model that was saved with the tf.train.Saver class, and so I have the .meta file, the data-00000-of-00001 file, the index file and the checkpoint file.\r\n\r\nI use it for inference like this :\r\n\r\n```\r\n    graph_num = tf.Graph()\r\n    with graph_num.as_default():\r\n        sess = tf.Session()\r\n        with sess.as_default():\r\n\r\n            new_saver = tf.train.import_meta_graph('{}.meta'.format(model_path), clear_devices=True)\r\n            new_saver.restore(sess, ('{}'.format(model_path)))\r\n            sess.run(tf.tables_initializer())\r\n\r\n            arr_placeholder = graph_num.get_operation_by_name('arr_placeholder/inp_array').outputs[0]\r\n            str_placeholder = graph_num.get_operation_by_name('str_placeholder/inp_string').outputs[0]\r\n            dropout_keep_prob = graph_num.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]\r\n\r\n            logis = graph_num.get_tensor_by_name('logits/preds/BiasAdd:0')\r\n\r\n            def model_api(input_data):\r\n                # ...preprocessing the input_data...\r\n\r\n                a = sess.run(tf.nn.softmax(logis),\r\n                             feed_dict={\r\n                                 arr_placeholder:\r\n                                     np.array(list_of_primary_inputs).reshape(len(list_of_primary_inputs), 142),\r\n                                 dropout_keep_prob: 1.0, str_placeholder: input_string\r\n                             })\r\n\r\n                return a\r\n```\r\n\r\nSo far so good, but then I call the function like this: \r\n\r\n```\r\ntf.reset_default_graph()\r\nresult = model_api(test_input_data)\r\n```\r\nand each time I call it, it gives me different results for the same test data.\r\n\r\nBut when I instantiate the graph again and then call the function, it gives me the same numbers.\r\n\r\nThis behaviour is rather odd, and I don't want to re load the graph every time I want to pass in a new instance(s).\r\n\r\nI can't use a for loop within the session, because the instances to be predicted come in real time, and so I have to use a function that supports arguments.\r\n\r\nI saw this post too : https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times but that wasn't helping my case.\r\n\r\nI tried freezing the graph ( converting the existing meta graph into .pb ) but that too was giving me an error with one of the lookup tables that I have. And that is filed as a separate issue on GitHub, and unfortunately the workaround mentioned there didn't work for me. That issue is still open : https://github.com/tensorflow/tensorflow/issues/8665\r\n\r\nI have even set tf.set_random_seed to a constant value while training, and tried doing the same to the inference part as well, but to no avail.\r\n\r\nSo right now I'm at my wits end.\r\n\r\n\r\nI have asked this question on SO ( https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times ) too, but that hasn't been helpful.\r\n\r\nWhy does it give me different results each time? And is there a way to load the graph once, and then keep running new instances without running into this issue of inconsistent outputs?\r\n\r\nI couldn't find such a query while researching on this topic, so if there is currently no way to load a graph and run it multiple times all the while producing consistent outputs, can this be considered a feature request?\r\n\r\n", "comments": ["have requirement on similar lines, at the inference time would like to have same(fixed) graph which to be executed for different run time inputs. Currently graph is getting loaded for each request which is over head and taking 1 sec more for every request\r\n\r\nfor eg: we have below approx wrapper which will be called in by webserver via POST/GET at runtime.\r\n```\r\nservice_wrapper(query):\r\n   _input_fn =Lambda: _populatedataset_fn(query)\r\n   return model.predict(_input_fn)\r\n```\r\nnow we are looking for a way where we can expose this as a api in a cloud service which should avoid loading graph multiple times for each query request by the client\r\n\r\n\r\n", "@suharshs can you please comment on how to avoid graph reloading?", "The random outputs problem has been solved, attributed to a bug in Google Sentence Encoder, which was part of the graph, corrected in a later release. ( https://github.com/tensorflow/hub/issues/74 )\r\nBut the reloading part is still a problem. I'm currently using sess.as_default(), and never explicitly closing the session, but this just keeps consuming memory on each POST request.\r\n", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Issue solved after using multiple functions that pass around the session and tensors within a sess.as_default block. ", "Hi ,\r\n\r\nCan you please elaborate this solution. i have a similar problem while using REST API", "What is the specific problem you're facing?", "check this\r\n\r\n```PYTHON\r\nmyGraph = tf.Graph()\r\nsess = tf.Session(graph=myGraph)\r\nwith myGraph.as_default():\r\n    with sess.as_default() as sess:\r\n        saver = tf.train.Save()\r\n        saver.restore(sess, ckpt_file_path)\r\nsess.run(loss)\r\n```"]}, {"number": 19968, "title": "Error raised in renaming the chekpont files while converting tensorflow to tflite. an i/o error", "body": "Error and logs:-\r\n%run \"C:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py\"\r\n[[ 70.   1.   4. ...,   2.   3.   3.]\r\n [ 67.   0.   3. ...,   2.   0.   7.]\r\n [ 57.   1.   2. ...,   1.   0.   7.]\r\n ..., \r\n [ 56.   0.   2. ...,   2.   0.   3.]\r\n [ 57.   1.   4. ...,   2.   0.   6.]\r\n [ 67.   1.   4. ...,   2.   3.   3.]]\r\n[2 1 2 1 1 1 2 2 2 2 1 1 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 2 2 2 2\r\n 2 1 1 2 1 1 1 2 1 2 2 2 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 2 2 1 1 1\r\n 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 1 1 1 2 1 2 2 2 1 2 2 1 2\r\n 1 2 1 1 1 2 2 1 2 2 2 2 1 1 1 2 1 1 2 2 2 1 2 1 1 1 2 1 1 2 1 2 1 2 2 2 2\r\n 2 1 1 1 1 1 1 1 2 1 1 2 2 2 1 2 1 1 1 1 1 2 1 2 2 1 1 2 2 2 2 1 1 2 2 1 1\r\n 1 2 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2 2\r\n 1 2 1 1 2 2 1 1 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 2 1 2 2 2 1 2 1 1 1 1 2 2\r\n 1 1 2 2 1 2 1 1 1 1 2]\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=13, units=7, kernel_initializer=\"uniform\")`\r\n  model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu',input_dim =13))\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=7, kernel_initializer=\"uniform\")`\r\n  model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu'))\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\r\n  model.add(Dense(output_dim = 1,init ='uniform',activation = 'sigmoid'))\r\nTrain on 216 samples, validate on 54 samples\r\nEpoch 1/100\r\n216/216 [==============================] - 2s 11ms/step - loss: 0.6799 - acc: 0.5509 - val_loss: 0.6642 - val_acc: 0.5741\r\nEpoch 2/100\r\n216/216 [==============================] - 0s 440us/step - loss: 0.6428 - acc: 0.5509 - val_loss: 0.6127 - val_acc: 0.5741\r\nEpoch 3/100\r\n216/216 [==============================] - 0s 468us/step - loss: 0.5682 - acc: 0.5509 - val_loss: 0.5131 - val_acc: 0.5741\r\nEpoch 4/100\r\n216/216 [==============================] - 0s 435us/step - loss: 0.4277 - acc: 0.5509 - val_loss: 0.3245 - val_acc: 0.5741\r\nEpoch 5/100\r\n216/216 [==============================] - 0s 491us/step - loss: 0.1722 - acc: 0.5509 - val_loss: 0.0395 - val_acc: 0.5741\r\nEpoch 6/100\r\n216/216 [==============================] - 0s 773us/step - loss: -0.1989 - acc: 0.5509 - val_loss: -0.3623 - val_acc: 0.5741\r\nEpoch 7/100\r\n216/216 [==============================] - 0s 699us/step - loss: -0.7056 - acc: 0.5509 - val_loss: -0.8693 - val_acc: 0.5741\r\nEpoch 8/100\r\n216/216 [==============================] - 0s 690us/step - loss: -1.3514 - acc: 0.5509 - val_loss: -1.5298 - val_acc: 0.5741\r\nEpoch 9/100\r\n216/216 [==============================] - 0s 722us/step - loss: -2.1595 - acc: 0.5509 - val_loss: -2.4054 - val_acc: 0.5741\r\nEpoch 10/100\r\n216/216 [==============================] - 0s 736us/step - loss: -3.2236 - acc: 0.5509 - val_loss: -3.4721 - val_acc: 0.5741\r\nEpoch 11/100\r\n216/216 [==============================] - 0s 727us/step - loss: -4.4167 - acc: 0.5509 - val_loss: -4.1341 - val_acc: 0.5741\r\nEpoch 12/100\r\n216/216 [==============================] - 0s 694us/step - loss: -5.1895 - acc: 0.5509 - val_loss: -4.5694 - val_acc: 0.5741\r\nEpoch 13/100\r\n216/216 [==============================] - 0s 778us/step - loss: -5.6066 - acc: 0.5509 - val_loss: -4.8527 - val_acc: 0.5741\r\nEpoch 14/100\r\n216/216 [==============================] - 0s 801us/step - loss: -5.8476 - acc: 0.5509 - val_loss: -5.0201 - val_acc: 0.5741\r\nEpoch 15/100\r\n216/216 [==============================] - 0s 833us/step - loss: -6.0103 - acc: 0.5509 - val_loss: -5.1307 - val_acc: 0.5741\r\nEpoch 16/100\r\n216/216 [==============================] - 0s 769us/step - loss: -6.1466 - acc: 0.5509 - val_loss: -5.2282 - val_acc: 0.5741\r\nEpoch 17/100\r\n216/216 [==============================] - 0s 838us/step - loss: -6.2473 - acc: 0.5509 - val_loss: -5.3047 - val_acc: 0.5741\r\nEpoch 18/100\r\n216/216 [==============================] - 0s 769us/step - loss: -6.3216 - acc: 0.5509 - val_loss: -5.3923 - val_acc: 0.5741\r\nEpoch 19/100\r\n216/216 [==============================] - 0s 495us/step - loss: -6.4006 - acc: 0.5509 - val_loss: -5.4703 - val_acc: 0.5741\r\nEpoch 20/100\r\n216/216 [==============================] - 0s 426us/step - loss: -6.4667 - acc: 0.5509 - val_loss: -5.5194 - val_acc: 0.5741\r\nEpoch 21/100\r\n216/216 [==============================] - 0s 421us/step - loss: -6.5198 - acc: 0.5509 - val_loss: -5.5850 - val_acc: 0.5741\r\nEpoch 22/100\r\n216/216 [==============================] - 0s 519us/step - loss: -6.5789 - acc: 0.5509 - val_loss: -5.6267 - val_acc: 0.5741\r\nEpoch 23/100\r\n216/216 [==============================] - 0s 764us/step - loss: -6.6248 - acc: 0.5509 - val_loss: -5.6667 - val_acc: 0.5741\r\nEpoch 24/100\r\n216/216 [==============================] - 0s 722us/step - loss: -6.6704 - acc: 0.5509 - val_loss: -5.7129 - val_acc: 0.5741\r\nEpoch 25/100\r\n216/216 [==============================] - 0s 713us/step - loss: -6.7225 - acc: 0.5509 - val_loss: -5.7570 - val_acc: 0.5741\r\nEpoch 26/100\r\n216/216 [==============================] - 0s 685us/step - loss: -6.7649 - acc: 0.5509 - val_loss: -5.7932 - val_acc: 0.5741\r\nEpoch 27/100\r\n216/216 [==============================] - 0s 699us/step - loss: -6.7995 - acc: 0.5509 - val_loss: -5.8360 - val_acc: 0.5741\r\nEpoch 28/100\r\n216/216 [==============================] - 0s 787us/step - loss: -6.8323 - acc: 0.5509 - val_loss: -5.8789 - val_acc: 0.5741\r\nEpoch 29/100\r\n216/216 [==============================] - 0s 769us/step - loss: -6.8675 - acc: 0.5509 - val_loss: -5.9081 - val_acc: 0.5741\r\nEpoch 30/100\r\n216/216 [==============================] - 0s 602us/step - loss: -6.8975 - acc: 0.5509 - val_loss: -5.9513 - val_acc: 0.5741\r\nEpoch 31/100\r\n216/216 [==============================] - 0s 639us/step - loss: -6.9255 - acc: 0.5509 - val_loss: -5.9945 - val_acc: 0.5741\r\nEpoch 32/100\r\n216/216 [==============================] - 0s 778us/step - loss: -6.9587 - acc: 0.5509 - val_loss: -6.0355 - val_acc: 0.5741\r\nEpoch 33/100\r\n216/216 [==============================] - 0s 773us/step - loss: -6.9862 - acc: 0.5509 - val_loss: -6.0792 - val_acc: 0.5741\r\nEpoch 34/100\r\n216/216 [==============================] - 0s 662us/step - loss: -7.0091 - acc: 0.5509 - val_loss: -6.1337 - val_acc: 0.5741\r\nEpoch 35/100\r\n216/216 [==============================] - 0s 653us/step - loss: -7.0404 - acc: 0.5509 - val_loss: -6.1758 - val_acc: 0.5741\r\nEpoch 36/100\r\n216/216 [==============================] - 0s 463us/step - loss: -7.0644 - acc: 0.5509 - val_loss: -6.2262 - val_acc: 0.5741\r\nEpoch 37/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.0898 - acc: 0.5509 - val_loss: -6.2752 - val_acc: 0.5741\r\nEpoch 38/100\r\n216/216 [==============================] - 0s 477us/step - loss: -7.1028 - acc: 0.5509 - val_loss: -6.3258 - val_acc: 0.5741\r\nEpoch 39/100\r\n216/216 [==============================] - 0s 468us/step - loss: -7.1160 - acc: 0.5509 - val_loss: -6.3659 - val_acc: 0.5741\r\nEpoch 40/100\r\n216/216 [==============================] - 0s 426us/step - loss: -7.1259 - acc: 0.5509 - val_loss: -6.4014 - val_acc: 0.5741\r\nEpoch 41/100\r\n216/216 [==============================] - 0s 426us/step - loss: -7.1340 - acc: 0.5509 - val_loss: -6.4243 - val_acc: 0.5741\r\nEpoch 42/100\r\n216/216 [==============================] - 0s 500us/step - loss: -7.1385 - acc: 0.5509 - val_loss: -6.4578 - val_acc: 0.5741\r\nEpoch 43/100\r\n216/216 [==============================] - 0s 727us/step - loss: -7.1431 - acc: 0.5509 - val_loss: -6.4915 - val_acc: 0.5741\r\nEpoch 44/100\r\n216/216 [==============================] - 0s 745us/step - loss: -7.1482 - acc: 0.5509 - val_loss: -6.5163 - val_acc: 0.5741\r\nEpoch 45/100\r\n216/216 [==============================] - 0s 708us/step - loss: -7.1525 - acc: 0.5509 - val_loss: -6.5387 - val_acc: 0.5741\r\nEpoch 46/100\r\n216/216 [==============================] - 0s 676us/step - loss: -7.1557 - acc: 0.5509 - val_loss: -6.5558 - val_acc: 0.5741\r\nEpoch 47/100\r\n216/216 [==============================] - 0s 769us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5746 - val_acc: 0.5741\r\nEpoch 48/100\r\n216/216 [==============================] - 0s 732us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5855 - val_acc: 0.5741\r\nEpoch 49/100\r\n216/216 [==============================] - 0s 745us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5863 - val_acc: 0.5741\r\nEpoch 50/100\r\n216/216 [==============================] - 0s 681us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741\r\nEpoch 51/100\r\n216/216 [==============================] - 0s 1ms/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741\r\nEpoch 52/100\r\n216/216 [==============================] - 0s 838us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741\r\nEpoch 53/100\r\n216/216 [==============================] - 0s 824us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741\r\nEpoch 54/100\r\n216/216 [==============================] - 0s 704us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741\r\nEpoch 55/100\r\n216/216 [==============================] - 0s 565us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741\r\nEpoch 56/100\r\n216/216 [==============================] - 0s 500us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741\r\nEpoch 57/100\r\n216/216 [==============================] - 0s 574us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741\r\nEpoch 58/100\r\n216/216 [==============================] - 0s 556us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741\r\nEpoch 59/100\r\n216/216 [==============================] - 0s 676us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741\r\nEpoch 60/100\r\n216/216 [==============================] - 0s 514us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5872 - val_acc: 0.5741\r\nEpoch 61/100\r\n216/216 [==============================] - 0s 532us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741\r\nEpoch 62/100\r\n216/216 [==============================] - 0s 565us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741\r\nEpoch 63/100\r\n216/216 [==============================] - 0s 593us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741\r\nEpoch 64/100\r\n216/216 [==============================] - 0s 611us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741\r\nEpoch 65/100\r\n216/216 [==============================] - 0s 634us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741\r\nEpoch 66/100\r\n216/216 [==============================] - 0s 657us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741\r\nEpoch 67/100\r\n216/216 [==============================] - 0s 542us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741\r\nEpoch 68/100\r\n216/216 [==============================] - 0s 528us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741\r\nEpoch 69/100\r\n216/216 [==============================] - 0s 523us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741\r\nEpoch 70/100\r\n216/216 [==============================] - 0s 796us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741\r\nEpoch 71/100\r\n216/216 [==============================] - 0s 653us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741\r\nEpoch 72/100\r\n216/216 [==============================] - 0s 676us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741\r\nEpoch 73/100\r\n216/216 [==============================] - 0s 644us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741\r\nEpoch 74/100\r\n216/216 [==============================] - 0s 431us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741\r\nEpoch 75/100\r\n216/216 [==============================] - 0s 417us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741\r\nEpoch 76/100\r\n216/216 [==============================] - 0s 440us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741\r\nEpoch 77/100\r\n216/216 [==============================] - 0s 468us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5886 - val_acc: 0.5741\r\nEpoch 78/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5886 - val_acc: 0.5741\r\nEpoch 79/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5888 - val_acc: 0.5741\r\nEpoch 80/100\r\n216/216 [==============================] - 0s 523us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741\r\nEpoch 81/100\r\n216/216 [==============================] - 0s 482us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741\r\nEpoch 82/100\r\n216/216 [==============================] - 0s 449us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741\r\nEpoch 83/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741\r\nEpoch 84/100\r\n216/216 [==============================] - 0s 426us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741\r\nEpoch 85/100\r\n216/216 [==============================] - 0s 477us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741\r\nEpoch 86/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741\r\nEpoch 87/100\r\n216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741\r\nEpoch 88/100\r\n216/216 [==============================] - 0s 421us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741\r\nEpoch 89/100\r\n216/216 [==============================] - 0s 745us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741\r\nEpoch 90/100\r\n216/216 [==============================] - 0s 704us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741\r\nEpoch 91/100\r\n216/216 [==============================] - 0s 801us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741\r\nEpoch 92/100\r\n216/216 [==============================] - 0s 1ms/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741\r\nEpoch 93/100\r\n216/216 [==============================] - 0s 843us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741\r\nEpoch 94/100\r\n216/216 [==============================] - 0s 801us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741\r\nEpoch 95/100\r\n216/216 [==============================] - 0s 690us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741\r\nEpoch 96/100\r\n216/216 [==============================] - 0s 634us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741\r\nEpoch 97/100\r\n216/216 [==============================] - 0s 542us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741\r\nEpoch 98/100\r\n216/216 [==============================] - 0s 546us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741\r\nEpoch 99/100\r\n216/216 [==============================] - 0s 546us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741\r\nEpoch 100/100\r\n216/216 [==============================] - 0s 528us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741\r\n2018-06-13 10:25:20.269185: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at save_restore_v2_ops.cc:137 : Unknown: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.\r\n; Input/output error\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1321     try:\r\n-> 1322       return fn(*args)\r\n   1323     except errors.OpError as e:\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1306       return self._call_tf_sessionrun(\r\n-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1308 \r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1408           self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1409           run_metadata)\r\n   1410     else:\r\nUnknownError: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.\r\n; Input/output error\r\n[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\nUnknownError                              Traceback (most recent call last)\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py in <module>()\r\n     84 \r\n     85 if __name__ == '__main__':\r\n---> 86     main()\r\n\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py in main()\r\n     81     model = build_model()\r\n     82     train(model, X_train, y_train, X_test, y_test)\r\n---> 83     export_model(tf.train.Saver(), model, [\"Age\",\"Sex\",\"ChestPain\",\"BloodPressure\",\"Cholestrol\",\"Sugar\",\"ExerciseSlope\",\"Electrocardiographic\",\"HeartRate\",\"Exercise\",\"Depression\",\"MajorVessels\",\"DefectType\",\"Heartdisease\" ], \"Heartdisease\")\r\n     84 \r\n     85 if __name__ == '__main__':\r\nC:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py in export_model(saver, model, input_node_names, output_node_name)\r\n     55         MODEL_NAME + '_graph.pbtxt')\r\n     56 \r\n---> 57     saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\r\n     58 \r\n     59     freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\r\n   1701           model_checkpoint_path = sess.run(\r\n   1702               self.saver_def.save_tensor_name,\r\n-> 1703               {self.saver_def.filename_tensor_name: checkpoint_file})\r\n   1704 \r\n   1705         model_checkpoint_path = compat.as_str(model_checkpoint_path)\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1134       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1135                              feed_dict_tensor, options, run_metadata)\r\n   1136     else:\r\n   1137       results = []\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1314     if handle is None:\r\n   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1316                            run_metadata)\r\n   1317     else:\r\n   1318       return self._do_call(_prun_fn, handle, feeds, fetches)\r\nC:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1333         except KeyError:\r\n   1334           pass\r\n-> 1335       raise type(e)(node_def, op, message)\r\n   1336 \r\n   1337   def _extend_graph(self):\r\nUnknownError: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.\r\n; Input/output error\r\n[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]]\r\n\r\nCaused by op 'save_7/SaveV2', defined at:\r\n  File \"<string>\", line 29, in <module>\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 484, in main\r\n    app.start()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tornado\\ioloop.py\", line 831, in start\r\n    self._run_callback(callback)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tornado\\ioloop.py\", line 604, in _run_callback\r\n    ret = callback()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 258, in enter_eventloop\r\n    self.eventloop(self)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\eventloops.py\", line 176, in loop_tk\r\n    kernel.timer.start()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\eventloops.py\", line 173, in start\r\n    self.app.mainloop()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\tkinter\\__init__.py\", line 1131, in mainloop\r\n    self.tk.mainloop(n)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\tkinter\\__init__.py\", line 1550, in __call__\r\n    return self.func(*args)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\tkinter\\__init__.py\", line 596, in callit\r\n    func(*args)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\eventloops.py\", line 168, in on_timer\r\n    self.func()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 291, in do_one_iteration\r\n    stream.flush(zmq.POLLIN, 1)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 352, in flush\r\n    self._handle_recv()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2827, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-10-c5b6ae558f44>\", line 1, in <module>\r\n    get_ipython().magic('run \"C:\\\\Users\\\\DELL\\\\Desktop\\\\iris\\\\final_project\\\\Machine Learning\\\\tfl.py\"')\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2158, in magic\r\n    return self.run_line_magic(magic_name, magic_arg_s)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in run_line_magic\r\n    result = fn(*args,**kwargs)\r\n  File \"<decorator-gen-58>\", line 2, in run\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\magic.py\", line 188, in <lambda>\r\n    call = lambda f, *a, **k: f(*a, **k)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 742, in run\r\n    run()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 728, in run\r\n    exit_ignore=exit_ignore)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 173, in mpl_execfile\r\n    safe_execfile(fname,*where,**kw)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2481, in safe_execfile\r\n    self.compile if kw['shell_futures'] else None)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\IPython\\utils\\py3compat.py\", line 186, in execfile\r\n    exec(compiler(f.read(), fname, 'exec'), glob, loc)\r\n  File \"C:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py\", line 86, in <module>\r\n    main()\r\n  File \"C:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py\", line 83, in main\r\n    export_model(tf.train.Saver(), model, [\"Age\",\"Sex\",\"ChestPain\",\"BloodPressure\",\"Cholestrol\",\"Sugar\",\"ExerciseSlope\",\"Electrocardiographic\",\"HeartRate\",\"Exercise\",\"Depression\",\"MajorVessels\",\"DefectType\",\"Heartdisease\" ], \"Heartdisease\")\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\r\n    tensors)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\r\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\DELL\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nUnknownError (see above for traceback): Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.\r\n; Input/output error\r\n[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]] \r\n\r\n\r\n\r\n\r\n\r\nThe code is:-\r\n\r\n\r\n\r\n\r\n\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Tue Jun 12 17:40:11 2018\r\n\r\n@author: DELL\r\n\"\"\"\r\nimport os\r\nimport os.path as path\r\nimport pandas as pd\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nimport tensorflow as tf\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\nfrom keras import backend as K\r\nMODEL_NAME = \"heart_disease\"\r\n\r\ndef load_data():\r\n    data = pd.read_csv('C:\\\\Users\\\\DELL\\\\Desktop\\\\iris\\\\final_project\\\\Machine Learning\\\\neew.csv')\r\n    X = data.iloc[:,:-1].values\r\n    y = data.iloc[:,13].values\r\n    print(X)\r\n    print(y)\r\n    from sklearn.model_selection import train_test_split \r\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\r\n    \r\n    from sklearn.preprocessing import StandardScaler\r\n    sc_X =StandardScaler()\r\n    X_train = sc_X.fit_transform(X_train)\r\n    X_test = sc_X.transform(X_test)\r\n    return X_train, y_train, X_test, y_test\r\n\r\ndef build_model():\r\n    model = Sequential()\r\n    model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu',input_dim =13))\r\n    model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu'))\r\n    model.add(Dense(output_dim = 1,init ='uniform',activation = 'sigmoid'))\r\n    return model\r\n\r\ndef train(model, X_train, y_train, X_test, y_test):\r\n    model.compile(loss='binary_crossentropy', \\\r\n                  optimizer='adam', \\\r\n                  metrics=['accuracy'])\r\n\r\n    model.fit(X_train, y_train, \\\r\n              batch_size=10, \\\r\n              epochs=100, \\\r\n              verbose=1, \\\r\n              validation_data=(X_test, y_test))\r\n    \r\ndef export_model(saver, model, input_node_names, output_node_name):\r\n    \r\n    tf.train.write_graph(K.get_session().graph_def, 'out', \\\r\n        MODEL_NAME + '_graph.pbtxt')\r\n\r\n    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\r\n\r\n    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\r\n        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\r\n        \"save/restore_all\", \"save/Const:0\", \\\r\n        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\r\n\r\n    input_graph_def = tf.GraphDef()\r\n    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\r\n        input_graph_def.ParseFromString(f.read())\r\n\r\n    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n            input_graph_def, input_node_names, [output_node_name],\r\n            tf.float32.as_datatype_enum)\r\n\r\n    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n\r\n    print(\"graph saved!\")\r\ndef main():\r\n    if not path.exists('out'):\r\n        os.mkdir('out')\r\n\r\n    X_train, y_train, X_test, y_test = load_data()\r\n    model = build_model()\r\n    train(model, X_train, y_train, X_test, y_test)\r\n    export_model(tf.train.Saver(), model, [\"Age\",\"Sex\",\"ChestPain\",\"BloodPressure\",\"Cholestrol\",\"Sugar\",\"ExerciseSlope\",\"Electrocardiographic\",\"HeartRate\",\"Exercise\",\"Depression\",\"MajorVessels\",\"DefectType\",\"Heartdisease\" ], \"Heartdisease\")\r\n    \r\nif __name__ == '__main__':\r\n    main()\r\n\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "The error says 'out/heart_disease.chkp.index : Access is denied' so I suppose you don't have access to write to that directory.\r\n\r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Getting similar error if i run tensorboard parallely on windows.\r\nIs this a known issue or \"working as intended\"?\r\n\r\nEdit:\r\nOh well guess I just have the same problem as described here:\r\nhttps://github.com/tensorflow/tensorflow/issues/21135", "> \u8c22\u8c22\u4f60\u7684\u6587\u7ae0\u3002\u6211\u4eec\u6ce8\u610f\u5230\u60a8\u5c1a\u672a\u5728\u95ee\u9898\u6a21\u677f\u4e2d\u586b\u5199\u4ee5\u4e0b\u5b57\u6bb5\u3002\u5982\u679c\u5b83\u4eec\u4e0e\u60a8\u7684\u60c5\u51b5\u76f8\u5173\uff0c\u6216\u8005\u5c06\u5b83\u4eec\u4fdd\u7559\u4e3aN / A\uff0c\u60a8\u80fd\u5426\u66f4\u65b0\u5b83\u4eec\uff1f\u8c22\u8c22\u3002\r\n> \u6211\u662f\u5426\u5df2\u7f16\u5199\u81ea\u5b9a\u4e49\u4ee3\u7801\r\n> OS\u5e73\u53f0\u548c\u5206\u53d1\r\n> TensorFlow\u4ece\r\n> TensorFlow\u7248\u672c\u5b89\u88c5\r\n> Bazel\u7248\u672c\r\n> CUDA / cuDNN\u7248\u672c\r\n> GPU\u6a21\u578b\u548c\u5185\u5b58\r\n> Exact\u547d\u4ee4\u91cd\u73b0\r\n\r\n\u4f60\u597d\uff0c\u6211\u4e5f\u662f\u5728\u8fd9\u91cc\u9047\u5230\u4e86\u95ee\u9898\uff0c\u5176\u4ed6\u914d\u7f6e\u6ca1\u6709\u95ee\u9898\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0d\u65ad\u62a5\u9519\uff0c\u65f6\u6709\u65f6\u65e0\uff0c\u62a5\u9519\u4fe1\u606f\u5982\u4e0b\uff1a2019-09-02 00:30:39.329290: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at save_restore_v2_ops.cc:137 : Unknown: Failed to rename: C:/Users/WangYifan/Desktop/CHECK/CNN-master/CNN-master/CK-_part/thing.ckpt.index.tempstate8246489905022791031 to: C:/Users/WangYifan/Desktop/CHECK/CNN-master/CNN-master/CK-_part/thing.ckpt.index : \u62d2\u7edd\u8bbf\u95ee\u3002\r\n; Input/output error", "I have the same problem when opening a previous tensorboard, but when I close tensorboard while running the program, this problem won't happen. Hope its useful for u :)"]}, {"number": 19967, "title": "GPU OOM with Keras and Estimator, fine with Keras alone", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: tensorflowGPU_1.7\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: CUDA 9.0/cuDNN7.0\r\n- **GPU model and memory**:NVidia Titan X (Pascal) 12GB\r\n- **Exact command to reproduce**:python TestKerasAndEstimator.py\r\n\r\n\r\n### Describe the problem\r\nI have developed a Keras model and used it successfully with only Keras train and evaluate calls. Now I would like to use the same model in an Estimator context using tf.keras.estimator.model_to_estimator.\r\n\r\nIt's quite a large model (3 LSTM layers with 100 units each, input dimension 598), but I can run it in the Keras-alone context with a batch_size up to 10.  However, with an Estimator, I get an OOM on the GPU even with a batch_size of 1.  If I reduce the sequence length (SEQ_LEN) from 24000 to 5000 however, it will run with an Estimator.\r\n\r\nHere is the output log with Keras alone (USE_ESTIMATOR=False)\r\n```\r\n[Console output redirected to file:C:\\Users\\philip.LMS\\git\\GIT_RD_Python\\Ch2018\\ch2018_train\\TestEstimator_20180612_2256_log.txt]\r\nUsing TensorFlow backend.\r\n2018-06-12 22:57:11.753350: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-06-12 22:57:12.396391: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found device 0 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 12.00GiB freeMemory: 9.93GiB\r\n2018-06-12 22:57:12.624894: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found device 1 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:a1:00.0\r\ntotalMemory: 12.00GiB freeMemory: 9.93GiB\r\n2018-06-12 22:57:12.625753: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-06-12 22:57:17.075745: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-06-12 22:57:17.076181: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917]      0 1 \r\n2018-06-12 22:57:17.076457: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 0:   N N \r\n2018-06-12 22:57:17.076746: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 1:   N N \r\n2018-06-12 22:57:17.077336: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-06-12 22:57:17.079930: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)\r\nCreating Model\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm_1 (LSTM)                (10, 24000, 100)          279600    \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (10, 24000, 100)          400       \r\n_________________________________________________________________\r\nlstm_2 (LSTM)                (10, 24000, 100)          80400     \r\n_________________________________________________________________\r\nbatch_normalization_2 (Batch (10, 24000, 100)          400       \r\n_________________________________________________________________\r\nlstm_3 (LSTM)                (10, 24000, 100)          80400     \r\n_________________________________________________________________\r\nbatch_normalization_3 (Batch (10, 24000, 100)          400       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (10, 24000, 3)            303       \r\n=================================================================\r\nTotal params: 441,903\r\nTrainable params: 441,303\r\nNon-trainable params: 600\r\n_________________________________________________________________\r\nNone\r\nEpoch 1/2\r\n\r\n10/20 [==============>...............] - ETA: 6:45 - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000\r\n20/20 [==============================] - 904s 45s/step - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000\r\nEpoch 2/2\r\n\r\n10/20 [==============>...............] - ETA: 8:59 - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000\r\n20/20 [==============================] - 1059s 53s/step - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000\r\n\r\n10/20 [==============>...............] - ETA: 43s\r\n20/20 [==============================] - 86s 4s/step\r\n```\r\n\r\nAnd here is the output log with Keras and Estimator (USE_ESTIMATOR=True)\r\n\r\n```\r\n[Console output redirected to file:C:\\Users\\philip.LMS\\git\\GIT_RD_Python\\Ch2018\\ch2018_train\\TestEstimator_20180612_2338_log.txt]\r\nCreating Model\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlstm_1 (LSTM)                (1, 24000, 100)           279600    \r\n_________________________________________________________________\r\nbatch_normalization_1 (Batch (1, 24000, 100)           400       \r\n_________________________________________________________________\r\nlstm_2 (LSTM)                (1, 24000, 100)           80400     \r\n_________________________________________________________________\r\nbatch_normalization_2 (Batch (1, 24000, 100)           400       \r\n_________________________________________________________________\r\nlstm_3 (LSTM)                (1, 24000, 100)           80400     \r\n_________________________________________________________________\r\nbatch_normalization_3 (Batch (1, 24000, 100)           400       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (1, 24000, 3)             303       \r\n=================================================================\r\nTotal params: 441,903\r\nTrainable params: 441,303\r\nNon-trainable params: 600\r\n_________________________________________________________________\r\nNone\r\n2018-06-12 23:39:11.126586: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-06-12 23:39:11.751372: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found device 0 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 12.00GiB freeMemory: 9.93GiB\r\n2018-06-12 23:39:11.981018: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1344] Found device 1 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:a1:00.0\r\ntotalMemory: 12.00GiB freeMemory: 9.93GiB\r\n2018-06-12 23:39:11.981905: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-06-12 23:39:17.295319: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-06-12 23:39:17.295766: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917]      0 1 \r\n2018-06-12 23:39:17.296030: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 0:   N N \r\n2018-06-12 23:39:17.296314: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 1:   N N \r\n2018-06-12 23:39:17.296888: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-06-12 23:39:17.299820: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)\r\n2018-06-12 23:39:17.644506: I T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\cuda_solvers.cc:159] Creating CudaSolver handles for stream 000001E5C8B53C10\r\n<MapDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.float32)>\r\nDataset point 1:\r\n<MapDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>\r\nDataset point 2:\r\n<MapDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>\r\nDataset point 3:\r\n<RepeatDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>\r\nBatch features\r\nTensor(\"IteratorGetNext:0\", shape=(?, 24000, 598), dtype=float32, device=/device:CPU:0)\r\nBatch labels\r\nTensor(\"IteratorGetNext:1\", shape=(?, 24000, 3), dtype=float32, device=/device:CPU:0)\r\n2018-06-12 23:39:26.545626: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-06-12 23:39:26.546174: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-06-12 23:39:26.546739: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:917]      0 1 \r\n2018-06-12 23:39:26.547090: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 0:   N N \r\n2018-06-12 23:39:26.547462: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:930] 1:   N N \r\n2018-06-12 23:39:26.548091: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-06-12 23:39:26.549907: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)\r\nInput File:\r\nb'record_0'\r\nDecoded File:\r\nrecord_0\r\nFeatures:\r\n[[ 0.  0.  0. ...,  0.  0.  0.]\r\n [ 0.  0.  0. ...,  0.  0.  0.]\r\n [ 0.  0.  0. ...,  0.  0.  0.]\r\n ..., \r\n [ 0.  0.  0. ...,  0.  0.  0.]\r\n [ 0.  0.  0. ...,  0.  0.  0.]\r\n [ 0.  0.  0. ...,  0.  0.  0.]]\r\nLabels:\r\n[[ 0.  0.  0.]\r\n [ 0.  0.  0.]\r\n [ 0.  0.  0.]\r\n ..., \r\n [ 0.  0.  0.]\r\n [ 0.  0.  0.]\r\n [ 0.  0.  0.]]\r\n2018-06-12 23:40:47.905054: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:967] failed to alloc 4294967296 bytes on host: CUDA_ERROR_OUT_OF_MEMORY\r\n2018-06-12 23:40:47.905614: W T:\\src\\github\\tensorflow\\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 4294967296\r\n2018-06-12 23:40:47.906068: E \r\n...\r\n```\r\n\r\nHere is the python test file TestKerasAndEstimator.py:\r\n```\r\nimport sys\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nUSE_ESTIMATOR = True\r\n#USE_ESTIMATOR = False\r\n\r\nif USE_ESTIMATOR:\r\n  from tensorflow.python import keras\r\n  from tensorflow.python.keras.models import Sequential\r\n  from tensorflow.python.keras.layers import Dense, LSTM, BatchNormalization\r\n  from tensorflow.python.keras.optimizers import SGD, RMSprop\r\n  N_RECORDS = 1\r\n  BATCH_SIZE = 1\r\nelse:\r\n  import keras\r\n  import keras.backend.tensorflow_backend as K\r\n  from keras.models import Sequential\r\n  from keras.layers import Dense, LSTM, BatchNormalization\r\n  from keras.optimizers import SGD, RMSprop\r\n  N_RECORDS = 20\r\n  BATCH_SIZE = 10\r\n\r\n#SEQ_LENGTH=1000\r\n#SEQ_LENGTH=5000\r\n#SEQ_LENGTH=10000\r\nSEQ_LENGTH=24000\r\n\r\nINPUT_DIM = 598\r\nOUTPUT_DIM = 3\r\n\r\nNP_DTYPE = np.float32\r\nTF_DTYPE = tf.float32\r\n  \r\nTRAIN_EPOCHS = 2\r\nDEVICE_ID = '/gpu:0'\r\n\r\nclass ModelLSTM():\r\n  def __init__(self, batch_size, max_length=None, device_id='/cpu:0', n_input_dim=1, n_output_dim=2):  \r\n    \r\n    self.batch_size = batch_size\r\n    self.max_length = max_length\r\n    self.device_id = device_id\r\n    self.n_input_dim = n_input_dim\r\n    self.n_output_dim = n_output_dim\r\n\r\n    self.lstm_n_cell=[100, 100, 100] \r\n    self.dropout=0.1 \r\n    self.recurrent_dropout=0.1\r\n    \r\n    self.create_model()\r\n        \r\n  def create_model(self):        \r\n      \r\n    with tf.device(self.device_id):\r\n    \r\n      print('Creating Model')\r\n      model = Sequential()\r\n      model.add(LSTM(self.lstm_n_cell[0],\r\n                      return_sequences=True,\r\n                      stateful=False,\r\n                      kernel_initializer='he_normal',\r\n                      activation='tanh',\r\n                      dropout = self.dropout, \r\n                      recurrent_dropout = self.recurrent_dropout,\r\n                      batch_input_shape=(self.batch_size, self.max_length, self.n_input_dim)))\r\n      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, \r\n                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\r\n      model.add(LSTM(self.lstm_n_cell[1],\r\n                     return_sequences=True,\r\n                     stateful=False,\r\n                     kernel_initializer='he_normal',\r\n                      activation='tanh',\r\n                      dropout = self.dropout, \r\n                      recurrent_dropout = self.recurrent_dropout))\r\n      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, \r\n                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\r\n      model.add(LSTM(self.lstm_n_cell[2],\r\n                     return_sequences=True,\r\n                     stateful=False,\r\n                     kernel_initializer='he_normal',\r\n                      activation='tanh',\r\n                      dropout = self.dropout, \r\n                      recurrent_dropout = self.recurrent_dropout))\r\n      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, \r\n                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\r\n       \r\n      model.add(Dense(self.n_output_dim, kernel_initializer='he_normal',\r\n                                      activation='softmax')) \r\n      \r\n      print (model.summary())\r\n      \r\n      opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\r\n  \r\n      model.compile(loss='categorical_crossentropy',\r\n                    optimizer=opt,\r\n                    metrics=['accuracy'],\r\n                    weighted_metrics=['accuracy'],\r\n                    sample_weight_mode='temporal')\r\n    \r\n    self.model = model\r\n    return self\r\n  \r\n  \r\nclass TestKerasAndEstimator():\r\n  def __init__(self):\r\n    self.device_id = DEVICE_ID\r\n      \r\n  def set_device(self, id):\r\n    self.device_id = id\r\n          \r\n  def the_input_fn(self, filenames, perform_shuffle=False, repeat_count=1, batch_size=1):\r\n    def _set_shapes(features, labels):\r\n      features.set_shape([SEQ_LENGTH, 598])\r\n      labels.set_shape([SEQ_LENGTH, 3])\r\n      return features, labels\r\n\r\n    def _my_parse_function(filename, label=None):\r\n      \r\n      print('Input File:')\r\n      print(filename)\r\n      \r\n      dec_filename = filename.decode(sys.getdefaultencoding())\r\n      print('Decoded File:')\r\n      print(dec_filename)\r\n      \r\n      features = np.zeros((SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)\r\n      labels = np.zeros((SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)\r\n\r\n      print('Features:')\r\n      print(features)\r\n      print('Labels:')\r\n      print(labels)\r\n      \r\n      return features, labels \r\n      \r\n     \r\n    labels = [0]*len(filenames)\r\n    labels = np.array(labels)\r\n    labels = tf.constant(labels)\r\n    labels = tf.cast(labels, TF_DTYPE)\r\n    \r\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))  \r\n    \r\n    dataset = dataset.map(\r\n      lambda filename, label: tuple(tf.py_func(\r\n        _my_parse_function, [filename, label], [TF_DTYPE, label.dtype])))\r\n    \r\n    print(dataset)\r\n\r\n    dataset = dataset.map(_set_shapes)\r\n    \r\n    print(\"Dataset point 1:\")\r\n    print(dataset)\r\n    \r\n    if perform_shuffle:\r\n        dataset = dataset.shuffle(buffer_size=batch_size)\r\n    print(\"Dataset point 2:\")\r\n    print(dataset)\r\n    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\r\n    print(\"Dataset point 3:\")\r\n    print(dataset)\r\n    dataset = dataset.batch(batch_size)  # Batch size to use\r\n    the_iterator = dataset.make_one_shot_iterator()    \r\n    batch_features, batch_labels = the_iterator.get_next()\r\n    print('Batch features') \r\n    print(batch_features) \r\n    print('Batch labels') \r\n    print(batch_labels) \r\n    return batch_features, batch_labels\r\n  \r\n  def test_keras_estimator(self, n_records=1, batch_size=1):\r\n    gpu_options = tf.GPUOptions(allow_growth=True) \r\n    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        \r\n    run_config = tf.estimator.RunConfig(session_config=sess_config)   \r\n    \r\n    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, \r\n                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)\r\n    self.estimator = tf.keras.estimator.model_to_estimator(keras_model=train_model.model,\r\n                                                           model_dir='.', config=run_config)\r\n    train_records = list()\r\n    for i in range(0, n_records):\r\n      train_records.append('record_' + str(i))\r\n      \r\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: \r\n                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size), \r\n                                        max_steps=TRAIN_EPOCHS)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: \r\n                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size))\r\n\r\n    tf.estimator.train_and_evaluate(self.estimator, train_spec, eval_spec)\r\n    \r\n     \r\n  def test_keras(self, n_records=1, batch_size=1):\r\n    gpu_options = tf.GPUOptions(allow_growth=True) \r\n    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        \r\n    K.set_session(tf.Session(config=sess_config))\r\n      \r\n    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, \r\n                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)\r\n    features = np.zeros((n_records, SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)\r\n    labels = np.zeros((n_records, SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)\r\n\r\n    train_model.model.fit(x=features, y=labels, batch_size=batch_size, epochs=TRAIN_EPOCHS, verbose=1)\r\n    train_model.model.evaluate(x=features, y=labels, batch_size=batch_size, verbose=1)    \r\n     \r\n     \r\n     \r\nif __name__ == \"__main__\":\r\n  mt = TestKerasAndEstimator()\r\n  if USE_ESTIMATOR:\r\n      mt.test_keras_estimator(n_records=N_RECORDS, batch_size=BATCH_SIZE)\r\n  else:\r\n      mt.test_keras(n_records=N_RECORDS, batch_size=BATCH_SIZE)\r\n\r\n    \r\n  \r\n```\r\nThanks!", "comments": ["Also, I see the same behaviour with tensorflowGPU_1.9rc0\r\n\r\nThanks for looking into this.", "@pawarrick Can you post your TF graph other than `model.summary()` output? For a code snippet check https://github.com/tensorflow/tensorflow/issues/16468", "Also with tensorflowGPU_1.9rc0, using \r\n\r\nkeras.layers.CuDNNLSTM instead of \r\nkeras.layers.LSTM\r\n\r\nthe Estimator version runs fine with SEQ_LEN=24000 and BATCH_SIZE=35\r\n\r\n", "Here is the updated code with CuDNNLSTM added:\r\n\r\n```\r\nimport sys\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nUSE_ESTIMATOR = True\r\n#USE_ESTIMATOR = False\r\n\r\n#USE_CUDNN_LSTM = True\r\nUSE_CUDNN_LSTM = False\r\n\r\nif USE_ESTIMATOR:\r\n  from tensorflow.python import keras\r\n  from tensorflow.python.keras.models import Sequential\r\n  from tensorflow.python.keras.layers import Dense, LSTM, BatchNormalization, CuDNNLSTM\r\n  from tensorflow.python.keras.optimizers import SGD, RMSprop\r\n  if USE_CUDNN_LSTM:\r\n    N_RECORDS = 35\r\n    BATCH_SIZE = 35\r\n  else:\r\n    N_RECORDS = 1\r\n    BATCH_SIZE = 1\r\n    \r\nelse:\r\n  import keras\r\n  import keras.backend.tensorflow_backend as K\r\n  from keras.models import Sequential\r\n  from keras.layers import Dense, LSTM, BatchNormalization\r\n  from keras.optimizers import SGD, RMSprop\r\n  N_RECORDS = 20\r\n  BATCH_SIZE = 10\r\n\r\n#SEQ_LENGTH=1000\r\n#SEQ_LENGTH=5000\r\n#SEQ_LENGTH=10000\r\nSEQ_LENGTH=24000\r\n\r\nINPUT_DIM = 598\r\nOUTPUT_DIM = 3\r\n\r\nNP_DTYPE = np.float32\r\nTF_DTYPE = tf.float32\r\n  \r\nTRAIN_EPOCHS = 2\r\nDEVICE_ID = '/gpu:0'\r\n\r\n\r\n\r\nclass ModelLSTM():\r\n  def __init__(self, batch_size, max_length=None, device_id='/cpu:0', n_input_dim=1, n_output_dim=2):  \r\n    \r\n    self.batch_size = batch_size\r\n    self.max_length = max_length\r\n    self.device_id = device_id\r\n    self.n_input_dim = n_input_dim\r\n    self.n_output_dim = n_output_dim\r\n\r\n    self.n_layers = 3\r\n    self.lstm_n_cell=[100, 100, 100] \r\n    self.dropout=0.1 \r\n    self.recurrent_dropout=0.1\r\n    \r\n    self.create_model()\r\n        \r\n  def create_model(self):        \r\n    with tf.device(self.device_id):\r\n    \r\n      print('Creating Model')\r\n      model = Sequential()\r\n      \r\n      for i_layer in range(0, self.n_layers):\r\n        if USE_CUDNN_LSTM:\r\n          model.add(keras.layers.CuDNNLSTM(self.lstm_n_cell[i_layer],\r\n                          return_sequences=True,\r\n                          stateful=False,\r\n                          kernel_initializer='he_normal',\r\n                          batch_input_shape=(self.batch_size, self.max_length, self.n_input_dim)))\r\n        else:\r\n          model.add(LSTM(self.lstm_n_cell[i_layer],\r\n                          return_sequences=True,\r\n                          stateful=False,\r\n                          kernel_initializer='he_normal',\r\n                          activation='tanh',\r\n                          dropout = self.dropout, \r\n                          recurrent_dropout = self.recurrent_dropout,\r\n                          batch_input_shape=(self.batch_size, self.max_length, self.n_input_dim)))\r\n          \r\n  \r\n        model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, \r\n                                     scale=True, beta_initializer='zeros', gamma_initializer='ones', \r\n                                     moving_mean_initializer='zeros', moving_variance_initializer='ones'))      \r\n       \r\n      model.add(Dense(self.n_output_dim, kernel_initializer='he_normal',\r\n                                      activation='softmax')) \r\n      \r\n      #print (model.summary())\r\n      opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\r\n  \r\n      model.compile(loss='categorical_crossentropy',\r\n                    optimizer=opt,\r\n                    metrics=['accuracy'],\r\n                    weighted_metrics=['accuracy'],\r\n                    sample_weight_mode='temporal')\r\n    \r\n    self.model = model\r\n    return self\r\n  \r\n  \r\nclass TestKerasAndEstimator():\r\n  def __init__(self):\r\n    self.device_id = DEVICE_ID\r\n      \r\n  def set_device(self, id):\r\n    self.device_id = id\r\n          \r\n  def the_input_fn(self, filenames, perform_shuffle=False, repeat_count=1, batch_size=1):\r\n    def _set_shapes(features, labels):\r\n      features.set_shape([SEQ_LENGTH, 598])\r\n      labels.set_shape([SEQ_LENGTH, 3])\r\n      return features, labels\r\n\r\n    def _my_parse_function(filename, label=None):\r\n      \r\n      print('Input File:')\r\n      print(filename)\r\n      \r\n      dec_filename = filename.decode(sys.getdefaultencoding())\r\n      print('Decoded File:')\r\n      print(dec_filename)\r\n      \r\n      # stub for testing, but normally read data from file here \r\n      features = np.zeros((SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)\r\n      labels = np.zeros((SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)\r\n\r\n      print('Features:')\r\n      print(features)\r\n      print('Labels:')\r\n      print(labels)\r\n      \r\n      return features, labels \r\n      \r\n     \r\n    labels = [0]*len(filenames)\r\n    labels = np.array(labels)\r\n    labels = tf.constant(labels)\r\n    labels = tf.cast(labels, TF_DTYPE)\r\n    \r\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))  \r\n    \r\n    dataset = dataset.map(\r\n      lambda filename, label: tuple(tf.py_func(\r\n        _my_parse_function, [filename, label], [TF_DTYPE, label.dtype])))\r\n    \r\n    print(dataset)\r\n\r\n    dataset = dataset.map(_set_shapes)\r\n    \r\n    print(\"Dataset point 1:\")\r\n    print(dataset)\r\n    \r\n    if perform_shuffle:\r\n        dataset = dataset.shuffle(buffer_size=batch_size)\r\n    print(\"Dataset point 2:\")\r\n    print(dataset)\r\n    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\r\n    print(\"Dataset point 3:\")\r\n    print(dataset)\r\n    dataset = dataset.batch(batch_size)  # Batch size to use\r\n    the_iterator = dataset.make_one_shot_iterator()    \r\n    batch_features, batch_labels = the_iterator.get_next()\r\n    print('Batch features') \r\n    print(batch_features) \r\n    print('Batch labels') \r\n    print(batch_labels) \r\n    return batch_features, batch_labels\r\n  \r\n  def test_keras_estimator(self, n_records=1, batch_size=1):\r\n    gpu_options = tf.GPUOptions(allow_growth=True) \r\n    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        \r\n    run_config = tf.estimator.RunConfig(session_config=sess_config)   \r\n    \r\n    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, \r\n                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)\r\n    \r\n        \r\n    self.estimator = tf.keras.estimator.model_to_estimator(keras_model=train_model.model,\r\n                                                           model_dir='models', config=run_config)\r\n    train_records = list()\r\n    for i in range(0, n_records):\r\n      train_records.append('record_' + str(i))\r\n      \r\n    train_spec = tf.estimator.TrainSpec(input_fn=lambda: \r\n                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size), \r\n                                        max_steps=TRAIN_EPOCHS)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: \r\n                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size))\r\n\r\n    tf.estimator.train_and_evaluate(self.estimator, train_spec, eval_spec)\r\n    #print (train_model.model.summary())\r\n      \r\n    \r\n     \r\n  def test_keras(self, n_records=1, batch_size=1):\r\n    gpu_options = tf.GPUOptions(allow_growth=True) \r\n    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        \r\n    K.set_session(tf.Session(config=sess_config))\r\n      \r\n    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, \r\n                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)\r\n    \r\n    # stub for testing, but normally read data from file here \r\n    features = np.zeros((n_records, SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)\r\n    labels = np.zeros((n_records, SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)\r\n\r\n    train_model.model.fit(x=features, y=labels, batch_size=batch_size, epochs=TRAIN_EPOCHS, verbose=1)\r\n    train_model.model.evaluate(x=features, y=labels, batch_size=batch_size, verbose=1)    \r\n     \r\n     \r\n     \r\nif __name__ == \"__main__\":\r\n  mt = TestKerasAndEstimator()\r\n  if USE_ESTIMATOR:\r\n      mt.test_keras_estimator(n_records=N_RECORDS, batch_size=BATCH_SIZE)\r\n  else:\r\n      mt.test_keras(n_records=N_RECORDS, batch_size=BATCH_SIZE)\r\n\r\n    \r\n  ```", "@bhack, I couldn't get your IPython code to display the graph (it ran without errors, but the HTML did not display in my Web browser--but I'm not very familiar with jupyter notebooks, so maybe I haven't configured something).  \r\n\r\nBut here's the graph as viewed in Tensorboard in case that's equivalent to what your code does:\r\n\r\n![lstmgraph](https://user-images.githubusercontent.com/8933353/41554829-f4224d7c-7303-11e8-9333-8b14c5db2f87.jpg)\r\n", "the graph above is for the failing keras.layers.LSTM case with an Estimator\r\n", "@pawarrick Yes that code was made for colab. So seems that in your case there is any spurious branch right? Generally spurious branches appeared in the graph with `model_to_estimator` as you can see in my issue but I've not tested recently with `tensorflowGPU_1.9rc0`.", "/cc @martinwicke @tanzhenyu  Has `model_to_estimator` struck again?", "I have had the same (but less 'weird') issue before. \r\n@pawarrick Have you tried with pure estimator implementation?  ", "The OOM message is about trying to allocate 4294967296 (MAXINT) bytes, which is failing. \r\n\r\nThis points to a bug where something tries to allocate ((unsigned int) -1) bytes, which sounds like a bug (and a bug in the error message to go with it).\r\n\r\nThis is, btw., also about host memory. Does this work if you disable the GPU? It might well not be a GPU problem at all. ", "If you mean by \u2018pure\u2019 without Keras, no\n\n> On Jul 23, 2018, at 10:42 AM, tanzhenyu <notifications@github.com> wrote:\n> \n> I have had the same (but less 'weird') issue before.\n> @pawarrick Have you tried with pure estimator implementation?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "The model_to_estimator merely copies the model (which shouldn't matter too much in your case as you only have less than 1M parameters), and allocating so much memory doesn't seem right but that process shouldn't happen during the conversion -- that's why I'm asking if pure estimator implementation can be checked.", "@martinwicke I've just tried https://github.com/tensorflow/tensorflow/issues/19967#issuecomment-398143577 on Colab/CPU ONLY. \r\nPure tf.keras `USE_ESTIMATOR = False` is working fine instead the estimator `USE_ESTIMATOR = True` code path it is crashing.", "That's nice, at least we can rule out GPU.\r\n\r\nOne more thing to try (for better comparability) is to run the the_input_fn in the pure keras path. I believe it will keep at least three copies of the \"features\" in memory (still not enough that it should break, but it would be better to rule it out). ", "@martinwicke Is it enough to add the_input_fn to the fit `callbacks= `?", "It shouldn't be called each iteration. Start by calling it once and keeping\na reference to the result. If that works, add a callback which evaluates\nthe result with K.get_session in each iteration.\n", "@pawarrick Have you time to test it?", "@tanzhenyu  Do you have a little bit more context for your case https://github.com/tensorflow/tensorflow/issues/19967#issuecomment-407081003?", "@tanzhenyu What was you case?", "@bhack @pawarrick I suspect if it has something to do with the input fn you are using in Estimator? (I'm not very familiar with tf.Dataset but I imagine it could need to allocate extra large amount of memory for the map function you're using (as well as the shuffling).", "@tanzhenyu Are the map executing gpu Ops? I have only pure python /numpy. My context was more on the [Shared vision model](https://github.com/tensorflow/tensorflow/issues/16468#issuecomment-385662734). With shared vision you need to heavily reduce the batch size against the same not shared model. ", "As we're approaching TF 2.0, can you try Keras natively? Or is there any other thing that you'd need that is only provided by Estimator?", "Is the bug still there running in TF2.0? ", "I mean using Keras natively, not through model_to_estimator", "Sorry I don't understand . In the original post, the code worked fine in with native Keras (with TF 1.7).  Are you asking if that's still the case in TF 1.13?  By the way, I stopped using Keras natively shortly after this post and began using the Keras within TF.  Later (in TF 1.12?), Keras supported Datasets directly without Estimator so I've been using that paradigm.", "Sorry I should have clarified. By Keras natively I mean is there anything you need to do in TF.Estimator that you won't be able to do in TF.Keras? \r\nDataset is already supported, as you mention. Another popular ask is for distributed training, which is also supported. So as long as you don't have any thing specific required from Estimator (like warm start, scaffold, hooks, etc), I'd think your case is already covered?", "I'm one of those who request distributed support too. But because of a lack of support for sample loss weighting (see issue #24226), I haven't been able to take my Keras-with-Datasets approach to distributed training.\r\n", "That's a valid request, I will respond on that issue.", "thanks", "Hi @pawarrick! we are checking to see if you still you need help in this issue , Have your tried TF 2.6 yet ? Please create a new issue if the issue persistss.", "This was resolved a while ago when sample loss weighting was supported with datasets. Thanks", "Thanks @pawarrick for confirming the same.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 19966, "title": "opencv interop fix: exclude libjpeg symbols from libtensorflow_framew\u2026", "body": "\u2026ork.so to avoid symbol conflict", "comments": []}, {"number": 19964, "title": "fix opencv imread failure: remove libjpeg symbols from export list of\u2026", "body": "\u2026 libtensorflow_framework.so to avoid symbol conflicts with opencv", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@allenlavoie could you please help review this pull request?", "\r\nI signed it!\r\n\r\n________________________________\r\nFrom: googlebot <notifications@github.com>\r\nSent: Tuesday, June 12, 2018 7:37 PM\r\nTo: tensorflow/tensorflow\r\nCc: ruanjiandong; Author\r\nSubject: Re: [tensorflow/tensorflow] fix opencv imread failure: remove libjpeg symbols from export list of\u2026 (#19964)\r\n\r\n\r\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n\r\n\ud83d\udcdd Please visit https://cla.developers.google.com/ to sign.\r\n\r\nAbout - Google CLA<https://cla.developers.google.com/>\r\ncla.developers.google.com\r\nWhen you sign a Contributor License Agreement (CLA), you give Google the legal permission to use and distribute your contribution. You do not surrender ownership of your contribution, and you do not give up any of your rights to use your contribution elsewhere.\r\n\r\n\r\nOnce you've signed (or fixed any issues), please reply here (e.g. I signed it!) and we'll verify it.\r\n\r\n________________________________\r\nWhat to do if you already signed the CLA\r\nIndividual signers\r\n\r\n  *   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check your existing CLA data<https://cla.developers.google.com/clas> and verify that your email is set on your git commits<https://help.github.com/articles/setting-your-email-in-git/>.\r\n\r\nCorporate signers\r\n\r\n  *   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to go/cla#troubleshoot (Public version<https://opensource.google.com/docs/cla/#troubleshoot>).\r\n  *   The email used to register you as an authorized contributor must be the email used for the Git commit. Check your existing CLA data<https://cla.developers.google.com/clas> and verify that your email is set on your git commits<https://help.github.com/articles/setting-your-email-in-git/>.\r\n  *   The email used to register you as an authorized contributor must also be attached to your GitHub account<https://github.com/settings/emails>.\r\n\r\n\u2014\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/pull/19964#issuecomment-396794493>, or mute the thread<https://github.com/notifications/unsubscribe-auth/APlqgP649TsJqs3oC_LmwJDVlQrh3kZVks5t8HrmgaJpZM4UlcIL>.\r\n", "I signed it!"]}, {"number": 19963, "title": "Check to ensure the Cloud TPU is ready before resolving.", "body": "Cherry picking this into the TF 1.9 release.\r\n\r\nPiperOrigin-RevId: 200095692\r\n\r\nPrevious commit: 32c8013f0ab3feb139648ae759e2d0168fb5dc95", "comments": []}, {"number": 19962, "title": "object detection API: tf profiler incompatible shape", "body": "I was trying to add profiler to the existing tensorflow object detection API, the following part of code is added to https://github.com/tensorflow/tensorflow/blob/dfa0f87e333c63277b7916a8ac4c56bf61daf1ac/tensorflow/contrib/slim/python/slim/learning.py#L489\r\n\r\n```\r\n  if run_metadata is not None:\r\n    logging.info('Added profiling by User')\r\n    ProfileOptionBuilder = profiler.ProfileOptionBuilder\r\n    opts = ProfileOptionBuilder(ProfileOptionBuilder.time_and_memory()).with_step(np_global_step).with_timeline_output(train_step_kwargs['logdir']+'/profile.json').build()\r\n    logging.info(train_step_kwargs['logdir']+'/profile.json')\r\n    profiler.profile(\r\n        ops.get_default_graph(),\r\n        run_meta=run_metadata,\r\n        cmd='graph',\r\n        options=opts)\r\n```\r\nbut when I was trying to run the training for resnet_101_coco with no other changes, the training progress with no error, but the profiler output incompatible shapes:\r\n```\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/pool1/MaxPool incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/shortcut/MaxPool incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/Pad incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 152, 229) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.\r\nNode clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.\r\nNode \r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "closing as duplicate of #19988 ", "@poxvoculi is it duplicate? one is incomplete shape, the other is incompatible shape", "I'm seeing the same issue with a custom CNN model - it seems that the profiler complains about the layer built with NHWC and report the the actual runtime shape being in NCHW. \r\n\r\n`Node import/lite_cnn/cnn/conv1/Conv2D incompatible shapes: Shapes (?, 96, 64, 16) and (1, 16, 96, 64) are not compatible.\r\nNode import/lite_cnn/cnn/conv1/BiasAdd incompatible shapes: Shapes (?, 96, 64, 16) and (1, 16, 96, 64) are not compatible.\r\nNode import/lite_cnn/cnn/conv1/Relu incompatible shapes: Shapes (?, 96, 64, 16) and (1, 16, 96, 64) are not compatible.\r\nNode import/lite_cnn/cnn/conv2/Conv2D incompatible shapes: Shapes (?, 96, 64, 32) and (1, 32, 96, 64) are not compatible.\r\nNode import/lite_cnn/cnn/conv2/BiasAdd incompatible shapes: Shapes (?, 96, 64, 32) and (1, 32, 96, 64) are not compatible.\r\nNode import/lite_cnn/cnn/conv2/Relu incompatible shapes: Shapes (?, 96, 64, 32) and (1, 32, 96, 64) are not compatible.`", "Facing the same problem.", "As discussed in #19988 this code is orphaned and scheduled to be dropped. "]}, {"number": 19961, "title": "compute_output_shape() Not Working For Custom Layer", "body": "I have created a custom layer (called GraphGather) in Keras, yet the output tensor prints as :\r\n>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\r\n\r\nFor some reason the shape is being returned as (?,?), which is causing the next dense layer to raise the following error:\r\n>ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\r\n\r\nThe GraphGather layer code is as follows:\r\n```python\r\nclass GraphGather(tf.keras.layers.Layer):\r\n\r\n  def __init__(self, batch_size, num_mols_in_batch, activation_fn=None, **kwargs):\r\n    self.batch_size = batch_size\r\n    self.num_mols_in_batch = num_mols_in_batch\r\n    self.activation_fn = activation_fn\r\n    super(GraphGather, self).__init__(**kwargs)\r\n\r\n  def build(self, input_shape):\r\n    super(GraphGather, self).build(input_shape)\r\n\r\n def call(self, x, **kwargs):\r\n    # some operations (most of def call omitted)\r\n    out_tensor = result_of_operations() # this line is pseudo code\r\n    if self.activation_fn is not None:\r\n      out_tensor = self.activation_fn(out_tensor)\r\n    out_tensor = out_tensor\r\n    return out_tensor\r\n\r\n  def compute_output_shape(self, input_shape):\r\n    return (self.num_mols_in_batch, 2 * input_shape[0][-1])\r\n```\r\nI have also tried hardcoding compute_output_shape to be:\r\n```python\r\ndef compute_output_shape(self, input_shape):\r\n    return (64, 150)\r\n```\r\nYet the output tensor when printed is still \r\n>Tensor(\"graph_gather/Tanh:0\", shape=(?, ?), dtype=float32)\r\n\r\nwhich causes the ValueError written above. \r\n\r\n------------------------\r\n\r\n### System information\r\n- Have written custom code\r\n- **OS Platform and Distribution*:  Linux Ubuntu 16.04\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.5.5\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: Yes\r\nTensorFlow installed from: Conda\r\nBazel version: NA\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce: Written above", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "@angersson Are you positive this is not a bug? I have brought this up on Stack Overflow and hopefully that will shed light on any user error on my behalf, but if not then from my understanding this still may be a bug. ", "https://stackoverflow.com/questions/51028861/tensorflow-compute-output-shape-not-working-for-custom-layer\r\n"]}, {"number": 19960, "title": "r1.9-rc1 cherry-pick request: Fix module docstrings", "body": "Improve module docstrings when generating TensorFlow API.", "comments": []}, {"number": 19959, "title": "Evaluate network first, and then apply gradients", "body": "Dear TensorFlow team,\r\n\r\nI believe I have hit a limitation of TensorFlow and was wondering if you (or the community) could assist me. I am trying to initialize a graph with a topology from the paper seen here: https://arxiv.org/abs/1708.06686. In this paper, one splits an image into tiles (which can overlap) and has some sort of network for each tile. The output of each network is then summed to obtain an output. The problem is when you split the image into many tiles, the computational graph becomes very large and one will often run out of memory. In this topology the network is shared across all tiles. For inference, one never hits a memory problem, because one can evaluate the value of each tile one by one. This is where I am having an issue. I cannot seem to define gradients properly if I first evaluate the tiles one by one. The way that TensorFlow is currently set up, I have to define the full computational graph to get the correct gradients. Is there a way I could evaluate the tiles first, and then apply gradients afterwards?\r\n\r\nOS Platform and Distribution: MacOS\r\nTensorFlow installed from: TensorFlow \r\nTensorFlow version: 1.8\r\nBazel version: Unknown\r\nCUDA/cuDNN version: N/A (this experiment was ran on CPU)\r\nGPU model and memory: N/A\r\nExact command to reproduce: https://anaconda.org/kryczko/untitled3/notebook", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Yes, this is still an issue.", "/CC @mrry what do you think the right think to do here is? ", "This is more like a Stack Overflow question than a bug.\r\n\r\nYou could try using a control-flow operator like `tf.map_fn()` to loop over tiles of your image and accumulate the gradients, or switch to using Eager Execution and sum the gradients manually.\r\n", "How would I go about implementing \"Eager execution\" in Tensorflow?", "It's now a standard feature of TensorFlow. You can find out more about Eager execution here: https://www.tensorflow.org/get_started/eager"]}, {"number": 19958, "title": "Support init_from_checkpoint and warm start with Distribution Strategy ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nReporting issues raise in this stackoverflow question:\r\nhttps://stackoverflow.com/questions/50758110/warm-start-with-distribute-mirroredstrategy-and-tf-estimator:\r\n1.  tf.train.init_from_checkpoint doesn't work well with MirroredStrategy\r\n2. tf.estimator.WarmStartSettings with Estimator doesn't work with MirroredStrategy \r\n\r\n\r\n### Source code / logs\r\nSee code snippets and error messages in this stack overflow page:\r\nhttps://stackoverflow.com/questions/50758110/warm-start-with-distribute-mirroredstrategy-and-tf-estimator\r\n\r\nThe root cause is that we haven't modified these 2 paths for restoring from checkpoints to work with mirrored variables. So we need to do 2 things:\r\n1. Use the appropriate method to restore mirrored variables in these codepaths - either via distribution.update or by using Saver (see Allen's suggestion below). \r\n2. if the restoring is happening in tower context(for e.g. when init_from_checkpoint is called in model_fn), then we may need to first enter cross tower context before restoring. \r\n\r\nSuggestion for addressing #1 from @allenlavoie :\r\nDo the same [SaveableObject extraction as Saver](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L531) in warm_start, then just call SaveableObject.restore() with the Tensor instead of using .assign. This will work for MirroredVariables and whatever else is checkpointable (and means that to work with both, new objects only need to do the checkpointable thing). Potentially we could just call [SaveableObjectsForOp](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L573) for everything including variables.\r\n\r\n", "comments": ["cc @josh11b @yuefengz @allenlavoie ", "duplicate https://github.com/tensorflow/tensorflow/issues/19744", "I also met the problem, and i solved by self defined train hooks like this:\r\n\r\n```import tensorflow as tf \r\n  import os\r\n  class RestoreCheckpointHook(tf.train.SessionRunHook):\r\n    def __init__(self,\r\n                 checkpoint_path,\r\n                 exclude_scope_patterns = None,\r\n                 include_scope_patterns = None\r\n                 ):\r\n        tf.logging.info(\"Create RestoreCheckpointHook.\")\r\n        self.checkpoint_path =  checkpoint_path\r\n        self.exclude_scope_patterns = exclude_scope_patterns\r\n        self.include_scope_patterns = include_scope_patterns\r\n    def begin(self):\r\n      # You can add ops to the graph here.\r\n      tf.logging.info('Before starting the session.')\r\n     \r\n      variables = tf.get_collection(tf.GraphKeys.VARIABLES)\r\n      \r\n      for v in variables:\r\n        if self.exclude_scope_patterns in v.name:\r\n          continue\r\n        vars.append(v)\r\n      #variables_to_restore = tf.contrib.framework.filter_variables(\r\n      #    variables,\r\n      #    include_patterns=self.include_scope_patterns,# ['Conv'],\r\n      #    exclude_patterns=['Adam'], # ['biases', 'Logits'],\r\n\r\n      #    # If True (default), performs re.search to find matches\r\n      #    # (i.e. pattern can match any substring of the variable name).\r\n      #    # If False, performs re.match (i.e. regexp should match from the beginning of the variable name).\r\n      #    reg_search = True\r\n      #)\r\n      self.saver = tf.train.Saver(vars)\r\n\r\n\r\n    def after_create_session(self, session, coord):\r\n      # When this is called, the graph is finalized and\r\n      # ops can no longer be added to the graph.\r\n\r\n      tf.logging.info('Session created.')\r\n\r\n      tf.logging.info('Fine-tuning from %s' % self.checkpoint_path)\r\n      self.saver.restore(session, os.path.expanduser(self.checkpoint_path))\r\n      tf.logging.info('End finetuning from %s' % self.checkpoint_path)\r\n\r\n    def before_run(self, run_context):\r\n      return None #SessionRunArgs(self.your_tensor)\r\n\r\n    def after_run(self, run_context, run_values):\r\n      #print('Done running one step. The value of my tensor: %s', run_values.results)\r\n      #if you-need-to-stop-loop:\r\n      #  run_context.request_stop()\r\n      pass\r\n\r\n\r\n    def end(self, session):\r\n      #print('Done with the session.')\r\n      pass\r\n```\r\nyou can using like this:\r\n```\r\n train_hooks = RestoreCheckpointHook('checkpointpath',exclude_scope_patterns=\"Adam\")\r\n estimator.train(\r\n        dataset.train_input_fn,\r\n        steps=schedule_manager.single_iteration_train_steps,\r\n        hooks=train_hooks)\r\n```\r\n", "@summersunshine1 I'm wondering what is the side effect of running this hook especially when you resume the training ? The expected behaviour is to restore the latest checkpoint in the model dir when you resume the training and only warm start with a given checkpoint at the beginning of the training step.", "@jrabary  In fact\uff0cestimator use training.CheckpointSaverHook to save model and load model if there is model in model dir and it can be seen in estimator.py. These hooks inherit form session run hook class. Writing you own hooks that inherit form session run hook  can help you realize you own function such as changing some layers variable or optimizer ", "@summersunshine1 thanks, I'll give a try to this workaround. ", "@guptapriya Any progress on this issue ?", "Hi, we will look at this in the next couple of weeks. Don't have any progress to report so far. BTW the suggestion from @summersunshine1 looks good to me - we do use Saver for estimator's default checkpoint restoring which works with mirrored strategy. ", "I tried the workaround using hooks but taking into account the fact that my model and the checkpoint don't have the same scope. For that I slightly modified the `RestoreHook` from `tensor2tensor` code base as follow:\r\n\r\n```class RestoreHook(tf.train.SessionRunHook):\r\n    \"\"\"Restore variables from a checkpoint path.\"\"\"\r\n\r\n    def __init__(self, checkpoint_path=\"\", new_model_scope=\"\", old_model_scope=\"\",\r\n                 include=None, exclude=None):\r\n        self._checkpoint_path = checkpoint_path\r\n        self._new_model_scope = new_model_scope\r\n        self._old_model_scope = old_model_scope\r\n        self._include = include\r\n        self._exclude = exclude\r\n        self._saver = None\r\n        self._assignment_map = None\r\n\r\n    def begin(self):\r\n        \"\"\"Load variables from checkpoint.\r\n\r\n        New model variables have the following name foramt:\r\n        new_model_scope/old_model_scope/xxx/xxx:0 To find the map of\r\n        name to variable, need to strip the new_model_scope and then\r\n        match the old_model_scope and remove the suffix :0.\r\n\r\n        \"\"\"\r\n        variables_to_restore = tf.contrib.framework.get_variables_to_restore(\r\n            include=self._include, exclude=self._exclude)\r\n        # remove new_model_scope from variable name prefix\r\n        assignment_map = {variable.name[len(self._new_model_scope):]: variable\r\n                          for variable in variables_to_restore\r\n                          if variable.name.startswith(self._new_model_scope)}\r\n        # remove :0 from variable name suffix\r\n        assignment_map = {name.split(\":\")[0]: variable\r\n                          for name, variable in six.iteritems(assignment_map)\r\n                          if name.startswith(self._old_model_scope)}\r\n\r\n        self._saver = tf.train.Saver(assignment_map)\r\n\r\n    def after_create_session(self, session, coord):\r\n        # When this is called, the graph is finalized and\r\n        # ops can no longer be added to the graph.\r\n\r\n        tf.logging.info('Session created.')\r\n\r\n        tf.logging.info('Fine-tuning from %s' % self._checkpoint_path)\r\n        self._saver.restore(session, self._checkpoint_path)\r\n        tf.logging.info('End finetuning from %s' % self._checkpoint_path)\r\n\r\n    def before_run(self, run_context):\r\n        return None  # SessionRunArgs(self.your_tensor)\r\n```\r\n\r\nBut this fails at `self._saver = tf.train.Saver(assignment_map)`  with a mysterious error \r\n```\r\ntensorflow/contrib/distribute/python/values.py\", line 242, in _tensor_conversion\r\n    assert not as_ref\r\nAssertionError\r\n```\r\n\r\nAny ideas ?", "I have a fix in progress for both the init_from_checkpoint and warm_start. Should be able to merge it sometime next week. ", "The fix has been merged: https://github.com/tensorflow/tensorflow/commit/f1de0ddd55dcae6237ea7d21ccddcc6467a6cf8b\r\n\r\nYou should be able to test this out in a nightly build soon. \r\n\r\n", "@guptapriya I test the fix using the master version of the git but still got an error. This time\r\n\r\n```RuntimeError: Tower-local variables may only be assigned in a tower context.```\r\n\r\nWhen should I call ```tf.train.init_from_checkpoint``` ?\r\n\r\nCurrently I call it inside the `model_fn` of the estimator. \r\n\r\nMy guess is that the synchronization is set on `variable_scope.VariableSynchronization.ON_READ`.", "Ah, yes there is another change in progress from @anj-s which will address Tower local variables. Will re-open until that is fixed. ", "Hi @guptapriya, I don't know whether  this last commit https://github.com/tensorflow/tensorflow/commit/89e06304aad35bfb019a8c10f39fc1ead83e0f99 is supposed to solve the issue but the error is now changed into:\r\n```\r\ntensorflow/python/training/checkpoint_utils.py\", line 334, in _set_checkpoint_initializer\r\n    v._initializer_op = init_op._index[d]\r\nAttributeError: 'Operation' object has no attribute '_index'\r\n```\r\n\r\nAfter some in investigation, I think that it doesn't handle the initialization of local variables such as moving mean in batch norm very well.", "Hi @jrabary , you're right, that change was supposed to solve it but looks like it didn't fully because the return type of `TowerLocalVariable.assign` is not what this code is expecting. I am looking into it. Thanks for bringing to our attention! ", "Update: I have a fix in progress. ", "Hi @jrabary , the fix is in master now (https://github.com/tensorflow/tensorflow/commit/53449eb635c4abce62c5f00d05fad1b1c8d1d9ab#diff-16ebf074671515b487601554ed95abce). Perhaps you could give it another shot? ", "I just tried it and it worked. Thank you so much that fix made my day :)", "That's great, thanks for the update @aaronmondal ", "Hi @guptapriya it works for me as well. Thanks!", "Thanks for the update @jrabary ! ", "[mirrorederror.txt](https://github.com/tensorflow/tensorflow/files/2685552/mirrorederror.txt)\r\nI'm still facing the same issue. Error log attached."]}, {"number": 19957, "title": "tf.dynamic_partition cannot have dynamic num_partitions", "body": "I am attempting to use `tf.dynamic_partition` as so:\r\n`tf.dynamic_partition(features, membership, tf.reduce_max(membership))`\r\nUnfortunately, however, it is throwing this error\r\n>TypeError: Expected int for argument 'num_partitions' not <tf.Tensor 'Max:0' shape=() dtype=int32>.\r\n\r\nCan `tf.dynamic_partition` not receive a dynamic input for num_partitions? ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: Yes\r\nOS Platform and Distribution: Linux Ubuntu 16.04\r\nTensorFlow installed from: Conda\r\nTensorFlow version: 1.5.0\r\nBazel version: NA\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce: Written above", "I have the same issues. I thought we could use a Tensor instead of an integer anywhere in the code?\r\nIt would be nice to have a dynamic number of partitions.", "I'm having the same problem as well - the documentation says \"partitions: A Tensor of type int32. Any shape. Indices in the range [0, num_partitions)\", but it doesn't seem to accept a Tensor. ", "No, num_partitions is an attribute which means it cannot be driven by a tensor.  See the op_def below:\r\n```op {\r\n  name: \"DynamicPartition\"\r\n  input_arg {\r\n    name: \"data\"\r\n    type_attr: \"T\"\r\n  }\r\n  input_arg {\r\n    name: \"partitions\"\r\n    type: DT_INT32\r\n  }\r\n  output_arg {\r\n    name: \"outputs\"\r\n    type_attr: \"T\"\r\n    number_attr: \"num_partitions\"\r\n  }\r\n  attr {\r\n    name: \"num_partitions\"\r\n    type: \"int\"\r\n    has_minimum: true\r\n    minimum: 1\r\n  }\r\n  attr {\r\n    name: \"T\"\r\n    type: \"type\"\r\n  }\r\n} \r\n```\r\nIf you can't work around it, you could certainly make a DynamicPartitionV2 that takes tensors and not attributes, but there is usually a cost to this in terms of shape inference. This is why there is a separation between the two.", "still an issue. Does anyone find a solution yet? I just want to convert a N*N matrix into N vectors, where N is a tensor; but so far, I have not found any solution yet.", "@aselle Could you please comment?", "is N constant for the graph?", "@aselle Thank you for your response. N is not constant. Actually, N is my dynamic input of batch_size. However, due to the non-divisible of the total number, the last batch will have a number of samples not equal to \"batch_size\". Also, I do not want to throw away the remaining few samples or pre-fix my total number of samples. Therefore, N is not constant.", "Will this functionality be extended ?", "I think this is only possible with eager execution at the moment\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\ndef dynamic_partition(inputs, labels):\r\n    '''\r\n    Splits tensor along first axis according to parition label\r\n    \r\n    Input: - inputs: tensor(shape=(N,...), dtype=T)\r\n           - labels: tensor(shape=(N), dtype=?) with M<=N unique values\r\n             the k-th unique value occurs exactly N_k times\r\n    Returns: outputs: [tensor(shape=(N_1,...), dtype=T), ..., tensor(shape=(N_M,...), dtype=T)]\r\n    '''\r\n    classes, idxs = tf.unique(labels)\r\n    \r\n    indices = tf.range(tf.size(labels))\r\n    \r\n    classes = tf.unstack(classes)\r\n    \r\n    index_partition = [tf.boolean_mask(indices, tf.equal(labels, cl)) for cl in classes]\r\n\r\n    input_partition = [tf.gather(x, cl_idx) for cl_idx in index_partition]\r\n         \r\n    return input_partition\r\n\r\n\r\nx = tf.constant([[0,0], [1,1], [2,2], [3,3], [4, 4], [5,5], [6,6], [7,7], [8,8]], dtype=tf.float32)\r\nlabels = tf.constant([\"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"A\", \"B\", \"C\"])\r\n_, idxs = tf.unique(labels)\r\n\r\nprint(dynamic_partition(x, labels))\r\nprint(tf.dynamic_partition(x, idxs, 3))\r\n```\r\n", "@Chasearmer Could you please refer to the[ link ](https://www.tensorflow.org/api_docs/python/tf/dynamic_partition),similar [ issue ](https://stackoverflow.com/questions/41408561/dynamic-partition-with-dynamic-num-partitions)& Please let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19957\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19957\">No</a>\n"]}, {"number": 19956, "title": "Problems while compiling lite on arm64", "body": "Hello everyone! I'm encountering this error compiling tensorflow r1.9 (which can help to the official release):\r\n```\r\n                                                     ^\r\nERROR: /home/nvidia/src/tensorflow/tensorflow/contrib/lite/kernels/BUILD:128:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:builtin_ops' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /home/nvidia/.cache/bazel/_bazel_nvidia/a3a3883903ac5bbe9db32b5447dc16d6/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64: \\\r\n    PATH=/usr/local/cuda/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TENSORRT_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.2 \\\r\n    TF_CUDA_VERSION=9.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=1 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_TENSORRT_VERSION=4.0.4 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.d '-frandom-seed=bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/arm-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/arm-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/arm-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/arm-opt/genfiles/external/local_config_sycl -iquote external/gemmlowp -iquote bazel-out/arm-opt/genfiles/external/gemmlowp -iquote external/flatbuffers -iquote bazel-out/arm-opt/genfiles/external/flatbuffers -iquote external/fft2d -iquote bazel-out/arm-opt/genfiles/external/fft2d -iquote external/arm_neon_2_x86_sse -iquote bazel-out/arm-opt/genfiles/external/arm_neon_2_x86_sse -iquote external/farmhash_archive -iquote bazel-out/arm-opt/genfiles/external/farmhash_archive -isystem external/eigen_archive -isystem bazel-out/arm-opt/genfiles/external/eigen_archive -isystem bazel-out/arm-opt/bin/external/eigen_archive -isystem tensorflow/contrib/lite/schema -isystem bazel-out/arm-opt/genfiles/tensorflow/contrib/lite/schema -isystem bazel-out/arm-opt/bin/tensorflow/contrib/lite/schema -isystem external/flatbuffers/include -isystem bazel-out/arm-opt/genfiles/external/flatbuffers/include -isystem bazel-out/arm-opt/bin/external/flatbuffers/include -isystem external/farmhash_archive/src -isystem bazel-out/arm-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/arm-opt/bin/external/farmhash_archive/src '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections '-march=native' -DFARMHASH_NO_CXX_STRING '-Wno-error=reorder' -c tensorflow/contrib/lite/kernels/depthwise_conv.cc -o bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.o)\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8.h:21:0,\r\n                 from tensorflow/contrib/lite/kernels/depthwise_conv.cc:26:\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, input_depth) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:45: error: 'input_depth' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_depth) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:56: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_depth) ==\r\n                                                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, input_row_size) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:45: error: 'input_row_size' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_row_size) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:59: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_row_size) ==\r\n                                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_depth) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:45: error: 'output_depth' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_depth) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:57: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_depth) ==\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_row_size) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:45: error: 'output_row_size' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_row_size) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:60: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_row_size) ==\r\n                                                            ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, input_offset) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:45: error: 'input_offset' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_offset) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:57: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_offset) ==\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_offset) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:45: error: 'output_offset' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_offset) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:58: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_offset) ==\r\n                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, filter_offset) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:45: error: 'filter_offset' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, filter_offset) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:58: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, filter_offset) ==\r\n                                                          ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:45: error: 'output_multiplier' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:62: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==\r\n                                                              ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:45: error: 'output_activation_min' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:66: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==\r\n                                                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:45: error: 'output_activation_max' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:66: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==\r\n                                                                  ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_shift) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:45: error: 'output_shift' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_shift) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:57: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_shift) ==\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, input_width) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:45: error: 'input_width' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_width) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:56: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_width) ==\r\n                                                        ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, input_height) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:45: error: 'input_height' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_height) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:57: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, input_height) ==\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_width) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:45: error: 'output_width' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_width) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:57: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_width) ==\r\n                                                         ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:43: error: expected primary-expression before ',' token\r\n static_assert(offsetof(DepthwiseConvParams, output_height) ==\r\n                                           ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:45: error: 'output_height' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_height) ==\r\n                                             ^\r\n./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:58: error: 'offsetof' was not declared in this scope\r\n static_assert(offsetof(DepthwiseConvParams, output_height) ==\r\n                                                          ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 5672.830s, Critical Path: 357.47s\r\nINFO: 2837 processes, local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nI had no problem compiling 1.8, it seems that something was broken in that branch. Any solution ?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: No\r\nOS Platform and Distribution: Xenial\r\nTensorFlow installed from: source\r\nTensorFlow version: 1.9\r\nBazel version: 0.14.1\r\nCUDA/cuDNN version: 9.0/7.0\r\nGPU model and memory: Tegra X2\r\nExact command to reproduce: N/A", "This issue is GOOGLE_L4T Marco is 'not defined' in gcc on Jetson(build on Jetson). So, it will enter these section, then error happened.\r\n__aarch64__ is defined, GOOGLE_L4T is not defined.\r\nA simple fix is here, but not good. This just a fix, change GOOGLE_L4T Marco may needed.\r\nchange \r\ntensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h\r\ntensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8.h\r\n```\r\n// Enable for arm64 except for the Nvidia Linux 4 Tegra (L4T) running on\r\n// Jetson TX-2. This compiler does not support the offsetof() macro.\r\n\r\n#if defined(__aarch64__) && !defined(GOOGLE_L4T) \r\nto\r\n#if defined(__aarch64__) && !defined(GOOGLE_L4T)\r\n#include <stddef.h>\r\n```\r\nBecause GOOGLE_L4T is not defined, so it will not enter these section.\r\n", "Please reopen if this is still an issue.", "@Davidnet, @peterlee0127 \r\n\r\nAs a part of a separate issue, I'll be looking into updating this so that we\r\n1. don't rely on this Google-only macro for TX2\r\n2. this code (which cannot compile on either the Jetson TX1 or TX2) \r\n\r\nSeeing if there are any specific macros we can use so that gcc / llvm don't include this code for TX1 / TX2.\r\n\r\n\r\n", "For the Jetson, we only need to add the \r\n```\r\n#include <stddef.h>\r\n```\r\nI think Jetson don't need the Google-only macro for TX2.\r\n\r\nThanks."]}, {"number": 19955, "title": "(tensorboard) TypeError: __new__() got an unexpected keyword argument 'file'", "body": "# System information\r\n\r\n    Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    Yes\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    Windows 10\r\n    TensorFlow installed from (source or binary):\r\n    binary\r\n    TensorFlow version (use command below):\r\n    1.8.0\r\n    Python version:\r\n    3.5\r\n    Bazel version (if compiling from source):\r\n    GCC/Compiler version (if compiling from source):\r\n    CUDA/cuDNN version:\r\n    9.0/7.2\r\n    GPU model and memory:\r\n    Nvidia\r\n    Exact command to reproduce:\r\n     tensorboard --logdir=\"C:\\Users\\isultan\\PycharmProjects\\deep-shading\\logs\"`\r\n\r\n# Describe the problem\r\n\r\nCalling tensorboard with an argument for the directory of logs from Anaconda prompt causes a type error. Logs where produced in tf.keras with tensorboard callback `model_tb = TensorBoard(log_dir='./logs', write_graph=True)` passed to `model.fit_generator`. \r\n\r\n# Source code / logs\r\n\r\n`(tf) C:\\Users\\isultan> tensorboard --logdir=\"C:\\Users\\isultan\\PycharmProjects\\deep-shading\\logs\"`\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\isultan\\AppData\\Local\\Continuum\\miniconda3\\envs\\tf\\Scripts\\tensorboard.exe\\__main__.py\", line 5, in <module>\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\main.py\", line 30, in <module>\r\n    from tensorboard import default\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\default.py\", line 35, in <module>\r\n    from tensorboard.plugins.audio import audio_plugin\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\plugins\\audio\\audio_plugin.py\", line 30, in <module>\r\n    from tensorboard.plugins.audio import metadata\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\plugins\\audio\\metadata.py\", line 22, in <module>\r\n    from tensorboard.plugins.audio import plugin_data_pb2\r\n  File \"c:\\users\\isultan\\appdata\\local\\continuum\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\plugins\\audio\\plugin_data_pb2.py\", line 63, in <module>\r\n    options=None, file=DESCRIPTOR),\r\nTypeError: __new__() got an unexpected keyword argument 'file'\r\n``", "comments": ["Nagging Assignee @rohan100jain: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Please submit this issue with the Tensorboard repo https://github.com/tensorflow/tensorboard. "]}, {"number": 19954, "title": "Support compression_type for tf.contrib.data.make_csv_dataset, CsvDataset", "body": "Currently `TFRecordDataset` and `TextLineDataset` support `compression_type` for reading compressed CSV/Tfrecords files. However the newer `make_csv_dataset` and `CsvDataset` do not support compression_type. Request tou to support the `compression_type` feature.\r\n", "comments": ["Nagging Assignee @rachellim: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rachellim: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 19953, "title": "tensorflow/go: operation attribute getters", "body": "This adds the ability to fetch operation attributes. This is needed for any sort of graph rewriting ability.\r\n\r\nThe tests on this are pretty minimal since I wasn't sure the best way to test all of the attributes. Hunting down operations that match each param seems like a huge pain and the C api style of creating test ops isn't currently possible from Go. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api_test.cc#L1703-L1753\r\n\r\nNot sure if it'd be possible to add in a small .h and .cc file containing just those lines while running the Go tests. Thoughts?", "comments": ["Yeah, that's probably a sane way of doing things. The C api is a bit over verbose."]}, {"number": 19952, "title": "tf.data.Dataset.shard_and_drop_remainder?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n      - yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n       - v.1.8.0\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm curious if there's anyway to accomplish a function like Dataset.shard_and_drop_remainder(num_shards, index) with the current machinery? If not, then I guess this is a feature request. The use case I have is, I'm training an RNN model with horovod and I've decided to bucket my variable length sequences, then batch them, and then shard to the number of workers, but I have no idea if there are enough batches at all my workers to perform an allreduce, which results in horovod complaining and failing in the allreduce. Ideally I would like the dataset to take \"num_shards\" and use that to check whether I have enough elements in the dataset to carry out another global step.\r\n\r\nThe solution I've come up with now is to iterate once to count the number of batches and then use Dataset.take((num_batches//num_workers)*num_workers) to ensure the number of batches is divisible by the number of workers. \r\n", "comments": ["I've thought of using Dataset.batch (and even Dataset.padded_batch), to batch num_workers and then tf.contrib.data.unbatch() them, but the shapes don't match, i.e., [batch_size, max_seq_len_1] and [batch_size, max_seq_len_2], not to mention it is a lot of extra work to batch() -> unbatch -> rebatch().", "@mrry could you please comment on whether there's a way to do what @terrykong wants, or if this is a feature request, whether we might do it, or we should mark it \"Community Support\"?", "I think this should be possible with the new batching operations that @jsimsa is working on.", "Hello @terrykong, the workaround you used is currently the best known solution. However, as alluded to by @mrry, I am working and a couple of new transformations that will allow you do to the following:\r\n\r\n```\r\ndataset = dataset.batch(batch_size).window(num_workers).filter(lambda x: tf.equal(count(x), num_workers)).flat_map(lambda x: x)\r\n```\r\n\r\nThe new transformations are:\r\n`window` -- which combines elements of the input dataset into windows of (nested) datasets\r\n`count` -- which assumes the input is a dataset and counts the number of elements of its elements\r\n\r\nThe design is expected to undergo an external review soon and I will notify you when it does.", "Very cool @jsimsa! I look forward to your changes :)", "@terrykong see the RFC [here](https://github.com/tensorflow/community/blob/4ecf2719615320993b830c186d3d3c35ed7a801f/rfcs/20180726-tf-data-windowing-reducers.md) and feel free to leave comments / feedback [here](https://github.com/tensorflow/community/pull/5).", "Nagging Assignee @jsimsa: It has been 109 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}]