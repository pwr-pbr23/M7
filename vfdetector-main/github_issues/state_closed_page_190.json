[{"number": 49036, "title": "Fix divide by zero error in `fractional_pool_common.cc`.", "body": "PiperOrigin-RevId: 371126221\nChange-Id: Iea4b2f363aaeb116ab460e3bc592c687484af344", "comments": []}, {"number": 49035, "title": "Validate work in `QuantizedAdd`, ensure at least one element.", "body": "PiperOrigin-RevId: 370127996\nChange-Id: I57c6f3e01afdeada84737820a131590137463855", "comments": []}, {"number": 49034, "title": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`", "body": "PiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33", "comments": []}, {"number": 49033, "title": "Prevent division by 0 in `QuantizedBiasAdd`.", "body": "PiperOrigin-RevId: 370117454\nChange-Id: I3804e2ac8dcc6d3afcc92e27853e2325a017ca4d", "comments": []}, {"number": 49032, "title": "Fix crash in `SparseTensorToCSRSparseMatrixCPUFunctor`", "body": "PiperOrigin-RevId: 370110290\nChange-Id: I4451e92661a55c2180f80d38b67a9b50bf5edec5", "comments": []}, {"number": 49031, "title": "Fix `tf.raw_ops.CTCGreedyDecoder` CHECK failure.", "body": "PiperOrigin-RevId: 369960465\nChange-Id: If0b8b3264d5a47a24ac0970ed7b81ce6b4921fae", "comments": []}, {"number": 49030, "title": "Add pred_transform_function in Accuracy", "body": "The motivation behind this pull request is to add flexibility in processing model output before calculating metric from it. One practical use case is for classification problem for ordered ordinal classes, which is easier to frame as a regression model. However, regression outputs a continuous-valued variable, therefore cannot be used to compute accuracy. In the prediction setting, we can clip and round the regression output to obtain integer i.e. the classification result. By adding pred_transform_function to accuracy, user can tweak model output and monitor their model better-suited to their needs.", "comments": ["My initial thinking is the team would probably prefer to not further expand the API when there's already several existing ways to manipulate desired metrics computation.\r\n\r\nhttps://keras.io/api/metrics/\r\n\r\nE.g. Several ways of specifying custom metrics which are free to wrap other metrics, several variations of add_metrics, multi-output models that compute different metrics on different outputs, custom training steps that modify details of metrics computation, etc.\r\n\r\nWe'll discuss this at our sync though.", "Thank you for your response, definitely waiting for updates after the sync", "Hi @ammarchalifah , we concluded that our api surface is too expansive as-is and so we unfortunately can't add this argument. You should be able to subclass the accuracy metric and override update_state (and call the super method in there) to make your own custom metric that has this functionality."]}, {"number": 49029, "title": "BasicDecoderOutput with None lengths in networks_seq2seq_nmt example", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt\r\n\r\n## Description of issue (what needs changing):\r\nIt is not clear what the output of the BasicDecoder is. The output variable is is from type BasicDecoderOutput and has two attributes: rnn_output and  sample_id. The output should be (in my opinion) of shape (batch_size, target_leghts, vocab_size) and (batch_size, target_leghts) respectively. When I print the variable in the training loop the larget_lengths is None. Why is this not an issue for the calculation of the loss? and how do I get the real predictions inside the train_step function e.g. to calculate metrics?\r\n\r\n### Submit a pull request?\r\nCurrently not since I don't understand the solution myself. But afterwards, I would create a pull request to share the information.\r\n", "comments": ["@soerenetler The issue is more related to TF Add ons. Could you please  submit a new issue on this [repo](https://github.com/tensorflow/addons). Thanks!", "You are absolutely right. I reposted it in the addons repository: https://github.com/tensorflow/addons/issues/2474\r\nThank you for your help \ud83d\udc4d "]}, {"number": 49028, "title": "tf_uniform_replay_buffer Warning", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Springdale Linux 7.9 (Verona)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.9.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: Tesla P100\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nTF uniform buffer raises error.\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing): no\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tf_agents import specs\r\nfrom tf_agents.agents.dqn import dqn_agent\r\nfrom tf_agents.drivers import dynamic_step_driver\r\nfrom tf_agents.environments import suite_gym\r\nfrom tf_agents.environments import tf_py_environment\r\nfrom tf_agents.networks import q_network\r\nfrom tf_agents.replay_buffers import py_uniform_replay_buffer\r\nfrom tf_agents.replay_buffers import tf_uniform_replay_buffer\r\nfrom tf_agents.specs import tensor_spec\r\nfrom tf_agents.trajectories import time_step\r\n\r\ntf.compat.v1.enable_v2_behavior()\r\n\r\ndata_spec =  (\r\n        tf.TensorSpec([3], tf.float32, 'action'),\r\n        (\r\n            tf.TensorSpec([5], tf.float32, 'lidar'),\r\n            tf.TensorSpec([3, 2], tf.float32, 'camera')\r\n        )\r\n)\r\n\r\nbatch_size = 1\r\nmax_length = 1000\r\n\r\nreplay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\r\n    data_spec,\r\n    batch_size=batch_size,\r\n    max_length=max_length)\r\n\r\naction = tf.constant(1 * np.ones(\r\n    data_spec[0].shape.as_list(), dtype=np.float32))\r\nlidar = tf.constant(\r\n    2 * np.ones(data_spec[1][0].shape.as_list(), dtype=np.float32))\r\ncamera = tf.constant(\r\n    3 * np.ones(data_spec[1][1].shape.as_list(), dtype=np.float32))\r\n\r\nvalues = (action, (lidar, camera))\r\nvalues_batched = tf.nest.map_structure(lambda t: tf.stack([t] * batch_size),\r\n                                       values)\r\n\r\nfor _ in range(5):\r\n    replay_buffer.add_batch(values_batched)\r\n\r\ndataset = replay_buffer.as_dataset(sample_batch_size=4,single_deterministic_pass=False)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n[bug_report.txt](https://github.com/tensorflow/tensorflow/files/6448373/bug_report.txt)\r\n\r\n", "comments": ["@weiT1993 \r\n\r\nI reproduced the code shared in tf2.4, tf2.5rc2 and in tf-nightly,didn't face any errors.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/1ce2da133353a87aa21afefd13fede50/untitled48.ipynb)  here.Thanks", "@weiT1993 The deprecation warning message you see in your `error.txt` is mentioned in the docs.\r\n`Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version. Instructions for updating: Use as_dataset(..., single_deterministic_pass=True) instead.`\r\nSee https://www.tensorflow.org/agents/api_docs/python/tf_agents/replay_buffers/replay_buffer/ReplayBuffer", "@ymodak Thanks. I am aware of the deprecation for `get_next`. But the code snippet (taken from the documentation [here](https://www.tensorflow.org/agents/tutorials/5_replay_buffers_tutorial)) is not calling `get_next`. Does the deprecation warning pop up regardless?", "On debugging further I see that calling `TFUniformReplayBuffer` under the hood\r\n```python\r\nreplay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\r\n    data_spec,\r\n    batch_size=batch_size,\r\n    max_length=max_length)\r\n```\r\nhits `get_next method` defined at https://github.com/tensorflow/agents/blob/29daabcc11b277a914f6b848d44c30b4aabbf659/tf_agents/replay_buffers/replay_buffer.py#L85 which has a deprecation warning.", "Thanks. I will just ignore the warning now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49028\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49028\">No</a>\n"]}, {"number": 49027, "title": "why with mirroredStrategy GPUs have different memory footprint?", "body": "With data parallelization, I was expecting all GPUs will have the same memory footprint for a training model with GLOBAL_BATCH_SIZE divisible by #GPUs. But why I am seeing different memory footprint ranging from 5.2GB to 9.2G per GPU? I am on a DGX-1 and training a GAN model with GLOBAL_BATCH_SIZE=32 and 8 V100 GPUs. The model is quite small though (128x128)\r\n\r\nAfter more testings, it seems that TF allocates a constant memory (~4GB) regardless of the model size and prefetch() causes this random memory footprint. Can someone help to explain TF memory model? \r\n\r\n<img width=\"890\" alt=\"Screen Shot 2021-05-09 at 3 28 26 PM\" src=\"https://user-images.githubusercontent.com/3358807/117586048-65f7d800-b0db-11eb-8648-ed342320ea16.png\">\r\n", "comments": ["@llodds ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version.Thanks!", "@tilakrayal \r\n```bash\r\nIn [3]: print(tf.version.VERSION)\r\n2.4.1\r\n```\r\n\r\nMore update: the 4GB constant memory is reduced by half if I am using mixed-precision training policy. So I guess this 4GB is purely the memory to store the training model. Sorry I can't share the code. Is it expected that different memory footprint for different GPUs during data parallel distributed training?", "@llodds ,\r\n\r\nWithout the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, could you please provide a minimal code snippet.\r\n\r\nAlso please take a look at [link1](https://www.tensorflow.org/install/source#gpu) for  tested build configurations.\r\n\r\nThanks!", "@tilakrayal \r\nI did another round of testing and found the issue only occurs when I am training with a small model, and the issue appears randomly. I will report back when I see more consistent behavior. You can close the ticket now.", "@llodds ,\r\n\r\nPlease feel free to move this issue to closed status if the issue is resolved.Thanks!"]}, {"number": 49026, "title": "Update ICU to 69.1", "body": "\r\nThis PR updates ICU from 64.2 to to 69.1.\r\n\r\nNote this PR will cover CVE-2020-10531 (https://www.cvedetails.com/cve/CVE-2020-10531/) which exists through 66.1.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yongtang  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "Thanks @gbaned @mihaimaruseac for the reminder. I think I find out where the issue is. Static files within `tensorflow/third_party/icu/data/` directory will need to be updated manually and provided as a part of the PR.\r\n\r\nHowever, there is no documentation on how to update those files so I am still in the process of understanding. I will provide update once I can make some progress.", "@yongtang Can you please resolve conflicts? Thanks!", "@yongtang Any update on this PR? Please. Thanks!", "@yongtang Any update on this PR? Please. Thanks!", "Sorry for duplicating the work, @yongtang . I was working to bump to 70.1, but due to some failing tests had to lower to 69.1 and then that closed this PR.\r\n\r\nI think PR failed before because we didn't also update the datafiles, I added some instructions so we don't forget in the future."]}, {"number": 49025, "title": "Update libjpeg-turbo from 2.0.5 to 2.1.0", "body": "This PR updates libjpeg-turbo from 2.0.5 to 2.1.0.\r\n\r\nThere were at least one CVE (CVE-2021-20205) (see https://github.com/libjpeg-turbo/libjpeg-turbo/releases/tag/2.1.0)\r\nthat has been fixed by libjpeg-turbo.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yongtang can you please check build failures ?", "The failures are not because of the PR, let's continue with the import"]}, {"number": 49024, "title": "Update LMDB to 0.9.29", "body": "The exiting LMDB used in tensorflow is from 0.9.22(03/22/2018) which\r\nis alreay 3 years old. For that it makes sense to update LMDB to\r\nthe latest version of 0.9.29 (released a month ago).\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 49023, "title": "Remove pcre library from Bazel file as it is not used anymore", "body": "\r\nIt looks like tensorflow does not use pcre anymore. For that it makes\r\nsense to remove pcre from Bazel files completely to avoid additional\r\nmaintenance.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": []}, {"number": 49022, "title": "Problems when using a100 graphics card", "body": "Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n\r\nIs there any way to install tensorflow directly when using a100 server?\r\nDo I have to use the docker image provided by nvidia?\r\nInstallation was done with pip tensorflow-gpu.", "comments": ["@Foreist Could you please be more specific about the missing libraries. Are you able to install tensorflow-gpu with pip package successfully? If not, Please provide the error logs.\r\n\r\nAlso, Provide the TF version and the OS platform you are using so that it helps us to  figure out the issue.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49022\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49022\">No</a>\n"]}, {"number": 49021, "title": "Variable scope is created repeatedly", "body": "tensorflow version: 1.15.0\r\npython version: 3.6.12\r\nVariable scope is created repeatedly using tf.variable_scope as follows:\r\n```python\r\nwith tf.variable_scope(\"my_variable_scope\", reuse=tf.AUTO_REUSE):\r\n    v = tf.get_variable(\"v\", [1])\r\n    print(v.name)\r\n    w = tf.get_variable(\"w\", [1])\r\n    print(w.name)\r\n    b = w + 1\r\n    c = w + 1\r\n    print(b.name, c.name)\r\n\r\nwith tf.variable_scope(\"my_variable_scope\", reuse=tf.AUTO_REUSE) as scope:\r\n    scope.reuse_variables()\r\n    v1 = tf.get_variable(\"v\")\r\n    a = v1 + 1\r\n    print(v1.name)\r\n    print(a.name)\r\n\r\nwith tf.variable_scope(\"my_variable_scope\", reuse=tf.AUTO_REUSE) as scope:\r\n    scope.reuse_variables()\r\n    v1 = tf.get_variable(\"v\")\r\n    a = v1 + 1\r\n    print(v1.name)\r\n    print(a.name)\r\n```\r\nHere comes the output:\r\n```bash\r\nmy_variable_scope/v:0\r\nmy_variable_scope/w:0\r\nmy_variable_scope/add:0 my_variable_scope/add_1:0\r\nmy_variable_scope/v:0\r\nmy_variable_scope_1/add:0\r\nmy_variable_scope/v:0\r\nmy_variable_scope_2/add:0\r\n```\r\nSo, why my_variable_scope, my_variable_scope_1, my_variable_scope_2 are created for a. Thanks for your help.", "comments": ["If you want reenter a premade variable scope, you can try use `auxiliary_name_scope=False` with `tf.name_scope()` as follows:\r\n\r\n```\r\nwith tf.variable_scope(\"my_variable_scope\", reuse=tf.AUTO_REUSE) as scope1:\r\n  v = tf.get_variable(\"v\", [1])\r\n  print(v.name)\r\n  w = tf.get_variable(\"w\", [1])\r\n  print(w.name)\r\n  b = w + 1\r\n  c = w + 1\r\n  print(b.name, c.name)\r\n\r\nwith tf.variable_scope(scope1, auxiliary_name_scope=False) as scope2:\r\n  with tf.name_scope(scope1.original_name_scope):\r\n    v1 = tf.get_variable(\"v\")\r\n    a = v1 + 1\r\n    print(v1.name)\r\n    print(a.name)\r\n\r\nwith tf.variable_scope(scope1, auxiliary_name_scope=False) as scope3:\r\n  with tf.name_scope(scope1.original_name_scope):\r\n    v1 = tf.get_variable(\"v\")\r\n    a = v1 + 1\r\n    print(v1.name)\r\n    print(a.name)\r\n```\r\nOutputs:\r\n```\r\nmy_variable_scope/v:0\r\nmy_variable_scope/w:0\r\nmy_variable_scope/add:0 my_variable_scope/add_1:0\r\nmy_variable_scope/v:0\r\nmy_variable_scope/add_2:0\r\nmy_variable_scope/v:0\r\nmy_variable_scope/add_3:0\r\n```", "@lizhen2017 Did you try the solution provided by @daugraph [here](https://github.com/tensorflow/tensorflow/issues/49021#issuecomment-835840899). You can also go through the [document](https://www.tensorflow.org/api_docs/python/tf/compat/v1/variable_scope) for more info. ", "> @lizhen2017 Did you try the solution provided by @daugraph [here](https://github.com/tensorflow/tensorflow/issues/49021#issuecomment-835840899). You can also go through the [document](https://www.tensorflow.org/api_docs/python/tf/compat/v1/variable_scope) for more info.\r\n\r\nYes, I've tried. And also tried https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/ops/variable_scope.py#L2104, both have succeeded.\r\nBut if the variable scope can't be known in advance, auxiliary_name_scope should be judged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49021\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49021\">No</a>\n", "> > @lizhen2017 Did you try the solution provided by @daugraph [here](https://github.com/tensorflow/tensorflow/issues/49021#issuecomment-835840899). You can also go through the [document](https://www.tensorflow.org/api_docs/python/tf/compat/v1/variable_scope) for more info.\r\n> \r\n> Yes, I've tried. And also tried https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/ops/variable_scope.py#L2104, both have succeeded.\r\n> But if the variable scope can't be known in advance, auxiliary_name_scope should be judged.\r\n\r\nI've tried with loops, scope variable must be reused, below I used a dict to store it with scope name as the key. And Would you please share a simpler code?\r\n```python\r\nscope = 'foo'\r\nscopes = {}\r\nfor i in range(3):\r\n    auxiliary_name_scope = True\r\n    reuse=tf.AUTO_REUSE\r\n    if scope in scopes:\r\n        reuse = None\r\n        auxiliary_name_scope = False\r\n    else:\r\n        scopes[scope] = tf.variable_scope(scope, auxiliary_name_scope=auxiliary_name_scope, reuse=tf.AUTO_REUSE)\r\n    with scopes[scope] as vs:\r\n        print(scope, auxiliary_name_scope, vs.original_name_scope, reuse)\r\n        with tf.name_scope(vs.original_name_scope):\r\n            v1 = tf.get_variable(\"v\", [1])\r\n            a = v1 + 1\r\n            print(v1.name)\r\n            print(a.name)\r\n```"]}, {"number": 49020, "title": "Hey there.", "body": "We are doing a survey on globally distributed software engineering focused on open source projects. If you have some spare time we would really appreciate your response. The form takes about 10 minutes. Thanks in advance!\r\nSurvey can be found [here](https://forms.gle/N1TnifRuCYHrCY9JA)\r\n", "comments": ["@tvheems ,\r\n\r\nCan you please provide more information/detials to understand the request.Thanks!"]}, {"number": 49019, "title": "Cached memory for Eigen backend since TF 2.5", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):  From source\r\n- TensorFlow version (use command below): TF 2.5.0-rc3\r\n- Python version:\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\nI have built `TF 2.5.0-rc3` from sources without MKL backend under Windows. I didn't specify `--config=mkl` in build command, so I assume Eigen backend was used during the build. Isn't it ? The full build command is:\r\n`bazel --output_base=myPath build -c opt --copt=/arch:AVX1 //tensorflow:get_tensorflow_cc_dll_import_lib`\r\n\r\n\r\nI know that in TF with MKL backend memory is cached. With Eigen there was not this issue, all memory after querying model was released (tested in TF2.1 and TF2.3). Now, since TF2.5 I have seen that memory is cached also for Eigen backend. Why is it so?\r\n\r\nI have modified primitive capacity inside `MklPrimitiveFactory` template from 1024 to 4, but not all memory is released, but it indicates that MKL backend was used to build library:\r\n\r\n```\r\n  static inline LRUCache<MklPrimitive>& GetLRUCache() {\r\n    static const int kCapacity = 4;  // 1024 cache capacity\r\n    static thread_local LRUCache<MklPrimitive> lru_cache_(kCapacity);\r\n    return lru_cache_;\r\n  }\r\n```\r\n \r\nWhat is going on here? Without explicitly specyfing `--config=mkl`, MKL is choosen by default ? \r\n\r\nQuestion: how to build TF with Eigen backend with releasing all memory, without caching?\r\n\r\n\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49019\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49019\">No</a>\n"]}, {"number": 49018, "title": "Adding example for uniform_row_length in RaggedTensor", "body": "There are total 6 schemes [here](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor#alternative_row-partitioning_schemes_2) for row-partitioning of RaggedTensor but the examples are only for 5. I have added missing example.\r\n\r\ncc: @mihaimaruseac ", "comments": []}, {"number": 49017, "title": "import tensorflow throws ImportError: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization' ", "body": "Hey, I have been trying to get my computer to use the GPU instead of the CPU for the last 2 days. During this process, I had reinstalled TensorFlow, CUDA, cuDNN and everything that's possibly related to the problem.\r\n\r\nAnyway, now I'm stuck with a new error. I'm not able to even import TensorFlow\r\n![image](https://user-images.githubusercontent.com/29381705/117567669-b884c480-b0da-11eb-867e-797e0e32255a.png)\r\n", "comments": ["I am having this issue as well.", "Generally we don't support directly Anacoda env as it is supported by third party:\r\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\r\nhttps://github.com/AnacondaRecipes/tensorflow_recipes", "For using TF-GPU, make sure you are having compatible cuda, cudnn version installed. You may refer following table:\r\n```\r\nTF  ==>  CUDA\r\n2.5.0  ==> 11.2\r\n2.4.0  ==> 11.0\r\n[2.1.0 - 2.3.0]  ==> 10.1 \r\n[1.13.1 - 2.0]   ==> 10.0  \r\n1.5.0 - 1.12.0  ==> 9.0 \r\n```\r\nFor tested builds cuda, cudnn, tf versions see https://www.tensorflow.org/install/source#gpu\r\n\r\nClosing this issue since it's related to conda env. Feel free to post another issue if still having problems installing TF using `pip`.\r\nThanks!"]}, {"number": 49016, "title": "Sparse Data support for tf.data.Dataset.from_generator API using sparse COO arrays", "body": "**System information**\r\n- TensorFlow version 2.4.1:\r\n\r\n\r\nI was trying to ingest sparse data into `tf.data.Dataset` by using the `from_generator` API. \u03a4he example below uses `scipy.coo_matrix`. Trying that with on-prem design for Sparse Arrays which follows the COO representation I was not able to pass the\r\n\r\n```\r\nrow = np.array([0, 3, 1, 0])\r\ncol = np.array([0, 3, 1, 2])\r\ndata = np.array([4, 5, 7, 9])\r\na = coo_matrix((data, (row, col)), shape=(4, 4))\r\nreturn tf.data.Dataset.from_generator(\r\n            generator=cls._generator,\r\n            output_signature=(\r\n                tf.SparseTensorSpec(dtype=tf.int32)\r\n            )\r\n            ,args=(a,),\r\n        )\r\n```\r\nI was getting the following error:\r\n```\r\nTypeError(\"Failed to convert object of type %s to Tensor. \"\r\nTypeError: Failed to convert object of type <class 'SparseArray'> to Tensor. Contents: ....\r\n```\r\nThinking that the culprit may be the `on-prem` implementation of sparse data I tried the same with `scipy.coo_matrix`\r\n\r\nI get the same error:\r\n\r\n```\r\nAttempt to convert a value (<4x4 sparse matrix of type '<class 'numpy.int64'>' with 4 stored elements in COOrdinate format>) with an unsupported type (<class 'scipy.sparse.coo.coo_matrix'>) to a Tensor.\r\n```\r\n\r\nAfter some debugging I saw that the error comes from the evaluation of the arguments of generator function, Which makes sense since in the docs here clearly states that the args should be `tf.Tensors`.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\r\n\r\n```\r\nargs | (Optional.) A tuple of tf.Tensor objects that will be evaluated and passed to generator as NumPy-array arguments.\r\n```\r\n\r\nHowever after the introduction of `SparseTensors` and `SparseTensorSpec` I'm not sure if it's just me, but when I read this part of the documentation I was under the impression that these `scipy.coo_matrix` would be translated into `SparseTensors` or at least to` index, value` Numpy-arrays by exploiting the `data, row, col` attr of the COO sparse format (e.g. `scipy.coo_matrix`), especially since `tf.SparseTensors` uses the same COO format. Is there any walk-around on how someone can ingest sparse data using from_generator? Is there any formal way that I am not aware? I think it would make sense to support it as a feature if it is not currently supported\r\n\r\n**I think it would make sense to support it as a feature if it is not currently supported. There might be alternatives but getting batches of sparse data without having to transform them into dense representation and lose memory efficiency of them I think can be critical in some implementations.**\r\n\r\n**I commented also on an old open issue https://github.com/tensorflow/tensorflow/issues/44565 but I thought that it might be better if I set it as a separate one.**", "comments": ["Hi @ktsitsi,\r\n\r\nThe issue is that tf.sparse.SparseTensor represents sparse matrices using `(indices, values, shape)` format, while coo_matrix represents sparse matrices using `(rows, cols, values, shape)` format.The difference is that TF expects a single matrix of indices, while coo_matrix has one vector for row indices and another vector for column indices. Reconciling these formats requires a copy. This can be done using `zip` like below\r\n\r\n```python\r\nshape = np.array([4, 4])\r\nrow = np.array([0, 3, 1, 0])\r\ncol = np.array([0, 3, 1, 2])\r\ndata = np.array([4, 5, 7, 9], dtype=np.int32)\r\ncoo = coo_matrix((data, (row, col)), shape=shape)\r\ntf_sparse = tf.sparse.SparseTensor(list(zip(coo.row, coo.col)), coo.data, coo.shape)\r\n\r\ndef gen():\r\n  yield tf_sparse\r\n\r\nds = tf.data.Dataset.from_generator(\r\n            generator=gen,\r\n            output_signature=(\r\n                tf.SparseTensorSpec(dtype=tf.int32)\r\n            ),\r\n        )\r\n```\r\n([full colab example](https://colab.research.google.com/drive/1z99pOCh4pl9J_A8HQPsDE9AA0DL_52T1))"]}, {"number": 49015, "title": "@mitramir55 please open a new issue, fill in issue template and provide minimal code to reproduce. It's likely you have some dependency issue / some wrong version of TF installed. `pip list` should also help in identifying the issue", "body": "@mitramir55 please open a new issue, fill in the issue template and provide minimal code to reproduce. It's likely you have some dependency issue / some wrong version of TF installed. `pip list` should also help in identifying the issue\r\n\r\n_Originally posted by @mihaimaruseac in https://github.com/tensorflow/tensorflow/issues/31315#issuecomment-643346367_\r\n\r\nI have checked the version too still the same issue. Attribute error: TensorFlow has no attribute ", "comments": ["@99003731 Could you please elaborate your query. Please provide the  standalone code/ colab to reproduce the issue at our end and share  error logs as well.  Also, let us know the TF version you are working on. Thanks!", "Issue template was not filled. Please fill in issue template, provide minimal code to reproduce the issue and give details. Otherwise, we are left to guess what could be the issue you are seeing and this is both not a good use of time and also will not lead to a quick solve of your issue.\r\n\r\nThe more details you provide, the faster it will be to provide a fix.", "code: label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\nmy error:File \"C:\\Users\\<my path>\\utils\\label_map_util.py\", line 137, in load_labelmap\r\n    with tf.gfile.GFile(path, 'r') as fid:\r\nAttributeError: module 'tensorflow' has no attribute 'gfile'\r\n\r\ntensorflow version 2.3.0\r\nthese are the details is this okay or more description/details you require\r\n", "@99003731  If possible, Could you please provide the complete reproducible code so that we can debug into issue and provide the response in a better way. Thanks!", "@saikumarchalla  here is the code you can debug\r\n\r\nimport glob\r\nimport math\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow.compat.v1 as tf\r\nfrom PIL import Image\r\nfrom utils import label_map_util\r\nfrom utils import visualization_utils as vis_util\r\n\r\n\r\nPATH_TO_LABELS = 'label_map_Thread.pbtxt'\r\nNUM_CLASSES = 1\r\n# Loading label map\r\n# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\r\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\ncategories = label_map_util.convert_label_map_to_categories(\r\n    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\ncategory_index = label_map_util.create_category_index(categories)\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@99003731  tf.gfile has been moved under tf.io. \r\nInstead of  `tf.gfile.GFile(path, 'r')` you can use `tf.io.gfile.GFile(name, mode='r')`. \r\nYou can find more info about this from the document [here](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49015\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49015\">No</a>\n"]}, {"number": 49014, "title": "MultiWorkerMirroredStrategy for multiple gpus on a worker", "body": "could tensorflow provide official examples for MultiWorkerMirroredStrategy for multiple gpus on a worker.", "comments": ["@chenxinhua \r\nCould you please find the [documentation](https://www.tensorflow.org/guide/distributed_training) with an [example](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) . Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@chenxinhua \r\nCould you please confirm if the issue still persist.Thanks", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 49013, "title": "E: Failed to stat /var/lib/apt/lists/partial/developer.download.nvidia.com_compute_cuda_repos_ntu1604_x86%5f64_Packages - pkgAcqTransactionItem::TransactionState-stat (2: No such file or directory)", "body": "\r\nhttps://www.tensorflow.org/install/gpu?hl=ur#ubuntu_1604_cuda_110\r\n\r\nOn 5th step\r\n\r\n```\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/ /\"\r\nsudo apt-get update\r\n```\r\n\r\n```\r\nHit:1 http://ru.archive.ubuntu.com/ubuntu xenial InRelease\r\nHit:2 http://ru.archive.ubuntu.com/ubuntu xenial-updates InRelease                                                                                     \r\nHit:3 http://ru.archive.ubuntu.com/ubuntu xenial-backports InRelease                                                                                   \r\nHit:4 http://linux.teamviewer.com/deb stable InRelease                                                                                                 \r\nIgn:5 http://dl.google.com/linux/chrome-remote-desktop/deb stable InRelease                                                                            \r\nHit:6 http://dl.google.com/linux/chrome-remote-desktop/deb stable Release                                                                              \r\nHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu xenial InRelease                                                                                  \r\nHit:8 http://deb.anydesk.com all InRelease                                                                                                             \r\nHit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu xenial InRelease                                                                           \r\nIgn:10 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease                                                           \r\nHit:11 http://security.ubuntu.com/ubuntu xenial-security InRelease      \r\nHit:12 https://deb.nodesource.com/node_12.x xenial InRelease            \r\nHit:13 https://apt.syncthing.net syncthing InRelease\r\nIgn:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\r\nGet:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [836 B]\r\nIgn:17 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\r\nGet:19 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release [697 B]\r\nHit:20 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\r\nGet:21 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [836 B]\r\nIgn:23 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages\r\nGet:23 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [687 kB]\r\nIgn:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages\r\nGet:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [687 kB]\r\nFetched 1 375 kB in 2s (619 kB/s) \r\nReading package lists... Done\r\nE: Failed to stat /var/lib/apt/lists/partial/developer.download.nvidia.com_compute_cuda_repos_ubuntu1604_x86%5f64_Packages - pkgAcqTransactionItem::TransactionState-stat (2: No such file or directory)\r\nW: Duplicate sources.list entry http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\r\n```", "comments": ["Seems to be fixed with https://forums.developer.nvidia.com/t/errors-during-adding-of-nvidia-repository-and-installing-nvidia-drivers/62079/6\r\n\r\n`sudo apt upgrade`\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49013\">No</a>\n"]}, {"number": 49010, "title": "[tf.data] graduate experimental `take_while` API to tf.data.Dataset", "body": "This PR graduates the `tf.data.experimental.take_while` API into `tf.data.Dataset.take_while` by making the following changes:\r\n\r\n- [x] Adds the deprecation decorator for the experimental API.\r\n- [x] Add the `take_while()` method to `DatasetV2` class.\r\n- [x] Updates example in documentation with new API.\r\n- [x] Regenerate golden API's.\r\n- [x] Moved and updated the `take_while_test` target from experimental/kernel_tests to kernel_tests\r\n- [x] Updated the RELEASE.md file\r\n\r\nTEST LOG\r\n```\r\nINFO: Build completed successfully, 355 total actions\r\n//tensorflow/python/data/kernel_tests:take_while_test                    PASSED in 3.9s\r\n  Stats over 4 runs: max = 3.9s, min = 3.7s, avg = 3.8s, dev = 0.1s\r\n\r\n```\r\n\r\ncc: @jsimsa @aaudiber ", "comments": ["@aaudiber any update on this?", "@kvignesh1420 still working on getting it merged, should hopefully be in soon", "sure, thanks!", "cc: @gbaned @aaudiber the conflicts have been resolved.", "closing the PR as the internal commit has been made."]}, {"number": 49009, "title": "[tf.data] graduate experimental `scan` API to tf.data.Dataset", "body": "This PR graduates the `tf.data.experimental.scan` API into `tf.data.Dataset.scan` by making the following changes:\r\n\r\n- [x] Adds the deprecation decorator for the experimental API.\r\n- [x] Add the `scan()` method to `DatasetV2` class.\r\n- [x] Updates example in documentation with new API.\r\n- [x] Regenerate golden API's.\r\n- [x] Moved and updated the `scan_test` target from experimental/kernel_tests to kernel_tests\r\n- [x] Updated the RELEASE.md file\r\n\r\nTEST LOG\r\n```\r\nINFO: Build completed successfully, 5 total actions\r\n//tensorflow/python/data/kernel_tests:scan_test                          PASSED in 5.0s\r\n```\r\n\r\ncc: @jsimsa @aaudiber ", "comments": ["cc: @aaudiber can you please take a look?", "@aaudiber  any update on this? Let me know if additional fixes are required."]}, {"number": 49008, "title": "fix numpy 1.20", "body": "Related #48918", "comments": ["I think that `>=` probably It will be a little bit \"out of control\" for the TF team. But I could be wrong. /cc @mihaimaruseac ", "This got rolled back", "> This got rolled back\n\nDo you know why?", "A TFX test broke, but didn't look into why yet."]}, {"number": 49007, "title": "Order of resampled dataset is wrong", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.4.1\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am using `tf.data.experimental.sample_from_datasets()` to balance a dataset. Now, I am creating two data loaders out of the resampled dataset and then zipping them up.  When I am iterating through the zipped dataset the images are coming in different orders. \r\n\r\nLet's walk this through step by step:\r\n\r\n**Data**\r\n\r\n```python\r\n(x_train, y_train), (_, _) = tf.keras.datasets.cifar10.load_data()\r\nsampled_idx = np.random.choice(len(x_train), 4000)\r\nsampled_train, sampled_labels = x_train[sampled_idx], y_train[sampled_idx].squeeze()\r\nsupport_ds = tf.data.Dataset.from_tensor_slices((sampled_train, sampled_labels))\r\n```\r\n\r\n**Utilities**\r\n\r\n```python\r\ndef support_sampler(ds):\r\n    ds_list = []\r\n    for i in np.arange(0, 10):\r\n        ds_label = ds.filter(lambda image, label: label == i).repeat()\r\n        ds_list.append(ds_label)\r\n    return ds_list\r\n\r\ndef get_support_ds(ds, bs=640):\r\n    listed_ds = support_sampler(ds)\r\n    balanced_ds = tf.data.experimental.sample_from_datasets(listed_ds, [0.1] * 10)\r\n\r\n    loaders = tuple()\r\n    for _ in range(2):\r\n        loaders += (balanced_ds, )\r\n\r\n    final_ds = tf.data.Dataset.zip(loaders)\r\n    return final_ds.batch(bs)\r\n```\r\n\r\n**Issue verification**\r\n\r\nGet a sample batch first:\r\n\r\n```python\r\nsample_support_ds = get_support_ds(support_ds)\r\nsupport_images_one, support_images_two = next(iter(sample_support_ds))\r\n```\r\n\r\n**Plot the images from `support_images_one`**\r\n\r\n```python\r\nplt.figure(figsize=(7, 7))\r\nfor i, image in enumerate(support_images_one[0][:9]):\r\n    ax = plt.subplot(3, 3, i + 1)\r\n    plt.imshow(image.numpy().astype(\"int\"))\r\n    plt.title(int(support_images_one[1][i]))\r\n    plt.axis(\"off\")\r\n```\r\n\r\nGives:\r\n\r\n![image](https://user-images.githubusercontent.com/22957388/117529164-a54af980-aff3-11eb-9c8e-8e1312c2c38c.png)\r\n\r\nThe same thing with `support_images_two[0][:9]` (with the labels printed accordingly):\r\n\r\n![image](https://user-images.githubusercontent.com/22957388/117529176-be53aa80-aff3-11eb-8c6f-2792b60b3bdb.png)\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe image batches should be the same.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing): No\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/7e003afbd3714549d6ecb0f39b6b81b4/scratchpad.ipynb)\r\n", "comments": ["Found out a solution. \r\n\r\nIf we simply set the seed while doing the sampling step with `tf.data.experimental.sample_from_datasets()` this can be solved. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49007\">No</a>\n"]}, {"number": 49006, "title": "[CherryPick:2.5]Fix `tf.raw_ops.QuantizeAndDequantizeV4Grad` CHECK failure.", "body": "PiperOrigin-RevId: 370532425\nChange-Id: I767721be266851b63d8fe55e7ac6be0af6017f6c", "comments": []}, {"number": 49005, "title": "[CherryPick:2.5]Enhance validation of ngram op and handle case of 0 tokens.", "body": "PiperOrigin-RevId: 369940178\nChange-Id: Ia82f42c09d14efe76e7dc013505b832a42282f0b", "comments": []}]