[{"number": 54071, "title": "Merge pull request #52707 from elfringham:init_ops_test_fix", "body": "PiperOrigin-RevId: 416941851\r\nChange-Id: Iefa5a9b841b053b36f6b105cd82c9d32d5e47850", "comments": []}, {"number": 54070, "title": "Merge pull request #52707 from elfringham:init_ops_test_fix", "body": "PiperOrigin-RevId: 416941851\r\nChange-Id: Iefa5a9b841b053b36f6b105cd82c9d32d5e47850", "comments": []}, {"number": 54068, "title": "Build failure due to cuda include being required on non-cuda platform", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuild fails with\r\nERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/service/gpu/BUILD:468:16: Compiling tensorflow/compiler/xla/service/gpu/nccl_all_to_all_thunk.cc failed: (Exit 1): gcc failed: error executing command \r\n  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-4.2.2-linux-arm64/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/local/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/nccl_collective_thunks/nccl_all_to_all_thunk.pic.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/nccl_collective_thunks/nccl_all_to_all_thunk.pic.o' -fPIC '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT=\".so\"' '-DLLVM_PLUGIN_EXT=\".so\"' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_DEREGISTER_FRAME=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_GETSPECIFIC=1' '-DHAVE_PTHREAD_H=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_SETENV_R=1' '-DHAVE_STRERROR_R=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_LSEEK64=1' '-DHAVE_MALLINFO=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=\"AArch64\"' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeAArch64AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeAArch64AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeAArch64Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeAArch64Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeAArch64TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeAArch64TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeAArch64TargetMCA' '-DLLVM_HOST_TRIPLE=\"aarch64-unknown-linux-gnu\"' '-DLLVM_DEFAULT_TARGET_TRIPLE=\"aarch64-unknown-linux-gnu\"' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote. -iquotebazel-out/aarch64-opt/bin -iquoteexternal/eigen_archive -iquotebazel-out/aarch64-opt/bin/external/eigen_archive -iquoteexternal/com_google_absl -iquotebazel-out/aarch64-opt/bin/external/com_google_absl -iquoteexternal/nsync -iquotebazel-out/aarch64-opt/bin/external/nsync -iquoteexternal/gif -iquotebazel-out/aarch64-opt/bin/external/gif -iquoteexternal/libjpeg_turbo -iquotebazel-out/aarch64-opt/bin/external/libjpeg_turbo -iquoteexternal/com_google_protobuf -iquotebazel-out/aarch64-opt/bin/external/com_google_protobuf -iquoteexternal/com_googlesource_code_re2 -iquotebazel-out/aarch64-opt/bin/external/com_googlesource_code_re2 -iquoteexternal/farmhash_archive -iquotebazel-out/aarch64-opt/bin/external/farmhash_archive -iquoteexternal/fft2d -iquotebazel-out/aarch64-opt/bin/external/fft2d -iquoteexternal/highwayhash -iquotebazel-out/aarch64-opt/bin/external/highwayhash -iquoteexternal/zlib -iquotebazel-out/aarch64-opt/bin/external/zlib -iquoteexternal/double_conversion -iquotebazel-out/aarch64-opt/bin/external/double_conversion -iquoteexternal/local_config_cuda -iquotebazel-out/aarch64-opt/bin/external/local_config_cuda -iquoteexternal/local_config_rocm -iquotebazel-out/aarch64-opt/bin/external/local_config_rocm -iquoteexternal/local_config_tensorrt -iquotebazel-out/aarch64-opt/bin/external/local_config_tensorrt -iquoteexternal/llvm-project -iquotebazel-out/aarch64-opt/bin/external/llvm-project -iquoteexternal/llvm_terminfo -iquotebazel-out/aarch64-opt/bin/external/llvm_terminfo -iquoteexternal/llvm_zlib -iquotebazel-out/aarch64-opt/bin/external/llvm_zlib -Ibazel-out/aarch64-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/aarch64-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributeInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypeInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/FunctionInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SubElementInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorEncodingIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ArithmeticBaseIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ArithmeticCanonicalizationIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ArithmeticOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefBaseIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/MemRefOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TilingInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AllocationOpInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BufferizableOpInterfaceIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BufferizationBaseIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/BufferizationOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgInterfacesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/MathBaseIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/MathOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLTypesIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/PDLInterpOpsIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ConversionPassIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/canonicalize_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/chlo_ops_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_base_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/hlo_ops_pattern_gen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/MLIRShapeCanonicalizationIncGen -Ibazel-out/aarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ShapeOpsIncGen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_structs_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_gpu_ops_enums_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_gpu_ops_inc_gen -Ibazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_gpu_ops_structs_inc_gen -isystem external/eigen_archive -isystem bazel-out/aarch64-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/aarch64-opt/bin/external/nsync/public -isystem external/gif -isystem bazel-out/aarch64-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/aarch64-opt/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/aarch64-opt/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/aarch64-opt/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/aarch64-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/aarch64-opt/bin/external/local_config_cuda/cuda/cuda/include -isystem external/local_config_rocm/rocm -isystem bazel-out/aarch64-opt/bin/external/local_config_rocm/rocm -isystem external/local_config_rocm/rocm/rocm/include -isystem bazel-out/aarch64-opt/bin/external/local_config_rocm/rocm/rocm/include -isystem external/local_config_rocm/rocm/rocm/include/rocrand -isystem bazel-out/aarch64-opt/bin/external/local_config_rocm/rocm/rocm/include/rocrand -isystem external/local_config_rocm/rocm/rocm/include/roctracer -isystem bazel-out/aarch64-opt/bin/external/local_config_rocm/rocm/rocm/include/roctracer -isystem external/llvm-project/llvm/include -isystem bazel-out/aarch64-opt/bin/external/llvm-project/llvm/include -isystem external/llvm-project/mlir/include -isystem bazel-out/aarch64-opt/bin/external/llvm-project/mlir/include -isystem tensorflow/compiler/mlir/hlo/include -isystem bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/hlo/include -isystem tensorflow/compiler/mlir/xla/include -isystem bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/xla/include -w -DAUTOLOAD_DYNAMIC_KERNELS '-ffp-contract=off' '-std=c++14' '-ffp-contract=off' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' -pthread '-DTENSORFLOW_USE_XLA=1' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/compiler/xla/service/gpu/nccl_all_to_all_thunk.cc -o bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/nccl_collective_thunks/nccl_all_to_all_thunk.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from ./tensorflow/stream_executor/gpu/gpu_driver.h:24,\r\n                 from ./tensorflow/stream_executor/gpu/gpu_stream.h:23,\r\n                 from tensorflow/compiler/xla/service/gpu/nccl_all_to_all_thunk.cc:33:\r\n./tensorflow/stream_executor/gpu/gpu_types.h:31:10: fatal error: third_party/gpus/cuda/include/cuComplex.h: No such file or directory\r\n   31 | #include \"third_party/gpus/cuda/include/cuComplex.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nINFO: Elapsed time: 3857.297s, Critical Path: 465.15s\r\nINFO: 30786 processes: 8824 internal, 21962 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl \\\r\n>                --copt=-ffp-contract=off --cxxopt=-ffp-contract=off \\\r\n>                --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 \\\r\n>                --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 \\\r\n>                -- ${DEFAULT_BAZEL_TARGETS} \\\r\n>                -//tensorflow/lite/... -//tensorflow/python/tools/... -//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/eager:function_test\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nSeems to be due to https://github.com/tensorflow/tensorflow/commit/ba1eab4dba24bd9a994941f0ba973fdecfcd187d\r\n", "comments": ["@cfRod @nSircombe ", "```\r\nIn file included from ./tensorflow/stream_executor/gpu/gpu_driver.h:24,\r\nfrom ./tensorflow/stream_executor/gpu/gpu_stream.h:23,\r\nfrom tensorflow/compiler/xla/service/gpu/nccl_all_to_all_thunk.cc:33:\r\n./tensorflow/stream_executor/gpu/gpu_types.h:31:10: fatal error: third_party/gpus/cuda/include/cuComplex.h: No such file or directory\r\n31 | #include \"third_party/gpus/cuda/include/cuComplex.h\"\r\n```\r\n\r\nI would retitle it 'CUDA includes used even in non-cuda builds' or sth like that.", "heh. mentioned commit just dropped cuda switch.\r\n\r\nmeh.", "Could someone enable CI and review for **all** developers?\r\n\r\nTurnes out that whenever there is build failure it is a result of yet another google employee merging change without checking does it pass CI at all.", "> Could someone enable CI and review for **all** developers?\r\n> \r\n> Turnes out that whenever there is build failure it is a result of yet another google employee merging change without checking does it pass CI at all.\r\n\r\nAdding @penpornk for some input.", "> > Could someone enable CI and review for **all** developers?\r\n> > Turnes out that whenever there is build failure it is a result of yet another google employee merging change without checking does it pass CI at all.\r\n> \r\n> Adding @penpornk for some input.\r\n\r\nTagging @yarri-oss and @mihaimaruseac for thoughts.", "Hi @jvishnuvardhan ! Could you please look at this issue?", "This seems to have been resolved, possibly by https://github.com/tensorflow/tensorflow/commit/1f5203498e6afdc88577ffb4bd1dfefe54fb855b#diff-10e7b23ad8d7400d5a23bc499fa11b06bbac4271975b009930a68a3c124fa1f7 but not completely sure about that.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54068\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54068\">No</a>\n"]}, {"number": 54067, "title": "Cannot reproducibly save a model to disk", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, below\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE Leap 15.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): from pip\r\n- TensorFlow version (use command below): 2.8.0-rc1\r\n- Python version: 3.9.10\r\n\r\n**Describe the current behavior**\r\n\r\nWhen training and saving the same model twice, I get different outputs stored to disk, even without any training: when saving the exact same model twice in the same Python process (same \"run\"), `saved_model.pb` files differ while all other files are identical. Interestingly, when saving the model in two separate runes, `saved_model.pb` files are identical.\r\n\r\n**Describe the expected behavior**\r\n\r\nSave the exact same files four times (two in each of two runs).\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\n\"\"\"Demonstrate bug.\"\"\"\r\nimport filecmp\r\nimport sys\r\n\r\nimport tensorflow as tf\r\n\r\nRUN = 1 if len(sys.argv) > 1 else 0\r\n\r\ntf.keras.utils.set_random_seed(0)\r\ntf.config.experimental.enable_op_determinism()\r\nmodel = tf.keras.applications.vgg16.VGG16(weights=None, classes=1)\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\")\r\nmodel.save(f\"tmp_save0_run{RUN}.tf\")\r\nmodel.save(f\"tmp_save1_run{RUN}.tf\")\r\n\r\nif not filecmp.cmp(\r\n    f\"tmp_save0_run{RUN}.tf/saved_model.pb\",\r\n    f\"tmp_save1_run{RUN}.tf/saved_model.pb\",\r\n):\r\n    print(\"Files are different in the same run!\")\r\n\r\nif (RUN == 1) and filecmp.cmp(\r\n    \"tmp_save0_run0.tf/saved_model.pb\",\r\n    \"tmp_save0_run1.tf/saved_model.pb\",\r\n):\r\n    print(\"Files are identical across runs!\")\r\n```\r\n\r\nTo compare between runs, run twice like this:\r\n```shell\r\npython bug.py && python bug.py X\r\n```\r\n\r\nThen compare:\r\n\r\n```shell\r\n# compare between two saves within the same run:\r\ndiff -r tmp_save0_run0.tf tmp_save1_run0.tf\r\n# compare between two saves of different runs:\r\ndiff -r tmp_save0_run0.tf tmp_save0_run1.tf\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nFiles are different in the same run!\r\nFiles are different in the same run!\r\nFiles are identical across runs!\r\nBinary files tmp_save0_run0.tf/saved_model.pb and tmp_save1_run0.tf/saved_model.pb differ\r\n```", "comments": ["Here's another variant of the problem. This time, `saved_model.pb` files also vary across runs (which they shouldn't), implying that the initial model creation in run 0 has an impact on the following loading and saving the model (which it shouldn't):\r\n\r\n```python\r\n\"\"\"Demonstrate bug.\"\"\"\r\nimport filecmp\r\nimport sys\r\n\r\nimport tensorflow as tf\r\n\r\nRUN = 1 if len(sys.argv) > 1 else 0\r\n\r\nif RUN == 0:\r\n    model = tf.keras.applications.vgg16.VGG16(weights=None, classes=1)\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"categorical_crossentropy\")\r\n    model.save(\"pre.tf\")\r\n\r\ntf.keras.backend.clear_session()\r\ntf.keras.utils.set_random_seed(0)\r\ntf.config.experimental.enable_op_determinism()\r\nmodel = tf.keras.models.load_model(\"pre.tf\")\r\nmodel.save(f\"tmp_save0_run{RUN}.tf\")\r\nmodel.save(f\"tmp_save1_run{RUN}.tf\")\r\n\r\nif not filecmp.cmp(\r\n    f\"tmp_save0_run{RUN}.tf/saved_model.pb\",\r\n    f\"tmp_save1_run{RUN}.tf/saved_model.pb\",\r\n):\r\n    print(\"Files are different in the same run!\")\r\n\r\nif (RUN == 1) and not filecmp.cmp(\r\n    \"tmp_save0_run0.tf/saved_model.pb\",\r\n    \"tmp_save0_run1.tf/saved_model.pb\",\r\n):\r\n    print(\"Files are different across runs!\")\r\n```\r\n\r\nAgain:\r\n```shell\r\npython bug2.py && python bug2.py X\r\ndiff -r tmp_save0_run0.tf tmp_save1_run0.tf\r\ndiff -r tmp_save0_run0.tf tmp_save0_run1.tf\r\n```\r\nOutput:\r\n```\r\nFiles are different in the same run!\r\nFiles are different in the same run!\r\nFiles are different across runs!\r\nBinary files tmp_save0_run0.tf/saved_model.pb and tmp_save1_run0.tf/saved_model.pb differ\r\nBinary files tmp_save0_run0.tf/saved_model.pb and tmp_save0_run1.tf/saved_model.pb differ\r\n```", "Looking at the `.pb` files in a text editor, the main differences that I notice are counters appended to functions:\r\n\r\n![image](https://user-images.githubusercontent.com/12128514/150976587-c7ee33c6-a804-49d5-bafb-d6060c521428.png)\r\n\r\n![image](https://user-images.githubusercontent.com/12128514/150976624-3d1bc5d0-fee1-465b-91d8-2f9c97f561e2.png)\r\n\r\n![image](https://user-images.githubusercontent.com/12128514/150976651-ebe9b392-88a5-4032-9756-07227244913a.png)\r\n\r\nI am surprised that this happens as a result of repeated `model.save`, and even more I wonder how I can reset these. `tf.keras.backend.clear_session()` does not seem to do it.", "@bersbersbers \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "Thanks, done.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54067\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54067\">No</a>\n"]}, {"number": 54066, "title": "Building Tensorflow lite from source: cannot fix unresolved external symbols in Visual Studio project", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Tensorflow lite (source)\r\n- TensorFlow version: 2.7.0\r\n- GCC/Compiler version (if compiling from source): MSVC 19.26.28806.0\r\n\r\n**Describe the problem**\r\n\r\nBuilding Tensorflow lite from source appears to work, in so far as I get the static libraries. However, when I create a Visual Studio project I get several linker errors (unresolved externals - see end of issue for error messages) and whatever libs I try to link, I cannot seem to get anything to build. I have followed the instructions for building the minimal example CMake project and **this appears to work**. However, we need to be able to link tensorflow lite in our application code which isn't managed with CMake, so using CMake isn't an option for us.\r\n\r\nIn a nutshell: the build process appears to work, but I can't seem to get a Visual Studio project set up. More details below.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Used this link as a guide: https://www.tensorflow.org/lite/guide/build_cmake\r\n2. Cloned the tensorflow repo\r\n3. Created a directory called \"mybuild\" at the top level of the repo\r\n4. Opened a command prompt in mybuild and ran: `cmake ../tensorflow_src/tensorflow/lite`\r\n5. Then ran: `cmake --build . -j`\r\n6. Created a visual studio project console application (see hello world program below)\r\n7. Set up the include directory to point to the tensorflow repo\r\n8. Added tensorflow-lite.lib to the linker input options\r\n9. Added the path to the lib in the additional linker directories\r\n10. Built in x64, and tried both Debug and Release* - both resulted in the same linker error.\r\n11. As a desperate measure, included all the libs in the _deps/ folder in the linker input options - still the same linker error\r\n\r\n*I wasn't totally clear whether the lib I'd built was for Debug or Release. The instructions say \"It generates an optimized release binary by default\", but then the built lib ends up in mybuild/Debug which was confusing. Is this a minor bug in the build or are the instructions wrong in saying this?\r\n\r\nHope this is clear enough and I've posted in the right place. Any more info I can provide let me know, thanks.\r\n\r\n**Sample code**\r\n```\r\n#include <iostream>\r\n#include <tensorflow/lite/c/c_api.h>\r\n\r\nint main()\r\n{\r\n\tstd::cout << \"Hello from TensorFlow C library version \" << TfLiteVersion() << std::endl;\r\n\treturn 0;\r\n}\r\n```\r\n\r\n**Build from sample project**\r\n```\r\n1>------ Build started: Project: ConsoleApplication2, Configuration: Release x64 ------\r\n1>ConsoleApplication2.cpp\r\n1>ConsoleApplication2.obj : error LNK2001: unresolved external symbol __imp_TfLiteVersion\r\n1>C:\\Users\\4Sight\\source\\repos\\ConsoleApplication2\\x64\\Release\\ConsoleApplication2.exe : fatal error LNK1120: 1 unresolved externals\r\n1>Done building project \"ConsoleApplication2.vcxproj\" -- FAILED.\r\n========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\r\n```\r\n", "comments": ["It could be due to the wrong choice of application type, make sure at the start of the application you choose Console Application instead of windows application for Visual Studio.\r\nStart the process again with option something like. File -> New -> Project -> Win32 Console Application. ", "Having checked the project properties I can confirm it is a console application. If I comment out the Tflite line/header and put in a standard cout statement the console app builds and runs fine.", "Mystery solved - we were trying to use the C API as opposed to the C++ binding. I was able to build and link the example code provided here without any significant problems: https://stackoverflow.com/a/56868813/1618009", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54066\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54066\">No</a>\n"]}, {"number": 54065, "title": "Compute gradients across two layers using gradients calculated from a previous layer using tf.gradients or tf.GradientTape", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n## I want to use the gradients of one layer to calculate the gradients of the layer that comes before it. \r\n\r\nMy motivation for doing this is, when I tried to use model parallelism using tf.device, I found out that backpropagation has been running on CPU. The entire Backprop started running on a chosen tf.device only after I wrapped the call to GradientTape(when it computes the gradient) within the tf.device context manager. Since the model is split, I want the backprop of each partition\u00a0to execute on the device where that partition is placed.\r\n\r\nIdeally, I would like to find out a method with which this oversimplified pseudocode is possible.\r\n```\r\nwith tf.device(device_3):\r\n   grad_3 = tf.gradients(loss, trainable_vars_of_partition_3)\r\n \r\nwith tf.device(device_2):\r\n   grad_2 = tf.gradients(grad_3, trainable_vars_of_partition_2)\r\n\r\nwith tf.device(device_1):\r\n   grad_1 = tf.gradients(grad_2, trainable_vars_of_partition_1)\r\n\r\ngrads = concat(grad_1, grad_2, grad_3)\r\n```\r\nIf something like this exists then I would be overjoyed if you could point me in the right direction. \r\n\r\nUnfortunately, I could not find something as simple as this. The next best approach that I could think of was using the gradients of one layer to find the gradients of a layer that comes before it. Using chain rule and backpropagation, I feel that this should be possible.\r\n\r\nI created this toy example, solving which is the first step towards the final goal.\r\n\r\n\r\nLet's say we have a model with 3 dense layers without activations functions. X, Y as defined as follows:\r\n\r\n```\r\nx = tf.concat([tf.random.uniform([1, 10], minval=0, maxval=0.25),\r\n               tf.random.uniform([1, 10], minval=0.25, maxval=0.5),\r\n               tf.random.uniform([1, 10], minval=0.5, maxval=0.75),\r\n               tf.random.uniform([1, 10], minval=0.75, maxval=1.),\r\n                ], axis = 0)\r\n\r\ny = tf.constant(0., shape=[4, 1])\r\n\r\nd1 = tf.keras.layers.Dense(5, name='d1') \r\nd2 = tf.keras.layers.Dense(2, name='d2') \r\nd3 = tf.keras.layers.Dense(1, name='d3') \r\n\r\n```\r\nI am using a tf.function in this toy example but an answer with eager mode enabled, using GradientTape will also be appreciated. \r\n\r\n```\r\n@tf.function\r\ndef tf_func(x, y, d1, d2, d3):\r\n    # Using shortforms of these function helped the code look neater and more readable to me. \r\n    g = tf.gradients\r\n    rs = tf.reduce_sum\r\n    rm = tf.reduce_mean\r\n\r\n    o1 = d1(x)\r\n    o2 = d2(o1)\r\n    o3 = d3(o2)\r\n\r\n    l = tf.reduce_mean(tf.square(o3 - y))\r\n    \r\n    w3, w2, w1 = d3.trainable_variables, d2.trainable_variables, d1.trainable_variables\r\n\r\n    tf.print('actual grads' + '=' * 80)\r\n\r\n    dl_dw3 = g(l, w3)\r\n    \r\n    dl_dw2 = g(l, w2)\r\n    tf.print('dl_dw2: \\n', dl_dw2)\r\n\r\n    dl_dw1 = g(l, w1)   \r\n\r\n    tf.print()\r\n    tf.print()\r\n    \r\n    tf.print('reference grads' + '=' * 80)\r\n    dl_do1 = g(l, o1)\r\n    dl_do2 = g(l, o2)\r\n    tf.print('dl_do2: \\n', dl_do2)\r\n    dl_do3 = g(l, o3)\r\n\r\n    dl_dw1 = g(l, w1)\r\n    dl_dw2 = g(l, w2)\r\n    dl_dw3 = g(l, w3)\r\n\r\n    do3_o2 = g(o3, o2)\r\n    do2_do1 = g(o2, o1)\r\n\r\n    do3_w3 = g(o3, w3)\r\n    do2_w2 = g(o2, w2)\r\n    do1_w1 = g(o1, w1)\r\n\r\n\r\n    tf.print('testing chain_rule method' + '=' * 80)\r\n    \r\n    # Added a 't' before derivatives to differentiate between ref_grads and grads obtained using chain rule\r\n\r\n    tdl_do3 = g(l, o3) # same as ref_grads\r\n\r\n    tdo3_dw3 = g(o3, w3) # same as ref_grads\r\n    tdl_dw3 = [rm(tdl_do3) * tdo3_dw3[0], rm(tdl_do3) * tdo3_dw3[1]] # same as actual grads\r\n\r\n    tdo3_do2 = g(o3, o2) # same as ref_grads\r\n\r\n    tdl_do2 = tdo3_do2 * rm(tdl_do3, axis=0)  # same as ref_grads\r\n    tf.print('tdl_do2: \\n', tdl_do2)\r\n\r\n    tdo2_dw2 = g(o2, w2) \r\n    tf.print('tdo2_dw2: \\n', tdo2_dw2)\r\n    \r\n    tdl_dw2 = [tdo2_dw2[0] * rm(tdl_do2, axis=[1]), tdo2_dw2[1] * rm(tdl_do2, axis=[1])]\r\n    tf.print('tdl_dw2: \\n', tdl_dw2)\r\n\r\n    return None \r\n\r\n\r\ntf_func(x, y, d1, d2, d3)\r\n```\r\nThe output was:\r\n\r\n```\r\nactual grads================================================================================\r\ndl_dw2: \r\n [[[-3.04819393 -1.30051827]\r\n [5.02123785 2.14232159]\r\n [-0.260933906 -0.111328]\r\n [5.87596226 2.50699162]\r\n [1.9655633 0.838611722]], [-4.69162369 -2.0016911]]\r\n\r\n\r\nreference grads================================================================================\r\ndl_do2: \r\n [[[-0.43842113 -0.187053293]\r\n [-0.889310718 -0.379426271]\r\n [-1.41650343 -0.604354143]\r\n [-1.94738865 -0.830857456]]]\r\n\r\n\r\ntesting chain_rule method================================================================================\r\ntdl_do2: \r\n [[[-0.43842113 -0.187053293]\r\n  [-0.889310718 -0.379426271]\r\n  [-1.41650343 -0.604354143]\r\n  [-1.94738865 -0.830857456]]]\r\ntdo2_dw2: \r\n [[[2.10966444 2.10966444]\r\n [-3.48670244 -3.48670244]\r\n [0.22972326 0.22972326]\r\n [-3.95618558 -3.95618558]\r\n [-1.3790133 -1.3790133]], [4 4]]\r\ntdl_dw2: \r\n [[[-2.47443795 -1.05572414]\r\n [4.08957386 1.74482536]\r\n [-0.26944378 -0.114958748]\r\n [4.64023352 1.97976542]\r\n [1.61745286 0.690089643]], [[-4.69162369 -2.0016911]]]\r\n\r\n```\r\n**For some reason, gradients wrt weights in tdl_dw2 and dl_dw2 differ slightly. Every value in tdl_dw2 is slightly less than dl_dw2 even though the gradients wrt biases are the same. I cannot figure out why.**\r\n\r\nThe gradient of loss wrt to w3 is as expected. \r\n\r\n\r\nI used tf.reduce_mean to replicate what tf.gradients was doing internally as far as I understand. Please correct me if I am wrong.\r\n\r\nFrom Tensorflow's documentations: \r\n\r\n> gradients() adds ops to the graph to output the derivatives of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the sum(dy/dx) for y in ys and for x in xs.\r\n\r\n> tf.gradients constructs symbolic derivatives of sum of ys w.r.t. x in xs.\r\n\r\n\r\nAny guidance or help will be greatly appreciated, thank you.\r\n\r\n\r\nSome Similar StackOverflow questions(there are many more):\r\n\r\n 1. https://stackoverflow.com/q/69545716/13629760\r\n 2. https://stackoverflow.com/questions/66120442/is-it-possible-to-acquire-an-intermediate-gradient-tensorflow\r\n 3. https://stackoverflow.com/questions/50075961/breaking-tensorflow-gradient-calculation-into-two-or-more-parts\r\n\r\nHere is a colab notebook with the code:\r\nhttps://colab.research.google.com/drive/1034hu6Zo766-spKu5qfeG4c2Yv2v-DGM?usp=sharing\r\n", "comments": ["Hi @Joy-Lunkad ! Could you please post this issue on [TF forum ](https://discuss.tensorflow.org/)for further assistance? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54065\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54065\">No</a>\n"]}, {"number": 54064, "title": "Prevent stack overflow when FunctionLib in GraphDef has a self-recurs\u2026", "body": "\u2026ive function.\r\n\r\nIt is likely that no recursivity is supported, but we should handle this separately.\r\n\r\nPiperOrigin-RevId: 414860329\r\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0", "comments": []}, {"number": 54063, "title": "Prevent stack overflow when FunctionLib in GraphDef has a self-recurs\u2026", "body": "\u2026ive function.\r\n\r\nIt is likely that no recursivity is supported, but we should handle this separately.\r\n\r\nPiperOrigin-RevId: 414860329\r\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0", "comments": []}, {"number": 54062, "title": "Prevent stack overflow when FunctionLib in GraphDef has a self-recurs\u2026", "body": "\u2026ive function.\r\n\r\nIt is likely that no recursivity is supported, but we should handle this separately.\r\n\r\nPiperOrigin-RevId: 414860329\r\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0", "comments": []}, {"number": 54061, "title": "Fix `CHECK`-failure caused by constant folding code.", "body": "We're losing a `const` qualifier here, but unless we get to use more `StatusOr` objects, this is the best alternative.\r\n\r\nPiperOrigin-RevId: 410072241\r\nChange-Id: I69535c91490f0d23facb9587d2ff59db0782cda6", "comments": []}, {"number": 54060, "title": "Fix `CHECK`-failure caused by constant folding code.", "body": "We're losing a `const` qualifier here, but unless we get to use more `StatusOr` objects, this is the best alternative.\r\n\r\nPiperOrigin-RevId: 410072241\r\nChange-Id: I69535c91490f0d23facb9587d2ff59db0782cda6", "comments": []}, {"number": 54059, "title": "allocate temp tensor would be free before the end of the aysnc gpu kernel  execution ", "body": "https://github.com/tensorflow/tensorflow/blob/a9e4e55bcfaa95c40b36ef9c85991e3534532b2c/tensorflow/core/kernels/gpu_device_array.h#L83", "comments": ["@MichoChan Could you please include more details on the issue?\r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54058, "title": "Fix `CHECK`-failure caused by constant folding code.", "body": "We're losing a `const` qualifier here, but unless we get to use more `StatusOr` objects, this is the best alternative.\r\n\r\nPiperOrigin-RevId: 410072241\r\nChange-Id: I69535c91490f0d23facb9587d2ff59db0782cda6", "comments": []}, {"number": 54057, "title": "Prevent null pointer dereference in constant folding.", "body": "Under certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\r\n\r\nPiperOrigin-RevId: 409683530\r\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "comments": []}, {"number": 54056, "title": "Prevent null pointer dereference in constant folding.", "body": "Under certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\r\n\r\nPiperOrigin-RevId: 409683530\r\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "comments": []}, {"number": 54055, "title": "Prevent null pointer dereference in constant folding.", "body": "Under certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\r\n\r\nPiperOrigin-RevId: 409683530\r\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "comments": []}, {"number": 54054, "title": "Prevent null pointer dereference in `mutable_graph_view`", "body": "PiperOrigin-RevId: 409684472\r\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "comments": []}, {"number": 54053, "title": "Prevent null pointer dereference in `mutable_graph_view`", "body": "PiperOrigin-RevId: 409684472\r\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "comments": []}, {"number": 54052, "title": "Prevent null pointer dereference in `mutable_graph_view`", "body": "PiperOrigin-RevId: 409684472\r\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "comments": []}, {"number": 54051, "title": "Prevent overflow in grappler cost estimation of crop&resize op.", "body": "The crop parameters are user controlled, so we should make sure a user can not trigger an overflow maliciously.\r\n\r\nPiperOrigin-RevId: 409670234\r\nChange-Id: I7994734a98b037c5642e051240329d16f959aae4", "comments": []}, {"number": 54050, "title": "Prevent overflow in grappler cost estimation of crop&resize op.", "body": "The crop parameters are user controlled, so we should make sure a user can not trigger an overflow maliciously.\r\n\r\nPiperOrigin-RevId: 409670234\r\nChange-Id: I7994734a98b037c5642e051240329d16f959aae4", "comments": []}, {"number": 54049, "title": "Prevent overflow in grappler cost estimation of crop&resize op.", "body": "The crop parameters are user controlled, so we should make sure a user can not trigger an overflow maliciously.\r\n\r\nPiperOrigin-RevId: 409670234\r\nChange-Id: I7994734a98b037c5642e051240329d16f959aae4", "comments": []}, {"number": 54048, "title": "Prevent overflow in `CalculateTensorElementCount`", "body": "Grappler cost estimation sometimes computes the number of elements in a tensor by multiplying all the dimensions in a shape. However, these tensors can also be controlled by users so a malicious attacker can trigger overflow that can be exploited.\r\n\r\nPiperOrigin-RevId: 409575048\r\nChange-Id: I7a958875ba6f3ad9cb5b9943fe5d459efcbe4557", "comments": []}, {"number": 54047, "title": "Prevent overflow in `CalculateTensorElementCount`", "body": "Grappler cost estimation sometimes computes the number of elements in a tensor by multiplying all the dimensions in a shape. However, these tensors can also be controlled by users so a malicious attacker can trigger overflow that can be exploited.\r\n\r\nPiperOrigin-RevId: 409575048\r\nChange-Id: I7a958875ba6f3ad9cb5b9943fe5d459efcbe4557", "comments": []}, {"number": 54046, "title": "Prevent overflow in `CalculateTensorElementCount`", "body": "Grappler cost estimation sometimes computes the number of elements in a tensor by multiplying all the dimensions in a shape. However, these tensors can also be controlled by users so a malicious attacker can trigger overflow that can be exploited.\r\n\r\nPiperOrigin-RevId: 409575048\r\nChange-Id: I7a958875ba6f3ad9cb5b9943fe5d459efcbe4557", "comments": []}, {"number": 54045, "title": "Prevent `CHECK`-fail when building reference tensor.", "body": "The tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\r\n\r\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\r\n\r\nPiperOrigin-RevId: 409662503\r\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59", "comments": []}, {"number": 54044, "title": "Prevent `CHECK`-fail when building reference tensor.", "body": "The tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\r\n\r\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\r\n\r\nPiperOrigin-RevId: 409662503\r\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59", "comments": []}, {"number": 54043, "title": "Eliminate `CHECK`-fail from `function.cc`.", "body": "PiperOrigin-RevId: 409414744\r\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad", "comments": []}, {"number": 54042, "title": "Eliminate `CHECK`-fail from `function.cc`.", "body": "PiperOrigin-RevId: 409414744\r\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad", "comments": []}, {"number": 54041, "title": "Eliminate `CHECK`-fail from `function.cc`.", "body": "PiperOrigin-RevId: 409414744\r\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad", "comments": []}]