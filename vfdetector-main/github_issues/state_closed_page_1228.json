[{"number": 16323, "title": "Does Broadcast in TF copy first or just do ops along the axis", "body": "For example, we have\r\ntensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)\r\nwhen running\r\nc = tf.multiply(a, b)\r\n\r\nIs b first copied 100 * 100 times for the **big** dot multiply with a (GPU memory consuming),\r\nor the dot multiply is done with the original b along axis 0 and 1?\r\n\r\nThe tf.multiply page refers to **numpy multiply** that says it won't copy, just loop.\r\nhttps://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\r\n\r\nI guess it's copied first that I run into GPU memory problem by adjusting a bit the b.\r\nHow's it implemented in TF? Couldn't find the source gen_math_ops\r\n\r\nIssue template update:\r\nHave I written custom code No\r\nOS Platform and Distribution: Windows 10 x64 Home version\r\nTensorFlow installed from pip (anaconda with python 3.6.3)\r\nTensorFlow version: 1.4.1\r\nBazel version: N/A\r\nCUDA/cuDNN version: CUDA 8.0, cuDNN 6\r\nGPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)\r\nExact command to reproduce N/A (not relevant to the question)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@tensorflowbutler I find out when doing the same work, the depthwise_conv2d is much more memory friendly than the matrix element-wise multiplication. I'm running with the depthwise_conv2d and free from the \"out of memory\" error now.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 16322, "title": "py_func convert unicode string results to bytes for python2", "body": "Fix #16320", "comments": ["@facaiy thanks for the contribution!\r\n@jhseu thanks for fixing the lint error!"]}, {"number": 16321, "title": "tpu contrib fix", "body": "fix the issue in https://github.com/tensorflow/tensorflow/issues/16262", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 16320, "title": "BUG: py_func don't support unicode string results for python2", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac 10.11\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nWhen I investigated #14116, I found that `py_func` converts unicode strings result to bytes only for  Python3, while raise an exception for Python 2.\r\n\r\nI'm curious why we don't the same thing for Python 2.\r\n\r\n### Source code / logs\r\n\r\nscript:\r\n\r\n```python\r\n  def testReturnUnicodeString(self):\r\n    with self.test_session():\r\n      correct = u\"\u4f60\u597d \u4e16\u754c\"\r\n\r\n      def unicode_string():\r\n        return correct\r\n\r\n      z, = script_ops.py_func(unicode_string, [], [dtypes.string])\r\n      self.assertEqual(z.eval(), correct.encode(\"utf8\"))\r\n```\r\n\r\nlogs:\r\n\r\n```python\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\n2018-01-23 09:43:04.611108: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n..2018-01-23 09:43:06.545687: W tensorflow/core/framework/op_kernel.cc:1181] Unimplemented: Unsupported numpy type 20\r\n.2018-01-23 09:43:06.548797: W tensorflow/core/framework/op_kernel.cc:1181] Unimplemented: Unsupported object type dict\r\n.....2018-01-23 09:43:08.129501: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.ValueError: blah\r\n2018-01-23 09:43:08.131595: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.TypeError: blah\r\n2018-01-23 09:43:08.134736: W tensorflow/core/framework/op_kernel.cc:1181] Resource exhausted: exceptions.MemoryError: blah\r\n2018-01-23 09:43:08.136335: W tensorflow/core/framework/op_kernel.cc:1181] Unimplemented: exceptions.NotImplementedError: blah\r\n2018-01-23 09:43:08.138000: W tensorflow/core/framework/op_kernel.cc:1181] Unknown: WeirdError: blah\r\n2018-01-23 09:43:08.138882: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.ValueError: blah\r\n2018-01-23 09:43:08.139022: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.TypeError: blah\r\n2018-01-23 09:43:08.139236: W tensorflow/core/framework/op_kernel.cc:1181] Resource exhausted: exceptions.MemoryError: blah\r\n2018-01-23 09:43:08.139349: W tensorflow/core/framework/op_kernel.cc:1181] Unimplemented: exceptions.NotImplementedError: blah\r\n2018-01-23 09:43:08.139492: W tensorflow/core/framework/op_kernel.cc:1181] Unknown: WeirdError: blah\r\n.....2018-01-23 09:43:10.036466: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.ValueError: blah\r\n2018-01-23 09:43:10.038219: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.TypeError: blah\r\n2018-01-23 09:43:10.041279: W tensorflow/core/framework/op_kernel.cc:1181] Resource exhausted: exceptions.MemoryError: blah\r\n2018-01-23 09:43:10.044136: W tensorflow/core/framework/op_kernel.cc:1181] Unimplemented: exceptions.NotImplementedError: blah\r\n2018-01-23 09:43:10.046983: W tensorflow/core/framework/op_kernel.cc:1181] Unknown: WeirdError: blah\r\n............2018-01-23 09:43:11.081837: W tensorflow/core/framework/op_kernel.cc:1181] Invalid argument: exceptions.UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\r\nE..........\r\n======================================================================\r\nERROR: testReturnUnicodeString (__main__.PyFuncTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/py_func_test.py\", line 227, in testReturnUnicodeString\r\n    self.assertEqual(z.eval(), correct.encode(\"utf8\"))\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 639, in eval\r\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 4795, in _eval_using_default_session\r\n    return session.run(tensors, feed_dict)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nInvalidArgumentError: exceptions.UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\r\n\t [[Node: PyFunc = PyFunc[Tin=[], Tout=[DT_STRING], token=\"pyfunc_2049\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'PyFunc', defined at:\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/py_func_test.py\", line 476, in <module>\r\n    test.main()\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 74, in main\r\n    return _googletest.main(argv)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 99, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 336, in benchmarks_main\r\n    true_main()\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 98, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 69, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/main.py\", line 232, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/runner.py\", line 151, in run\r\n    test(result)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/suite.py\", line 70, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/suite.py\", line 108, in run\r\n    test(result)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/suite.py\", line 70, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/suite.py\", line 108, in run\r\n    test(result)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/case.py\", line 393, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/home/facai/workshop/anaconda2/lib/python2.7/unittest/case.py\", line 329, in run\r\n    testMethod()\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/py_func_test.py\", line 226, in testReturnUnicodeString\r\n    z, = script_ops.py_func(unicode_string, [], [dtypes.string])\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/ops/script_ops.py\", line 300, in py_func\r\n    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/ops/script_ops.py\", line 209, in _internal_py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/ops/gen_script_ops.py\", line 93, in _py_func\r\n    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 3172, in create_op\r\n    op_def=op_def)\r\n  File \"/data1/users/facai/.cache/bazel/_bazel_facai/3338df3cdc4fd0e5fdd3f3ae6490e0be/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/py_func_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1617, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): exceptions.UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\r\n\t [[Node: PyFunc = PyFunc[Tin=[], Tout=[DT_STRING], token=\"pyfunc_2049\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\n\r\n----------------------------------------------------------------------\r\nRan 36 tests in 6.497s\r\n\r\nFAILED (errors=1)\r\n```\r\n", "comments": ["Moreover, `py_func` runs well for English (even though unicode string), while Chinese failed. I don't know whether the inconsistent result is intentional. #16322 is proposed to fix the issue.", "Thank you for noticing this issue. As you already submitted PR that fixes it I am closing the issue.", "Thank you for noticing this issue. As you already submitted PR that fixes it I am closing the issue."]}, {"number": 16319, "title": "Add alternative paths for CUDA installation.", "body": "This detects negativo17's CUDA packages for Fedora.\r\n\r\nI tried following the feedback in #15614, so I added alternative paths and avoided adding questions to the `./configure` script.", "comments": ["So far, this PR is one step short of fully working. I haven't figured out how to set the `NVVMIR_LIBRARY_DIR` environment variable to the directory returned by `_find_nvvm_libdevice_dir`. After setting that environment variable manually in `.bazelrc`, I ended up with a fully working CUDA build on Fedora 27 with negativo17's drivers.\r\n\r\nEven if there's no easy way to set the environment variable, I figure there's value in getting the rest of the work reviewed and merged, so others have less customizing to do. I look forward to your feedback!", "negativo17 rpm package cuda already sets NVVMIR_LIBRARY_DIR so configure.py could read that and if it exists, call write_to_bazelrc(), or give user a choice by calling set_build_var(environ_cp, 'NVVMIR_LIBRARY_DIR',..). The same with cuda_configure.bzl.\r\n\r\nAnyway, I can confirm the patch builds without problem on Fedora 27.", "I was able to get past the initial path issues on Fedora 27 with Negativo drivers by \r\n```\r\nexport NVVMIR_LIBRARY_DIR=\\usr\\share\\cuda\r\nbazel build --config=opt --config=cuda --action_env=\"NVVMIR_LIBRARY_DIR=${NVVMIR_LIBRARY_DIR}\" //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nHowever the build still fails later on, when compiling with gcc 6.4 which is also provided by the aforementioned repository:\r\n[tens-build.txt](https://github.com/tensorflow/tensorflow/files/1713722/tens-build.txt) \r\nEDIT: The above error was solves with  #16165 and TF now builds successfully.", "Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Sorry, the past few weeks have been rough. I'll try to find some time to address the comments this week.", "@gunan Thank you very much for your feedback! I hope I've addressed it. PTAL?\r\n\r\nIn case it makes your life easier, I've also created CL 187808905 with the changes here.", "@pwnall has sent this PR internally, closing the external one.\r\nThanks for the contribution!", "@gunan Thank you very much for the quick responses!\r\n\r\nEveryone else interested in this: The internal patch has been committed, and should show up soon."]}, {"number": 16318, "title": "import tensorflow as tf", "body": "These five files do not explicitly `import tensorflow as tf` yet they use they use __tf.__ methods or functions which drives linters like pylint and flake8 crazy unless special directives are put in place.", "comments": ["@cclauss please resolve the conflicts.", "Resolve done but I do not see that it changed anything.  Was it supposed to?", "Based on @mdanatg comment, lets revert py2tf changes.\r\nPlease also see my comment and make the change accordingly.", "I have made the changes suggested above.\r\n\r\nThe method that I use for finding these issues:\r\n```\r\n$ git checkout master\r\n$ git pull --rebase upstream master\r\n$ git push origin master\r\n$ python2 -m flake8 . --count --select=--select=E901,E999,F821,F822,F823 --show-source --statistics\r\n$ python3 -m flake8 . --count --select=--select=E901,E999,F821,F822,F823 --show-source --statistics\r\n```"]}, {"number": 16317, "title": "tensorflow crash on android mobile with libtensorflowlite_jni.so of arm-v7a ", "body": "\r\n### System information\r\n- **OS Platform and Distribution ( android 5.1 )**:\r\n- **TensorFlow installed from (source )**:\r\n- **TensorFlow version ( # Release 1.5.0 )**:\r\n- **Python version** 2.7 : \r\n- **Bazel version ( 0.9.0-homebrew )**:\r\n- **GCC/Compiler version\r\n (Apple LLVM version 7.3.0 (clang-703.0.31)\r\nTarget: x86_64-apple-darwin17.3.0 )**:\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nafter using tensorflow source to build the libtensorflowlite_jni.so of arm-v7a , it crash in the android \r\nmobile frequently with the following message ;  somehow came with the libtensorflowlite_jni.so of arm just work fine but too long; someone can help ? \r\n\r\n\r\n01-23 16:17:25.292 414-414/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n01-23 16:17:25.292 414-414/? I/DEBUG: Build fingerprint: 'nubia/NX529J/NX529J:5.1.1/LMY47V/eng.nubia.20160612.203636:user/release-keys'\r\n01-23 16:17:25.292 414-414/? I/DEBUG: Revision: '0'\r\n01-23 16:17:25.292 414-414/? I/DEBUG: ABI: 'arm'\r\n01-23 16:17:25.292 414-414/? I/DEBUG: pid: 8073, tid: 8930, name: AsyncTask #6  >>> com.test.tensorflow <<<\r\n01-23 16:17:25.292 414-414/? I/DEBUG: signal 7 (SIGBUS), code -6 (SI_TKILL), fault addr 0xac66df18\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     r0 ac66df18  r1 00000004  r2 b5ba5050  r3 000003e9\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     r4 b6df239c  r5 00000002  r6 ac66df18  r7 d7744d20\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     r8 00000002  r9 b5ba5040  sl 00000000  fp b5ba5fe4\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     ip b5ba5fec  sp d7744cc8  lr 000003e8  pc c3e5ae9c  cpsr 000f0030\r\n01-23 16:17:25.372 414-414/? I/DEBUG: backtrace:\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #00 pc 00067e9c  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #01 pc 0004870f  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #02 pc 0004894b  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #03 pc 0005d333  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #04 pc 00007205  /data/app/com.test.tensorflow-1/lib/arm/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+1280)\r\n01-23 16:17:25.372 414-414/? I/DEBUG:     #05 pc 00011bf3  /data/dalvik-cache/arm/data@app@com.test.tensorflow-1@base.apk@classes.dex\r\n01-23 16:17:28.882 414-414/? I/DEBUG: Tombstone written to: /data/tombstones/tombstone_07\r\n\r\n\r\n", "comments": ["Just so we understand correctly: you are building for 'arm' on macosx, right? Could you tell use the blaze command line you are using?", "bazel build --cxxopt='--std=c++11' //tensorflow/contrib/lite/java:tensorflowlite \\\r\n--crosstool_top=//external:android/crosstool \\\r\n--host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n--cpu=armeabi-v7a\r\n\r\n@andrehentz i build the so for arm on macosx", "so, is there any way i can fix the problem? i used the so in the demo apk ([https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#building-tensorflow-lite-and-the-demo-app-from-source](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#building-tensorflow-lite-and-the-demo-app-from-source) ) , it crash too", "@angersson can you take a look?", "it seems the problem is about multi model run on mobile; there are two model in the demo.", "What Android SDK and NDK levels are you using?", "sdk of 25 And Ndk of 14", "Can you provide us with complete error messages and a way to replicate this, e.g. in docker?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 99 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 16316, "title": "Lack of clarity in tf.while_loop documentation", "body": "I believe that the documentation for tf.while_loop is lacking usage clarity, and actually provides contradictory statements. \r\n\r\nSpecifically, it seems that many people are using the tf.while_loop as a \"for loop\" ([see stackoverflow](https://stackoverflow.com/questions/35330117/how-can-i-run-a-loop-with-a-tensor-as-its-range-in-tensorflow)). However, the [tf.while_loop](https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/control_flow_operations#while_loop) docs state:\r\n\r\n> For correct programs, while_loop should return the same result for any parallel_iterations > 0.\r\n\r\nA loop counter inside of the \"while loop\" body, seems to violate this constraint despite the fact that this is given as an example usage in the docs:\r\n\r\n> python i = tf.constant(0) c = lambda i: tf.less(i, 10) b = lambda i: tf.add(i, 1) r = tf.while_loop(c, b, [i])\r\n\r\nSo it seems that there are two bad outcomes here:\r\n\r\n1. If this is indeed the canonical way of creating a \"for loop\", then the example explicitly creates a dependency between iterations, meaning that the \"while loop\" iterations cannot be run in parallel. \r\n\r\n1. The example is incorrect? \r\n\r\nIt seems like the while_loop docs should have an example which better illustrates how to use it as a \"for loop\", if such usage is indeed intended, or a warning on the implications of the provided example.  \r\n", "comments": ["Thank you for your report. As far as I can see, the loop that you show above is correct. In Python, parallel execution does not allow more than one thread run at a time. The execution of multiple threads might overlap, however. So, a code with reduction, such as the one shown above works just fine if executed in parallel.\r\n\r\nLet me confirm with an expert, though. @michaelisard could you take a quick look?", "@tatianashp I found [this comment in issue 1984](https://github.com/tensorflow/tensorflow/issues/1984#issuecomment-211199897) that was incredibly helpful in understanding what is going on.  But even that comment is not complete [as I note here](https://github.com/tensorflow/tensorflow/issues/1984#issuecomment-359713984). It would be nice for somebody to have a look at these comments and incorporate them into the documentation. \r\n\r\nFinally, one more thing that is not explained in the docs is why [this phenomenon occurs (reported in issue 16333)](https://github.com/tensorflow/tensorflow/issues/16333). Specifically, it seems as though the while loop is doing some type of copy semantics instead of referencing the inputs. In my mind, that is not at all the behavior I expect.  ", "The discussion of this issue has migrated to #16333. "]}, {"number": 16315, "title": "Remove Variables from a TF Server (e.g.)", "body": "I have a cluster of long-lived TensorFlow servers  (//tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server).\r\nMy problem is how to reset variables on these server. \r\n\r\nThere is a behavior in distributed TensorFlow in which a variable defined on a worker (e.g. PS) outlives the session which defines it. I understand this behavior is intentional to support between graph model-replica.\r\n\r\nHowever, In my use case this behavior causes unexpected problem. I have not found a mechanism to override this. It there is, I believe it is helpful to better reflect it in the documentation, if there is not, I hope I can make a case to motivate its existence.\r\n\r\nIn my use case different training jobs are ran _sequentially_ (i.e. one training job at a time) on this cluster, each using one client (which connects to only one master). \r\n\r\nThe problem I have is if a variable is defined in two training job with a same name but different shape sizes, the latter client gets the following error on \"Session\" creation:\r\n```\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [100] rhs shape= [200]%0A%09 [[Node: a/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@a\"], use_locking=true, validate_shape=true, _device=\"/job:worker/replica:0/task:0/device:GPU:0\"](a, a/Initializer/random_uniform)]]\r\n```\r\n\r\n`tf.reset_default_graph` does not help. The solution to this problem could be a mechanism similar `tf.reset_default_graph` that resets variables in all the workers.\r\n\r\nTo replicate this problem let say we have two workers: (one PS, and on Worker)\r\n\r\nWorker 1:\r\n```bash\r\n#worker 1\r\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0 &\r\n#worker 2\r\n./bazel-bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server --cluster_spec=\"ps|localhost:2222,worker|localhost:2223\" --job_name=worker --task_id=0\r\n```\r\n(Same result with `tf.train.Server` workers.)\r\n\r\nThen run the simple code:\r\n```python\r\nimport tensorflow as tf\r\nvar = tf.get_variable(\"A\", shape=(100,))\r\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\r\n   pass\r\n```\r\nIt should work just fine.\r\nThen when this code (which is identical except the variable shape) is ran:\r\n```python\r\nimport tensorflow as tf\r\nvar = tf.get_variable(\"A\", shape=(5000,))\r\nwith tf.train.MonitoredTrainingSession(master=\"localhost:2223\") as sess:\r\n   pass\r\n```\r\nThis example fails.\r\n", "comments": ["@mrry Could you take a look at this?", "Calling `tf.Session.reset(\"grpc://localhost:2223\")` will delete all of the variables in all of the workers reachable from the server at `localhost:2223`.", "@mrry   Can you please post an example of how to use tf.Session.reset(\"grpc://localhost:2222\")  so that it deletes the variables in all of the workers and donot give an InvalidArgumentError when the variable shape changes.\r\nI am also facing the same problem."]}, {"number": 16314, "title": "Published libtensorflow_framework.so binaries ABI Problem", "body": "The distributed `libtensorflow_framework.so` included in the JAR files published to Maven are built using the C++ 11 ABI, in contrast to the main TF build. I think that affects all continuous integration builds of the shared objects. I believe the `-D_GLIBCXX_USE_CXX11_ABI=0` compiler flag should be used for the CI builds as is done for the main build. An example of its use is shown in commit 550df413158b32645ca5df4dcaabc67f1a48964d. This causes some trouble when using these shared objects and developing custom ops, as those are required to be built using that compiler flag. It would be great if the use of the flag was consistent and all binaries were built using the same ABI.\r\n\r\nThanks! ", "comments": ["I just made a pull request that fixes this issue for me."]}, {"number": 16313, "title": "Bug of tf.data.TFRecordDataset? Couldn't use tf.reshape after the operations of tf.data.TFRecordDataset", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: Nvidia GeForce GTX TITAN X 12GB\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI want to use  function **tf.profiler.ProfileOptionBuilder.float_operation** to show the flops of the model. But it need a certain input shape while the the output shape of **tf.data.TFrecordDataset** is like (?, 32,32,3). When I want to use tf.reshape to reshape the output of **tf.data.TFrecordDataset**, it generates an error \"Input to reshape is a tensor with 64512 values, but the requested shape has 98304\".  \r\n\r\n### Source code \r\n\r\n  def dataset_input(self, dataset_type):\r\n    with tf.variable_scope(\"batch_\" + dataset_type):\r\n        def parser(record):\r\n            features = tf.parse_single_example(\r\n                record,\r\n                features={\r\n                    'image': tf.FixedLenFeature([], tf.string),\r\n                    'label': tf.FixedLenFeature([], tf.int64)\r\n                })\r\n            image, label = features['image'], features['label']\r\n            height, width, channels = self.input_size, self.input_size, self.input_dim\r\n            image = tf.decode_raw(image, tf.uint8)\r\n            image = tf.reshape(image, [height, width, channels])\r\n            return image, label\r\n        dataset = tf.data.TFRecordDataset([self.dataset_dir[dataset_type]])\r\n        dataset = dataset.map(parser)\r\n        dataset = dataset.shuffle(buffer_size=50000)\r\n        dataset = dataset.batch(self.batch_size)\r\n        dataset = dataset.repeat()\r\n        iterator = dataset.make_one_shot_iterator()\r\n        features, labels = iterator.get_next()\r\n        features = tf.reshape(features, [self.batch_size, self.input_size, self.input_size, self.input_dim])\r\n        return features, labels\r\n  ", "comments": ["Looks like simply your data is smaller than what you are trying to resize to. Are you sure the number of channels (`input_dim`) is correct, and image is not e.g. with an alpha channel too?\r\nHow are you generating the dataset?\r\n\r\nThis discussion is better moved to stack overflow, since it does not look like a bug in tf.", "The most likely cause is that the input file does not contain an exact multiple of `self.batch_size` records, and your program is crashing when the final batch (containing `total_batch_size * self.batch_size` rows) is emitted. To avoid this problem, avoid using `self.batch_size` in your model, for example by replacing the `tf.reshape()` call with:\r\n\r\n```python\r\nfeatures = tf.reshape(features, [-1, self.input_size, self.input_size, self.input_dim])\r\n```", "@monomon  I have already verified the value of input_dim and it is correct. I also use tf.TFRecordReader to read the dataset directly and it worked well.\r\n\r\n    def loadDataFromRecord(self, dataset_label, name = None):\r\n        with tf.variable_scope(\"batch_\"+name):\r\n            reader = tf.TFRecordReader()\r\n            dataset_dir = [self.dataset_dir[dataset_label]]\r\n            filename_queue = tf.train.string_input_producer(dataset_dir, shuffle=True, capacity=64)\r\n            _, serializedData = reader.read(filename_queue)\r\n            features = tf.parse_single_example(\r\n                serializedData,\r\n                features={\r\n                    'image': tf.FixedLenFeature([], tf.string),\r\n                    'label': tf.FixedLenFeature([], tf.int64) \r\n                })\r\n            image, label = features['image'], features['label']\r\n            height, width, channels = self.input_size, self.input_size, self.input_dim\r\n            image = tf.decode_raw(image, tf.uint8)\r\n            image = tf.reshape(image, [height, width, channels])\r\n            min_after_dequeue = 10000\r\n            capacity = min_after_dequeue + 3*self.batch_size\r\n            image_batch, label_batch = tf.train.shuffle_batch(\r\n                [image, label], batch_size=self.batch_size,\r\n                capacity=capacity, min_after_dequeue=min_after_dequeue)\r\n            image_batch = tf.reshape(image_batch, [self.batch_size, self.input_size, self.input_size, self.input_dim])\r\n            return image_batch, label_batch", "I solve this problem.  The total number of samples is not an integral multiple of the number of batch. Thanks @mrry "]}, {"number": 16312, "title": "Allow step callback for scipy SLSQP", "body": "This simple fix allows `SLSQP` method of scipy optimizer to use step callback as reported in issue [#16294](https://github.com/tensorflow/tensorflow/issues/16294). ", "comments": ["@rmlarsen I added a `test_callbacks()` method to the `ScipyOptimizerInterfaceTest` class, which mimics that in the `ExternalOptimizerInterfaceTest` class with minor modifications. Please let me know if further modifications are needed.  ", "@mjwen thanks for adding the unit test."]}, {"number": 16311, "title": "Segmentation fault in _pywrap_tensorflow_internal.so", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS (Xenial)\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9', '1.4.1')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Cuda8, cudnn6\r\n- **GPU model and memory**: Titan Xp (with driver 387.26)\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux ubuntu 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux ubuntu 4.4.0-87-generic #110-Ubuntu SMP Tue Jul 18 12:55:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.14.0)\r\nprotobuf (3.5.1)\r\ntensorflow-gpu (1.4.1)\r\ntensorflow-tensorboard (0.4.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.4.1\r\ntf.GIT_VERSION = v1.4.0-19-ga52c8d9\r\ntf.COMPILER_VERSION = v1.4.0-19-ga52c8d9\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda/lib64/\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Jan 23 11:09:12 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            Off  | 00000000:04:00.0 Off |                  N/A |\r\n| 40%   66C    P2   182W / 250W |  11763MiB / 12189MiB |     73%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\r\n| 23%   30C    P8     8W / 250W |  11591MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN Xp            Off  | 00000000:06:00.0 Off |                  N/A |\r\n| 28%   48C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN Xp            Off  | 00000000:07:00.0 Off |                  N/A |\r\n| 26%   46C    P0    63W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  TITAN Xp            Off  | 00000000:08:00.0 Off |                  N/A |\r\n| 26%   46C    P0    63W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  TITAN Xp            Off  | 00000000:0C:00.0 Off |                  N/A |\r\n| 23%   43C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  TITAN Xp            Off  | 00000000:0E:00.0 Off |                  N/A |\r\n| 25%   44C    P0    62W / 250W |      0MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  TITAN Xp            Off  | 00000000:0F:00.0 Off |                  N/A |\r\n| 42%   69C    P2   167W / 250W |  11833MiB / 12189MiB |     31%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     19682      C   /home/peiliang/tensorflow/bin/python       11751MiB |\r\n|    1     19682      C   /home/peiliang/tensorflow/bin/python       11579MiB |\r\n|    7     27581      C   python                                     11823MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/lib64/libcudart_static.a\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n```\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nMy custom learning code works perfectly on my older workstation with 2 GPU cards. But am having issue with our new workstation which has 8 GPU cards. I get a Segmentation fault. \r\n\r\n\r\n### Source code / logs\r\n\r\nThe entire source code is: https://github.com/mpkuse/cartwheel_train/tree/config-files\r\n\r\nThe main-script is `train_netvlad.py`. Currently my learning data is private, \r\nif you really need it to test, I can provide the data as well (~100 GB). \r\n\r\nMy code basically builds a network with tf.slim. I have a custom operations to build a layer. Have a custom loss function. Can be found in `CartWheelFlow.py/ class VGGDescriptor`. It uses tf.while. \r\nData is managed by `class TimeMachineRender`\r\n\r\nstack trace for the crash. \r\n\r\n```\r\n$ gdb --args python train_netvlad.py -t tfsuper.logs/test \r\n(gdb) run\r\n.\r\n.\r\n.\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0x00007ffef7f61a2c in std::__detail::_Map_base<std::string, std::pair<std::string const, unsigned long>, std::allocator<std::pair<std::string const, unsigned long> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::string const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n(gdb) where\r\n#0  0x00007ffef7f61a2c in std::__detail::_Map_base<std::string, std::pair<std::string const, unsigned long>, std::allocator<std::pair<std::string const, unsigned long> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::string const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007ffef7f6c4d9 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007ffef5ed94ea in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorfl---Type <return> to continue, or q <return> to quit---\r\now::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007ffef5ed9824 in TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007ffef5bf701a in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007ffef5bf7411 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/---Type <return> to continue, or q <return> to quit---\r\n_pywrap_tensorflow_internal.so\r\n#6  0x00007ffef5bbb6f1 in _wrap_TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00000000004c45fa in PyEval_EvalFrameEx ()\r\n#8  0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#9  0x00000000004de69e in ?? ()\r\n#10 0x00000000004b0c93 in PyObject_Call ()\r\n#11 0x00000000004c6ef6 in PyEval_EvalFrameEx ()\r\n#12 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#13 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#14 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#15 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#16 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#17 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#18 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#19 0x00000000004ca088 in PyEval_EvalFrameEx ()\r\n#20 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#21 0x00000000004c24a9 in PyEval_EvalCode ()\r\n#22 0x00000000004f19ef in ?? ()\r\n#23 0x00000000004ec372 in PyRun_FileExFlags ()\r\n#24 0x00000000004eaaf1 in PyRun_SimpleFileExFlags ()\r\n#25 0x000000000049e208 in Py_Main ()\r\n#26 0x00007ffff7810830 in __libc_start_main (main=0x49db30 <main>, argc=4, \r\n    argv=0x7fffffffe558, init=<optimized out>, fini=<optimized out>, \r\n    rtld_fini=<optimized out>, stack_end=0x7fffffffe548) at ../csu/libc-start.c:291\r\n#27 0x000000000049da59 in _start ()\r\n```\r\n", "comments": ["I have the similar issue when I follow these steps https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md to train object detection. I use tensorflow object detection API and the model checkpoint is download from http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_kitti_2017_11_08.tar.gz. The pipeline config file and datasets are exactly same with the provide one.\r\nThe train.py can work normally for several steps, and then segmentation fault. Sample logs:\r\n```\r\nINFO:tensorflow:global step 4457: loss = 0.0524 (0.523 sec/step)\r\nINFO:tensorflow:global step 4458: loss = 0.0071 (0.789 sec/step)\r\nINFO:tensorflow:global step 4459: loss = 0.4697 (0.677 sec/step)\r\nINFO:tensorflow:global step 4460: loss = 0.0488 (0.396 sec/step)\r\nINFO:tensorflow:global step 4461: loss = 0.0560 (0.637 sec/step)\r\nINFO:tensorflow:global step 4462: loss = 0.0424 (0.588 sec/step)\r\nINFO:tensorflow:global step 4463: loss = 0.0227 (0.525 sec/step)\r\nINFO:tensorflow:global step 4464: loss = 0.0826 (0.693 sec/step)\r\n\r\nThread 157 \"python\" received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7ff7b4ff9700 (LWP 19993)]\r\n0x00007fff4d5cdd80 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::string const&, unsigned long) const ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n(gdb) where\r\n#0  0x00007fff4d5cdd80 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::string const&, unsigned long) const ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#1  0x00007fff4d5cde25 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::string const&) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#2  0x00007fff4d5ce6e1 in tensorflow::ResourceMgr::DoLookup(std::string const&, std::type_index, std::string const&, tensorflow::ResourceBase**) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#3  0x00007fff4fbd36e6 in tensorflow::GetStack(tensorflow::OpKernelContext*, tensorflow::Stack**) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fff4fbd439d in tensorflow::StackPushOp<Eigen::GpuDevice>::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fff4da034ea in tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#6  0x00007fff4da3a17b in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#7  0x00007fff4da3a3ea in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#8  0x00007fff4d6d7782 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#9  0x00007fff4d6d6832 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#10 0x00007fff462dfc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#11 0x00007ffff7bc16ba in start_thread (arg=0x7ff7b4ff9700) at pthread_create.c:333\r\n#12 0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```\r\n## System information\r\n* #### Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n* #### OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS (Xenial)\r\n* #### TensorFlow installed from (source or binary): Binary\r\n* #### TensorFlow version (use command below): ('v1.4.0-19-ga52c8d9', '1.4.1')\r\n* #### Python version: 2.7.12\r\n* #### CUDA/cuDNN version: Cuda8, cudnn6\r\n* #### GPU model and memory: Titan Xp (with driver 387.26)\r\n", "@mpkuse @PeiliangLi it's not clear to me whether your segfaults are related or not.  I took a look into @PeiliangLi's stacktrace (since it has more info) and I'm not sure exactly why we'd segfault in that logic.\r\n\r\nPerhaps either/both of you can try running on our nightly builds, to see if that changes anything?\r\nhttps://pypi.python.org/pypi/tf-nightly-gpu\r\nhttps://github.com/tensorflow/tensorflow", "I tried out the nightly build (\r\ntf_nightly_gpu-1.6.0.dev20180125-cp27-cp27mu-manylinux1_x86_64.whl )\r\n\r\n\r\nBasically uninstalled my previously installed version. For it to work, had to also install CUDA-9.0 and cudnn7. \r\n\r\nMy codes worked for a while (usually about 50 iterations). Still SIGSEGV and get the same stack trace. \r\nIs it helpful to mention that I use `feed_dict ` in tf.run() to set my current batch for training. \r\n\r\nMyself and Peiliang Li are using the same pysical computer. \r\n\r\n\r\nHere is the output from `tf_env_collect`, after the new nightly installation\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.6.0-dev20180125\r\ntf.GIT_VERSION = v1.5.0-rc1-1632-g6743031\r\ntf.COMPILER_VERSION = v1.5.0-rc1-1632-g6743031\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda/lib64/:/usr/local/cuda/lib64/\r\nDYLD_LIBRARY_PATH is unset\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/lib64/libcudart_static.a\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n\r\n\r\nHere is my gdb bracktrace\r\n```\r\n#0  0x00007ffefff0c9ab in std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned long> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#1  0x00007ffefff17fc6 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007ffefd53b791 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Tensor**, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Buffer*, TF_Status*) [clone .constprop.698] ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007ffefd53c06a in TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007ffefd237c8b in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007ffefd237d93 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007ffefd1f9fa4 in _wrap_TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00000000004c45fa in PyEval_EvalFrameEx ()\r\n#8  0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#9  0x00000000004de69e in ?? ()\r\n#10 0x00000000004b0c93 in PyObject_Call ()\r\n#11 0x00000000004c6ef6 in PyEval_EvalFrameEx ()\r\n#12 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#13 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#14 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#15 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#16 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#17 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#18 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#19 0x00000000004ca088 in PyEval_EvalFrameEx ()\r\n#20 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#21 0x00000000004c24a9 in PyEval_EvalCode ()\r\n#22 0x00000000004f19ef in ?? ()\r\n#23 0x00000000004ec372 in PyRun_FileExFlags ()\r\n#24 0x00000000004eaaf1 in PyRun_SimpleFileExFlags ()\r\n#25 0x000000000049e208 in Py_Main ()\r\n#26 0x00007ffff7810830 in __libc_start_main (main=0x49db30 <main>, argc=6, argv=0x7fffffffe478, init=<optimized out>, \r\n    fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffe468) at ../csu/libc-start.c:291\r\n#27 0x000000000049da59 in _start ()\r\n```\r\n\r\nI also noticed that the process uses 65 threads. Used `cat /proc/22222/status`. Is this normal behaviour? ", "Here is a standalone script for my code. \r\nhttps://gist.github.com/mpkuse/10985d9ca11d9555a3ef065aab5070d3\r\n\r\nSample execution:\r\n1 (17, 4096)\r\n2 (17, 4096)\r\n3 (17, 4096)\r\n4 (17, 4096)\r\n5 (17, 4096)\r\n6 (17, 4096)\r\n7 (17, 4096)\r\n8 (17, 4096)\r\n\r\n\r\nI tested it on an older version and a newer version of tensorflow (on separate computers). \r\nI still get a segmentation fault on the newer computer. However, it works well on the older computer. \r\n\r\n\r\nFollowing are the details of the config of the older computer. \r\n\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux mpkusex-ri-desktop2 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"14.04.3 LTS, Trusty Tahr\"\r\nVERSION_ID=\"14.04\"\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux mpkusex-ri-desktop2 3.19.0-25-generic #26~14.04.1-Ubuntu SMP Fri Jul 24 21:16:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.0)\r\nprotobuf (3.3.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.0.1\r\ntf.GIT_VERSION = v1.0.0-65-g4763edf-dirty\r\ntf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty\r\nSanity check: array([1], dtype=int32)\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /home/mpkusex/ros_workspaces/trial_ws/devel/lib/x86_64-linux-gnu:/home/mpkusex/ros_workspaces/robotic_vision/devel/lib/x86_64-linux-gnu:/home/mpkusex/ros_installation/install_isolated/lib/x86_64-linux-gnu:/home/mpkusex/ros_workspaces/trial_ws/devel/lib:/home/mpkusex/ros_workspaces/robotic_vision/devel/lib:/home/mpkusex/caffe/build/install/share/lib:/home/mpkusex/caffe/build/install/share/lib/x86_64-linux-gnu:/home/mpkusex/ros_installation/install_isolated/lib:/usr/local/cuda/lib64:/opt/gurobi651/linux64/lib\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nMon Jan 29 12:15:38 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 690     Off  | 0000:03:00.0     N/A |                  N/A |\r\n| 42%   59C    P0    N/A /  N/A |      1MiB /  1999MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 690     Off  | 0000:04:00.0     N/A |                  N/A |\r\n| 35%   50C    P0    N/A /  N/A |    825MiB /  1998MiB |     N/A      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0                  Not Supported                                         |\r\n|    1                  Not Supported                                         |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-7.5/doc/man/man7/libcudart.7\r\n/usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18\r\n/usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart_static.a\r\n```\r\n\r\n\r\nfollowing is the backtrace on the new computer. Configuration of new computer\r\nare in 1st message of this thread. \r\n```\r\nStarting program: /usr/bin/python -i test_tfdata.py\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff3418700 (LWP 48450)]\r\n[New Thread 0x7ffff2c17700 (LWP 48451)]\r\n[New Thread 0x7ffff0416700 (LWP 48452)]\r\n[New Thread 0x7fffebc15700 (LWP 48453)]\r\n[New Thread 0x7fffeb414700 (LWP 48454)]\r\n[New Thread 0x7fffe6c13700 (LWP 48455)]\r\n[New Thread 0x7fffe4412700 (LWP 48456)]\r\n[New Thread 0x7fffe1c11700 (LWP 48457)]\r\n[New Thread 0x7fffdf410700 (LWP 48458)]\r\n[New Thread 0x7fffdcc0f700 (LWP 48459)]\r\n[New Thread 0x7fffda40e700 (LWP 48460)]\r\n[New Thread 0x7fffd7c0d700 (LWP 48461)]\r\n[New Thread 0x7fffd540c700 (LWP 48462)]\r\n[New Thread 0x7fffd2c0b700 (LWP 48463)]\r\n[New Thread 0x7fffd040a700 (LWP 48464)]\r\n[New Thread 0x7fffcdc09700 (LWP 48465)]\r\n[New Thread 0x7fffcb408700 (LWP 48466)]\r\n[New Thread 0x7fffcac07700 (LWP 48467)]\r\n[New Thread 0x7fffca406700 (LWP 48468)]\r\n[New Thread 0x7fffc9c05700 (LWP 48469)]\r\n[New Thread 0x7fffc3404700 (LWP 48470)]\r\n[New Thread 0x7fffbec03700 (LWP 48471)]\r\n[New Thread 0x7fffbc402700 (LWP 48472)]\r\n[New Thread 0x7fffb9c01700 (LWP 48473)]\r\n[New Thread 0x7fffb7400700 (LWP 48474)]\r\n[New Thread 0x7fffb4bff700 (LWP 48475)]\r\n[New Thread 0x7fffb23fe700 (LWP 48476)]\r\n[New Thread 0x7fffafbfd700 (LWP 48477)]\r\n[New Thread 0x7fffad3fc700 (LWP 48478)]\r\n[New Thread 0x7fffaabfb700 (LWP 48479)]\r\n[New Thread 0x7fffa83fa700 (LWP 48480)]\r\n[New Thread 0x7fffa5bf9700 (LWP 48481)]\r\n[New Thread 0x7fffa53f8700 (LWP 48482)]\r\n[New Thread 0x7fffa2bf7700 (LWP 48483)]\r\n[New Thread 0x7fffa03f6700 (LWP 48484)]\r\n[New Thread 0x7fff9dbf5700 (LWP 48485)]\r\n[New Thread 0x7fff9b3f4700 (LWP 48486)]\r\n[New Thread 0x7fff98bf3700 (LWP 48487)]\r\n[New Thread 0x7fff963f2700 (LWP 48488)]\r\n[New Thread 0x7fff93bf1700 (LWP 48489)]\r\n[New Thread 0x7fff933f0700 (LWP 48490)]\r\n[New Thread 0x7fff8ebef700 (LWP 48491)]\r\n[New Thread 0x7fff8c3ee700 (LWP 48492)]\r\n[New Thread 0x7fff89bed700 (LWP 48493)]\r\n[New Thread 0x7fff873ec700 (LWP 48494)]\r\n[New Thread 0x7fff84beb700 (LWP 48495)]\r\n[New Thread 0x7fff823ea700 (LWP 48496)]\r\n[New Thread 0x7fff7fbe9700 (LWP 48497)]\r\n[New Thread 0x7fff7d3e8700 (LWP 48498)]\r\n[New Thread 0x7fff7abe7700 (LWP 48499)]\r\n[New Thread 0x7fff783e6700 (LWP 48500)]\r\n[New Thread 0x7fff75be5700 (LWP 48501)]\r\n[New Thread 0x7fff733e4700 (LWP 48502)]\r\n[New Thread 0x7fff70be3700 (LWP 48503)]\r\n[New Thread 0x7fff6e3e2700 (LWP 48504)]\r\n[Thread 0x7fffdf410700 (LWP 48458) exited]\r\n[Thread 0x7fff8c3ee700 (LWP 48492) exited]\r\n[Thread 0x7fff7abe7700 (LWP 48499) exited]\r\n[Thread 0x7fff7d3e8700 (LWP 48498) exited]\r\n[Thread 0x7fff7fbe9700 (LWP 48497) exited]\r\n[Thread 0x7fff823ea700 (LWP 48496) exited]\r\n[Thread 0x7fff873ec700 (LWP 48494) exited]\r\n[Thread 0x7fff8ebef700 (LWP 48491) exited]\r\n[Thread 0x7fff933f0700 (LWP 48490) exited]\r\n[Thread 0x7fff93bf1700 (LWP 48489) exited]\r\n[Thread 0x7fff963f2700 (LWP 48488) exited]\r\n[Thread 0x7fff98bf3700 (LWP 48487) exited]\r\n[Thread 0x7fff9b3f4700 (LWP 48486) exited]\r\n[Thread 0x7fffa03f6700 (LWP 48484) exited]\r\n[Thread 0x7fffa2bf7700 (LWP 48483) exited]\r\n[Thread 0x7fffa5bf9700 (LWP 48481) exited]\r\n[Thread 0x7fffa83fa700 (LWP 48480) exited]\r\n[Thread 0x7fffaabfb700 (LWP 48479) exited]\r\n[Thread 0x7fffad3fc700 (LWP 48478) exited]\r\n[Thread 0x7fffafbfd700 (LWP 48477) exited]\r\n[Thread 0x7fffb23fe700 (LWP 48476) exited]\r\n[Thread 0x7fffb9c01700 (LWP 48473) exited]\r\n[Thread 0x7fffbc402700 (LWP 48472) exited]\r\n[Thread 0x7fffbec03700 (LWP 48471) exited]\r\n[Thread 0x7fffc3404700 (LWP 48470) exited]\r\n[Thread 0x7fffc9c05700 (LWP 48469) exited]\r\n[Thread 0x7fff783e6700 (LWP 48500) exited]\r\n[Thread 0x7fff89bed700 (LWP 48493) exited]\r\n[Thread 0x7fff6e3e2700 (LWP 48504) exited]\r\n[Thread 0x7fff733e4700 (LWP 48502) exited]\r\n[Thread 0x7fff70be3700 (LWP 48503) exited]\r\n[Thread 0x7fff75be5700 (LWP 48501) exited]\r\n[Thread 0x7fff84beb700 (LWP 48495) exited]\r\n[Thread 0x7fff9dbf5700 (LWP 48485) exited]\r\n[Thread 0x7fffa53f8700 (LWP 48482) exited]\r\n[Thread 0x7fffb4bff700 (LWP 48475) exited]\r\n[Thread 0x7fffb7400700 (LWP 48474) exited]\r\n[Thread 0x7fffca406700 (LWP 48468) exited]\r\n[Thread 0x7fffcac07700 (LWP 48467) exited]\r\n[Thread 0x7fffcb408700 (LWP 48466) exited]\r\n[Thread 0x7fffcdc09700 (LWP 48465) exited]\r\n[Thread 0x7fffd040a700 (LWP 48464) exited]\r\n[Thread 0x7fffd2c0b700 (LWP 48463) exited]\r\n[Thread 0x7fffd540c700 (LWP 48462) exited]\r\n[Thread 0x7fffd7c0d700 (LWP 48461) exited]\r\n[Thread 0x7fffda40e700 (LWP 48460) exited]\r\n[Thread 0x7fffdcc0f700 (LWP 48459) exited]\r\n[Thread 0x7fffe1c11700 (LWP 48457) exited]\r\n[Thread 0x7fffe4412700 (LWP 48456) exited]\r\n[Thread 0x7fffe6c13700 (LWP 48455) exited]\r\n[Thread 0x7fffeb414700 (LWP 48454) exited]\r\n[Thread 0x7fffebc15700 (LWP 48453) exited]\r\n[Thread 0x7ffff0416700 (LWP 48452) exited]\r\n[Thread 0x7ffff2c17700 (LWP 48451) exited]\r\n[Thread 0x7ffff3418700 (LWP 48450) exited]\r\n[New Thread 0x7fff6e3e2700 (LWP 48545)]\r\n[New Thread 0x7fff70be3700 (LWP 48546)]\r\n[New Thread 0x7fff733e4700 (LWP 48547)]\r\n[New Thread 0x7fff75be5700 (LWP 48548)]\r\n[New Thread 0x7ffedde56700 (LWP 48549)]\r\n[New Thread 0x7ffedd655700 (LWP 48550)]\r\n[New Thread 0x7ffedce54700 (LWP 48551)]\r\n[New Thread 0x7ffebffff700 (LWP 48552)]\r\n[New Thread 0x7ffebf7fe700 (LWP 48553)]\r\n[New Thread 0x7ffebeffd700 (LWP 48554)]\r\n[New Thread 0x7ffebe7fc700 (LWP 48555)]\r\n[New Thread 0x7ffebdffb700 (LWP 48556)]\r\n[New Thread 0x7ffebd7fa700 (LWP 48557)]\r\n[New Thread 0x7ffebcff9700 (LWP 48558)]\r\n[New Thread 0x7ffe9ffff700 (LWP 48559)]\r\n[New Thread 0x7ffe9f7fe700 (LWP 48560)]\r\n[New Thread 0x7ffe9effd700 (LWP 48561)]\r\n[New Thread 0x7ffe9e7fc700 (LWP 48562)]\r\n[New Thread 0x7ffe9dffb700 (LWP 48563)]\r\n[New Thread 0x7ffe9d7fa700 (LWP 48564)]\r\n[New Thread 0x7ffe9cff9700 (LWP 48565)]\r\n[New Thread 0x7ffe7ffff700 (LWP 48566)]\r\n[New Thread 0x7ffe7f7fe700 (LWP 48567)]\r\n[New Thread 0x7ffe7effd700 (LWP 48568)]\r\n[New Thread 0x7ffe7e7fc700 (LWP 48569)]\r\n[New Thread 0x7ffe7dffb700 (LWP 48570)]\r\n[New Thread 0x7ffe7d7fa700 (LWP 48571)]\r\n[New Thread 0x7ffe7cff9700 (LWP 48572)]\r\n[New Thread 0x7ffe5ffff700 (LWP 48573)]\r\n[New Thread 0x7ffe5f7fe700 (LWP 48574)]\r\n[New Thread 0x7ffe5effd700 (LWP 48575)]\r\n[New Thread 0x7ffe5e7fc700 (LWP 48576)]\r\n[New Thread 0x7ffe5dffb700 (LWP 48577)]\r\n[New Thread 0x7ffe5d7fa700 (LWP 48578)]\r\n[New Thread 0x7ffe5cff9700 (LWP 48579)]\r\n[New Thread 0x7ffe3ffff700 (LWP 48580)]\r\n[New Thread 0x7ffe3f7fe700 (LWP 48581)]\r\n[New Thread 0x7ffe3effd700 (LWP 48582)]\r\n[New Thread 0x7ffe3e7fc700 (LWP 48583)]\r\n[New Thread 0x7ffe3dffb700 (LWP 48584)]\r\n[New Thread 0x7ffe3d7fa700 (LWP 48585)]\r\n[New Thread 0x7ffe3cff9700 (LWP 48586)]\r\n[New Thread 0x7ffe1ffff700 (LWP 48587)]\r\n[New Thread 0x7ffe1f7fe700 (LWP 48588)]\r\n[New Thread 0x7ffe1effd700 (LWP 48589)]\r\n[New Thread 0x7ffe1e7fc700 (LWP 48590)]\r\n[New Thread 0x7ffe1dffb700 (LWP 48591)]\r\n[New Thread 0x7ffe1d7fa700 (LWP 48592)]\r\n[New Thread 0x7ffe1cff9700 (LWP 48593)]\r\n[New Thread 0x7ffdfffff700 (LWP 48594)]\r\n[New Thread 0x7ffdff7fe700 (LWP 48595)]\r\n[New Thread 0x7ffdfeffd700 (LWP 48597)]\r\n[New Thread 0x7ffdfe7fc700 (LWP 48598)]\r\n[New Thread 0x7ffdfdffb700 (LWP 48599)]\r\n[New Thread 0x7ffdfd7fa700 (LWP 48600)]\r\n[New Thread 0x7ffdfcff9700 (LWP 48601)]\r\n[New Thread 0x7ffdd9fff700 (LWP 48606)]\r\n[New Thread 0x7ffdd97fe700 (LWP 48607)]\r\n[New Thread 0x7ffdd0ffd700 (LWP 48608)]\r\n[New Thread 0x7ffdd8ffd700 (LWP 48612)]\r\n[New Thread 0x7ffdd2bff700 (LWP 48616)]\r\n[New Thread 0x7ffdd23fe700 (LWP 48617)]\r\n[New Thread 0x7ffdd1bfd700 (LWP 48618)]\r\n[New Thread 0x7ffac3fff700 (LWP 48619)]\r\n[New Thread 0x7ffacb4c9700 (LWP 48620)]\r\n[New Thread 0x7ffacacc8700 (LWP 48621)]\r\n[New Thread 0x7ffaca4c7700 (LWP 48622)]\r\n[New Thread 0x7ffac9cc6700 (LWP 48623)]\r\n[New Thread 0x7ffac94c5700 (LWP 48624)]\r\n[New Thread 0x7ffac8cc4700 (LWP 48625)]\r\n[New Thread 0x7ffac37fe700 (LWP 48626)]\r\n[New Thread 0x7ffac2ffd700 (LWP 48627)]\r\n[New Thread 0x7ffac27fc700 (LWP 48628)]\r\n[New Thread 0x7ffac1ffb700 (LWP 48629)]\r\n[New Thread 0x7ffac17fa700 (LWP 48630)]\r\n[New Thread 0x7ffac0ff9700 (LWP 48631)]\r\n[New Thread 0x7ffa8bfff700 (LWP 48632)]\r\n[New Thread 0x7ffa8b7fe700 (LWP 48633)]\r\n[New Thread 0x7ffa8affd700 (LWP 48634)]\r\n[New Thread 0x7ffa8a7fc700 (LWP 48635)]\r\n[New Thread 0x7ffa89ffb700 (LWP 48636)]\r\n[New Thread 0x7ffa897fa700 (LWP 48637)]\r\n[New Thread 0x7ffa88ff9700 (LWP 48638)]\r\n[New Thread 0x7ffa6bfff700 (LWP 48639)]\r\n[New Thread 0x7ffa6b7fe700 (LWP 48640)]\r\n[New Thread 0x7ffa6affd700 (LWP 48641)]\r\n[New Thread 0x7ffa6a7fc700 (LWP 48642)]\r\n[New Thread 0x7ffa69ffb700 (LWP 48643)]\r\n[New Thread 0x7ffa697fa700 (LWP 48644)]\r\n[New Thread 0x7ffa68ff9700 (LWP 48645)]\r\n[New Thread 0x7ffa4bfff700 (LWP 48646)]\r\n[New Thread 0x7ffa4b7fe700 (LWP 48647)]\r\n[New Thread 0x7ffa4affd700 (LWP 48648)]\r\n[New Thread 0x7ffa4a7fc700 (LWP 48649)]\r\n[New Thread 0x7ffa49ffb700 (LWP 48650)]\r\n[New Thread 0x7ffa497fa700 (LWP 48651)]\r\n[New Thread 0x7ffa48ff9700 (LWP 48652)]\r\n[New Thread 0x7ffa2bfff700 (LWP 48653)]\r\n[New Thread 0x7ffa2b7fe700 (LWP 48654)]\r\n[New Thread 0x7ffa2affd700 (LWP 48655)]\r\n[New Thread 0x7ffa2a7fc700 (LWP 48656)]\r\n[New Thread 0x7ffa29ffb700 (LWP 48657)]\r\n[New Thread 0x7ffa297fa700 (LWP 48658)]\r\n[New Thread 0x7ffa28ff9700 (LWP 48659)]\r\n[New Thread 0x7ffa0bfff700 (LWP 48660)]\r\n[New Thread 0x7ffa03fff700 (LWP 48661)]\r\n[New Thread 0x7ffa0b7fe700 (LWP 48662)]\r\n[New Thread 0x7ffa0affd700 (LWP 48663)]\r\n[New Thread 0x7ffa0a7fc700 (LWP 48664)]\r\n[New Thread 0x7ffa09ffb700 (LWP 48665)]\r\n[New Thread 0x7ffa097fa700 (LWP 48666)]\r\n[New Thread 0x7ffa08ff9700 (LWP 48667)]\r\n[New Thread 0x7ffa037fe700 (LWP 48668)]\r\n[New Thread 0x7ffa02ffd700 (LWP 48669)]\r\n[New Thread 0x7ffa027fc700 (LWP 48670)]\r\n[New Thread 0x7ffa01ffb700 (LWP 48671)]\r\n[New Thread 0x7ffa017fa700 (LWP 48672)]\r\n[New Thread 0x7ffa00ff9700 (LWP 48673)]\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0x00007fff54286fcd in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unordered_map<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unordered_map<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long) const ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#0  0x00007fff54286fcd in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unordered_map<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::unordered_map<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long) const ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#1  0x00007fff542890dd in tensorflow::ResourceMgr::Cleanup(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#2  0x00007fff58fa2972 in std::_Function_handler<void (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), tensorflow::DirectSession::RunState::RunState(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, long long, std::vector<tensorflow::Device*, std::allocator<tensorflow::Device*> > const*)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_invoke(std::_Any_data const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fff58fa5b25 in tensorflow::DirectSession::RunState::~RunState() ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fff58fb0461 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fff565d4791 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Tensor**, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, TF_Buffer*, TF_Status*) [clone .constprop.698] ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fff565d506a in TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fff562d0c8b in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fff562d0d93 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fff56292fa4 in _wrap_TF_Run ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#10 0x00000000004c45fa in PyEval_EvalFrameEx ()\r\n#11 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#12 0x00000000004de69e in ?? ()\r\n#13 0x00000000004b0c93 in PyObject_Call ()\r\n#14 0x00000000004c6ef6 in PyEval_EvalFrameEx ()\r\n#15 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#16 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#17 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#18 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#19 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#20 0x00000000004ca7df in PyEval_EvalFrameEx ()\r\n#21 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#22 0x00000000004ca088 in PyEval_EvalFrameEx ()\r\n#23 0x00000000004c2705 in PyEval_EvalCodeEx ()\r\n#24 0x00000000004c24a9 in PyEval_EvalCode ()\r\n#25 0x00000000004f19ef in ?? ()\r\n#26 0x00000000004ec372 in PyRun_FileExFlags ()\r\n#27 0x00000000004eaaf1 in PyRun_SimpleFileExFlags ()\r\n#28 0x000000000049e208 in Py_Main ()\r\n#29 0x00007ffff7810830 in __libc_start_main (main=0x49db30 <main>, argc=3, \r\n    argv=0x7fffffffe488, init=<optimized out>, fini=<optimized out>, \r\n    rtld_fini=<optimized out>, stack_end=0x7fffffffe478)\r\n    at ../csu/libc-start.c:291\r\n#30 0x000000000049da59 in _start ()\r\nquit\r\n```\r\n", "@asimshankar any thoughts on this, or can you suggest someone who might be able to look into this?", "Any updates on this?", "Sorry for the delay... @mpkuse and @PeiliangLi, are either of you still experiencing these segfaults? It's possible they were fixed since you orginally posted.", "I upgraded to tensorflow 1.6.0. Still experiencing the same issue. Here is my standalone code that replicates the issue: https://gist.github.com/mpkuse/10985d9ca11d9555a3ef065aab5070d3", "@mpkuse do you experience the crash when you disable GPU?", "@skye No, we did try the same version tensorflow on CPU, and no crash.", "any updates on this? \r\ngdb output:\r\n\r\n```\r\nThread 41 \"python\" received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7fff1cff9700 (LWP 28774)]\r\n0x00007fffd4c14998 in Eigen::internal::gemm_pack_rhs<float, long, \r\nEigen::internal::TensorContractionSubMapper<float, long, 0, \r\nEigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, \r\nEigen::TensorVolumePatchOp<-1l, -1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 5, 1, long>, 16, \r\nEigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, \r\nEigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>::operator()(float*, \r\nEigen::internal::TensorContractionSubMapper<float, long, 0, \r\nEigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, \r\nEigen::TensorVolumePatchOp<-1l, -1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 5, 1, long>, 16, \r\nEigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, \r\nEigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer> const&, long, long, long, long) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\n```\r\n", "I also have this error. Any updates so far?", "After checking once more all the installed packages, I found out that somehow by mistake I installed Tensorflow for CPU. By uninstalling the tensorflow and installing tensorflow-gpu the problem is solved.", "ran into the same issue on `GPU` with `conda install tensorflow-gpu` and/or `build from source`, however tensorflow worked on `CPU`,\r\n\r\n```\r\n(gdb) run\r\nStarting program: /anaconda3/envs/tensorflow-gpu/bin/python \r\n[Thread debugging using libthread_db enabled]\r\nPython 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 13:39:56) \r\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nMissing separate debuginfo for /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/numpy/../../../libiomp5.so\r\nTry: yum --disablerepo='*' --enablerepo='*-debug*' install /usr/lib/debug/.build-id/2f/ffee478c58c351d3624c7aeee95c351cdacfea.debug\r\n\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n0x00007fffd7b7c5e4 in _ZSt9call_onceIRFvvEJEEvRSt9once_flagOT_DpOT0_ () from /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\nMissing separate debuginfos, use: debuginfo-install glibc-2.12-1.132.el6_5.4.x86_64\r\n(gdb) runbt full\r\nUndefined command: \"runbt\".  Try \"help\".\r\n(gdb) bt full\r\n#0  0x00007fffd7b7c5e4 in _ZSt9call_onceIRFvvEJEEvRSt9once_flagOT_DpOT0_ () from /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\nNo symbol table info available.\r\n#1  0x00007fffd7b7c64e in tensorflow::port::TestCPUFeature(tensorflow::port::CPUFeature) () from /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\nNo symbol table info available.\r\n#2  0x00007fffd7b7c341 in tensorflow::port::(anonymous namespace)::CheckFeatureOrDie(tensorflow::port::CPUFeature, std::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()\r\n   from /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\nNo symbol table info available.\r\n#3  0x00007fffd7b7c394 in _GLOBAL__sub_I_cpu_feature_guard.cc () from /anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so\r\nNo symbol table info available.\r\n#4  0x000000307ae0e59f in _dl_init_internal () from /lib64/ld-linux-x86-64.so.2\r\nNo symbol table info available.\r\n#5  0x000000307ae12cb5 in dl_open_worker () from /lib64/ld-linux-x86-64.so.2\r\nNo symbol table info available.\r\n#6  0x000000307ae0e1b6 in _dl_catch_error () from /lib64/ld-linux-x86-64.so.2\r\nNo symbol table info available.\r\n#7  0x000000307ae124fa in _dl_open () from /lib64/ld-linux-x86-64.so.2\r\nNo symbol table info available.\r\n#8  0x000000368ae00f66 in dlopen_doit () from /lib64/libdl.so.2\r\nNo symbol table info available.\r\n#9  0x000000307ae0e1b6 in _dl_catch_error () from /lib64/ld-linux-x86-64.so.2\r\nNo symbol table info available.\r\n#10 0x000000368ae0129c in _dlerror_run () from /lib64/libdl.so.2\r\nNo symbol table info available.\r\n#11 0x000000368ae00ee1 in dlopen@@GLIBC_2.2.5 () from /lib64/libdl.so.2\r\nNo symbol table info available.\r\n#12 0x00007ffff7c79161 in _PyImport_FindSharedFuncptr (prefix=0x7ffff7d026a6 \"PyInit\", shortname=0x7fffebee3410 \"_pywrap_tensorflow_internal\", \r\n    pathname=0x7fffebe67050 \"/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\", fp=0x0) at ./Python/dynload_shlib.c:95\r\n        p = <value optimized out>\r\n        handle = <value optimized out>\r\n        funcname = \"PyInit__pywrap_tensorflow_internal\\000\\000\\001\", '\\000' <repeats 11 times>, \"\\006\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\062.\\273\\367\\377\\177\\000\\000@\u05b6\\361\\377\\177\\000\\000 k\\377\\377\\377\\177\", '\\000' <repeats 18 times>, \" k\\377\\377\\377\\177\\000\\000\\240\\003\\362\\353\\377\\177\\000\\000\\240\\003\\362\\353\\377\\177\\000\\000\\022\\026\\276\\367\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000X \\320\\367\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\241D\\276\\367\\377\\177\\000\\000\\330p!\\354\\377\\177\\000\\000\\360\\063\\356\\353\\377\\177\\000\\000H2\\356\\353\\377\\177\\000\\000\\251\\005\\304\\367\\377\\177\\000\\000\\240\\003\\362\\353\\377\\177\\000\\000\\004\\273\\267\\367\\377\\177\\000\\000\\320j\\377\\377\\377\\177\\000\\000\\020k\\377\\377\\377\\177\\000\\000\\020k\\377\\377\\377\\177\\000\\000\\377\\177\\000\\000\\000\\000\\000\\000\\210\"\r\n        pathbuf = \"\\033T(\\004\\212;=\\245X \\320\\367\\377\\177\\000\\000origin\\000\\000\\330p!\\354\\377\\177\\000\\000\\360\\330\\355\\353\\377\\177\\000\\000\\030\\363\\355\\353\\377\\177\\000\\000\\240\\227\\273\\361\\377\\177\\000\\000\\033T(\\004\\212;=\\245@\\322\\355\\353\\377\\177\\000\\000\\370=a\", '\\000' <repeats 13 times>\"\\246, \u0577\\367\\377\\177\\000\\000\\000\\311\\355\\353\\377\\177\\000\\000 k\\377\\377\\377\\177\\000\\000\\310q\\227\\000\\000\\000\\000\\000\\316\\b\\271\\367\\377\\177\\000\\000\\001\\000\\000\\000\\177\\000\\000\\000\\265/\\271\\367\\377\\177\\000\\000\\022\\000\\000\\000\\000\\000\\000\\000a3\\271\\367\\377\\177\\000\\000\\240\\227\\273\\361\\377\\177\\000\\000\\227\\000\\000\\000\\000\\000\\000\\000\\260k\\377\\377\\377\\177\\000\\000\\200\\035\\362\\353\\377\\177\\000\\000Pp\\346\\353\\377\\177\\000\\000\\375\\003\\264\\367\\377\\177\\000\\000\\360\\063\\356\\353\\377\\177\\000\\000v\\000\\000\\000\\000\\000\\000\\000\\260k\\377\\377\\377\\177\\000\\000\\200\\234d\\000\\000\\000\\000\\000P\\035\\362\\353\\377\\177\\000\\000;R\\275\\367\\377\\177\\000\\000utf_\"\r\n        dlopenflags = <value optimized out>\r\n#13 0x00007ffff7c4b08f in _PyImport_LoadDynamicModuleWithSpec (spec=0x7fffebedd240, fp=0x0) at ./Python/importdl.c:129\r\n        pathbytes = 0x7fffebe67030\r\n        name_unicode = 0x7fffebf203a0\r\n        name = <value optimized out>\r\n        path = 0x7fffebf21d50\r\n        m = 0x0\r\n        name_buf = 0x7fffebee3410 \"_pywrap_tensorflow_internal\"\r\n        hook_prefix = 0x7ffff7d026a6 \"PyInit\"\r\n        oldcontext = <value optimized out>\r\n        exportfunc = <value optimized out>\r\n        def = <value optimized out>\r\n        p0 = <value optimized out>\r\n#14 0x00007ffff7c4921b in _imp_create_dynamic_impl (module=Unhandled dwarf expression opcode 0xf3\r\n) at Python/import.c:1982\r\n        mod = 0x0\r\n        name = 0x7fffebf203a0\r\n---Type <return> to continue, or q <return> to quit---\r\n        path = 0x7fffebf21d50\r\n        fp = 0x0\r\n#15 _imp_create_dynamic (module=Unhandled dwarf expression opcode 0xf3\r\n) at Python/clinic/import.c.h:289\r\n        return_value = 0x0\r\n        spec = 0x7fffebedd240\r\n        file = 0x0\r\n#16 0x00007ffff7b8c1b9 in PyCFunction_Call (func=0x7ffff1bcbee8, args=0x7fffebedd2b0, kwds=Unhandled dwarf expression opcode 0xf3\r\n) at Objects/methodobject.c:114\r\n        f = 0x7ffff1bcbee8\r\n        meth = 0x7ffff7c49110 <_imp_create_dynamic>\r\n        self = 0x7ffff1bcc4a8\r\n        arg = <value optimized out>\r\n        res = <value optimized out>\r\n        size = <value optimized out>\r\n        flags = 1\r\n#17 0x00007ffff7c2cbe8 in do_call_core (f=Unhandled dwarf expression opcode 0xf3\r\n) at Python/ceval.c:5089\r\n        result = <value optimized out>\r\n        tstate = <value optimized out>\r\n#18 _PyEval_EvalFrameDefault (f=Unhandled dwarf expression opcode 0xf3\r\n) at Python/ceval.c:3391\r\n        func = 0x7ffff1bcbee8\r\n        callargs = 0x7fffebedd2b0\r\n        kwargs = 0x7fffebedfcf0\r\n        stack_pointer = 0x8081f0\r\n        next_instr = 0x7ffff1bd8268\r\n        opcode = <value optimized out>\r\n        oparg = <value optimized out>\r\n        why = <value optimized out>\r\n        fastlocals = <error reading variable fastlocals (Unhandled dwarf expression opcode 0xf3)>\r\n        freevars = <value optimized out>\r\n        retval = 0x0\r\n        tstate = <value optimized out>\r\n        co = <value optimized out>\r\n        instr_ub = -1\r\n        instr_lb = 0\r\n        instr_prev = -1\r\n        first_instr = <value optimized out>\r\n        names = <value optimized out>\r\n        consts = <value optimized out>\r\n        opcode_targets = {0x7ffff7c2aa60, 0x7ffff7c26ffc, 0x7ffff7c2aa17, 0x7ffff7c2a5e6, 0x7ffff7c274f9, 0x7ffff7c2749e, 0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c2745f, 0x7ffff7c273df, 0x7ffff7c27365, 0x7ffff7c272d9, \r\n          0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c2a389, 0x7ffff7c29b88, 0x7ffff7c27f96, 0x7ffff7c2aa60, 0x7ffff7c27ef2, 0x7ffff7c27e55, 0x7ffff7c2aa60, 0x7ffff7c27d8c, 0x7ffff7c27cc3, 0x7ffff7c27c26, 0x7ffff7c27b89, 0x7ffff7c27aec, \r\n          0x7ffff7c27a4f, 0x7ffff7c279b2, 0x7ffff7c27915, 0x7ffff7c2aa60 <repeats 20 times>, 0x7ffff7c27837, 0x7ffff7c2777e, 0x7ffff7c276aa, 0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c275e1, 0x7ffff7c27544, 0x7ffff7c2723c, 0x7ffff7c2aa60, \r\n          0x7ffff7c2719f, 0x7ffff7c270e9, 0x7ffff7c2704f, 0x7ffff7c2992d, 0x7ffff7c29890, 0x7ffff7c26a06, 0x7ffff7c26969, 0x7ffff7c268cc, 0x7ffff7c26828, 0x7ffff7c28bc9, 0x7ffff7c28b35, 0x7ffff7c28a90, 0x7ffff7c289fa, 0x7ffff7c286e8, \r\n          0x7ffff7c2865e, 0x7ffff7c2aa60, 0x7ffff7c285c1, 0x7ffff7c28524, 0x7ffff7c28946, 0x7ffff7c288a9, 0x7ffff7c2880c, 0x7ffff7c28801, 0x7ffff7c26ef1, 0x7ffff7c26e3b, 0x7ffff7c289e3, 0x7ffff7c26c30, 0x7ffff7c2825d, 0x7ffff7c28231, \r\n          0x7ffff7c281df, 0x7ffff7c2813c, 0x7ffff7c280d7, 0x7ffff7c28033, 0x7ffff7c291ee, 0x7ffff7c290f0, 0x7ffff7c2907f, 0x7ffff7c28f99, 0x7ffff7c28ef2, 0x7ffff7c28e62, 0x7ffff7c28dd0, 0x7ffff7c2a45d, 0x7ffff7c2aa60, 0x7ffff7c2a409, \r\n          0x7ffff7c29a12, 0x7ffff7c299ca, 0x7ffff7c29aaa, 0x7ffff7c28d50, 0x7ffff7c28cc9, 0x7ffff7c28c43, 0x7ffff7c29f67, 0x7ffff7c2a75b, 0x7ffff7c2a990, 0x7ffff7c2a4d1, 0x7ffff7c2849a, 0x7ffff7c28413, 0x7ffff7c283bb, 0x7ffff7c2830e, \r\n          0x7ffff7c29265, 0x7ffff7c2a637, 0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c2a73a, 0x7ffff7c2d1de, 0x7ffff7c26756, 0x7ffff7c26756, 0x7ffff7c2aa60, 0x7ffff7c2a57e, 0x7ffff7c2a514, 0x7ffff7c2a6c1, 0x7ffff7c29e63, 0x7ffff7c2aa60, \r\n          0x7ffff7c2aa60, 0x7ffff7c29e2b, 0x7ffff7c29daf, 0x7ffff7c2a034, 0x7ffff7c29f96, 0x7ffff7c2aa60, 0x7ffff7c2a322, 0x7ffff7c29310, 0x7ffff7c29c90, 0x7ffff7c29c25, 0x7ffff7c2aa60, 0x7ffff7c2aa60, 0x7ffff7c297f8, 0x7ffff7c29645, \r\n          0x7ffff7c29537, 0x7ffff7c2951c, 0x7ffff7c29490, 0x7ffff7c29404, 0x7ffff7c29d0a, 0x7ffff7c26aa3, 0x7ffff7c266b7, 0x7ffff7c29af5, 0x7ffff7c26b3b, 0x7ffff7c266b7, 0x7ffff7c2a157, 0x7ffff7c2a2a3, 0x7ffff7c2a1d8, 0x7ffff7c2a8c1, \r\n          0x7ffff7c29384, 0x7ffff7c2cd72, 0x7ffff7c2aa60 <repeats 97 times>}\r\n#19 0x00007ffff7c2501e in _PyEval_EvalCodeWithName (_co=0x7ffff1c03db0, globals=Unhandled dwarf expression opcode 0xf3\r\n) at Python/ceval.c:4153\r\n        co = 0x7ffff1c03db0\r\n        f = 0x808058\r\n        retval = 0x0\r\n        fastlocals = 0x8081d0\r\n---Type <return> to continue, or q <return> to quit---q\r\nQuit\r\n(gdb)\r\n\r\n\r\n$ nvidia-smi\r\nThu Jul 12 10:15:53 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K40m          Off  | 00000000:05:00.0 Off |                    0 |\r\n| N/A   30C    P0    63W / 235W |      0MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K40m          Off  | 00000000:42:00.0 Off |                    0 |\r\n| N/A   30C    P0    65W / 235W |      0MiB / 11439MiB |     51%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n```\r\n", "I met similar segfault error right here. The trace back is following:\r\n\r\n```\r\n[New Thread 0x7f96ccff9700 (LWP 23574)]\r\n[Thread 0x7f96ccff9700 (LWP 23574) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23575)]\r\n[Thread 0x7f96ccff9700 (LWP 23575) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23576)]\r\n[Thread 0x7f96ccff9700 (LWP 23576) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23577)]\r\n[Thread 0x7f96ccff9700 (LWP 23577) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23578)]\r\n[Thread 0x7f96ccff9700 (LWP 23578) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23579)]\r\n[Thread 0x7f96ce7fc700 (LWP 23166) exited]\r\n[New Thread 0x7f96ce7fc700 (LWP 23580)]\r\n[Thread 0x7f9722ffd700 (LWP 23177) exited]\r\n[New Thread 0x7f9722ffd700 (LWP 23581)]\r\n[Thread 0x7f96ccff9700 (LWP 23579) exited]\r\n[New Thread 0x7f96ccff9700 (LWP 23582)]\r\n\r\nThread 75 \"python\" received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7f97f5ffb700 (LWP 105)]\r\n0x00007f9be9ecf660 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::string const&, unsigned long) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n(gdb) where\r\n#0  0x00007f9be9ecf660 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node(unsigned long, std::string const&, unsigned long) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#1  0x00007f9be9ecf705 in std::_Hashtable<std::string, std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*>, std::allocator<std::pair<std::string const, std::unordered_map<std::pair<unsigned long long, std::string>, tensorflow::ResourceBase*, tensorflow::ResourceMgr::KeyHash, tensorflow::ResourceMgr::KeyEqual, std::allocator<std::pair<std::pair<unsigned long long, std::string> const, tensorflow::ResourceBase*> > >*> >, std::__detail::_Select1st, std::equal_to<std::string>, std::hash<std::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::string const&) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#2  0x00007f9be9ecff26 in tensorflow::ResourceMgr::DoLookup(std::string const&, std::type_index, std::string const&, tensorflow::ResourceBase**) const ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#3  0x00007f9c2c26595b in tensorflow::Status tensorflow::LookupResource<tensorflow::(anonymous namespace)::Batcher>(tensorflow::OpKernelContext*, tensorflow::ResourceHandle const&, tensorflow::(anonymous namespace)::Batcher**) () from ./batcher.so\r\n#4  0x00007f9c2c265b11 in tensorflow::(anonymous namespace)::ComputeOp::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>) () from ./batcher.so\r\n#5  0x00007f9bef58112f in tensorflow::Device::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007f9bea078622 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#7  0x00007f9bea07889a in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#8  0x00007f9bea0d6e2a in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#9  0x00007f9bea0d5ed2 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()\r\n   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so\r\n#10 0x00007f9bccc19c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#11 0x00007f9c50a346ba in start_thread (arg=0x7f97f5ffb700) at pthread_create.c:333\r\n#12 0x00007f9c5076a41d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n\r\n```\r\nSystem Information:\r\n\r\nUbuntu 16.04\r\nCUDA 9.0\r\nCuDNN 7\r\nPython 2.7\r\ntensorflow: tensorflow-gpu 1.9.0\r\nGPU: NVIDIA TITAN V, driver: 396.24.10\r\n\r\n@PeiliangLi Did you figure out what's the segfault coming from? I saw that we have very similar trace report.", "We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 16310, "title": "Bug of tf.data.TFRecordDataset ?  couldnot use tf.reshape to reshape the output of tf.data.TFRecordDataset", "body": "", "comments": []}, {"number": 16309, "title": "Workaround 'too perfect forwarding' issue in variant_op_registry", "body": "In variant_op_registry.h \r\n```\r\nstd::unordered_map<std::tuple<VariantXOp, StringPiece, StringPiece>, \r\n                     VariantXOpFn, TupleHash>\r\n```\r\nseems to be falling victim to 'too perfect forwarding' issue ( [SO link](https://stackoverflow.com/questions/44475317/variadic-template-issue), [Andrzej's blog](https://akrzemi1.wordpress.com/2013/10/10/too-perfect-forwarding/)) with gcc-6.4, gcc-7.2 and clang-4 in ubuntu-17.10 (and possibly others). This PR works around the issue by replacing std::tuple with a simple struct.", "comments": ["Sorry. I just noticed clang-format broke the comment/code. Fixing it right now.", "@samikama thanks for catching that.", "Sorry about missed friend declaration for clang. Docker testing is not working for testing with different compilers. Everything seems fine now."]}, {"number": 16308, "title": "A crash found on tensorflow_jni.so when create interpreter using byteBufferMode", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n### System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\u2022OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04.4 LTS\r\n\u2022TensorFlow installed from (source or binary):use the pip install\r\n\u2022TensorFlow version (use command below):1.4.0\r\n\u2022Python version: Python 2.7.6\r\n\u2022Bazel version (if compiling from source):0.9.0\r\n\u2022GCC/Compiler version (if compiling from source):(Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n\u2022CUDA/cuDNN version:NA\r\n\u2022GPU model and memory:NA\r\n\u2022Exact command to reproduce:NAYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI put my training model to the tflitecamerademo projects, but I encounter a crash issue.\r\nThe crash stack is\r\n\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: Process: android.example.com.tflitecamerademo, PID: 21514\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: java.lang.IllegalArgumentException: Invalid handle to Interpreter.\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:117)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat com.example.android.tflitecamerademo.Camera2BasicFragment.access$900(Camera2BasicFragment.java:69)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat com.example.android.tflitecamerademo.Camera2BasicFragment$5.run(Camera2BasicFragment.java:558)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat android.os.Handler.handleCallback(Handler.java:789)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat android.os.Handler.dispatchMessage(Handler.java:98)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat android.os.Looper.loop(Looper.java:180)\r\n01-23 10:46:45.292 21514 21536 E AndroidRuntime: \tat android.os.HandlerThread.run(HandlerThread.java:65)\r\n\r\nI see the similar issue in https://groups.google.com/a/tensorflow.org/forum/?hl=es-VE#!topic/discuss/jJSH5RQO4Mo, but no one answer.\r\n\r\nP.S. My training tflite file size is about 248293KB\r\n\r\nCould you kindly to help?\r\n\r\nThanks\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This error means that tf lite can not create a valid model driver (a.k.a. Interpreter) with the given model file. I tried to reproduce this error with two large models: one is ~150MB, and another one is over 600MB. Both of them worked fine. It is likely that the model file that you used is not a valid tf lite model, or the tf lite runtime that you used does not support all the ops of the model. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite#step-2-model-format-conversion has the instructions to prepare a model file for tf lite.\r\n\r\nIn the meanwhile, could you please run your model with most recently updated tf lite in Github, then post the exceptions here? There were some code changes released recently, to throw exceptions with details error messages, if tf lite fails to create a valid model driver. With them, we could have a better understanding of the error. Thanks!", "Hello kang-lee:\r\nMany thanks for your response. I will try to use the updated tf lite to dump the error message.\r\nAnd post the error messge here.\r\n\r\nThanks", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I have the same problem. When I use tf.gather(), I encounter a crash issue:\r\nE/AndroidRuntime: FATAL EXCEPTION: CameraBackground\r\n                  Process: android.example.com.tflitecamerademo, PID: 11148\r\n                  java.lang.IllegalArgumentException: Invalid handle to Interpreter.\r\n                      at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)\r\n                      at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)\r\n                      at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)\r\n                      at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)\r\n                      at com.example.android.tflitecamerademo.ImageClassifierFloatInception.runInference(ImageClassifierFloatInception.java:104)\r\n                      at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:110)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:664)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:560)\r\n                      at android.os.Handler.handleCallback(Handler.java:743)\r\n                      at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                      at android.os.Looper.loop(Looper.java:150)\r\n                      at android.os.HandlerThread.run(HandlerThread.java:61)", "Again, 'Invalid handle to Interpreter' means you failed to create a valid model interpreter with the given model file. Please run your model with the most recently updated tf lite in Github, then post the exceptions here. The updated tf lite should throw exceptions when it fails to create a valid model interpreter with more detailed messages.", "I'm trying this with what's in master (trying to get a yolo model working and I only get the same ` Invalid handle to Interpreter.` when calling tflite.run().  Are you sure the new logging/exceptions are in place and output to logcat?", "Yes, it is in the github head: please check line 382 at  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/java/src/main/native/nativeinterpreterwrapper_jni.cc.\r\n\r\nAn IllegalArgumentException will be thrown in Java with the messages if it fails to create a valid Interpreter.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 68 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 16307, "title": "Fix Conv3DTranspose in tf.keras", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Fix tf.layers.Conv3DTranspose as stated in https://github.com/tensorflow/tensorflow/issues/15655", "@fchollet would you please take another look at the changes made after your approval?", "@mktozk thanks for the contribution!\r\n"]}, {"number": 16306, "title": "Add LINM (Loop Invariant Node Motion) optimization pass in GraphOptim\u2026", "body": "\u2026izer\r\nThis change was inspired by LICM (Loop Invariant Code Motion) of compilers. We observed from some public models, e.g. seq2seq (https://github.com/google/seq2seq) and tensor2tensor (https://github.com/tensorflow/tensor2tensor), as well as some of our in-house models that there are many invariant nodes, including expensive MatMul nodes, inside the loop body. \r\nThis optimization pass is to apply on Tensorflow computational graph to detect these invariant nodes and move them out of the loop body, that's why we call it LINM (Loop Invariant Node Motion).\r\n\r\nAlthough there's already a LICM pass in XLA (https://github.com/tensorflow/tensorflow/commit/51895fe67434b6e9f5419872f69c7e6092ed69e9), we still feel necessary to add this LINM pass in GraphOptimizer because:\r\n1. The XLA LICM pass is based on XlaWhile instruction, but the conversion from loop nodes (Enter/Exit/Switch/Merge/LoopCond) of tf.while to XlaWhile instruction is not hooked up yet (https://groups.google.com/forum/#!topic/xla-dev/IqLyL67cemI)\r\n2. We further found out that even if the conversion is hooked up, it works only when all nodes inside the loop has XLA kernel registered. It's a long way to go to get all operators supported by XLA.\r\n3. The LINM pass in GraphOptimizer is expected to work no matter whether XLA is on or off. ", "comments": ["I'm not the best person to review TF graph-level optimizations. Assigning to @hawkinsp for further dispensing\r\n\r\nAlso @jlebar for visibility", "@eliben @rmlarsen Anyone could help take a look at this PR?\r\nIt has been waiting for review for more than one week. \r\nActually we would like to set-up closer collaboration with community. That's why we push this PR as quick as possible to ensure the community could know the details of our work at the first time.\r\nTHanks", "Jun, apologies for the delay. Complicated PRs take a bit longer to review. They require persons closely familiar with the exact areas of code involved, and these folks can be on vacation / occupied temporarily.", "This looks like it would also make a good grappler graph optimization @benoitsteiner.", "@minminsun Most current work on graph-level optimizations is done in the [Grappler subdirectory](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/grappler). Grappler does graph optimizations (constant folding & materialization, CSE, arithmetic optimizations, graph pruning, layout optimization etc.), and is on by default in the TF runtime. It operates on the same high-level graph representation ([GraphDef](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/graph.proto#L14)) as TensorFlow. \r\n\r\nGrappler has a number of advantages over the older graph optimizer framework:\r\n\r\n* It is actively maintained by a team at Google.\r\n* Test coverage is formidable - optimizers are tested against a Google-scale collection of model graphs.  Also, by being on by default, new optimizations are run through every TensorFlow unit test.\r\n* It is backend agnostic: The optimizations will apply whether you use the TensorFlow runtime, XLA, TensorRT, or any other backend, including mobile and web backends like deeplearn.js. \r\n* It can be applied offline to stored graphs, which can be useful for mobile or serving from stored graphs.\r\n* It is applied at the full graph level, before partitioning, which allows full graph optimizations, which may not be possible after partitioning.\r\n\r\nThe individual passes are here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/grappler/optimizers\r\n\r\nWe would be happy to help you migrate your code to the Grappler framework, and change it to operate as another Grappler optimizer pass run by the [meta-optimizer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/meta_optimizer.cc#L81). The main difference is that Grappler works at the GraphDef level, but the underlying algorithms for your pass should be the same.\r\n\r\n", "@minminsun I would also encourage you to refactor this PR to work at the GraphDef level in Grappler. In addition to the technical reasons that @rmlarsen mentioned above, we have just started to work on loop optimizations in Grappler (including invariant code motion) and it would be great to collaborate with you on this. ", "Thanks for your suggestion @ebrevdo @rmlarsen @benoitsteiner . Sure, we'd like to migrate the LINM code to the Grappler framework as a Grappler optimizer pass. ", "Thanks for you guys' response.\r\nWe would like to migrate our code from original TF graph optimization passes to grappler optimization passes(actually we have made a small PR related to grappler's memory optimization accepted by r1.4 before, also recently there is another op fusion work done at grappler code base which we would also like to push to TF upstream when internal test is ready enough).\r\nAs @benoitsteiner mentioned you are also adding some loop optimization work in grappler, could you share a little bit more detail as to those loop optimization? Since we have already implemented LINM optimization, we would be more than happy to re-implement it as another grappler optimization pass. Also I want to know more details about your grappler-level loop optimization work to ensure that your internal work will not be quite duplicated from ours since engineering resource is always limited and there are still quite a lot of things that we could put at our radar:) \r\nWe have already had such issues with TensorRT&TF integration work:), and also I know working with community will not completely avoid such duplicated and overlap work since people seeing the same code base may figure out the same optimization idea based on their specific scenarios. But I do want to set up a mechanism so that we could catch up with the community as soon as possible and then we can steer the direction of our engineering resources in a more productive way.\r\n\r\nThanks", "@yangjunpro: Here is where we are with respect to loop optimizations:\r\n * We have completed the work on shape inference for loops. Since most of the optimizations we do depend on shape information, this allowed us to optimize the body and fanout of loops using existing  optimizers.\r\n * We implemented utilities that are helpful when optimizing loops (frame identification, ...)\r\n * We barely started to work on loop invariant code motion. Since you're miles ahead of us here, it will be much more productive to leverage your code.\r\n * We are thinking about optimizing the 0 iteration case by removing the loop body, enter, exit, merge, switch, and next iteration nodes. We haven't found this to be a common pattern though, so we haven't started  to work on this.\r\n * Ultimately, we'd like to infer the iteration count when it is static, or an upper bound otherwise. This will enable us to detect and optimize the 1 iteration case by removing all the loop logic. This will also enable us to apply the memory optimizations we're working on to loops. We haven't started work on this either though.\r\n * We're also thinking about experimenting with partial loop unrolling. We aren't planning to work on this until we can analyze the loop iteration counter though.\r\n\r\nLet us know if any of this is also on your radar, or if you have other optimizations in mind, and we'd be happy to align our efforts with yours. This will avoid further duplication of effort.\r\n", "Thanks for the information.\r\n\r\n@benoitsteiner , as you said:\r\n_Since most of the optimizations we do depend on shape information, this allowed us to optimize the body and fanout of loops using existing optimizers._\r\n\r\nCould you provide some more information about why the shape information is important (except XLA)?\r\n", "@benoitsteiner \r\n\r\nThanks for sharing the detailed information as to your plan about loop optimizations.\r\nWe have also made a discussion about refactoring LINM into grappler passes. Currently we plan to release the grappler pass based LINM PR by the end of February since there will be a long traditional Chinese sprint festivals:) and also at present there is an ongoing project which is close to its release date and we don't want to make context switch too frequently. \r\nLet us know whether this time slot is suitable for you.\r\n\r\nBefore the official PR to be submit, we would keep update with the community to ensure what we are doing is at good pace. For example, in your replies, it is mentioned that \"We implemented utilities that are helpful when optimizing loops (frame identification, ...)\", actually in LINM we have already implemented the same \"frame identification\" utility function, and if your implementation is already ready, we may base on your utility functions within our LINM implementation. If it is not ready, we would also like to contribute to its implementation since frame identification actually is a somewhat tricky and complex functionality. \r\n\r\nAs to those loop optimization plans mentioned in your previous reply, they are really interesting work. Internally we had some discussions about loop unrolling but we are not sure about the performance benefit with it since in our understanding loop unrolling in TF graph level may not bring as much performance gain as in traditional IR/low-level language level because the condition check overhead will be mitigated by the long execution of loop body itself. Also another potential performance improvement with loop unrolling is the interleave execution of loop iterations, however with our analysis, it looks that not too many DL workloads will trigger such optimization behavior. \r\nActually an interesting question we keep asking ourselves is that \"which kind of traditional compiler optimization techniques may be suitable for Deep Learning graph level optimization?\".  For XLA, it could re-implement a lots of traditional  compiler optimization passes since HLO IR is quite like traditional programming language(XLA has its LLVLM IR emitter and LLVM backend for different targets, GPU  or CPU,etc.). But also I am wondering whether it is more productive by leveraging existing compiler for those mature targets, such as NVIDIA's nvcc or Intel's ICC. I don't know the exact answer.Also I have started a discussion here(https://groups.google.com/forum/#!topic/xla-dev/doFohtEAoLU), and it is still a open discussion thread. \r\n\r\nAs to our graph-level optimization plan, I can provide a list as following:\r\n1. We are currently implementing a template-based op fusion engine(somewhat like TensorRT's catalog based behavior), since we found that there are some op fusion patterns with high usage frequency, for those \"high frequent\" op fusion patterns, we think it deserves to write a macro-op for it then use template-based op fusion to replace the origin subgraph with the macro-op within the graph optimization passes. We have already made some improvement with this op fusion engine, and significant performance improvement is observed. Actually in TensorFlow, we have found there are some offline post-processing tools like graph_transform which will transform the original graph into another one with better performance(such as replace conv+bias+relu with a single op, and micro-op based BN with fused BN, etc.), this is a cheaper way. However, by introducing a post-processing phase, it will require some behavior change of end-users, which may bring some overhead, especially for existing systems. So we choose to add this template-based op fusion engine as a new graph optimization pass. Fortunately, we have caught up with TF team on time, so we will ensure most of the logic will be implemented into grappler passes:). \r\n2. Another optimization plan wandering in our mind is that we are also wondering whether the \"non-mutable\" property of model weights at inference phase could be further leveraged for performance boost. For example, in traditional EDA compiler \r\ncommunity, a specific logic optimization passes will be introduced for doing some logic optimizations to replace the original logic with a new one with better performance(such as mux logic optimization). We are curious whether such optimization could be imported into TF. I know grappler already has its arithmetic_optimization pass which does some strength reduction optimization, but I am wondering whether we could do the optimization in a more principal way, such as formulating it as  SAT problem. This is not a easy problem, so after doing some initial investigation, we temporarily switch to other threads. If Google guys have interest, we may collaboratively discuss the possibility of this optimization direction. \r\n3. Profiling-guided optimization. Since in Alibaba, we had both in-house and public cloud-based environment, and in those environments, various workloads are keeping running. For each workloads, lot of optimization passes may be triggered.  We believe that by collecting those online runtime behavior as profiling data, we may guide the optimization of  subsequent workloads execution. Of course, based on Google's paper in Micro 2010, it looks that Google already has the company-level online profiling tool earlier, maybe you have already have such optimization enabled within your in-house TF environment. \r\n\r\nThanks", "@linearhit One of the main reasons we need shapes to optimize is that TensorFlow does automatic broadcasting. As a result, optimizations such as replacing A+0 or A*1 (where A, 0, and 1 are tensors) with A are only safe if A is a larger tensor than the constants. If for example, A is the vector [a1, a2] and 0 is the tensor [[0,0,][0,0]], A+0 will result in the tensor [[a1, a2][a1,a2]].", "@yangjunpro\r\nReleasing the loop invariant code by the end of February would be great. That would leave plenty of time to make it part of the 1.7 release of TensorFlow.\r\n We put common grappler utilities in the [grappler/utils](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/grappler/utils) directory. In particular, our frame inference api resides in the [frame.h](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/grappler/utils/frame.h) header file. Another commonly used tools is our [shape and type inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/costs/graph_properties.h) code.\r\n\r\nWe believe that loop unrolling can help the performance of models during training since it would cut down some of the overhead needed to feed the activations generated during the forward pass to the corresponding gradient computations during the backward pass. We could also take advantage of unrolling to reduce the memory usage: The idea is to unroll the loop k times, and only keep the activation generated at the end of each unrolled forward mini sequence of k iterations. The would reduce the amount of memory needed to keep activations around by a factor of k at the expense of having to recompute the activations at the beginning of each unrolled backward sequence of k iterations.\r\n\r\nI've worked on formal verification of ASIC circuits in the past, so I've pondered the use of SAT solvers to drive some of the optimizations we're doing. I believe there is a lot of potential in doing this, but given the initial investment needed to get this off the ground I doubt we will get to this before next year. In any case, we'll get in touch with you before we start.\r\n\r\nWe've invested a lot of time in making it possible to collect performance data either by [running the graph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/costs/measuring_cost_estimator.h), or by [simulating](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/costs/analytical_cost_estimator.h) the execution of the graph. We're in the process of releasing the first optimizer that takes advantage these predictions (the [memory optimizer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/memory_optimizer.h)). We will start releasing the second one (automated graph placement) later this month. There are many more graph level optimizations that could benefit from this though. The first one that comes to mind is to automatically choose the between the sparse, dense, or semi sparse implementations of common TF operations depending on the input workload. ", "@benoitsteiner \r\nAs to the loop unrolling optimization related to memory saving, it looks like the similar idea from DeepMind's paper \"Memory-Efficient Backpropagation Through Time\". Also there is a related work from OpenAI's https://github.com/openai/gradient-checkpointing. \r\n\r\nI agree with the memory optimization idea with loop unrolling. However, I think maybe it will more graceful to be implemented in the grappler MemoryOptimizer? Since in MemoryOptimizer it already has the swap2host and re-computation support, I think this loop unrolling memory optimization could be integrated into the MemoryOptimizer. Thus all memory related optimization code could be placed in the same optimization pass. \r\nPreviously, we have use the same alike idea of re-computation for implementing a memory-efficient attention-operator(since it is a specific operator, so we haven't pushed it to the community TF repo). And it has to be admit that by implementing memory optimization in a specific way(such as a dedicated memory-efficient operator or within the customization of a special graph pattern such as loop construct) would require less effort. To generalize all those memory optimization behavior in a principal way, much much more effort may be required. But \r\nas a graph-optimization tool, maybe it would be better to put this loop-unrolling based memory optimization work into the MemoryOptimizer? Please correct me if I am wrong. I think you guys must have deeper thinking about this design.\r\n\r\nAs to the \"automated graph placement\" optimization, is it applicable for local execution(I mean single worker) or both for distributed execution? For local execution, I personally feel that the optimization room may not be quite big.  For distributed execution, the story is different, since based on the profiling data, we may choose how to allocate the workload computation among different devices(CPU, GPU, FPGA or other NPUs), also based on the profiling data, we may choose a optimal(or perhaps sub-optimal) distributed solution(worker number, ps number, communication strategy, shard strategy, etc.). Actually, the more complex the execution scenario is, the more room we could have with automatic placement.  We are also started working on this job but it is not easy and before figuring out a general solution, we need to do a lot of task analysis to ensure the abstracted general solution is good enough. \r\n\r\nThanks", "@benoitsteiner what should happen with this PR?", "@martinwicke: Alibaba will update the code, at which point we'll start the review/testing/merging process. ", "@benoitsteiner @martinwicke \r\n\r\nWe are already working on moving this optimization pass into grappler, the major code logic is completed and we are adding unit test now, it is hopefully that we may submit the first grappler version pull request around the end of this month.\r\n\r\n@minminsun ", "Hi @benoitsteiner \r\n\r\nThe LINM code has been migrated to grappler in this PR. Could you please help to take a look? Thanks!\r\n\r\nBTW, I was not aware that (almost empty) loop_optimizer files have been added in grappler in TF master 15 days ago after I started the code migration, as a result my commit has conflicts with them. So  I'm starting to prepare a new commit based on the latest TF master.\r\n", "@minminsun: thanks, I'll start the code review. @rmlarsen added a new loop optimizer to start working on stack push/pop removal when possible. If this introduces further conflicts, they should be minimal.", "@minminsun can you resolve the conflicts? Thanks!", "@martinwicke Sure, we will resolve the conflicts ASAP.\r\n@minminsun ", "@martinwicke I have resolved the conflicts. Let me know if there's any further issue, thanks!"]}, {"number": 16305, "title": "Add LINM (Loop Invariant Node Motion) optimization pass in GraphOptim\u2026", "body": "\u2026izer", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Committed with wrong user name leading to an cla: no. Closing and will file another one."]}, {"number": 16304, "title": "Replace inception5h references with inception_v1", "body": "In addition to bringing the name to the updated naming scheme, the new archive contains a version of the graph which does not have the CPU attribute set, meaning that it will run with GPU acceleration if available.", "comments": []}, {"number": 16303, "title": "Don't load libcupti.so from regular path on Android", "body": "Open to alternatives, but as other methods in this file work similarly this doesn't seem too bad.", "comments": ["Looks OK to me, but @petewarden better take a look.", "@yifei @gunan why does the CLA check not pass for this, despite CLA being added by the bot earlier?!?", "Not sure why it is failing. The pull request and commit authors are the same, and he is a googler.\r\n@willnorris any ideas?", "I am going to set the CLA label manually and merge this.", "@willnorris @gunan that doesn't seem to help?!? How to merge this?", "Could it be related to this? Duplicate random PR from \"unknown repository\" with a missing CLA: https://github.com/tensorflow/tensorflow/pull/16367", "Weird, I added the CLA to that one and it fixed this one... :P", "The only thing from @googlebot that I see here is setting \"cla:yes\" four days ago.  What is/was the problem?", "@willnorris there's no current issue, the problem resolved itself after I manually set the CLA:yes tag on #16367. It seems they somehow created a phantom PR that masked the flags on this one. GitHub bug possibly?", "Setting the cla status on one PR has no effect on other PRs.  I think the timing of you manually setting that is just coincidental.", "Possibly, but it cleared up instantly when I flipped the tag after being blocked for over a day. Something is strange with that PR because it says it's from an \"unknown repository\" despite being a clone of this one."]}, {"number": 16302, "title": "Update README.md", "body": "Correct MobilenetV1 variable", "comments": ["Looks to be a duplicate of https://github.com/tensorflow/tensorflow/pull/16301\r\nClosing."]}, {"number": 16301, "title": "Update README.md", "body": "Correct MobilenetV1 variable", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!\n\nBest Regards\n\nTarang Chugh <http://tchugh.github.io>\nPRIP Lab, MSU <http://biometrics.cse.msu.edu>\nchughtar@msu.edu | +1-517-515-2575\n\nOn Mon, Jan 22, 2018 at 6:25 PM, googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> verify. Thanks.\n> ------------------------------\n>\n>    - If you've already signed a CLA, it's possible we don't have your\n>    GitHub username or you're using a different email address on your commit.\n>    Check your existing CLA data <https://cla.developers.google.com/clas>\n>    and verify that your email is set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - If your company signed a CLA, they designated a Point of Contact who\n>    decides which employees are authorized to participate. You may need to\n>    contact the Point of Contact for your company and ask to be added to the\n>    group of authorized contributors. If you don't know who your Point of\n>    Contact is, direct the project maintainer to go/cla#troubleshoot. The email\n>    used to register you as an authorized contributor must be the email used\n>    for the Git commit.\n>    - In order to pass this check, please resolve this problem and have\n>    the pull request author add another comment and the bot will run again. If\n>    the bot doesn't comment, it means it doesn't think anything has changed.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/16301#issuecomment-359608478>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AI6d6xicEg9kUWrGgwrKF7uw46XegsOrks5tNRjkgaJpZM4RozZk>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@aselle can you take a look?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@aselle does this look OK?"]}, {"number": 16300, "title": "Add tf.multi_one_hot that one-hot encodes multiple columns of Tensor", "body": "Hello,\r\nhere is the PR for my feature request #16044 \r\nExcited to see your feedback for my first TF PR and hope to give something useful back to this great library ;)", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I signed the CLA", "@squall-1002 Are you sure you signed with the same email you used to submit the PR?", "Maybe you have to say \"I signed it!\"", "CLAs look good, thanks!\n\n<!-- ok -->", "@squall-1002 Please resolve the conflicts by rebasing.", "@caisq can you review this, please?", "@caisq ping", "@caisq No worries, it also took me some time to get back and add some unit tests - looking forward to your response.", "Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@caisq one more look?", "@caisq thanks for the review", "@caisq another look, please?", "Mind also updating the API goldens? See the test failures.", "Hi @jhseu, don't care about my last comment.\r\nSo, I just run\r\n\r\n`bazel build tensorflow/tools/api/tests:api_compatibility_test`\r\n`bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True`\r\nas described in the README and it says\r\n\r\ns.s.\r\n----------------------------------------------------------------------\r\nRan 4 tests in 0.001s\r\n\r\nOK (skipped=2)\r\n\r\nBut there are in fact no changed files I could commmit. I am little puzzled with this part. Do you have some advice?", "@gunan knows more, but I believe it might only work with Python 2 and Linux.", "It only works with python 2 at the moment. It should work both on linux and macos.\r\nOn windows there is no way to run this yet, as TF does not work on windows with python2.", "@jhseu I updated the API goldens, can you trigger the tests again, please?", "Test failures are unrelated. Just waiting on API review.", "@caisq already approved the changes, or does it need a new approval for merge?", "@jhseu Not sure how API review is supposed to work on github nowadays, but should any API reviewers be added to this PR?", "Usually API reviewers meet once weekly and go over the PRs. If another week goes by, I'll ping someone manually.", "(for API review)\r\n\r\nWe looked at this and we have some trouble with the semantics of this. This seems to be very hard to use correctly, and we have the concern that it is easier to write your own (and possibly specialized) version of this rather than understand what exactly `multi_one_hot` does. Therefore, we would rather not add `multi_one_hot` to the API. I will close this PR.\r\n\r\nI apologize for the back and forth -- we should have made this decision on the original issue, and not make you do a bunch of work. We'll make some changes in order catch this type of issue earlier in the future."]}, {"number": 16299, "title": "Branch 182808673", "body": "", "comments": []}, {"number": 16298, "title": "Bug of tf.data.TFRecordDataset? or my codes wrong?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10\r\n- **TensorFlow installed from (source or binary)**:  binary\r\n- **TensorFlow version (use command below)**:  1.4\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: Nvidia Quadro K4000\r\n- **Exact command to reproduce**: \r\n\r\n\r\nI tested to write dynamic numbers of variables into tfrecord. But when I use the tf.data.TFRecordDataset to read VarLenFeature, the program crashes. However, if I do not use dataset, but just tf.python_io.tf_record_iterator. The program works without problem. I wonder whether this is a bug of tf.data.TFRecordDataset, or there is something wrong in my codes?\r\n\r\nMy writing codes are \r\n\r\n    def test_write():\r\n      writer = tf.python_io.TFRecordWriter('test.tfrecord')\r\n\r\n      for i in range(3):\r\n        val_list = []\r\n        for j in range(i+1):\r\n          val_list.append(i+j)\r\n        feature_dict = {\r\n          'val': tf.train.Feature(int64_list=tf.train.Int64List(value=val_list)),\r\n        }\r\n    \r\n        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\r\n        writer.write(example.SerializeToString())\r\n\r\n      writer.close()\r\n\r\nThe reading codes using tf.data.TFRecordDataset and causing error are\r\n\r\n\tdef parse_test(example):\r\n\t  features = {\r\n\t\t'val': tf.VarLenFeature(dtype=tf.int64)\r\n\t  }\r\n\t  parsed_features = tf.parse_single_example(example, features)\r\n\r\n\t  return parsed_features\r\n\r\n\tdef test_read():\r\n\t  dataset = tf.data.TFRecordDataset(['test.tfrecord'])\r\n\t  dataset = dataset.map(parse_test)\r\n\t  dataset = dataset.batch(1)\r\n\r\n\t  iterator = dataset.make_one_shot_iterator()\r\n\t  feature_dict =  iterator.get_next()\r\n\r\n\t  with tf.Session() as sess:\r\n\t\tfor _ in range(3):\r\n\t\t  curr_dict = sess.run(feature_dict)\r\n\t\t  print([curr_dict['val']])\r\n\r\nThe error message is:\r\n\r\n\tTypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"ParseSingleExample/Slice_Indices_val:0\", shape=(?, 1), dtype=int64), values=Tensor(\"ParseSingleExample/ParseExample/ParseExample:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"ParseSingleExample/Squeeze_Shape_val:0\", shape=(1,), dtype=int64)). Consider casting elements to a supported type.\r\n\r\n\r\n The successful reading codes without using tf.data.TFRecordDataset are as below\r\n\r\n\tdef test_read2():\r\n\t  with tf.Session() as sess:\r\n\t\tfor serialized_example in tf.python_io.tf_record_iterator('test.tfrecord'):\r\n\t\t  features = tf.parse_single_example(serialized_example,\r\n\t\t\tfeatures={\r\n\t\t\t  'val': tf.VarLenFeature(dtype=tf.int64),\r\n\t\t\t}\r\n\t\t  )\r\n\r\n\t\t  temp = features['val']\r\n\r\n\t\t  values = sess.run(temp)\r\n\t\t  print(values)\r\n\r\nThis code successfully print out\r\n\r\n\tSparseTensorValue(indices=array([[0]], dtype=int64), values=array([0], dtype=int64), dense_shape=array([1], dtype=int64))\r\n\tSparseTensorValue(indices=array([[0],\r\n\t\t   [1]], dtype=int64), values=array([1, 2], dtype=int64), dense_shape=array([2], dtype=int64))\r\n\tSparseTensorValue(indices=array([[0],\r\n\t\t   [1],\r\n\t\t   [2]], dtype=int64), values=array([2, 3, 4], dtype=int64), dense_shape=array([3], dtype=int64))\r\n\r\nHowever, I am still hoping to use the dataset structure to deal with the VarLenFeature. Is there anything wrong with my reading codes or there is a bug in tf.data.TFRecordDataset? Thank you.\r\n\r\n", "comments": ["`tf.SparseTensor` support was added to `tf.data.Dataset` in TensorFlow 1.5. I confirmed that your program works as expected with TensorFlow 1.5.0rc1, so you should be able to upgrade to that version (or a nightly build) to fix this problem."]}, {"number": 16297, "title": "MKL: Fix convolutional_recurrent_test failure", "body": "This branch fixes the convolutional_recurrent_test failure.", "comments": []}, {"number": 16296, "title": "MKL: Fixed convolutional_recurrent_test", "body": "This PR is to fix convolutional_recurrent_test unit test.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->"]}, {"number": 16295, "title": "Branch 182802058", "body": "", "comments": []}, {"number": 16294, "title": "ScipyOptimizer SLSQP supporting callback", "body": "The callback is deprecated when `SLSQP` method in scipy optimizer is selected (see [here](https://github.com/tensorflow/tensorflow/blob/04b5c75aae4bdbdac7c713714a369f9b360daf70/tensorflow/contrib/opt/python/training/external_optimizer.py#L400)). Actually, `SLSQP` does support callback, so \r\n```python \r\nif method == 'SLSQP':\r\n  # SLSQP doesn't support step callbacks. Obviate associated warning\r\n  # message.\r\n  del minimize_kwargs['callback']\r\n```\r\nin the above linked file could be removed. \r\n\r\nThe following example shows that `SLSQP` do support callback. \r\n\r\n```python \r\nfrom scipy.optimize import minimize, rosen, rosen_der\r\n\r\ndef callback(xk, step=[0]):\r\n  print step[0], xk[0]\r\n  step[0] += 1\r\n  \r\nx0 = [1.3, 0.7, 0.8, 1.9, 1.2]\r\nres = minimize(rosen, x0, callback=callback, method='SLSQP',\r\n    options={'ftol': 1e-6, 'disp': True})\r\n \r\nprint res.x[0]\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@mjwen - thank you for reporting this issue.  Would you be interested in submitting a pull request that implements the change that you suggest?", "@tatianashp Sure. The pull request has been submitted at [#16312](https://github.com/tensorflow/tensorflow/pull/16312).", "Great! \r\n\r\nThank you."]}]