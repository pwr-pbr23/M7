[{"number": 47194, "title": "Bug related to Martin G\u00f6rnes Attend Tutorial", "body": "I know that TF 1 is no longer supported but if I test this notebook related to Martin G\u00f6rner Attention Based Classification Tutorial: https://github.com/conversationai/conversationai-models/blob/master/attention-tutorial/Attention_Model_Tutorial.ipynb\r\n\r\nAnd add the following lines to the bi_rnn_model Function after the encoding was calculated:\r\n\r\nOriginal Code\r\n```\r\nencoding, alphas = attend(outputs, \r\n                            hparams['attention_size'], \r\n                            hparams['attention_depth'])\r\n```\r\nTo add code.\r\n\r\n```\r\n  with tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n    \r\n    xev = encoding.eval()\r\n\r\n```\r\nThe eval Method will hang forever. This happens in session.py:\r\n\r\n```\r\ndef _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\r\n                          run_metadata):\r\n    return tf_session.TF_SessionRun_wrapper(\r\n        self._session, options, feed_dict, fetch_list, target_list,\r\n        run_metadata)\r\n\r\n```\r\n\r\n\r\nAm I doing it completely wrong or is it an old TF1 Bug???\r\n\r\nKind regards,\r\n\r\nDirk", "comments": ["@DHOFM \r\n1.x is not suuported,please upgrade to 2.x and let us know in case you face any issues.", "@Saduf2019 Yes, I know, but my question was / is: Is it an old TF Bug or am I doing it completely wrong?", "@DHOFM This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 47193, "title": "Non exact-zero value for fake quantizer ops", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: 11.0 / 8.1.0\r\n- GPU model and memory: Tesla T4 and GeForce GTX 1650\r\n\r\n**Describe the current behavior**\r\n\r\nThe [tf.quantization.fake_quant_with_min_max_vars](https://www.tensorflow.org/api_docs/python/tf/quantization/fake_quant_with_min_max_vars) (and similar) does not include an exact zero result. Depending on the `min` and `max` parameters these values are actually slightly above zero or below zero, e.g. -0.0000002 or 0.0000006.\r\n\r\n**Describe the expected behavior**\r\n\r\nAn exact zero should be returned and it should not be dependent on the `min` and `max` parameters. Or at least, this was the behaviour in pre-TF 2.4.0 tensorflow versions on the CPU. It is also mentioned in [this article in section 2.1](https://arxiv.org/abs/1712.05877).\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe simplest snippet to reproduce the issue is:\r\n```python\r\nprint(tf.quantization.fake_quant_with_min_max_vars(0.0, -25, 20, num_bits=8))\r\n```\r\nwith TF 2.4.1 on (CPU or GPU) I get:\r\n```python\r\ntf.Tensor(-3.874302e-07, shape=(), dtype=float32)\r\n```\r\nwith TF 2.3.2 on the CPU I get:\r\n```python\r\ntf.Tensor(0.0, shape=(), dtype=float32)\r\n```\r\nand with TF 2.3.2 on the GPU I get:\r\n```python\r\ntf.Tensor(-3.874302e-07, shape=(), dtype=float32)\r\n```\r\n\r\nA more realistic example would look something like this:\r\n```python\r\ndata = tf.random.normal(shape=(4096,), mean=0.0, stddev=1.0)\r\nresult = tf.quantization.fake_quant_with_min_max_vars(data, -21, 23, num_bits=8).numpy()\r\nprint([result[index] for index in range(result.shape[0]) if -1e-4 < result[index] < 1e-4][0])\r\n```\r\n\r\nColab link: https://colab.research.google.com/drive/1swMaNOZpQp1psllRguWH13YHYOpf2Kqa?usp=sharing\r\n\r\n**Other info / logs**\r\n\r\nI've tested this in various settings on various machines, and it seems to work in certain scenarios:\r\n\r\n| platform | TF 2.2.x | TF 2.3.x | TF 2.4.x |\r\n|------------|-------------|------------|-------------|\r\n| Mac      | \u2705  | \u2705  | \u2705 |\r\n| Ubuntu 20.04 CPU | \u2705 | \u2705 | \u274c |\r\n| Ubuntu 20.04 GPU | \u274c | \u274c | \u274c | \r\n\r\nHere \u274c means it is not exact zero, and \u2705 means it is exact zero.\r\n\r\nIt also seems to work if the function is enclosed in a `tf.function` and XLA is enabled by passing in `experimental_compile=True`.\r\n\r\nI could not find any recent commits to the relevant files:\r\n* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fake_quant_ops.cc\r\n* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fake_quant_ops_gpu.cu.cc\r\n* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fake_quant_ops_functor.h\r\n\r\nSo, most likely the issue is in one of the TF utility functions or in an external library (e.g. Eigen) or in the way the TensorFlow wheels are compiled.", "comments": ["Was able to reproduce the issue with  TF v2.4. In TF-nightly using cpu i get output (`<tf.Tensor: shape=(), dtype=float32, numpy=0.0>`) .Please find the gist of it [here](https://colab.research.google.com/gist/ravikyram/5ca92301c765d1a163d2b1efacde0a92/untitled673.ipynb). Thanks!", "@CNugteren Agree. This was an issue with `TF2.4` but I think this was resolved in recent `tf-nightly`. I cannot reproduce the error with `tf-nightly` and `tf-nightly-gpu`.  [Here](https://colab.research.google.com/gist/jvishnuvardhan/167ae4305a6f4e09859291188b8643a2/untitled673.ipynb) is a gist for our reference.\r\n\r\nPlease verify with `tf-nightly` and let us know how it progresses. Thanks!", "@jvishnuvardhan Thanks for taking a look.\r\nI checked out your GPU notebook but it looks like the computation actually doesn't run on the GPU but on the CPU instead even though a GPU is connected to the runtime. I am not sure whether this is an issue with Colab or the latest nightly, but we'll still need to check whether this issue is also fixed in the GPU kernel.\r\nPlease see [this gist](https://colab.research.google.com/drive/1l3VCKACv81rDM_B88czUDbWftid8Q027?usp=sharing) for reference.", "Thanks for looking into this. On my own local machine it does seem to use the GPU properly, but there the value is still not exact zero. It does work on the CPU now indeed, but not on the GPU:\r\n```python\r\n$ cat test_quant.py\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nwith tf.device(\"GPU\"):\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8).device)\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8))\r\n```\r\n```bash\r\n$ export CUDA_VISIBLE_DEVICES= && python test_quant.py \r\n(...)\r\n2.5.0-dev20210218\r\n(...)\r\n2021-02-19 10:46:15.910727: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n(...)\r\n/job:localhost/replica:0/task:0/device:CPU:0\r\ntf.Tensor(0.0, shape=(), dtype=float32)\r\n```\r\n```bash\r\n$ export CUDA_VISIBLE_DEVICES=0 && python test_quant.py \r\n(...)\r\n2.5.0-dev20210218\r\n(...)\r\n2021-02-19 10:46:12.245787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1456] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2208 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n/job:localhost/replica:0/task:0/device:GPU:0\r\ntf.Tensor(-4.917383e-07, shape=(), dtype=float32)\r\n```", "Hello, sorry for late reply. Seems like it's been resolved in the `tf-nightly`. Can you check again?", "> Hello, sorry for late reply. Seems like it's been resolved in the `tf-nightly`. Can you check again?\r\n\r\nIt does not seem to be resolved, at least not on my specific GPU/CUDA combination:\r\n\r\n```python\r\n$ cat test_quant.py\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nwith tf.device(\"GPU\"):\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8).device)\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8))\r\n```\r\n\r\n```bash\r\n$ export CUDA_VISIBLE_DEVICES= && python test_quant.py\r\n(...)\r\n2.5.0-dev20210323\r\n(...)\r\n2021-03-23 10:50:12.857546: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n(...)\r\n/job:localhost/replica:0/task:0/device:CPU:0\r\ntf.Tensor(0.0, shape=(), dtype=float32)\r\n```\r\n```bash\r\n$ export CUDA_VISIBLE_DEVICES=0 && python test_quant.py\r\n(...)\r\n2.5.0-dev20210323\r\n(...)\r\n2021-03-23 10:55:37.606288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5\r\ncoreClock: 1.56GHz coreCount: 16 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 119.24GiB/s\r\n(...)\r\n2021-03-23 10:55:37.983165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n/job:localhost/replica:0/task:0/device:GPU:0\r\ntf.Tensor(-4.917383e-07, shape=(), dtype=float32)\r\n\r\n```", "Logic on fake quant try to make zero to be one of the quantized integer, so result should be close to zero.\r\nBut due to internal logic only saves nudged_min (map to min value) and scale, It can have small numerical errors.\r\n\r\nI think it's not possible to have exact zero on GPU because usually CUDA ops are not deterministic. \r\n(has random small errors)\r\n\r\nWe don't prioritize this kinds of small numeric error.\r\n(I think we don't have easy way to fix it on GPU. it requires deterministic like this : https://github.com/tensorflow/community/blob/master/rfcs/20210119-determinism.md)\r\n\r\nDo you have any task that this bug is critical?", "@Xhark thanks for the answer. I agree that numerical stability is not a priority for floating point neural networks. However, I think for the ops that emulate quantized networks the story can be a bit different.\r\n\r\n> Do you have any task that this bug is critical?\r\n\r\nWe work on Binarized Neural Networks which we train using [larq/larq](https://github.com/larq/larq) and deploy using TFLite and [larq/compute-engine](https://github.com/larq/compute-engine) on edge devices. In these networks weights and activations tend to be binary values `{-1, +1}`. A common pattern is the use of higher precision int8 or floating point shortcuts that will be binarized using a `sign` function before the next binary convolution, such that strictly negative values are mapped to `-1` and the rest to `+1`.\r\nUnfortunately this causes issues in cases where int8 quantization doesn't correctly represent `0`, since huge quantization errors will be introduced in the following binarization operation. Values might flip from `+1` to `-1` due to these numerical instabilities during int8 quantization which can completely destroy the accuracy of these models when converted to TFLite.\r\n\r\nWhile our use case is particular to low bit networks, the issue can also be problematic for general `int8` quantized networks:\r\nBoth https://arxiv.org/pdf/1712.05877.pdf (section 2.1) and https://arxiv.org/pdf/2004.09602.pdf (section 3.1.1) mention that it is important for the int8 quantization scheme to represent zero exactly and https://arxiv.org/pdf/1806.08342.pdf (section 2.1) explicitly states:\r\n>  Zero-point is an integer, ensuring that zero is quantized with no error. This is important to ensure that common operations like zero padding do not cause quantization error.\r\n\r\nIf the ops used in quantization aware training do not satisfy this constrain the error can accumulate over many layers, potentially leading to a bias in the predictions.\r\n\r\nCurrently this doesn't seem to be an issue when using [`tf.quantization.quantize_and_dequantize`](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize_and_dequantize) but that might change as well since numerical stability might not be guaranteed between different TF versions.\r\nIs this op preferred when doing quantization aware training in TensorFlow?\r\n\r\nMost docs point to `tf.quantization.fake_quant_with_min_max_vars` which is also used in TF-MOT but also has limited support for mixed precising float16 training and suffers from the numerical issues discussed here.\r\nWhile `tf.quantization.quantize_and_dequantize` seems to work fine, it is deprecated in favour of [`tf.quantization.quantize_and_dequantize_v2`](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize_and_dequantize_v2). `tf.quantization.quantize_and_dequantize_v2` in turn is not yet supported by the TFLite converter. ~~I opened #47225 some time ago which is a requirement for adding support for `tf.quantization.quantize_and_dequantize_v2` to the TFLite converter in a followup PR, but it seems to be stuck in the pipeline.~~ I opened #48410 to fix this.\r\n\r\n@Xhark I am curious to hear your thoughts on this and would also appreciate some pointers on the difference between the mentioned `tf.quantization` ops.", "Just for reference it looks like a similar issue has been reported in https://github.com/tensorflow/model-optimization/issues/635\r\n\r\nAnd it seems like #48580 might fix this issue, but the PR is still waiting for review.", "@lgeiger \r\nThanks for your comment. It might be better to add epsilon value for your binarizing use case if it possible.\r\nWe assume that zero-point is representable with integer number, and all optimization / implementation also assume that we have integer zero-point. (e.g. zero-padding is easily possible on quantized domain, some pre-compute optimizations for the symmetric quantized weight assume we have integer zero-point.)\r\n\r\nI agree that it can causes accumulate floating numeric errors, but it also happens for other than zero value. (Of course, zero might be more critical than other values for some use cases.)\r\n\r\n - tf.quantization\r\n For QAT, all TF level training & inference only uses FakeQuant. There's no actual quantization yet. It only actually quantized when you convert the model to TFLite format. I think tf.quantization.quantize_and_dequantize_v2 is only for backward compatibility. But very interesting that it's better than FakeQuant in terms of numerical stability. Theoretically, FakeQuant also has same level of the numerical stability. It seems need to do more research on it.\r\n\r\n - About pull request\r\nI think that pull request that you linked will solve more cases, but we can't guarantee it works for all kinds of accelerator. (some compiler optimizations also can changes numerical stability.) It potentially can causes a big problem if your code is very sensitive for this kinds of near-zero numeric error, so the best way is makes it less error sensitive if possible.", "Was able to reproduce the issue with TF v2.5 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/6b04ad9466aa0beb140834d9df5e3051/untitled125.ipynb?authuser=1)..Thanks !", "This issue seems to be resolved with TF 2.8.0 :tada:\r\n\r\nI just re-ran the same test as above on my machine and it produces exact zero in both cases:\r\n\r\n```\r\n$ cat test_quant.py\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nwith tf.device(\"GPU\"):\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8).device)\r\n    print(tf.quantization.fake_quant_with_min_max_vars(0.0, -20, 20, num_bits=8))\r\n```\r\n\r\n```\r\n$ export CUDA_VISIBLE_DEVICES= && python test_quant.py\r\n2.8.0\r\n2022-02-14 17:31:17.693433: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n(...)\r\n/job:localhost/replica:0/task:0/device:CPU:0\r\ntf.Tensor(0.0, shape=(), dtype=float32)\r\n```\r\n```\r\n$ export CUDA_VISIBLE_DEVICES=0 && python test_quant.py\r\n2.8.0\r\n(...)\r\n2022-02-14 17:31:27.142216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2036 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\r\n/job:localhost/replica:0/task:0/device:GPU:0\r\ntf.Tensor(0.0, shape=(), dtype=float32)\r\n```\r\nThis is with CUDA 11.6 and cuDNN 8.3.2 on Ubuntu 20.04.\r\n", "@CNugteren Thank you for the update!\r\nCould you please let us know if we can move this issue to closed status if it is resolved for you ?\r\nThanks!", "Yes this issue can be closed. I cross-checked with my colleague on macOS that it works as expected there as well.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47193\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47193\">No</a>\n"]}, {"number": 47191, "title": "CUDA devices are not recognized", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.3.0\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: Anaconda 4.8.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1.243/7.6.5\r\n- GPU model and memory: NVIDIA Quadro P2000 4GB\r\n\r\n**Describe the problem**\r\n- The list of available GPU is empty!\r\n- TensorFlow runs only on CPU\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`conda env create -f tf-gpu-test.yaml`\r\n`conda activate tf-gpu-test`\r\n`python tf-gpu-test.py`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nFiles: [tf-gpu-test.zip](https://github.com/tensorflow/tensorflow/files/5989857/tf-gpu-test.zip)\r\nCUDA: []\r\nCPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]", "comments": ["@sdonatti \r\nCan you please confirm if you have followed installation as mentioned in the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu).", "The virtual environment uses the [tensorflow-gpu](https://anaconda.org/anaconda/tensorflow-gpu) package from Anaconda. I confirm that the platform has installed CUDA 10.1.243 and cuDNN 7.6.5 in-line with the [tested build configurations](https://www.tensorflow.org/install/source_windows#gpu) for TensorFlow 2.3.0.", "@sdonatti We don't support Anaconda related issues. Did you check whether `tf-gpu` working in local (instead of virtual env). Did you try with other python versions (such as Python 3.6 or 3.7)? Thanks!", "No, I have not tried other Python versions. It seems the issue is with the tensorflow-gpu package from Anaconda because I can detect the CUDA devices properly when using PIP virtual environments with the same major versions. It is a pity and a disappointment that TensorFlow does not support its Anaconda packages, as this package manager shines in providing the versatility to handle CUDA/cuDNN dependencies automatically and binds them to a virtual environment. You can close this issue.", "@sdonatti I understand your feelings about Anaconda package but we don't have any control on those builds and I am sure their repo might provide faster resolution to your problem.\r\n\r\ncc @mihaimaruseac \r\n\r\nI am closing this issue as we cannot do much with Anaconda based TF Package. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47191\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47191\">No</a>\n", "The issue can be mitigated using earlier TensorFlow versions (e.g., 1.15.0) or other package managers (e.g., PIP). It would be good if TensorFlow starts to support its Anaconda packages in the future. Cheers!"]}, {"number": 47190, "title": "Removed deprecated TAGS option and fixed few READMEs for ARC.", "body": "This pull request removes deprecated functionality and fixes build for ARC targets.\r\n\r\nFixes #42932", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47189, "title": "test ExtractVolumePatches with float types that GPU supports", "body": "The original test case tests int64 data type only, which GPU does not register at all.\r\nThe padding issue on GPU was fixed already on eigen side: https://gitlab.com/libeigen/eigen/-/merge_requests/362, https://gitlab.com/libeigen/eigen/-/merge_requests/367 .\r\nSo update the case to test data types that GPU supports here.\r\n\r\nWe may also need to remove the specialization of ExtractVolumePatches op for CPU on TensorFlow side later(as discussed in eigen's MRs)", "comments": ["@GHGmc2 can you please check sanity build failures ?", "> @GHGmc2 can you please check sanity build failures ?\r\n\r\nfixed pylint error"]}, {"number": 47188, "title": "Error with running tensorflow after installation", "body": "I just installed tensorflow 2.4.1.  I use python 3.6 and there were no problem when I installed tensorflow. But the error comes up exactly after importing Tensorflow when I run:\r\n\r\nimport tensorflow as tf\r\nI will get:\r\n\r\nITraceback (most recent call last):\r\n  File \"C:\\Users\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/MultiCNN.py\", line 9, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Python36\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 39, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n\r\n\r\n", "comments": ["@Zahra-zso,\r\nYou might be facing this issue because of the following reasons\r\n\r\n- You are running 32-bit Python or 32-bit OS\r\n- You have not installed the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) package\r\n- Your CPU does not support AVX instructions. \r\n\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nAlso, check this similar duplicate issue: #36167\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47188\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47188\">No</a>\n"]}, {"number": 47187, "title": "tf.keras.layers.Embedding updating embeddings of nearby indices even though they were not updated in the code", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.6.9\r\n\r\n\r\nI am using tf.keras.layers.embedding on a dictionary size of 20 million. For indices greater than 16777216, updates happening in one embedding gets reflected in some other embedding .i.e I am getting same final embeddings for indices above 16777216 in groups of 3.\r\neg. final embeddings for 16777216, 16777217, 16777218 are equal, 16777220, 16777221, 16777222 are equal and so on.\r\n\r\nSomehow higher indices are getting mapped to same entry in the look up table, or may be some hash collision.\r\n\r\nSimplified reproducible code can be found [here.](https://colab.research.google.com/drive/1m-zz4mlPMqOZ_fpz9GpwHTllqH3uqM4g?usp=sharing)\r\n\r\n<img width=\"1422\" alt=\"Screenshot 2021-02-16 at 8 36 26 PM\" src=\"https://user-images.githubusercontent.com/69950926/108081744-4d0cf700-7097-11eb-847c-b93e7897e089.png\">\r\n\r\n\r\nAlso, on a side note, this behaviour is not observed in tf version 2.1.0, embedding layer works fine there.\r\nAny help will be really appreciated, as this is resulting in serious performance issue.\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, [TF v2.4](https://colab.research.google.com/gist/amahendrakar/3d5e8681055b8b4ba7c85e2421907b1f/47187.ipynb) and TF-nightly. \r\n\r\nAnd as mentioned, code works fine with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/6bfb14e802fd9f35a6c8ef497a920a5b/47187-2-1.ipynb). Please check the linked gist for reference. Thanks! ", "Chiming in here. This isn't exactly a bug. Though we may be able to do something on the Keras side to avoid users running into this issue.\r\n\r\nAs you may be aware, the default dtype for all Keras model inputs is `float32`. This is well documented.\r\n\r\nIn your model you don't specify an input dtype. Therefore you default to `float32`.\r\n\r\n`float32` doesn't have the numerical precision to hold large integer values. Hence we get numerical collisions.\r\n\r\nWhen using an Embedding layer with large input values, make sure to specify the input dtype as `int64`.\r\n\r\nHere's an example that works:\r\n\r\n```python\r\nuser_model = tf.keras.Sequential([\r\n    tf.keras.Input((1,), dtype='int64'),\r\n    tf.keras.layers.Embedding(20000000, 10)\r\n])\r\n\r\nuser_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.2),loss='mse')\r\n```\r\n\r\nAction item for the Keras team: consider refusing to process `float32` inputs if the embedding space is too large.\r\n\r\n", "> Chiming in here. This isn't exactly a bug. Though we may be able to do something on the Keras side to avoid users running into this issue.\r\n> \r\n> As you may be aware, the default dtype for all Keras model inputs is `float32`. This is well documented.\r\n> \r\n> In your model you don't specify an input dtype. Therefore you default to `float32`.\r\n> \r\n> `float32` doesn't have the numerical precision to hold large integer values. Hence we get numerical collisions.\r\n> \r\n> When using an Embedding layer with large input values, make sure to specify the input dtype as `int64`.\r\n> \r\n> Here's an example that works:\r\n> \r\n> ```python\r\n> user_model = tf.keras.Sequential([\r\n>     tf.keras.Input((1,), dtype='int64'),\r\n>     tf.keras.layers.Embedding(20000000, 10)\r\n> ])\r\n> \r\n> user_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.2),loss='mse')\r\n> ```\r\n> \r\n> Action item for the Keras team: consider refusing to process `float32` inputs if the embedding space is too large.\r\n\r\n\r\n\r\nThank you for the input. After specifying dtype, the problem of initialisation by same vector seems to be gone. \r\n\r\nBut, there still seems to be some problem with higher indices. I am using embedding vocabulary of around 40 million data points, and for test data with indices greater than 30 million, getting very poor metric. But when I reverse the indices during training, such that the test set has same data (with reversed indices eg. data point with index 40 million will now have index 0, and index 0 will now be 40 million) and training data in a batch also remains same, but the indices of test instances are now less than 10 million, great improvement in metric is observed i.e the model is performing good for smaller indices, but poor for larger indices, irrespective of the data.\r\n\r\nCan not figure out why this is happening .", "Was able to reproduce the issue in TF 2.6.0-dev20210528 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/0377f18f18e1ba42232a0c9468115455/untitled34.ipynb#scrollTo=fLPQgbDHXGKo)...Thanks !", "I still see the issue existing in updating embeddings of nearby indices in Tensorflow 2.7. Since development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47187\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47187\">No</a>\n"]}, {"number": 47185, "title": "Cannot import Tensorflow Lite model with an LSTM layer to Android Studio", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04, Google Colaboratory\r\n- TensorFlow installed from (source or binary): Bundled with Google Colaboratory\r\n- TensorFlow version (use command below): 2.5.0 (latest, installed from nightly, but also occurs on the latest stable version 2.4)\r\n- Python version: 3.6 (Bundled with Google Colaboratory)\r\n\r\n**Describe the current behavior**\r\nI have created a Tensorflow Lite model using[ the official guide](https://www.tensorflow.org/lite/convert/index#convert_a_keras_model_), and then tried to import it to Android Studio using [another official guide](https://www.tensorflow.org/lite/guide/android#use_android_studio_ml_model_binding). However, Android Studio will not make the \"Next\" button available, while displaying an error saying \"This is not a valid Tensorflow Lite model file\".\r\n\r\n**Describe the expected behavior**\r\nThe model should have been imported, as it follows your own official guides.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n1. Create the minimal model I have been using the following Google Colaboratory notebook: https://colab.research.google.com/drive/1VAsXLGHHF4tYxJbq4VtjkccdkVm09hkH?usp=sharing\r\n2. Download the resulting file to your local computer\r\n3. In any Android Studio project, right-click on any module and select New => Other => Tensorflow Lite model\r\n4. Choose the file you downloaded in Step 2\r\n5. The error message will be displayed. (This can be seen in the attached image)\r\n\r\n**Other info / logs** \r\nI opened the same bug with Android Studio in the following [Link](https://issuetracker.google.com/issues/180311612). You can see the Android Studio details and screenshots of the bug in the link.\r\n\r\nAlso note that removing the LSTM layer causes Android Studio to recognize the model as valid. It's the inclusion of the LSTM layer that causes the problem.", "comments": ["Hi @yonatankarimish ! Have you checked the issue in Android studio 4.2 or later ? Thanks!", "@mohantym \r\n(TL:DR; - No...)\r\n\r\nWhen I first opened the ticket, Android studio 4.2 was not yet available.\r\n\r\nThe team working on Android studio gave a swift response saying the issue was solved by version 4.2. But since 4.2 was not yet available back then, there was no way for me to test that.\r\n\r\nConsidering the bad support from the Tensorflow team, I has no choice but to migrate to Pytorch, in which I successfully deployed my model.\r\n\r\nNow, more than a year later, the issue is no longer relevant for me.\r\nYou are welcome to download Android studio 4.2 and check for yourself.\r\n\r\nAll the best\r\n", "@yonatankarimish ! Sorry for the inconvenience. We tested internally in 4.2 and let you know to hear from your side too. Closing as it has been resolved . Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47185\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47185\">No</a>\n"]}, {"number": 47184, "title": "Conv2D operator not XLA compliant with Windows 10", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: conda 3.8.5\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: RTX 2080 super\r\n\r\n**Describe the current behavior**\r\nThe following error is raised, either the code is run on CPU or GPU:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\snake\\miniconda3\\envs\\transformers\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\snake\\miniconda3\\envs\\transformers\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 894, in _call\r\n    return self._concrete_stateful_fn._call_flat(\r\n  File \"C:\\Users\\snake\\miniconda3\\envs\\transformers\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Users\\snake\\miniconda3\\envs\\transformers\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Users\\snake\\miniconda3\\envs\\transformers\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_test_9}} = __inference_test_9[_XlaMustCompile=true, config_proto=\"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0012\\005*\\0010J\\0008\\001\\202\\001\\000\", executor_type=\"\"](dummy_input, dummy_input).\r\nUncompilable nodes:\r\nConv2D: unsupported op: No registered 'Conv2D' OpKernel for XLA_GPU_JIT devices compatible with node {{node Conv2D}}\r\n        Stacktrace:\r\n                Node: __inference_test_9, function:\r\n                Node: Conv2D, function: __inference_test_9\r\n [Op:__inference_test_9]\r\n```\r\n\r\n**Describe the expected behavior**\r\nI'm expecting to have the `Conv2D` op compliant with XLA on GPU and CPU as stated in the TF documentation https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/gpu_supported_ops.md and get the following result:\r\n```\r\n<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=\r\narray([[[[10.        ,  1.8999999 ],\r\n         [ 9.999999  ,  2.1999998 ],\r\n         [ 5.999999  ,  1.5999999 ],\r\n         [ 6.        ,  2.        ]],\r\n\r\n        [[11.999998  ,  1.3999999 ],\r\n         [14.999998  ,  2.1999998 ],\r\n         [12.999999  ,  2.6999998 ],\r\n         [12.999998  ,  1.7       ]],\r\n\r\n        [[ 6.999999  ,  1.6999998 ],\r\n         [10.999998  ,  1.3       ],\r\n         [15.999998  ,  1.3       ],\r\n         [ 7.        ,  1.        ]],\r\n\r\n        [[10.        ,  0.59999996],\r\n         [ 7.        ,  1.3999999 ],\r\n         [ 4.        ,  1.5       ],\r\n         [ 6.9999995 ,  1.4000001 ]]]], dtype=float32)>\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nHere a piece of code to reproduce the issue:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx_in = np.array([[\r\n  [[2], [1], [2], [0], [1]],\r\n  [[1], [3], [2], [2], [3]],\r\n  [[1], [1], [3], [3], [0]],\r\n  [[2], [2], [0], [1], [1]],\r\n  [[0], [0], [3], [1], [2]], ]])\r\n\r\nkernel_in = np.array([\r\n [ [[2, 0.1]], [[3, 0.2]] ],\r\n [ [[0, 0.3]],[[1, 0.4]] ], ])\r\n\r\nx = tf.constant(x_in, dtype=tf.float32)\r\nkernel = tf.constant(kernel_in, dtype=tf.float32)\r\n\r\n@tf.function(experimental_compile=True)\r\ndef run_xla():\r\n  return tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\r\n\r\nrun_xla()\r\n```\r\n\r\nThis issue appears only on Windows, but not on Linux, then it might be an OS related issue.", "comments": ["As mentioned, I was able to run the code on Colab (Linux) without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/5eaf0d636d9d7cb831195bacdf88a611/47184.ipynb). Thanks!", "@amahendrakar Thanks but as stated in the title I'm not on Linux, but on Windows, you cannot reproduce this bug in colab.", "Can you try again by creating virtual environment with latest Tensorflow version on your Windows machine and let us know if you still face the issue. Thanks!", "Thanks a lot! It works as expected.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47184\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47184\">No</a>\n"]}, {"number": 47183, "title": "Crash when creating Dataset from RaggedTensor, parallel function calls", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, see in colab below\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nDocker image tensorflow/tensorflow:2.4.1-gpu-jupyter\r\n\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n\r\n- TensorFlow version (use command below):\r\n2.4.1\r\n\r\n- Python version:\r\n3.6.9\r\n\r\n- GPU model and memory:\r\nTesla V100 with 16GB\r\n\r\n**Describe the current behavior**\r\n\r\nRunning the script in the colab below crashes:\r\n- at random times (but typically soon after launching the script)\r\n- **most often with a segfault without further info**, sometimes with a variety of error such as\r\n  - tensorflow.python.framework.errors_impl.InvalidArgumentError: PartialTensorShape: Incompatible ranks during merge: 1 vs. 0\r\n         [[{{node TensorListConcatV2}}]] [Op:IteratorGetNext]\r\n  - F tensorflow/core/framework/tensor_shape.cc:466] Check failed: end <= dims() (1 vs. 0)\r\n  - invalid fastbin entry (free)\r\n  - InvalidArgumentError: Trying to concat list with only uninitialized tensors but element_shape_except_first_dim_ is not fully defined: []\r\n\t [[{{node TensorListConcatV2}}]]\r\n\r\n**Describe the expected behavior**\r\n\r\nNo crashes, the expected output is \r\n2\r\n0\r\n2\r\n0\r\n...\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1TA2kXxM5mQXDKI5-mcY28IuTl4zO4Syv?usp=sharing\r\n\r\n**Other info**\r\nThe problem does not occur if\r\n- **the num_parallel_calls is set to 1**\r\nand/or\r\n- the ragged tensor is changed to an ordinary tensor\r\nand/or\r\n- the tf.fill is changed to a constant tensor\r\n", "comments": ["@azertyken \r\nCan you please refer to this resolved issue and let us know if it helps: [link](https://stackoverflow.com/questions/62712483/tensorflow-partialtensorshape-incompatible-ranks-during-merge-2-vs-1)", "@Saduf2019 I don't think the issue you refer to is similar to the one that I'm experiencing. Please note that most of the time, the script just segfaults and there is no error indication whatsoever.", "@azertyken \r\nI ran the code on tf 2.4 and nightly and do not see any errors on tf-nightly , nor does the colab crash, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/36a97496f09e72d44e6ca025ec205a9e/untitled540.ipynb).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Saduf2019 You're right, the errors are gone, thanks!", "@ddeweerdt \r\nThank you for your update, please move the issue to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47183\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47183\">No</a>\n"]}, {"number": 47182, "title": "TF repo preprocessing for EfficientNet differs from that contained in Keras repo.", "body": "Hi all,\r\n\r\nI've noticed that the code for EfficientNet image preprocessing contained [here](https://github.com/keras-team/keras-applications/blob/master/keras_applications/efficientnet.py#L530) is different from the one contained [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet.py#L740).\r\nIn the first link (from keras-team) standard ImageNet preprocessing is performed, while in the second link (from tensorflow) nothing is done.\r\n\r\nWhich version of the code should I trust for reusing the EfficientNet checkpoints publicly released by Google?\r\n\r\nThanks for your time!", "comments": ["@albertotonon,\r\nWe can't say that nothing is done in the [TF Keras (second) link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet.py#L740) because it is wrapped with `@keras_export('keras.applications.efficientnet.preprocess_input')`.\r\n\r\nIt is recommended to use PreProcess function of [TF Keras](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet.py#L740) over [Keras-Teams Applications](https://github.com/keras-team/keras-applications/blob/master/keras_applications/efficientnet.py#L530) because [TF Keras Applications Code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/applications/efficientnet.py#L740) is actively/recently updated.", "Thanks a lot, @rmothukuru ! This completely clarifies my doubt, so, i'll close the ticket.\r\nKeep up the good work, people :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47182\">No</a>\n"]}, {"number": 47181, "title": "Updated the equation for FTLP as per the paper", "body": "Used this https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf to update the description.\r\n![image](https://user-images.githubusercontent.com/16112670/108043678-6433f080-7067-11eb-9e00-9d7d56ae6e22.png)\r\n\r\nCurrenly, in the exisiting website:\r\n![image](https://user-images.githubusercontent.com/16112670/108043964-b6751180-7067-11eb-94d7-e7f7ef60a85c.png)\r\n\r\nThe \\abs function is errornious, Lambda_2 is doubled but as per the paper it is not multiplied by 2.\r\n", "comments": ["Tested the commited Latex at mathcha.io and it is fine.\r\n\r\n![image](https://user-images.githubusercontent.com/16112670/108045381-69923a80-7069-11eb-9c88-d2eb61378c36.png)\r\n", "Anymore formalities from my side @mattdangerw ?"]}, {"number": 47180, "title": "[TFL] Remove (log-)softmax before arg-minmax as (log-)softmax is monotonic", "body": "It's a common pattern for classification task. Most models in `tf.keras.applications` set `classifier_activation=\"softmax\"` by default. This PR optimizes out that softmax op when users want to get prediction ids only instead of probabilities.", "comments": ["@WindQAQ Could you sync it to head again? There are merge conflicts, which block the submission.", "Updated!"]}, {"number": 47178, "title": "'An error ocurred while starting the kernel' while training on gpu in Spyder!", "body": "I want to train a Bidirectional LSTM model on my GPU but this is what I get after 2-3 epochs:\r\n`An error ocurred while starting the kernel\r\n2021\udae1\udea6\udae1\udeb4 09:06:13.678667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:16.489943: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:06:16.492166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.272286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.274418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.308431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.308767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.327392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.331839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.345486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.363282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.364864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:17.365316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:06:48.969791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance\u2011critical operations: AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.127162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.127794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.128172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.128483: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.128781: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.129096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.129508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.130288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.130789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.131620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.885459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.885798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.885996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.886418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 3023 MB memory) \u2011> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2021\udae1\udea6\udae1\udeb4 09:06:49.887589: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.591865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.592482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.592765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.593045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.593372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.593648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.593932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.594485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.594999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.595489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.596239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.596684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.597243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.598111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3023 MB memory) \u2011> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2021\udae1\udea6\udae1\udeb4 09:07:13.598930: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:07:14.536186: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021\udae1\udea6\udae1\udeb4 09:07:20.533796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:07:20.874353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.760699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.761518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.761935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.762304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.762632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.762953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.763477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.763869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.764196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.764560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.764888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.765192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.765382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.765714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 3023 MB memory) \u2011> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2021\udae1\udea6\udae1\udeb4 09:08:09.766262: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.232789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.233388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.234009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.234656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.235187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.235952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.236577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.237076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.237535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.238326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.239011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.239505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.239812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.240130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 3023 MB memory) \u2011> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2021\udae1\udea6\udae1\udeb4 09:12:27.240670: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.349103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.349690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.349989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.350288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.350653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.350996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.351675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.352405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.353289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.354195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.355185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.356032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] 0\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.356764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0: N\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.357599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 3023 MB memory) \u2011> physical GPU (device: 0, name: Quadro M2000M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2021\udae1\udea6\udae1\udeb4 09:18:44.358700: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021\udae1\udea6\udae1\udeb4 09:19:11.594693: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO\u2011mode, and switching to DATA\u2011based sharding, instead of FILE\u2011based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\nkey: \"Targuments\"\r\nvalue {\r\nlist {\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"f\"\r\nvalue {\r\nfunc {\r\nname: \"__inference_Dataset_flat_map_slice_batch_indices_20559\"\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"output_shapes\"\r\nvalue {\r\nlist {\r\nshape {\r\ndim {\r\nsize: \ud810\udcab\r\n}\r\n}\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"output_types\"\r\nvalue {\r\nlist {\r\ntype: DT_INT64\r\n}\r\n}\r\n}\r\n. Consider either turning off auto\u2011sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\r\n2021\udae1\udea6\udae1\udeb4 10:01:56.865667: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO\u2011mode, and switching to DATA\u2011based sharding, instead of FILE\u2011based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\nkey: \"Targuments\"\r\nvalue {\r\nlist {\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"f\"\r\nvalue {\r\nfunc {\r\nname: \"__inference_Dataset_flat_map_slice_batch_indices_27929\"\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"output_shapes\"\r\nvalue {\r\nlist {\r\nshape {\r\ndim {\r\nsize: \ud810\udcab\r\n}\r\n}\r\n}\r\n}\r\n}\r\nattr {\r\nkey: \"output_types\"\r\nvalue {\r\nlist {\r\ntype: DT_INT64\r\n}\r\n}\r\n}\r\n. Consider either turning off auto\u2011sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\r\n2021\udae1\udea6\udae1\udeb4 10:02:00.920677: F tensorflow/core/kernels/split_lib_gpu.cu.cc:205] Non\u2011OK\u2011status: GpuLaunchKernel(SplitOpKernel, config.block_count, config.thread_per_block, 0, d.stream(), input, prefix_dim_size, split_dim_size, suffix_dim_size, output_ptr_data) status: Internal: unspecified launch failure\r\n`\r\nGPU model: Quadro M2000M\r\nTensorflow 2.4.1\r\nWindows 10\r\nCUDA 11\r\ncudNN 8.6", "comments": ["@sgolestanian \r\nPlease provide with simple stand alone code or if possible share a colab gist with error reported.", "this only occurs in my laptop but the code works fine in colab!", "@sgolestanian \r\nCan you please try in virtual env and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47177, "title": "tensorflow_model_server  taking a lot of time in deploying model", "body": "Command is running from hours \r\nnohup tensorflow_model_server \\\r\n  --rest_api_port=9090 \\\r\n  --model_name=seman_model \\\r\n  --model_base_path=\"${Model_Directory}\" >server1.log 2>&1", "comments": ["@akanksha4116 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47176, "title": "Need to get the version info from the model", "body": "I have downloaded / created tfLite Model.\r\n\r\nHow do i know the version of the tfLite Model from just the flatbuffer model(*.tflite ) file..\r\nCan i fetch the version information from this model.\r\n\r\nAnother query - we have schema_generated.h file in every tfLite release. (tensorflow/lite/schema)\r\nI could not see any version information in this file. \r\n\r\nCan i fetch the version of tfLite from this file .", "comments": ["I am afraid that `.tflite` file by itself won't be sufficient to extract the TF version. Perhaps you may want to try asking the version on the repository where you downloaded the model.\r\nTensorFlow Lite Runtime version value is shared with that of TensorFlow.\r\nhttps://github.com/tensorflow/tensorflow/blob/e2cd9cda8001d6c9aaeb454ecc6f14dcc7a1a2d7/tensorflow/lite/version.h#L25", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47176\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47176\">No</a>\n"]}, {"number": 47175, "title": "Model benchmark binary throws \"unconsumed cmdline flag: --graph\" error", "body": "**System information**\r\n- Windows 10\r\n- ADB\r\n- Binary downloaded from [here](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model_performance_options)\r\n\r\n**Describe the current behavior**\r\nADB Shell input and output:\r\n```\r\nCPH1920:/data/local/tmp $ ./android_aarch64_benchmark_model_performance_options --graph test\r\nSTARTING!\r\nUnconsumed cmdline flags: --graph test\r\nWARNING: unrecognized commandline flag: --graph\r\nWARNING: unrecognized commandline flag: test\r\nThe list of TFLite runtime options to be benchmarked: [all]\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\nPlease specify the name of your TF Lite input file with --graph\r\n\r\n==============Summary of All Runs w/ Different Performance Options==============\r\n                  gpu-fp16:  failed!\r\n          cpu w/ 1 threads:  failed!\r\ncpu w/ 2 threads (xnnpack):  failed!\r\ncpu w/ 4 threads (xnnpack):  failed!\r\n               gpu-default:  failed!\r\n     nnapi(w/o accel name):  failed!\r\n          cpu w/ 4 threads:  failed!\r\ncpu w/ 1 threads (xnnpack):  failed!\r\n          cpu w/ 2 threads:  failed!\r\n            dsp w/ hexagon:  failed!\r\n```\r\n**Describe the expected behavior**\r\nShould not be asking for `--graph` flag if it is already provided.", "comments": ["Whoops. The command should have been in the form of `./android_aarch64_benchmark_model_performance_options --graph=test`. (Notice the equal sign after graph)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47175\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47175\">No</a>\n"]}, {"number": 47172, "title": "How to compute gradient of output wrt input in Tensorflow 2.0 when there are multi-labels?", "body": "In my case, the input shape is (None, 16) (sample size, feature size), and my output is (None, 3). It means that my DNN is a mapping from input space to 3-D output space. In that case how can I use the tape to calculate the gradients of output w.r.t input?\r\nHere is my code:\r\n```\r\nimport tensorflow as tf\r\nx_grad = tf.Variable(gpi_input, dtype=tf.float32)\r\nwith tf.GradientTape(persistent=True) as tape:\r\n    pred = best_model(x_grad)\r\ngrads = tape.gradient(pred, x_grad)\r\n```\r\nwhere ```pred``` is of [None, 3] and ```x_grad``` is of [None, 16]. But what I got is a tensor of shape [None, 16] which means ```grads``` is of shape [None, 16]. But I want to know the gradients of each output w.r.t to each input. So what should I do?\r\n\r\n\r\nThe ```best_model``` has been already trained and we cannot retrain a model from input to first label, the second label and the third label. So how can I get gradients of every label given the model I have in my hand?\r\n\r\nThanks a lot! ", "comments": ["@xushanthu-2014 \r\nPlease provide with simple stand alone code or if possible share a colab gist with error reported.", "Hi @Saduf2019, the simple stand alone code see here:\r\n```\r\nimport tensorflow as tf\r\nsample_size, dim_feature,dim_multilabel=8000,16,3\r\ngpi_input = np.random.normal(0, 1, size=(sample_size, dim_feature))\r\nground_truth = np.random.normal(0, 1, size=(sample_size, dim_multilabel))\r\nx_grad = tf.Variable(gpi_input, dtype=tf.float32)\r\nwith tf.GradientTape(persistent=True) as tape:\r\n    pred = best_model(x_grad)\r\ngrads = tape.gradient(pred, x_grad)\r\n```\r\nThere is no error. But I want to get grads for 3 labels at the same time in this case of multi-label problem. How do I do that? by simply using tape.gradient I can just get grads of size [sample_size, dim_input] which means I can only get one value for 3 labels. So how can I get the derivatives of each label w.r.t each input?\r\n\r\nThanks", "@xushanthu-2014 \r\nPlease refer to [this link](https://github.com/dipanjanS/adversarial-learning-robustness/blob/main/tutorials/attacks/02_2_targeted_pgd.ipynb) and let us know if it helps.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@xushanthu-2014 did you managed to solve this problem? If yes, how? Thanks!"]}, {"number": 47169, "title": "Modernize TF_CPP_VMODULE handling using absl", "body": "This gets rid of the custom StringData struct since flat_hash_map\r\nsupports heterogenous lookups.", "comments": ["@sanjoy  Can you please address Ubuntu Sanity errors? Thanks!", "@sanjoy Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@sanjoy Any update on this PR? Please. Thanks!", "@sanjoy Any update on this PR? Please. Thanks!", "It has been 19 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 59 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 47167, "title": "Add axis argument in losses.categorical_crossentropy and losses.binary_crossentropy", "body": "Fix tensorflow/tensorflow/issues/39230.\r\nThis pull request will add the axis argument in tensorflow.keras.losses.categorical_crossentropy() and in tensorflow.keras.losses.binary_crossentropy() as in tensorflow.keras.losses.sparse_categorical_crossentropy().", "comments": []}, {"number": 47166, "title": "Failed to build Tensorflow Lite for Win32 using CMake", "body": "**System information**\r\n- OS Platform and Distribution: Windows - 10.0.19041 - AMD64\r\n- TensorFlow installed from: tag v2.4.1 (85c8b2a) or master (bf157579cf0)\r\n- TensorFlow version: 2.4.1\r\n- CMake version: 3.17.2\r\n- GCC/Compiler version: MSVC 19.27.29111.0\r\n- CUDA/cuDNN version: Not used\r\n- GPU model and memory: Not used\r\n\r\nThis is probably not relevant since I'm building with CMake, but follow my Bazel environment information:\r\n- Python version: 3.8.3 (x64 and x86)\r\n- Installed using virtualenv: tried with both Python x86 venv and with x64 venv\r\n- Bazel version: 3.1.0\r\n\r\n\r\n\r\n\r\n**My problem:**\r\nI'm currently tying to build Tensorflow Lite library to be used by my library that should support both Linux and Windows, x86 and x64. Since Bazel does not builds for x86 out of the box I was following the [documentation](https://www.tensorflow.org/lite/guide/build_cmake) to build TF Lite using CMake, including its source with _add_subdirectory()_ .\r\nIt works great for for x64 builds (-A x64) but when I change it to windows x86 (-A Win32) it always fails building _gemmlowp_.\r\nI also tried to build via cmake on command line, using the tensorflow/lite/CMakeLists.txt to build the static library, but get the same error.\r\n**I wonder if it was even supposed to be supported** and if so, if it is a issue to be handled by tensorflow or [gemmlowp](https://github.com/google/gemmlowp). I can also see some pthread releated errors on CMakeError.log\r\n\r\n\r\n**Build steps:**\r\n\r\n- \u03bb cmake -A Win32 -DCMAKE_BUILD_TYPE=Release -S ..\\tensorflow\\lite\\ -B .\r\n- \u03bb cmake --build . --config Release\r\n...\r\n  ...\r\n  expand_dims.cc\r\n  fake_quant.cc\r\n  Generating Code...\r\n**C:\\workspace\\tensorflow\\build-tflite\\gemmlowp\\internal\\output.h(176): fatal error C1001: Internal compiler error.** [C :\\workspace\\tensorflow\\build-tflite\\tensorflow-lite.vcxproj]\r\n  (compiler file 'd:\\agent\\_work\\7\\s\\src\\vctools\\Compiler\\Utc\\src\\p2\\main.c', line 195)\r\n   To work around this problem, try simplifying or changing the program near the locations listed above.\r\n  If possible please provide a repro here: https://developercommunity.visualstudio.com\r\n  Please choose the Technical Support command on the Visual C++\r\n   Help menu, or open the Technical Support help file for more information\r\n\r\n**Other logs**\r\n\r\n**CMakeError.log**\r\n\r\nDetermining if the include file pthread.h exists failed with the following output:\r\nChange Dir: C:/workspace/tensorflow/build-tflite/CMakeFiles/CMakeTmp\r\n\r\n...\r\n\r\nCopyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\n\r\n  CheckIncludeFile.c\r\n\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  cl /c /I\"C:\\workspace\\vcpkg\\scripts\\buildsystems\\msbuild\\..\\..\\..\\installed\\x86-windows\\include\" /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /Oy- /D WIN32 /D _WINDOWS /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_d958e.dir\\Debug\\\\\" /Fd\"cmTC_d958e.dir\\Debug\\vc142.pdb\" /Gd /TC /analyze- /errorReport:queue \"C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c\"\r\n\r\nC:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c(1,10): **fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory** [C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\cmTC_d958e.vcxproj]\r\n\r\nPerforming C++ SOURCE FILE Test EIGEN_COMPILER_SUPPORT_CPP11 failed with the following output:\r\nChange Dir: C:/workspace/tensorflow/build-tflite/CMakeFiles/CMakeTmp\r\n\r\n...\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\n  src.cxx\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  cl /c /I\"C:\\workspace\\vcpkg\\scripts\\buildsystems\\msbuild\\..\\..\\..\\installed\\x86-windows\\include\" /Zi /W1 /WX- /diagnostics:column /Od /Ob0 /Oy- /D WIN32 /D _WINDOWS /D EIGEN_COMPILER_SUPPORT_CPP11 /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /EHsc /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /GR /Fo\"cmTC_94317.dir\\Debug\\\\\" /Fd\"cmTC_94317.dir\\Debug\\vc142.pdb\" /Gd /TP /analyze- /errorReport:queue  -std=c++11 \"C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\src.cxx\"\r\n\r\ncl : **command line warning D9002: ignoring unknown option '-std=c++11'** [C:\\workspace\\tensorflow\\build-tflite\\CMakeFiles\\CMakeTmp\\cmTC_94317.vcxproj]\r\n\r\nSource file was:\r\nint main(int argc, char* argv[]) { return (int)__builtin_expect(0, 0); }\r\n**Checking whether the ASM compiler is GNU using \"--version\" did not match \"(GNU assembler)|(GCC)|(Free Software Foundation)\":**\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.27.29111 for x86\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n\r\n\r\nThanks in advance, cheers!", "comments": ["Hi, I tried this and it works well on my side.\r\n\r\nI used CMake 3.20.0-rc2 and MSVC 19.27.29111.0.\r\nAlso I installed some necessary packages for TF build. https://www.tensorflow.org/install/source_windows\r\n\r\n```\r\nC:\\tensorflow\\tfbuild>cmake -A Win32 ..\\tensorflow\\lite -DTFLITE_ENABLE_XNNPACK=OFF\r\n-- Building for: Visual Studio 16 2019\r\n-- Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.\r\n-- The C compiler identification is MSVC 19.27.29111.0\r\n-- The CXX compiler identification is MSVC 19.27.29111.0\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x86/cl.exe - skipped\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/Hostx64/x86/cl.exe - skipped\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - not found\r\n-- Found Threads: TRUE\r\n```\r\n\r\nAnd I verified it's a 32bit binary.\r\n```\r\nC:\\tensorflow\\tfbuild>debug\\benchmark_model\r\nSTARTING!\r\nDuplicate flags: num_threads\r\nPlease specify the name of your TF Lite input file with --graph\r\nBenchmarking failed.\r\n\r\nC:\\tensorflow\\tfbuild>file debug\\benchmark_model.exe\r\ndebug\\benchmark_model.exe: PE32 executable (console) Intel 80386, for MS Windows\r\n```", "Thanks for your feedback @terryheo,\r\nfrom which branch/tag did you run this build?\r\n\r\nWill give it a new try next Monday and check if I missed any Windows dependency.\r\n\r\nCheers", "I used master branch.", "Indeed it works from master branch @terryheo\r\nIt only generates tensorflow-lite.lib though, for both x64 and x86 (Win32) \ud83d\ude22 \r\nI probably was not clear before, but my main issue is that I need to generate a Dynamic library for Win32 systems.\r\n\r\nI took a look at tensorflow/lite/CMakeLists;txt and forced to generate a shared line adding SHARED to line 371:\r\n`add_library(tensorflow-lite SHARED`\r\nI used this change to build a x64 dll and compare to the one built using Bazel.\r\nIt generated a dll but much smaller than the dll generate when using Bazel to build `//tensorflow/lite:tensorflowlite.dll`\r\nUsing Bazel the output dll has ~14Mb and ~30k exported symbols. The CMake output dll has ~3Mb and 33 exported symbols.\r\nApparently the CMake output does not contain the library dependencies. In fact when I tried to dynamically use it windows complained about Flatbuffers symbols that could not be located in the dynamic link library, and am using it the same way I do with Bazel output dll. \r\n\r\nThat's why I assume the dependencies are note being handled properly and will dig a bit deeper into this CMake build to compare the differences when building via Bazel, but would also appreciate any help or thoughts from your side. Again, Bazel would not help me to build it for Win32 systems \ud83d\ude22 \r\n\r\nI checked both dll dependencies using Dumpbin, the results follow:\r\n\r\n- CMake output dll:\r\n`>dumpbin /dependents tensorflow-lite.dll | findstr dll\r\nDump of file tensorflow-lite.dll\r\nKERNEL32.dll`\r\n- Bazel output dll:\r\n`>dumpbin /dependents tensorflowlite.dll | findstr dll\r\nDump of file tensorflow-lite.dll\r\nMSVCP140.dll\r\nKERNEL32.dll\r\nVCRUNTIME140.dll\r\nVCRUNTIME140_1.dll\r\napi-ms-win-crt-runtime-l1-1-0.dll\r\napi-ms-win-crt-math-l1-1-0.dll\r\napi-ms-win-crt-heap-l1-1-0.dll\r\napi-ms-win-crt-utility-l1-1-0.dll\r\napi-ms-win-crt-stdio-l1-1-0.dll\r\napi-ms-win-crt-string-l1-1-0.dll\r\napi-ms-win-crt-convert-l1-1-0.dll\r\napi-ms-win-crt-filesystem-l1-1-0.dll\r\napi-ms-win-crt-environment-l1-1-0.dll\r\napi-ms-win-crt-locale-l1-1-0.dll`\r\n\r\nI used DependencyWalker to get this screenshot:\r\n![image](https://user-images.githubusercontent.com/19482569/111505405-59808000-8727-11eb-9ece-13bc65480201.png)\r\n\r\n", "If you want to use a shared library, how about using C API?\r\nhttps://www.tensorflow.org/lite/guide/build_cmake#build_tensorflow_lite_c_library\r\n\r\nEven though you have a C++ standalone shared library, you might have trouble to collect all the necessary header files.\r\n(If you're not having a CMake project)\r\nIn this case, using C API is much easier.", "**About the C++ standalone shared library:** \r\nI reckon I got all the header files sorted since was able to build and run x64 version. My issue was building the shared library for x86.\r\n**About the C API:** \r\nIt's indeed a good suggestion, for now my use case is simple (load model, load input tensor, run inference and read output tensor), it should handle it. \r\n\r\nI did compile the C API using CMake and MSVC for x64 and Win32 (Debug and Release) but there is something wrong with the Win32 release build when it tries to build gemmlowp related code. I reckon it is the same issue I faced in the beginning when I raised this issue here. I just can not understand why it works for Win32 Debug builds, need to investigate further \ud83d\ude15 \r\n\r\n**Results** - TFLite C API (*.dll) Build: \r\n- MSVC x64 Release: \u2705 \r\n- MSVC x64 Debug: \u2705 \r\n- MSVC x86 Release: \u274c \r\n- MSVC x86 Debug: \u2705 \r\n\r\n**Output Error for Win32 Release build:**\r\n- \u03bb cmake -A Win32 ../tensorflow/lite/c \r\n(with or without -DTFLITE_ENABLE_XNNPACK=OFF)\r\n- \u03bb cmake --build . --config Release\r\n...\r\n  expand_dims.cc\r\n  fake_quant.cc\r\n  Generating Code...\r\nC:\\workspace\\tensorflow\\build-tflite\\gemmlowp\\internal\\output.h(176): fatal error C1001: Internal compiler error. [C:\\workspa\r\nce\\tensorflow\\build-tflite\\tensorflow-lite\\tensorflow-lite.vcxproj]\r\n  (compiler file 'd:\\agent\\_work\\7\\s\\src\\vctools\\Compiler\\Utc\\src\\p2\\main.c', line 195)\r\n   To work around this problem, try simplifying or changing the program near the locations listed above.\r\n  If possible please provide a repro here: https://developercommunity.visualstudio.com\r\n  Please choose the Technical Support command on the Visual C++\r\n   Help menu, or open the Technical Support help file for more information\r\n\r\nThe line 176 is the end of a gemmlowp enum, not sure what is causing this build error. I'm specially confused because the build works when it is a Debug build \ud83d\ude04 \r\nMy problem with Debug DLL is that the inference time ridiculously increased \ud83d\ude22 \r\n\r\n\r\n**To sum it up:**\r\nThanks @terryheo for the C API tip, it may make my life easier indeed.\r\nThe CMake build for C API with MSVC targetin Win32 still have an issue though.\r\nNot sure if the build issue should be addressed to TF team or to Gemmlowp team. Also, am not sure if it would even be considered to be fixed. The fix would help people trying to use TFLite on Win32 devices but probably that's a vast minority of TF users. Unfortunately, since my project is multi-platform and multi-arch, I'm one of those \ud83d\ude04 ", "> **About the C++ standalone shared library:**\r\n> I reckon I got all the header files sorted since was able to build and run x64 version. My issue was building the shared library for x86.\r\n> **About the C API:**\r\n> It's indeed a good suggestion, for now my use case is simple (load model, load input tensor, run inference and read output tensor), it should handle it.\r\n> \r\n> I did compile the C API using CMake and MSVC for x64 and Win32 (Debug and Release) but there is something wrong with the Win32 release build when it tries to build gemmlowp related code. I reckon it is the same issue I faced in the beginning when I raised this issue here. I just can not understand why it works for Win32 Debug builds, need to investigate further \r\n> \r\n> **Results** - TFLite C API (*.dll) Build:\r\n> \r\n> * MSVC x64 Release: white_check_mark\r\n> * MSVC x64 Debug: white_check_mark\r\n> * MSVC x86 Release: x\r\n> * MSVC x86 Debug: white_check_mark\r\n> \r\n> **Output Error for Win32 Release build:**\r\n> \r\n> * \u03bb cmake -A Win32 ../tensorflow/lite/c\r\n>   (with or without -DTFLITE_ENABLE_XNNPACK=OFF)\r\n> * \u03bb cmake --build . --config Release\r\n>   ...\r\n>   expand_dims.cc\r\n>   fake_quant.cc\r\n>   Generating Code...\r\n>   C:\\workspace\\tensorflow\\build-tflite\\gemmlowp\\internal\\output.h(176): fatal error C1001: Internal compiler error. [C:\\workspa\r\n>   ce\\tensorflow\\build-tflite\\tensorflow-lite\\tensorflow-lite.vcxproj]\r\n>   (compiler file 'd:\\agent_work\\7\\s\\src\\vctools\\Compiler\\Utc\\src\\p2\\main.c', line 195)\r\n>   To work around this problem, try simplifying or changing the program near the locations listed above.\r\n>   If possible please provide a repro here: https://developercommunity.visualstudio.com\r\n>   Please choose the Technical Support command on the Visual C++\r\n>   Help menu, or open the Technical Support help file for more information\r\n> \r\n> The line 176 is the end of a gemmlowp enum, not sure what is causing this build error. I'm specially confused because the build works when it is a Debug build \r\n> My problem with Debug DLL is that the inference time ridiculously increased \r\n> \r\n> **To sum it up:**\r\n> Thanks @terryheo for the C API tip, it may make my life easier indeed.\r\n> The CMake build for C API with MSVC targetin Win32 still have an issue though.\r\n> Not sure if the build issue should be addressed to TF team or to Gemmlowp team. Also, am not sure if it would even be considered to be fixed. The fix would help people trying to use TFLite on Win32 devices but probably that's a vast minority of TF users. Unfortunately, since my project is multi-platform and multi-arch, I'm one of those\r\n\r\nHi tcervi,\r\nI have the same issue when compile Release version(Win32) before. Now, I fixed the issues when use msvs to build. Change the default optimization option from O2 to O1 or disable the optimizaiton option. I think you can set optimization option use cmake command. Sorry to share the Chinese picture below, I haven't the English package. If you compile use msvs, you should change all the project in the solution from x64 to x86.\r\n![image](https://user-images.githubusercontent.com/22075829/116644764-d483ba00-a9a6-11eb-8532-4f650e446270.png)\r\n\r\n\r\n", "Hi @ruiyq, thanks for your comment, indeed your configuration works!\r\nWhen I searched for that  MSVC \"C1001: Internal compiler error.\" found [some information](https://docs.microsoft.com/en-us/cpp/error-messages/compiler-errors-1/fatal-error-c1001?view=msvc-160) about this error being usually linked to optimisation failure. I was planning to maybe generate a build repro and upload it for MSVC team, but was not investing that much time on this specific build and the simple change from \"/O2\" to \"/O1\", as you suggested, solved my issue. In my case the speed decrease is negligible. \r\nThanks again for sharing your experience!\r\n\r\n@terryheo since I was not using Visual Studio Code, instead was building from command line using cmake + msvc build tools (windows container), there was no gui for me to configure the build optimisation flags. I solved it by modifying the CMakeLists.txt: checking for MSVC-x86 builds and updating the optimisation flags accordingly. Do you think it is a valid PR?\r\nIf in the future the MSVC team fix something on their compiler and it becomes able to build tflite-c with \"/O2\", the code can be removed. Until there, anyone using MSVC to build for Win32 targets will not suffer with **THIS** build failure.\r\nI guess the main goal of Tensorflow Lite is the portability right?\r\n\r\nCheers", "Hi @tcervi I am also trying to build a shared tflite c library for x86 and ARM64. Using the fix you sent as a pull request, the build process gets completed successfully, But in the Release directory, only the .dll file generated(no .lib file). And the size of the .dll file is also too small (180 KB). \r\n\r\nI see that in one of the [comment ](https://github.com/tensorflow/tensorflow/issues/47166#issuecomment-801250436) above, you also encounter a similar issue for C++ builds. Are you able to get the \".lib\" file for C library build?\r\n\r\nThanks", "@Kartik14 did you follow \r\nhttps://www.tensorflow.org/lite/guide/build_cmake#build_tensorflow_lite_c_library ?", "Hi @terryheo Thanks for the quick response. I used slightly different commands, similar to @tcervi \r\n\r\n1) First I changed the **CMakeLists.txt** file in **tensorflow\\lite\\c** according to the pull request [here](https://github.com/tensorflow/tensorflow/pull/49171)\r\n\r\n2) Then I used the following two commands:\r\n\r\n`cmake -A Win32 -DCMAKE_BUILD_TYPE=Release -S ..\\tensorflow\\lite\\c -B .`\r\n`cmake --build . --config Release`\r\n\r\nIt generated a **tensorflowlite_c.dl**l file in the **Release** folder. But isn't it also supposed to create a **.lib** file (something like tensorflowlite_c.dll.if.lib) for use in some other project? I apologize if I am asking a wrong question since it is my first time trying to build a shared C library. \r\n\r\nThanks", "@Kartik14\r\nAs showed in the https://www.tensorflow.org/lite/guide/build_cmake#build_tensorflow_lite_c_library \r\ntensorflowlite_c.dll is the target binary you will use.\r\nIt doesn't generate lib file since it's difficult to use for 3rd party library dependency (without using CMake project).\r\n\r\nDo you have any issue on using the dll file?", "@terryheo \r\n\r\nI am using Visual Studio to build my other project (where I wish to use tflite). I am using steps described [here](https://docs.microsoft.com/en-us/cpp/build/walkthrough-creating-and-using-a-dynamic-link-library-cpp?view=msvc-160) to import the dll file in my project. But here they [add the lib file](https://docs.microsoft.com/en-us/cpp/build/walkthrough-creating-and-using-a-dynamic-link-library-cpp?view=msvc-160#to-add-the-dll-import-library-to-your-project) as additional dependencies.\r\n\r\nI tried to find if there was a way to use just the dll file, but [here](https://stackoverflow.com/questions/38336876/dont-know-how-to-load-and-use-dll-file-in-c) the user mentions:\r\n\r\n>Generally, the library will consist of a .lib file (for linking to your .exe), a .dll file (for dynamically linked code) and an include >folder with lots of .h files. You cannot use a .dll file on its own, you must have the headers and lib files.\r\n\r\nCan you please guide to some resource I can check out for importing the dll file.\r\n\r\nThanks", "Hi @Kartik14 \r\n\r\nI was not using Visual Studio, only building my library windows version with a combination of MSVC and CMake. And yes I used the built DLL (x86 release) along with my library and for my use it worked fine (model inferences).\r\nUsing the PR code I was able to build both .lib and .dll.\r\n\r\nPreviously, when I was building from commit [bf15757](https://github.com/tensorflow/tensorflow/commit/bf157579cf016bcd00e4d01956a0807a2ff6f608) + my PR code, MSVC was finishing the build with both .lib and .dll on the same dir. Recently (master branch up to date), not sure if it was a TF code update or MSVC version update, it started to release both files in separate dirs.\r\nI can't remember which sub directory now, but it should definitely be inside your build output dir. Anyways you can give a try on that commit SHA I linked and check the output as well.\r\n\r\nLast question: did you run the configuration script before building it? \r\nIf not, please check this link: https://www.tensorflow.org/install/source_windows", "Hi @tcervi, I was indeed able to build both x64 and x86 (dll and lib file) using the commit SHA you linked. Thanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47166\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47166\">No</a>\n", "Solved by: https://github.com/tensorflow/tensorflow/pull/49171", "Hello,\r\n\r\nI'm having the same problem. I follow the instructions on how to build the TFLite C API via CMake. The build succeeds and I have a .dll file, but no .lib is generated.\r\n\r\nTrying to trace the reason for it, it seems that the cause is TFL_STATIC_LIBRARY_BUILD being defined and thus interfering with the dllexport/dllimport definition in [c_api_types.h](https://github.com/tensorflow/tensorflow/blob/81f73e6812cf6a1fcecdd35a4bb19ae71eef5a54/tensorflow/lite/c/c_api_types.h#L34). If no symbol is exported in a dll, no .lib is generated.\r\n\r\nTracing back TFL_STATIC_LIBRARY_BUILD, I see that it is defined [here in the CMakeLists.txt in the lite root](https://github.com/tensorflow/tensorflow/blob/81f73e6812cf6a1fcecdd35a4bb19ae71eef5a54/tensorflow/lite/CMakeLists.txt#L452). The root CMakeLists.txt is included from the C API one [here](https://github.com/tensorflow/tensorflow/blob/81f73e6812cf6a1fcecdd35a4bb19ae71eef5a54/tensorflow/lite/c/CMakeLists.txt#L31). The flag that controls if the C API is built statically or dynamically is TFLITE_C_BUILD_SHARED_LIBS, but because BUILD_SHARED_LIBS itself is not defined when including the lite root, \"-DTFL_STATIC_LIBRARY_BUILD\" is added to the compilation flags.\r\n\r\nSetting BUILD_SHARED_LIBS to ON before importing the lite root dir leads to other issues (more dependencies are built as shared libs), but **adding to the test [here](https://github.com/tensorflow/tensorflow/blob/81f73e6812cf6a1fcecdd35a4bb19ae71eef5a54/tensorflow/lite/CMakeLists.txt#L451) a check for TFLITE_C_BUILD_SHARED_LIBS seems to obtain the desired effect** and I can build the C API outputting the necessary .lib file.\r\n\r\nIt seems it's still not the a self-contained library (I haven't figured out all the dependencies yet), but I believe this might still be useful to someone trying to debug this like I am at the moment.", "I can compile with te command below\r\n\r\nFor x64\r\nD:\\Downloads\\tensorflow-r2.6\\buildGui64>cmake ..\\tensorflow\\lite\\c -DTFLITE_ENABLE_XNNPACK=OFF -DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=True\r\n\r\nFor win32\r\nD:\\Downloads\\tensorflow-r2.6\\buildGui>cmake -A Win32 ..\\tensorflow\\lite\\c -DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=True -DTFLITE_ENABLE_XNNPACK=OFF\r\n\r\nAfter the cmake just run \" cmake --build . -j \" or open the visual studio 2019 to build. There should have a lib and dll in the folder. If you want to split the dll, just use \"-DBUILD_SHARED_LIBS=TRUE\" to replace the  \"-DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=True\"\r\n\r\nAlso, git clone command or some download protcess may fail. Rerun the cmake command may not try to download or clone again. You may need to FOCUS ON THE LOG and try to download or git clone manually to ensure the file have been download and extract in the right position. Maybe done it in midnight with a good network may make it easy. \r\n\r\nps: my computer: xps 2015 with win10, visual studio 2019, git, python 3.5, cmake 3.22.1, tensorflow source r2.6.", "Is there anyone has tensorflowlite_c.dll and tensorflowlite_c.dll.if.lib which can run under x86? I need it. I found x86_64 here: https://github.com/ValYouW/tflite-dist, but this cannot be used in X86 project in visual studio."]}, {"number": 47165, "title": "Update input parameter validation for advanced activation layers.", "body": "Added alpha/theta value validation on the ThresholdedReLU and PReLU layers, and updated the error messages raised on ThresholdedReLU, PReLU, and ELU. Also added test cases for these changes, and added stride validation in convolutional layers.", "comments": ["@amogh7joshi can you please check sanity build failures ?", "The LeakyReLU `alpha` value isn't supposed to be less than 0 but one of the primary test cases for it (see line 34 of https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/advanced_activations_test.py) uses a value of -1.\r\n\r\nNot sure if I should remove that test case or remove the error that looks for alpha <= 0. Let me know.", "@mattdangerw  Can you please take a look on the above comment from @amogh7joshi. Thanks!", "@amogh7joshi is correct that we should not have alpha < 0. We can just remove the `-1` from this list of alpha values to test on line 34. Shouldn't have been testing that anyway.\r\n\r\nThanks!", "@mattdangerw @gbaned, I will remove the test case then and we should be good to go from there. Thanks!", "@mattdangerw The build has broken again, but for a different reason unrelated to this pull request (it is in the bazel build files that the error is located). Is there any way to fix this?", "Can you try just syncing to the latest master? We may have had some build breakages earlier this week.", "It doesn't allow me to resync to any other branches, I think the checks will re-run if you re-approve the pull request though. I've re-requested a review. We can try that to see if it works.", "@amogh7joshi Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned The issue was with the line lengths on one of the tests, from what I gathered. That is fixed now, and hopefully that should resolve all build conflicts."]}, {"number": 47164, "title": "[XLA] More readable emitted LLVM code.", "body": "Sometimes use named llvm variable that match (or are close) to the name used in the hlo file. This greatly help find the relevant part of the code we want to investigate.\r\n\r\n@cheshire ", "comments": []}, {"number": 47163, "title": "Error while training a model using spark and elephas estimator- Please suggest", "body": "I am still getting the same error while executing on spark cluster \r\n\r\nestimator = ElephasEstimator()\r\nestimator.set_keras_model_config(model.to_yaml())\r\nestimator.set_optimizer_config(sgd_conf)\r\nestimator.set_mode(\"synchronous\")\r\nestimator.set_loss(\"mae\")\r\nestimator.set_metrics(['mse'])\r\nestimator.set_epochs(epochs)\r\nestimator.set_batch_size(batch_size)\r\nestimator.set_validation_split(0.1)\r\nestimator.set_categorical_labels(False)\r\npipeline = Pipeline(stages=[estimator])\r\nfitted_pipeline = pipeline.fit(df)\r\n\r\n<img width=\"633\" alt=\"Capture1\" src=\"https://user-images.githubusercontent.com/53963317/107957497-b3761480-6fc6-11eb-8247-e0ba551f10da.PNG\">\r\n<img width=\"751\" alt=\"Capture2\" src=\"https://user-images.githubusercontent.com/53963317/107957501-b53fd800-6fc6-11eb-9c2c-ce335eadfd9e.PNG\">\r\n\r\n", "comments": ["@snigdhasen,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", " @amahendrakar TF Version 2.2.0. dataset size is more than 150MB. Not able to attach here\r\nCode is below: \r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Activation\r\nfrom tensorflow.keras import optimizers\r\n\r\nfrom elephas.ml_model import ElephasEstimator\r\nfrom elephas.ml.adapter import to_data_frame\r\n\r\nfrom pyspark import SparkContext, SparkConf\r\nfrom pyspark.mllib.evaluation import RegressionMetrics\r\nfrom pyspark.ml import Pipeline\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.preprocessing import StandardScaler\r\ndata= pd.read_csv(\"/home/newbiggatcdh1/phd/LALR.csv\")\r\ndata[data[\"modelMag_u\"]==-9999]=np.nan\r\ndata[data[\"modelMag_g\"]==-9999]=np.nan\r\ndata[data[\"modelMag_r\"]==-9999]=np.nan\r\ndata[data[\"modelMag_i\"]==-9999]=np.nan\r\ndata[data[\"modelMag_z\"]==-9999]=np.nan\r\ndata[data[\"fiberMag_u\"]==-9999]=np.nan\r\ndata[data[\"fiberMag_g\"]==-9999]=np.nan\r\ndata[data[\"fiberMag_r\"]==-9999]=np.nan\r\ndata[data[\"fiberMag_i\"]==-9999]=np.nan\r\ndata[data[\"fiberMag_z\"]==-9999]=np.nan\r\ndata[data[\"dered_u\"]==-9999]=np.nan\r\ndata[data[\"dered_g\"]==-9999]=np.nan\r\ndata[data[\"dered_r\"]==-9999]=np.nan\r\ndata[data[\"dered_i\"]==-9999]=np.nan\r\ndata[data[\"dered_z\"]==-9999]=np.nan\r\ndata=data.dropna()\r\nprint(data.shape)\r\nprint(data.shape)\r\nprint(type(data))\r\ndata1=data.to_numpy()\r\nX=data1[:,0:32]\r\ny=data1[:,-1]\r\nprint(y)\r\nfrom sklearn.model_selection import train_test_split\r\nX_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.33)\r\nX_train = X_train.astype(\"float32\")\r\nX_test = X_test.astype(\"float32\")\r\nX_train /= 255\r\nX_test /= 255\r\nprint(X_train.shape[0], 'train samples')\r\nprint(X_test.shape[0], 'test samples')\r\nprint(type(X_train))\r\nfrom tensorflow.keras.models import Sequential\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.layers import Input, Dense\r\nfrom tensorflow.keras.layers import Dropout\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(512, input_shape=(X_train.shape[1],))) # shape[1] will be number of columns\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(512))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(512))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(512))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(1))\r\nmodel.add(Activation('linear'))\r\nconf = SparkConf().setAppName('Regression_Spark_MLP').setMaster('local[*]')\r\nsc = SparkContext(conf=conf)\r\ndf = to_data_frame(sc, X_train, y_train)\r\ntest_df = to_data_frame(sc, X_test, y_test)\r\nprint(type(df))\r\nopt = optimizers.Adam(learning_rate=0.05)\r\nsgd_conf = optimizers.serialize(opt)\r\nbatch_size = 256\r\nepochs = 10\r\nestimator = ElephasEstimator()\r\nestimator.set_keras_model_config(model.to_yaml())\r\nestimator.set_optimizer_config(sgd_conf)\r\nestimator.set_mode(\"synchronous\")\r\nestimator.set_loss(\"mae\")\r\nestimator.set_metrics(['mse'])\r\nestimator.set_epochs(epochs)\r\nestimator.set_batch_size(batch_size)\r\nestimator.set_validation_split(0.1)\r\nestimator.set_categorical_labels(False)\r\nimport timeit\r\npipeline = Pipeline(stages=[estimator])\r\nstart = timeit.default_timer()\r\nfitted_pipeline = pipeline.fit(df)\r\nstop = timeit.default_timer()\r\nexecution_time = (stop - start)/60\r\nprint(\"Program Executed in minutes \"+str(execution_time)) # It returns time in minutes", "@amahendrakar Please let me know if any update on this", "For reference, this appears to be the same as https://github.com/tensorflow/tensozflow/issues/37885\r\nBatchNormalization layers appear to not deserialise properly with pyyaml>5.1.\r\nI just tried in tensorflow 2.4.1 and the problem is still there. There should be instructions to reproduce this easily in the previous issue, but let me know if you would like me to test anything specific.", "@snigdhasen,\r\nOn running the code, I am facing an error stating `FileNotFoundError: [Errno 2] No such file or directory:'/home/newbiggatcdh1/phd/LALR.csv'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/506c3a9910d69a32be4216c0dd234a40/47163.ipynb#scrollTo=hmUnOeaAIRVX).\r\n\r\n\r\n\r\n> dataset size is more than 150MB. Not able to attach here\r\n\r\nIn this case, could you please upload the dataset to Google Drive and share it with us. Thanks!", "@amahendrakar \r\nPlease find attached dataset \r\nhttps://drive.google.com/file/d/1x94BgnF6gfabFqpHgKmfgT9gIsnNboGp/view?usp=sharing", "@snigdhasen,\r\nI did not face any errors while running the code with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/a3c7645acf43e03b36662a8c0bbe5455/47163-2-2.ipynb) and TF v2.3. \r\n\r\nWhereas with [TF v2.4](https://colab.research.google.com/gist/amahendrakar/73a845a7506035da518bbca8d46c687d/47163-2-4.ipynb#scrollTo=hmUnOeaAIRVX) and TF-nightly, the `pyspark` module throws an error stating `PicklingError: Could not serialize object: ValueError: Cell is empty`. Please check the linked gist for reference. \r\n\r\nCould you please run the code in a new virtual environment and check if you're facing the same issue. Thanks!", "@amahendrakar\r\nYes thanks.That issue got resolved now. But everytime the output is coming like this. For all object same value\r\n\r\n![image](https://user-images.githubusercontent.com/53963317/110797041-a9ca8e80-829e-11eb-9c9e-1d11d8f13dcd.png)\r\n ", "> Yes thanks.That issue got resolved now. But everytime the output is coming like this. For all object same value\r\n\r\n@snigdhasen,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. \r\n\r\nPlease feel free to close the issue if the original error is resolved. Thanks!\r\n", "Thanks for help.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47163\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47163\">No</a>\n"]}, {"number": 47160, "title": "Same dataset(180 GB), why training 1 epoch on 2 nodes(16 gpus) takes around 10 minutes, training on 4 nodes(32 gpus) only take 33 seconds?", "body": "# System Information:\r\nTensorFlow version (use command below): 2.1.1\r\nPython version: 3.7\r\nmpi/openmpi: 4.0.3-gnu-9.2.0\r\ncompiler/gnu/: 9.2.0\r\nCUDA version: 10.1.243\r\nGPU model and memory:  Tesla V100-SXM2-32GB\r\n\r\n\r\n# Description:\r\n\r\nI tested the code with multiple nodes in a cluster, and the training time for one epoch has sudden decrease when use 4 nodes, and I have no idea why it happens. The codes tries to read from 343 csv files(around 180 gb in total), and each csv file has 14406 records, each record has 4860 features, and 8 labels to be predicted. The 8 labels are numbers, thus it is a regression problem.\r\n\r\nHere is the code: \r\n\r\n\r\n# Code: \r\n```\r\nimport time\r\nimport pathlib\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout, Activation\r\nfrom tensorflow.keras.optimizers import SGD, RMSprop\r\nimport sys\r\nimport json\r\nimport os\r\nimport socket\r\nimport datetime\r\nimport math\r\nimport pathlib\r\n\r\ntf.random.set_seed(22)\r\n\r\nhostlist=sys.argv[1].split(',')\r\ncurrent_host=socket.gethostname()\r\nindex=hostlist.index(current_host)\r\n\r\nsimsInFile=14406\r\n\r\nverbose = index < 1\r\nnodes=[]\r\n\r\nfor host in hostlist:\r\n  nodes.append(host + ':2001')\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n  'cluster': {\r\n    'worker': nodes\r\n  },\r\n  'task': {'type': 'worker', 'index': index}\r\n})\r\nprint(os.environ['TF_CONFIG'])\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.AUTO)\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\nper_worker_batch_size = 512\r\nnum_workers = strategy.num_replicas_in_sync\r\nglobal_batch_size = per_worker_batch_size * num_workers\r\n\r\nnum_epochs = 1\r\n\r\ndef read_csv(line):\r\n  fields = tf.io.decode_csv(line, record_defaults=[tf.constant([], dtype=tf.float32)]*4869, field_delim=\",\")\r\n  label = tf.stack(fields[4861:4869])\r\n  label = tf.dtypes.cast(label, tf.dtypes.float32)\r\n  label = tf.reshape(label,[8])\r\n\r\n  features = tf.stack(fields[1:4861])\r\n  features = tf.dtypes.cast(features, tf.dtypes.float32)\r\n  features = tf.reshape(features,[10,486])\r\n\r\n  return features, label\r\n\r\ndef create_train_dataset(ds_files_, batch_size=global_batch_size, nr_epochs=num_epochs, buffer_size=10000):\r\n  dataset = ds_files_.interleave(lambda x:tf.data.TextLineDataset(x).skip(1))\r\n  dataset = dataset.map(read_csv, num_parallel_calls=AUTOTUNE)\r\n  dataset = dataset.cache()\r\n  dataset = dataset.shuffle(buffer_size=buffer_size)\r\n  dataset = dataset.repeat()\r\n  dataset = dataset.batch(batch_size)\r\n  dataset = dataset.prefetch(1)\r\n  return dataset\r\n\r\nlearning_rate = 1e-3\r\ntotal_epoch = 1\r\nds_files = tf.data.Dataset.list_files(xxx/*.csv')\r\nds_files = ds_files.shard(num_workers, index)\r\ntrain_dataset = create_train_dataset(ds_files)\r\n\r\ndef build_model():\r\n  return tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv1D(64,3,input_shape=(10, 486)),\r\n    tf.keras.layers.Conv1D(64,3),\r\n    tf.keras.layers.Dropout(0.3),\r\n    tf.keras.layers.MaxPooling1D(pool_size=2),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(100, activation='relu'),\r\n    tf.keras.layers.Dense(8)\r\n  ])\r\n\r\nwith strategy.scope():\r\n  model = build_model()\r\n  model.compile(optimizer=RMSprop(learning_rate), loss='mse')\r\n  start_time = datetime.datetime.now()\r\n  steps_epoch = 9651//num_workers\r\n  history = model.fit(train_dataset,steps_per_epoch = steps_epoch,epochs = num_epochs, verbose = 1)\r\n  print(\"Training Finished!\")\r\n\r\nos.environ.pop('TF_CONFIG', None)\r\n```\r\n\r\n", "comments": ["I found the reason:  the training time should exponentially decay as the number of GPUs increases"]}, {"number": 47159, "title": "TFL: Update detection_postprocess kernel", "body": "This change uses std::stable_sort instead of std::partial_sort for the case where std::partial_sort use the full range.\r\n\r\nThis is the case preventing bit-exactness between TFL and TFLM. Problem with std::partial_sort is that the order of equal elements is not guaranteed to be preserved. Potentially std::partial_sort should be totally replaced but leaving that for now.\r\n\r\nNext step would be to add a custom stable sort to TFLM, as std::stable_sort uses heap.\r\n\r\nThis progress towards: https://github.com/tensorflow/tensorflow/issues/47158\r\n", "comments": ["Some more context (from the TFLM team chatting with @mansnils, @freddan80 and the CMSIS-NN team):\r\n\r\nThe CMSIS-NN team has CI to make sure that the TFLM and TfLite kernels are bit exact and the use of std::partial sort has been preventing that for the detection_postprocess kernel.\r\n\r\nIf switching the lite implementation to use std::stable_sort is acceptable, then there is a path for the TFLM implementation to also be made bit exact.\r\n\r\nThe purpose of this PR is to make sure that such a change is ok for the TfLite kernel before going down the path of making a corresponding (but more involved) change to the TFLM kernel.", "> I profiled these changes internally & the latency seems fine, there is no noticable change.\r\n> \r\n> Will it be possible to add a test in detection_postprocess_test.cc to verify that sorting retains order?\r\n\r\n@mansnils, unfortunately this PR got merged before you likely had a chance to address this comment from @srjoglekar246. Can you please open a new PR with the requested test, if adding an isolated test case is feasible?", "@advaitjain @srjoglekar246 Yes I will open a new PR."]}, {"number": 47158, "title": "std::partial_sort in detection_postprocess kernel is not stable", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source): 5eac5b75b48232e93f2a96ed856131201cd2ae3c\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nstd::partial_sort in detection_postprocess kernel is not stable, i.e. the order of equal elements is not guaranteed to be preserved. The problem with this is that it is hard to be bit-exact between TFL and TFLM. At least when compiling TFLM with Arm clang.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["@mansnils We see that the PR  is merged ,Could you please let us know if we can close this issue ? Thanks!", "@sushreebarsa What is left is to update it on TFLM as well. But TFLM now has its own repo so maybe we should close this and create a new issue for TFLM.", "@mansnils Thank you for the update ! Please move this issue to closed status .Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47158\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47158\">No</a>\n"]}, {"number": 47157, "title": "Add the ability load specific weights with the tf.keras.Model.load_weights method", "body": "**System information**\r\n- **TensorFlow version (you are using):** 2.4.1\r\n**Are you willing to contribute it (~Yes~/No):** At the moment I'm a bit short on time, I might have time to do this in the future. This feature request is a way to check if there is enough support to implement it.\r\n\r\n\r\n**Describe the feature and the current behaviour/state.**\r\n\r\nCurrently the [tf.keras.Model.load_weights](https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights) method loads all the weights that are in a checkpoint. In my project, I want the user to have the ability to load only certain layers (weights) that are in a checkpoint. The user should be able to do this by supplying CLI arguments.\r\n\r\nCurrently, I achieve this behaviour by overloading the [tf.keras.Model.load_weights](https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights) method. I first store the old model state in this overloaded method before I call the `super().load_weights` method. After the weights are restored, I then overwrite the weights the user didn't want to load based on the old mode state. \r\n\r\nGiving Tensorflow users the ability to supply an `ignore_list`, for example, in the [CheckpointOptions](https://www.tensorflow.org/api_docs/python/tf/train/CheckpointOptions) object would ease this process.\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt would add a extra parameter to the [CheckpointOptions](https://www.tensorflow.org/api_docs/python/tf/train/CheckpointOptions) object and some additional code to the [tf.keras.Model.load_weights](https://www.tensorflow.org/api_docs/python/tf/keras/Model#load_weights) method in order to filter based on parameter names.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nI think it will ease the loading process for people that are using transfer learning. It would stop them from relying on workarounds as the one explained above. I am not sure how much work it is to implement such an addition, and if the work outweighs the benefits. I, therefore, opened this issue to see if other people also think this is helpful.", "comments": ["Thanks for the report! Team talked today, and we don't plan on adding functionality like that right now.\r\n\r\nThe main tool for transfer learning would be to nest models and/or layers and set `trainable=True/False` as desired. See https://keras.io/guides/transfer_learning.\r\n\r\nBeyond that, if you need more custom loading of weights, using `layer.set_weights` on the layers you want is the way to go. We want to move away from any whitelists/blacklists based on names, which can be brittle."]}, {"number": 47156, "title": "Mixed precision : Numerical instability with instance normalization layer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 4.0.0\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.1/8.0.5\r\n- GPU model and memory: Nvidia Quadro RTX 6000 ~ 23.8G\r\n\r\n**Describe the current behavior**\r\nI've developed a [WGAN-GP](http://arxiv.org/abs/1704.00028) model which uses some _Instance Normalization_ layers. The code I've written for _Instance Normalization_ is given above. Also I use mixed precision to speed up computations and save GPU memory. What I've observed by experimenting my model is that these normalization layers cause important numerical instability (gradient penalty goes up after hundreds of train steps) when their _dtype_ are left to mixed precision. Indeed, when I explicitly set the dtype to \"float32\" in the [parent constructor](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#arguments), I don't have these problems.\r\n\r\n\r\n**Describe the expected behavior**\r\nI don't understand why the normalization layers whose code is quite simple don't work well in mixed precision mode.\r\n\r\n**Standalone code to reproduce the issue**\r\nThere is no simple way to reproduce the issue, I just hope to have advises, suggestions or explanations to better understand this behavior.\r\n\r\n**Other info / logs** \r\n```\r\nclass InstanceNormalization(keras.layers.Layer):\r\n\r\n    def __init__(self, epsilon=1e-3, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.epsilon=epsilon\r\n\r\n    def build(self, batch_input_shape):\r\n        self.scale = self.add_weight(\r\n            name='scale',\r\n            shape=batch_input_shape[-1:],\r\n            initializer=tensorflow.random_normal_initializer(1,0.02),\r\n            trainable=True\r\n        )\r\n        self.offset = self.add_weight(\r\n            name='offset',\r\n            shape=batch_input_shape[-1:],\r\n            initializer=\"zeros\",\r\n            trainable=True\r\n        )\r\n        self.axis = range(1, len(batch_input_shape)-1)\r\n        super().build(batch_input_shape)\r\n\r\n    def call(self, x):\r\n        mean = keras.backend.mean(x, axis=self.axis, keepdims=True)\r\n        variance = keras.backend.mean(keras.backend.square(x-mean), axis=self.axis, keepdims=True)\r\n        normalized = (x - mean) / keras.backend.sqrt(variance+self.epsilon)\r\n        return self.scale * normalized + self.offset\r\n```\r\n", "comments": ["@RocaVincent,\r\nWithout a reproducible code it would be difficult for us to determine the source of the issue. \r\n\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here. Thanks!", "Hi @amahendrakar,\r\nAs I said in the first post, this issue is not reproducible with a minimal code. However, I can assure you that there is no training instability when I made this layers computing in float32 (this find took a long time). The results are clear and are very surprising because these layers are just a small part of my model. Therefore, I've shared the layer's code in the case you have any explanations concerning the bad results with mixed precision.\r\n\r\nHere is a typical example of the evolution of gradient penalties when I let the _InstanceNormalization_ layers in mixed precision (x axis represents epochs) :\r\n\r\n![instability](https://user-images.githubusercontent.com/18594965/108049030-0d6aee80-7048-11eb-86fd-401d6e88d881.png)\r\n", "@RocaVincent Can you please check whether this was an issue (regression) with earlier version like 2.3 or 2.4? thanks!", "For the nonfused cases, Tensorflow does both [BatchNormalization](https://github.com/tensorflow/tensorflow/blob/c20905d3da8027bb8cd1b2de71f266a64cd7d0fe/tensorflow/python/keras/layers/normalization.py#L783-L786) and [LayerNormalization](https://github.com/tensorflow/tensorflow/blob/c20905d3da8027bb8cd1b2de71f266a64cd7d0fe/tensorflow/python/keras/layers/normalization.py#L1236-L1238) in float32 internally. Other than variance overflowing, which results in NaNs, I am unsure if this needed and if so, why it needs to be float32. But the fact InstanceNormalization is running into issues indicates there is probably some underlying issue with normalization in float16.\r\n\r\n@RocaVincent I doubt variance is overflowing in this case since I've only observed this happen near the start of training, but if you want you can check with [`tf.debugging.check_numerics`](https://www.tensorflow.org/api_docs/python/tf/debugging/check_numerics). I suspect there is some other issue but unfortunately I don't know what it is.\r\n\r\n@nluehr do you know why InstanceNormalization would have issues in float16, and whether BatchNormalization and LayerNormalization would run into the same issue (other than variance overflowing)? Also, when fused, do you know what parts of cudnn's BatchNormalization are done in float32 and what parts are in float16? It would be nice to root cause this so we could give advice in the mixed precision documentation, or perhaps somehow give a warning/error in these cases.\r\n\r\n> @RocaVincent Can you please check whether this was an issue (regression) with earlier version like 2.3 or 2.4? thanks!\r\n\r\nI don't think this is necessary, since it's time consuming and I doubt any changes to TF would have caused this issue.\r\n\r\n", "@reedwm I just tested what you mention with *tf.debugging.check_numerics* and indeed variance overflowed quite quickly. It's certainly the cause of the GAN divergence even if this divergence happens only after lots of train steps.\r\n\r\n> Other than variance overflowing, which results in NaNs, I am unsure if this needed and if so,\r\n\r\nDo you think mean computation (not only in InstanceNormalization) can also product overflow ?", "Thank you for the update! I am unsure why the variance overflows quickly but the gradient penalty takes longer to diverge. It is possible that the NaN or Inf from the overflow is removed in a future layer, making all values finite and allowing the model to partially train. I am also currently unfamiliar with WGAN-GP and gradient penalty in general, so it could be something specific to how gradient penalty is computed.\r\n\r\n> Do you think mean computation (not only in InstanceNormalization) can also product overflow ?\r\n\r\nThe mean computation will not overflow, as the mean cannot possibly be larger in magnitude than the largest input value. However the [NVIDIA mixed precision guide](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html) claims both mean and variance should be in float32. I'm not sure why, but better to do mean in float32 to be safe, I think. @nluehr do you know why the NVIDIA guide recommends computation the mean in float32?\r\n", "The tests I have done for few days show that the mean computation may overflow (wheter with `keras.backend.mean` or `tensorflow.reduce_mean`), even if there is no overflow in the input. It's certainly due to the sum before division. It's a bad thing beacause all these casts to float32 and float16 (for every mean computation) dtype make the model much more heavier.", "@RocaVincent Is this still an issue for you? Can you please check with recent TF versions (`TF2.7` , `tf-nightly`) and let us know whether it is persisting with recent TF versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47156\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47156\">No</a>\n"]}, {"number": 47155, "title": "RuntimeError: Cannot use a constraint function on a sparse variable in google colab", "body": "I am trying to train my model using Keras and TensorFlow 2.x, while using the model.fit() method I ran into this error\r\n\r\nError\r\n\r\n```\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n\r\n<ipython-input-73-4871a80f91a3> in <module>()\r\n      2 \r\n      3 for i in range(N_epoch):\r\n----> 4     model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))\r\n      5     output = model.predict_proba(val_X, batch_size=10, verbose=1)\r\n      6     # find validation accuracy using the best threshold value t\r\n\r\n9 frames\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nRuntimeError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step\r\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:498 minimize\r\n        return self.apply_gradients(grads_and_vars, name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:635 apply_gradients\r\n        \"name\": name,\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2941 merge_call\r\n        return self._merge_call(merge_fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2948 _merge_call\r\n        return merge_fn(self._strategy, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:683 _distributed_apply  **\r\n        var, apply_grad_to_update_var, args=(grad,), group=False))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2494 update\r\n        return self._update(var, fn, args, kwargs, group)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3431 _update\r\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3437 _update_non_slot\r\n        result = fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:650 apply_grad_to_update_var  **\r\n        \"Cannot use a constraint function on a sparse variable.\")\r\n\r\n    RuntimeError: Cannot use a constraint function on a sparse variable.\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (Please find the code below)\r\n- OS Platform and Distribution: Mac OSX Big Sur\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): Tensorflow 2.2\r\n- Python version: Python 3.9.1\r\n\r\nCode is given below. [Link](https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb?usp=sharing) to the colab for full code. \r\n```\r\n\r\n# Train data preparation\r\nN = datasets[0].shape[0]\r\nconv_input_width = W.shape[1]\r\nconv_input_height = int(datasets[0].shape[1]-1)\r\n\r\n# For each word write a word index (not vector) to X tensor\r\ntrain_X = np.zeros((N, conv_input_height), dtype=np.int)\r\ntrain_Y = np.zeros((N, 2), dtype=np.int)\r\nfor i in range(N):\r\n    for j in range(conv_input_height):\r\n        train_X[i, j] = datasets[0][i, j]\r\n    \r\nprint ('train_X.shape = {}'.format(train_X.shape))\r\nprint ('train_Y.shape = {}'.format(train_Y.shape))\r\n\r\n# Validation data preparation\r\nNv = datasets[1].shape[0]\r\n\r\n# For each word write a word index (not vector) to X tensor\r\nval_X = np.zeros((Nv, conv_input_height), dtype=np.int)\r\nval_Y = np.zeros((Nv, 2), dtype=np.int)\r\nfor i in range(Nv):\r\n    for j in range(conv_input_height):\r\n        val_X[i, j] = datasets[1][i, j]\r\nprint('val_X.shape = {}'.format(val_X.shape))\r\nprint('val_Y.shape = {}'.format(val_Y.shape))\r\nfor i in range(Nv):\r\n    val_Y[i,data_train.iloc[i,3]] = 1\r\n\r\nfrom keras.optimizers import RMSprop\r\nfrom keras import backend\r\nbackend.set_image_data_format('channels_first')\r\nimport keras\r\n\r\n\r\n# Number of feature maps (outputs of convolutional layer)\r\nN_fm = 200\r\n# kernel size of convolutional layer\r\nkernel_size = 5\r\n\r\nmodel = Sequential()\r\n# Embedding layer (lookup table of trainable word vectors)\r\nmodel.add(Embedding(input_dim=W.shape[0], \r\n                    output_dim=W.shape[1], \r\n                    input_length=conv_input_height,\r\n                    weights=[W], \r\n                    embeddings_constraint=UnitNorm,\r\n                    name = 'e_l'))\r\n# Reshape word vectors from Embedding to tensor format suitable for Convolutional layer\r\nmodel.add(Reshape((1, conv_input_height, conv_input_width)))\r\n\r\n# first convolutional layer\r\nmodel.add(Convolution2D(N_fm,\r\n                        kernel_size, \r\n                        conv_input_width,\r\n                        kernel_initializer='random_uniform',\r\n                        padding='valid',\r\n                        kernel_regularizer=l2(0.001)))\r\n# ReLU activation\r\nmodel.add(Activation('relu'))\r\n\r\n# aggregate data in every feature map to scalar using MAX operation\r\nmodel.add(MaxPooling2D(pool_size=(conv_input_height+kernel_size+1,1), padding='same'))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dropout(0.4))\r\nmodel.add(Dense(128,kernel_initializer='random_uniform'))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.4))\r\n# Inner Product layer (as in regular neural network, but without non-linear activation function)\r\nmodel.add(Dense(2))\r\n# SoftMax activation; actually, Dense+SoftMax works as Multinomial Logistic Regression\r\nmodel.add(Activation('softmax'))\r\n\r\n# Custom optimizers could be used, though right now standard adadelta is employed\r\nopt = RMSprop(lr=0.001, rho=0.9, epsilon=None)\r\nmodel.compile(loss='mean_squared_error', \r\n              optimizer=opt,\r\n              metrics=['accuracy'])\r\n\r\n```\r\n\r\n**The line that throws the error**\r\n\r\n```\r\nN_epoch = 3\r\n\r\nfor i in range(N_epoch):\r\n    model.fit(x=train_X,y=train_Y,batch_size=32,epochs=10,verbose=1, validation_data=(val_X,val_Y))\r\n    output = model.predict_proba(val_X, batch_size=10, verbose=1)\r\n    # find validation accuracy using the best threshold value t\r\n    vacc = np.max([np.sum((output[:,1]>t)==(val_Y[:,1]>0.5))*1.0/len(output) for t in np.arange(0.0, 1.0, 0.01)])\r\n    # find validation AUC\r\n    vauc = roc_auc_score(val_Y, output)\r\n    val_acc.append(vacc)\r\n    val_auc.append(vauc)\r\n    print('Epoch {}: validation accuracy = {:.3%}, validation AUC = {:.3%}'.format(epoch, vacc, vauc))\r\n    epoch += 1\r\n    \r\nprint('{} epochs passed'.format(epoch))\r\nprint('Accuracy on validation dataset:')\r\nprint(val_acc)\r\nprint('AUC on validation dataset:')\r\nprint(val_auc)\r\n```\r\n\r\n**Tweaks I tried**\r\n1. I have tried changing the UnitNorm in the embedding layer\r\n2. Verified the embedding layer doesn't use sparse data. Instead, it uses a dense matrix to store that data.\r\n3.  Referred this [link](https://github.com/tensorflow/tensorflow/issues/33755) but couldn't solve my error.\r\n\r\n\r\nPlease can anyone suggest a solution? Thanks", "comments": ["@addy1997 \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/35b1ef8b9c1fdc4026ccca281a4e3b6d/untitled535.ipynb).", "@Saduf2019  Here's my colab [link](https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb?usp=sharing)\r\n\r\nfor uploading files \r\n\r\nessay.csv file link - https://github.com/addy1997/Task9-personality-prediction/blob/main/essays.csv\r\nlink to imdb-train-val-testN.pickle file - https://github.com/addy1997/Task9-personality-prediction/blob/main/imdb-train-val-testN.pickle", "@addy1997 \r\nI ran the code but face a truncating error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/d052e95c9655cb91d07e968da71d418c/untitled537.ipynb).", "> @addy1997\r\n> I ran the code but face a truncating error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/d052e95c9655cb91d07e968da71d418c/untitled537.ipynb).\r\n\r\nI uploaded the file and I don't get that truncating error - [gist](https://colab.research.google.com/gist/Saduf2019/d052e95c9655cb91d07e968da71d418c/untitled537.ipynb)", "@Saduf2019 were you able to get rid of the error?", "I am able to replicate the issue reported on 2.x, please find the [gist here for nightly](https://colab.research.google.com/gist/Saduf2019/a9b2237166d30c74ec55726e1dc2d52e/untitled542.ipynb), and[ tf 2.4](https://colab.research.google.com/gist/Saduf2019/7613f9b4953bccc5e38c3c4bf95c278a/untitled542.ipynb)", "> I am able to replicate the issue reported on 2.x, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a9b2237166d30c74ec55726e1dc2d52e/untitled542.ipynb).\r\n\r\nThat's great. Now, what do you suggest about the issue? What is to be done to solve it? @tensorflower-gardener can you suggest something on this?\r\n\r\n", "@addy1997 Is it possible to share a simple standalone code to reproduce the issue? Thanks!", "> @addy1997 Is it possible to share a simple standalone code to reproduce the issue? Thanks!\r\n\r\nSorry, it is not possible to provide a standalone code without loading files as I am performing text classification which requires the \".pickle\" file to be loaded.\r\n\r\nHere's the link to my [colab](https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb?usp=sharing) and link to the .pickle [file](https://github.com/addy1997/Task9-personality-prediction/blob/main/imdb-train-val-testN.pickle). ", "This is low priority for us right now, but please consider contributing a fix!", "> This is low priority for us right now, but please consider contributing a fix!\r\n\r\nThis is a new issue and really important part of my project. At least, can you give me some hint about how to tackle this @mattdangerw ? I have asked it on stackoverflow but they told me to raise an issue on github.", "Hi sorry for the quick reply above, was typing fast in our triage meeting.\r\n\r\nDug a little deeper. This looks like a duplicate of #33755\r\n\r\nI would suggest the [workaround here](https://github.com/tensorflow/tensorflow/issues/33755#issuecomment-708061069), can you see if this works for you?\r\n\r\nWe have also bumped up the priority for the #33755.\r\n\r\nThanks for bringing this up!", "> Hi sorry for the quick reply above, was typing fast in our triage meeting.\r\n> \r\n> Dug a little deeper. This looks like a duplicate of #33755\r\n> \r\n> I would suggest the [workaround here](https://github.com/tensorflow/tensorflow/issues/33755#issuecomment-708061069), can you see if this works for you?\r\n> \r\n> We have also bumped up the priority for the #33755.\r\n> \r\n> Thanks for bringing this up!\r\n\r\n@mattdangerw the workaround you suggested isn't working for my code. Here's the [colab](https://colab.research.google.com/drive/1nxjfPUWFWDW9jtoVK7AzKWuTT-C2o-Cb?usp=sharing)", "With the workaround, you should be removing any use of `embeddings_constraint` completely. You may need to switch to a functional model.\r\n\r\nThis is broken with #33755:\r\n```\r\nX = np.random.randint(100, size=(32, 10))\r\nY = np.ones((32, 1))\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Embedding(100, 8, input_length=10, embeddings_constraint=tf.keras.constraints.UnitNorm(axis=1)))\r\nmodel.add(tf.keras.layers.Dense(1))\r\nmodel.compile('rmsprop', 'mse')\r\nmodel.fit(X, Y)\r\n```\r\n\r\nThis should work:\r\n```\r\nX = np.random.randint(100, size=(32, 10))\r\nY = np.ones((32, 1))\r\ninput = tf.keras.Input(shape=(10,))\r\noutput = tf.keras.layers.Embedding(100, 8, input_length=10)(input)\r\noutput = tf.keras.constraints.UnitNorm(axis=1)(output)\r\noutput = tf.keras.layers.Dense(1)(output)\r\nmodel = tf.keras.Model(input, output)\r\nmodel.compile('rmsprop', 'mse')\r\nmodel.fit(X, Y)\r\n```\r\n\r\nFor updates on the main bug, follow #33755. This bug can be closed as a duplicate.", "@mattdangerw thanks a lot. I removed the embedding constraint and trained my model. It worked perfectly. [colab](https://colab.research.google.com/drive/1pbB3bcegg9eDaXnMpTS1Jhx4sYMIDTPQ?usp=sharing). \r\n\r\nThough the model overfits (validation acc.- 53% and accuracy= 0.9987%), I will try to optimize it. Thanks to @jvishnuvardhan and @Saduf2019 for their guidance. This bug was really important.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47155\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47155\">No</a>\n"]}]