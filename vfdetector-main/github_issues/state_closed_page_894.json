[{"number": 26660, "title": "GraphOptimizationPass(POST_PARTITIONING) after graph partition", "body": "There is difference about GraphOptimizationPass between DirectSession::CreateGraphs and ProcessFunctionLibraryRuntime::InstantiateMultiDevice.\r\nBecause **POST_REWRITE_FOR_EXEC** pass is missing in the ProcessFunctionLibraryRuntime::InstantiateMultiDevice, we can not apply the optimizations.\r\n\r\nThis PR adds the **POST_REWRITE_FOR_EXEC** pass to ProcessFunctionLibraryRuntime::InstantiateMultiDevice.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26660) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26660) for more info**.\n\n<!-- ok -->", "@iganichev \r\n\r\nThanks for the review.\r\nI fixed all issues you commented.\r\nCould you review the fixed code?", "Changes are merged, closing this issue "]}, {"number": 26659, "title": "how to enable gpu_options properties when in eager distributed execution of multi-gpus", "body": "I use MirroredStrategy to create distributed execution. And I use the ConfigProto to set gpu_options.allow_growth and set to tf.enable_eager_execution(config=config). However after I run the distributed code in eager mode, my 4 gpus in the same machine are allocated all their memory. It seems that the  gpu_options does not work.\r\n\r\nI use tensorflow1.12 and python3.6.", "comments": ["I believe it's something the team is working on. See #25446 for details.\r\n\r\nEDIT: there seems to be a fix b29b3f5. Could you try the nightly version?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "A number of new API were added in `tf.config` namespace to support this use case. Please let me know if there is anything we missed regarding this specific issue."]}, {"number": 26658, "title": "Dataset object is not an iterator, although I can iterate on it.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Archlinux\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-dev20190312\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: 1080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\n> TypeError: 'DatasetV1Adapter' object is not an iterator\r\n\r\n**Describe the expected behavior**:\r\n\r\nShould fetch the first element of the iterator, thus print 10.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef real_gen():\r\n    for _ in range(10):\r\n        yield 10.0\r\n\r\ndataset = tf.data.Dataset.from_generator(real_gen, (tf.float32))\r\n# Fails\r\nprint(next(dataset))\r\n```\r\n\r\nSince I can iterate on the dataset using a for loop\r\n\r\n```python\r\n# It works\r\nfor real in dataset:\r\n    print(real)\r\n```\r\n\r\nI do expect I can treat the dataset as an iterator, thus extracting the next element by calling `next(dataset)`.\r\n\r\n", "comments": ["A Dataset is not the same thing as an iterators, so this is expected behavior. You can think of a TensorFlow iterator as the combination of a Dataset **and** a current position in that Dataset.\r\n\r\nYou can create an iterator from a dataset using `iter(dataset)`, so the following code should work (in TensorFlow 2.0, or with eager execution enabled):\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef real_gen():\r\n    for _ in range(10):\r\n        yield 10.0\r\n\r\ndataset = tf.data.Dataset.from_generator(real_gen, tf.float32)\r\niterator = iter(dataset)\r\nprint(next(iterator))\r\n```", "Hi @mrry and thank you for the quick response.\r\n\r\nI understand a dataset is not the same thing as an iterator and I'll use your solution to convert the dataset to a Python iterator when working in eager mode.\r\n\r\nHowever, I found a (related?) issue when wrapping a dataset into a `tf.function`.\r\n\r\nA code that loops using Tensorflow primitives (like `for i in tf.range(10)`) can be converted into its graph representation without any problem, while a code that creates a python iterator from a dataset object (like you suggested, using `iter(dataset)`) can't.\r\n\r\nMoreover, maybe because we are in the early stage of the development, I'm unable to convert a loop that loops over a dataset to its graph representation.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef real_gen():\r\n    for i in range(10):\r\n        yield i\r\n\r\ndataset = tf.data.Dataset.from_generator(real_gen, (tf.float32))\r\n\r\n@tf.function\r\ndef itertest():\r\n    tf.print(next(iter(dataset)))\r\nitertest()\r\n\r\n@tf.function\r\ndef loopiter():\r\n    for real in dataset:\r\n        tf.print(real)\r\nloopiter()\r\n```\r\n\r\nThe `itertest()` call fails because `RuntimeError: dataset.__iter__() is only supported when eager execution is enabled.`\r\n\r\nWhile the `loopiter()` call fails because `tensorflow.python.framework.errors_impl.NotFoundError: Function __inference_Dataset_flat_map_flat_map_fn_22 is not defined.\r\n         [[{{node ReduceDataset}}]] [Op:__inference_loopiter_35]`\r\n\r\nShould I open a new issue for this or it is a known and desired behavior?", "I'm going to create a new issue", "have a similar issue when trying to add breakpoints on preprocess( ) here, the code wont go inside, tried changing the .map into a for loop but doesnt have iter object, tried to loop an iter(mnist_train) but couldnt either cause iter only allowed inside tf.function when eager execution is enabled...\r\n\r\n```\r\ndef preprocess(item):\r\n    image = item['image']\r\n    label = item['label']\r\n    image = tf.image.convert_image_dtype(\r\n        image, tf.float32)\r\n    image = tf.reshape(image, (-1,))\r\n\r\n    return {'image-pixels':image}, label[..., tf.newaxis]\r\n\r\n\r\ndef train_input_fn():\r\n    datasets = tfds.load(name='mnist')\r\n    mnist_train = datasets['train']\r\n\r\n    dataset = mnist_train.map(preprocess)\r\n    dataset = dataset.shuffle(BUFFER_SIZE)\r\n    dataset = dataset.batch(BATCH_SIZE)\r\n    return dataset.repeat()\r\n```\r\n\r\nstopped inside train_input, checked if eager execution was on, returned false, tried enabling it via compat, still was returning false from within, tried decorating with tf.function etc... in the end i removed the input f out of the function, placed it on the outside and iterated from there, this function was originally called by an estimator.train(), kinda of a crappy solution, but i can finally peek inside\r\n\r\n```\r\ndef preprocess(item):\r\n    image = item['image']\r\n    label = item['label']\r\n    image = tf.image.convert_image_dtype(\r\n        image, tf.float32)\r\n    image = tf.reshape(image, (-1,))\r\n\r\n    return {'image-pixels':image}, label[..., tf.newaxis]\r\n\r\ndatasets = tfds.load(name='mnist')\r\nmnist_train = datasets['train']\r\n\r\nfor foo in mnist_train:\r\n    preprocess(foo)\r\n```"]}, {"number": 26657, "title": "Session.run() doesn't accepts string of image bytes(2nd Parameter), as it usually does", "body": "*System information**\r\n- Os Ubuntu \r\n- Tensorflow 1.13.1\r\n- Python 2.7\r\nCode:\r\n`image_data = tf.gfile.FastGFile(image_path, 'rb').read()`\r\n`prediction = sess.run('final_result:0', {'Placeholder:0': image_data})`\r\n\r\nError:\r\n`could not convert string to float`", "comments": ["@AnandAron Could you provide a code to reproduce the bug? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26657\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26657\">No</a>\n"]}, {"number": 26656, "title": "tensorflow serving embedding get Truncate\uff1f", "body": "NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: embedding_1/Cast = Cast[DstT=DT_INT32, SrcT=DT_FLOAT, Truncate=false, _output_shapes=[[?,15]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_1_0_0). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).%0A%09 [[Node: embedding_1/Cast = Cast[DstT=DT_INT32, SrcT=DT_FLOAT, Truncate=false, _output_shapes=[[?,15]], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_1_0_0)]]|", "comments": ["This issue is more appropriate on TensorFlow Serving repo. Please post it on [TF Serving](https://github.com/tensorflow/serving/issues) from here. \r\n Thanks!"]}, {"number": 26655, "title": "TF Lite is_hybrid_op check move to util", "body": "is_hybrid_op generic check move to kernel_util file (ToDo activity).", "comments": ["@haozha111 \r\n\r\nThanks for review comments, handle the comments , please have check one more time, TIA!"]}, {"number": 26654, "title": "TF Lite ambiguous overload fix", "body": "Ambiguous call overload compilation fix changes.", "comments": []}, {"number": 26653, "title": "Multi-GPU workstation crashes during tf.Session()", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):`Linux 5.0.0-arch1-1-ARCH #1 SMP PREEMPT Mon Mar 4 14:11:43 UTC 2019 x86_64 GNU/Linux`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None\r\n- TensorFlow installed from (source or binary):`community python-tensorflow-opt-cuda`\r\n- TensorFlow version (use command below):`1.13.1`\r\n- Python version:`3.7.2`\r\n- Bazel version (if compiling from source):None\r\n- GCC/Compiler version (if compiling from source):None\r\n- CUDA/cuDNN version:`V10.0.130` / `7.5.0`\r\n- GPU model and memory: 2 x `Geforce GTX 1080 Ti 11GB`; Driver Version: `418.43`\r\n\r\n**Describe the current behavior**\r\nThe workstation completely crashes if a `tf.Session()` is created when multiple GPUs are present.\r\n\r\nI will roll back the last driver updates and post any updates.\r\nNot sure if this is an error tensorflow can fix, maybe it is just a faulty driver.\r\n\r\n**Describe the expected behavior**\r\nWorkstation should not crash.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nimport tensorflow as tf\r\ns = tf.Session()\r\n```\r\nor, in short\r\n`python -c \"import tensorflow as tf; s = tf.Session()\"`\r\nthe following line crashes as well\r\n`CUDA_VISIBLE_DEVICES=\"0,1\" python -c \"import tensorflow as tf; s = tf.Session()\"`\r\n\r\n**Other info / logs**\r\nThe Problem exists only if multiple GPUs are present, so the following code works as expected:\r\n- `CUDA_VISIBLE_DEVICES=\"\" python -c \"import tensorflow as tf; s = tf.Session()\"`\r\n```\r\n2019-03-13 09:49:14.192325: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3193000000 Hz\r\n2019-03-13 09:49:14.193496: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f504e31540 executing computations on platform Host. Devices:\r\n2019-03-13 09:49:14.193508: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-13 09:49:14.201742: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2019-03-13 09:49:14.201756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: ***\r\n2019-03-13 09:49:14.201773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: ***\r\n2019-03-13 09:49:14.201820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 418.43.0\r\n2019-03-13 09:49:14.201833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.43.0\r\n2019-03-13 09:49:14.201837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 418.43.0\r\n```\r\n- `CUDA_VISIBLE_DEVICES=\"0\" python -c \"import tensorflow as tf; s = tf.Session()\"`\r\n```\r\n2019-03-13 09:50:13.918948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3193000000 Hz\r\n2019-03-13 09:50:13.919562: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55be94d7cdb0 executing computations on platform Host. Devices:\r\n2019-03-13 09:50:13.919598: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-13 09:50:14.009982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-13 09:50:14.010633: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55be949e86f0 executing computations on platform CUDA. Devices:\r\n2019-03-13 09:50:14.010646: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-03-13 09:50:14.011034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.32GiB\r\n2019-03-13 09:50:14.011044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-13 09:50:14.778440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-13 09:50:14.778463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-13 09:50:14.778467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-13 09:50:14.778759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9970 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n```\r\n- `CUDA_VISIBLE_DEVICES=\"1\" python -c \"import tensorflow as tf; s = tf.Session()\"`\r\n```\r\n2019-03-13 09:50:19.398946: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3193000000 Hz\r\n2019-03-13 09:50:19.400142: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55eb2ee074e0 executing computations on platform Host. Devices:\r\n2019-03-13 09:50:19.400177: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-13 09:50:19.480237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-13 09:50:19.480807: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55eb2e7cc660 executing computations on platform CUDA. Devices:\r\n2019-03-13 09:50:19.480820: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-03-13 09:50:19.481144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.77GiB\r\n2019-03-13 09:50:19.481169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-13 09:50:19.790419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-13 09:50:19.790445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-13 09:50:19.790464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-13 09:50:19.790752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10411 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n```\r\n\r\nI ran the code on a different machine with only one GPU and it worked just fine.\r\n```\r\n2019-03-13 09:55:10.169250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n2019-03-13 09:55:10.193346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3801830000 Hz\r\n2019-03-13 09:55:10.194746: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55667abb6310 executing computations on platform Host. Devices:\r\n2019-03-13 09:55:10.194784: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-13 09:55:10.992667: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55667bfd5a40 executing computations on platform CUDA. Devices:\r\n2019-03-13 09:55:10.992720: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5\r\n2019-03-13 09:55:10.994345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77\r\npciBusID: 0000:65:00.0\r\ntotalMemory: 23.62GiB freeMemory: 23.45GiB\r\n2019-03-13 09:55:10.994378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-13 09:55:11.302104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-13 09:55:11.302139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-13 09:55:11.302143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-13 09:55:11.302652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22722 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)\r\n```", "comments": ["@davidenunes mentions the same issue in https://github.com/tensorflow/tensorflow/issues/18652#issuecomment-471356680, where downgrading the nvidia package to `415.27` and linux kernel to `4.20.11` solved the issue.", "I was able to get some detailed error logs \r\n\r\n```\r\nMar 13 10:58:49.229631 myhostname kernel: nvidia-uvm: Loaded the UVM driver in 8 mode, major device number 236\r\nMar 13 10:58:49.947274 myhostname kernel: BUG: unable to handle kernel NULL pointer dereference at 0000000000000040\r\nMar 13 10:58:49.947376 myhostname kernel: #PF error: [normal kernel read fault]\r\nMar 13 10:58:49.958319 myhostname kernel: PGD 8000000fd71fa067 P4D 8000000fd71fa067 PUD 0 \r\nMar 13 10:58:49.958392 myhostname kernel: Oops: 0000 [#1] PREEMPT SMP PTI\r\nMar 13 10:58:49.958413 myhostname kernel: CPU: 9 PID: 1208 Comm: python Tainted: P           OE     5.0.0-arch1-1-ARCH #1\r\nMar 13 10:58:49.958427 myhostname kernel: Hardware name: Gigabyte Technology Co., Ltd. Z370 AORUS Gaming 7/Z370 AORUS Gaming 7, BIOS F5l 01/10/2018\r\nMar 13 10:58:49.958441 myhostname kernel: RIP: 0010:nv_dma_map_peer+0xd0/0x160 [nvidia]\r\nMar 13 10:58:49.958453 myhostname kernel: Code: ce e8 b4 fd ff ff 48 8b 5c 24 10 65 48 33 1c 25 28 00 00 00 0f 85 8e 00 00 00 48 83 c4 18 5b 5d 41 5c c3 48 8b 05 78 dc 7e f6 <48> 83 78 40 00 75 ca 49 c1 e2 06 49 8b 78 10 48 89 e6 4b 8d 94 10\r\nMar 13 10:58:49.958465 myhostname kernel: RSP: 0018:ffffbb9c52edf9a0 EFLAGS: 00010246\r\nMar 13 10:58:49.958477 myhostname kernel: RAX: 0000000000000000 RBX: ffff998fe5fd08f0 RCX: 0000000000000010\r\nMar 13 10:58:49.958489 myhostname kernel: RDX: 0000000000000001 RSI: ffff99900888f000 RDI: ffff99900888c800\r\nMar 13 10:58:49.958500 myhostname kernel: RBP: 00000000d0000000 R08: ffff9990173f0000 R09: 00000000dfffffff\r\nMar 13 10:58:49.958512 myhostname kernel: R10: 0000000000000001 R11: 0000000000010000 R12: 00000000d0000000\r\nMar 13 10:58:49.958525 myhostname kernel: R13: ffff99900888f000 R14: 000000000888c800 R15: ffff998fe5fd08c8\r\nMar 13 10:58:49.958537 myhostname kernel: FS:  00007f10ab1f8600(0000) GS:ffff99901ea40000(0000) knlGS:0000000000000000\r\nMar 13 10:58:49.958548 myhostname kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nMar 13 10:58:49.958560 myhostname kernel: CR2: 0000000000000040 CR3: 0000000fdf7f8001 CR4: 00000000003606e0\r\nMar 13 10:58:49.958572 myhostname kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\nMar 13 10:58:49.958582 myhostname kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\nMar 13 10:58:49.958594 myhostname kernel: Call Trace:\r\nMar 13 10:58:49.958604 myhostname kernel:  _nv029594rm+0x265/0x490 [nvidia]\r\nMar 13 10:58:49.958615 myhostname kernel:  ? _nv025108rm+0x17c/0x3f0 [nvidia]\r\nMar 13 10:58:49.958625 myhostname kernel:  ? _nv026018rm+0xd7/0x270 [nvidia]\r\nMar 13 10:58:49.958636 myhostname kernel:  ? _nv010042rm+0x122/0x1b0 [nvidia]\r\nMar 13 10:58:49.958646 myhostname kernel:  ? _nv010038rm+0xc7/0x300 [nvidia]\r\nMar 13 10:58:49.958656 myhostname kernel:  ? _nv009772rm+0x2a2/0x770 [nvidia]\r\nMar 13 10:58:49.958671 myhostname kernel:  ? _nv009773rm+0x2a1/0x500 [nvidia]\r\nMar 13 10:58:49.958683 myhostname kernel:  ? _nv029782rm+0x367/0x870 [nvidia]\r\nMar 13 10:58:49.958694 myhostname kernel:  ? _nv003494rm+0x4e/0x70 [nvidia]\r\nMar 13 10:58:49.958705 myhostname kernel:  ? _nv004154rm+0xd9/0x180 [nvidia]\r\nMar 13 10:58:49.958715 myhostname kernel:  ? _nv032625rm+0x48/0x90 [nvidia]\r\nMar 13 10:58:49.958726 myhostname kernel:  ? _nv006068rm+0x1ca/0x350 [nvidia]\r\nMar 13 10:58:49.958736 myhostname kernel:  ? _nv033934rm+0x3cc/0x5e0 [nvidia]\r\nMar 13 10:58:49.958747 myhostname kernel:  ? _nv033933rm+0x98/0xf0 [nvidia]\r\nMar 13 10:58:49.958758 myhostname kernel:  ? _nv032726rm+0xfc/0x270 [nvidia]\r\nMar 13 10:58:49.958770 myhostname kernel:  ? _nv032727rm+0x53/0x80 [nvidia]\r\nMar 13 10:58:49.958781 myhostname kernel:  ? _nv007017rm+0x4b/0x80 [nvidia]\r\nMar 13 10:58:49.958791 myhostname kernel:  ? _nv000935rm+0x46e/0x900 [nvidia]\r\nMar 13 10:58:49.958822 myhostname kernel:  ? _raw_spin_unlock_irqrestore+0x20/0x40\r\nMar 13 10:58:49.958834 myhostname kernel:  ? rm_ioctl+0x54/0xb0 [nvidia]\r\nMar 13 10:58:49.958843 myhostname kernel:  ? filemap_map_pages+0x185/0x380\r\nMar 13 10:58:49.958855 myhostname kernel:  ? nvidia_ioctl+0xb0/0x7c0 [nvidia]\r\nMar 13 10:58:49.958867 myhostname kernel:  ? nvidia_ioctl+0x5f0/0x7c0 [nvidia]\r\nMar 13 10:58:49.958877 myhostname kernel:  ? nvidia_frontend_unlocked_ioctl+0x3a/0x50 [nvidia]\r\nMar 13 10:58:49.958887 myhostname kernel:  ? do_vfs_ioctl+0xa4/0x630\r\nMar 13 10:58:49.958896 myhostname kernel:  ? handle_mm_fault+0x10a/0x250\r\nMar 13 10:58:49.958908 myhostname kernel:  ? ksys_ioctl+0x60/0x90\r\nMar 13 10:58:49.958918 myhostname kernel:  ? __x64_sys_ioctl+0x16/0x20\r\nMar 13 10:58:49.958929 myhostname kernel:  ? do_syscall_64+0x5b/0x170\r\nMar 13 10:58:49.958941 myhostname kernel:  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9\r\nMar 13 10:58:49.958952 myhostname kernel: Modules linked in: nvidia_uvm(OE) ipt_MASQUERADE nf_conntrack_netlink nfnetlink xfrm_user xfrm_algo iptable_nat nf_nat_ipv4 xt_addrtype iptable_filter xt_conntrack nf_nat nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 libcrc32c br_netfilter bridge stp llc mousedev hid_logitech_hidpp joydev input_leds hid_logitech_dj overlay hid_generic usbhid hid nvidia_drm(POE) nvidia_modeset(POE) snd_hda_codec_hdmi uas usb_storage nvidia(POE) intel_rapl x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass drm_kms_helper snd_hda_codec_realtek crct10dif_pclmul snd_hda_codec_generic drm ledtrig_audio crc32_pclmul ghash_clmulni_intel snd_hda_intel snd_hda_codec agpgart ipmi_devintf ipmi_msghandler snd_hda_core syscopyarea sysfillrect sysimgblt fb_sys_fops snd_hwdep iTCO_wdt iTCO_vendor_support aesni_intel wmi_bmof mxm_wmi intel_wmi_thunderbolt snd_pcm aes_x86_64 crypto_simd cryptd snd_timer glue_helper intel_cstate snd e1000e mei_me mei soundcore alx intel_uncore mdio i2c_i801\r\nMar 13 10:58:49.958976 myhostname kernel:  pcspkr intel_rapl_perf evdev mac_hid wmi pcc_cpufreq crypto_user ip_tables x_tables ext4 crc32c_generic crc16 mbcache jbd2 fscrypto sr_mod cdrom sd_mod ahci libahci libata xhci_pci crc32c_intel xhci_hcd scsi_mod\r\nMar 13 10:58:49.958989 myhostname kernel: CR2: 0000000000000040\r\nMar 13 10:58:49.958999 myhostname kernel: ---[ end trace b892d5812d52b5d5 ]---\r\nMar 13 10:58:49.959010 myhostname kernel: RIP: 0010:nv_dma_map_peer+0xd0/0x160 [nvidia]\r\nMar 13 10:58:49.959021 myhostname kernel: Code: ce e8 b4 fd ff ff 48 8b 5c 24 10 65 48 33 1c 25 28 00 00 00 0f 85 8e 00 00 00 48 83 c4 18 5b 5d 41 5c c3 48 8b 05 78 dc 7e f6 <48> 83 78 40 00 75 ca 49 c1 e2 06 49 8b 78 10 48 89 e6 4b 8d 94 10\r\nMar 13 10:58:49.959031 myhostname kernel: RSP: 0018:ffffbb9c52edf9a0 EFLAGS: 00010246\r\nMar 13 10:58:49.959044 myhostname kernel: RAX: 0000000000000000 RBX: ffff998fe5fd08f0 RCX: 0000000000000010\r\nMar 13 10:58:49.959054 myhostname kernel: RDX: 0000000000000001 RSI: ffff99900888f000 RDI: ffff99900888c800\r\nMar 13 10:58:49.959065 myhostname kernel: RBP: 00000000d0000000 R08: ffff9990173f0000 R09: 00000000dfffffff\r\nMar 13 10:58:49.959075 myhostname kernel: R10: 0000000000000001 R11: 0000000000010000 R12: 00000000d0000000\r\nMar 13 10:58:49.959085 myhostname kernel: R13: ffff99900888f000 R14: 000000000888c800 R15: ffff998fe5fd08c8\r\nMar 13 10:58:49.959097 myhostname kernel: FS:  00007f10ab1f8600(0000) GS:ffff99901ea40000(0000) knlGS:0000000000000000\r\nMar 13 10:58:49.959107 myhostname kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nMar 13 10:58:49.959118 myhostname kernel: CR2: 0000000000000040 CR3: 0000000fdf7f8001 CR4: 00000000003606e0\r\nMar 13 10:58:49.959128 myhostname kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\nMar 13 10:58:49.959138 myhostname kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\n```\r\n\r\nHere is a nvidia-smi call after the crash\r\n\r\n```\r\nMar 13 11:01:55.588061 myhostname kernel: BUG: unable to handle kernel paging request at ffffbb9c52edfdb8\r\nMar 13 11:01:55.588156 myhostname kernel: #PF error: [normal kernel read fault]\r\nMar 13 11:01:55.594782 myhostname kernel: PGD 101e536067 P4D 101e536067 PUD 101e537067 PMD ffb0c6067 PTE 0\r\nMar 13 11:01:55.594839 myhostname kernel: Oops: 0000 [#2] PREEMPT SMP PTI\r\nMar 13 11:01:55.594871 myhostname kernel: CPU: 4 PID: 1334 Comm: nvidia-smi Tainted: P      D    OE     5.0.0-arch1-1-ARCH #1\r\nMar 13 11:01:55.594883 myhostname kernel: Hardware name: Gigabyte Technology Co., Ltd. Z370 AORUS Gaming 7/Z370 AORUS Gaming 7, BIOS F5l 01/10/2018\r\nMar 13 11:01:55.594895 myhostname kernel: RIP: 0010:_nv006968rm+0x2c/0x330 [nvidia]\r\nMar 13 11:01:55.594907 myhostname kernel: Code: 48 85 d2 74 07 48 63 47 08 48 01 d0 48 8b 17 48 85 d2 75 16 e9 9d 02 00 00 0f 1f 44 00 00 48 8b 4a 10 48 85 c9 74 17 48 89 ca <48> 39 32 77 ef 0f 83 29 02 00 00 48 8b 4a 18 48 85 c9 75 e9 48 89\r\nMar 13 11:01:55.594920 myhostname kernel: RSP: 0018:ffffbb9c462bfd30 EFLAGS: 00010086\r\nMar 13 11:01:55.594932 myhostname kernel: RAX: ffffbb9c462bfdb8 RBX: ffffbb9c462bfd60 RCX: 0000000000000000\r\nMar 13 11:01:55.594942 myhostname kernel: RDX: ffffbb9c52edfdb8 RSI: 0000000000000536 RDI: ffffffffc21bd2d8\r\nMar 13 11:01:55.594953 myhostname kernel: RBP: ffff998fc11baff0 R08: 0000000000000048 R09: 0000000000000060\r\nMar 13 11:01:55.594964 myhostname kernel: R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000\r\nMar 13 11:01:55.594975 myhostname kernel: R13: ffff998fe897dd20 R14: 000000000000001f R15: 0000000000000048\r\nMar 13 11:01:55.594987 myhostname kernel: FS:  00007fed23e5fb80(0000) GS:ffff99901e900000(0000) knlGS:0000000000000000\r\nMar 13 11:01:55.594997 myhostname kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nMar 13 11:01:55.595011 myhostname kernel: CR2: ffffbb9c52edfdb8 CR3: 0000001017b90003 CR4: 00000000003606e0\r\nMar 13 11:01:55.595024 myhostname kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\nMar 13 11:01:55.595041 myhostname kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\nMar 13 11:01:55.595054 myhostname kernel: Call Trace:\r\nMar 13 11:01:55.595066 myhostname kernel:  ? _nv035386rm+0xf1/0x1d0 [nvidia]\r\nMar 13 11:01:55.595078 myhostname kernel:  ? rm_perform_version_check+0x35/0x150 [nvidia]\r\nMar 13 11:01:55.595089 myhostname kernel:  ? __kmalloc+0x188/0x210\r\nMar 13 11:01:55.595100 myhostname kernel:  ? nvidia_ioctl+0xd6/0x7c0 [nvidia]\r\nMar 13 11:01:55.595112 myhostname kernel:  ? nvidia_ioctl+0x630/0x7c0 [nvidia]\r\nMar 13 11:01:55.595122 myhostname kernel:  ? nvidia_frontend_unlocked_ioctl+0x3a/0x50 [nvidia]\r\nMar 13 11:01:55.595134 myhostname kernel:  ? do_vfs_ioctl+0xa4/0x630\r\nMar 13 11:01:55.595147 myhostname kernel:  ? syscall_trace_enter+0x1d3/0x2d0\r\nMar 13 11:01:55.595159 myhostname kernel:  ? ksys_ioctl+0x60/0x90\r\nMar 13 11:01:55.595170 myhostname kernel:  ? __x64_sys_ioctl+0x16/0x20\r\nMar 13 11:01:55.595180 myhostname kernel:  ? do_syscall_64+0x5b/0x170\r\nMar 13 11:01:55.595191 myhostname kernel:  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9\r\nMar 13 11:01:55.595202 myhostname kernel: Modules linked in: nvidia_uvm(OE) ipt_MASQUERADE nf_conntrack_netlink nfnetlink xfrm_user xfrm_algo iptable_nat nf_nat_ipv4 xt_addrtype iptable_filter xt_conntrack nf_nat nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 libcrc32c br_netfilter bridge stp llc mousedev hid_logitech_hidpp joydev input_leds hid_logitech_dj overlay hid_generic usbhid hid nvidia_drm(POE) nvidia_modeset(POE) snd_hda_codec_hdmi uas usb_storage nvidia(POE) intel_rapl x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass drm_kms_helper snd_hda_codec_realtek crct10dif_pclmul snd_hda_codec_generic drm ledtrig_audio crc32_pclmul ghash_clmulni_intel snd_hda_intel snd_hda_codec agpgart ipmi_devintf ipmi_msghandler snd_hda_core syscopyarea sysfillrect sysimgblt fb_sys_fops snd_hwdep iTCO_wdt iTCO_vendor_support aesni_intel wmi_bmof mxm_wmi intel_wmi_thunderbolt snd_pcm aes_x86_64 crypto_simd cryptd snd_timer glue_helper intel_cstate snd e1000e mei_me mei soundcore alx intel_uncore mdio i2c_i801\r\nMar 13 11:01:55.595215 myhostname kernel:  pcspkr intel_rapl_perf evdev mac_hid wmi pcc_cpufreq crypto_user ip_tables x_tables ext4 crc32c_generic crc16 mbcache jbd2 fscrypto sr_mod cdrom sd_mod ahci libahci libata xhci_pci crc32c_intel xhci_hcd scsi_mod\r\nMar 13 11:01:55.595226 myhostname kernel: CR2: ffffbb9c52edfdb8\r\nMar 13 11:01:55.595237 myhostname kernel: ---[ end trace b892d5812d52b5d6 ]---\r\nMar 13 11:01:55.595248 myhostname kernel: RIP: 0010:nv_dma_map_peer+0xd0/0x160 [nvidia]\r\nMar 13 11:01:55.595258 myhostname kernel: Code: ce e8 b4 fd ff ff 48 8b 5c 24 10 65 48 33 1c 25 28 00 00 00 0f 85 8e 00 00 00 48 83 c4 18 5b 5d 41 5c c3 48 8b 05 78 dc 7e f6 <48> 83 78 40 00 75 ca 49 c1 e2 06 49 8b 78 10 48 89 e6 4b 8d 94 10\r\nMar 13 11:01:55.595267 myhostname kernel: RSP: 0018:ffffbb9c52edf9a0 EFLAGS: 00010246\r\nMar 13 11:01:55.595280 myhostname kernel: RAX: 0000000000000000 RBX: ffff998fe5fd08f0 RCX: 0000000000000010\r\nMar 13 11:01:55.595290 myhostname kernel: RDX: 0000000000000001 RSI: ffff99900888f000 RDI: ffff99900888c800\r\nMar 13 11:01:55.595300 myhostname kernel: RBP: 00000000d0000000 R08: ffff9990173f0000 R09: 00000000dfffffff\r\nMar 13 11:01:55.595310 myhostname kernel: R10: 0000000000000001 R11: 0000000000010000 R12: 00000000d0000000\r\nMar 13 11:01:55.595321 myhostname kernel: R13: ffff99900888f000 R14: 000000000888c800 R15: ffff998fe5fd08c8\r\nMar 13 11:01:55.595331 myhostname kernel: FS:  00007fed23e5fb80(0000) GS:ffff99901e900000(0000) knlGS:0000000000000000\r\nMar 13 11:01:55.595341 myhostname kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nMar 13 11:01:55.595351 myhostname kernel: CR2: ffffbb9c52edfdb8 CR3: 0000001017b90003 CR4: 00000000003606e0\r\nMar 13 11:01:55.595361 myhostname kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\nMar 13 11:01:55.595371 myhostname kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\nMar 13 11:01:55.595381 myhostname kernel: note: nvidia-smi[1334] exited with preempt_count 1\r\n```\r\n", "Your kernel seems way too new for CUDA. Please make sure your CUDA is supported in your Linux distro. Otherwise, we cannot make sure it is a TF issue or not.", "tensorflow only supports CUDA 10.0, so I am not able to upgrade CUDA.\r\nnvidia driver 418.43 works with linux kernel v5, but I guess for now I will assume that there is an issue with CUDA/driver and linux kernel v5.", "Thank you for reporting this issue, it helped me resolve it on my system. I'm running a nearly identical setup as you, Arch Linux, 2 GPUs, linux kernel 5.0.3 and it crashes with the same error. After seeing this issue I downgraded to `linux-lts` and `nvidia-lts`, that has resolved my problem. Apparently, something in linux / nvidia / tensorflow is causing issues.", "I'm also hitting similar behavior, uptodate Debian Sid with two RTX2080Ti. Currently using `nvidia-driver` at version 418.56-2 on kernel 4.19, CUDA 10.0 and TensorFlow r1.13. Previously I could train properly for several hours, and indeed driver was v415.xx from experimental.", "> I'm also hitting similar behavior, uptodate Debian Sid with two RTX2080Ti. Currently using `nvidia-driver` at version 418.56-2 on kernel 4.19, CUDA 10.0 and TensorFlow r1.13. Previously I could train properly for several hours, and indeed driver was v415.xx from experimental.\r\n\r\n@sbrodehl I don't know in your case, but in mine, adjusting the batch size in DeepSpeech when training model helped avoiding the crashes. I suspect something going on with new driver when GPU runs out of memory.", "> > I'm also hitting similar behavior, uptodate Debian Sid with two RTX2080Ti. Currently using `nvidia-driver` at version 418.56-2 on kernel 4.19, CUDA 10.0 and TensorFlow r1.13. Previously I could train properly for several hours, and indeed driver was v415.xx from experimental.\r\n> \r\n> @sbrodehl I don't know in your case, but in mine, adjusting the batch size in DeepSpeech when training model helped avoiding the crashes. I suspect something going on with new driver when GPU runs out of memory.\r\n\r\nOk, never mind, this was noise, in my case the recurrent shutdown was, as I expected at first, just a power issue. Looks like when installing the new setup I forgot we should wire two PCIe cables per RTX, and I only wired one using the Y connector to plug both on each RTX."]}, {"number": 26652, "title": "Replaced get_shape() with shape.", "body": "This is the recommended method to use.", "comments": []}, {"number": 26651, "title": "resize_image_with_pad is not available as described in documentation", "body": "\r\n**System information**\r\n- TensorFlow version: 2.0.0-alpha\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/resize_image_with_pad\r\n\r\n\r\n**Describe the documentation issue**\r\nThis is not available in 2.0.0 it is renamed as tf.image.resize_with_pad\r\n", "comments": ["i am not getting what the real issue is?", "Just to clarify. This is an issue as the documentation is not updated in accordance to the renaming in TF2.0\r\n\r\n```cmd\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.0.0-alpha0'\r\n>>> tf.image.resize_image_with_pad\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow._api.v2.image' has no attribute 'resize_image_with_pad'\r\n>>> tf.image.resize_with_pad\r\n<function resize_image_with_pad_v2 at 0x7f9cb26b86a8>\r\n```", "@drpngx hi, do you know about the renaming?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/b244682665372a4e5aaf16b13a54d1dba2613c57/tensorflow/python/ops/image_ops_impl.py#L1370-L1371", "I think @meyerjo is right, the symbol is exported as `tf.image.resize_with_pad` in 2.0 and not `resize_image_with_pad`, which is v1, so the published doc is incorrect.\r\n\r\nIt is just a matter of re-running the docs generation and uploading the new version.\r\n\r\nYou can check what docs would be generated with:\r\n```\r\nbazel-bin/third_party/tensorflow/tools/docs/generate2 --output_dir=/tmp/tf2_docs_preview\r\n```\r\nI ran that locally and it produces the right docs. I'm leaving that issue open until we update the site.", "It looks like this has been fixed."]}, {"number": 26650, "title": "Fix TF Lite Slice kernel behaviour", "body": "This PR fixes the incorrect behaviour of the TF Lite Slice operation.\r\n\r\nCiting the documentation: [https://www.tensorflow.org/api_docs/python/tf/slice](https://www.tensorflow.org/api_docs/python/tf/slice)\r\n\r\n> If `size[i]` is -1, all remaining elements in dimension `i` are included in the slice. In other words, this is equivalent to setting: `size[i] = input.dim_size(i) - begin[i]`\r\n\r\nHowever, the behaviour of code was described as: `size[i] = input.dim_size(i) - 2 * begin[i]`.\r\n\r\nThis PR fixes described bug and adds tests for the following cases: `begin[i]` for `i >= 1` is 1 while the `end[i]` is -1.\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26650) for more info**.\n\n<!-- need_sender_cla -->", "@akhtyamovpavel please sign CLA ", "Is there a test case we can add in lite/testing/generate_examples.py?", "@jdduke, I have added tests for the `generating_examples` with size -1\r\n@rthadur, we are investigating the questions with corporate CLA. As soon as we could solve this problem (in the near future), I will give you a sign. ", "@rthadur Could you help with passing of the CLA Review? We have signed and accepted request for the Corporate CLA. Furthermore, I have changed the email of commits via `rebase` and amend commands. However, the CLA check has not been completed.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26650) for more info**.\n\n<!-- ok -->", "@alanchiao @jdduke We have signed the CLA. Could you review the code or notify about the announced date for the reviewing this pull request?", "@akhtyamovpavel  can you please address build failures.", "@rthadur I have fixed sanity build, the issue was about having too many characters in line", "@jdduke, could you restart the build or say how to get logs from the Ubuntu CC checks? It seems that the previous build has been failed for the other reasons.", "@rthadur can you help move this through the presubmit check?"]}, {"number": 26649, "title": "Documentation link broken for what is transfer learning?", "body": "Doc Link: https://www.tensorflow.org/js/tutorials/transfer/image-classification\r\n\r\nThe above link is broken.\r\n\r\n\r\n", "comments": ["Thanks for catching this. Indeed following links seem to be broken under [what is transfer learning](https://www.tensorflow.org/js/tutorials/transfer/what_is_transfer_learning)\r\n[Build a transfer-learning based image classifier](https://www.tensorflow.org/js/tutorials/transfer/image-classification)\r\n[Build a transfer-learning based audio recognizer](https://www.tensorflow.org/js/tutorials/transfer/audio-recognizer)", "Can I fix this?", "@Shrutihegde13 Thanks for the offer to help! It looks like we already have a PR pending that fixes this so i'll look into getting that merged.", "Fix has been submitted. Will update once its been deployed.", "FIx is deployed."]}, {"number": 26648, "title": "How To build And deploy Tensor flow label_image code wit Qt Envirnment", "body": "\r\n\r\n\r\n**System information**\r\n- Linux Ubuntu 16.04\r\n- TensorFlow installed from source\r\n- TensorFlow version:1.7.0\r\n- Python version:Python 2.7.12\r\n- Installed using  pip\r\n- Bazel version (if compiling from source):Build label: 0.23.1\r\n- GCC/Compiler version (if compiling from source):gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11) \r\n- CUDA/cuDNN version: CUDA10\r\n- GPU model and memory:nvidia  6GB\r\n\r\n\r\n<em>\r\nI have build and test the tensor flow with label_image test code. I have used bazel on ubuntu 16.04 (x64) system. I have build and test both the python and c++ code.\r\n\r\n\r\nNow I want to build the label_image c++ code with my project in Qt.\r\n         For the same i have tried to build my project by including -ltensorflow_framework generated via tensor flow build through bazel, but not succeeded.\r\n\r\nAlso I have tried by building label_image as library and tried to include this label_image output in my Qt Project, but this was also not sccessfull.\r\n\r\n Can you please let me know the best way to complete my task (build label_image c++ code with Qt)?\r\n        I am interested to build the tensor flow with gpu support.\r\n\r\nplease point me to the exact example or step by step guide to build the target.\r\n</em>", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 26647, "title": "Keras added missing test cases in backend_test", "body": "Added test cases for following \r\n\r\n1. cast_to_floatx\r\n2. identity\r\n3. cumsum\r\n4. cumprod\r\n5. any\r\n6. all", "comments": ["Please redirect the review to high level APIs/Keras owners.", "Thanks for the contributions. Looks reasonable to me. \r\nI would like fchollet to review. ", "@PariksheetPinjari909 can you please address Ubuntu Sanity build failures", "@gbaned Solved the failure\r\n@karmel Can you please approve again. Thanks", "@PariksheetPinjari909 Can you please check the build failures? Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 26646, "title": "Trivial fixes in the files", "body": "Fixed some trivial fixes in the file.", "comments": ["@rthadur , all checks have passed for this PR, kindly help to merge this one."]}, {"number": 26645, "title": "Testing guide page not exist (404)", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.13\r\n- Doc Link: https://www.tensorflow.org/api_guides/python/test\r\n\r\n\r\n**Describe the documentation issue**\r\n[Testing guide](https://www.tensorflow.org/api_guides/python/test) not exist which linked from [tf.test page](https://www.tensorflow.org/api_docs/python/tf/test).\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nI don't know if the page originally exists. \ud83e\udd14 ", "comments": ["Thanks for filing the issue! The link you referenced is pointing to a [Testing Guide](https://web.archive.org/web/20180908070834/https://tensorflow.org/api_guides/python/test) we had historically; but I do not think has been upgraded to TF 2.0.\r\n\r\n@MarkDaoust, do you know if we have plans to update the guide?", "The testing guide is still missing. \r\n\r\nI went to [this page](https://www.tensorflow.org/api_docs/python/tf/test), which points to the testing guide, but I only see a 404 error. See [here](https://www.tensorflow.org/api_guides/python/test).", "@Jasonnor \r\n@krishnap25 \r\ncould you please confirm if the issue still persist", "Not see a 404 now, but the link of test guild on [this page](https://www.tensorflow.org/api_docs/python/tf/test) is same as it(api page). \ud83e\udd23 "]}, {"number": 26644, "title": "Expose tf.lookup.TextFileIndex in 2.0", "body": "This fix tries to address the issue raised in #26622 where tf.lookup.TextFileIndex was not exposed from public API though it is used by tf.lookup.TextFileInitializer which actually needs tf.lookup.TextFileIndex.\r\n\r\nThis fix exposed the tf.lookup.TextFileIndex.\r\n\r\nThis fix fixes #26622.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": ["@rohan100jain @alextp Thanks for the review. The doc string for `tf.lookup.TextFileIndex` has been added. Please take a look.", "Ok, looks good. I'll approve after the next tf api owners sync."]}, {"number": 26643, "title": "Inconsistent argument for compression between TFRecordWriter and TFRecordDataset", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMacOSX 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\ntf.version.VERSION='2.0.0-dev20190311'\r\ntf.version.GIT_VERSION='v1.12.0-9917-gf988edacf4'\r\n- Python version:\r\n3.6.8\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\n`TFRecordOptions`'s `compression_type` argument expects an int (defined in `tf.io.TFRecordCompressionType`), while `tf.data.TFRecordDataset`'s `compression_type` must be a string.  IMHO, TensorFlow 2.0 should eliminate this sort of inconsistency, it would be more pythonic:\r\n\r\n```bash\r\n$ python -m this | grep \"do it\"\r\nThere should be one-- and preferably only one --obvious way to do it.\r\n```\r\n\r\n**Describe the expected behavior**\r\nBoth should be consistent (and accepting a string would provide the simplest API).  Any other function that expects a `compression_type` should also respect the same API.\r\n\r\n**Code to reproduce the issue**\r\nFor example:\r\n\r\n```python\r\nGZIP = tf.io.TFRecordCompressionType.GZIP\r\noptions = tf.io.TFRecordOptions(compression_type=GZIP)\r\nwith tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\r\n    f.write(b\"This is the first record\")\r\n    f.write(b\"And this is the second record\")\r\n\r\ndataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=GZIP)\r\n```\r\n\r\n**Other info / logs**\r\nHere is the stacktrace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-40e8c78e4ba4> in <module>\r\n      5     f.write(b\"And this is the second record\")\r\n      6\r\n----> 7 dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=GZIP)\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/readers.py in __init__(self, filenames, compression_type, buffer_size, num_parallel_reads)\r\n    168\r\n    169     if num_parallel_reads is None:\r\n--> 170       self._impl = filenames.flat_map(read_one_file)\r\n    171     else:\r\n    172       self._impl = filenames.interleave(\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in flat_map(self, map_func)\r\n   1043       Dataset: A `Dataset`.\r\n   1044     \"\"\"\r\n-> 1045     return FlatMapDataset(self, map_func)\r\n   1046\r\n   1047   def interleave(self,\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, input_dataset, map_func)\r\n   3063     self._input_dataset = input_dataset\r\n   3064     self._map_func = StructuredFunctionWrapper(\r\n-> 3065         map_func, self._transformation_name(), dataset=input_dataset)\r\n   3066     if not isinstance(self._map_func.output_structure, DatasetStructure):\r\n   3067       raise TypeError(\"`map_func` must return a `Dataset` object.\")\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   2386           ops.GraphKeys.TABLE_INITIALIZERS))\r\n   2387\r\n-> 2388       self._function = wrapper_fn._get_concrete_function_internal()\r\n   2389       if add_to_graph:\r\n   2390         self._function.add_to_graph(ops.get_default_graph())\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal(self, *args, **kwargs)\r\n   1299     \"\"\"Bypasses error checking when getting a graph function.\"\"\"\r\n   1300     graph_function = self._get_concrete_function_internal_garbage_collected(\r\n-> 1301         *args, **kwargs)\r\n   1302     # We're returning this concrete function to someone, and they may keep a\r\n   1303     # reference to the FuncGraph without keeping a reference to the\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1293     if self.input_signature:\r\n   1294       args, kwargs = None, None\r\n-> 1295     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1296     return graph_function\r\n   1297\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   1556           or call_context_key not in self._function_cache.missed):\r\n   1557         self._function_cache.missed.add(call_context_key)\r\n-> 1558         graph_function = self._create_graph_function(args, kwargs)\r\n   1559         self._function_cache.primary[cache_key] = graph_function\r\n   1560         return graph_function, args, kwargs\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   1489             arg_names=arg_names,\r\n   1490             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 1491             capture_by_value=self._capture_by_value),\r\n   1492         self._function_attributes)\r\n   1493\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    692                                           converted_func)\r\n    693\r\n--> 694       func_outputs = python_func(*func_args, **func_kwargs)\r\n    695\r\n    696       # invariant: `func_outputs` contains only Tensors, IndexedSlices,\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in wrapper_fn(*args)\r\n   2379           attributes=defun_kwargs)\r\n   2380       def wrapper_fn(*args):  # pylint: disable=missing-docstring\r\n-> 2381         ret = _wrapper_helper(*args)\r\n   2382         ret = self._output_structure._to_tensor_list(ret)\r\n   2383         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py in _wrapper_helper(*args)\r\n   2324         nested_args = (nested_args,)\r\n   2325\r\n-> 2326       ret = func(*nested_args)\r\n   2327       # If `func` returns a list of tensors, `nest.flatten()` and\r\n   2328       # `ops.convert_to_tensor()` would conspire to attempt to stack\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/readers.py in read_one_file(filename)\r\n    165\r\n    166     def read_one_file(filename):\r\n--> 167       return _TFRecordDataset(filename, compression_type, buffer_size)\r\n    168\r\n    169     if num_parallel_reads is None:\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/readers.py in __init__(self, filenames, compression_type, buffer_size)\r\n    105         compression_type,\r\n    106         argument_default=\"\",\r\n--> 107         argument_dtype=dtypes.string)\r\n    108     self._buffer_size = convert.optional_param_to_tensor(\r\n    109         \"buffer_size\",\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/data/util/convert.py in optional_param_to_tensor(argument_name, argument_value, argument_default, argument_dtype)\r\n     30   if argument_value is not None:\r\n     31     return ops.convert_to_tensor(\r\n---> 32         argument_value, dtype=argument_dtype, name=argument_name)\r\n     33   else:\r\n     34     return constant_op.constant(\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n   1048   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n   1049       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n-> 1050   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1051\r\n   1052\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1106       name=name,\r\n   1107       preferred_dtype=dtype_hint,\r\n-> 1108       as_ref=False)\r\n   1109\r\n   1110\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\r\n   1184\r\n   1185     if ret is None:\r\n-> 1186       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1187\r\n   1188     if ret is NotImplemented:\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    302                                          as_ref=False):\r\n    303   _ = as_ref\r\n--> 304   return constant(v, dtype=dtype, name=name)\r\n    305\r\n    306\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    243   \"\"\"\r\n    244   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 245                         allow_broadcast=True)\r\n    246\r\n    247\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281       tensor_util.make_tensor_proto(\r\n    282           value, dtype=dtype, shape=shape, verify_shape=verify_shape,\r\n--> 283           allow_broadcast=allow_broadcast))\r\n    284   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n    285   const_tensor = g.create_op(\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    465       nparray = np.empty(shape, dtype=np_dt)\r\n    466     else:\r\n--> 467       _AssertCompatible(values, dtype)\r\n    468       nparray = np.array(values, dtype=np_dt)\r\n    469       # check to them.\r\n\r\n~/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py in _AssertCompatible(values, dtype)\r\n    370     else:\r\n    371       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\r\n--> 372                       (dtype.name, repr(mismatch), type(mismatch).__name__))\r\n    373\r\n    374\r\n\r\nTypeError: Expected string, got 2 of type 'int' instead.\r\n```", "comments": ["The string type `\"GZIP\"`, `\"ZLIB\"`, and `\"NONE\"` are actually supported for both `TFRecordWriter` and `TFRecordDataset`. For that I am in favor of removing `tf.io.TFRecordCompressionType` as it is just a pure enum. Created a PR #26676 for the fix.", "Thanks for the PR @yongtang! That change sounds good to me."]}, {"number": 26641, "title": "Added the TCs for CopyFromBufferHandle scenario.", "body": "This was one of the TODO mentioned in the file.", "comments": ["Nagging Reviewer @haozha111, @miaout17: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 16 days with no activity and the `awaiting review` label has been applied."]}, {"number": 26640, "title": "Added dynamic pad subgraph test", "body": "PAD op return dynamic tensor directly. But ADD and MUL only return static tensors and with the use of IF, dynamic tensor subgraph can be built with ADD and MUL. ", "comments": []}, {"number": 26639, "title": "Nasnet models don't support custom image sizes even if include_top is set to False", "body": "The general idea for fine-tuning pre-trained models with a custom image size is to set the `include_top` parameter to `False` when loading the models. However it doesn't seem to be working with the Nasnet models in `tf.keras` so far. All other models including Inception are working fine.\r\n\r\n__Note:__ I was using tensorflow 2.0 alpha so I'm not sure if that is the problem.\r\n\r\nI believe maybe some issue somewhere in checking dimension size along with the `include_top` flag but I might be wrong.\r\n\r\nFollowing is the stack trace.\r\n\r\n```\r\n\r\nCode executed:\r\nnasnet = tf.keras.applications.nasnet.NASNetLarge(include_top=False, weights='imagenet', \r\n                                                                                  input_shape=(100, 100, 3))\r\n\r\nError Message:\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-100-64f6d45dc54d> in <module>\r\n      1 nasnet = tf.keras.applications.nasnet.NASNetLarge(include_top=False, weights='imagenet', \r\n----> 2                                                                                 input_shape=(100, 100, 3))\r\n      3 nasnet.summary()\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/__init__.py in wrapper(*args, **kwargs)\r\n     68       kwargs['models'] = models\r\n     69       kwargs['utils'] = utils\r\n---> 70     return base_fun(*args, **kwargs)\r\n     71   return wrapper\r\n     72 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/applications/nasnet.py in NASNetLarge(*args, **kwargs)\r\n     37 @keras_modules_injection\r\n     38 def NASNetLarge(*args, **kwargs):\r\n---> 39   return nasnet.NASNetLarge(*args, **kwargs)\r\n     40 \r\n     41 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/keras_applications/nasnet.py in NASNetLarge(input_shape, include_top, weights, input_tensor, pooling, classes, **kwargs)\r\n    364                   classes=classes,\r\n    365                   default_size=331,\r\n--> 366                   **kwargs)\r\n    367 \r\n    368 \r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/keras_applications/nasnet.py in NASNet(input_shape, penultimate_filters, num_blocks, stem_block_filters, skip_reduction, filter_multiplier, include_top, weights, input_tensor, pooling, classes, default_size, **kwargs)\r\n    166                                       data_format=backend.image_data_format(),\r\n    167                                       require_flatten=True,\r\n--> 168                                       weights=weights)\r\n    169 \r\n    170     if backend.image_data_format() != 'channels_last':\r\n\r\n/opt/anaconda3/lib/python3.6/site-packages/keras_applications/imagenet_utils.py in _obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights)\r\n    290                                  'and loading `imagenet` weights, '\r\n    291                                  '`input_shape` should be ' +\r\n--> 292                                  str(default_shape) + '.')\r\n    293         return default_shape\r\n    294     if input_shape:\r\n\r\nValueError: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (331, 331, 3).\r\n```", "comments": ["@dipanjanS Could you provide a code to reproduce the bug? Thanks!", "Hi, it's mentioned in the previous comment, reposting here again separately.\r\n\r\n```\r\nnasnet = tf.keras.applications.nasnet.NASNetLarge(include_top=False, weights='imagenet', \r\n                                                  input_shape=(100, 100, 3))\r\n```\r\n\r\nTensorflow version being used: `'2.0.0-alpha0'`", "Adding Francois who is the owner Keras overall.", "Same question", "@fchollet any idea on this aspect?", "I need to wrote weights=None, then the training runs successfully. ", "That is just random initialization of weights, the whole point of using this is to do transfer learning with pre-trained weights obtained from imagenet. Using `weights=None` defeats the purpose of doing that. That's the same like building your own CNN and copying the layers from Nasnet.", "I understand.but then you see in practice, nasnet was requiring fixed image size after loading imagenet.whats the solution to that besides dumping imagenet?-------- Original Message --------Subject: Re: [tensorflow/tensorflow] Nasnet models don't support custom image sizes even if include_top is set to False (#26639)From: Dipanjan Sarkar To: tensorflow/tensorflow CC: Kirosealin ,Manual That is just random initialization of weights, the whole point of using this is to do transfer learning with pre-trained weights obtained from imagenet. Using weights=None defeats the purpose of doing that. That's the same like building your own CNN and copying the layers from Nasnet.\r\n\r\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.\r\n[\r\n{\r\n\"@context\": \"http://schema.org\",\r\n\"@type\": \"EmailMessage\",\r\n\"potentialAction\": {\r\n\"@type\": \"ViewAction\",\r\n\"target\": \"https://github.com/tensorflow/tensorflow/issues/26639?email_source=notifications\\u0026email_token=AFSLRD4TMTZWQ2OWYGGW2V3PWKC4RA5CNFSM4G5RM342YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYP2CY#issuecomment-493944075\",\r\n\"url\": \"https://github.com/tensorflow/tensorflow/issues/26639?email_source=notifications\\u0026email_token=AFSLRD4TMTZWQ2OWYGGW2V3PWKC4RA5CNFSM4G5RM342YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYP2CY#issuecomment-493944075\",\r\n\"name\": \"View Issue\"\r\n},\r\n\"description\": \"View this Issue on GitHub\",\r\n\"publisher\": {\r\n\"@type\": \"Organization\",\r\n\"name\": \"GitHub\",\r\n\"url\": \"https://github.com\"\r\n}\r\n}\r\n]", "fixing the API so it is consistent with the other pre-trained models I guess?", "The problem is not with the TensorFlow itself, but with the `keras_applications` module. The reason for such behavior of NASNet is described [here](https://github.com/keras-team/keras-applications/pull/62). So it's more likely a bug than a feature, however, I think that documentation should be updated.", "I just ran into this, agree the documentation should be updated - both the tensorflow and keras documentation say that you should be able to set input_shape to something other than (331,331,3).", "The documentation for loading weights with correct input_shape has been updated. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26639\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26639\">No</a>\n"]}, {"number": 26638, "title": " Filter out empty strings as post processing", "body": "Let users filter out empty strings as post-processing if they do want to.\r\nRe indices and shapes, the right answer is to have proper ragged and sparse tensor support to tf.boolean_mask.\r\n\r\nThis is a follow up to issue #26368 . and PR #26475 . \r\n", "comments": ["@alextp ", "@edloper do you have any pointers as to how to implement boolean_mask support for RaggedTensor?", "Has there been any movement?\r\n", "Sorry I\u2019ve been out sick for the past few days.\n\nIt\u2019s already implemented. See:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/ragged/ragged_array_ops.py\n\nBut it\u2019s not exported yet (via delegation) because the API doesn\u2019t exactly\nmatch the existing boolean_mask op.  In particular it has a new keepdims\nargument.\n\nI would like to modify the existing boolean_mask op to add a keepdims arg\n(defaulting to false) and to delegate to this if keepdims is true.\n\n-Edward\n\nOn Fri, Mar 15, 2019 at 10:46 AM lhendre <notifications@github.com> wrote:\n\n> Has there been any movement?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26638#issuecomment-473312191>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFhajJ_fNm9j9rBPTYfQMqyXDUl8Igv5ks5vW7JegaJpZM4bsUSd>\n> .\n>\n", "Is this something that you would want help on?", "@lhendre I'd happily review a pull request with this change. Do you think you have enough information to open one?", "Let me do a little digging and work over the day and Ill get back here with questions", "I had some personal things come up over the last two weeks, but this week is looking better to dig into this", "I have started working on this and have some stuff down but I want to clarify and make sure I am on the right path.\r\nThe existing boolean mask I am modifying to add a keepdims arg(defaulting to false) and to delegate to the ragged ops is here right?\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py\r\nI am a little less familiar with this portion of the code and wanted to check first?  Additionally the ragged function does make a callback to this so I am unsure of it or is their a higher level location?  @alextp and @edloper ", "Checking in real quick @edloper, I want to make sure this is the correct approach.", "Yes, you'll need to make changes to the boolean_mask function in array_ops.py.  However, looking at this a little closer, we might have some issues with circular dependencies that make this more of a pain to do than it would otherwise be.  If you can figure out a good way around the circular dependencies, I'm happy to look at a PR; otherwise, I'll try to look at this sometime in the next couple weeks to see what I can do.", "I think we will refactor the code a little to make this circular dependency go away.  So it's probably easiest to hold off on this until we do that.", "Its been a while and thought I'd circle back and see if there have been any updates?", "Sorry for not updating this thread.  In PR 1366762 I added a \"tf.ragged.boolean_mask\" op, which preserves the masked dimensions.  (We decided that it was better to add this as a separate op, rather than adding an option to the existing tf.boolean_mask op.)", "No Problem, thanks for the update!"]}, {"number": 26637, "title": "Update cost_estimator.h", "body": "include `cmath` for INFINITY", "comments": []}, {"number": 26636, "title": "Add a origin url param to load_data function in keras.datasets", "body": "**System information**\r\n- TensorFlow version (you are using): 2.0.0-alpha0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n`keras.datasets` is a nice place for beginners to start, but `storage.googleapis.com` is blocked in some country, it makes it impossible to directly download the dataset. I propose to add a URL param to the `load_data` function of the dataset. So we could provide some mirror URL for users in our country.\r\n\r\n**Will this change the current API? How?**\r\nYes, will add a param with default value None to all `load_data` function in `tensorflow/python/keras/datasets`\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAll new beginners in countries blocked `storage.googleapis.com`\r\n\r\n**Any Other info.**\r\n", "comments": ["This issue is more suitable for keras repo since ```keras.datasets``` is maintained by keras team. Please post it on [keras github repo](https://github.com/keras-team/keras/issues). Thanks!"]}, {"number": 26635, "title": "Transformer step/sec decrease over time to 0", "body": "**System information**\r\n**- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**\r\nYes\r\n**- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**\r\nUbuntu 18.04\r\n**- TensorFlow installed from (source or binary):**\r\nBinary / pip install\r\n**- TensorFlow version**\r\n1.13.1\r\n**- Python version:**\r\n3.6.7\r\n**- CUDA/cuDNN version:**\r\nCUDA = 10\r\nCUDNN_VERSION 7.5\r\n**- GPU model and memory:**\r\n8X V100 16 GB\r\n\r\n(We observed same behavior with CUDA 9.2 & TF 1.12 compiled for CUDA 9.2.)\r\n[Docker Image](https://gitlab.com/nvidia/cuda/blob/ubuntu18.04/9.2/devel/cudnn7/Dockerfile)\r\n\r\n**Problem:** \r\nTraining steps/s while using a Transformer model repeatedly drops from 20 steps/s to <1 step/s.  \r\nThis is internally reproducible. \r\nGPU usage plummets to ~0% during the periods at <1 step/s\r\n\r\n**Context:**\r\nWe train with a [Transformer model](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py#L175).\r\n\r\nTraining behaves poorly with [Transformer](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py#L175), but works well with [Universal Transformer](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/research/universal_transformer.py#L41).\r\n\r\nIn both scenarios, we use 4x P100, subword tokens (https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/text_encoder.py#L448), and [MirroredStrategy Enabled](https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/MirroredStrategy) distribution strategy. \r\n\r\n(We observed the same behavior with 8x V100, as well.)\r\n\r\nAblation tests on 1) P100 versus V100, 2) MirroredStrategy versus t2t\u2019s built-in multi-GPU, and 3) Universal Transformer versus Transformer reveal that #3 is the driving variable.\r\n\r\nWe\u2019re using tensor2tensor\u2019s transformer / universal_transformer implementations. \r\nThe hparams used are transformer_tiny and universal_transformer_tiny. One noteworthy deviation from common usage is that our hparams.max_length value is large (2500) and our batch size is often small, since our median sequence length is 750 tokens.\r\n\r\n**Describe the current behaviour**\r\nWith Transformer, training run\u2019s step/sec alternates between roughly 20 step/sec and 0.5 step/sec.\r\n\r\nFor the first 3-4 hours it is biased towards 20 steps/sec. For the next is ~2 it hours it  begins dropping to 0.5 step/sec more frequently, before finally dropping almost exclusively to 0.5 step/sec.\r\n\r\nIf we restart our training process from a checkpoint that was made when the model ran slowly, the behaviour repeats itself, starting at 20 step/sec before dropping back down to 0.5. \r\n\r\nBelow are two graphs The first is a graph of our model\u2019s step/sec degradation over a training run. The median value early on is ~20 (with some occasional drops to below 5 step/sec) but as the training continues our performance drops to almost 0 step/sec.\r\nNote the vertical axis is logarithmic\r\n![image](https://user-images.githubusercontent.com/43351375/54249496-c64c5880-4516-11e9-86ad-3a6d6f1c940b.png)\r\n\r\n The second graph shows 3.25 consecutive runs of our model, where each restart picks up a checkpoint the previous run generated. These restarts were not caused an error, but are due to our system automatically preempting gpu intensive jobs after 24 hours. Note the consistent degradation in performance after every restart.\r\n![image](https://user-images.githubusercontent.com/43351375/54249582-0b708a80-4517-11e9-9287-663c54799d00.png)\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nOur runs with universal transformer exhibit a completely flat step/sec curve. The figure below shows the expected behaviour in red in terms of step/sec variance. Note that the model\u2019s step/sec exhibit almost no variation except for the sharp drops attributed to evaluation steps.\r\n![Transformer vs Universal Transformer Step_Sec Decrease (2)](https://user-images.githubusercontent.com/43351375/54287868-dc8cff80-457c-11e9-8c64-52dbfa98c833.png)\r\n\r\n**Other info / logs**\r\nOur GPU utilization (as measured by nvidia-smi) is tightly coupled with the above graph. Where our step/sec is high, our gpu utilization is nearly always at 50%, occasionally dropping to 0 for a second or two before shooting back up. When our step/sec consistently drops to below one, our gpu utilization is mostly at 0%. Every few minutes it will briefly shoot up to 50% and then drop to 0% a second later.\r\n\r\nIn terms of auc performance, our transformer model continues to improve even as the step/sec decay. \r\n\r\nNote this is a sibling issue to: https://github.com/tensorflow/tensor2tensor/issues/1484", "comments": ["Hey @jvishnuvardhan any thoughts on this?", "It is better to first investigate in https://github.com/tensorflow/tensor2tensor/issues/1484 to isolate the issue from Tensor2Tensor specific application logic.\r\n\r\nPlease reopen this issue when further investigation is done and the issue is reproducible with MCV example as described in https://stackoverflow.com/help/mcve. You should also consider using profiler to identify the bottleneck.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26635\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26635\">No</a>\n"]}, {"number": 26634, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "I have this error, how can i solve this problem?\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"generate_tfrecord.py\", line 17, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\User\\Anaconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["Please provide following info:\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "   - OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\n   Pro 64-bit (10.0, biuld 17134)\n   - TensorFlow installed from (source or binary): from source\n   - TensorFlow version: 1.13.1\n   - Python version:  python 3.6\n   - Installed using virtualenv? pip? conda?: conda\n   - CUDA/cuDNN version: CUDA:9.0 / cuDNN: v9\n   - GPU model and memory:    memory:8192MB RAM\n\n\nOn Thu, Mar 14, 2019 at 2:44 AM ymodak <notifications@github.com> wrote:\n\n> Please provide following info:\n> *System information*\n>\n>    - OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n>    - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\n>    happens on mobile device:\n>    - TensorFlow installed from (source or binary):\n>    - TensorFlow version:\n>    - Python version:\n>    - Installed using virtualenv? pip? conda?:\n>    - Bazel version (if compiling from source):\n>    - GCC/Compiler version (if compiling from source):\n>    - CUDA/cuDNN version:\n>    - GPU model and memory:\n>\n> *Describe the problem*\n>\n> *Provide the exact sequence of commands / steps that you executed before\n> running into the problem*\n>\n> *Any other info / logs*\n> Include any logs or source code that would be helpful to diagnose the\n> problem. If including tracebacks, please include the full traceback. Large\n> logs and files should be attached.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26634#issuecomment-472553123>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ap8eqW7U5LVWFi4v_V07nTf2zdwDfgzeks5vWUcKgaJpZM4bsQfQ>\n> .\n>\n", "Thanks for providing the info. Did you add cuda to your path? Can you please attach a screenshot of added paths if added already?\r\nTake a look at this [windows setup guide for gpu support](https://www.tensorflow.org/install/gpu#windows_setup) if haven't already.\r\nYou need to add sub folders: ```bin``` , ```include``` and ```lib``` to the path. Can you please try adding them as well?", "yes i have add cuda in my path. The attachment is my added path.\n\nOn Fri, Mar 15, 2019 at 9:16 AM ymodak <notifications@github.com> wrote:\n\n> Thanks for providing the info. Did you add cuda to your path?\n> Take a look at this windows setup guide for gpu support\n> <https://www.tensorflow.org/install/gpu#windows_setup> if haven't already.\n> You need to add sub folders: bin , include and ```lib`` to the path. Can\n> you please try adding them as well?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26634#issuecomment-473122827>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ap8eqTAsn-OWbVIbxbWbqAz_wZBWI2CQks5vWvSAgaJpZM4bsQfQ>\n> .\n>\n", "shall i need the NVIDIA package launcher for my cudnna and cuda? if need\nmay i know the  Product Series,  Product Type and  Product suitable for my\nlaptop? i have try to download the driver but it cannot work. thanks\n\nOn Fri, Mar 15, 2019 at 9:20 AM yen peiyi <peiyiyen1996@gmail.com> wrote:\n\n> yes i have add cuda in my path. The attachment is my added path.\n>\n> On Fri, Mar 15, 2019 at 9:16 AM ymodak <notifications@github.com> wrote:\n>\n>> Thanks for providing the info. Did you add cuda to your path?\n>> Take a look at this windows setup guide for gpu support\n>> <https://www.tensorflow.org/install/gpu#windows_setup> if haven't\n>> already.\n>> You need to add sub folders: bin , include and ```lib`` to the path. Can\n>> you please try adding them as well?\n>>\n>> \u2014\n>> You are receiving this because you authored the thread.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/26634#issuecomment-473122827>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/Ap8eqTAsn-OWbVIbxbWbqAz_wZBWI2CQks5vWvSAgaJpZM4bsQfQ>\n>> .\n>>\n>\n", "ah I see you are using cuda 9.0. TF 1.13.1 comes with pre built cuda 10.0 binaries. So please upgrade to cuda 10.0 and make sure to add path as well. You can download [cuda 10.0 toolkit](https://developer.nvidia.com/cuda-toolkit-archive)\r\nAlso take a look at https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12\r\nYou can use cuda 10.0 instead of cuda 9.0 rest of the steps should be the same.", "thanks for your suggestion.\n\nOn Sat, Mar 16, 2019 at 2:05 AM ymodak <notifications@github.com> wrote:\n\n> ah I see you are using cuda 9.0. TF 1.13.1 comes with pre built cuda 10.0\n> binaries. So please upgrade to cuda 10.0 and make sure to add path as well.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26634#issuecomment-473386080>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ap8eqbCsX8KxQ7c3FdKWtiQNRi0LazmIks5vW-DmgaJpZM4bsQfQ>\n> .\n>\n", "@peyifyp Were you able to install TF? Any updates yet.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26634\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26634\">No</a>\n"]}, {"number": 26633, "title": "about  deeplearning models center repository.", "body": "The technology of in-depth learning has been developed for a long time. At present, it is not clear whether there is a model library of the type of Maven docker central library. If not, I hope we can build it. If there is, please let me know. Thanks.", "comments": ["I believe this is a feature request. Can you elaborate more by providing following information asked by the template? Thanks\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 26632, "title": "Add the test for TakeDatasetOp", "body": "This PR adds the test for `TakeDatasetOp`.\r\n\r\ncc: @jsimsa @rachellim ", "comments": ["@feihugis Thank you for another unit test! I like that unit test style that we have converged on (defining test cases through functions that return a TestCase). When you get a chance, could you please apply it consistently across the existing unit tests? For instance, I recently made changes to tensor_slice_dataset_op_test.cc and sparse_tensor_slice_dataset_op_test.cc to fix an internal test failure and it would be great if you could apply your test style to those for consistency. Thanks again for the contributions!", "@jsimsa Thanks for your quick review! The class and function names have been updated in [this commit](https://github.com/tensorflow/tensorflow/pull/26632/commits/66b8ba465139aafe1c66e4e2f1aa2d1a1d044c85).\r\n\r\nSure, I will update the existing unit tests this week and keep the test style on the future PRs.  "]}, {"number": 26631, "title": "TFTRT: Fix type set for constants in TRT 5.1.3+", "body": "There was previously a bug in TRT which required ITensor::setType to be called for constants created by IConstantLayer. This was not the desired behavior: IConstantLayer was supposed to get the type automatically from the Weights provided to it. Because of this, setType would display an warning everytime we created a constant. With TRT 5.1.3+, we remove this unnecessary call to setType.\r\n\r\nI've also added a macro, `IS_TRT_VERSION_GE(major, minor, patch)` to make it easier to require certain versions of TRT. Suggestions for improving the name or where it is defined are very welcome.", "comments": []}, {"number": 26630, "title": "Fix support for generators in Keras fit_generator", "body": "Keras supports generators in [fit_generator](https://keras.io/models/model/#fit_generator); however, support for generators was dropped in TensorFlow Keras with https://github.com/tensorflow/tensorflow/commit/8420f5741558c79fa71b442bcc613800c3b3dfa6.\r\n\r\nNotice that `data` should support a `generator` [training_generator.py#L439-L442](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_generator.py#L439-L442).\r\n\r\nHowever, current code does not handle generators and assume the objects have a `shape` [training_generator.py#L458-L475](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_generator.py#L458-L475)\r\n\r\nThis PR fixes https://github.com/rstudio/keras/issues/682, but this is likely to be also reproducible in the Python interface. Tests are already available in the R interface for Keras.", "comments": ["Ah! I think I found out while this works with the Keras implementation and not with the TensorFlow implementation. Keras handles iterators: https://github.com/keras-team/keras/blob/master/keras/engine/training_generator.py#L181 while the TensorFlow implementation does not.\r\n\r\nTo be fair, the documentation does not seem to mention that iterators are supported, so one could argue breaking this API is acceptable.\r\n\r\nIn any case, we would appreciate if someone with knowledge in this codebase could comment.", "We have a fix on our by using a generator instead of an iterator so I'm tempted to close this PR.\r\n\r\nHowever, there might be other code bases that assume iterators work with `generator_fit()`. I would suggest someone, with more knowledge in this codebase, considers bringing back iterator support and close or merge this PR as needed. Thanks!", "@javierluraschi thank you for your contribution , can you please check build failures ?", "Hi @rthadur thanks for reviewing! May I ask what to make of the \r\n\r\n`exited with error code 1`\r\n\r\nin the \"Ubuntu Sanity Check\"? This seems to be the only _required_ check failing... (and there's the required Ubuntu CC waiting for some reason?)\r\n\r\nHow are the remaining failing tests handled? For example in the case of Ubuntu CPU failing, I see that all errors are related to metric tests not being close enough (which is a kind of soft criterion because one might ask whether the thresholds are adequate)...\r\n\r\nThanks!", "@skeydan, for that one you need to open the [\"logs\" tab](https://source.cloud.google.com/results/invocations/e9954d6a-005b-459d-96ae-5d4600a1cce2/log)\r\n\r\nThen I usually each for \"Fail\" or \"Error\". For Ubuntu Sanity the error is:\r\n\r\n```\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/keras/engine/training_generator.py:494: [E0102(function-redefined), convert_to_generator_like._gen] function already defined line 463\r\n```\r\n\r\nI'm not sure what the 'required' label is about, but the others may be failing tests, can you check if they're related?", "Can one of the admins verify this patch?", "@MarkDaoust thanks! Didn't know that :-)", "The broken tests seem unrelated to this change,\r\n\r\n```\r\n# Linux GPU\r\n//tensorflow/python/distribute:input_lib_test_gpu\r\n# MacOS Python2\r\n//tensorflow/python/keras:metrics_correctness_test\r\n//tensorflow/python/keras:temporal_sample_weights_correctness_test\r\n# Ubuntu CPU\r\n//tensorflow/python/keras:metrics_correctness_test\r\n//tensorflow/python/keras:temporal_sample_weights_correctness_test\r\n//tensorflow/python/keras:training_eager_test\r\n# Ubuntu Sanity\r\n//tensorflow/tools/ci_build:gen_ci_sanity_out\r\n# Windows Bazel\r\n//tensorflow/tools/ci_build/builds:gen_win_out\r\n```\r\n\r\nHowever, we currently don't have a lot of spare cycles to contribute more to this PR and already placed a workaround on the R package to perform this conversion ourselves; therefore, I'm closing this PR due to lack of time but someone might want to take it from here. Thanks everyone!", "Support for iterators should be fixed as part of https://github.com/tensorflow/tensorflow/commit/177b6056239805e4de0a8e8e9c258edfa4a21099. If you get a chance could you check and see if that restores compatibility?", "@robieta I'm afraid this would be pretty complicated from our side, since a lot in the code base has changed (meaning: in our code base as well), and also pretty error-prone - in the sense of \"not a guarantee that it runs the way you think\" - , since we use our R wrapper. I think it would be better to rely on Python unit tests instead for this, to be on the safe side..."]}]