[{"number": 51401, "title": "AttributeError: type object 'IteratorBase' has no attribute 'from_structure'", "body": "\uff54\uff45\uff4e\uff53\uff4f\uff52\uff46\uff4c\uff4f\uff57\u3000\uff12\uff0e\uff15\r\n\r\nI've issued this https://github.com/tensorflow/tensorflow/issues/50871. However, there's no reply at all. May it has been forgotten, so I have to raise this issue again.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntraining_dataset = tf.data.Dataset.range(100).map(\r\n    lambda x: x + tf.random.uniform([], -10, 10, tf.int64))\r\nvalidation_dataset = tf.data.Dataset.range(50)\r\n\r\n# A reinitializable iterator is defined by its structure. We could use the\r\n# `output_types` and `output_shapes` properties of either `training_dataset`\r\n# or `validation_dataset` here, because they are compatible.\r\niterator = tf.data.Iterator.from_structure(training_dataset.output_types,\r\n                                           training_dataset.output_shapes)\r\nnext_element = iterator.get_next()\r\n\r\ntraining_init_op = iterator.make_initializer(training_dataset)\r\nvalidation_init_op = iterator.make_initializer(validation_dataset)\r\n\r\n# Run 20 epochs in which the training dataset is traversed, followed by the\r\n# validation dataset.\r\nfor _ in range(20):\r\n    # Initialize an iterator over the training dataset.\r\n    sess.run(training_init_op)\r\n    for _ in range(100):\r\n        sess.run(next_element)\r\n\r\n    # Initialize an iterator over the validation dataset.\r\n    sess.run(validation_init_op)\r\n    for _ in range(50):\r\n        sess.run(next_element)`\r\n\r\n```", "comments": ["@sjtusmartboy Could you please refer to the[ link ](https://www.tensorflow.org/api_docs/python/tf/compat/v1/data/Iterator),[ link1](https://www.tensorflow.org/api_docs/python/tf/data/Iterator) and let us know if it helps?Thanks!", "@sushreebarsa Thanks, but the link certainly would not help because I've read it several times. Please teach me how to revise the code because it's the tensorflow's kernel error.", "@sjtusmartboy Thank you for the update! I tried to run your code using `tf.compat.v1.disable_v2_behavior()` on colab with TF v2.5 and It is throwing warning message ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/2bf39b081ae5fa2e31c2ef68ace334c3/untitled374.ipynb) for your reference.Session is not supported in TF version 2.x . Please find the [link](https://www.tensorflow.org/guide/effective_tf2#functions_not_sessions) ,[ link1](https://www.tensorflow.org/guide/migrate) for more information on migration from 1.x to 2.x and let us know if it helps?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51401\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51401\">No</a>\n"]}, {"number": 51400, "title": "Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_LAUNCH_FAILED", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Conda\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1.168/7.6.5\r\n- GPU model and memory: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nCan't complete any TensorFlow Operations (i.e. import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000]))))\r\n\r\n**Describe the expected behavior**\r\nComplete TensorFlow Operations\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport os\r\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\r\nimport tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nLogs:\r\n```\r\n(base) user@computer:~$ python\r\nPython 3.8.8 (default, Apr 13 2021, 19:58:26) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import os\r\n>>> os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\r\n>>> import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\r\n2021-08-09 18:25:50.895134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-08-09 18:25:51.967116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-08-09 18:25:52.035250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-08-09 18:25:52.036032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-08-09 18:25:52.037043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \r\npciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-08-09 18:25:52.037996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-08-09 18:25:52.038016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-08-09 18:25:52.039398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-08-09 18:25:52.039431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-08-09 18:25:52.040687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-08-09 18:25:52.040882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-08-09 18:25:52.042260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-08-09 18:25:52.043012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-08-09 18:25:52.045963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-08-09 18:25:52.052758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\r\n2021-08-09 18:25:52.053048: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-08-09 18:25:52.072766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3597710000 Hz\r\n2021-08-09 18:25:52.073339: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5618cc45fbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-08-09 18:25:52.073366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2021-08-09 18:26:22.377801: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure\r\nAborted (core dumped)\r\n```\r\n\r\nAnaconda Package List:\r\n```\r\n_ipyw_jlab_nb_ext_conf    0.1.0                    py38_0  \r\n_libgcc_mutex             0.1                        main  \r\n_tflow_select             2.1.0                       gpu  \r\nabsl-py                   0.13.0           py38h06a4308_0  \r\nalabaster                 0.7.12             pyhd3eb1b0_0  \r\nanaconda                  2021.05                  py38_0  \r\nanaconda-client           1.7.2                    py38_0  \r\nanaconda-navigator        2.0.3                    py38_0  \r\nanaconda-project          0.9.1              pyhd3eb1b0_1  \r\nanyio                     2.2.0            py38h06a4308_1  \r\nappdirs                   1.4.4                      py_0  \r\nargh                      0.26.2                   py38_0  \r\nargon2-cffi               20.1.0           py38h27cfd23_1  \r\nasn1crypto                1.4.0                      py_0  \r\nastor                     0.8.1            py38h06a4308_0  \r\nastroid                   2.5              py38h06a4308_1  \r\nastropy                   4.2.1            py38h27cfd23_1  \r\nastunparse                1.6.3                      py_0  \r\nasync_generator           1.10               pyhd3eb1b0_0  \r\natomicwrites              1.4.0                      py_0  \r\nattrs                     20.3.0             pyhd3eb1b0_0  \r\nautopep8                  1.5.6              pyhd3eb1b0_0  \r\nbabel                     2.9.0              pyhd3eb1b0_0  \r\nbackcall                  0.2.0              pyhd3eb1b0_0  \r\nbackports                 1.0                pyhd3eb1b0_2  \r\nbackports.functools_lru_cache 1.6.4              pyhd3eb1b0_0  \r\nbackports.shutil_get_terminal_size 1.0.0              pyhd3eb1b0_3  \r\nbackports.tempfile        1.0                pyhd3eb1b0_1  \r\nbackports.weakref         1.0.post1                  py_1  \r\nbeautifulsoup4            4.9.3              pyha847dfd_0  \r\nbitarray                  2.1.0            py38h27cfd23_1  \r\nbkcharts                  0.2                      py38_0  \r\nblack                     19.10b0                    py_0  \r\nblas                      1.0                         mkl  \r\nbleach                    3.3.0              pyhd3eb1b0_0  \r\nblinker                   1.4              py38h06a4308_0  \r\nblosc                     1.21.0               h8c45485_0  \r\nbokeh                     2.3.2            py38h06a4308_0  \r\nboto                      2.49.0                   py38_0  \r\nbottleneck                1.3.2            py38heb32a55_1  \r\nbrotlipy                  0.7.0           py38h27cfd23_1003  \r\nbzip2                     1.0.8                h7b6447c_0  \r\nc-ares                    1.17.1               h27cfd23_0  \r\nca-certificates           2021.4.13            h06a4308_1  \r\ncachetools                4.2.2              pyhd3eb1b0_0  \r\ncairo                     1.16.0               hf32fb01_1  \r\ncertifi                   2020.12.5        py38h06a4308_0  \r\ncffi                      1.14.5           py38h261ae71_0  \r\nchardet                   4.0.0           py38h06a4308_1003  \r\nclick                     7.1.2              pyhd3eb1b0_0  \r\ncloudpickle               1.6.0                      py_0  \r\nclyent                    1.2.2                    py38_1  \r\ncolorama                  0.4.4              pyhd3eb1b0_0  \r\nconda                     4.10.3           py38h06a4308_0  \r\nconda-build               3.21.4           py38h06a4308_0  \r\nconda-content-trust       0.1.1              pyhd3eb1b0_0  \r\nconda-env                 2.6.0                         1  \r\nconda-package-handling    1.7.3            py38h27cfd23_1  \r\nconda-repo-cli            1.0.4              pyhd3eb1b0_0  \r\nconda-token               0.3.0              pyhd3eb1b0_0  \r\nconda-verify              3.4.2                      py_1  \r\ncontextlib2               0.6.0.post1                py_0  \r\ncoverage                  5.5              py38h27cfd23_2  \r\ncryptography              3.4.7            py38hd23ed53_0  \r\ncudatoolkit               10.1.243             h6bb024c_0  \r\ncudnn                     7.6.5                cuda10.1_0  \r\ncupti                     10.1.168                      0  \r\ncurl                      7.71.1               hbc83047_1  \r\ncycler                    0.10.0                   py38_0  \r\ncython                    0.29.23          py38h2531618_0  \r\ncytoolz                   0.11.0           py38h7b6447c_0  \r\ndask                      2021.4.0           pyhd3eb1b0_0  \r\ndask-core                 2021.4.0           pyhd3eb1b0_0  \r\ndataclasses               0.8                pyh6d0b6a4_7  \r\ndbus                      1.13.18              hb2f20db_0  \r\ndecorator                 5.0.6              pyhd3eb1b0_0  \r\ndefusedxml                0.7.1              pyhd3eb1b0_0  \r\ndiff-match-patch          20200713                   py_0  \r\ndistributed               2021.4.1         py38h06a4308_0  \r\ndocutils                  0.17.1           py38h06a4308_1  \r\nentrypoints               0.3                      py38_0  \r\net_xmlfile                1.0.1                   py_1001  \r\nexpat                     2.3.0                h2531618_2  \r\nfastcache                 1.1.0            py38h7b6447c_0  \r\nfilelock                  3.0.12             pyhd3eb1b0_1  \r\nflake8                    3.9.0              pyhd3eb1b0_0  \r\nflask                     1.1.2              pyhd3eb1b0_0  \r\nfontconfig                2.13.1               h6c09931_0  \r\nfreetype                  2.10.4               h5ab3b9f_0  \r\nfribidi                   1.0.10               h7b6447c_0  \r\nfsspec                    0.9.0              pyhd3eb1b0_0  \r\nfuture                    0.18.2                   py38_1  \r\ngast                      0.4.0                      py_0  \r\nget_terminal_size         1.0.0                haa9412d_0  \r\ngevent                    21.1.2           py38h27cfd23_1  \r\nglib                      2.68.1               h36276a3_0  \r\nglob2                     0.7                pyhd3eb1b0_0  \r\ngmp                       6.2.1                h2531618_2  \r\ngmpy2                     2.0.8            py38hd5f6e3b_3  \r\ngoogle-auth               1.21.3                     py_0  \r\ngoogle-auth-oauthlib      0.4.4              pyhd3eb1b0_0  \r\ngoogle-pasta              0.2.0                      py_0  \r\ngperftools                2.7                  h767d802_2    conda-forge\r\ngraphite2                 1.3.14               h23475e2_0  \r\ngreenlet                  1.0.0            py38h2531618_2  \r\ngrpcio                    1.36.1           py38h2157cd5_1  \r\ngst-plugins-base          1.14.0               h8213a91_2  \r\ngstreamer                 1.14.0               h28cd5cc_2  \r\nh5py                      2.10.0           py38h7918eee_0  \r\nharfbuzz                  2.8.0                h6f93f22_0  \r\nhdf5                      1.10.4               hb1b8bf9_0  \r\nheapdict                  1.0.1                      py_0  \r\nhtml5lib                  1.1                        py_0  \r\nhuggingface_hub           0.0.8                      py_0    huggingface\r\nicu                       58.2                 he6710b0_3  \r\nidna                      2.10               pyhd3eb1b0_0  \r\nimageio                   2.9.0              pyhd3eb1b0_0  \r\nimagesize                 1.2.0              pyhd3eb1b0_0  \r\nimportlib-metadata        3.10.0           py38h06a4308_0  \r\nimportlib_metadata        3.10.0               hd3eb1b0_0  \r\niniconfig                 1.1.1              pyhd3eb1b0_0  \r\nintel-openmp              2021.2.0           h06a4308_610  \r\nintervaltree              3.1.0                      py_0  \r\nipykernel                 5.3.4            py38h5ca1d4c_0  \r\nipython                   7.22.0           py38hb070fc8_0  \r\nipython_genutils          0.2.0              pyhd3eb1b0_1  \r\nipywidgets                7.6.3              pyhd3eb1b0_1  \r\nisort                     5.8.0              pyhd3eb1b0_0  \r\nitsdangerous              1.1.0              pyhd3eb1b0_0  \r\njbig                      2.1                  hdba287a_0  \r\njdcal                     1.4.1                      py_0  \r\njedi                      0.17.2           py38h06a4308_1  \r\njeepney                   0.6.0              pyhd3eb1b0_0  \r\njinja2                    2.11.3             pyhd3eb1b0_0  \r\njoblib                    1.0.1              pyhd3eb1b0_0  \r\njpeg                      9b                   h024ee3a_2  \r\njson5                     0.9.5                      py_0  \r\njsonschema                3.2.0                      py_2  \r\njupyter                   1.0.0                    py38_7  \r\njupyter-packaging         0.7.12             pyhd3eb1b0_0  \r\njupyter_client            6.1.12             pyhd3eb1b0_0  \r\njupyter_console           6.4.0              pyhd3eb1b0_0  \r\njupyter_core              4.7.1            py38h06a4308_0  \r\njupyter_server            1.4.1            py38h06a4308_0  \r\njupyterlab                3.0.14             pyhd3eb1b0_1  \r\njupyterlab_pygments       0.1.2                      py_0  \r\njupyterlab_server         2.4.0              pyhd3eb1b0_0  \r\njupyterlab_widgets        1.0.0              pyhd3eb1b0_1  \r\nkeras-preprocessing       1.1.2              pyhd3eb1b0_0  \r\nkeyring                   22.3.0           py38h06a4308_0  \r\nkiwisolver                1.3.1            py38h2531618_0  \r\nkrb5                      1.18.2               h173b8e3_0  \r\nlazy-object-proxy         1.6.0            py38h27cfd23_0  \r\nlcms2                     2.12                 h3be6417_0  \r\nld_impl_linux-64          2.33.1               h53a641e_7  \r\nlibarchive                3.4.2                h62408e4_0  \r\nlibcurl                   7.71.1               h20c2e04_1  \r\nlibedit                   3.1.20210216         h27cfd23_1  \r\nlibev                     4.33                 h7b6447c_0  \r\nlibffi                    3.3                  he6710b0_2  \r\nlibgcc-ng                 9.1.0                hdf63c60_0  \r\nlibgfortran-ng            7.3.0                hdf63c60_0  \r\nliblief                   0.10.1               he6710b0_0  \r\nlibllvm10                 10.0.1               hbcb73fb_5  \r\nlibpng                    1.6.37               hbc83047_0  \r\nlibprotobuf               3.17.2               h4ff587b_1  \r\nlibsodium                 1.0.18               h7b6447c_0  \r\nlibspatialindex           1.9.3                h2531618_0  \r\nlibssh2                   1.9.0                h1ba5d50_1  \r\nlibstdcxx-ng              9.1.0                hdf63c60_0  \r\nlibtiff                   4.2.0                h85742a9_0  \r\nlibtool                   2.4.6             h7b6447c_1005  \r\nlibuuid                   1.0.3                h1bed415_2  \r\nlibuv                     1.40.0               h7b6447c_0  \r\nlibwebp-base              1.2.0                h27cfd23_0  \r\nlibxcb                    1.14                 h7b6447c_0  \r\nlibxml2                   2.9.10               hb55368b_3  \r\nlibxslt                   1.1.34               hc22bd24_0  \r\nllvmlite                  0.36.0           py38h612dafd_4  \r\nlocket                    0.2.1            py38h06a4308_1  \r\nlxml                      4.6.3            py38h9120a33_0  \r\nlz4-c                     1.9.3                h2531618_0  \r\nlzo                       2.10                 h7b6447c_2  \r\nmarkdown                  3.3.4            py38h06a4308_0  \r\nmarkupsafe                1.1.1            py38h7b6447c_0  \r\nmatplotlib                3.3.4            py38h06a4308_0  \r\nmatplotlib-base           3.3.4            py38h62a2d02_0  \r\nmccabe                    0.6.1                    py38_1  \r\nmistune                   0.8.4           py38h7b6447c_1000  \r\nmkl                       2021.2.0           h06a4308_296  \r\nmkl-service               2.3.0            py38h27cfd23_1  \r\nmkl_fft                   1.3.0            py38h42c9631_2  \r\nmkl_random                1.2.1            py38ha9443f7_2  \r\nmock                      4.0.3              pyhd3eb1b0_0  \r\nmore-itertools            8.7.0              pyhd3eb1b0_0  \r\nmpc                       1.1.0                h10f8cd9_1  \r\nmpfr                      4.0.2                hb69a4c5_1  \r\nmpmath                    1.2.1            py38h06a4308_0  \r\nmsgpack-python            1.0.2            py38hff7bd54_1  \r\nmultipledispatch          0.6.0                    py38_0  \r\nmypy_extensions           0.4.3                    py38_0  \r\nnavigator-updater         0.2.1                    py38_0  \r\nnbclassic                 0.2.6              pyhd3eb1b0_0  \r\nnbclient                  0.5.3              pyhd3eb1b0_0  \r\nnbconvert                 6.0.7                    py38_0  \r\nnbformat                  5.1.3              pyhd3eb1b0_0  \r\nncurses                   6.2                  he6710b0_1  \r\nnest-asyncio              1.5.1              pyhd3eb1b0_0  \r\nnetworkx                  2.5                        py_0  \r\nnltk                      3.6.1              pyhd3eb1b0_0  \r\nnose                      1.3.7           pyhd3eb1b0_1006  \r\nnotebook                  6.3.0            py38h06a4308_0  \r\nnumba                     0.53.1           py38ha9443f7_0  \r\nnumexpr                   2.7.3            py38h22e1b3c_1  \r\nnumpy                     1.20.1           py38h93e21f0_0  \r\nnumpy-base                1.20.1           py38h7d8b39e_0  \r\nnumpydoc                  1.1.0              pyhd3eb1b0_1  \r\noauthlib                  3.1.1              pyhd3eb1b0_0  \r\nolefile                   0.46                       py_0  \r\nopenpyxl                  3.0.7              pyhd3eb1b0_0  \r\nopenssl                   1.1.1k               h27cfd23_0  \r\nopt_einsum                3.3.0              pyhd3eb1b0_1  \r\npackaging                 20.9               pyhd3eb1b0_0  \r\npandas                    1.2.4            py38h2531618_0  \r\npandoc                    2.12                 h06a4308_0  \r\npandocfilters             1.4.3            py38h06a4308_1  \r\npango                     1.45.3               hd140c19_0  \r\nparso                     0.7.0                      py_0  \r\npartd                     1.2.0              pyhd3eb1b0_0  \r\npatchelf                  0.12                 h2531618_1  \r\npath                      15.1.2           py38h06a4308_0  \r\npath.py                   12.5.0                        0  \r\npathlib2                  2.3.5            py38h06a4308_2  \r\npathspec                  0.7.0                      py_0  \r\npatsy                     0.5.1                    py38_0  \r\npcre                      8.44                 he6710b0_0  \r\npep8                      1.7.1                    py38_0  \r\nperl                      5.26.2               h14c3975_0  \r\npexpect                   4.8.0              pyhd3eb1b0_3  \r\npickleshare               0.7.5           pyhd3eb1b0_1003  \r\npillow                    8.2.0            py38he98fc37_0  \r\npip                       21.0.1           py38h06a4308_0  \r\npixman                    0.40.0               h7b6447c_0  \r\npkginfo                   1.7.0            py38h06a4308_0  \r\npluggy                    0.13.1           py38h06a4308_0  \r\nply                       3.11                     py38_0  \r\nprometheus_client         0.10.1             pyhd3eb1b0_0  \r\nprompt-toolkit            3.0.17             pyh06a4308_0  \r\nprompt_toolkit            3.0.17               hd3eb1b0_0  \r\nprotobuf                  3.17.2           py38h295c915_0  \r\npsutil                    5.8.0            py38h27cfd23_1  \r\nptyprocess                0.7.0              pyhd3eb1b0_2  \r\npy                        1.10.0             pyhd3eb1b0_0  \r\npy-lief                   0.10.1           py38h403a769_0  \r\npyasn1                    0.4.8                      py_0  \r\npyasn1-modules            0.2.8                      py_0  \r\npycodestyle               2.6.0              pyhd3eb1b0_0  \r\npycosat                   0.6.3            py38h7b6447c_1  \r\npycparser                 2.20                       py_2  \r\npycurl                    7.43.0.6         py38h1ba5d50_0  \r\npydocstyle                6.0.0              pyhd3eb1b0_0  \r\npyerfa                    1.7.3            py38h27cfd23_0  \r\npyflakes                  2.2.0              pyhd3eb1b0_0  \r\npygments                  2.8.1              pyhd3eb1b0_0  \r\npyjwt                     2.1.0            py38h06a4308_0  \r\npylint                    2.7.4            py38h06a4308_1  \r\npyls-black                0.4.6                hd3eb1b0_0  \r\npyls-spyder               0.3.2              pyhd3eb1b0_0  \r\npyodbc                    4.0.30           py38he6710b0_0  \r\npyopenssl                 20.0.1             pyhd3eb1b0_1  \r\npyparsing                 2.4.7              pyhd3eb1b0_0  \r\npyqt                      5.9.2            py38h05f1152_4  \r\npyrsistent                0.17.3           py38h7b6447c_0  \r\npysocks                   1.7.1            py38h06a4308_0  \r\npytables                  3.6.1            py38h9fd0a39_0  \r\npytest                    6.2.3            py38h06a4308_2  \r\npython                    3.8.8                hdb3f193_5  \r\npython-dateutil           2.8.1              pyhd3eb1b0_0  \r\npython-flatbuffers        1.12               pyhd3eb1b0_0  \r\npython-jsonrpc-server     0.4.0                      py_0  \r\npython-language-server    0.36.2             pyhd3eb1b0_0  \r\npython-libarchive-c       2.9                pyhd3eb1b0_1  \r\npython_abi                3.8                      1_cp38    huggingface\r\npytz                      2021.1             pyhd3eb1b0_0  \r\npywavelets                1.1.1            py38h7b6447c_2  \r\npyxdg                     0.27               pyhd3eb1b0_0  \r\npyyaml                    5.4.1            py38h27cfd23_1  \r\npyzmq                     20.0.0           py38h2531618_1  \r\nqdarkstyle                2.8.1                      py_0  \r\nqt                        5.9.7                h5867ecd_1  \r\nqtawesome                 1.0.2              pyhd3eb1b0_0  \r\nqtconsole                 5.0.3              pyhd3eb1b0_0  \r\nqtpy                      1.9.0                      py_0  \r\nreadline                  8.1                  h27cfd23_0  \r\nregex                     2021.4.4         py38h27cfd23_0  \r\nrequests                  2.25.1             pyhd3eb1b0_0  \r\nrequests-oauthlib         1.3.0                      py_0  \r\nripgrep                   12.1.1                        0  \r\nrope                      0.18.0                     py_0  \r\nrsa                       4.7.2              pyhd3eb1b0_1  \r\nrtree                     0.9.7            py38h06a4308_1  \r\nruamel_yaml               0.15.100         py38h27cfd23_0  \r\nsacremoses                master                     py_0    huggingface\r\nscikit-image              0.18.1           py38ha9443f7_0  \r\nscikit-learn              0.24.1           py38ha9443f7_0  \r\nscipy                     1.6.2            py38had2a1c9_1  \r\nseaborn                   0.11.1             pyhd3eb1b0_0  \r\nsecretstorage             3.3.1            py38h06a4308_0  \r\nsend2trash                1.5.0              pyhd3eb1b0_1  \r\nsentencepiece             0.1.91           py38hbf85e49_3    conda-forge\r\nsetuptools                52.0.0           py38h06a4308_0  \r\nsimplegeneric             0.8.1                    py38_2  \r\nsingledispatch            3.6.1           pyhd3eb1b0_1001  \r\nsip                       4.19.13          py38he6710b0_0  \r\nsix                       1.15.0           py38h06a4308_0  \r\nsniffio                   1.2.0            py38h06a4308_1  \r\nsnowballstemmer           2.1.0              pyhd3eb1b0_0  \r\nsortedcollections         2.1.0              pyhd3eb1b0_0  \r\nsortedcontainers          2.3.0              pyhd3eb1b0_0  \r\nsoupsieve                 2.2.1              pyhd3eb1b0_0  \r\nsphinx                    4.0.1              pyhd3eb1b0_0  \r\nsphinxcontrib             1.0                      py38_1  \r\nsphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  \r\nsphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  \r\nsphinxcontrib-htmlhelp    1.0.3              pyhd3eb1b0_0  \r\nsphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  \r\nsphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  \r\nsphinxcontrib-serializinghtml 1.1.4              pyhd3eb1b0_0  \r\nsphinxcontrib-websupport  1.2.4                      py_0  \r\nspyder                    4.2.5            py38h06a4308_0  \r\nspyder-kernels            1.10.2           py38h06a4308_0  \r\nsqlalchemy                1.4.15           py38h27cfd23_0  \r\nsqlite                    3.35.4               hdfb4753_0  \r\nstatsmodels               0.12.2           py38h27cfd23_0  \r\nsympy                     1.8              py38h06a4308_0  \r\ntbb                       2020.3               hfd86e86_0  \r\ntblib                     1.7.0                      py_0  \r\ntensorboard               2.4.0              pyhc547734_0  \r\ntensorboard-plugin-wit    1.6.0                      py_0  \r\ntensorflow                2.4.1           gpu_py38h8a7d6ce_0  \r\ntensorflow-base           2.4.1           gpu_py38h29c2da4_0  \r\ntensorflow-estimator      2.4.1              pyheb71bc4_0  \r\ntensorflow-gpu            2.4.1                h30adc30_0  \r\ntermcolor                 1.1.0            py38h06a4308_1  \r\nterminado                 0.9.4            py38h06a4308_0  \r\ntestpath                  0.4.4              pyhd3eb1b0_0  \r\ntextdistance              4.2.1              pyhd3eb1b0_0  \r\nthreadpoolctl             2.1.0              pyh5ca1d4c_0  \r\nthree-merge               0.1.1              pyhd3eb1b0_0  \r\ntifffile                  2020.10.1        py38hdd07704_2  \r\ntk                        8.6.10               hbc83047_0  \r\ntokenizers                0.10.3                   py38_0    huggingface\r\ntoml                      0.10.2             pyhd3eb1b0_0  \r\ntoolz                     0.11.1             pyhd3eb1b0_0  \r\ntornado                   6.1              py38h27cfd23_0  \r\ntqdm                      4.59.0             pyhd3eb1b0_1  \r\ntraitlets                 5.0.5              pyhd3eb1b0_0  \r\ntransformers              4.8.1                      py_0    huggingface\r\ntyped-ast                 1.4.2            py38h27cfd23_1  \r\ntyping_extensions         3.7.4.3            pyha847dfd_0  \r\nujson                     4.0.2            py38h2531618_0  \r\nunicodecsv                0.14.1                   py38_0  \r\nunixodbc                  2.3.9                h7b6447c_0  \r\nurllib3                   1.26.4             pyhd3eb1b0_0  \r\nwatchdog                  1.0.2            py38h06a4308_1  \r\nwcwidth                   0.2.5                      py_0  \r\nwebencodings              0.5.1                    py38_1  \r\nwerkzeug                  1.0.1              pyhd3eb1b0_0  \r\nwheel                     0.36.2             pyhd3eb1b0_0  \r\nwidgetsnbextension        3.5.1                    py38_0  \r\nwrapt                     1.12.1           py38h7b6447c_1  \r\nwurlitzer                 2.1.0            py38h06a4308_0  \r\nxlrd                      2.0.1              pyhd3eb1b0_0  \r\nxlsxwriter                1.3.8              pyhd3eb1b0_0  \r\nxlwt                      1.3.0                    py38_0  \r\nxmltodict                 0.12.0                     py_0  \r\nxz                        5.2.5                h7b6447c_0  \r\nyaml                      0.2.5                h7b6447c_0  \r\nyapf                      0.31.0             pyhd3eb1b0_0  \r\nzeromq                    4.3.4                h2531618_0  \r\nzict                      2.0.0              pyhd3eb1b0_0  \r\nzipp                      3.4.1              pyhd3eb1b0_0  \r\nzlib                      1.2.11               h7b6447c_3  \r\nzope                      1.0                      py38_1  \r\nzope.event                4.5.0                    py38_0  \r\nzope.interface            5.3.0            py38h27cfd23_0  \r\nzstd                      1.4.5                h9ceee32_0\r\n```\r\n\r\n", "comments": ["@Phill-at-GE ,\r\n\r\nCan you please try installing TensorFlow v2.4 with CUDA 11.0 and cuDNN 8 and check if you are facing the same error. For more information please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu).Thanks!", "Thanks for the response! So, it's a little confusing with the way the Conda Packages are set up, along with the pre-installed NVIDIA driver and CUDA toolkit. \r\n\r\nBased on the link you sent, the compatibilities are: \r\n```\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\ntensorflow-2.5.0 | 3.6-3.9 | GCC 7.3.1 | Bazel 3.7.2 | 8.1 | 11.2\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 7.6 | 10.1\r\n```\r\nBased on the Anaconda Packages, the following are available to my Linux system (using `conda search (cudnn|cudatoolkit|tensorflow)`. \r\n```\r\ncudnn                          7.6.5       cuda9.2_0  pkgs/main           \r\ncudnn                          8.2.1      cuda11.3_0  pkgs/main \r\n\r\ncudatoolkit                 11.0.221      h6bb024c_0  pkgs/main           \r\ncudatoolkit                   11.3.1      h2bc3f7f_2  pkgs/main\r\n   \r\ntensorflow                     2.4.1 gpu_py38h8a7d6ce_0  pkgs/main                \r\ntensorflow                     2.4.1 mkl_py38hb2083e0_0  pkgs/main                 \r\ntensorflow                     2.5.0 eigen_py38h94feaef_0  pkgs/main           \r\ntensorflow                     2.5.0 mkl_py38hce4fbe1_0  pkgs/main           \r\n```\r\n\r\nI can't install the needed `cuDNN==8.0` for TF 2.4 (or even the `cuDNN==8.1` for TF 2.5). Also, I can't upgrade to `tensorflow-2.5.0` since conda doesn't provide a gpu version of TensorFlow for that (I know that TF 2.x on, that TF automatically searches for GPU's but I have found with Conda that you must install the gpu version in order to get GPU's to even be recognized). \r\n\r\nThe pre-installed drivers/CUDA library on the Linux system is (nvidia-smi):\r\n```\r\nNVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2 \r\n```\r\nSo, maybe because of this, I can't even use TF 2.4 unless I uninstall the current CUDA Version: 11.2?\r\n\r\nIn summary, it seems like it is impossible to get the correct configuration required because of:\r\n1) Anaconda packages don't support cuDNN (for either TF 2.4 or TF 2.5)\r\n2) Anaconda packages don't support TF 2.5 with GPU support \r\n3) The installed CUDA version on my Linux is only for  TF 2.5.", "@Phill-at-GE ,\r\n\r\nAs mentioned, please try to install the tf v2.4 with compatible CUDA and cuDNN.Also installation issues within the Anaconda environment are tracked in the Anaconda repo.Please submit the new issue in Anaconda repo.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51400\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51400\">No</a>\n"]}, {"number": 51399, "title": "setting learning rate with `tk.backend.set_value` fails with `tf.keras.optimizers.schedules`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): '2.5.0'\r\n- Python version: '3.8.10'\r\n\r\n**Describe the current behavior**\r\n\r\nCheck the code snippet with two cases below\r\n\r\n**Describe the expected behavior**\r\n\r\nBoth the cases should succeed.\r\nCurrently, when `learning_rate` is not a schedule it works.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow.keras as tk\r\n\r\n# [1] this case works\r\n_o = tk.optimizers.Adam(learning_rate=3.44)\r\ntk.backend.set_value(_o.learning_rate, 0.01)\r\n\r\n# [2] but when using learning rate sheculer it fails\r\n_o = tk.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(0.1, 1000, 0.96))\r\ntk.backend.set_value(_o.learning_rate, 0.01)\r\n```\r\nFails with below error\r\n```txt\r\nTraceback (most recent call last):\r\n  File \"C:\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-85-b93ddba04c22>\", line 3, in <module>\r\n    tk.backend.set_value(_o.learning_rate, 0.01)\r\n  File \"C:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3769, in set_value\r\n    value = np.asarray(value, dtype=dtype(x))\r\n  File \"C:\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"C:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 1516, in dtype\r\n    return x.dtype.base_dtype.name\r\nAttributeError: 'ExponentialDecay' object has no attribute 'dtype'\r\n```\r\n\r\n", "comments": ["@pbk0,\r\n\r\nThis looks like an issue related to Keras. So can you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see;[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51399\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51399\">No</a>\n"]}, {"number": 51398, "title": "Update version numbers for TensorFlow 2.6.0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 6 -> 6\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.6.0-rc2\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"2.6.0rc2\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 51397, "title": "Update keras and estimator deps", "body": "PiperOrigin-RevId: 389672438\r\nChange-Id: Iaee9f29c10caeffad752009faa1fcafab7935b67", "comments": []}, {"number": 51396, "title": "2.6 cherry-pick request: Update tensorboard dependencies.", "body": "Update tensorboard dependency to 2.6.x and tb-nightly dependency to 2.7.x.\r\nNecessary to have a tensorboard version installed with tensorflow 2.6.0 that will work.\r\n\r\nPiperOrigin-RevId: 389635311\r\nChange-Id: I73e876a3f398463f600c4c61bfd27468a1d7a2dc", "comments": []}, {"number": 51395, "title": "[AutoML] [Tensorflow Lite] Export for TensorFlow Lite is broken for confidence score", "body": "**System information**\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.9.5\r\n\r\n**Describe the current behavior**\r\nI trained a model on a dataset via AutoML Vision and exported models[ using the UI.](https://cloud.google.com/vision/automl/object-detection/docs/export-edge)  I've used AutoML in the past and the models have always worked well.\r\n\r\nThe .tflite version has bounding boxes and class names that are perfectly correct, but the confidence scores are wrong.\r\n\r\nSpecifically, the .tflite seems to cap its confidence score at 50%. It never goes higher than 50%.\r\n\r\nGiven the same input image, the top 4 confidence scores are as follows:\r\nfor .tflite `0.5, 0.0429, 0.0273, .002343`\r\nfor tf js `0.9975, 0.02638, 0.0182, 0.00969`\r\n\r\n**Describe the expected behavior**\r\nThe top confidence score should not be 0.5 and should instead be around 0.99 in the tflite\r\n\r\nAccording to Netron, the TF run time for the TFLite was 2.5.0. For the TF JS, the model.json indicates that it was generated by 2.7.0 (the brand new release). I don't have any obvious way to select what runtime I want TFLite to be exported in.\r\n\r\n**Standalone code to reproduce the issue**\r\nI used basic code to test the TF JS\r\n```\r\n<!---- python -m SimpleHTTPServer 8000 ---->\r\n\r\n<script src=\"https://unpkg.com/@tensorflow/tfjs\"></script>\r\n<script src=\"https://unpkg.com/@tensorflow/tfjs-automl\"></script>\r\n<img id=\"salad\" crossorigin=\"anonymous\" src=\"test.jpeg\">\r\n<script>\r\nasync function run() {\r\n  const model = await tf.automl.loadObjectDetection('model.json');\r\n  const img = document.getElementById('salad');\r\nconst options = {score: 0.005, iou: 0.5, topk: 5};\r\n  const predictions = await model.detect(img, options); // , options\r\n  console.log(predictions);\r\n  // Show the resulting object on the page.\r\n  const pre = document.createElement('pre');\r\n  pre.textContent = JSON.stringify(predictions, null, 2);\r\n  document.body.append(pre);\r\n}\r\nrun();\r\n</script>\r\n```\r\n\r\nAnd the Tensorflow Lite tester:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport cv2\r\n\r\nimg = cv2.imread(\"test.jpeg\")\r\nnew_img = cv2.resize(img, (320,320))\r\n\r\n# Load the TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test the model on random input data.\r\ninterpreter.set_tensor(input_details[0]['index'], [new_img])\r\n\r\ninterpreter.invoke()\r\n\r\n# Show the scores\r\nscores = interpreter.get_tensor(output_details[2]['index'])\r\nprint(scores)\r\n```\r\n\r\n\r\nCouple of questions:\r\n1. What would a capped confidence of 50% be a symptom of? (Something weird with quantization?)\r\n2. Should I just multiple the confidence score by 2 or is that completely wrong?\r\n3. Is this the right place to post about AutoML bugs?\r\n", "comments": ["Can you please post this issue on automl repo https://github.com/google/automl for support?\r\nThis repository focuses on TF Core and TF Lite related bugs. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51395\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51395\">No</a>\n"]}, {"number": 51394, "title": "memory allocation exceeds 10 of free system memory", "body": "tensorflow2.5\r\nubuntu 18.10\r\nmemory 16gb\r\n\r\nI've added the swap memory up to 8 gb, but still showing the warning of that message. In the meaning time, I find the swap allocation is almost 0. \r\nWhat happens, the tensorflow cannot use the swap? \r\nWhich kind of memory is not enough, is it gpu memory or just physical memory?\r\nAlso I'd like to ask what happens if I continue training ignoring that warning message, the precision being lost, or other effects? \r\nWhy the training could still go on if the training result is not correct?", "comments": ["@sjtusmartboy ,\r\n\r\nPlease take a look at this link for similar error.[Link1](https://stackoverflow.com/questions/49440630/is-there-any-way-of-swapping-gpu-memory-in-tensorflow),[Link2](https://www.tutorialexample.com/fix-tensorflow-allocation-memory-allocation-exceeds-10-of-system-memory-error/).It helps.Thanks!", "In order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "@tilakrayal First thank you for your link. I've raised 4 questions, please assigned this issue to the relative engineers and ask them if they can answer, thanks.", "@sjtusmartboy ,\r\nKindly open a [tf discussion forum](https://discuss.tensorflow.org/) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51394\">No</a>\n"]}, {"number": 51392, "title": "Use new GPU kernel for [unsorted] segment reductions", "body": "- Optionally replaces the old atomics-based kernels with calls to `SegmentReduceGPU` (the same kernel already used for sparse segment reductions). This behavior is enabled by default, but the old kernels can be re-enabled by setting the environment variable `TF_USE_ATOMIC_SEGMENT_REDUCTIONS=1`. On Windows, the old kernels are always used due to a build issue with the new kernel.\r\n- This improves performance, and guarantees that these ops are deterministic. In future it is hoped that the old kernels can be removed completely.\r\n- Also adds a GPU kernel registration for `SegmentMean`, which didn't previously exist.\r\n\r\ncc @nluehr @reedwm @duncanriach ", "comments": ["First pass through this. Nice work, @benbarsdell. A couple of thoughts:\r\n\r\n1. The original code differentiated between atomic and nonatomic reductions (because there were sometimes both), but not for reasons of determinism. And, of course, atomics can be used in deterministic code. So, there's some lingering old symbology around atomic/nonatomic which has gotten tangled up with (or repurposed for) deterministic/nondeterministic operation. @sanjoy picked out one example of that above. There are other places in the code where perhaps \"non-atomic\" would ideally be replaced with \"deterministic\" and where \"atomic\" would ideally be replaced with \"nondeterministic.\"\r\n2. I'm wondering if we should add tests to confirm determinism, or if we should rely on it being deterministic by design. There will, of course, be backup testing from @reedwm's determinism auto-checker.\r\n", "Thanks for the suggestions Duncan. I'm facing some build issues right now but will push the additional atomic->deterministic rewordings tomorrow along with a rebase.\r\n\r\nI haven't looked closely at how the determinism tests work but will take a look.", "This was rolled back in https://github.com/tensorflow/tensorflow/commit/44cdcda71ef77ad200af7b9cf2c247f41423b0ed. Will investigate.", "Rolled forward in 9a1072e69c2bbff89dec51d2bc8042f5a4d0d259", "Unfortunately this was rolled back again in 51ee4155408c29a94345dd38595331b189b829fc, since it caused a performance regression in an internal model. Also, the test  `segment_reduction_ops_deterministic_test.py` failed on Windows, since the deterministic algorithms were disabled on Windows.\r\n\r\nI think the best approach here is to keep using the old nondeterministic kernels by default, and only use the new ones if either determinism is enabled or an environmental variable is set (say, `TF_USE_DETERMINISTIC_SEGMENT_REDUCTIONS`). Then the determinism API is unblocked and we can internally debug the performance issue, and potentially send you an example to reproduce.\r\n\r\n@benbarsdell, do you want to create a new PR with the new kernels disabled by default, by this Wednesday? If not, I can rollforward, disabling the new kernels by default. I want to get this in as soon as possible since it is required for determinism."]}, {"number": 51391, "title": "Add GPU kernel for SparseConcat", "body": "Adds GPU implementation and enables tests on GPU.\r\n\r\ncc @nluehr @sanjoy ", "comments": ["@penpornk could you take a look?"]}, {"number": 51390, "title": "version tag mismatch github: v2.5.0 python: 2.5.1", "body": "if you build from source from github tag v2.5.0 it produces a module file that's 2.5.1", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51390\">No</a>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51390\">No</a>\n", "nevermind I pulled branch r2.5 rather than tag v2.5.0"]}, {"number": 51389, "title": "Android Studio CPU Profiler", "body": "Hello!\r\n\r\nI have a model built with tensorflow and exported to tensorflow lite and integrated to Android Studio.  I want to profile it and hence i follow the steps [] (https://www.tensorflow.org/lite/performance/measurement#android_studio_cpu_profiler) in the section of Android Studio CPU Profiler.  However, in the end, I see no thread like the one called \"recognizeImage()\" in the example and I am not able to see the \"per-op\" profile as in the example.\r\n\r\nWhat do I need to implement to visualize the per-op results there?\r\n\r\nThank you!", "comments": ["Can you confirm that you've also followed the steps right above the section you linked?\r\nhttps://www.tensorflow.org/lite/performance/measurement#trace_tensorflow_lite_internals_in_android\r\n\r\nAlso, what version of TFLite are you running?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51389\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51389\">No</a>\n"]}, {"number": 51388, "title": "can not open include file,   \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:1.2.0\r\n- Python version:3.5.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): CMake 3.8.12\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: disable\r\n- GPU model and memory: disable\r\n\r\n\r\n\r\n**Describe the problem**\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.cc)\r\n  table.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\format.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\buffered_inputstream.cc)\r\n  table_builder.cc\r\n  two_level_iterator.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\gtl\\array_slice_internal.h(89): error C2064: \u9879\u4e0d\u4f1a\u8ba1\u7b97\u4e3a\u63a5\u53d7 0 \u4e2a\u53c2\u6570\u7684\u51fd\u6570 (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\histogram\\histogram.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\block.cc)\r\n  zlib_inputstream.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\inputbuffer.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\threadpool.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\block_builder.cc)\r\n  zlib_outputbuffer.cc\r\n  jpeg_handle.cc\r\n  jpeg_mem.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\iterator.cc)\r\n  collection_registry.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\record_reader.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\inputstream_interface.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\record_writer.cc)\r\n  distribution_sampler.cc\r\n  simple_philox.cc\r\n  weighted_picker.cc\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\random_inputstream.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\snappy\\snappy_outputbuffer.cc)\r\nf:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\core\\status.h(22): fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u5305\u62ec\u6587\u4ef6: \u201ctensorflow/core/lib/core/error_codes.pb.h\u201d: No such file or directory (\u7f16\u8bd1\u6e90\u6587\u4ef6 F:\\temp\\tensorflow-1.2.0\\tensorflow\\core\\lib\\io\\path.cc)\r\n  base64.cc\r\n  proto_text_util.cc\r\n  str_util.cc\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nwhen i use cmake to compile tensorflow from source code, raise up error.\r\nif anyone occur the same error\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["[error.log](https://github.com/tensorflow/tensorflow/files/6951901/error.log)\r\nattachment is whole error log for reference", "@zhousteven \r\nWe see that you are using older version of tensorflow ( 1.2.0 ) which is officially considered as end of life and not actively supported.We recommend that you upgrade to TF v2.5 & please let us know if the issue still persists in newer versions .Thanks!", "> @zhousteven\r\n> We see that you are using older version of tensorflow ( 1.2.0 ) which is officially considered as end of life and not actively supported.We recommend that you upgrade to TF v2.5 & please let us know if the issue still persists in newer versions .Thanks!\r\n\r\nthanks for your kindly response, according your advice, try TF v2.x", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51388\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51388\">No</a>\n"]}, {"number": 51387, "title": "Disable broken/flaky test", "body": null, "comments": []}, {"number": 51386, "title": "Disable broken/flaky test", "body": null, "comments": []}, {"number": 51385, "title": "Mixed precision not working with stateful LSTM/GRU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (Colab and own machine)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested\r\n- TensorFlow installed from (source or binary): pip from a conda env\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7.11\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: Tested with Tesla T4 (Colab) and GeForce RTX 3090 (24GB RAM)\r\n\r\n**Describe the current behavior**\r\n\r\nIt seems it is not possible to use stateful RNNs (LSTM, GRU) with mixed precision. Trying to run the following on Colab (Tesla T4):\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\r\n\r\ndata = tf.random.uniform((1, 64, 16), minval=0, maxval=1, dtype=tf.float16)\r\nrnn = tf.keras.layers.GRU(1024, return_sequences=True, stateful=True)\r\n\r\nrnn(data)\r\n```\r\n\r\nI get this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nValueError                                Traceback (most recent call last)\r\n\r\n<ipython-input-5-48878f0a1437> in <module>()\r\n----> 1 rnn(data)\r\n\r\n11 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\r\n    666 \r\n    667     if initial_state is None and constants is None:\r\n--> 668       return super(RNN, self).__call__(inputs, **kwargs)\r\n    669 \r\n    670     # If any of `initial_state` or `constants` are specified and are Keras\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n   1028         with autocast_variable.enable_auto_cast_variables(\r\n   1029             self._compute_dtype_object):\r\n-> 1030           outputs = call_fn(inputs, *args, **kwargs)\r\n   1031 \r\n   1032         if self._activity_regularizer:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)\r\n    456     else:\r\n    457       last_output, outputs, runtime, states = self._defun_gru_call(\r\n--> 458           inputs, initial_state, training, mask, row_lengths)\r\n    459 \r\n    460     if self.stateful:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in _defun_gru_call(self, inputs, initial_state, training, mask, sequence_lengths)\r\n    527         # Under eager context, check the device placement and prefer the\r\n    528         if can_use_gpu:\r\n--> 529           last_output, outputs, new_h, runtime = gpu_gru(**gpu_gru_kwargs)\r\n    530         else:\r\n    531           last_output, outputs, new_h, runtime = standard_gru(\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in gpu_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\r\n    690     outputs, h, _, _ = gen_cudnn_rnn_ops.CudnnRNN(\r\n    691         input=inputs, input_h=init_h, input_c=0, params=params,\r\n--> 692         is_training=True, rnn_mode='gru')\r\n    693 \r\n    694   last_output = outputs[-1]\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py in wrapper(*args, **kwargs)\r\n    402           'Please pass these args as kwargs instead.'\r\n    403           .format(f=f.__name__, kwargs=f_argspec.args))\r\n--> 404     return f(**kwargs)\r\n    405 \r\n    406   return tf_decorator.make_decorator(f, wrapper, decorator_argspec=f_argspec)\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\r\n    101           input_mode=input_mode, direction=direction, dropout=dropout,\r\n    102           seed=seed, seed2=seed2, is_training=is_training, name=name,\r\n--> 103           ctx=_ctx)\r\n    104     except _core._SymbolicException:\r\n    105       pass  # Add nodes to the TensorFlow graph.\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\r\n    171     is_training = True\r\n    172   is_training = _execute.make_bool(is_training, \"is_training\")\r\n--> 173   _attr_T, _inputs_T = _execute.args_to_matching_eager([input, input_h, input_c, params], ctx, [_dtypes.half, _dtypes.float32, _dtypes.float64, ])\r\n    174   (input, input_h, input_c, params) = _inputs_T\r\n    175   _inputs_flat = [input, input_h, input_c, params]\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, allowed_dtypes, default_dtype)\r\n    278         dtype = tensor.dtype\r\n    279   else:\r\n--> 280     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n    281 \r\n    282   # TODO(slebedev): consider removing this as it leaks a Keras concept.\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in <listcomp>(.0)\r\n    278         dtype = tensor.dtype\r\n    279   else:\r\n--> 280     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]\r\n    281 \r\n    282   # TODO(slebedev): consider removing this as it leaks a Keras concept.\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)\r\n    161         with Trace(trace_name, **trace_kwargs):\r\n    162           return func(*args, **kwargs)\r\n--> 163       return func(*args, **kwargs)\r\n    164 \r\n    165     return wrapped\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1533       raise ValueError(\r\n   1534           \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n-> 1535           (dtype.name, value.dtype.name, value))\r\n   1536     return value\r\n   1537 \r\n\r\nValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: <tf.Tensor: shape=(1, 1, 1024), dtype=float32, numpy=array([[[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>\r\n```\r\n\r\nPerhaps this is something to do with the dtype of the initial state - the last `ValueError` seems to be printing that tensor (hence the zeroes), with `dtype=float32`. Even if I explicitly set the initial state with a float16 tensor, however, the issue persists.\r\n\r\nIt makes no difference if I run an LSTM or GRU layer, same error.\r\n\r\nI also ran this code on my own Ubuntu machine with a GeForce RTX 3090 (24GB RAM) and got the following:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a half tensor [Op:MatMul]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nWithout `stateful=True` the code runs without a problem, returning a tensor with shape `(1, 64, 1024)` and `dtype=float16`.\r\n\r\nMixed precision is surely expected to work with stateful RNN layers. The documentation doesn't seem to indicate otherwise, unless I'm missing something.\r\n", "comments": ["On both platforms if I explicitly set the dtype of the rnn layer to tf.float16 I get:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node Qr}} = Qr[T=DT_HALF, full_matrices=false]\r\nAll kernels registered for op Qr:\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n [Op:Qr]\r\n```", "Reposted this to https://github.com/keras-team/keras/issues.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51385\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51385\">No</a>\n"]}, {"number": 51384, "title": "Fix compile error, no function call needed", "body": null, "comments": []}, {"number": 51383, "title": "Fix compile error, missing implicit conversion", "body": null, "comments": []}, {"number": 51382, "title": "Fix compile error, missing implicit conversion", "body": null, "comments": []}, {"number": 51381, "title": "Disable broken/flaky test", "body": null, "comments": []}, {"number": 51380, "title": "Exception Error while converting Keras LSTM model to TFlite model ", "body": "I have trained an LSTM model that takes in sensor values from a smartphone using Keras and currently am trying to convert the model into TFLite format to deploy it on Android Studio. However, I am facing this issue. I am relatively new to all this, therefore any pointers, suggestions and even criticism to improve my code will be very useful. The error code is too long therefore I have to snip it a little, please refer to the Google Colab file attached to see the full error\r\n\r\n### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): Tensorflow 2.3.0\r\n\r\n### Command used to run the converter\r\n\r\n```\r\n# Convert the model.\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('driver_profiler_deploy.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n```\r\n\r\n#### The output after executing the conversion line\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    195     try:\r\n--> 196       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n    197                                                  toco_flags_str, input_data_str,\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     31   \"\"\"Wraps TocoConvert with lazy loader.\"\"\"\r\n---> 32   return _pywrap_toco_api.TocoConvert(\r\n     33       model_flags_str,\r\n\r\nException: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at \"sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975\") at \"StatefulPartitionedCall@__inference_signature_wrapper_292250\") at \"StatefulPartitionedCall\")): We cannot duplicate the value since it's not constant.\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(callsite(unknown at \"sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975\") at \"StatefulPartitionedCall@__inference_signature_wrapper_292250\") at \"StatefulPartitionedCall\")): see current operation: %4 = \"tfl.unidirectional_sequence_lstm\"(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>\r\n<unknown>:0: error: Failed to duplicate values for the stateful op\r\n\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x50x6xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<[5.58075495E-4, 0.0313672647, -0.0188098513, -0.0246837344]> : tensor<4xf32>} : () -> tensor<4xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<[0.0168908536, 0.0328395516, 0.032890223, 0.0250963103, 0.0189044718, -0.0114660431, 0.0205141585, 0.0246794671, 0.0165602472, 0.0507745668, -0.00160693936, 0.0168250985, 0.0210511424, 0.0273013972, 0.0362471119, 0.0202392936, 0.0296635088, 0.0094857458, 0.0339091942, 0.0257274546, 0.0100004124, -0.0119953547, 0.0321875811, 0.0217365436, 0.0301411357, 0.0284080133, -0.00616158592, 0.0177836455, 0.037834093, 0.0353285074, 0.0446266644, 0.02094361]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<[-1, 1600]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_3 = \"std.constant\"() {value = dense<32> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value} : () -> none\r\n  %cst_5 = \"std.constant\"() {value = dense<\"0x507631BD189A80BCD5C2733ED4E290BC50CED43C3A5D883D59216B3D5C8655BE8DA77EBD0730CE3D28808CBC9849F7BDB4B8583E83AFDA3D253A9FBD61E09CBDE40B5DBE664A90BD1FEA963C8C7182BDCB83E93DD8643CBED633A7BDF8BDD63C5D85133DECE2E1BC32DDC13D878B92BD967B4BBEA4FC79BD4EAA463E394DBCBD123B213E5A4FEB3DFE63213DAA4C1BBDC5BDEE59D73D424DE8BD130735BD1E818ABDEF9E433D5A7F68BE8131F93AB20927BB599D563D932DC63D205D933BF7C3D4BD3BEE20BEA67AD1BC\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_6 = \"std.constant\"() {value = dense<\"0xC5098CBD408DDBBC314E433ECD6BDA3D6FC376BDE191E8BD0C83AA3C26A7D03CB6A3F83D69AC083ED3E450BD7C1A2ABDD5399BBD5B4856BC54154CBE3610BABD3294B3BD1893033E362EEDBDEF55183ED97FD3BD265B0DBD122FBF3A4B74C16BD246F16BE1D03DFBC\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_7 = \"std.constant\"() {value = dense<\"0x43512EBE2D7D3FBDC919BFBD6E77B93DE12A51BD7C780BBE2DA4A73CC8923D3D2B013A3C11E5A8BD9CED16BEA75EE2BC3943B0BB7EB687BDE02343BDDDCD46BD84D79ABDAB07FC3CDA7143BC824AE3BD2F1275BD5D24B8BA56A2363E5751AC3CDE06223E7679FFBD83C7B5BD\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_8 = \"std.constant\"() {value = dense<\"0xC1CE5CBC2598F43D11156ABC8639173E5D49453DECB4033E396DAF3D9020C33DFDB9353E89364A3E59B29DBC2AF5A9BD3E71513EABB5893BC79D0BBD62D7CD38CB94EABD31909E3D675939BED9DA9B3D65B9AFBD7D48733D56C0CA3CD6A9173EA0BDE33509BEA77AB0BD456201BE240DB4BE5E4C2CBEF8D79B3DFE3DAEBDB0D999BB4E39663D6196E23C2AD2463C8697C73D0963033E5964F0BDFEDAA43B121F233E\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_14 = \"std.constant\"() {value = dense<\"0x09496D3D8CCDE5BD2FAEF73D18E2D6BDFE7238BEBC7B4ABE780F26BD53138B3EF7C62DBEF485CF3DBB8291BB9FEF023EDD5F5BBE7B0C25B96605E13D19AB7CBD0C6EDC3D042BC7BDE0458D3DE12FE7BD9B5A833DF7275A3E6C28D1BC9C83E53D87FBED28192BDE1B22E3E2CA9363EE19F3B3E\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_16 = \"std.constant\"() {value = dense<\"0x231CB5BD1AE52D3EF6D2A7BD26C717BE2297C6BDEB7C47BD2CCF28BDBB5E0ABD75BC53BE884B1DBC63C86E3D1A4536BE4C5E253D22A573BE96AB413E2D9815BE74AEC0BD1E1673BCBE5805BD43E6A6BC995C223EF62F4ABE98F60A3E3219893D53D4E970ABE586DC4BC4847A73D8FCC253EEDCB55BE1F14E33D08BDCFBD8FD334BB512333BEB17B19BE14E8113E0ADA6B3D0A82593E1E270D3E5B538B3DC98F93BDE0B5F23A9E5FF5BA\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_17 = \"std.constant\"() {value = dense<\"0xC45CFBBC2D98813CD0AE393D99C27A3DF3AD7B3DA82134BCEE687FBB4B4E5FBDBEED0EBD8AFC8DBC3FEFE23CFF39F7BB5234EFBC7CC681BC741B0B3DEA3601BDE4EA72BDB121D23B301740BD4CE70C3D423C45BC57F0513C25B331BD0D05B93C3C04CBBB062967BCBAE113BDE44B993DE177D4BC7145563B0A8E44BDC3B33D3D89B0A0BCA187EBBC3F5A973DD2F6D7BCE9B07D0713C4D7258BD7C6E1C3D872B93BD48C7813D\"> : tensor<32x1600xf32>} : () -> tensor<32x1600xf32>\r\n  %cst_18 = \"std.constant\"() {value = dense<\"0xBEBAAFBEC3EB073E7179C43E0D4656BDD887BCBEDD0FA7BEFC851DBC5A6F9B3E1410183E0722133E5FE27DBE4CB3BD74173EDF66BCBEBAA2B13C\"> : tensor<4x32xf32>} : () -> tensor<4x32xf32>\r\n  %cst_19 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_20 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tfl.shape\"(%arg0) : (tensor<?x50x6xf32>) -> tensor<3xi32>\r\n  %1 = \"tfl.strided_slice\"(%0, %cst_19, %cst_20, %cst_20) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %2 = \"tfl.pack\"(%1, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %3 = \"tfl.fill\"(%2, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x32xf32>\r\n  %4 = \"tfl.unidirectional_sequence_lstm\"(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>\r\n  %5 = \"tfl.reshape\"(%4, %cst_1) : (tensor<?x50x32xf32>, tensor<2xi32>) -> tensor<?x1600xf32>\r\n  %6 = \"tfl.fully_connected\"(%5, %cst_17, %cst_0) {fused_activation_function = \"RELU\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x1600xf32>, tensor<32x1600xf32>, tensor<32xf32>) -> tensor<?x32xf32>\r\n  %7 = \"tfl.fully_connected\"(%6, %cst_18, %cst) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x32xf32>, tensor<4x32xf32>, tensor<4xf32>) -> tensor<?x4xf32>\r\n  %8 = \"tfl.softmax\"(%7) {beta = 1.000000e+00 : f32} : (tensor<?x4xf32>) -> tensor<?x4xf32>\r\n  \"std.return\"(%8) : (tensor<?x4xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"LSTM_1st_layer_input\"]}, result0 = {tf_saved_model.index_path = [\"Dense_Output_Layer\"]}, sym_name = \"serving_default\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_LSTM_1st_layer_input:0\", outputs = \"StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<?x50x6xf32>) -> tensor<?x4xf32>} : () -> ()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-514-df6454e45435> in <module>\r\n      1 # Convert the model.\r\n      2 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n----> 3 tflite_model = converter.convert()\r\n      4 \r\n      5 # Save the model.\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    785         Invalid quantization parameters.\r\n    786     \"\"\"\r\n--> 787     saved_model_convert_result = self._convert_as_saved_model()\r\n    788     if saved_model_convert_result:\r\n    789       return saved_model_convert_result\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in _convert_as_saved_model(self)\r\n    767         self._trackable_obj = _load(self.saved_model_dir,\r\n    768                                     self._saved_model_tags)\r\n--> 769         return super(TFLiteKerasModelConverterV2,\r\n    770                      self).convert(meta_graph.graph_def, input_tensors,\r\n    771                                    output_tensors)\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self, graph_def, input_tensors, output_tensors)\r\n    627 \r\n    628     # Converts model.\r\n--> 629     result = _toco_convert_impl(\r\n    630         input_data=graph_def,\r\n    631         input_tensors=input_tensors,\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    567       input_tensors, output_tensors, *args, **kwargs)\r\n    568   debug_info_str = debug_info.SerializeToString() if debug_info else None\r\n--> 569   data = toco_convert_protos(\r\n    570       model_flags.SerializeToString(),\r\n    571       toco_flags.SerializeToString(),\r\n\r\nC:\\Anaconda\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at \"sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975\") at \"StatefulPartitionedCall@__inference_signature_wrapper_292250\") at \"StatefulPartitionedCall\")): We cannot duplicate the value since it's not constant.\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(callsite(unknown at \"sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975\") at \"StatefulPartitionedCall@__inference_signature_wrapper_292250\") at \"StatefulPartitionedCall\")): see current operation: %4 = \"tfl.unidirectional_sequence_lstm\"(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>\r\n<unknown>:0: error: Failed to duplicate values for the stateful op\r\n\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x50x6xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<[5.58075495E-4, 0.0313672647, -0.0188098513, -0.0246837344]> : tensor<4xf32>} : () -> tensor<4xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<[0.0168908536, 0.0328395516, 0.032890223, 0.0250963103, 0.0189044718, -0.0114660431, 0.0205141585, 0.0246794671, 0.0165602472, 0.0507745668, -0.00160693936, 0.0168250985, 0.0210511424, 0.0273013972, 0.0362471119, 0.0202392936, 0.0296635088, 0.0094857458, 0.0339091942, 0.0257274546, 0.0100004124, -0.0119953547, 0.0321875811, 0.0217365436, 0.0301411357, 0.0284080133, -0.00616158592, 0.0177836455, 0.037834093, 0.0353285074, 0.0446266644, 0.02094361]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<[-1, 1600]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_3 = \"std.constant\"() {value = dense<32> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value} : () -> none\r\n  %cst_5 = \"std.constant\"() {value = dense<\"0x507631BD189A80BCD5C2733ED4E290BC50CED43C3A5D883D59216B3D5C8655BE8DA77EBD0730CE3D28808CBC9849F7BDB4B8583E83AFDA3D253A9FBD61E09CBDE40B5DBE664A90BD1FEA963C8C7182BDCB83E93DD8643CBED633A7BDF8BDD68A5BDEE59D73D424DE8BD130735BD1E818ABDEF9E433D5A7F68BE8131F93AB20927BB599D563D932DC63D205D933BF7C3D4BD3BEE20BEA67AD1BC\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_6 = \"std.constant\"() {value = dense<\"0xC5098CBD408DDBBC314E433ECD6BDA3D6FC376BDE191E8BD0C83AA3C26A7D03CB6A3F83D69AC083ED3E450BD7C1A2ABDD5399BBD5B4856BC54154CBE3610BABD3294B3BD1893033E362EEDBDEF55183ED97FD3BD265B0DBD122FBF3A4B74C16BD246F16BE1D03DFBC\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_7 = \"std.constant\"() {value = dense<\"0x43512EBE2D7D3FBDC919BFBD6E77B93DE12A51BD7C780BBE2DA4A73CC8923D3D2B013A3C11E5A8BD9CED16BEA75EE2BC3943B0BB7EB687BDE02343BDDDCD46BD84D79ABDAB07FC3CDA7143BC824AE3BD2F1275BD5D24B8BA56A2363E5751AC223E7679FFBD83C7B5BD\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_8 = \"std.constant\"() {value = dense<\"0xC1CE5CBC2598F43D11156ABC8639173E5D49453DECB4033E396DAF3D9020C33DFDB9353E89364A3E59B29DBC2AF5A9BD3E71513EABB5893BC79D0BBD62D7CD38CB94EABD31909E3D675939BED9DA9B3D65B9AFBD7D48733D56C0CA3CD6A9173E850162BDB7A7BDBDC2D5A53ED25AABBD816643BE480A193E1D20483D01327C3D3217353DECB9F1BCDCE961BD68D9123DC73D523975BDA28AF23BDD3CDB3D76CF45BA4C7C413D9243173D1C4A59BC7409C43CC452D9BD6DAA9D3D72594ABCC7C8023D124DD9BD8BE4E73D91EDF73CA46340BD5525DFBD96A31CBD7AC41F3E0A9989BD48A4ACBB7CC85F3ECA2F3A3C224824BE2AE865BD\"> : tensor<32x32xf32>} : () -> tensor<32x32xf32>\r\n  %cst_9 = \"std.constant\"() {value = dense<[0.0144452555, 0.0439436212, 0.0415196344, 0.0175064709, 0.0429508053, 0.0735509619, 0.0491249301, 0.0418154374, 0.0602816083, 0.045234289, 5.909860e-02, 0.0427618176, 0.0817241296, 0.0802346095, 0.0551247187, 0.0658099055, 0.0615411662, 0.00372897903, 0.0607171729, 0.0572465882, 0.0421632193, 0.0733279287, 0.031675335, 0.0185546968, 0.0603379421, 0.051861681, 3.635350e-02, 0.0380876064, 0.0809857174, 0.0439099669, 0.0539641976, 0.0418169759]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_10 = \"std.constant\"() {value = dense<[1.00700974, 1.04556596, 1.03545511, 1.0162183, 1.0175035, 1.08579636, 1.01043904, 1.04590869, 1.04253387, 1.03596485, 1.05140936, 1.03108668, 1.07964396, 1.0831908, 1.09043574, 1.02333474, 1.04881787, 1.0237242, 1.05353069, 1.04014802, 1.05490816, 1.05565023, 1.01534796, 1.03404355, 1.07461286, 1.03379011, 1.05220687, 1.02958488, 1.082533, 1.06203258, 1.0333389, 1.02156973]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_11 = \"std.constant\"() {value = dense<[-0.0155429579, -0.0149332602, -2.810480e-03, -0.00695943832, -0.0290646255, 2.06409313E-5, 0.00824266858, 0.00734761823, 0.00945399608, 0.023697529, -0.0115692951, 0.00534931803, 0.00947638787, 0.0181952436, -0.0154710943, 0.00264836196, -0.00150267023, -0.00198521675, 0.0417954363, -0.00790990796, -0.00273986137, -0.0116288625, 0.00412545074, -0.0379990861, -0.0182854049, 0.0314916559, -0.0511364788, 0.0203785244, -0.0182113275, 0.0208651014, -0.0222315397, -0.00638690404]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_12 = \"std.constant\"() {value = dense<[0.0499719679, 0.0823660269, 0.0490536653, 0.0406278074, 0.058024019, 0.117005043, 0.0509332679, 0.0851290673, 0.0671336576, 0.0613935478, 0.0641625077, 0.0680163354, 0.0695394427, 0.0915709212, 0.110055275, 0.070103921, 0.06133404, 0.0508842357, 0.046390295, 0.0355754569, 0.0540821813, 0.0656848847, 0.0382119045, 0.0256700907, 0.101019681, 0.0558630377, 0.0504671149, 0.0564667471, 0.0997239723, 0.0563018657, 0.0500954203, 0.0496940762]> : tensor<32xf32>} : () -> tensor<32xf32>\r\n  %cst_13 = \"std.constant\"() {value = dense<\"0x4C871E3EB55234BEC30F2C3EA52355BEA740A9BDC5CAF1BD945A6EBE1DC3983EB2D134BE0DD3223EC5BDBA3B2640433DF943B53DCEDB0ABE4BA540BE8E390BBE255A293E0814F2BDD4D06D3EEDFA733EFB04E93DA09EAABCEDAD30BE878FDFBDEA0BDE33509BEA77AB0BD456201BE240DB4BE5E4C2CBEF8D79B3DFE3DAEBDB0D999BB4E39663D6196E23C2AD2463C8697C73D0963033E5964F0BDFEDAA43B121F233E\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_14 = \"std.constant\"() {value = dense<\"0x09496D3D8CCDE5BD2FAEF73D18E2D6BDFE7238BEBC7B4ABE780F26BD53138B3EF7C62DBEF485CF3DBB8291BB9FEF023EDD5F5BBE7B0C25B96605E13D19AB7CBD0C6EDC3D042BC7BDE0458D3DE12FE7BD9B5A833DF7275A3E6C28D1BC9C83E53DE5271EBEC92DD83DB4A2293EB5FE95BDAE0320BE540E1A3E675613BDA1C8FBBDDE2238BE12F041BE2F79F3BCD72E763E4C2435BE9A99BCBC2733143E164F0CBE8885403E507772BD3EF096BCFAC4AA3DED5D3A3E99651E3D4C83FCBDBC70EABD696F2B3E6FDBC63DBC94673E1F0F443EC01AB9BDAFBE143E2A8CD73DC0B9983E3617E53D74624F3EEB0AEF3D80D662BE5EA33E3EEE5EEC3D74574EBE5BCE11BD361D623D34BC04BEC5BD31BE97741B3E5026853E1B9D903E063017BDCA732BBD41773A3EB1CA46BD8D0D183DAA92993E8EE6F6BB4FA8BFBD9A69713D6E0E60BE21E7403E142D8BBDFA882FBE9D5A453EBF89DF3C3706913DA1FB0D3E87B6FEBA0750153EBBB29EBCD6670BBED47462BE9F74193DA0C8973C98053DBEA83E0FBE1A551EBDC1F7D1BD8BB506BE36C3B13CEDB45B3DDE6F013DFE0E03BE89958B3E2DF4023ED028B2BC1F81F53DE07F3EBDE31E083E65F363BE003E8BBE36F76D3DBFE0093E5FAA36BE357D263D2D1D273ED077FE3C5D1AC1BDB53F883C4B41B33BF79A1E3E16BE2D3D762DC93D37D1A6BB882A323EF27FF9BDF36D5C3EEBFDF3BC8A1332BDBBE96D3E96218FBBF9D4B7BC6E52F13DE6587BBDD7DE93BDF160F03D857E47BE220E56BDACB9C2BD9D954BBEB19639BEA6A392BD6B2F843ED49711BEBCDF77BD0C94F0BDEFE2A8BC5ACFA43EF6C9103EC7590BBB46CE25BDB2631CBE96D44EBB455582BD7C936A3E5694B8BD90C781BD3919203E2A63963DA66219BE4CA96CBD4CF5FFBD773316BD34FD253EB2784B3E7B1AAC3C552D99BD3835BABD9577AABC4C373CBE319F553DDEEA38BDF95A1A3EFEEEDB3DB797293EEB6C483E78F534BEFA08C9BD94CC8EBDE3B21BBC1C4EC83DFB3532BE91DC42BE9B96ED3DF6D530BD1E7252BE24151E3D727B87BDB81556BEEBC3373D13725CBEFAF3AD3D\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_15 = \"std.constant\"() {value = dense<\"0xF8B4BE3D58147DBDC2B66DBE2EC7E9BCED1EDB3DCCBBD53D82A42E3D45B729BED0EA3E3E91EB7CBE2493CE3BE1023C41BC123E5C257DBE9C4658BD8E9AF2BDA150FF3D8C60003EE52216BD34F4DABD8C0714BE7C7D3F3D5CEBA53D3B81183DB7B1AABC88E11D3EA4F11C3C4174FDBD4F59D93BC8CB0A3DF1FCE03DFE20B93CF983113DEAA44EBEF8EE9EBD3505DDBDE494C13DB75EC6BDD7CCABBC62775C3E0E02463E3D77A3BD9E72DABD4E0BC8BB52051ABD7431D1BD3AA0903BCD2B28BEEB9AB73D4E970ABE586DC4BC4847A73D8FCC253EEDCB55BE1F14E33D08BDCFBD8FD334BB512333BEB17B19BE14E8113E0ADA6B3D0A82593E1E270D3E5B538B3DC98F93BDE0B5F23A9E5FF5BA\"> : tensor<32x6xf32>} : () -> tensor<32x6xf32>\r\n  %cst_17 = \"std.constant\"() {value = dense<\"0xC45CFBBC2D98813CD0AE393D99C27A3DF3AD7B3DA82134BCEE687FBB4B4E5FBDBEED0EBD8AFC8DBC3FEFE23CFF39F7BB5234EFBC7CC681BC741B0B3DEA3601BDE4EA72BDB121D23B301740BD4CE70C3D423C45BC57F0513C25B331BD0D05B93CBC3650BD9EB9073DE01A753C525381BDD17FD43A81FC7EBCD93D8B3C31BB3B3C7AB2AE3C4F07973D8A74903D2E087B3D203F2C3DA5D72B3D72E66EBC3264183D9C606F3C05A26A3DCE36903CAD21083BC911F3BC96D6FCBBBFD3A03C9B311A3DDC3E57B5635BD73552739A5CAF43CDB17233DBAAE27BCC90C183DD151083DFCC32FBDA29B11BD8605363DE97A51BC9DAAC33CEE03193B6C83CC3CB3808ABD269D143DEDF90E3DEB7BF43CDE7691BDE609D3BA429F11BD46DE4EBC4950583D9C2AA0BCFE4673BD7BDC21BC9FBC0E7D873C2A33333D8B734A3DE0E60B3D40C5BB3D19FC94BD1E4499BB90CA15BD3BB38F3D14FA54BD362E193DFE3BC33C4905373C1F90393DEDAE09BCB567053CD00553BC0BA1293C78C770BC1FE7F23CBD25E2BC35263D3DCC4910BDD87B323DF762533D860BA4BC91F7EFB93D55E83B50FA883A1DDE483B351A073D7BD408BD16B455BD4D63983BC79B06BDE7BB773DBC516EBB1AF827BD03190BBD9514B6BB3D3F9C3D1F873BBDC856B1BC2D56153D5ADF98BC467F193CE6CDCCBCA3C312BD2BC75C3B13E4E6BF4E3C6CE763BDDA6F38BDDD5D53BD9E664F3DF9AE11BD0D98443D5AC8E8BCE741C53BC924083D3E23813DDCBA623C2ECA9FBCD6469ABBD5AEA1BA7257043C9766A93C447A993A719FE5BAED58A93BA21597BD2C02C13B92E608BBA55196BD3502DE3BA8\"> : tensor<32x1600xf32>} : () -> tensor<32x1600xf32>\r\n  %cst_18 = \"std.constant\"() {value = dense<\"0xBEBAAFBEC3EB073E7179C43E0D4656BDD887BCBEDD0FA7BEFC851DBC5A6F9B3E1410183E0722133E5FE27DBE4CB3BBBDD8156EBEE919BB3E3B93E8BE9B5326BEAE8C7A3EE3C0A33E8FF0A73EF50D063EFBFF313C162261BE20DC383E832209BE79FCB63D0AE3DABE482082BE883185BE3CECA53DE08D863EAFCB2B3EA29FD33E2502093ECE2A0BBEBBADAB3D490FB43E8AD0D93ED74173EDF66BCBEBAA2B13C\"> : tensor<4x32xf32>} : () -> tensor<4x32xf32>\r\n  %cst_19 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_20 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tfl.shape\"(%arg0) : (tensor<?x50x6xf32>) -> tensor<3xi32>\r\n  %1 = \"tfl.strided_slice\"(%0, %cst_19, %cst_20, %cst_20) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %2 = \"tfl.pack\"(%1, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %3 = \"tfl.fill\"(%2, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x32xf32>\r\n  %4 = \"tfl.unidirectional_sequence_lstm\"(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>\r\n  %5 = \"tfl.reshape\"(%4, %cst_1) : (tensor<?x50x32xf32>, tensor<2xi32>) -> tensor<?x1600xf32>\r\n  %6 = \"tfl.fully_connected\"(%5, %cst_17, %cst_0) {fused_activation_function = \"RELU\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x1600xf32>, tensor<32x1600xf32>, tensor<32xf32>) -> tensor<?x32xf32>\r\n  %7 = \"tfl.fully_connected\"(%6, %cst_18, %cst) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x32xf32>, tensor<4x32xf32>, tensor<4xf32>) -> tensor<?x4xf32>\r\n  %8 = \"tfl.softmax\"(%7) {beta = 1.000000e+00 : f32} : (tensor<?x4xf32>) -> tensor<?x4xf32>\r\n  \"std.return\"(%8) : (tensor<?x4xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"LSTM_1st_layer_input\"]}, result0 = {tf_saved_model.index_path = [\"Dense_Output_Layer\"]}, sym_name = \"serving_default\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_LSTM_1st_layer_input:0\", outputs = \"StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<?x50x6xf32>) -> tensor<?x4xf32>} : () -> ()\r\n\r\n```\r\n\r\n### Architecture of LSTM Model\r\n```\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nLSTM_1st_layer (LSTM)        (None, 50, 32)            4992      \r\n_________________________________________________________________\r\nDropout_1 (Dropout)          (None, 50, 32)            0         \r\n_________________________________________________________________\r\nFlatten_2nd_layer (Flatten)  (None, 1600)              0         \r\n_________________________________________________________________\r\nDropout_2 (Dropout)          (None, 1600)              0         \r\n_________________________________________________________________\r\nDense_3rd_layer (Dense)      (None, 32)                51232     \r\n_________________________________________________________________\r\nDropout_3 (Dropout)          (None, 32)                0         \r\n_________________________________________________________________\r\nDense_Output_Layer (Dense)   (None, 4)                 132       \r\n=================================================================\r\nTotal params: 56,356\r\nTrainable params: 56,356\r\nNon-trainable params: 0\r\n```\r\n\r\n### 4. Google Colab file for your reference.\r\n\r\nhttps://github.com/Kimidoge/DriveProfiler-LSTM/blob/main/Driver_Classifier_using_LSTM_(Main).ipynb\r\n\r\n\r\n\r\n\r\n", "comments": ["Please try out with the recent TensorFlow version.", "> Please try out with the recent TensorFlow version.\r\n\r\nOkay I'll give that a try and will let you know ASAP. \r\nI've also ran the code using Google Colab and it seemed to worked in  converting the Keras file to TFlite. Is there any downside of using Colab to do the conversion?", "> Please try out with the recent TensorFlow version.\r\n\r\nI upgraded to Tensorflow 2.5, now I have a new error popping up as follows:\r\n\r\n``\r\nNotImplementedError: Cannot convert a symbolic Tensor (LSTM_1st_layer/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n``\r\nnumpy version: 1.20.3\r\npandas version: 1.3.1\r\n\r\nPlease help!\r\n", "Here is the full error, I forgot to include in the previous:\r\n\r\n``\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<timed exec> in <module>\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py in _method_wrapper(self, *args, **kwargs)\r\n    520     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    521     try:\r\n--> 522       result = method(self, *args, **kwargs)\r\n    523     finally:\r\n    524       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py in add(self, layer)\r\n    211           # and create the node connecting the current layer\r\n    212           # to the input layer we just created.\r\n--> 213           layer(x)\r\n    214           set_inputs = True\r\n    215 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\r\n    666 \r\n    667     if initial_state is None and constants is None:\r\n--> 668       return super(RNN, self).__call__(inputs, **kwargs)\r\n    669 \r\n    670     # If any of `initial_state` or `constants` are specified and are Keras\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in __call__(self, *args, **kwargs)\r\n    967     # >> model = tf.keras.Model(inputs, outputs)\r\n    968     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n--> 969       return self._functional_construction_call(inputs, args, kwargs,\r\n    970                                                 input_list)\r\n    971 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n   1105         layer=self, inputs=inputs, build_graph=True, training=training_value):\r\n   1106       # Check input assumptions set after layer building, e.g. input shape.\r\n-> 1107       outputs = self._keras_tensor_symbolic_call(\r\n   1108           inputs, input_masks, args, kwargs)\r\n   1109 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)\r\n    838       return nest.map_structure(keras_tensor.KerasTensor, output_signature)\r\n    839     else:\r\n--> 840       return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n    841 \r\n    842   def _infer_output_signature(self, inputs, args, kwargs, input_masks):\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)\r\n    878           self._maybe_build(inputs)\r\n    879           inputs = self._maybe_cast_inputs(inputs)\r\n--> 880           outputs = call_fn(inputs, *args, **kwargs)\r\n    881 \r\n    882         self._handle_activity_regularization(inputs, outputs)\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py in call(self, inputs, mask, training, initial_state)\r\n   1151 \r\n   1152     # LSTM does not support constants. Ignore it during process.\r\n-> 1153     inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n   1154 \r\n   1155     if isinstance(mask, list):\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in _process_inputs(self, inputs, initial_state, constants)\r\n    866         initial_state = self.states\r\n    867     elif initial_state is None:\r\n--> 868       initial_state = self.get_initial_state(inputs)\r\n    869 \r\n    870     if len(initial_state) != len(self.states):\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in get_initial_state(self, inputs)\r\n    648     dtype = inputs.dtype\r\n    649     if get_initial_state_fn:\r\n--> 650       init_state = get_initial_state_fn(\r\n    651           inputs=None, batch_size=batch_size, dtype=dtype)\r\n    652     else:\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in get_initial_state(self, inputs, batch_size, dtype)\r\n   2514 \r\n   2515   def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n-> 2516     return list(_generate_zero_filled_state_for_cell(\r\n   2517         self, inputs, batch_size, dtype))\r\n   2518 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype)\r\n   2996     batch_size = array_ops.shape(inputs)[0]\r\n   2997     dtype = inputs.dtype\r\n-> 2998   return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n   2999 \r\n   3000 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in _generate_zero_filled_state(batch_size_tensor, state_size, dtype)\r\n   3012 \r\n   3013   if nest.is_nested(state_size):\r\n-> 3014     return nest.map_structure(create_zeros, state_size)\r\n   3015   else:\r\n   3016     return create_zeros(state_size)\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\util\\nest.py in map_structure(func, *structure, **kwargs)\r\n    865 \r\n    866   return pack_sequence_as(\r\n--> 867       structure[0], [func(*x) for x in entries],\r\n    868       expand_composites=expand_composites)\r\n    869 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\util\\nest.py in <listcomp>(.0)\r\n    865 \r\n    866   return pack_sequence_as(\r\n--> 867       structure[0], [func(*x) for x in entries],\r\n    868       expand_composites=expand_composites)\r\n    869 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py in create_zeros(unnested_state_size)\r\n   3009     flat_dims = tensor_shape.TensorShape(unnested_state_size).as_list()\r\n   3010     init_state_size = [batch_size_tensor] + flat_dims\r\n-> 3011     return array_ops.zeros(init_state_size, dtype=dtype)\r\n   3012 \r\n   3013   if nest.is_nested(state_size):\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py in wrapper(*args, **kwargs)\r\n    204     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    205     try:\r\n--> 206       return target(*args, **kwargs)\r\n    207     except (TypeError, ValueError):\r\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py in wrapped(*args, **kwargs)\r\n   2909   \"\"\"\r\n   2910 \r\n-> 2911   def wrapped(*args, **kwargs):\r\n   2912     tensor = fun(*args, **kwargs)\r\n   2913     tensor._is_zeros_tensor = True\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py in zeros(shape, dtype, name)\r\n   2958         if not context.executing_eagerly():\r\n   2959           # Create a constant if it won't be very big. Otherwise create a fill\r\n-> 2960           # op to prevent serialized GraphDefs from becoming too large.\r\n   2961           output = _constant_if_small(zero, shape, dtype, name)\r\n   2962           if output is not None:\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py in _constant_if_small(value, shape, dtype, name)\r\n   2894 \r\n   2895 def _constant_if_small(value, shape, dtype, name):\r\n-> 2896   try:\r\n   2897     if np.prod(shape) < 1000:\r\n   2898       return constant(value, shape=shape, dtype=dtype, name=name)\r\n\r\n<__array_function__ internals> in prod(*args, **kwargs)\r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\numpy\\core\\fromnumeric.py in prod(a, axis, dtype, out, keepdims, initial, where)\r\n   3028     10\r\n   3029     \"\"\"\r\n-> 3030     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n   3031                           keepdims=keepdims, initial=initial, where=where)\r\n   3032 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\numpy\\core\\fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)\r\n     85                 return reduction(axis=axis, out=out, **passkwargs)\r\n     86 \r\n---> 87     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n     88 \r\n     89 \r\n\r\nC:\\Anaconda\\envs\\tensorflow25yt\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in __array__(self)\r\n    865 \r\n    866   def __array__(self):\r\n--> 867     raise NotImplementedError(\r\n    868         \"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\r\n    869         \" This error may indicate that you're trying to pass a Tensor to\"\r\n\r\nNotImplementedError: Cannot convert a symbolic Tensor (LSTM_1st_layer/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n``", "I wonder why colab version worked for conversion and not your local session. Can you please confirm if you are trying the same code in both instances?", "> I wonder why colab version worked for conversion and not your local session. Can you please confirm if you are trying the same code in both instances?\r\n\r\nI was wondering the same thing. \r\nI can confirm that I'm using the exact code as the one I ran on Google Colab. \r\n\r\nHere's a link to my repository for your reference (Error is at Line 57) :\r\nhttps://github.com/Kimidoge/DriveProfiler-LSTM/blob/main/Driver%20Classifier%20using%20LSTM%20(Main)%20-%20Github.ipynb\r\n\r\nCould it be an error I made when building the LSTM model? Many thanks for the help!", "Were you able to build model successfully using keras sequential api? Can you please share the gist of the successful trained model if available? Thanks! ", "waiting for fix ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51380\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51380\">No</a>\n"]}, {"number": 51379, "title": "InputSpec missing float64 support and wrong error message", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nThe [InputSpec](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec?hl=ja) seems to have an issue when the dtype argument is set to float64. In this case an error is produced that doesn't make much sense: `ValueError: Input 0 of layer sequential is incompatible with the layer: expected dtype=float64, found dtype=<dtype: 'float32'`; (and strangely, the opposite error (`expected dtype=float32, found dtype=<dtype: 'float64')` occurs, when only the dtype is set to float32).\r\nThe issue is illustrated in the following example with a simple custom layer. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\ntf.keras.backend.set_floatx('float64')\r\nclass TempLayer(tf.keras.layers.Activation):\r\n    def __init__(self):\r\n        super(keras.layers.Activation, self).__init__()\r\n        self.input_spec = keras.layers.InputSpec(dtype='float64',shape=(1,1))#float32/float also does not work\r\n    def call(self, input_1, training=False):\r\n        return input_1\r\n        \r\nmodel = keras.Sequential([TempLayer()])\r\nx = tf.constant([[1.4392]])\r\nprint (np.array2string(model.predict(x,steps=1), separator=', '))\r\n```", "comments": ["@rschumi0 ,\r\n\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tilakrayal it's now in the keras repo: https://github.com/keras-team/keras/issues/15226", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51379\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51379\">No</a>\n"]}, {"number": 51378, "title": "transfer learning model based on universal sentence encoder cannot save to tf model for tensorflow serving", "body": "The model is created using the following codes,\r\n\r\n    model = tf.keras.models.Sequential()\r\n\r\n    model.add(hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", input_shape=[], output_shape=[512], dtype=tf.string, trainable=False))\r\n\r\n    model.add(tf.keras.layers.Dense(10, activation='relu'))\r\n    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n\r\n    model.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\n......\r\n    model.fit(X_train, Y_train, epochs=1, validation_data=(X_test, Y_test))\r\n    model.save(model_save_loc)\r\n......\r\n\r\nI tried tensorflow 2.5.0 and 2.2.0. Both gave me the following exception when I saved the model after fully training it, (model training works perfectly)\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py\", line 277, in __del__\r\n    self._destroy_resource()\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 924, in _call\r\n    results = self._stateful_fn(*args, **kwds)\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3022, in __call__\r\n    filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\nAttributeError: 'NoneType' object has no attribute '__wrapped__'\r\n", "comments": ["To reproduce, please simply create the model using the codes and save it in 'tf' format. TIA", "@jacksonfengwa Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "@sushreebarsa  If you look at the codes and the error message, all the issues happen in tensorflow, instead of keras. any particular reason you want this issue to move to keras? ", "@jacksonfengwa This issue is more related to save and load Keras model . For more information please have a look on the [link](https://www.tensorflow.org/tutorials/keras/save_and_load) , [link1](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) ,[ link2](https://keras.io/guides/training_with_built_in_methods/) and let us know if it helps ?Thanks!", "Thanks sushreebarsa. Just opened a ticket there. will see how it goes.", "@jacksonfengwa Thank you for the update .Could you please move this issue to closed status as you have opened a new ticket in Keras repo , you will get the right help there !Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51378\">No</a>\n"]}, {"number": 51377, "title": "InputSpec argument ignored ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nThe `ndim` argument of the [InputSpec](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec?hl=ja) of a layer seems to be ignored when the `shape` argument is set. The issue is illustrated in the following example with a simple custom layer. \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\n\r\nclass TempLayer(tf.keras.layers.Activation):\r\n    def __init__(self):\r\n        super(keras.layers.Activation, self).__init__()\r\n        self.input_spec = keras.layers.InputSpec(ndim=5, shape=(1,2))\r\n    def call(self, input_1, training=False):\r\n        return input_1\r\n        \r\nmodel = keras.Sequential([TempLayer()])\r\nx = tf.constant([[1.4392, 1.9206]])\r\nprint (np.array2string(model.predict(x,steps=1), separator=', '))\r\n```\r\n", "comments": ["@rschumi0 ,\r\n\r\nPlease post this issue on [keras-team/keras](https://github.com/keras-team/keras/issues) repo.\r\nTo know more refer to:\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tilakrayal It's now in the keras repo: https://github.com/keras-team/keras/issues/15225", "@rschumi0 ,\r\nPlease feel free to move this issue to closed status,as it  has been tracked in keras repo.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51377\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51377\">No</a>\n"]}, {"number": 51376, "title": "ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.", "body": "I'm Trying to write my own RandomHSV custom layer to create faster augmentations to images (and later on just remove it from the model).\r\nthe code is as follows:\r\n```\r\n\r\nclass RandomHSV(Layer):\r\n    \"\"\"Adding Random Noise to HSV image. output is RGB\r\n  Input shape:\r\n    Arbitrary.\r\n  Output shape:\r\n    Same as input.\r\n  Arguments:\r\n    hsv_max_amp: list or tuple of the maximum amplitudes of the noise in range of [0, 1]\r\n    name: A string, the name of the layer.\r\n    NOTE: MAKE SURE INPUTS LAYERS HAS THE BATCH SIZE FIGURED BEFORE USING THIS LAYER.\r\n  \"\"\"\r\n\r\n    def __init__(self, hsv_max_amp=(0, 0, 0), batch_size=None, name=None, **kwargs):\r\n        super(RandomHSV, self).__init__(name=name, **kwargs)\r\n        # self.rand_generator = tf.random.Generator.from_seed(seed=int(time.time()))\r\n        self.hsv_max_amp = np.array(list(hsv_max_amp), dtype='float32')\r\n\r\n    def build(self, input_shape):\r\n        # self.batch_size = input_shape[0]\r\n        super(RandomHSV, self).build(input_shape)  # Be sure to call this at the end\r\n\r\n    def call(self, inputs, training=True, **kwargs):\r\n        def hsv_noise():\r\n            hsv = tf.image.rgb_to_hsv(inputs)\r\n            # the random noise is a random matrix in shape (batch_size, img_w, img_h, depth)\r\n            # after creating the random matrix, multiply it (element wise) by the self.hsv_max_amp.\r\n            # that gets multiplied by random enabler (np.random.randint(0, 2, 3) -> 3 items, 0 or 1)\r\n            # then removing an offset.\r\n            random_noise = (np.random.ranf(inputs.shape) * (\r\n                    np.random.random(1) * self.hsv_max_amp * np.random.randint(0, 2, 3)) - self.hsv_max_amp / 2) * 2\r\n            # those lines will cut any number which goes above 1 or goes below 0 (round it to 1 or 0 respectively).\r\n            hsv = tf.minimum(1., tf.maximum(0., tf.add(hsv, random_noise)))\r\n            batch = tf.image.hsv_to_rgb(hsv)\r\n            batch.set_shape(inputs.shape)\r\n            return batch\r\n\r\n        # applying hsv_noise if Training. if Testing then just passing batch forward unchanged\r\n        return control_flow_util.smart_cond(pred=training, true_fn=hsv_noise, false_fn=lambda: inputs)\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape\r\n\r\n    def get_config(self):\r\n        config = {\r\n            'hsv_max_amp': self.hsv_max_amp,\r\n            'batch_size': self.batch_size\r\n        }\r\n        base_config = super(RandomHSV, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n```\r\n\r\nWhen the whole model is built (or trying to build it self), I get the error:\r\n```\r\nTypeError: 'NoneType' object cannot be interpreted as an integer\r\n```\r\nor when I use the ```tf.random.Generator()``` class:\r\n```\r\nValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.\r\n```\r\nthis is because I don't tell the model's Inputs layers the batch size before I run it.\r\nI tried to figure out how to work around it, but the only solution is to let the model know the batch size (```Input(batch_size=BATCH_SIZE)``` layer is mandatory)\r\non other layers (such as Dense, Conv2D and so on...) its not mandatory to name the batch_size. Is there any idea how could I do it on my layer too?", "comments": ["@JJKK1313 Can you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) to expedite the troubleshooting process. Thanks!", "@kumariko I did, its that post. There is a specific template I should use? @kumariko #", "@JJKK1313 In order to reproduce the issue reported here, could you please provide the complete code and the dataset , tensorflow version you are using. Thanks!", "The version if Tensorflow is 2.4.1\r\nThe dataset is [LFW](http://vis-www.cs.umass.edu/lfw/) dataset.\r\nThe missing part from the code:\r\n```python\r\ndef get_siamese_model(input_shape, conv2d_filts):\r\n    # Define the tensors for the two input images\r\n    # ================================= THE INNER MODEL =================================\r\n    augmentations = Sequential(\r\n        [\r\n            tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.70),\r\n            RandomBrightnessLayer(max_delta=0.1, name='RandomBrightness'),\r\n            RandomHSVLayer(hsv_max_amp=[0.05, 0.25, 0], name='RandomHSVPreprocessor'),\r\n        ],\r\n        name=configurations.AUGMENTATIONS_LAYER_NAME\r\n    )\r\n\r\n    # ================================= THE INNER MODEL =================================\r\n    # THE PROBLEM IS HERE, WHEN NOT SPECIFING 'batch_size' TO INPUT LAYER.\r\n    left_input = Input(input_shape, name=\"Input1\")\r\n    right_input = Input(input_shape, name=\"Input2\")\r\n    left_input_augmented = augmentations(left_input)\r\n    right_input_augmented = augmentations(right_input)\r\n\r\n    # Generate the encodings (feature vectors) for the two images\r\n    body = build_body(input_shape=input_shape, conv2d_filts=conv2d_filts)\r\n    encoded_l = body(left_input_augmented)\r\n    encoded_r = body(right_input_augmented)\r\n    distance = Lambda(lambda embeds: euclidean_distance(embeds), name='Distance')([encoded_l, encoded_r])\r\n    # normed_layer = BatchNormalization()(distance)  # making sure the distances wont be all over the place.\r\n    distance = Dense(1, activation='sigmoid', name='Prediction')(distance)\r\n\r\n    # Connect the inputs with the outputs\r\n    siamese_net = Model(inputs=[left_input, right_input], outputs=distance)\r\n\r\n    return siamese_net\r\n\r\n\r\n# DataFrameGeneratorClass is a custom pair image generator, since nither Keras or Tensorflow has one.\r\ntrain_gen, test_gen = DataFrameGeneratorClass.create_train_test_generators(\r\n    csv_path='data.csv',\r\n    validation_split=0.1,\r\n    shuffle=True,\r\n    batch_size=32,\r\n    rescale=1. / 255.,\r\n    img_size=(128, 128),\r\n)\r\nsiamese_model = get_siamese_model(IMG_SIZE, conv2d_filts=CONV2D_FILTERS)\r\nsiamese_model.summary()\r\n\r\n# siamese_model.load_weights('check_points/29-07-21_034351/')\r\noptimizer = Adam()\r\nsiamese_model.compile(loss='binary_crossentropy',\r\n                      optimizer=optimizer,\r\n                      metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\r\nhistory = siamese_model.fit(train_gen, epochs=10, validation_data=test_gen)\r\n```\r\n\r\nIf you want the code for the generators:\r\n```python\r\nclass PairDataGenerator(tf.keras.utils.Sequence):\r\n    \"\"\"\r\n    NOTE: ON model.fit(SHUFFLE=FALSE) -> MUST BE FALSE!\r\n    \"\"\"\r\n\r\n    def __init__(self,\r\n                 df_similar: pd.DataFrame,\r\n                 df_dissimilar: pd.DataFrame,\r\n                 batch_size=256,\r\n                 shuffle=True,\r\n                 rescale: {float, None} = 1. / 255.,\r\n                 target_img_size=(128, 128),\r\n                 preprocess_function=None,\r\n                 rand_preproc_single: {ImageDataGenerator, dict} = None,\r\n                 rand_preproc_batch: list = None):\r\n        # self.batch_counter = 0\r\n        self.last_batch_index = 0\r\n        self.df_similar = df_similar.sample(frac=1).reset_index(drop=True)\r\n        self.df_dissimilar = df_dissimilar.sample(frac=1).reset_index(drop=True)\r\n        self.preprocess_function = preprocess_function\r\n        self.rescale = rescale\r\n        self.target_img_size = target_img_size\r\n        # rounding up batch size to be an even number.\r\n        self.batch_size = batch_size + (batch_size % 2 == 1)\r\n        self.shuffle = shuffle\r\n        # indexes of rows. every batch we draw 2 samples. 1 similar and 1 dissimilar\r\n        assert batch_size <= len(self.df_similar) + len(\r\n            self.df_dissimilar), f\"Cannot create batch of size {batch_size} when there \" \\\r\n                                 f\"are only {len(self.df_similar)} samples\"\r\n        self.indexes_similar = np.arange(len(self.df_similar))\r\n        self.similar_max_idx = len(self.indexes_similar) // self.batch_size\r\n        self.indexes_dissimilar = np.arange(len(self.df_dissimilar))\r\n        self.dissimilar_max_idx = len(self.indexes_dissimilar) // self.batch_size\r\n        if self.shuffle:\r\n            np.random.shuffle(self.indexes_dissimilar)\r\n            np.random.shuffle(self.indexes_similar)\r\n\r\n        self.rand_preproc_single = rand_preproc_single\r\n        self.rand_preproc_batch = rand_preproc_batch\r\n\r\n    def __len__(self):\r\n        \"\"\"Denotes the number of batches per epoch\"\"\"\r\n        return (len(self.df_similar) + len(self.df_dissimilar)) // self.batch_size\r\n\r\n    def __getitem__(self, index):\r\n        \"\"\"Generate one batch of data\"\"\"\r\n        # Generate indexes of the batch\r\n        batch_idx_sim = index % self.similar_max_idx\r\n        indexes_sim = self.indexes_similar[batch_idx_sim * (self.batch_size // 2):\r\n                                           (batch_idx_sim + 1) * (self.batch_size // 2)]\r\n\r\n        batch_idx_dissim = index % self.dissimilar_max_idx\r\n        indexes_dissim = self.indexes_dissimilar[batch_idx_dissim * (self.batch_size // 2):\r\n                                                 (batch_idx_dissim + 1) * (self.batch_size // 2)]\r\n        self.last_batch_index = index\r\n\r\n        img1 = []\r\n        img2 = []\r\n        labels = [0, 1] * (self.batch_size // 2)  # creating labels list\r\n        np.random.shuffle(labels)\r\n        same_counter = 0\r\n        diff_counter = 0\r\n        for idx, label in enumerate(labels):\r\n            if label == configurations.LABELS['same']:\r\n                img1_path, img2_path, _ = self.df_similar.iloc[indexes_sim[same_counter]]\r\n                same_counter += 1\r\n            else:\r\n                img1_path, img2_path, _ = self.df_dissimilar.iloc[indexes_dissim[diff_counter]]\r\n                diff_counter += 1\r\n\r\n            img1.append(self.load_image(img1_path))\r\n            img2.append(self.load_image(img2_path))\r\n\r\n        img1 = np.array(img1, dtype='float32')\r\n        img2 = np.array(img2, dtype='float32')\r\n        labels = np.array(labels, dtype='float32')\r\n\r\n        if self.rand_preproc_batch is not None:\r\n            for func in self.rand_preproc_batch:\r\n                img1 = func(img1)\r\n                img2 = func(img2)\r\n\r\n        return [img1, img2], labels\r\n\r\n    def on_epoch_end(self):\r\n        \"\"\"Updates indexes after each epoch\"\"\"\r\n        if (self.last_batch_index + 1) % self.dissimilar_max_idx == 0 and self.shuffle:\r\n            self.indexes_dissimilar = np.arange(len(self.df_dissimilar))\r\n            np.random.shuffle(self.indexes_dissimilar)\r\n\r\n        if (self.last_batch_index + 1) % self.similar_max_idx == 0 and self.shuffle:\r\n            self.indexes_similar = np.arange(len(self.df_similar))\r\n            np.random.shuffle(self.indexes_similar)\r\n\r\n\r\n    def load_image(self, path):\r\n        \"\"\"\r\n        loads an image using tensorflow tools\r\n        :param path: absolute path (refers to the project's folder) to the image\r\n        :return: an image array.\r\n        \"\"\"\r\n\r\n        if self.rand_preproc_single is not None:\r\n            if isinstance(self.rand_preproc_single, ImageDataGenerator):\r\n                img_arr = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\r\n                img_arr = self.rand_preproc_single.random_transform(img_arr)\r\n                img_arr = cv2.resize(img_arr, self.target_img_size)\r\n            else:\r\n                img_arr = my_utils.image_augmentations(path, **self.rand_preproc_single)\r\n        else:\r\n            img_arr = cv2.imread(path)\r\n            img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\r\n            img_arr = cv2.resize(img_arr, self.target_img_size)\r\n        if self.preprocess_function is not None:\r\n            img_arr = self.preprocess_function(img_arr)\r\n        elif self.rescale is not None:\r\n            img_arr = img_arr * self.rescale\r\n        return img_arr\r\n```\r\nand the function you saw on main:\r\n```python\r\ndef create_train_test_generators(csv_path: str,\r\n                                 pair_gen: bool = True,\r\n                                 validation_split: float = 0.1,\r\n                                 shuffle: bool = True,\r\n                                 batch_size: int = 256,\r\n                                 rescale: {float, None} = 1. / 255.,\r\n                                 img_size: tuple = (128, 128),\r\n                                 preprocess_func=None,\r\n                                 rand_preproc_single: {ImageDataGenerator, dict} = None,\r\n                                 rand_preproc_batch: list = None,\r\n                                 ):\r\n    \"\"\"\r\n    Initialization\r\n    :param rand_preproc_batch: list of functions which augments a whole batch.\r\n    :param rand_preproc_single: an ImageDataGenerator Instance or dictionary for my_utils.image_augmentation function.\r\n    :param pair_gen: boolean. True = Pair Gen. False = Triplets Gen.\r\n    :param rescale: rescaling factor\r\n    :param preprocess_func: a preprocessing function for the network's inputs.\r\n    :param img_size: the size of the output image.\r\n    :param batch_size: batch size\r\n    :param shuffle: whether to shuffle the data before casting to Train Test.\r\n    :param csv_path: the path to the csv file which we create DataFrame object from.\r\n    :param validation_split: how much from the whole data goes to validation.\r\n    \"\"\"\r\n    from sklearn.model_selection import train_test_split\r\n\r\n    # read all the csv file\r\n    df = pd.read_csv(csv_path, index_col=False)\r\n\r\n    params = dict(batch_size=batch_size,\r\n                  shuffle=shuffle,\r\n                  rescale=rescale,\r\n                  target_img_size=img_size,\r\n                  preprocess_function=preprocess_func,\r\n                  rand_preproc_single=rand_preproc_single,\r\n                  rand_preproc_batch=rand_preproc_batch)\r\n    if pair_gen:\r\n        # split the rows to similar and dissimilar by label column\r\n        df_similar = df.where(df['labels'] == 1.0).dropna().reset_index(drop=True)\r\n        df_dissimilar = df.where(df['labels'] == 0.0).dropna().reset_index(drop=True)\r\n\r\n        print(len(df_dissimilar), len(df_similar))\r\n        print(f\"Found {len(df)} pairs.\")\r\n\r\n        # split similar and dissimilar to train and test (4 groups)\r\n        df_train_similar, df_test_similar = train_test_split(df_similar, test_size=validation_split, shuffle=shuffle)\r\n        df_train_dissimilar, df_test_dissimilar = train_test_split(df_dissimilar, test_size=validation_split,\r\n                                                                   shuffle=shuffle)\r\n\r\n        # drop the index column, no need of that.\r\n        df_train_similar = df_train_similar.reset_index(drop=True)\r\n        df_test_similar = df_test_similar.reset_index(drop=True)\r\n        df_train_dissimilar = df_train_dissimilar.reset_index(drop=True)\r\n        df_test_similar = df_test_similar.reset_index(drop=True)\r\n\r\n        # print(len(pd.merge(df_train_similar, df_train_dissimilar, how='inner', on=['img1_p', 'img2_p', 'labels'])))\r\n\r\n        print(f\"Total={len(df)}\",\r\n              f\"Train={len(df_train_similar)} + {len(df_train_dissimilar)}\",\r\n              f\"Test={len(df_test_similar)} + {len(df_test_dissimilar)}\", sep='\\n')\r\n        return PairDataGenerator(df_similar=df_train_similar, df_dissimilar=df_train_dissimilar, **params), \\\r\n               PairDataGenerator(df_similar=df_test_similar, df_dissimilar=df_test_dissimilar, **params)\r\n\r\n    else:\r\n        print(f\"Found {len(df)} triplets.\")\r\n\r\n        # split similar and dissimilar to train and test (4 groups)\r\n        df_train, df_test = train_test_split(df,\r\n                                             test_size=validation_split,\r\n                                             shuffle=shuffle)\r\n\r\n        # drop the index column, no need of that.\r\n        df_train = df_train.reset_index(drop=True)\r\n        df_test = df_test.reset_index(drop=True)\r\n\r\n        # print(len(pd.merge(df_train_similar, df_train_dissimilar, how='inner', on=['img1_p', 'img2_p', 'labels'])))\r\n\r\n        print(f\"Total={len(df)}\",\r\n              f\"Train={len(df_train)}\",\r\n              f\"Test={len(df_test)}\", sep='\\n')\r\n\r\n        return TripletDataGenerator(df=df_train, **params), \\\r\n               TripletDataGenerator(df=df_test, **params)\r\n```\r\nNotice that the ```else``` part isn't relevant here so I didn't add it. If you still want it, let me know.\r\n\r\n", "@JJKK1313 Thank you for the response ! We see that this issue is more related to Keras .Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) To know more see; [https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)  .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51376\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51376\">No</a>\n"]}, {"number": 51375, "title": "trainable_variables being empty in tf2.5", "body": "tf2.5\r\n```\r\n\r\ninitial = tf.random.normal(shape=[2, 5], mean=0, stddev=0.05, dtype=tf.dtypes.float64)\r\ninitial = tf.Variable(initial, name='eeeeeee', trainable=True)\r\n\r\nprint(tf.compat.v1.trainable_variables())\r\n```\r\n\r\nIn tf2.5, the above output is [ ], but in tf1.13, it has variables `[<tf.Variable 'eeeeeee:0' shape=(2, 5) dtype=float64_ref>]`. Why?", "comments": ["@sjtusmartboy Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@sushreebarsa try the code and you will find it", "@sjtusmartboy I tried to run your code on colab with TF v2.5 and 1.15, and was able to replicate the issue as reported here .\r\n`tf.compat.v1.trainable_variables()`  API was designed for TensorFlow v1. Please refer to this [link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/trainable_variables?version=nightly) to migrate from this API to a native TensorFlow v2 equivalent and let us know if it helps? Thank you!", "@sushreebarsa thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51375\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51375\">No</a>\n"]}, {"number": 51374, "title": "Add expected failing test for path with glob", "body": "Add a failing test for https://github.com/tensorflow/tensorflow/issues/35489\r\n\r\n/cc @mihaimaruseac \r\n\r\nYou can test locally with:\r\n`bazel test --test_arg=FileIoTest.testGetMatchingFilesWhenContainsGlob  //tensorflow/python/lib/io:file_io_test`\r\n\r\nWhen the test will fail it is probably fixed and you can remove `@unittest.expectedFailure` to pass the test. \r\nYou could temp comment `#@unittest.expectedFailure` for debugging the failure when you are developing a fix.\r\n\r\nWhen it will be fixed, more in general it is suggested that you will locally test the whole target:\r\n`bazel test --test_arg=FileIoTest.testGetMatchingFilesWhenContainsGlob  //tensorflow/python/lib/io:file_io_test`", "comments": ["@gbaned I don't think It could be classfied as `prtype:bugfix`. \n@mihaimaruseac Probably we need to creare a new label.", "Check if you like with a message when it fail (so when it is probably fixed).", "@mihaimaruseac We had an `import/copybara` fail, let me know tomorrow", "Here are the internal errors, @bhack  can you please verify ?\r\n\r\nTraceback (most recent call last):\r\n  File \"/tensorflow/python/lib/io/file_io_test.py\", line 59, in tearDown\r\n    file_io.delete_recursively(self._base_dir)\r\n  File \"/tensorflow/python/lib/io/file_io.py\", line 664, in delete_recursively\r\n    delete_recursively_v2(dirname)\r\n  File \"/tensorflow/python/lib/io/file_io.py\", line 677, in delete_recursively_v2\r\n    _pywrap_file_io.DeleteRecursively(compat.path_to_bytes(path))\r\ngoogle3.third_party.tensorflow.python.framework.errors_impl.FailedPreconditionError: Delete failed: /tmp/tmprxj1885g/base_dir/[dir_special]: Directory not empty", "@gbaned I haven't visibility about these internal tests. We need to wait for @mihaimaruseac ", "@mihaimaruseac \r\n\r\nCan I wrap this as a conditional expected fail for the copybara internal env (if is it still in the oss sourcecode)?\r\n\r\n```\r\n_pywrap_file_io.DeleteRecursively(compat.path_to_bytes(path))\r\ngoogle3.third_party.tensorflow.python.framework.errors_impl.FailedPreconditionError: Delete failed: /tmp/tmprxj1885g/base_dir/[dir_special]: Directory not empty\r\n```\r\n", "Thank you for running this but it is failing again internally. \r\nI will close this as we don't have a clear position and allocated resources about the expecting failing tests proposal.\r\n\r\nI will open some of these PRs again in the case this process it will be officially approved."]}, {"number": 51373, "title": "[tflite] add same scale constraint to tflite's mean op", "body": "Add SameOperandsAndResultsScal to tflite's mean. Without this constraint, post-training quantization ([PTQ](https://www.tensorflow.org/lite/performance/post_training_quantization)) may result in MEAN with different quantization scales for inputs and outputs. Because NNAPI only supports MEAN with same quantization parameters for inputs and output, this kind of mean ops could not be delegated to NNAPI via the NNAPI delegate.\r\n\r\nE.g., if we do PTQ on the [ResNet 50 from tfhub](https://tfhub.dev/tensorflow/resnet_50/classification/1),\r\n```python\r\nimport itertools\r\nimport os\r\nimport pathlib\r\nimport requests\r\nimport tarfile\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nsaved_model_dir = \"./resnet_saved_model/\"\r\nresnet_saved_model_file = \"https://tfhub.dev/tensorflow/resnet_50/classification/1?tf-hub-format=compressed\"\r\nresponse = requests.get(resnet_saved_model_file, stream=True)\r\nfile = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\r\nfile.extractall(path=saved_model_dir)\r\n\r\nimagenet_validation = tfds.load(name=\"imagenet2012\", split=\"validation\")\r\n\r\ndef representative_data_gen():\r\n  for imagenet_example in imagenet_validation.take(100):\r\n    image, label = imagenet_example[\"image\"], imagenet_example[\"label\"]\r\n    image = tf.cast(image, tf.float32) / 255.0\r\n    image = tf.image.central_crop(image, central_fraction=0.875)\r\n    image = tf.expand_dims(image, 0)\r\n    image = tf.image.resize(image, (224,224))\r\n    yield [image]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8 \r\nconverter.inference_output_type = tf.int8 \r\ntflite_quant_model = converter.convert()\r\n\r\ntflite_quant_model_file = pathlib.Path('/tmp')/\"resnet50_quant.tflite\"\r\ntflite_quant_model_file.write_bytes(tflite_quant_model)\r\n```\r\nthen `adb push /tmp/resnet50_quant.tflite /data/local/tmp/`, and run `benchmark_model` on device (here I ran it on a Pixel 4)\r\n```\r\n$ ./benchmark_model_validation --graph=resnet50_qnant.tflite   --use_nnapi=1 --enable_op_profiling=1\r\n\r\n```\r\nIt shows something like:\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [resnet_v15_quant_original_mean.tflite]\r\nEnable op profiling: [1]\r\nUse NNAPI: [1]\r\nNNAPI accelerators available: [qti-default,qti-dsp,qti-gpu,google-edgetpu,nnapi-reference]\r\nLoaded model resnet50_quant.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nNNAPI delegate created.\r\nWARNING: Operator MEAN (v2) refused by NNAPI delegate: NNAPI requires that the input and output have the same quantization parameters.\r\nINFO: Replacing 75 node(s) with delegate (TfLiteNnapiDelegate) node, yielding 3 partitions.\r\nExplicitly applied NNAPI delegate, and the model graph will be partially executed by the delegate w/ 2 delegate kernels.\r\n.......\r\nOperator-wise Profiling Info for Regular Benchmark Runs:\r\n============================== Run Order ==============================\r\n\t             [node type]\t          [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t     TfLiteNnapiDelegate\t            0.009\t   14.431\t   14.449\t 48.545%\t 48.545%\t     0.000\t        1\t[resnet50/activation_48/Relu;resnet50/add_15/add]:76\r\n\t                    MEAN\t           14.460\t   13.399\t   13.501\t 45.359%\t 93.904%\t     0.000\t        1\t[resnet50/reduce_mean/Mean]:73\r\n\t     TfLiteNnapiDelegate\t           27.962\t    1.754\t    1.814\t  6.096%\t100.000%\t     0.000\t        1\t[StatefulPartitionedCall:0]:77\r\n.......\r\nNumber of nodes executed: 3\r\n============================== Summary by node type ==============================\r\n\t             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\r\n\t     TfLiteNnapiDelegate\t        2\t    16.263\t    54.642%\t    54.642%\t     0.000\t        2\r\n\t                    MEAN\t        1\t    13.500\t    45.358%\t   100.000%\t     0.000\t        1\r\n\r\nTimings (microseconds): count=50 first=29584 curr=22585 min=22585 max=33233 avg=29764 std=1779\r\nMemory (bytes): count=0\r\n3 nodes observe\r\n```\r\nWith this constraint applied, for the same ResNet 50 model, I got something like the following:\r\n```\r\n....\r\nNumber of nodes executed: 1\r\n============================== Summary by node type ==============================\r\n\t             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\r\n\t     TfLiteNnapiDelegate\t        1\t    14.762\t   100.000%\t   100.000%\t     0.000\t        1\r\n\r\nTimings (microseconds): count=67 first=14774 curr=15087 min=13959 max=15226 avg=14762.4 std=248\r\nMemory (bytes): count=0\r\n1 nodes observed\r\n```", "comments": ["@multiverse-tf and @miaowang14 For your information, I ran into some PTQ models with TFLite MEAN v2 which is not supported NNAPI.", "Since TFLite kernel supports mean op with different input and output  scales, this would solve NNAPI issue but might introduce problems for other models' performance. I think this fix will surely be an easiest way to get models running with NNAPI, but more complex but safer fix would be needed to prevent regressions.", "@miaowang14  Instead of failing on the NNAPI side, can we reject the partition when there are unsupported cases in the Mean op in the partitioning logic in the NNAPI delegate? ", "> @miaowang14  Instead of failing on the NNAPI side, can we reject the partition when there are unsupported cases in the Mean op in the partitioning logic in the NNAPI delegate? \r\n\r\n@abattery The MEAN op is rejected by the NNAPI delegate now (not by the NNAPI runtime or drivers)\r\nThe following `WARNING` is generated by the NNAPI delegate\r\n```\r\nWARNING: Operator MEAN (v2) refused by NNAPI delegate: NNAPI requires that the input and output have the same quantization parameters.\r\n```", "I see. Thanks @freedomtan for the quick confirmation.\r\n\r\nThere will be something we can do when we would like to convert the given graph based on the related circumstances. @renjie-liu Please take a look.", "@teijeong, @abattery and @renjie-liu As far as I can tell, yes, TFLite MEAN kernel supports mean op with different input and output scales, but that means implicit re-quantization is done inside the kernel. My guess is that there is no performance lost when scales are the same. I guess if proper logic is added into kernel, same quantization scale should be a bit faster. There could be potential accuracy issues though.\r\n\r\n| original | after this one-line patch|\r\n| ---------- | -------------------------------|\r\n| <img src=\"https://user-images.githubusercontent.com/3395998/128652923-02075170-4058-4e81-acbd-5dfe652cd957.png\" width=\"100%\" height=\"100%\">|  <img src=\"https://user-images.githubusercontent.com/3395998/128653097-454de22f-8974-4d2e-8bab-e0f48ddb83d8.png\" width=\"100%\" height=\"100%\">\r\n|", "I think there are a few things:\r\n\r\n- It's not guaranteed mean op should have same scale for both inputs & outputs, imagine you have an input tensor [-3.0, 0.0, 3.0], the reduced output will be just [0.0] (the scale shrunk down!) \r\n- So Ensure the input output have the same scale does not help on keeping accuracy (and it hurt the accuracy)\r\n- Well, it does not simplify the implementation either: For reduce mean, you will still need to do at least one \"division\" : sum(elements) / element_count, and you actually fuse the input-output scale withe the element_count, see how we implemented [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/optimized/integer_ops/mean.h#L210-L213) \r\n- TfLite CPU kernel supports different scales for mean op.\r\n\r\nTo sum up, I don't think we should add the constraints to the Mean op for the reasons mentioned above, instead, we should fix on the NNAPI side.\r\n\r\nIf you need a temporary workaround, I think you should go for reduce_sum then a broadcast_mul with (reciprocal of tensor shape).", "@renjie-liu Agree there could be accuracy problem, but I don't see why shrunk scale is better. We know MEAN (different from some common cases, such as CONCAT) is a special case that same scale constraint for inputs and outputs is guaranteed to work most of time.", "You can consider `mean` is more like a \"smoother\" operation, so `mean` can shrink the output range (a lot).\r\n\r\nI agree that maybe let `mean` have the same constraint for inputs and outputs can work sometime, but I don't think that can work for all cases.\r\n\r\n`avg_pool` may have this constraint since most of the time the window size is not large, `mean` is more like a global `avg_pool` so the situation may change.\r\n\r\nOn the safe side, I think we should keep the current setting for `mean`, we probably can push NNAPI to fix the issue.\r\n\r\nAs for the temporary workaround, I think you can either do: reduce_sum then divide the element_count or you can just transform the mean op into a global avg_pool.", "Thanks for the comments. I'll close this and open an issue instead later."]}, {"number": 51372, "title": "Fix build", "body": null, "comments": []}, {"number": 51371, "title": "Fix build", "body": null, "comments": []}]