[{"number": 3075, "title": "Fix for iOS compile problems", "body": "Fixes #3065 and #3004 \n", "comments": []}, {"number": 3074, "title": "Tensorflow compile failed", "body": "bazel's version :0.30\ntensorflow's version: git clone lastest source code\ncuda: 7.0\ni've tried compiling tensorflow and get the following error:\n@damienmg @vrv \n\n---\n\nERROR: /home/scw4350/yxc/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/scw4350/.cache/bazel/_bazel_scw4350/e4878b1a7f151dbce57ddd078b0591b0/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/home/scw4350/bin:/usr/local/cuda-7.0/bin:/usr/local/cuda-7.5/bin:/home/scw4350/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o' -fPIC -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/highwayhash -isystem bazel-out/local_linux-opt/genfiles/external/highwayhash -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-802d984ade26 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-802d984ade26 -isystem external/zlib_archive/zlib-1.2.8 -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive/zlib-1.2.8 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -MD -MF bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionFwdAlgo_t perftools::gputools::cuda::{anonymous}::ToConvForwardAlgo(perftools::gputools::dnn::AlgorithmType)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:271:10: error: 'CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING' was not declared in this scope\n     case CUDNN_CONVOLUTION_FWD_ALGO_FFT_TILING:\n          ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In function 'cudnnConvolutionBwdDataAlgo_t perftools::gputools::cuda::{anonymous}::ToConvBackwardDataAlgo(perftools::gputools::dnn::AlgorithmType)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:289:10: error: 'CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING' was not declared in this scope\n     case CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT_TILING:\n", "comments": ["That's a CUDA C++ error. I am mostly unfamiliar. I hope that @vrv can help. Sorry.\n", "I'm getting the same error using the same specifications. It happens when I try to build on an EC2 Ubuntu linux 14.04.\n", "My guess is that cuda_dnn.cc is now using symbols only available in later versions of cudnn.  Try upgrading / using cudnn v4 or higher?\n", "Thanks @vrv, using cudnn v4 solved it for me.\n", "Great news, closing issue.\n"]}, {"number": 3073, "title": "tf.reset_default_graph() doesn't work on kubernetes?", "body": "In my understanding reset_default_graph() will reset the whole graph. However, it seems that this will only reset the value of variables when running parameter servers on kubernetes.\n\nFirst, I tried to get variable values before and after reset_default_graph(). The value is reset (value is 0) after running reset_default_graph().\n\nThen I tried to run a totally different algorithm using the same parameter server, it reported the error below:\n\n**Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64] rhs shape= [50000]**\n\nOnly chief run the reset_default_graph()  cmd. The code is:\n\n```\nis_chief = (FLAGS.worker_index == 0)\nif is_chief: tf.reset_default_graph()\n```\n\nThe whole error message is:\n\n```\nTraceback (most recent call last):                                                                                                 \n  File \"word2vector.py\", line 160, in <module>                                                                                     \n    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:                                        \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 685, in prepare_or_wait_for_session \n    config=config, init_feed_dict=self._init_feed_dict)                                                                            \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 163, in prepare_session        \n    sess.run(init_op, feed_dict=init_feed_dict)                                                                                    \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run                              \n    run_metadata_ptr)                                                                                                              \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run                             \n    feed_dict_string, options, run_metadata)                                                                                       \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run                          \n    target_list, options, run_metadata)                                                                                            \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call                         \n    e.code)                    \n\ntensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64] rhs shape= [50000]                                                                                                                   \n\n         [[Node: Variable_3/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_3\"], use_locking=true, validate_shape=true, _device=\n\"/job:ps/replica:0/task:3/cpu:0\"](Variable_3, zeros_S1)]]                                                                          \nCaused by op u'Variable_3/Assign', defined at:                                                                                     \n  File \"word2vector.py\", line 127, in <module>                                                                                     \n    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))                                                                          \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__                          \n    dtype=dtype)                                                                                                                   \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 308, in _init_from_args                   \n    validate_shape=validate_shape).op                                                                                              \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 40, in assign                         \n    use_locking=use_locking, name=name)                                                                                            \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op                     \n    op_def=op_def)                                                                                                                 \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op                        \n    original_op=self._default_original_op, op_def=op_def)                                                                          \n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__                         \n    self._traceback = _extract_stack()                   \n```\n", "comments": ["Variables sizes do not get reset. Variables buffers are allocated in a\ncontainer, which is a property of a session. There's no way to destroy a\nvariable in a session, so to reset size you need to create new session, or\ncreate new variable (use different name)\n\nOn Tue, Jun 28, 2016 at 11:50 AM, \u90d1\u6cfd\u5b87 notifications@github.com wrote:\n\n> In my understanding reset_default_graph() will reset the whole graph.\n> However, it seems that this will only reset the value of variables when\n> running parameter servers on kubernetes.\n> \n> First, I tried to get variable values before and after\n> reset_default_graph(). The value is reset (value is 0) after running\n> reset_default_graph().\n> \n> Then I tried to run a totally different algorithm using the same parameter\n> server, it reported the error below:\n> \n> _Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64]\n> rhs shape= [50000]_\n> \n> Only chief run the reset_default_graph() cmd. The code is:\n> \n> is_chief = (FLAGS.worker_index == 0)\n> if is_chief: tf.reset_default_graph()\n> \n> The whole error message is:\n> \n> Traceback (most recent call last):\n>   File \"word2vector.py\", line 160, in <module>\n>     with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 685, in prepare_or_wait_for_session\n>     config=config, init_feed_dict=self._init_feed_dict)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 163, in prepare_session\n>     sess.run(init_op, feed_dict=init_feed_dict)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 340, in run\n>     run_metadata_ptr)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 564, in _run\n>     feed_dict_string, options, run_metadata)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n>     target_list, options, run_metadata)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n>     e.code)\n> \n> tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [5,5,32,64] rhs shape= [50000]\n> \n> ```\n>      [[Node: Variable_3/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@Variable_3\"], use_locking=true, validate_shape=true, _device=\n> ```\n> \n> \"/job:ps/replica:0/task:3/cpu:0\"](Variable_3, zeros_S1)]]\n> Caused by op u'Variable_3/Assign', defined at:\n>   File \"word2vector.py\", line 127, in <module>\n>     nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 209, in **init**\n>     dtype=dtype)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 308, in _init_from_args\n>     validate_shape=validate_shape).op\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 40, in assign\n>     use_locking=use_locking, name=name)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n>     op_def=op_def)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n>     original_op=self._default_original_op, op_def=op_def)\n>   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n>     self._traceback = _extract_stack()\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3073, or mute the thread\n> https://github.com/notifications/unsubscribe/AABaHKDyt4ZMvgAkoMYlbJv0G39xETpTks5qQOBygaJpZM4I_4JN\n> .\n", "how could I create a new session without restarting the server?\n", "Test testSameVariablesClear\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/server_lib_test.py#L74\nlooks\nrelevant\nIE, tf.Session.reset(target)\n\nOn Tue, Jun 28, 2016 at 5:13 PM, \u90d1\u6cfd\u5b87 notifications@github.com wrote:\n\n> how could I create a new session without restarting the server?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3073#issuecomment-229061600,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AABaHII6C1_5DEMLg0WYxAROaS9o_MWeks5qQSwhgaJpZM4I_4JN\n> .\n", "It seems that I can't find tf.Session.reset in both [github api doc](https://github.com/tensorflow/tensorflow/blob/e39d8feebb9666a331345cd8d960f5ade4652bba/tensorflow/g3doc/api_docs/python/client.md#Session.run) and [tensorflow.org api doc](https://www.tensorflow.org/versions/r0.9/api_docs/python/client.html#Session)\n\nWhen I tried to run the test code, it also reported error: \n\n```\nAttributeError: type object 'Session' has no attribute 'reset'\n```\n\nI tried to run locally with tensorflow 0.9.0 and python 2.7; I also tried docker image tensorflow/tensorflow:r0.9;  both of them reported the same error message.\n", "btw, if I use different name scopes for different runs, will the server stores all the variables from different runs and uses lots of disk?\n", "From GIT blame, it seems that test was added 5 days ago. TensorFlow version\n0.9.0 is several weeks old so you need to build from source.\n\nYou can select which variables are saved by specifying it in Saver\nconstructor\n\nOn Wed, Jun 29, 2016 at 4:42 AM, \u90d1\u6cfd\u5b87 notifications@github.com wrote:\n\n> btw, if I use different name scopes for different runs, will the server\n> stores all the variables from different runs and uses lots of disk?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3073#issuecomment-229233828,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AABaHJmYPjsBLu0mPsbsTnVNNp1VF5yBks5qQc2AgaJpZM4I_4JN\n> .\n", "Thanks. At least it worked using different name scope.\n"]}, {"number": 3072, "title": "Update framework.md", "body": "# Create a nested scope called \"inner_1\".\n\n```\nwith g.name_scope(\"inner\"): \n```\n\ncode conflict with comment\u3002shall be \"inner_1\"\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n"]}, {"number": 3071, "title": "0.9.0 installation issue ", "body": "I have a system that have no access to the internet. usually I download the wheel file of tensorflow and install it via file. I'm trying to upgrade tensorflow version with my method but it seem it cant be done. I'm trying to upgrade my tensorflow version from 0.8.0 to 0.9.0.\n### Environment info\n\nOperating System: Ubuntu 14.04  (CPU version)\n### Logs or other output that would be helpful\n\n``` Exception:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/pip/basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"/usr/local/lib/python2.7/dist-packages/pip/commands/install.py\", line 317, in run\n    prefix=options.prefix_path,\n  File \"/usr/local/lib/python2.7/dist-packages/pip/req/req_set.py\", line 742, in install\n    **kwargs\n  File \"/usr/local/lib/python2.7/dist-packages/pip/req/req_install.py\", line 831, in install\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n  File \"/usr/local/lib/python2.7/dist-packages/pip/req/req_install.py\", line 1032, in move_wheel_files\n    isolated=self.isolated,\n  File \"/usr/local/lib/python2.7/dist-packages/pip/wheel.py\", line 348, in move_wheel_files\n    assert info_dir, \"%s .dist-info directory not found\" % req\nAssertionError: cpu-tensorflow==0.9.0 .dist-info directory not found\n```\n", "comments": ["What version of pip/setuptools are you running? Can you check if upgrading\nmight help? We haven't changed anything in our wheel file so I'm surprised\neither way since you were able to install 0.8.\nOn Wed, Jun 29, 2016 at 18:45 andydavis1 notifications@github.com wrote:\n\n> Assigned #3071 https://github.com/tensorflow/tensorflow/issues/3071 to\n> @martinwicke https://github.com/martinwicke.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3071#event-708576239,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_cj9I8VI3HEbugI00_7Hw7uLNLI_ks5qQx_UgaJpZM4I_xw-\n> .\n", "@martinwicke  \nmy pip version is the latest one 8.1.2 \nas I said before upgrading tensorflow from web cause no problem in my system. But when I'm trying to upgrade it via downloaded wheel file in my offline system, It gives me the error that i mentioned before. I'm surprised too. before this release I had no such problem in upgrading via file.\n", "Can you uninstall 0.8.0 first? I'm wondering whether this is a problem with 0.8.0 instead which surfaces during upgrades. Although I'm just guessing at this point.\n", "Automatically closing due to lack of recent of activity. Please reopen if new information becomes available.\n"]}, {"number": 3070, "title": "GLIBC bug", "body": "I use ubuntu16.04, at before it is OK to build, after I updated GLIBC, this bug happened.\n\n```\nERROR: /home/wenjian/pkgs/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n//lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n```\n", "comments": ["Can you rebuild from scratch or revert to your previous glibc? Also, if the issue persists, please fill out all of the information in the template provided when you click \"New Issue\".\n", "Closing via your commit in 09d2363, thanks for the PR!\n", "Even though I have your commit on my tensorflow source (r0.10 branch), I still get the same error. Do you know why?\n\n```\nERROR: /home/s1510032/.cache/bazel/_bazel_s1510032/5dcba7ab6ef0dd7febafd447d7c0db96/external/protobuf/BUILD:331:1: Linking of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/external/protobuf/protoc ... (remaining 15 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/opt/rh/devtoolset-3/root/usr/bin/ld: /opt/rh/devtoolset-3/root/usr/lib/gcc/x86_64-redhat-linux/4.9.2/libstdc++_nonshared.a(hashtable_c++0x.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n//lib64/libm.so.6: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n```\n"]}, {"number": 3069, "title": "Installation issue with CUDA 8", "body": "Hi,\n\nI've attempted to install Tensorflow with CUDA 8 on Ubuntu 14.04 by installing from source since it doesn't seem like there are binaries available (following https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installing-from-sources)\n\nEverything installed well, but once I tried importing, I received this while trying to import tensorflow in python:\nImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory.\n\nI'm not sure where this is coming from, since I'm using CUDA 8.  I did have a previous installation of CUDA 7.5, but all those files got replaced, and there is no libcudart.so.7.5 (or anything 7.5) in the cuda lib64 folder.\n\nAny thoughts? Many Thanks!\n### Environment info\n\nOperating System: Ubuntu 14.04\nGraphics Card: NVIDIA GTX 1080 Founders Edition\n\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 5.0\n-rw-r--r-- 1 root     root       560184 Jun 27 16:13 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root     root           16 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root     root           19 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root     root       394472 Jun 27 16:13 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root     root       737516 Jun 27 16:13 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 lfibrain lfibrain       13 Jun 27 17:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 lfibrain lfibrain       17 Jun 27 17:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\nlrwxrwxrwx 1 lfibrain lfibrain       17 Jun 27 17:46 /usr/local/cuda/lib64/libcudnn.so.5.0 -> libcudnn.so.5.0.5\n-rwxr-xr-x 1 lfibrain lfibrain 78065952 Apr 22 15:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 lfibrain lfibrain 68709594 Apr 22 15:17 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from sources, provide the commit hash:\n861644c\n### Steps to reproduce\n1. Install NVIDIA 367 driver\n2. Install CUDA 8.0\n3. Install cuDNN 5.0\n4. Reboot\n5. Install tensorflow from source with bazel using the above configuration\n### What have you tried?\n1. reconfiguring/reinstalling tensorflow with inputting the exact directory locations (instead of pressing ENTER for default), even if the default locations were already correct.\n", "comments": ["afaik, it requires and work just fine with `cuda-7.5` and after you have it installed, you'd have all required `.so` files at `/usr/local/cuda-7.5`\n", "Try to install with cuda7.5 instead. But i found weird results running the CIFAR 10 example under /models/imag/cifar10/cifar10_train.py\n\nLet me know your results. \n", "Closing for now, as we unfortunately do not yet support Cuda 8 as was mentioned by @zongyuange  and @MInner.\n", "Others have been able to get it working with cuda 8.0, so I'd try a fresh clone of tensorflow in a different directory and use the latest bazel as well.\n", "Yes indeed - a fresh clone worked out for me.  Thanks everyone.\n", "Awesome. Glad you got it to work.\n", "Also, there will be a Cuda 8.0 pre built binary when we are out of RC (see @vrv comment on #3052)\n", "Our ./configure process unfortunately requires modifying the source code in the tree when you give it something other than the empty string, so re-cloning is probably the best thing to do in cases like these.\n\nAlternatively, if you leave the defaults, it uses whatever is symlinked at libcudnn.so, and then there should be no source code rewriting going on.\n\n@aselle , it's Nvidia we have to wait for, not us.\n", "@vrv I noticed that the official cuda 8 drivers are out. The tensorflow install instructions still indicate that source compilation is necessary for this version. Are the docs out of date or does the issue remain?\n", "@bozhu5 could you comment your process for working with a new clone? Many people, including myself, are having issues with cuda 8.0 and tf.  \n", "@aselle Is TensorFlow binary for CUDA 8 ready?\n", "I keep getting:\n\n`ImportError: dlopen(/usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib`\n\nUsing CUDA 8 drivers on OSX.\n", "Checked in with @gunan. We are aiming for CUDA 8 binaries in rc1.  @andrenatal, your error is because our binaries are for cuda 7.5, so if you want to use cuda 8 right now you have to build it yoruself.\n", "@yifeif will keep track of the release of cuda8 binaries.\nYifei, could you close this issue once cuda8 binaries are released?\n", "@aselle @gunan What's the ETA of rc1?\n", "It depends on the number of issues we see during the release, but at most 1\nweek.\n\nOn Oct 9, 2016 1:59 AM, \"Gokula Krishnan\" notifications@github.com wrote:\n\n> @aselle https://github.com/aselle @gunan https://github.com/gunan\n> What's the ETA of rc1?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3069#issuecomment-252474020,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AHlCOcK5QwccH7WUjZpPC-J46fOTzkyXks5qyKz9gaJpZM4I_rnJ\n> .\n", "Hi @andrenatal --\n\nI get the same error [ ImportError: dlopen(/usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib ]  on my MacbookPro (OS X 10.11.6) with \n-- TensorFlow 0.10\n-- Python 2.7.12\n\nI installed CUDA 8.0.\n\nHave you been able to make CUDA 8 and Tensor Flow work??\n\nThanks,\n\n# Atul\n\n# Here are the results from deviceQuery:\n\n```\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"GeForce GT 750M\"\n  CUDA Driver Version / Runtime Version          8.0 / 8.0\n  CUDA Capability Major/Minor version number:    3.0\n  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\n  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n  GPU Max Clock rate:                            926 MHz (0.93 GHz)\n  Memory Clock rate:                             2508 Mhz\n  Memory Bus Width:                              128-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 65536\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            No\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n  Compute Mode:\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 750M\nResult = PASS\n```\n", "@laventura 11rc0 and before are only for CUDA 7.5, you have to wait for later version or build from source if you want CUDA 8\n", "Building from source, at this step:\n\n`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\n\nI  get this error:\n\n`ERROR: /Users/anatal/projects/mozilla/tensorflow/tensorflow/core/kernels/BUILD:1020:1: error while parsing .d file: /private/var/tmp/_bazel_anatal/7c0501261859d426c184c23a4c9e36fa/execroot/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/core/kernels/_objs/adjust_contrast_op_gpu/tensorflow/core/kernels/adjust_contrast_op_gpu.cu.pic.d (No such file or directory).\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc fatal   : The version ('80000') of the host compiler ('Apple clang') is not supported\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 262.184s, Critical Path: 250.97s`\n", "That particular error looks like a mismatch between your XCode version and Cuda.\nOn ubuntu, I was able to get the source code to compile successfully with cuda8.\n", "Googling for error suggests that you need xcode 7.2\n\nOn Oct 11, 2016 12:10 AM, \"gunan\" notifications@github.com wrote:\n\n> That particular error looks like a mismatch between your XCode version and\n> Cuda.\n> On ubuntu, I was able to get the source code to compile successfully with\n> cuda8.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3069#issuecomment-252831146,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHIMO77LlzvCp-GQxvlc8Ggh1uk9fks5qyzZUgaJpZM4I_rnJ\n> .\n"]}, {"number": 3068, "title": "GTX 1080 with CIFAR 10 example", "body": "I ran the tensorflow CIFAR10 example and got the following error: (sometimes shows loss such as loss = 523454323, I reinstall the CPU only version and that works fine.)\n### Environment info\n\nOperating System: Ubuntu 14.04\nGPU: GTX 1080\nInstalled version of CUDA and cuDNN: CUDA7.5, CUDNN V4\n\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:02:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x1e22300\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:01:00.0\nTotal memory: 7.92GiB\nFree memory: 7.05GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n2016-06-28 12:03:35.740025: step 0, loss = 4.68 (4.7 examples/sec; 27.498 sec/batch)\nW tensorflow/core/kernels/queue_base.cc:292] _0_input_producer: Skipping cancelled enqueue attempt with queue not closed\nTraceback (most recent call last):\n  File \"cifar10_train.py\", line 136, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_train.py\", line 132, in main\n    train()\n  File \"cifar10_train.py\", line 105, in train\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\nAssertionError: Model diverged with loss = NaN\n", "comments": ["Does it happen with CUDA 8.0? (GTX 1080 might not be well tested with CUDA 7.5, and there's a large improvement in performance on CUDA 8 as well)\n", "Using a similar environment: Ubuntu 16.04, GTX1080 (driver 367.27), CUDA 8, CUDNN v5, I didn't run into any issue. It may be linked to CUDA 7.5 (or your driver?).\n", "Thanks, I will give it a try with CUDA 8.0 and see if this problem still exists.\n", "Did this resolve the issue? Can we close this out?\n", "Hi all, This issues has been resolved with code compiled with CUDA 8.0. \nThanks all\n", "What tensorflow version were you using?\n", "the **master branch** of tensorflow works well with GTX1080, CUDA8.0 and cudnn5.\n(r0.9 doesn't work.)\n", "confirmed on a box with tf r10.0 cuDNN4.0 CUDA7.5 GTX970\n\n```\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 970\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.1775\npciBusID 0000:01:00.0\nTotal memory: 4.00GiB\nFree memory: 3.92GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)\n2016-09-06 16:32:46.091636: step 0, loss = 4.68 (4.1 examples/sec; 31.136 sec/batch)\nTraceback (most recent call last):\n  File \"./tensorflow/models/image/cifar10/cifar10_train.py\", line 134, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./tensorflow/models/image/cifar10/cifar10_train.py\", line 130, in main\n    train()\n  File \"./tensorflow/models/image/cifar10/cifar10_train.py\", line 103, in train\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\nAssertionError: Model diverged with loss = NaN\n```\n\nwon't-fix/please-get-new-cuda?\n"]}, {"number": 3067, "title": "reshape on bad data: \"segment_ids[0] = -1 is out of range\"", "body": "This piece of code fails in `unsorted_segment_sum` inside `Reshape` op. It works just fine for a few batches and then fails on one specific batch of data: it just so happened (bug in my code) that the length of one line of the input of rnn turned out to be zero (and `length` param in `dynamic_rnn` was also zero), and I was passing the resulting tensor to a reshape, so it gave me this error:\n\n```\nInvalidArgumentError: segment_ids[0] = -1 is out of range [0, 100100)\n     [[Node: gradients/Reshape_grad/Reshape/tensor = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/Gather_grad/Reshape/_137, gradients/Gather_grad/Reshape_1/_139, gradients/Reshape_grad/Reshape/Squeeze/_141)]]\n     [[Node: gradients/Reshape_grad/Reshape/tensor/_143 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:2\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_31_gradients/Reshape_grad/Reshape/tensor\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:2\"]()]]\n...\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1383, in reshape\n    name=name)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\", line 455, in apply_op\n    as_ref=input_arg.is_ref)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 620, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py\", line 94, in _IndexedSlicesToTensor\n    name=name)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2215, in unsorted_segment_sum\n    num_segments=num_segments, name=name)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/home/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n```\n\nhere's the piece of code on which it fails:\n\n```\ndef last_relevant(output, length):\n    batch_size = tf.shape(output)[0]\n    max_length = int(output.get_shape()[1])\n    output_size = int(output.get_shape()[2])\n    index = tf.range(0, batch_size) * max_length + (length - 1)\n    flat = tf.reshape(output, [-1, output_size])\n    relevant = tf.gather(flat, index)\n    return relevant\n```\n\njust wondering if error message could be less obscure.\n", "comments": ["The main reason this is so confusing is that `tf.gather` currently doesn't check its indices when running as a GPU op: https://github.com/tensorflow/tensorflow/blob/c8b59c0/tensorflow/core/kernels/gather_op_gpu.cu.cc#L65\nIf you pass in `[-1]`, as in your case, it will return a tensor containing zeros.\nIt then continues to run until the gradient gives you an error.\n\nI think once `tf.gather` checks its inputs when running on the GPU, this issue should be considered fixed.\n", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 3066, "title": "Tensorboard webpage breaking on current build", "body": "**Tensorboard** GUI is breaking on the latest build after commit https://github.com/tensorflow/tensorflow/commit/861644c0bcae5d56f7b3f439696eefa6df8580ec.\n\nOn Chrome, only a blue header with buttons appears.\nOn Firefox, large button icons appear (unclickable).\n\nThe nightly build from about a week ago works fine with the orange header and using same event files.\nOperating System: Ubuntu 14.04 x64\n", "comments": ["This happens to me, too.\n", "Same here. Here's a screenshot:\n\n<img width=\"804\" alt=\"screen shot 2016-06-28 at 8 33 14 pm\" src=\"https://cloud.githubusercontent.com/assets/241299/16436876/9c4d87b8-3d6f-11e6-9386-9dd8b12a8249.png\">\n", "I had this error, but pulling the most recent version seems to have fixed it.\n", "Just pulled and rebuilt. Yes this is fixed. I think we can close this issue.\n", "Verified. Orange header and orange plots now.\n"]}, {"number": 3065, "title": "Problem running build_all_ios.sh ", "body": "Mac OS X: El Capitan (10.11.4)\n\nI am trying to build Tensorflow for iOS and am following the \"Building all at once\" instructions found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/README.md).  When running the build_all_ios.sh file, I am getting the following errors:\n\nIn file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/Core:355:\n/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/NEON/Complex.h:18:35: error: \n      statement expression not allowed at file scope\nstatic uint32x4_t p4ui_CONJ_XOR = vld1q_u32( conj_XOR_DATA );\n\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/7.3.0/include/arm_neon.h:7609:39: note: \n      expanded from macro 'vld1q_u32'\n# define vld1q_u32(**p0) __extension** ({ \\\n\nIn file included from tensorflow/core/kernels/xent_op.cc:20:\nIn file included from ./tensorflow/core/kernels/xent_op.h:20:\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\nIn file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/Tensor:14:\nIn file included from /Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/Core:355:\n/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/downloads/eigen-eigen-802d984ade26/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/NEON/Complex.h:19:35: error: \n      statement expression not allowed at file scope\nstatic uint32x2_t p2ui_CONJ_XOR = vld1_u32( conj_XOR_DATA );\n\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../lib/clang/7.3.0/include/arm_neon.h:7759:38: note: \n      expanded from macro 'vld1_u32'\n# define vld1_u32(**p0) __extension** ({ \\\n\n2 errors generated.\nmake: **\\* [/Users/mw/Tensorflow_gitclone/tensorflow/tensorflow/contrib/makefile/gen/obj/tensorflow/core/kernels/xent_op.o] Error 1\n- '[' 2 -ne 0 ']'\n- echo 'armv7 compilation failed.'\n  armv7 compilation failed.\n- exit 1\n  MW:makefile mw$ ./build_all_ios.sh\n\nI have been able to overcome many issues up to this one but am now stuck.  Any suggestions?\n", "comments": ["I encountered exactly the same problem.   As a temporary measure just to get it to build the lib, I removed the assignment to the static vars mentioned above.    But in Xcode building the Camera sample, I got stuck on the same error described in #3004.   I set flags in Clang to ignore reference errors (bad idea, but I wanted to see how far I could take it), and managed to deploy the app to a physical iPad.  But it crashes on launch due to those missing refs.   It would be nice if this gets fixed in the next couple of hours as I'm planning to demo the app at a company meeting.   So you'll have a very motivated tester here if you have a fix.\n", "Sorry about the recent issues with iOS building. I've put in a temporary patch for the Eigen problem until we get around the underlying problem, along with a build process fix in #3075. Can you give this a try and let me know if you're still having issues?\n", "Thanks, Pete.   That fixed the problem!   I can confirm that the sample iOS app 'CameraExample' is now running happily on my iPad Air. \n", "That's awesome to hear, thanks for the update!\n", "This worked for me as well.  Thanks!\n"]}, {"number": 3064, "title": "Explanation of blank label in ctc_loss", "body": "The doc string of ctc_loss is lacking of several details. I tried to explain a little better of what is needed to get it working, but english is not my native language, so I'm sure that you can do much better!\n", "comments": ["Can one of the admins verify this patch?\n", "ping for @ebrevdo \n", "Jenkins, test this please.\n", "@igormq can you resolve the comments from code review please?\n", "I messed up my github and deleted my fork of tensorFlow (and i can't edit this PR). So, I'll have to submit it again and do another pull request. That is ok for you?\n", "sure!\n", "PR #3713. :)\n"]}, {"number": 3063, "title": "Fix Nightly Python3 error in graph_io_test.py", "body": "Change: 125988941\n", "comments": ["@tensorflow-jenkins test this please.\n"]}, {"number": 3062, "title": "Better docs of returned tensor in ctc_ops.py", "body": "'Logits' aren't a meaningful word for what the ctc_cost function returns. Browsing the implementation (tensorflow/tensorflow/core/util/ctc/) I saw that the cost function is returning the negative log probabilities of the target labelling, so, this new comment erases any doubt. Thanks!\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "@googlebot I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@ebrevdo \n", "Can one of the admins verify this patch?\n", "Oops, hit close by mistake.\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3061, "title": "Supervisor should start queue runners before initializing the model", "body": "For some use cases, the models use a random batch of inputs when initializing the weights. Currently (as of version 0.9) this is not supported with Supervisor that uses queues. It attempts to initialize the model before starting queue runners (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py#L650 method prepare_or_wait_for_session).\n\nDo you think changing the order of operations in this method is reasonable? \n1. recover_session() \n2. start_queue_runners() (currently done at the end)\n3. initialize_model()\n\nThanks!\n", "comments": ["Please migrate to using monitored_session which does exactly what you want. I will close this bug as we will not be making any more changes to Supervisor.", "Apparently, MonitoredSession does not solve the issue (see [here](https://github.com/tensorflow/tensorflow/issues/6624))."]}, {"number": 3060, "title": "User op warp ctc", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "sorry, wrong pr.\n"]}, {"number": 3059, "title": "tf_version_script giving syntaxerror", "body": "Hi everyone,\nI ran the command `ld tf_version_script.lds` and it gave this error-\n`ld:/home/me/tensorflow/tensorflow/tf_version_script.lds:1: syntax error`\nI had the directory mounted. Why is this happening?\nThanks!\n", "comments": ["Can you please fill out all of fields from the template? Environment, steps to reproduce, etc...\n", "@andydavis1 which template do you mean? It's quite simple. I am using the default configs for tensorflow. And the only steps I took was, mounting the tensorflow directory and running `ld tf_version_script.lds`. Is there some step I am missing?\n", "There is a template when you click the \"New Issue\" button. I've copied it below:\n\nGitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from sources, provide the commit hash:\n\n### Steps to reproduce\n\n1.\n2.\n3.\n\n### What have you tried?\n\n1.\n\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3058, "title": "Branch 125939528", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "CLAbot is wrong, all commits are from internal.\n"]}, {"number": 3057, "title": "Use gpu_memory_fraction in while using distributed tensorflow", "body": "While I'm implementing models in A3C, I tried to allocate a fraction of gpu to a process and processes that use multiple fractions of gpus update a parameters of a parameter server (in a single machine). For example, I want to create 12 workers with 3 gpus to update a master model.\n\nI referenced https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html and used `tf.GPUOptions(per_process_gpu_memory_fraction=0.1)` but it doesn't work when we pass it to `sv.managed_session` (just take all of the memory of the first visible gpu).\n\nAlso, I can't find how to give `GPUOptions` to parameter server that does not have session creation (I always pass `GPUoptions` to `tf.Session` which similar to `sv.managed_session`). **How can I allocate a specific fraction of a gpu to each tasks including parameter server and workers?**\n\nCode can be found https://github.com/devsisters/DQN-tensorflow/blob/distributed/main.py#L78.\n", "comments": ["It's possible to do this today, but the interface isn't very intuitive. **TL;DR:** The `GPUOptions` in the session creation will be ignored, and you have to pass them when you create the `tf.train.Server` objects to which these settings apply. (The reason for this is that the GPU device is created when you create the server, not when you create the session. When you use _non-distributed_ TensorFlow, the device is created when you create the session.)\n\nTo set this option then, you have to set the `tf.ServerDef.default_session_config.gpu_options.per_process_gpu_memory_fraction` field when you create the server. Currently you can only do that if you build the `tf.train.ServerDef` yourself. I'll add a interface to let you override the `tf.ConfigProto` on its own while still using the Pythonic sugar for defining a cluster, and use that to close this issue.\n", "@mrry What if I didn't define any `tf.train.Server` object? And my code is sth like sess = sv.prepare_or_wait_for_session(config=tf.ConfigProto(gpu_options=gpu_options)). So where should I pass the config object to? TIA!"]}, {"number": 3056, "title": "LSTMStateTuple without get_shape() method", "body": "I have a problem when building seq2seq model with attention based on the LSTM cell, using TensorFlow r0.9 on OS X.\n\nI find that the LSTMCell generates a LSTMStateTuple state if the state_is_tuple parameter is set to True (the rnn_cell.py code seems to encourage this setting). But when I feed the output to an attention_decoder as the initial_state, the attention() function in seq2seq.py calls the _linear() function in rnn_cell.py, and _linear() calls the get_shape() function of the initial_state variable, and the program reports \"AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'\". \n\nCould you please help me find if I am missing some important steps in building seq2seq with attention based on the LSTM cell, or should LSTMStateTuple support the get_shape() function?\n\n(The error does not appear when I set state_is_tuple=False.)\n\nThank you!\n", "comments": ["@lukaszkaiser any plans to update seq2seq to support state tuples?\n", "This has been resolved in a CL a few days ago.\n", "@lukaszkaiser Thank you very much for resolving the problem. However, my program still reports the same error when I set state_is_tuple=True. \n\nI have pip-installed the latest tensorflow-0.10.0rc0 with GPU on a linux system.\n\nI do not know the meaning of \"CL\" in your post. Maybe I am missing some important factor here. \n", "Sorry, by CL I meant PR. It should be fixed in 0.10, so if it's not working for you, let's take a look. Could you write a small example model that shows the problem and paste it here, so I can confirm? That would be great, thanks!\n", "@lukaszkaiser Thank you for quick response. Please find the code in attachment. \nThe program does not report error until I set `state_is_tuple=True`.\n[lstm_state_is_tuple.py.zip](https://github.com/tensorflow/tensorflow/files/395233/lstm_state_is_tuple.py.zip)\n", "I can replicate the problem now, working on a fix. Thanks!\n", "Hope the above PR fixed it. Let me know if any problems are still there, of course!\n", "I have the same problem and I'm using the latest version of tensorflow(0.10.0). Anyone has some ideas about how to solve it? @kangxin @lukaszkaiser \n", "I'm not sure the PR that fixed it made into 0.10.0. Could you try with the head TF from github?\n", "Yes- likely to be at head.\n\nOn Thu, Sep 8, 2016 at 9:52 AM, Lukasz Kaiser notifications@github.com\nwrote:\n\n> I'm not sure the PR that fixed it made into 0.10.0. Could you try with the\n> head TF from github?\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-245663118,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimwkbbCVnU7QV31iDcYUiEvxzHm5Lks5qoD06gaJpZM4I-sU0\n> .\n", "This problem is solved now with the head TF from github. But another error ocurrs: \"tensorflow.python.framework.errors.InternalError: Dst tensor is not initialized.\"\n\nI assume this problem may be related to running out of memory, so I set the batch size to 1. The problem still exist.\n", "It's important to know how large is your model and how long you're unfolding it. Does it work with a smaller model (say 32 units in a cell)? How much GPU memory do you have? That'd make it clear if it's about memory. Unluckily the seq2seq library does static unrolling -- dynamic_rnn and while_loop do dynamic unrolling and can use CPU memory, so they're much better in terms of practical memory use. But we'll need to write a new seq2seq library to use them.\n", "In fact, I run the embedding_rnn_seq2seq model before. It works well with my GPU. However, when I switch to embedding_attention_seq2seq model with the same hyper-parameters, it cannot work even if I set the batch size to 1 (128 before) and RNN hidden state dimension to 1 (256 before). So I think this is not a issue related with memory. Any other factors may cause this problem?\n", "Looks like a bug -- please, let us know when you dig some more information. The seq2seq code didn't change much with state_is_tuple, so it's very strange what you're seeing.\n", "This does indeed sound like a bug, perhaps with the while_loop.  Can you\nprovide a minimal failing example?\n\nOn Sep 9, 2016 8:39 PM, \"Lukasz Kaiser\" notifications@github.com wrote:\n\n> Looks like a bug -- please, let us know when you dig some more\n> information. The seq2seq code didn't change much with state_is_tuple, so\n> it's very strange what you're seeing.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-246086127,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim8Acr9UbbM-SWEfhLpdjh8LTk40pks5qoiZ8gaJpZM4I-sU0\n> .\n", "@lukaszkaiser @ebrevdo  Thanks for your response. The code is in the attachment. \n When I call the train_batch function, it returns a error.\n\n[test.txt](https://github.com/tensorflow/tensorflow/files/468799/test.txt)\n", "```# Running with tensorflow (0.12.1)\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import rnn\r\nfrom tensorflow.python.ops import rnn_cell\r\n\r\nbatch_size = 100\r\nsize = 20\r\nnum_encoder_symbols = 30\r\nembedding_size = 64\r\nstate_is_tuple = True\r\nnum_layers = 3\r\nencoder_inputs = [tf.zeros([32],dtype=tf.int32) for _ in range(batch_size)]\r\nsingle_cell = tf.nn.rnn_cell.BasicLSTMCell(size, state_is_tuple=state_is_tuple) # Or GRU\r\ncell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\r\nencoder_cell = rnn_cell.EmbeddingWrapper(cell, embedding_classes=num_encoder_symbols, embedding_size=embedding_size)\r\n_, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\r\nencoder_state[0].get_shape()\r\n```\r\n\r\n`encoder_state` is a tuple of `LSTMStateTuple` of size `num_layers`\r\n\r\nCalling `encoder_state[0].get_shape()` fails with ` 'LSTMStateTuple' object has no attribute 'get_shape'`\r\n\r\nFor now `encoder_state[0].c.get_shape()` , `encoder_state[0].h.get_shape()` is the only way I know to work around this\r\nor concatenating the states which is slower and goes against using state_is_tuple=True", "That's right, a tuple may contain multiple tensors, each of which may have\ndifferent shapes.  Thus you must call .get_shape() on whichever tensor you\ncare about.  You can use encoder_state[0][0].get_shape() which is\nequivalent to encoder_state[0].c.get_shape().\n\nWe may add a get_shape() or shape property to LSTMStateTuple, feel free to\nopen a new issue for that.\n\nOn Tue, Jan 17, 2017 at 3:29 AM, Chirag Jain <notifications@github.com>\nwrote:\n\n> import tensorflow as tf\n> from tensorflow.python.ops import rnn\n> from tensorflow.python.ops import rnn_cell\n>\n> batch_size = 100\n> size = 20\n> num_encoder_symbols = 30\n> embedding_size = 64\n> state_is_tuple = True\n> num_layers = 3\n> encoder_inputs = [tf.zeros([32],dtype=tf.int32) for _ in range(batch_size)]\n> single_cell = tf.nn.rnn_cell.BasicLSTMCell(size, state_is_tuple=state_is_tuple) # Or GRU\n> cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n> encoder_cell = rnn_cell.EmbeddingWrapper(cell, embedding_classes=num_encoder_symbols, embedding_size=embedding_size)\n> _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=tf.float32)\n> encoder_state[0].get_shape()\n>\n> encoder_state is a tuple of LSTMStateTuple of size num_layers\n>\n> Calling encoder_state[0].get_shape() fails with 'LSTMStateTuple' object\n> has no attribute 'get_shape'\n>\n> For now encoder_state[0].c.get_shape() , encoder_state[0].h.get_shape()\n> is the only way I know to work around this\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3056#issuecomment-273114865>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimzmQ6V1B0vTmTYTUVTBZDw2qIGK4ks5rTKYVgaJpZM4I-sU0>\n> .\n>\n", "Hey, guys, any update for the shape property?"]}, {"number": 3055, "title": "wide_n_deep_tutorial.py", "body": "I want to output the data's result: such as: age: 18,  percent, gender: female, percent.\nWhat should I do?\n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.\n"]}, {"number": 3054, "title": "Multivariate normal distribution crashes on broadcast", "body": "### Environment info\n\nOperating System: Mac OS X 10.11.5\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. \n   https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0-py3-none-any.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.9.0\n### Issue\n\nThe Multivariate Normal distribution in `contrib.distributions` [claims to support broadcasting](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/contrib/distributions/python/ops/mvn.py#L378) but it does not appear to work. This script will illustrate the issue:\n\n``` python\nimport numpy as np\nimport tensorflow as tf\n\n# dimensions\na = 2\nb = 3\nc = 4\n\nmu = tf.reshape(tf.constant(\n    np.arange(a * b * c * 1.0)),\n    [a, b, c])\n\nsigma = tf.batch_matrix_diag(tf.reshape(tf.constant(\n    np.arange(a * b * c * 1.0) + 1),\n    [a, b, c]))\n\nmvn = tf.contrib.distributions.MultivariateNormal(mu, sigma)\n\nwith tf.Session() as sess:\n    # works because shape(input) == shape(mu)\n    sess.run(mvn.pdf(np.ones((a, b, c))))\n\n    # fails even though input and mu are broadcastable\n    sess.run(mvn.pdf(np.ones((1, a, b, c))))\n```\n", "comments": ["Hello Andy,\n\nThanks for bringing this to our attention.  I verified that this operation indeed raises an error during the broadcast attempt.  Just today we have updated the MultivariateNormal API ([PR](https://github.com/tensorflow/tensorflow/commit/94cbf42a074128f9c46d980f9fddb47fba3602a6)).  I verified that your example works in the new API.  For your reference, in the new API you would do:\n\n``` python\nmvn = tf.contrib.distributions.MultivariateNormalFull(mu, sigma)\n```\n\nThis defines an MVN via the full covariance matrix.  Also see `MultivariateNormalCholesky`.  I'll add `MultivariateNormalDiag` soon as well.\n", "@langmore very cool! Looking forward to the new tools. I'll close this issue.\n"]}, {"number": 3053, "title": "Templatize dtype in RGBToHSV and HSVToRGB", "body": "`RGBToHSV` and `HSVToRGB` currently work only for `float32` inputs. Made the data type a template parameter so that other input types like `float16` and `float64` can be used. This change is towards resolving #1140 for the above mentioned operations.\n\nThis change does not enable `float64`, as incorporating new types will also need new tests, something I'm not sure about at this point. (Addressed to whoever looks at the PR) Could you explain how the tests in `core/kernels/colorspace_op_test.cc` can be executed, and how they need to be changed in case `float64` is enabled?\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@rmlarsen Should I update this PR, or keep it for the follow up PR?\n", "Please update this PR.\n", "@rmlarsen Updated. Could you respond to the question I posted in the PR description?\n", "You should be able to run the specific test with\n\nbazel test ${my_tf_dir}/tensorflow/core/kernels:colorspace_op_test\n\nIn term of adding test coverage for all types in colorspace_op_test.cc, I would probably \n1. templatize class RGBToHSVOpTest on the data type \n2. replace the constructor with a MakeOp method (see scatter_op_test.cc for example)\n3. make the test code members of class RGBToHSVOpTest \n\ne.g. something along the lines of\n\n```\ntemplate <typename T>\nclass RGBToHSVOpTest : public OpsTestBase {\n protected:\n  void MakeOp(DataType datatype) {\n    TF_EXPECT_OK(NodeDefBuilder(\"rgb_to_hsv_op\", \"RGBToHSV\")\n                     .Input(FakeInput(datatype))\n                     .Finalize(node_def()));\n    TF_EXPECT_OK(InitOp());\n  }\n\n  void CheckBlack(DataType datatype) {\n      // Black pixel should map to hsv = [0,0,0]\n    AddInputFromArray<float>(TensorShape({3}), {T(0), T(0), T(0)});\n    TF_ASSERT_OK(RunOpKernel());\n\n  Tensor expected(allocator(), datatype, TensorShape({3}));\n  test::FillValues<T>(&expected, {T(0.0), T(0.0), T(0.0)});\n  test::ExpectTensorEqual<T>(expected, *GetOutput(0));\n  }\n\n  void  CheckGray(DataType datatype) {\n    ...\n  }\n};\n\ntypedef RGBToHSVOpTest<float> RGBToHSVOpTest_float;\n\nTEST_F(RGBToHSVOpTest_float, CheckBlack_float) {\n  MakeOp(DT_FLOAT);\n  CheckBlack(DT_FLOAT);\n}\n\n...\n\n// You can use macros to get rid of the duplication here...\ntypedef RGBToHSVOpTest<double> RGBToHSVOpTest_double;\n\nTEST_F(RGBToHSVOpTest_double, CheckBlack_double) {\n  MakeOp(DT_DOUBLE);\n  CheckBlack(DT_DOUBLE);\n}\n\n```\n", "@rmlarsen Is there something I need to do here?\n", "I went ahead and gave making these changes a shot. Opened up a pull request on @siddharth-agrawal's fork [here](https://github.com/siddharth-agrawal/tensorflow/pull/1)\\- I figured that would be better than opening up a separate pull request here. Here are the bullet points of what I added in:\n- Registers both HSVToRGB and RGBToHSV for `float` and `double`, setting default value to `DT_FLOAT` for backwards compatibility\n- Refactors tests to be reusable with different data types (as @rmlarsen suggested)\n- Adds HSVToRBG CheckNegativeDifference test, which was missing for some reason previously\n- Cleans up a few missed `float` -> `T` bugs\n\nI also found that the Eigen::half type doesn't want to play nice with [these three lines of code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/colorspace_op.h#L74-L76), which is why I didn't include the `half` type in these changes. Trying to add it in spits out [this error log](http://pastebin.com/qXnqU5K6).\n", "@siddharth-agrawal @samjabrahams As commented on the private repo, Sam's refactoring of the tests looks good to me. If you merge the changes into this PR, I think we are ready to merge this.\n", "@rmlarsen The change is incomplete according to me, there are some Python tests that will be affected too. This is why I made a separate PR for this change, otherwise the set of changes would just be too big. @samjabrahams if you don't mind, I will make the follow up changes as I have already made all the necessary investigations. There are other ops that you can help with, complete list [here](https://github.com/tensorflow/tensorflow/issues/1140).\n", "@siddharth-agrawal SGTM. I'll wait for your followup changes.\n", "That's fine, hopefully the bits I added in will help with the rest of the changes you're hoping to do.\n\nI'll add the list of \"needs 64-bit floating point support\" ops to my list of things I could help out with!\n", "@samjabrahams Yes, your changes will make the refactoring a lot easier, thanks!\n", "@rmlarsen Do you mean I should update this PR? I was thinking that I will send out a new PR once this is merged in.\n", "@siddharth-agrawal I think you might be sending mixed messages- above you said that you don't want to  merge this PR in until you update the related Python tests, but now you're saying it should be merged-in as-is?\n\nUsually pull requests contain a complete set of features, or at least a complete feature on it's own. The changes that you currently have don't change any functionality on their own. This pull-request should probably include all changes related to HSVToRGB and RGBToHSV you'd like to see (including C++/Python tests). If you're worried about the pull-request getting \"too big\": plenty of pull requests are several-hundred lines long, this one is pretty neatly contained thus far.\n", "@samjabrahams Maybe I wasn't clear earlier, in this change I just wanted to templatize the `RGBToHSV` and `HSVToRGB` ops and retain the functionality that they already provide, that is work for type `float`; thus not changing any tests. In the follow up changes (new PR), I wanted to do what you did, add new types and make changes to the corresponding tests.\n\nI don't mind making all those changes in this PR itself, but I prefer keeping PRs short (easy for both the reviewer and the author). If @rmlarsen wants me to make the changes in this PR itself, I will do it.\n", "@siddharth-agrawal I had the same impression as @samjabrahams, i.e. that you wanted to add the missing tests. I do prefer that PRs bundle new code (in this case new classes) and associated new tests, so I prefer you add the tests to this PR. Since I've already reviewed most of the code it will not be a a lot of work.\n", "@rmlarsen I will try to update the PR this weekend, I'm traveling tomorrow.\n", "@siddharth-agrawal sounds good, thanks! I'll keep an eye on the PR.\n", "@rmlarsen Updated.\n@samjabrahams Thanks for the PR! Your changes made the process a lot easier.\n", "@tensorflow-jenkins test this please\n", "@rmlarsen Looks like `RGBToHSV` and `HSVToRGB` are \"core\" ops, do I need to change something for the test to pass?\n", "@siddharth-agrawal it looks like the backwards compatibility test fails because you have not set a default value for the type.\n\nSee http://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/932/consoleFull\n<snip>\nGetting all registered ops...\nReading op history from tensorflow/core/ops/compat/ops_history.v0.pbtxt...\nVerifying updates are compatible...\ntensorflow/core/ops/compat/backwards_compatibility_test.cc:36: Failure\nValue of: (compatibility.ValidateCompatible(env, &changed_ops, &added_ops, nullptr))\n  Actual: Invalid argument: Incompatible Op change: Attr 'T' added without default; old: Op<name=HSVToRGB; signature=images:float -> output:float>; new: Op<name=HSVToRGB; signature=images:T -> output:T; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE]>\nExpected: ::tensorflow::Status::OK()\n\nCan you please set the default to float to ensure backwards compatibility?\n", "@rmlarsen Updated the PR.\n", "@siddharth-agrawal test this please\n", "Oops! :-)\n\n@tensorflow-jenkins test this please\n", "@vrv  I reviewed this, just waiting for all tests to pass, then I'll merge it.\n", "@rmlarsen Can I delete the branch that I used? Generally, Github shows a message saying that it is safe to delete the branch, but not here. Is it because of the multiple commits?\n"]}, {"number": 3052, "title": "No nightly wheel with CUDA 8.0", "body": "Current nightly Linux wheel seems to be built with CUDA 7.5\n\nGoing from 7.5 to CUDA 8.0 gives me about 50% speed in TensorFlow up on 2048x2048 matmul on GTX 980 (2 T ops/sec -> 3 T ops/sec)\n\n```\n\nexport url=http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/143/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\npip install --upgrade $url\n\n# check that it has GPU support\n# note, I see performance gain of 50% on matmul going from 7.5 to 8.0\nldd ~/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so | grep libcudart\n    libcudart.so.7.5 => /usr/local/cuda-7.5/lib64/libcudart.so.7.5 (0x00007f4290bec000)\n\n```\n", "comments": ["Checking on status of pip 8.0...\n", "We'll switch our binaries to cuda 8.0 once it's out of RC -- users can always build from sources to get 8.0 goodness.\n", "Hi @yaroslavvb . The [link](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/143/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl) of your package is 404 now.\n\nCan you provide another package for cuda 8.0? We would like to test with Tesla M40 and cuda 8.0.\n", "That was link for cuda 7.5 version, you have to build from source if you\nwant 8\n\nOn Sep 28, 2016 6:34 AM, \"tobe\" notifications@github.com wrote:\n\n> Hi @yaroslavvb https://github.com/yaroslavvb . The link\n> http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/143/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n> of your package is 404 now.\n> \n> Can you provide another package for cuda 8.0? We would like to test with\n> Tesla M40 and cuda 8.0.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3052#issuecomment-250167732,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHI3193nBUwJRiEmdfZ2hWvehw31kks5qumzRgaJpZM4I-k1b\n> .\n", "BTW, CUDA 8.0 has been officially released\n", "Cool!  https://github.com/nvidia/nvidia-docker hasn't yet been updated with the next version, which is what we use in our CI to build the releases.\n\n@3XX0, @benbarsdell -- do you have an ETA when this will be done?\n\n(We just minted r0.11,  so this will probably be part of r0.12).\n", "Yes sorry for that, we need approval and QA the new images before publishing them, this might take a while.\n", "Installing with source is quite a task. So please let us know asap when it is done. Thank You.\n", "CUDA 8.0 images are now available!\n", "Where can I find them? \n", "@3XX0 where can these images be found\n", "It's probably cuda images, not tensorflow\n", "Yes, @Dawars is right, @3XX0 is referring to  CUDA nvidia-docker images being available for 8.0. We are looking to release CUDA 8.0 binaries,for rc1. Until then you can build from source.\n", "any can help?\r\nI need tf0.8 with cuda8"]}, {"number": 3051, "title": "wide_n_deep_tutorial.py", "body": "hello\uff01I am woking on wide_n_deep_tutorial.py\uff0c and I change the download part like this:\n\n```\ndef maybe_download():\n  \"\"\"May be downloads training data and returns train and test file names.\"\"\"\n  train_file_name = \"./adult.data\"\n  print(\"Training data is %s\" % train_file_name)\n\n  test_file_name = \"./adult.test\"\n  print(\"Test data is %s\" % test_file_name)\n\n  return train_file_name, test_file_name\n```\n\nand I got this error! :TypeError: argument of type 'float' is not iterable! \nat this line:`df_train[LABEL_COLUMN] = (df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)`\nI don't known how to make it right! please help!\n", "comments": []}, {"number": 3050, "title": "tf_version_script giving syntaxerror", "body": "Hi everyone,\nI ran the command `ld tf_version_script.lds` and it gave this error-\n`ld:/home/me/tensorflow/tensorflow/tf_version_script.lds:1: syntax error`\nI had the directory mounted. Why is this happening? \nThanks!\n", "comments": []}, {"number": 3049, "title": "Adds conv3d_transpose operation (3D \"deconvolution\")", "body": "This pull request contains the following changes:\n- Define gradients for Conv3DBackpropInputV2 and Conv3DBackpropFilterV2.\n- Add a new conv3d_transpose operation which uses Conv3DBackpropInputV2.\n- Test conv3d_transpose and Conv3DBackpropFilterV2.\n\nFixes #3012 #150\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed the CLA.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "very nice!  just a few minor comments and then we can test.\n", "Thanks, done.\n", "Thanks!\n@tensorflow-jenkins test this please\n", "has this been tested and verified?\n", "There's a test to validate correctness, yes.  If you think there's a bug in the implementation, please feel free to file an issue.  Thanks!\n", "I'm having a difficult time updating Tensorflow to include this code. I noticed that the function is in source code in the nn_ops.py file, but when I run the pip --upgrade it isn't included. Could I simply copy the function into my existing code, or does it include other dependencies? \n", "You could try one of the nightlies that might have this change in it: https://github.com/tensorflow/tensorflow#installation \n\nAlternatively, you could build from sources at HEAD as well.\n\nYou could copy the contents of the files too, though it might be easy to get wrong.\n", "that had it, thanks!\n", "Can we fix the issue where after a transpose, the dimensions are always <?,?, ?, ?, n_classes> -- can we get rid of the question marks and make them show the actual dimension value?\n", "@vrv it isn't included in the Mac OSX nightly build or the build currently posted to the main install page. Is there any other way I can get it installed on my mac? I ask because of this issue on both of my linux machines **\\* Error in 'python': free(): invalid pointer outlined in this SO post: http://stackoverflow.com/questions/38129441/tensorflow-conv3d-transpose-error-in-python-free-invalid-pointer\n", "http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=mac-slave/\n\nlooks like no mac builds have been created for a while -- pinging @caisq who might know more.\n", "@vrv Do you think this a bug with the latest build, or with the development of `conv3d_transpose` ? If it is with the development, then I need to open another issue.\n", "I have no idea -- conv3d_transpose is just a wrapper calling an existing function that already likely worked.  I think filing a bug with a reproducible small example would help (small being the clear word here -- it should be a single call to conv3d_transpose that triggers the bug, ideally).\n", "I opened a new issue: https://github.com/tensorflow/tensorflow/issues/3128\n\nI wrote a small network to reproduce the issue -- I hope it was concise enough\n", "@vrv Mac OS nightly build still hasn't been updated -- over a month old\n", "I guess there's a stale link somewhere. Try these?\n\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/156/\n\nE.g., http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/156/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=mac1-slave/\n", "Is this feature implemented for GPU? \nI am getting the following error when tensorflow is compiled with GPU support\n\n`AttributeError: 'module' object has no attribute 'conv3d_transpose'`\n", "@juanprietob I'm not sure this is in production at the moment. I installed from a nightly build. See the links for nightly builds in an above comment.\n"]}, {"number": 3048, "title": "android demo protobuf-related build error", "body": "### Environment info\n\nOperating System:\nUbuntu 14.04\n\nInstalled version of CUDA and cuDNN: \nNone\n\nIf installed from binary pip package, provide:\nGit cloned. Tried several versions of TF. Same result.\n### Steps to reproduce\n1. Clone repo here : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\n2. I installed SDK 24 (part of Android Studio) and NKD 10e.\n3. Also installed build tools 23.0.1. Seemed to be required.\n4. Followed steps on page\n### What have you tried?\n1. I tried several versions of bazel and tensorflow. The error persists.\n### Logs or other output that would be helpful\n\nThis is my error:\n\nC++ compilation of rule '@protobuf//:protobuf' failed: namespace-sandbox failed: error executing command /home/sander/.cache/bazel/_bazel_sander/577a8dcd97360f56540bc1f3f08ac240/tf-cat-face/_bin/namespace-sandbox ... (remaining 51 argument(s) skipped).\nsrc/main/tools/namespace-sandbox.c:697: execvp(argv[0], argv): No such file or directory\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n### Also, here's how I edited the WORKSPACE file.\n\nworkspace(name = \"org_tensorflow\")\n\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 24,\n    build_tools_version = \"23.0.1\",\n    # Replace with path to Android SDK on your system\n    path = \"/home/sander/Android/Sdk/\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/home/sander/Android/android-ndk-r10e/\",\n    api_level=21)\n\nThis error is quite persistent as I've already tried many installations of both TF and Bazel. I also have a little side question: if the build succeeds, what should the output be when there is no camera attached to my PC? Should I build with my android phone plugged in via USB? Thanks!\n", "comments": ["Andrew, do you have any ideas on what's going wrong here?\n", "@SanderDalm Does it work if you set api_level to 23? If not, can you run again with --verbose_failures and copy the entire failing command please?\n", "Hello Andrew,\n\nIf I set api_level to 23, it fails because my SDK is level 24. It gives:\nERROR: missing input file '@androidsdk//:platforms/android-23/android.jar'.\nERROR: /home/sander/tensorflow/tensorflow/examples/android/BUILD:47:1: //tensorflow/examples/android:tensorflow_demo: missing input file '@androidsdk//:platforms/android-23/android.jar'.\n\nI included the output file of the original error I got when running with api_level 24.\n\nCould it be possible that the demo only works with SDK 23?\n\nThanks for your time!\n\n`____Loading package: tensorflow/examples/android\n____Loading...\n____Loading package: @bazel_tools//tools/cpp\n____Loading package: @androidsdk//\n____Loading package: @local_config_cc//\n____Loading package: @androidndk//\n____Loading complete.  Analyzing...\n____Loading package: @bazel_tools//tools/python\n____Loading package: @bazel_tools//third_party/py/concurrent\n____Loading package: third_party/eigen3\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /home/sander/tensorflow/google/protobuf/BUILD:59:16: in includes attribute of cc_library rule //google/protobuf:protobuf_lite: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sander/tensorflow/google/protobuf/BUILD:124:16: in includes attribute of cc_library rule //google/protobuf:protobuf: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\nWARNING: /home/sander/tensorflow/google/protobuf/BUILD:266:16: in includes attribute of cc_library rule //google/protobuf:protoc_lib: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.\n____Loading package: @eigen_archive//\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:636:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n____Found 1 target...\n____Building...\n____[0 / 1] BazelWorkspaceStatusAction stable-status.txt\n____[4 / 25] Executing genrule @androidsdk//:zipalign_runner [for host]\n____[12 / 40] Creating source manifest for @bazel_tools//third_party/java/apkbuilder:embedded_apkbuilder [for host]\n____[17 / 76] Writing file google/protobuf/libprotobuf.a-2.params [for host]\n____[32 / 605] Compiling google/protobuf/src/google/protobuf/any.cc [for host]\n____[32 / 605] Compiling external/re2/util/logging.cc\n____[32 / 605] Compiling google/protobuf/src/google/protobuf/util/internal/utility.cc\n____[32 / 605] Compiling google/protobuf/src/google/protobuf/util/internal/type_info.cc\n____[32 / 605] Compiling external/re2/re2/perl_groups.cc\nERROR: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/BUILD:9:1: C++ compilation of rule '@re2//:re2' failed: namespace-sandbox failed: error executing command \n  (cd /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/home/sander/anaconda2/bin:/home/sander/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/execroot/tensorflow/_bin/namespace-sandbox @/home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/execroot/tensorflow/bazel-sandbox/f3e4c8b8-47aa-4c62-8afe-8ad94e178795-6.params -- external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes -fno-canonical-system-headers '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' '-frandom-seed=bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/re2/external/re2/util/logging.o' -iquote external/re2 -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm' -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include-fixed -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -MD -MF bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/re2/external/re2/util/logging.d -c external/re2/util/logging.cc -o bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/re2/_objs/re2/external/re2/util/logging.o).\nsrc/main/tools/namespace-sandbox.c:707: execvp(argv[0], argv): No such file or directory\n____[32 / 605] Compiling google/protobuf/src/google/protobuf/descriptor.pb.cc\n____Building complete.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\n____Elapsed time: 8.188s, Critical Path: 2.50s`\n", "I just checked, and it builds fine for me with API 24. In any case you're running into native compilation errors, not a Java problem, so it should be a non-issue.\n\nThe error in your log output seems to be re2-related (@protobuf appears nowhere in the pasted log). Because the failing module varies, this could be a general workspace issue, with the error depending on which module it tries to build first.\n\nHow did you initialize your repo? I just tested, and the following works for me at API 24:\n\n```\ngit clone --recursive https://github.com/tensorflow/tensorflow\ncd tensorflow\n<edit WORKSPACE>\nbazel build -s //tensorflow/examples/android:tensorflow_demo -s --verbose_failures\n```\n", "Hello Andrew,\n\nI cloned the repo, downloaded the inception model (and the label file) into examples/android/assets and edited the WORKSPACE file in home/tensorflow  including this at the top.\n\nIs there some vital step I missed?\n\n```\n\nworkspace(name = \"org_tensorflow\")\n\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 24,\n    build_tools_version = \"23.0.1\",\n    # Replace with path to Android SDK on your system\n    path = \"/home/sander/Android/Sdk/\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/home/sander/Android/android-ndk-r10e/\",\n    api_level=21)\n\n\n```\n", "What are the exact commands you use to clone and build?\n\nI would try removing the trailing slashes for the NDK and SDK paths in your WORKSPACE file, sometimes those can cause issues.\n", "Hello Andrew,\n\nI followed exactly the steps on this page (build from source version, bazel version 0.3.0 and oracle java 1.8, if that helps?): \n\nhttps://www.tensorflow.org/versions/r0.9/get_started/os_setup.html\n\nI just did a full re-install and ended up getting this error. It looks like a slightly different one? Removing the trailing slashes unfortunately did not help.\n\n`____Loading...\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/protobuf/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/highwayhash/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n____Found 1 target...\n____[0 / 17] BazelWorkspaceStatusAction stable-status.txt\n____[0 / 143] Compiling external/protobuf/src/google/protobuf/compiler/zip_writer.cc [for host]\n____[0 / 114] Compiling external/protobuf/src/google/protobuf/util/time_util.cc [for host]\n____[1 / 191] Compiling external/protobuf/src/google/protobuf/compiler/java/java_lazy_message_field_lite.cc [for host]\n____[0 / 105] Compiling external/protobuf/src/google/protobuf/io/zero_copy_stream.cc [for host]\n____[0 / 100] Compiling external/protobuf/src/google/protobuf/stubs/atomicops_internals_x86_msvc.cc [for host]\n____[0 / 94] Compiling external/protobuf/src/google/protobuf/stubs/statusor.cc [for host]\n____[0 / 88] Compiling external/protobuf/src/google/protobuf/wire_format_lite.cc [for host]\n____[2 / 279] Compiling external/protobuf/src/google/protobuf/util/message_differencer.cc\n____[2 / 309] Compiling external/protobuf/src/google/protobuf/util/internal/utility.cc\n____[3 / 315] Compiling external/protobuf/src/google/protobuf/generated_message_reflection.cc\n____[2 / 305] Compiling external/protobuf/src/google/protobuf/service.cc\n____[4 / 331] Compiling external/protobuf/src/google/protobuf/field_mask.pb.cc\n____[5 / 338] Compiling external/protobuf/src/google/protobuf/stubs/atomicops_internals_x86_gcc.cc\n____[4 / 331] Compiling external/protobuf/src/google/protobuf/stubs/status.cc\n____[5 / 346] Compiling external/protobuf/src/google/protobuf/empty.pb.cc\n____[5 / 352] Compiling external/protobuf/src/google/protobuf/io/coded_stream.cc\n____[8 / 399] Compiling external/protobuf/src/google/protobuf/stubs/stringprintf.cc\nERROR: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/protobuf/BUILD:111:1: C++ compilation of rule '@protobuf//:protobuf' failed: arm-linux-androideabi-gcc failed: error executing command \n  (cd /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/home/sander/anaconda2/bin:/home/sander/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes -fno-canonical-system-headers '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' '-frandom-seed=bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/any.o' -iquote external/protobuf -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm' -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include -isystem external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9/include-fixed -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -MD -MF bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/any.d -c external/protobuf/src/google/protobuf/any.cc -o bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/any.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nprocess-wrapper: execvp(\"external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc\", ...): No such file or directory\n____Building complete.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\n____Elapsed time: 4.974s, Critical Path: 3.93s`\n", "The workspace name mismatches are worrisome -- I'm not sure why you'd be getting those. Perhaps clear your bazel cache and make sure you don't have any hidden bazel config files or env variables that might be messing things up?\n\nCan you please verify that you have \n\n```\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/home/sander/Android/android-ndk-r10e\",\n    api_level=21)\n```\n\nin your WORKSPACE file, and that\n`/home/sander/Android/android-ndk-r10e/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc`\nexists?\n\nWhat are the exact commands you use to clone and build?\n", "Hello Andrew,\n\nSuccess! I looks like the build is now error free. After the complete re-install the bazel error disappeared and a less serious NKD error popped up. Building from source using the newest version of TF and bazel did the trick. The build and clone commands were these:\n\n`git clone https://github.com/tensorflow/tensorflow`\n`- bazel already installed -`\n`bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`\n`sudo pip install /tmp/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl`\n`cd /home/sander/tensorflow`\n`bazel clean`\n'bazel build //tensorflow/examples/android:tensorflow_demo'\n\nThe NDK error was quickly fixed. I followed your advise to confirm the existence of the folders and it turned out the 10e NDK was a darwin version rather than a linux version. I switched to the already installed NDK 12 linux version and now my output looks better (see below).\n\nThanks a lot for helping me out so patiently!\n\nIf you don't mind me asking one last question. As I have little experience integrating resources like these into Android apps, could you quickly point out the steps to actually deploying this on my phone and/or publishing an app using TF? Can I simply use the jar-file in Android Studio? A link to a helpful page would be awesome.\n\nKind regards and thanks again!\n\nSander\n\n`____Loading...\nWARNING: Bazel Android NDK crosstools are based on Android NDK revision 11. The revision of the Android NDK given in android_ndk_repository rule 'androidndk' is '12.0.2931149'.\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/protobuf/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/highwayhash/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nWARNING: /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE:1: Workspace name in /home/sander/.cache/bazel/_bazel_sander/748832a8b72d340071e33de307f082db/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/sander/tensorflow/tensorflow/core/BUILD:612:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n____Found 1 target...\n____Building...\n____[0 / 1] BazelWorkspaceStatusAction stable-status.txt\nTarget //tensorflow/examples/android:tensorflow_demo up-to-date:\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk\n  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\n____Elapsed time: 2.841s, Critical Path: 0.00s`\n", "Glad it's working!\n\nBazel outputs tensorflow_demo as an apk (Android application package), so it's actually already a fully functional app -- no need to do anything else with it at that point but install and run.\n\nAssuming you have device connected with adb debugging enabled (run `adb devices` to check), you can install it via `adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk`.\n\nYou can find the adb tool under your SDK/platform-tools directory.\n\n`bazel mobile-install -c opt tensorflow/examples/android:tensorflow_demo --start_app` will also build, install, and start the app in a single command, which you may find more convenient.\n"]}, {"number": 3047, "title": "Logging doesn't produce any output in console or in Jupyter", "body": "Currently running examples leads to a void of empty output.\nBoth in console and in Jupyter notebooks. Which for example of LinearClassifier leads to a \"stuck\" model because steps by default is None.\n", "comments": ["Should we simply force --alsologtostderr, at least in opensource (only file logging is highly unusual), and possibly whenever we detect we're running in an interactive environment?\n", "Hm. So the logger is already configured to make a StreamHandler which should by default point to stderr (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/tf_logging.py#L46). Does jupyter discard stderr? Do we have to log to stdout for it to show up?\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "So to make it work in Jupyter, one right now needs to add \n`tf.logging.set_verbosity(tf.logging.INFO)`. Also it prints right now in red as it's `stderr`.\n\nWe should support a way to print into `stdout` and by default show `INFO`.\n", "Is this still current?\n", "The problem persists.\n", "@ilblackdragon setting `tf.logging.set_verbosity(tf.logging.INFO)` did not produce any logging in Jupyter (QtConsole) for me, but I can see the logs in `ipython` shell.\r\nSo, following the documents [here](https://www.tensorflow.org/tutorials/using_gpu) will not produce any logs as expected.", "EDIT: My logging is done not in the actual notebook but in the terminal where I started the notebook.", "No logging for me, either.", "FWIW this isn't working for me either. I'm not running in ipython/jupyter. I've tried `tf.logging.set_verbosity(tf.logging.DEBUG)`, `tf.logging.set_verbosity(0)`, and pretty much everything else I can think of. But I'm not seeing anything from `tf.logging.info(...)` in stdout or stderr."]}, {"number": 3046, "title": "Please add Cuda compute capability 6.1 for GTX 1080", "body": "I am building tensorflow from source, and after running below from the root\n\n`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`\n\nI get\n\n> ERROR: /home/shuaiwang/Downloads/tensorflow/tensorflow/cc/BUILD:61:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.\n> ERROR: /home/shuaiwang/Downloads/tensorflow/tensorflow/cc/BUILD:61:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error cloning repository: https://github.com/google/protobuf: cannot open git-upload-pack caused by https://github.com/google/protobuf: cannot open git-upload-pack caused by github.com and referenced by '//tensorflow/cc:tutorials_example_trainer'.\n> ERROR: Analysis of target '//tensorflow/cc:tutorials_example_trainer' failed; build aborted.\n> INFO: Elapsed time: 11.805s\n\nI guess this is because tensorflow doesn't support compute capability for 6.1, which is the only option for GTX 1080, according to [this](https://developer.nvidia.com/cuda-gpus)?\n", "comments": ["You can set this option during ./configure\n", "@vrv can you be more specific? thanks\n", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#configure-tensorflows-canonical-view-of-cuda-libraries\n", "@vrv hi I did specify 6.1 in the Cuda compute capabilities step\n\n> Please specify a list of comma-separated Cuda compute capabilities you want to build with.\n> You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\n> Please note that each additional compute capability significantly increases your build time and binary size.\n> [Default is: \"3.5,5.2\"]: 6.1\n\nthen I got the error build aborted \n", "Ah, sorry, I didn't read the error message closely enough.  I'd just try again -- it looks like bazel couldn't git clone the protobuf repository properly, possibly due to transient network issues.  Nothing to do with cuda at all :)\n\nIf this isn't true, maybe worth trying to file a bug with bazel to make the error message more helpful, if it's not just a transient network problem.\n", "@vrv tried multiple times and got the same error :(\n\nDo you think it might be possible that bazel was not installed properly?\n", "No idea :(.  Try re-installing bazel, fresh cloning the tensorflow repository in a new directory and try again..\n", "@vrv hey I tried re-install bazel and fresh clone, but I get a different error\n\n> ERROR: /home/shuaiwang/Downloads/tensorflow/tensorflow/tools/proto_text/BUILD:31:1: Linking of rule '//tensorflow/tools/proto_text:gen_proto_text_functions' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/tools/proto_text/gen_proto_text_functions ... (remaining 26 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n> /usr/bin/ld: bazel-out/host/bin/tensorflow/core/liblib_internal.a(numbers.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n> //lib/x86_64-linux-gnu/libm.so.6: error adding symbols: DSO missing from command line\n> collect2: error: ld returned 1 exit status\n> Target //tensorflow/cc:tutorials_example_trainer failed to build\n> Use --verbose_failures to see the command lines of failed build steps.\n> INFO: Elapsed time: 7.452s, Critical Path: 6.54s\n\nThoughts?\n", "The same linking problem as #3029 \n\nPlease edit proto_text\\BUILD and try building again.\n"]}]