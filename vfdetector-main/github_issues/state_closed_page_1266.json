[{"number": 15158, "title": "Feature: MonitoredSession should have run() method with 'hooks_to_trigger' argument: run(..., hooks_to_trigger=[hooks[1], hooks[3], ...])", "body": "At the moment the session_run_hooks are passed to the constructor of MonitoredSession(..., hooks=[...]) \r\nand then they get executed for EVERY session.run() call within the MonitoredSession block.\r\n\r\nThis is inefficient and problematic.\r\n\r\nE.g., if I define a LoggingTensorHook, I want the logging output to be evaluated and printed at most ONCE per global step and not after some auxiliary session.run() calls that only evaluate the size of some queue or whatever else.\r\n\r\nIf you use feedable iterators, the current MonitoredSession implementation actually crashes the program, see https://github.com/tensorflow/tensorflow/issues/12859#issuecomment-348290076\r\n\r\nThe best solution in my opinion would be, to be able to specify which run() calls should actually trigger the before_run and after_run methods of the hooks, e.g. via some flag-argument in MonitoredSession.run(..., execute_hooks=True)\r\nor alternatively pass a list of specific hooks whose before_run and after_run methods should be triggered by a run call, via MonitoredSession.run(..., hooks_to_trigger=[...])\r\n", "comments": ["Simple solution could be: (in _HookedSession) marked with **\r\n```\r\ndef run(self, fetches, feed_dict=None, options=None, run_metadata=None, **hooks_to_trigger=[None]**):\r\n    \"\"\"See base class.\"\"\"\r\n    if self.should_stop():\r\n      raise RuntimeError('Run called even after should_stop requested.')\r\n\r\n    actual_fetches = {'caller': fetches}\r\n\r\n    run_context = session_run_hook.SessionRunContext(\r\n        original_args=session_run_hook.SessionRunArgs(fetches, feed_dict),\r\n        session=self._sess)\r\n\r\n    options = options or config_pb2.RunOptions()\r\n    feed_dict = self._call_hook_before_run(run_context, actual_fetches,\r\n                                           feed_dict, options, **hooks_to_trigger**)\r\n\r\n    # Do session run.\r\n    run_metadata = run_metadata or config_pb2.RunMetadata()\r\n    outputs = _WrappedSession.run(self,\r\n                                  fetches=actual_fetches,\r\n                                  feed_dict=feed_dict,\r\n                                  options=options,\r\n                                  run_metadata=run_metadata)\r\n\r\n    for hook in **list(set(self._hooks).intersection(hooks_to_trigger))**:\r\n      hook.after_run(\r\n          run_context,\r\n          session_run_hook.SessionRunValues(\r\n              results=outputs[hook] if hook in outputs else None,\r\n              options=options,\r\n              run_metadata=run_metadata))\r\n    self._should_stop = self._should_stop or run_context.stop_requested\r\n\r\nreturn outputs['caller']\r\n```\r\n", "We think allowing different hook sets to be used in each run complicates the usage. MonitoredSession.run_step_fn should be used instead.", "Okay.\r\nPersonally, I don't think that will offer enough flexibility. What if you need to implement Faster R-CNN style alternative training schedules, where you first train only the RPN and then the classifier Head. \r\nIf you use e.g. a LoggingTensorHook in this setting and tell it to log Tensors both from RPN and the Head, then you will produce an error while training only RPN for the first time as Tensors in the Head cannot be evaluated yet. \r\nWrapping all this in the run_step_fn would be super convoluted and ugly. \r\nI guess you can say, that for such more complex problems one just should not use hooks at all ...", "Why not at least implement a simple switch with which you can signal that a specific session.run should NOT trigger the hooks?\r\ni.e. `MonitoredSession.run(..., trigger_hooks=False)` (default=True)\r\nor a separate wrapper `MonitoredSession.run_without_hooks`\r\nSeems way more straightforward than having to implement a step_fn with an if-statement that is executed only once and then never again (in the example you gave:\r\n```\r\ndef step_fn(step_context):\r\n  if handle_train is None:\r\n    handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\r\n  return step_context.run_with_hooks(fetches=..., feed_dict=...)\r\n``` ", "Hi!  \r\n\r\nWould [after_create_session()](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/training/session_run_hook.py#L115) work for something that you want to run only once?\r\n\r\nWhat are those \"auxiliary session.run() calls\" that you are talking about?  [The relevant queues that I can think of are given](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/training/monitored_session.py#L557) the raw session that doesn't run hooks.", "As an example, in our old input pipeline, we needed to evaluate the current size of the RandomShuffleQueues several times within the session block, in order to efficiently be able to switch between training and validation queues. For these evaluations we needed three separate session.run(rsq.size) calls, that evaluated nothing else and that always triggered all hooks, even though nothing in the weights had changed in the meantime. So for example LoggingTensorHook would log the same tensors with exactly the same values 4 times in the same global step. \r\nSo, here it would have been nice to tell the hooks to just ignore the session.run(rsq.size) calls.", "As for the problem with creating the string_handles for the feedable iterator, after_create_session could be used to solve it I guess, but then I would have to create an extra hook just for that, that would also make the code much harder to read. \r\nI am not a great fan of hiding away simple logical algorithmic steps in convoluted constructs. I should be able to recognize all essential steps of the graph evaluation in the session block (so, except for logging and saving stuff, for this hooks are great).\r\nSo, I would still like to have this structure:\r\n```\r\nwith MonitoredSession(hooks=hooks) as sess: \r\n  # everything that needs to be evaluated only once\r\n  handles = session.run(handles)\r\n  condition = session.run(some_structural_evaluation_of_the_graph )\r\n\r\n  # everything that needs to be evaluated per global step\r\n  while iter < iter_max and not sess.should_stop():\r\n    session.run(opt)\r\n    ...\r\n```", "If you run the calls to evaluate the size of the queues inside run_step_fn, then it won't trigger hooks.\r\n\r\nIn your code example, suppose the MonitoredSession instance handled a transient failure for you that resulted in a new underlying raw session.  The new session has restored from the last saved checkpoint, possibly undoing the updates that have been computed but haven't been checkpointed yet.  In such a scenario, would like for `session.run(handles)` and for `session.run(some_structural_evaluation_of_the_graph)` to be re-run for you when the session is re-recreated and variables are restored? ", "> Why not at least implement a simple switch with which you can signal that a specific session.run should NOT trigger the hooks?\r\n> i.e. MonitoredSession.run(..., trigger_hooks=False) (default=True)\r\n> or a separate wrapper MonitoredSession.run_without_hooks\r\n> Seems way more straightforward than having to implement a step_fn with an if-statement that is executed only once and then never again (in the example you gave:\r\n> def step_fn(step_context):\r\n>   if handle_train is None:\r\n>     handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\r\n>   return step_context.run_with_hooks(fetches=..., feed_dict=...)\r\n\r\nCould you give a complete example by using this step_fn?Thanks!"]}, {"number": 15157, "title": "Feature: GANEstimator allow passing of namedtuples", "body": "In the current `GANEstimator` implementation in `train.py` `gan_model(..)` both `real_data` as well as `generator_inputs` is converted to tensors with either `_convert_tensor_or_l_or_d` or `ops.convert_to_tensor`. This prevents the user from using own data structures like `namedtuples` to pass information between the `generator` and `discriminator`.\r\n\r\nIn the current implementation when passing a `namedtuple` the result will be a `list` with all name information being lost.\r\n\r\nI propose to either extend the tensor conversion to exclude namedtuples from them or to remove them entirely.\r\n\r\n@joel-shor Do you think that is a good idea? I am currently passing logits as well as sample_id from a dynamic_decoding around and I would like to keep the meaning of these across loss_fn and discriminator_fn.\r\n\r\n1. I could remove the conversions entirely. This would introduce breaking changes.\r\n2. I could exclude namedtuples from the conversion.\r\n3. Idk yet??\r\n\r\nI would create a PR for any of them if we find a suitable solution. ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hi, I am not familiar with gan estimator, however many function support dict in tensorflow. Could dict solve the problem? ", "@facaiy made the point I wanted to make: TFGAN already supports dictionaries. Could you just use the namedtuple `_asdict()` function for the duration of the GANEstimator? I'm hesitant to support namedtuples, since AFAIK they're not support by default in many tensor conversion functions", "I would still love to see namedtuples for their immutability but I can live for now with a dictionary.\r\n@joel-shor You can decide wether you leave this request open or close it."]}, {"number": 15156, "title": "Tensorflow set_random_seed", "body": "I use `tf.set_random_seed` to set the seed of graph, and run programs many times, but the result is different.\r\nIs it a bug or precision problem?\r\n\r\n```python\r\nimport tensorflow as tf\r\nslim =tf.contrib.slim\r\n\r\ntf.set_random_seed(0)\r\n\r\ndef vgg16(inputs):\r\n  with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                      activation_fn=tf.nn.relu,\r\n                      weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\r\n                      weights_regularizer=slim.l2_regularizer(0.0005)):\r\n    net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\r\n    net = slim.max_pool2d(net, [2, 2], scope='pool1')\r\n    net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\r\n    net = slim.max_pool2d(net, [2, 2], scope='pool2')\r\n    net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\r\n    net = slim.max_pool2d(net, [2, 2], scope='pool3')\r\n    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\r\n    net = slim.max_pool2d(net, [2, 2], scope='pool4')\r\n    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\r\n    net = slim.max_pool2d(net, [2, 2], scope='pool5')\r\n    net = slim.flatten(net)\r\n    net = slim.fully_connected(net, 4096, scope='fc6')\r\n    net = slim.dropout(net, 0.5, scope='dropout6')\r\n    net = slim.fully_connected(net, 4096, scope='fc7')\r\n    net = slim.dropout(net, 0.5, scope='dropout7')\r\n    net = slim.fully_connected(net, 1000, activation_fn=None, scope='fc8')\r\n  return net\r\n\r\noutputs = vgg16(tf.random_normal([32, 224, 224, 3]))\r\nloss = tf.reduce_mean(tf.square(outputs-tf.random_normal([32, 1000])))\r\nloss = tf.Print(loss, [loss])\r\noptimizer = tf.train.GradientDescentOptimizer(0.001)\r\ntrain_op = optimizer.minimize(loss)\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    for i in range(10):\r\n        sess.run([loss, train_op])\r\n```\r\n\r\nSometimes it prints\r\n```\r\n2017-12-06 22:12:46.008551: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00103784]\r\n2017-12-06 22:12:48.309682: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01074851]\r\n2017-12-06 22:12:49.039724: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00621808]\r\n2017-12-06 22:12:49.683761: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00629878]\r\n2017-12-06 22:12:50.326798: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.999040961]\r\n2017-12-06 22:12:50.973835: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.991326749]\r\n2017-12-06 22:12:51.621872: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01098168]\r\n2017-12-06 22:12:52.266909: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.989544928]\r\n2017-12-06 22:12:52.911945: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01077247]\r\n2017-12-06 22:12:53.558982: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00654614]\r\n```\r\nOr\r\n\r\n```\r\n2017-12-06 22:14:15.614676: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00103784]\r\n2017-12-06 22:14:17.945809: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01074851]\r\n2017-12-06 22:14:18.633848: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00621808]\r\n2017-12-06 22:14:19.283886: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00629878]\r\n2017-12-06 22:14:19.932923: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.999040902]\r\n2017-12-06 22:14:20.582960: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.99132669]\r\n2017-12-06 22:14:21.231997: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01098168]\r\n2017-12-06 22:14:21.878034: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [0.989544928]\r\n2017-12-06 22:14:22.525071: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.01077247]\r\n2017-12-06 22:14:23.137106: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [1.00654614]\r\n```\r\n\r\nThe fifth and sixth float number are a little different.\r\n\r\nIf it is the precision problem, the output of program will be different while running on different situation.\r\n\r\nIf I use` resnet_v1.resnet_v1_101`, the difference becomes bigger.\r\nSee below\r\n```\r\n2017-12-06 22:36:10.263869: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.38138771]\r\n2017-12-06 22:36:10.957909: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.37634754]\r\n2017-12-06 22:36:11.511941: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.37431192]\r\n2017-12-06 22:36:12.065973: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.32495236]\r\n2017-12-06 22:36:12.618004: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.31184864]\r\n2017-12-06 22:36:13.171036: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.26968479]\r\n2017-12-06 22:36:13.726067: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.26032281]\r\n2017-12-06 22:36:14.282099: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.21301842]\r\n2017-12-06 22:36:14.831131: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.25101829]\r\n2017-12-06 22:36:15.386162: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.14982963]\r\n```\r\nand\r\n```\r\n017-12-06 22:36:46.220926: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.38138771]\r\n2017-12-06 22:36:46.913966: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.3763473]\r\n2017-12-06 22:36:47.466997: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.37354136]\r\n2017-12-06 22:36:48.022029: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.32750821]\r\n2017-12-06 22:36:48.571060: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.30615568]\r\n2017-12-06 22:36:49.126092: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.26913476]\r\n2017-12-06 22:36:49.682124: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.26520848]\r\n2017-12-06 22:36:50.238156: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.21404171]\r\n2017-12-06 22:36:50.793188: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.25153565]\r\n2017-12-06 22:36:51.347219: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\r\n\\PY\\35\\tensorflow\\core\\kernels\\logging_ops.cc:79] [3.14605141]\r\n``` \r\n", "comments": ["did you try to pass the seed to `random_normal`?", "@drpngx I have tried, but also get the same result, a little difference among different running.", "@sguada is there anything special here?", "There are known issues with op ordering that may prevent you from getting the same results after different runs. Especially with larger graphs this can be a problem.\r\nThis is just caused by how the threads are scheduled by the OS.", "@gunan I find the first number never changes, which means the issues happened during the backpropagation.  So I wonder whether it will cause the gradient updating more unstable.", "Cuda can also introduce randomness in backpropagation", "Try passing seed to truncated_normal_initializer and to random_normal", "@sguada I have tried to pass seed to truncated_normal_initializer and to random_normal, but no effect.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "You also need to pass a seed to all tf.random_normal Tensors you create"]}, {"number": 15155, "title": "Input too short to compute filterbank", "body": "Hi,\r\nI am new to tensorflow and i am trying to train model with my own data but i am getting below error\r\n\r\n2017-12-06 18:56:38.030081: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030095: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030105: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030162: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030203: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030243: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030256: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030267: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030305: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030347: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030359: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030370: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030408: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030446: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030458: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030469: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030481: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030492: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030534: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030547: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030558: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030569: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030632: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030645: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030656: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030668: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030679: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030720: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030732: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030743: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030754: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030790: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030851: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030865: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030877: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030937: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030954: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.030967: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031028: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031043: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031054: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031066: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031078: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031118: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031132: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031144: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031155: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031211: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031227: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031238: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031249: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031309: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031325: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031338: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031349: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031408: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031425: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031437: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031474: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031512: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031525: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031537: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031573: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031608: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031620: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031631: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031643: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031687: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031699: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031710: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031769: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031799: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031812: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031823: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031834: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.031965: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032014: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032024: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032036: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032046: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032057: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032069: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032081: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032128: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032141: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032153: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032165: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032176: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032236: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032248: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032260: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032272: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032313: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032326: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032336: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032347: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032360: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n2017-12-06 18:56:38.032399: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank\r\n\r\nand i am using below command to train\r\nbazel run tensorflow/examples/speech_commands:train -- \\ --data_dir=sound --wanted_words=yes,no --data_url=\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Try to flag data_url=\"\"", "Did you find a resolution to the problem? I'm getting the same error when using upper_limit_frequency=10500 for the mfcc."]}, {"number": 15154, "title": "Add uint32 and uint64 kernel support for `Invert`", "body": "This fix adds uint32 and uint64 kernel support for `Invert`.\r\n\r\nIn bitwise_ops.cc, uint32 and uint64 have been registered for `Invert` like other bitwise ops `BitwiseAnd`/`BitwiseOr`/`BitwiseXor`/`LeftShift`/`RightShift`.\r\n\r\nHowever, no uint32 and uint64 kernels available for `Invert` yet.\r\n\r\nThis fix add uint32 and uint64 kernel for `Invert`, and adds additional test cases to cover the changes.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@tensorflow-jenkins test this please", "Jenkins, test this please.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Ping @caisq @drpngx. Any chance to take a look?", "@caisq Thanks for the review. The PR has been updated. Please take a look.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@caisq The PR has been rebased and pushed to resolve the merge conflict. Please take a look."]}, {"number": 15153, "title": "Tensorflow Unit Test //tensorflow/python/kernel_tests:depthtospace_op_test TIMEOUT", "body": "System Information\r\nLinux  ppc64le GNU/Linux\r\ncommit id 3fe5fa08dbed8134ad400f03be474aeb39bcc922\r\nPython 2.7.5\r\nBazel Build label: 0.5.4- (@non-git)\r\ngcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)\r\ncuda-9.0/\r\nNVIDIA GPU driver \r\n\r\ncommand to reproduce  - bazel test tensorflow/python/kernel_tests:depthtospace_op_test\r\n\r\n*Failure log* \r\n\r\npci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-06 08:58:27.675099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\n2017-12-06 08:58:27.699874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-06 08:58:27.699885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\nTerminated\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "we see this issue right now as well, We are debugging it on power and will verify on x86 as well. ", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "There is no TensorFlow commit 3fe5fa08dbed8134ad400f03be474aeb39bcc922. Did you make a commit yourself?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "This issue doesn't recreate with Tensorflow 1.5"]}, {"number": 15152, "title": "Strange Dataset API behaviour", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nv1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: \r\nsys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0)\r\n- **Bazel version (if compiling from source)**:\r\nn/a\r\n- **GCC/Compiler version (if compiling from source)**:\r\nn/a\r\n- **CUDA/cuDNN version**:\r\nCuda 8.0 \r\n- **GPU model and memory**:\r\nTitan XP 12Gb\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI get very strange behaviour of image read function. See attached screenshot from tensorboard. This is NOT a tensorboard problem as I get images as they are from Dataset object.\r\n![kodak_messed](https://user-images.githubusercontent.com/6204851/33659749-37586c4e-da79-11e7-8977-7d8f6da31c2d.png)\r\n\r\nSource images are fine, I have attached a zip archive with source images:\r\n[Kodak.zip](https://github.com/tensorflow/tensorflow/files/1534996/Kodak.zip)\r\n\r\n```\r\nimport glob\r\nimport tensorflow as tf\r\n\r\ndef simply_read_image(image_path):\r\n    image_string = tf.read_file(image_path)\r\n    image_source = tf.image.decode_png(image_string, channels=3)\r\n    image_source = tf.image.convert_image_dtype(image_source, dtype=tf.float32)\r\n    return image_source\r\n\r\nvalidation_files = glob.glob(os.path.join(validation_folder, '*.png'))\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(validation_files)\r\ndataset = dataset.map(simply_read_image).batch(len(validation_files)).repeat(30)\r\n\r\nnext_element = iterator.get_next()\r\n\r\n    with tf.Session() as s:\r\n        for i in range(30):\r\n            im = s.run(next_element)\r\n            for j in range(25):\r\n                current_image = im[j]\r\n                pass\r\n\r\n```\r\nAny ` current_image` with portrait orientation seems to be read incorrectly. \r\n### Source code / logs\r\nThere are no logs that could help", "comments": ["Me and my colleague have made a small investigation of this behaviour. \r\nThe reason of this happening is not very surprising. All images in Kodak set are either 512x768 or 768x512 pixels. That said, it is just a pure luck that every time you precisely the same amount of pixels. \r\n\r\nEvery time an image is read with a correct shape, which can be seen if we put \r\n`tf.Print(image_source, [tf.shape(image_source)], summarize=1000)` somewhere in `simply_read_image` function.\r\n\r\nHowever, after Dataset object takes it place, it \"memorises\" the shape of the _first_ entry and then tries to fill image buffer _somehow_. There are two indicators of this: \r\n\r\n1. `dataset = dataset.map(lambda x: tf.Print(x, [tf.shape(x)], summarize=1000), num_parallel_calls=12)` This line will print the same shape for all image. This shape will of the first image met in file list\r\n\r\n2. This can be easily checked by rescaling one of images so that is has different from 512x768 amount of pixels and try to do the same.\r\n\r\nAfter this the code above will crush with an obvious error:\r\n```\r\nInternalError (see above for traceback): HandleElementToSlice Cannot copy slice: number of elements does not match.  Shapes are: [element]: [512,768,3], [parent slice]: [433,288,3]\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,?,3]], output_types=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n```\r\n\r\nI think this is a wrong behaviour for `dataset` object, because:\r\n\r\n1. I may want to use `Dataset` API for running my autoencoders on real world images of different sizes.\r\n2. In image processing tasks you can't rescale image to standard size, because images will seen by humans after network does it's job\r\n\r\nTaking these into account and that (to the best of my knowledge) there is no other way to use `Dataset` API for image reading images of different sizes, I think this poses a problem. \r\n\r\nProbably the resolution could be allow dispatching images of different sizes by `dataset` object, if batch size is equal to 1.", "Hm, it looks like the problem is that `Dataset.batch()` doesn't validate that the shapes of all elements in the batch are the same. It merely checks that the number of elements matches, which allows you to silently batch together 512x768 and 768x512 images. I'm preparing a fix."]}, {"number": 15151, "title": " model.fit crash ( keras example mnist) TensorFlow1.4", "body": " I run example : https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\r\nbut it crashed when train, namely model.fit\r\n\r\n\r\nThe error is :\r\nAn error ocurred while starting the kernel\r\n\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that thisTensorFlow binary was not compiled to use: AVX AVX2\r\n\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties: \r\n\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) \u2011> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\r\ntensorflow\\stream_executor\\cuda\\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\ntensorflow\\stream_executor\\cuda\\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n\\tensorflow\\core\\kernels\\conv_ops.cc:667] Check failed: stream\u2011>parent()\u2011>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) \r\n\r\nAnd I run another example it crashed too when run at  model.fit, but the error is not the same:\r\nAn error ocurred while starting the kernel\r\n\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) \u2011> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\r\n \\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\ntensorflow\\stream_executor\\cuda\\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n \\tensorflow\\core\\kernels\\conv_ops.cc:667] Check failed: stream\u2011>parent()\u2011>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) \r\n \r\n\r\n# My environment:\r\nwin7\r\ntensorflow-gpu 1.4\r\ncuda 8.0 \r\ncudnn6.0 \r\nGeForce GTX 1080 Ti \r\n\r\nI really appreciate your help\uff01", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This seems like the same issue as #6698. Try some of the advice there. In particular, try making sure no other processes are using the GPU by running `nvidia-smi`.\r\n\r\n@mrry, any ideas what the problem could be?", "No idea, sorry!", "Thank you for your replies so quickly ! It's OK when i restart the computer.", "After that i think i should introduce this solve in detail , \r\nif you  encounter \r\n\"An error ocurred while starting the kernel\r\ncc:366  failed to create cublas handle: CUBLAS_STATUS_NOT_INITALIZED\r\ncc:4637 stream 000000000F5CB190 did not memcpy host-to-device; sorce:0000000204C00900\r\ncc306 Error recording event in stream:error recording CUDA event on stream 0000000008C4220:\r\nCUDA_ERROR_OUT_OF_MEMORY; not marking stream as bad,as the Event object may be at fault. Monitor for further errors. \r\ncc:49    Error polling for event status: failed to query event: CUDA_ERROR_OUT_OF_MEMORY\r\n\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc\r\n Unexpected Event status:1\"\r\nmaybe because cudnn is not match. \r\n\r\n Then i  set a new environment install tensorflow1.4 which has keras without install\uff0cbut after installing i did not check GPU, just as reedwm say \u201cother processes are using the GPU \u201d. So i restart the computer.\r\nThank you!\r\n"]}, {"number": 15150, "title": "`variational_recurrent` in contrib DropoutWrapper causes extreme perplexity jumps", "body": "I have done extensive testing of the `variational_recurrent` option in the tf.contrib dropout wrapper and neither me nor my colleagues can explain the extreme perplexity jumps that are caused by it.\r\n\r\nI am training an RNN language model on the Penn Treebank Dataset. The model code is very similar to the one provided in the [TensorFlow Tutorial](https://www.tensorflow.org/tutorials/recurrent), using the same learning parameters, hidden sizes, etc. like the MEDIUM config. I am using the newest TensorFlow version (1.4.0).\r\n\r\nConsider the following models together with the dropout values used in the tf.contrib Dropout Wrapper. If not mentioned, no further regularization was used.\r\n\r\n**model1:** \r\n\r\n - input dropout 0.3, state dropout: 0.3, output dropout: 0.3\r\n - variational_recurrent=True\r\n - Perplexity test set: 83.81\r\n - Perplexity validation set: 86.97\r\n\r\n**model2:**\r\n\r\n - input dropout 0.5, state dropout: 0.3, output dropout: 0.5\r\n - variational_recurrent=True   \r\n - Perplexity test set: 639.65\r\n - Perplexity validation set: 686.95\r\n\r\n**model3 (as a comparison):**\r\n\r\n - input dropout 0.5, output dropout: 0.5\r\n - variational_recurrent=False\r\n - Perplexity test set: 82.88\r\n - Perplexity validation set: 86.11\r\n\r\n\r\nI have tested various architectures, with and without variational dropout. I could not find an explanation for the fact that the perplexity sometimes jumps up to >600 when using variational dropout. Also, the effects vanish when tying the embedding and softmax weights.\r\nIn general, variational dropout does not improve but worsen the results (which is different to the results reported in recent papers using variational dropout on the PTB dataset).\r\n\r\nTo test this problem further, I have adapted the official tensorflow tutorial to use variational dropout instead of standard dropout, by removing lines 131+132 and replacing lines 218-220 with:\r\n\r\n    if is_training and config.keep_prob < 1:\r\n      cell = tf.contrib.rnn.DropoutWrapper(cell,\r\n                input_keep_prob=config.keep_prob,\r\n                output_keep_prob=config.keep_prob,\r\n                state_keep_prob=config.keep_prob,\r\n                variational_recurrent=True, dtype=tf.float32,\r\n                input_size=config.hidden_size)\r\n\r\nTraining the medium model with this configuration causes the same issues, i.e. perplexity > 600\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code\r\n- **OS Platform and Distribution**:  Debian GNU/Linux 8.9 (jessie)\r\n- **TensorFlow version **: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: Python 3.5.4 \r\n- **GCC/Compiler version**:\r\ntf.VERSION = 1.4.0\r\ntf.GIT_VERSION = v1.4.0-rc1-11-g130a514\r\ntf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514", "comments": ["+Andrew.  Andrew, wdyt?  A bug in the variational dropout wrapper?\n\nOn Wed, Dec 6, 2017 at 9:22 AM, drpngx <notifications@github.com> wrote:\n\n> Assigned #15150 <https://github.com/tensorflow/tensorflow/issues/15150>\n> to @ebrevdo <https://github.com/ebrevdo>.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15150#event-1375261423>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim93Ygm3pAKER1eEfhz5ajc5iiKWCks5s9s1BgaJpZM4Q3snQ>\n> .\n>\n", "I can provide all code and a table with validation and test perplexities of all tested models if that helps. I've trained >30 models with different dropout values.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Is there any update yet?", "@zotroneneis iirc, a short while ago we realized that the variational recurrent dropout was being applied to both `h` and `c` states of LSTM cells; but according to some literature, it should only be applied to the `h` state.  We made a change adjusting this, and i'm not sure if it made it into TF 1.4.  Can you try a nightly?", "@ebrevdo sorry but I don't understand what you mean with \"can you try a nightly\"\r\n", "@zotroneneis Install nightly vesrion by using `pip install tf-nightly` or `pip install tf-nightly-gpu`: https://github.com/tensorflow/tensorflow#installation", "@facaiy Sorry for the late reply. I will try that and get back to you. Thanks!\r\n", "> but according to some literature, it should only be applied to the h state\r\n\r\n @ebrevdo Would you mind sharing the reference please? Thanks!", "@zotroneneis any updates?", "@ashimb9 No, regrettably not. We are having problems to get tf-nightly to work. As soon as I get results I will post them here. \r\nRegarding the reference: it was discussed in [this post](https://github.com/tensorflow/tensorflow/issues/11650)", "@zotroneneis Ouch! that is indeed unfortunate. But please do keep us posted if something comes up. \r\nAnyway, thank you for your response and also for the reference link.", "I trained different medium models using the adapted version of the tensorflow tutorial (see original post) with tensorflow version '1.6.0-dev20180126'. It seems to be working correctly now! Thanks for the support.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 96 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 111 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 127 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 142 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 157 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@zotroneneis i'll close this for now since i think this should be fixed in recent TF builds (1.4+).  if you find otherwise; please reopen the bug."]}, {"number": 15149, "title": "BatchNorm/gamma not found in checkpoint", "body": "I trained a model with tensorflow1.4\uff0c and want to finetune in tensorflow 1.3\uff0cfollowing is part of my code:\r\n1\uff09train code with tf1.4:\r\n            with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\r\n          y, endpoints = inception_v3.inception_v3(x, CLASSES, True)\r\n2\uff09test code with master:\r\n     with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\r\n        y, end_points = inception_v3.inception_v3(x, label_dim, False)\r\n    with tf.name_scope('train'):\r\n        loss = custom_function.loss_function(y, y_)\r\n        train_op = custom_function.train_function(loss, learn_rate)\r\n        accuracy_op = custom_function.accuracy_function(y, y_)\r\n        output_result = custom_function.output_result(y)\r\n        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\r\n        saver = tf.train.Saver()\r\n        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\r\n        sess_config.gpu_options.allow_growth = True\r\n        sess = tf.Session(config=sess_config)\r\n        merged_summary = tf.summary.merge_all()\r\n        train_writer = tf.summary.FileWriter(log_dir, sess.graph)\r\n        #saver = tf.train.import_meta_graph('model_meishi/inception-v3/graph-1205-190241.meta',clear_devices=True)\r\n        sess.run(init_op)\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        #saver.restore(sess, \"model_meishi/model-6690\")\r\n        saver.restore(sess, \"model_meishi/inception-v3/model-12042\")\r\nerror is:NotFoundError (see above for traceback): Key InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma not found in checkpoint\r\nat first, i think the reason is slim.argscope is not the same in these two version tensorflow and \r\nI tried to replace the slim of tf1.4 with the slim of master\uff0cbut the error still exist.\r\nwhat's the problem of my code ?thx\r\n     \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code      yes\r\nOS Platform and Distribution    centos6.5\r\nTensorFlow installed from         anaconda\r\nTensorFlow version                    1.4 train & 1.1 test\r\nBazel version                               n/a\r\nCUDA/cuDNN version                 5.0\r\nGPU model and memory             p40\uff0c4kernels\r\nExact command to reproduce     n/a", "Closing, since this appears to be a duplicate of tensorflow/models#2977."]}, {"number": 15148, "title": "Using function defun and while loops", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: Tesla x Pascal 12gb\r\n- **Exact command to reproduce**: run defun_while.py\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nFunction.defun when used alongside a while loop is throwing shape errors.\r\n\r\nMore explicitly: when using a concatenation operation of sliced tensors with the loop variable, the newly defined op throws no errors.  However, when the slices are added to the loop variable, it throws shape errors related to the while loop. \r\n\r\nIt might be an issue with the fetch argument that fails to work in this case.\r\n\r\nThe code (along with a more detailed explanation) can be found on:\r\nhttps://stackoverflow.com/questions/47646962/tensorflow-function-defun-with-a-a-while-loop-in-the-body-is-throwing-shape-err\r\n\r\n \r\n\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@skye @alextp any idea?", "The shape of the tf.add(...) tensor returned from the body seems to be confusing / not invariant. Do instead x = tf.add(...); x.set_shape(...); return index+1, x in your body and it should work.", "@drpngx @alextp  got some updates on https://stackoverflow.com/questions/47646962/tensorflow-function-defun-with-a-a-while-loop-in-the-body-is-throwing-shape-err/47707845#47707845\r\nStill have the issue of global N though.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly."]}, {"number": 15147, "title": "summary_image_op_test_fixed_on_ppc64le", "body": "Hi @gunan , \r\nAs we discussed here https://github.com/tensorflow/tensorflow/issues/12325 , I have created this PR to fix summary_image_op_test on ppc64le.\r\n\r\nThanks!", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "Patch was manually tested before, will merge.", "Can one of the admins verify this patch?", "Thanks @gunan !!"]}, {"number": 15146, "title": "Allow keras applications to load weights from arbitrary path", "body": "This PR allows tensorflow.python.keras.applications to load pretrained weights from an arbitrary filepath (rather than only ~/.keras/models).  It is the parallel PR to https://github.com/fchollet/keras/pull/8637 which was merged by @fchollet on November 30.\r\n\r\nThis change allows useres to load models in environments with limited access to ~/.keras/models \r\n\r\nKaggle notebooks are an example of this environment, and this PR will help us support Keras in TensorFlow. \r\n\r\nI have locally tested that I get the same predictions when loading a model with `weights='imagenet'` and with `weights` pointing to another location with the same pretrained model file.\r\n", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 15145, "title": "TensorFLow build Error", "body": "\r\nwhen iam trying to retrain as per sample given in tensorflow.org\\tutorials.\r\ngiven below command \r\nbazel build tensorflow/examples/image_retraining:retrain\r\nafter that gaving below errors . any clue on this?\r\nError \r\ntensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': BUILD file not found on package path and referenced by '//third_party/py/numpy:headers'\r\n\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.\r\n\r\nAlso, make sure you follow this and install all TF dependencies \r\nhttps://www.tensorflow.org/install/install_sources\r\nbefore trying to use bazel to build any TF code", "I see the same problem with Tensorflow 1.4 and Python 3.6 (Anaconda), trying to build the CPU version.\r\n\r\nbazel build --verbose_failures --copt=-mavx --copt=-mfma --copt=-msse4.2 --copt=-msse4.1\r\n\r\nInterestingly building the GPU version with Python 3.6 works, and building the CPU/GPU version with python 2.7.11 works too."]}, {"number": 15144, "title": "Error_Converting_TliteFormat", "body": "  .....................................................## System information##........................................................................\r\n-Python -2.7.12\r\n-OS -Ubuntu 16.04\r\n-Tensorflow version-1.4.0\r\n-Bazel version-0.8.0\r\n     ......................................................##Description ###...............................................................\r\n1. I went through the following link and \r\n=>https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\r\nand successfully retrained the last layer of the model.\r\n\r\n2. Now i was trying to use that retrained.pb file and convert into.tlite format.\r\n=>https://github.com/tensorflow/tensorflow\r\n--Downloaded the tensorflow-master directory.\r\n--Install Bazel (0.8.0)\r\n--Then, using the retrained.pb file,trying to do model format conversion\r\n--Downloaded the checkpoints from \r\n=>https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\r\nBut got stucked while running the command for conversion.[bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax}\r\n\r\n\r\n\r\n.........................................................### Source code ##..........................................................................................\r\n1. \r\n(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel build -c opt --copt=-msse4.1 --copt=-msse4.2 tensorflow/python/tools:freeze_graph\r\n\r\n=>INFO: Elapsed time: 1057.269s, Critical Path: 44.92s\r\nINFO: Build completed successfully, 2109 total actions\r\n.................................................................................................................................\r\n\r\n2. But while running the below script [To convert into .tlite format] ,i was unable to resolved the following error?\r\n(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax\r\n\r\nError:::::::::::::::::::::::::::::::::::::::::\r\n```\r\nTraceback (most recent call last):\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 56, in <module>\r\n    from tensorflow.python.tools import saved_model_utils\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_utils.py\", line 21, in <module>\r\n    from tensorflow.contrib.saved_model.python.saved_model import reader\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 82, in <module>\r\n    from tensorflow.contrib.eager.python import tfe as eager\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 75, in <module>\r\n    from tensorflow.contrib.eager.python.datasets import Iterator\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in <module>\r\n    from tensorflow.contrib.data.python.ops import prefetching_ops\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in <module>\r\n    resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n  File \"/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\n\r\n=>tensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\n.........................................................................................................................\r\n```\r\nPlease let me know what does above error\r\n--(tensorflow.python.framework.errors_impl.NotFoundError: --_ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E)\r\nmeans and how to solved it.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: N/A\r\nOS Platform and Distribution: UBUNTU 16.04LTS\r\nTensorFlow installed from:  https://www.tensorflow.org/install/install_linux\r\n                                           https://www.tensorflow.org/install/install_linux#InstallingVirtualenv\r\nCUDA/cuDNN version : N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce:\r\n 1.https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\r\n( generated the new pb file from the above site)=>retranined.pb obtained\r\n2. wanted to convert .tlite format.I have followed the below link:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/README.md\r\nStep 2. Model format conversion\r\nGraph freezing can be done using the command below (and modifying the arguments appropriately)\r\n\r\nbazel build tensorflow/python/tools:freeze_graph\r\n\r\nbazel-bin/tensorflow/python/tools/freeze_graph\\\r\n    --input_graph=/tmp/retrained.pb \\\r\n    --input_checkpoint=/tmp/checkpoints/mobilenet-10202.ckpt \\\r\n    --input_binary=true \r\n       --output_graph=/tmp/frozen_mobilenet_v1_224.pb \\\r\n    --output_node_names=MobileNet/Softmax\r\n", "After running the 2nd command ,i got error as:\r\ntensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E", "Please let me know if you want any other information to solved the problem.", "I think this might be a protobuf version problem. protobuf 3.5.0.post1 works fine.", "Please someone guide me how can i convert my retrained model (.pb file) into .tflite format so that i can run on the  android device.", "Are you able to run the network correctly without freeze graph? Can you use `nm` on the tensorflow shared object and see which one is defined? Did you try the protobuf as suggested by @euntaik ?", "Hi,\r\nyes,its running correctly without freeze graph.\r\n-> protoc --version\r\nlibprotoc 2.6.1\r\n I am trying now with protobuf 3.5.0 version and shall update the same.\r\n\r\n", "Actually,my current version of protobuf: 3.0.0 ,so i was trying to install 3.5.0 version but got the following error:\r\n\r\nroot@pcz-ee210201:/u/protobuf-master/python# pip install protobu\r\nCollecting protobu\r\n  Could not find a version that satisfies the requirement protobu (from versions: )\r\nNo matching distribution found for protobu\r\n", "->I have downloaded the protobuf 3.5.0 from the below link :\r\nhttps://github.com/google/protobuf/releases\r\n\r\n->and followed the following steps to install from\r\nhttps://github.com/google/protobuf/tree/master/python\r\n->Then i tried to run the below cmd:\r\nroot@pcz-ee210201:/u/tensorflow-master#  bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb --output_node_names=Softmax\r\n\r\n-> But getting the same error:\r\ntensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\nIs my approach is alright?", "I have installed  protobuf-3.5.0:\r\n  /usr/local/lib/python2.7/dist-packages/protobuf-3.5.0-py2.7.egg\r\nBut still its showing the same error.Please guide me in order to resolved this.\r\n", "Please suggest me what should i try to resolved the issue.", "I have same problem. No updates?", "I am unable to resolve the issue.", "We started seeing the same error in TensorFlow Serving at around the same time when running an example client - https://github.com/tensorflow/serving/issues/684\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: /tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\n```\r\n\r\nAny ideas?", "Sorry,i don't have any idea.", "I am following the below steps from [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite] and obtained the retrrained.pb file by retraining the model(tensorflow for poets) and now wanted to convert .pb to .tlite format so that i can used in android phone.\r\n\r\nStep 2. Model format conversion:\r\nFreeze Graph\r\n\r\nTo use this .pb GraphDef file within TensorFlow Lite, the application developer will need checkpoints containing trained weight parameters. The .pb contains only the structure of the graph. The process of merging the checkpoint values with the graph structure is known as \"freezing\" the graph.\r\n\r\nThe developer should know where the checkpoints folder is present or checkpoints can also be downloaded for a pre-trained model (Example: Here is a link to the MobileNets).\r\n\r\nGraph freezing can be done using the command below (and modifying the arguments appropriately)\r\n\r\nbazel build tensorflow/python/tools:freeze_graph\r\n\r\nbazel-bin/tensorflow/python/tools/freeze_graph\\\r\n    --input_graph=/tmp/mobilenet_v1_224.pb \\\r\n    --input_checkpoint=/tmp/checkpoints/mobilenet-10202.ckpt \\\r\n    --input_binary=true --output_graph=/tmp/frozen_mobilenet_v1_224.pb \\\r\n    --output_node_names=MobileNet/Predictions/Reshape_1\r\n\r\n\r\n", "About the link error of  tensorflow/serving#684 ,\r\nI fixed adding deps on BUILD file under \"./tensorflow/tensorflow/contrib/data/\" as below.\r\n\r\n\r\n\r\n 28 tf_custom_op_library(\r\n 29     name = \"_prefetching_ops.so\",\r\n 30     srcs = [\"ops/prefetching_ops.cc\"],\r\n 31     deps = [\r\n 32             \"//tensorflow/contrib/data/kernels:prefetching_kernels\",\r\n 33             \"@protobuf_archive//:protobuf\",\r\n 34     ],\r\n 35 )\r\n\r\n\r\nBut it makes core dump...\r\n\r\n\r\n\r\nTraining model...\r\nExtracting /tmp/train-images-idx3-ubyte.gz\r\nExtracting /tmp/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/t10k-labels-idx1-ubyte.gz\r\n2017-12-20 15:40:15.177713: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-20 15:40:15.584699: F external/org_tensorflow/tensorflow/core/framework/op.cc:54] Non-OK-status: RegisterAlreadyLocked(op_data_factory) status: Already exists: Op with name _Arg\r\n (core dumped)\r\n\r\n", "Get the same error running a query client\r\n\r\nroot@ubuntu:~/tools/tensorflow-serving$ bazel-bin/tensorflow_serving/example/inception_client --server=localhost:9000 --image=/root/data/flower_photos/roses/5529341024_0c35f2657d.jpg\r\n`Traceback (most recent call last):\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 56, in <module>\r\n    tf.app.run()\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 50, in main\r\n    tf.contrib.util.make_tensor_proto(data, shape=[1]))\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\r\n    module = self._load()\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 42, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/usr/lib64/python2.7/importlib/__init__.py\", line 37, in import_module\r\n    __import__(name)\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 82, in <module>\r\n    from tensorflow.contrib.eager.python import tfe as eager\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 75, in <module>\r\n    from tensorflow.contrib.eager.python.datasets import Iterator\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in <module>\r\n    from tensorflow.contrib.data.python.ops import prefetching_ops\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in <module>\r\n    resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n  File \"/root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /root/tools/tensorflow-serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringE`", "Same here, on ubuntu 16.04.\r\ncompiled with:\r\nbazel build -c opt --copt=-msse4.1 --copt=-msse4.2 tensorflow/python/tools:freeze_graph\r\nfrom [here](https://github.com/tensorflow/tensorflow/issues/14610) ", "I have the same issue. It seems this issue _may have been_ introduced after this commit (https://github.com/tensorflow/tensorflow/commit/cd81bc8e09c7f551911276c5bfaafa6930f1961f). \r\n  ", "@manjunaths Got the same issue, have you solved it using the commit u mentioned? Thx!", "@fengdragon In my specific case that problem disappeared, but I am getting a segfault. I do not know if the segfault is because of the change or some other new issue that I have.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I had this issue with Tensorflow 1.5, but everything seems to be working fine as of 1.6-rc. Both versions were compiled from sources", "I have tried on both r1.5 and r1.6 and I am getting the same error when trying to run my client.  I tried to build r1.4 but was dealing with a number of bazel related issues that had answers online aligned with upgrading to the newer versions of TF. Going to try running my model in docker to see if I have any better luck.\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/tf_serving/tensorflow_serving/example/sentiment_client.py\", line 107, in <module>\r\n>     tf.app.run()\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 126, in run\r\n>     _sys.exit(main(argv))\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/tf_serving/tensorflow_serving/example/sentiment_client.py\", line 97, in main\r\n>     tf.contrib.util.make_tensor_proto(tf.convert_to_tensor(\"This is awesome\"), shape=[1]))\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\r\n>     module = self._load()\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 42, in _load\r\n>     module = importlib.import_module(self.__name__)\r\n>   File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\r\n>     __import__(name)\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 84, in <module>\r\n>     from tensorflow.contrib.eager.python import tfe as eager\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 78, in <module>\r\n>     from tensorflow.contrib.eager.python.datasets import Iterator\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in <module>\r\n>     from tensorflow.contrib.data.python.ops import prefetching_ops\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in <module>\r\n>     resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n>     ret = load_library.load_op_library(path)\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n>     lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n>   File \"/media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n>     c_api.TF_GetCode(self.status.status))\r\n> tensorflow.python.framework.errors_impl.NotFoundError: /media/daniel/Data/serving/bazel-bin/tensorflow_serving/example/sentiment_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal9ArenaImpl10AddCleanupEPvPFvS3_E", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@himsikha123 Have you got the solution? I have the same error. I'll very appreciate your help ", "I had this issue because I installed \"libtensorflow_framework.so\" in my system. Removing this library out of \"/usr/local/lib\" solved this problem for me."]}, {"number": 15143, "title": "tensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 15142, "title": "Tensorflow (current master) build failure due to cuda/cudnn?", "body": "I would like to try out `tf.contrib.framework.sort()`, which available on current master only.\r\n\r\nTried to build master but failed due to cuda/cudnn library cannot found by bazel. However, I verified these library are exist at `/usr/local/cuda/lib64`.\r\n\r\n```\r\nERROR: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/lite/toco/BUILD:330:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1)\r\n/usr/bin/ld: warning: libcublas.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n```\r\n\r\nSystem Environment:\r\nUbuntu 16.04, cuda8.0, cudnn6.0, gcc-5\r\n\r\nBuild Steps:\r\n```\r\n# checkout master\r\n$ git clone https://github.com/tensorflow/tensorflow \r\n$ cd tensorflow\r\n$ git checkout master\r\n\r\n# python dependencies\r\n$ sudo apt-get install python-numpy python-dev python-pip python-wheel\r\n$ sudo apt-get install libcupti-dev \r\n\r\n# gcc-5\r\n$ bazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nCheck cuda/cudnn\r\n```\r\n$ ls -alhF /usr/local/cuda/lib64\r\n\r\ntotal 1.4G\r\ndrwxr-xr-x  3 root root  4.0K Nov 28 18:21 ./\r\ndrwxr-xr-x 17 root root  4.0K Nov 28 16:38 ../\r\n-rw-r--r--  1 root root   51M Nov 28 16:37 libcublas_device.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libcublas.so -> libcublas.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libcublas.so.8.0 -> libcublas.so.8.0.61*\r\n-rwxr-xr-x  1 root root   41M Nov 28 16:37 libcublas.so.8.0.61*\r\n-rw-r--r--  1 root root   47M Nov 28 16:37 libcublas_static.a\r\n-rw-r--r--  1 root root  543K Nov 28 16:37 libcudadevrt.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libcudart.so -> libcudart.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libcudart.so.8.0 -> libcudart.so.8.0.61*\r\n-rwxr-xr-x  1 root root  406K Nov 28 16:37 libcudart.so.8.0.61*\r\n-rw-r--r--  1 root root  757K Nov 28 16:37 libcudart_static.a\r\nlrwxrwxrwx  1 root root    13 Nov 28 18:21 libcudnn.so -> libcudnn.so.6*\r\nlrwxrwxrwx  1 root root    18 Nov 28 18:21 libcudnn.so.6 -> libcudnn.so.6.0.21*\r\n-rwxr-xr-x  1 root root  148M Nov 28 18:19 libcudnn.so.6.0.21*\r\n-rw-r--r--  1 root root  138M Nov 28 18:19 libcudnn_static.a\r\nlrwxrwxrwx  1 root root    15 Nov 28 16:37 libcufft.so -> libcufft.so.8.0*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libcufft.so.8.0 -> libcufft.so.8.0.61*\r\n-rwxr-xr-x  1 root root  140M Nov 28 16:37 libcufft.so.8.0.61*\r\n-rw-r--r--  1 root root  124M Nov 28 16:37 libcufft_static.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libcufftw.so -> libcufftw.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libcufftw.so.8.0 -> libcufftw.so.8.0.61*\r\n-rwxr-xr-x  1 root root  466K Nov 28 16:37 libcufftw.so.8.0.61*\r\n-rw-r--r--  1 root root   42K Nov 28 16:37 libcufftw_static.a\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libcuinj64.so -> libcuinj64.so.8.0*\r\nlrwxrwxrwx  1 root root    20 Nov 28 16:37 libcuinj64.so.8.0 -> libcuinj64.so.8.0.61*\r\n-rwxr-xr-x  1 root root  6.2M Nov 28 16:37 libcuinj64.so.8.0.61*\r\n-rw-r--r--  1 root root  1.6M Nov 28 16:37 libculibos.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libcurand.so -> libcurand.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libcurand.so.8.0 -> libcurand.so.8.0.61*\r\n-rwxr-xr-x  1 root root   57M Nov 28 16:37 libcurand.so.8.0.61*\r\n-rw-r--r--  1 root root   57M Nov 28 16:37 libcurand_static.a\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libcusolver.so -> libcusolver.so.8.0*\r\nlrwxrwxrwx  1 root root    21 Nov 28 16:37 libcusolver.so.8.0 -> libcusolver.so.8.0.61*\r\n-rwxr-xr-x  1 root root   52M Nov 28 16:37 libcusolver.so.8.0.61*\r\n-rw-r--r--  1 root root   22M Nov 28 16:37 libcusolver_static.a\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libcusparse.so -> libcusparse.so.8.0*\r\nlrwxrwxrwx  1 root root    21 Nov 28 16:37 libcusparse.so.8.0 -> libcusparse.so.8.0.61*\r\n-rwxr-xr-x  1 root root   42M Nov 28 16:37 libcusparse.so.8.0.61*\r\n-rw-r--r--  1 root root   50M Nov 28 16:37 libcusparse_static.a\r\nlrwxrwxrwx  1 root root    14 Nov 28 16:37 libnppc.so -> libnppc.so.8.0*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppc.so.8.0 -> libnppc.so.8.0.61*\r\n-rwxr-xr-x  1 root root  446K Nov 28 16:37 libnppc.so.8.0.61*\r\n-rw-r--r--  1 root root   24K Nov 28 16:37 libnppc_static.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppial.so -> libnppial.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppial.so.8.0 -> libnppial.so.8.0.61*\r\n-rwxr-xr-x  1 root root  9.7M Nov 28 16:37 libnppial.so.8.0.61*\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppicc.so -> libnppicc.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppicc.so.8.0 -> libnppicc.so.8.0.61*\r\n-rwxr-xr-x  1 root root  3.7M Nov 28 16:37 libnppicc.so.8.0.61*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppicom.so -> libnppicom.so.8.0*\r\nlrwxrwxrwx  1 root root    20 Nov 28 16:37 libnppicom.so.8.0 -> libnppicom.so.8.0.61*\r\n-rwxr-xr-x  1 root root 1007K Nov 28 16:37 libnppicom.so.8.0.61*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppidei.so -> libnppidei.so.8.0*\r\nlrwxrwxrwx  1 root root    20 Nov 28 16:37 libnppidei.so.8.0 -> libnppidei.so.8.0.61*\r\n-rwxr-xr-x  1 root root  6.8M Nov 28 16:37 libnppidei.so.8.0.61*\r\nlrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppif.so -> libnppif.so.8.0*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppif.so.8.0 -> libnppif.so.8.0.61*\r\n-rwxr-xr-x  1 root root   46M Nov 28 16:37 libnppif.so.8.0.61*\r\nlrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppig.so -> libnppig.so.8.0*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppig.so.8.0 -> libnppig.so.8.0.61*\r\n-rwxr-xr-x  1 root root   21M Nov 28 16:37 libnppig.so.8.0.61*\r\nlrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppim.so -> libnppim.so.8.0*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppim.so.8.0 -> libnppim.so.8.0.61*\r\n-rwxr-xr-x  1 root root  4.2M Nov 28 16:37 libnppim.so.8.0.61*\r\nlrwxrwxrwx  1 root root    14 Nov 28 16:37 libnppi.so -> libnppi.so.8.0*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppi.so.8.0 -> libnppi.so.8.0.61*\r\n-rwxr-xr-x  1 root root  104M Nov 28 16:37 libnppi.so.8.0.61*\r\n-rw-r--r--  1 root root  131M Nov 28 16:37 libnppi_static.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppist.so -> libnppist.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppist.so.8.0 -> libnppist.so.8.0.61*\r\n-rwxr-xr-x  1 root root   14M Nov 28 16:37 libnppist.so.8.0.61*\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppisu.so -> libnppisu.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppisu.so.8.0 -> libnppisu.so.8.0.61*\r\n-rwxr-xr-x  1 root root  438K Nov 28 16:37 libnppisu.so.8.0.61*\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppitc.so -> libnppitc.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppitc.so.8.0 -> libnppitc.so.8.0.61*\r\n-rwxr-xr-x  1 root root  2.8M Nov 28 16:37 libnppitc.so.8.0.61*\r\nlrwxrwxrwx  1 root root    14 Nov 28 16:37 libnpps.so -> libnpps.so.8.0*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnpps.so.8.0 -> libnpps.so.8.0.61*\r\n-rwxr-xr-x  1 root root  7.8M Nov 28 16:37 libnpps.so.8.0.61*\r\n-rw-r--r--  1 root root   11M Nov 28 16:37 libnpps_static.a\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libnvblas.so -> libnvblas.so.8.0*\r\nlrwxrwxrwx  1 root root    19 Nov 28 16:37 libnvblas.so.8.0 -> libnvblas.so.8.0.61*\r\n-rwxr-xr-x  1 root root  487K Nov 28 16:37 libnvblas.so.8.0.61*\r\nlrwxrwxrwx  1 root root    17 Nov 28 16:37 libnvgraph.so -> libnvgraph.so.8.0*\r\nlrwxrwxrwx  1 root root    20 Nov 28 16:37 libnvgraph.so.8.0 -> libnvgraph.so.8.0.61*\r\n-rwxr-xr-x  1 root root  5.0M Nov 28 16:37 libnvgraph.so.8.0.61*\r\n-rw-r--r--  1 root root  7.8M Nov 28 16:37 libnvgraph_static.a\r\nlrwxrwxrwx  1 root root    24 Nov 28 16:37 libnvrtc-builtins.so -> libnvrtc-builtins.so.8.0*\r\nlrwxrwxrwx  1 root root    27 Nov 28 16:37 libnvrtc-builtins.so.8.0 -> libnvrtc-builtins.so.8.0.61*\r\n-rwxr-xr-x  1 root root  9.3M Nov 28 16:37 libnvrtc-builtins.so.8.0.61*\r\nlrwxrwxrwx  1 root root    15 Nov 28 16:37 libnvrtc.so -> libnvrtc.so.8.0*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libnvrtc.so.8.0 -> libnvrtc.so.8.0.61*\r\n-rwxr-xr-x  1 root root   18M Nov 28 16:37 libnvrtc.so.8.0.61*\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libnvToolsExt.so -> libnvToolsExt.so.1*\r\nlrwxrwxrwx  1 root root    22 Nov 28 16:37 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0*\r\n-rwxr-xr-x  1 root root   37K Nov 28 16:37 libnvToolsExt.so.1.0.0*\r\nlrwxrwxrwx  1 root root    14 Nov 28 16:37 libOpenCL.so -> libOpenCL.so.1\r\nlrwxrwxrwx  1 root root    16 Nov 28 16:37 libOpenCL.so.1 -> libOpenCL.so.1.0\r\nlrwxrwxrwx  1 root root    18 Nov 28 16:37 libOpenCL.so.1.0 -> libOpenCL.so.1.0.0\r\n-rw-r--r--  1 root root   26K Nov 28 16:37 libOpenCL.so.1.0.0\r\ndrwxr-xr-x  2 root root  4.0K Nov 28 16:37 stubs/\r\n```\r\n\r\nVerbose Failure:\r\n```\r\n$ bazel build --verbose_failures  --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: /srv/yg/researches/gits/tensorflow/tensorflow/core/BUILD:1806:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /srv/yg/researches/gits/tensorflow/tensorflow/tensorflow.bzl:1100:30\r\nWARNING: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (2 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/lite/toco/BUILD:330:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/<usr>/.cache/bazel/_bazel_<usr>/eac5d1dca31d986f2b063251871502de/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/home/<usr>/anaconda2/envs/ygtf/lib/python2.7/site-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=3.7,3.7 \\\r\n    TF_CUDA_VERSION=8.0 \\\r\n    TF_CUDNN_VERSION=6 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/local_linux-opt/bin/tensorflow/contrib/lite/toco/toco '-Wl,-rpath,$ORIGIN/../../../../_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow' '-Wl,-rpath,$ORIGIN/../../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' -Lbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../..' -pthread -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/contrib/lite/toco/toco-2.params)\r\n/usr/bin/ld: warning: libcublas.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcudnn.so.6, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcufft.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libcurand.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetLRNDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan2d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyrk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerMatrixParams'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardAlgorithm'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCaxpy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterWorkspaceSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemmBatched'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamax_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlanMany'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyr2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateConvolutionDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyConvolutionDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensorNdDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecD2Z'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetFilterNdDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetStream_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotmg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetPointerMode_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan1d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDswap_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgeru_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsymm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionForward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSswap_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemmBatched'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdForwardOutputDim'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCherk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan2d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerBiasParams'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelBackward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCrotg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniform'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingBackward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZaxpy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionNdDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateTensorDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyDropoutDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardInference'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardData'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDdot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateDropoutDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniformDouble'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2Z'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyFilterDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardInference'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSnrm2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamin_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgerc_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPoolingNdDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgerc_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZswap_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftDestroy'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyTensorDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNParamsSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDaxpy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetPointerMode_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateLRNDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandCreateGenerator'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyRNNDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotc_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZrotg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScopy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyr2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetAutoAllocation'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZcopy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnAddTensor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPoolingDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetFilterNdDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotmg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnActivationForward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDger_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNWorkspaceSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetVersion'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotc_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingForward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftCreate'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardWeights'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNTrainingReserveSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetPseudoRandomGeneratorSeed'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSdot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2R'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemmBatched'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCswap_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScnrm2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateRNNDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDnrm2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDropoutGetStatesSize'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandDestroyGenerator'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardBias'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationBackward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGemmEx'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDcopy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterAlgorithm'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2C'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDestroy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamin_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsrot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyrk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormalDouble'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmEx'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateFilterDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetActivationDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDzasum_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnTransformTensor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecR2C'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDasum_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardFilter'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetStream'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelForward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2k_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyLRNDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCcopy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotu_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardData'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNDescriptor_v6'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamin_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetStream'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateActivationDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetGeneratorOffset'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBiasActivationForward'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyrk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSaxpy_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamax_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotg_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensor4dDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZherk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroy'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan3d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetWorkArea'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyActivationDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan1d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardTraining'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetDropoutDescriptor'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate'\r\nbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1.557s, Critical Path: 0.36s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n", "comments": ["Workaround with tf-nightly-gpu. Thanks.", "Hi,\r\n\r\nI'm having the same issue. I can't find a branch under that name. How were you able to fix the issue?\r\n\r\nThank you,", "@frankgh it's a pip package, see https://github.com/tensorflow/tensorflow#installation", "Adding `--action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"` to `bazel build` fixed my issue.\r\n\r\nSolution was found here: https://stackoverflow.com/questions/47080760/tensorflow-fails-to-compile/47295278#47295278", "had the same issue, solution from @frankgh  works!", "The solution from @frankchn resolved the same issue. Thanks!!!\r\n\r\nMy system:\r\nRELEASE=18.3\r\nCODENAME=sylvia\r\nEDITION=\"Cinnamon 64-bit\"\r\nDESCRIPTION=\"Linux Mint 18.3 Sylvia\"\r\nDESKTOP=Gnome\r\nTOOLKIT=GTK\r\nGRUB_TITLE=Linux Mint 18.3 Cinnamon 64-bit\r\n\r\nGPU:\r\ndescription: 3D controller\r\nproduct: GK106M [GeForce GTX 765M]\r\nvendor: NVIDIA Corporation\r\nphysical id: 0\r\n\r\nNvidia Driver:\r\n384.111\r\n\r\nCUDA:\r\ncuda_8.0.61_375.26_linux.run\r\n\r\ncuDNN\r\ncudnn-8.0-linux-x64-v7.tgz\r\n\r\nTensorFlow branch\r\norigin/master\r\nSHA1 ID: a77096897f1a8068ca8f57ffb6e3d9e28508cc27", "The solution from @frankchn resolved the initial issue, however, there is another one followed.\r\n\r\nI checked and I am sure that libcudnn.so.7 is in LD_LIBRARY_PATH.\r\n\r\n```\r\nERROR: /data/users/zhuangzr/tools/tensorflow/tensorflow/contrib/boosted_trees/BUILD:426:1: Linking of rule '//tensorflow/contrib/boosted_trees:gen_gen_training_ops_py_py_wrappers_cc' failed (Exit 1)\r\n/usr/bin/ld: warning: libcudnn.so.7, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNParamsSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnActivationForward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensor4dDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardWeights'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionNdDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateFilterDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyFilterDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroy'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyDropoutDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetDropoutDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnAddTensor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardInference'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetFilterNdDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateTensorDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetLRNDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerBiasParams'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNTrainingReserveSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyTensorDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardTraining'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyRNNDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdForwardOutputDim'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelForward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPoolingDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNWorkspaceSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNDescriptor_v6'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationBackward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerMatrixParams'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardBias'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateConvolutionDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetFilterNdDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetVersion'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterAlgorithm'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetStream'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPoolingNdDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingBackward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardAlgorithm'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelBackward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyActivationDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterWorkspaceSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetActivationDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardInference'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionForward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBiasActivationForward'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateDropoutDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateLRNDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnTransformTensor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardFilter'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardData'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyLRNDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDropoutGetStatesSize'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensorNdDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardData'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateActivationDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyConvolutionDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateRNNDescriptor'\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingForward'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 223.731s, Critical Path: 171.49s\r\nFAILED: Build did NOT complete successfully\r\n```", "this is still broken. I had run into the same issue with building tf 1.8 from source on redhat 6.7\r\nI am using cudnn 7 and cuda toolkit 9.2 . \r\nsee my solutions below. ", "Same on latest 1.8, building from source on Ubuntu 18.04 with cudnn 7.1, cuda 9.2.", "I had resolved  this after a week of research by modifying links of cudnn\r\nI had installed cudnn at the same folder as cuda toolkit but I had to run ldconfig tool for the folder and all the libraries to be added to system linker path. when I had ldconfig it had complained about cudnn libs. apparently cudnn installs 3 libraries. what you want is to keep the latest library cudnn.so.major.minor version and have the cudnn.so to point to cudnn.so.major.minor. \r\nthis resolved the compilation issue. \r\nalso tensorflow requires latest protobuf so make sure to install that using pip or condo-forge", "here is more detailed descriptions of the steps I had madeafter cuDNN unzip one needs to copy *.h files to /usr/local/cuda/include and *.so and *.a from lib64 folder to /usr/local/cuda/lib64\r\nafter the copy make sure to set cudnn libs as follows\r\nlrwxrwxrwx. 1 root root        17 May 22 15:26 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.7.1.4\r\nlrwxrwxrwx. 1 root root        17 May 22 15:26 /usr/local/cuda/lib64/libcudnn.so.7 -> libcudnn.so.7.1.4\r\n-rwxr-xr-x. 1 root root 339920048 May 19 20:00 /usr/local/cuda/lib64/libcudnn.so.7.1.4\r\n-rw-r--r--. 1 root root 331122430 May 19 20:00 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\nif this is not setup tensorflow compilation will fail later with unresolved symbols in cudnn. \r\nalso after symbolic links are setup  make sure to run ldconfig as root.", "@gyang274 is there an  integration test for tensorflow, which  installs latest cuda cudnn automatically from Nvidia and tries to compile TF 1.8 with it? if so it would have failed on any linux platform without cudnn steps I had outlined above. ", "Thanks @petacube for your explenation I'll give it a try tomorrow. For other desperate souls: downgrading to tf 1.7 (on ubuntu 18.04) does not work because of problems with the new gcc.", "It works now, I did not need to execute any of your steps @petacube , I have no clue what solved it to be honest. I just did a clean install with latest cuda 9.2 (with run file) and cudnn 7.1", "I've solved it with:\r\n```\r\nsudo touch /etc/ld.so.conf.d/cuda.conf\r\nsudo nano /etc/ld.so.conf.d/cuda.conf\r\n```\r\nAfter edit the file :\r\n`/usr/local/cuda/lib64`\r\n\r\nSave the changes :\r\n`sudo ldconfig`\r\n\r\nCF : https://stackoverflow.com/questions/13428910/how-to-set-the-environmental-variable-ld-library-path-in-linux.", "For those who cannot modify ld.so.conf directly, I was able to work around this problem by modifying the CROSSTOOL.tpl file.  I added -L and -Wl,-rpath flags to point to my cuDNN install path in the link steps:\r\n\r\nin the \"local_linux\" toolchain section of tensorflow-1.13.1/third_party/gpus/crosstool/CROSSTOOL.tpl:\r\n```\r\ntoolchain {\r\n  abi_version: \"local\"\r\n  abi_libc_version: \"local\"\r\n  compiler: \"compiler\"\r\n  host_system_name: \"local\"\r\n  needsPic: true\r\n  target_libc: \"local\"\r\n  target_cpu: \"local\"\r\n  target_system_name: \"local\"\r\n  toolchain_identifier: \"local_linux\"\r\n\r\n< ... snip ... >\r\n\r\n  feature {\r\n    name: \"linker-bin-path\"\r\n\r\n    flag_set {\r\n      action: \"c++-link-executable\"\r\n      action: \"c++-link-dynamic-library\"\r\n      action: \"c++-link-nodeps-dynamic-library\"\r\n      flag_group {\r\n        %{linker_bin_path_flag}\r\n# >>>> add flags here >>>>\r\n        flag: \"-L/path/to/cudnn/install/lib64\"\r\n        flag: \"-Wl,-rpath,/path/to/cudnn/install/lib64\"\r\n# <<<<<<<<<<<<<<<<\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nFor good measure, I also added -L and -Wl,-rpath flags to tensorflow-1.13.1/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl:\r\n```\r\n  cmd = (NVCC_PATH + ' ' + nvccopts +\r\n         ' --compiler-options \"' + host_compiler_options + ' -fPIC\"' +\r\n         ' --compiler-bindir=' + GCC_HOST_COMPILER_PATH +\r\n         ' -I .' +\r\n         ' -x cu ' + opt + includes + ' -c ' + srcs + out + ' --linker-options \"-L/path/to/cudnn/install/lib64 -Wl,-rpath,/path/to/cudnn/install/lib64\" ')\r\n```\r\n\r\nHowever, the CROSSTOOL patch may have been sufficient."]}, {"number": 15141, "title": "MKL: Revving mkl-dnn to include all changes before 2017-11-20.", "body": "This commit will pull the latest changes from the mkl-dnn tree.\r\n\r\n@jart the mirror.bazel.build URL doesn't exist: \"https://mirror.bazel.build/github.com/01org/mkl-dnn/archive/aab753280e83137ba955f8f19d72cb6aaba545ef.tar.gz\" can you create it?", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 15140, "title": "CUDA 9.1 planning ticket", "body": "**Update 05-FEB-2018**\r\nThe plan of record is to stick with CUDA 9.x until CUDA 10.  That plan has an issue in that CUDA 9 and 9.1 cause problems with XLA that should be resolved with CUDA 9.2.  The soft plan is we would move to 9.2 when it comes out if it resolves the issues with XLA.  \r\n\r\n**Update 23-JAN-2018**\r\nCUDA 9.1 requires an upgrade to device driver 387 (CUDA 9 was 384).  Moving device drivers is painful for production environments.  We are not going to move the default builds to CUDA 9.1 or 9.2 we will stick with CUDA 9 likely until CUDA 10.  We will move cuDNN forward which will have a larger impact and not require device drive upgrades.  This space is developing as everyone involved evolves their processes and learns from the past.  \r\n\r\nWhile I cannot promise anything, I do want to create a \"channel\" where we are building and testing the latest CUDA 9.x so we can track performance improvements and have some avenue for people to get those builds.  The testing infrastructure is large and maintaining this has a cost.  I hope to find a middle ground as I like perf testing the latest libraries.  \r\n\r\n**Original Message**\r\nThe purpose of this thread is to keep CUDA 9.1 questions related to when it will be in TensorFlow in a single area.  Separate issues are fine.  I will try to keep this first comment updated with information as it comes out.  \r\n\r\n**Current Status:**  Unknown, waiting for RC and gathering information to formulate a plan.  \r\n\r\np.s. There is a tendency to treat TensorFlow like a one way product.  I want to continue to change that with this type of dialog and transparency.  Many people outside Google will contribute to CUDA 9.1 support for TensorFlow.  ", "comments": ["Is cuda 9.1 an upcoming release? I can only download cuda_9.0.176 from the nvidia dev portal. Will this version be supported in the RC too?", "CUDA 9.1 has been released.\r\n\r\nSome hpp headers have been removed, namely math_functions.hpp which is included by Eigen/Core.\r\n\r\nNoting that math_functions.h just diverts to crt/math_functions.h, I tried the same with the hpp version. I put this into /usr/local/cuda/math_functions.hpp.\r\n```\r\n#include \"crt/math_functions.hpp\"\r\n```\r\n\r\nCompilation and a basic test of 1.4.0 worked. Didn't run the bazel tests.", "CUDA 9.1 will require driver 387+.  This means enterprises have to upgrade their fleets.  I have not looked at a timeline for 9.1.  It should work in source (someone internally was using it the other day but I did not ask how or even with TensorFlow directly) now but maybe not using all the latest optimized features that were added.  We will likely not look to closely until Jan.  Once I get things together I will try to publish a very unofficial timeline.  If anyone has verified it works (even just with CUDA 9 level perf) at head let me know.  I am too busy to try right now.", "Running https://github.com/tensorflow/benchmarks/commit/0f0492dd5590549e1ce7d1d91bf5c88794f95f69 (a few commits after this introduces an operation from master that isn't in 1.4).\r\n\r\n```\r\npython tf_cnn_benchmarks.py --num_gpus=4 --batch_size=64 --model=inception3 --variable_update=parameter_server --local_parameter_device=cpu\r\n```\r\n\r\nMachine is 4x Titan V with driver 387.34. Both versions are Tensorflow 1.4.1.\r\n\r\n| GPUs | CUDA 9.0.176 + cuDNN 7.0.5 | CUDA 9.1.85 + cuDNN 7.0.5 |\r\n| :---: | :---: | :---: |\r\n| 1 | 191.56 images/sec | 191.59 images/sec |\r\n| 4 | 727.90 images/sec | 738.54 images/sec |\r\n\r\nI only ran these once, so I'm not sure that the increased 4 GPU performance is significant. I can run it on imagenet data if you'd like to see that, as well.\r\n\r\n", "copy /usr/local/cuda/include/math_functions.h to /usr/local/include/math_functions.hpp, and it works.\r\n```bash\r\nsudo cp /usr/local/cuda/include/math_functions.h /usr/local/cuda/include/math_functions.hpp\r\n```", "@gdshen : That's a bit dangerous, because you might end up with an outdated copy on next cuda-update, if you forget about that second copy.\r\n@sclarkson 's approach is somewhat safer. This is anyway most probably a CUDA-9.1 issue.\r\n", "@domschl A soft copy may be safer. \r\nIt would be more elegant to put header file in /usr/local/cuda/include, not in /usr/local/cuda", "cd /usr/local/cuda/include\r\n\r\nThere are two solutions:\r\n(A)\r\nsudo ln -s math_functions.h math_functions.hpp\r\n\r\n(B)\r\nsudo ln  -s  /usr/local/cuda/include/crt/math_functions.hpp math_functions.hpp \r\n\r\n(C)  As svenstaro suggested:\r\n\r\nbazel build  --config=opt --config=cuda  --cxxopt=\"-I/opt/cuda/include/crt\"    //tensorflow/tools/pip_package:build_pip_package\r\n\r\n choice(B) : Build completed successfully\r\n\r\nBut,  choice (C) is much better than (A) and (B)\r\n(C) also build completed successfully.\r\n\r\n\r\n", "@sclarkson   You made me jealous.  I do not have a good way to have 4 Titan Vs but I ordered two for the t team so we could help ensure things are working when the community has issues.  Things will slow down for the holidays but we have discussed 9.1 and the team desires to roll it out fast in Q1 as well as finish up the CUDA 9 upgrade.    ", "A better way to make this compile in the meantime is to just add the cuda crt include path to the cxxopts as I have done in the Arch Linux package: https://git.archlinux.org/svntogit/community.git/commit/trunk/PKGBUILD?h=packages/tensorflow&id=530561e9e6bac127d1091f206f6214c967072833", "Hi, I built the tensorflow 1.4.1 sauce code on cuda9.1, but I got the error message like this:\r\n`ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n`\r\ncan anybody help?", "Tensorflow 1.5 rc  is built  under cuda 9.1 and cudnn 7.0.5 under python 3.5  successfully.\r\n\r\nI highly recommend arunmandal53's tutorial. \"step by step installation of tensorflow with cuda 9.1 and cudnn7.05 on ubuntu\". http://www.python36.com/install-tensorflow141-gpu/", "Using Plan(C) , \r\n```\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda --incompatible_load_argument_is_label=false --cxxopt=\"-I/usr/local/cuda/include/crt\" -k //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nthe compiling complains:\r\n```\r\nERROR: /home/vimos/Downloads/tensorflow-1.4.1/tensorflow/contrib/resampler/BUILD:45:1: Couldn't build file tensorflow/contrib/resampler/_objs/python/ops/_resampler_ops_gpu/tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.pic.o: undeclared inclusion(s) in rule '//tensorflow/contrib/resampler:python/ops/_resampler_ops_gpu':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/contrib/resampler/kernels/resampler_ops_gpu.cu.cc':\r\n  '/usr/local/cuda/include/crt/math_functions.hpp'\r\n  '/usr/local/cuda/include/crt/host_defines.h'\r\n\r\n```", "Just wondering if anyone managed to build CUDA9.1 with tensorflow on windows 10 ? Thanks", "Yes. I have built it. just testing it. Tensorflow gpu with cuda 9.1 and cudnn 7.0.5. I have built it with bazel and cmake. But using cmake is recommended by contributers.", "Finally created a working tutorial for building Tensorflow 1.5.0 on windows with cuda 9.1 and cudnn 7.0.5 using cmake and visual studio 2015 update 3. I have tested and worked. Please comment if it worked for you too. Here is the link for blog http://www.python36.com/install-tensorflow-gpu-windows", "Got Tensorflow 1.5.0 working for Linux Mint 18.3, CUDA 9.1 and cuDNN 7.0.5, built from source.\r\nMake sure to append `--action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\"` to the build command  in case the build fails while linking :)", "I followed the instructions verbatim and I get this - After 11hrs and 18 mins of build. \r\n![tensorflow_build_source_errors](https://user-images.githubusercontent.com/2142626/35197294-0e94ab78-fe92-11e7-9d8e-83fbc32e8b99.png)\r\n", "arunmandal53c can you update this http://www.python36.com/install-tensorflow-gpu-windows to include bazel too \r\nanother Q what can I did to solve kernel update issue in Ubuntu 16.04.3 with cuda 9.1 ,, do I have to keep using my old kernel or there is a workaround for that", "@rolla12 Using cmake is more stable than bazel on windows. I will update the tutorial if issues in bazel build fixed for windows. Using Network installer of cuda 9.1 toolkit update your driver to latest version which may have compatibility with latest linux kernel. If you have issue to load nvidia driver then you can downgrade linux kernel by going to advanced option for ubuntu in boot menu. Then reinstalling cuda toolkit 9.1 will fix the driver issue. Currently on my test linux kernel 4.10 worked.  ", "use it worked with 4.10 but give not sufficient driver with 4.13 ,,,thanks\r\n", "i build it successfully.However, when i import it. it throw an error.\r\n```\r\nbringtree@bringtree-HP-Z420-Workstation:~/tensorflow-1.5.0/tensorflow_pkg$ python3\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01)\r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nt>>> sess= tf.Session()\r\n2018-01-28 20:14:56.074102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.8475\r\npciBusID: 0000:05:00.0\r\ntotalMemory: 5.93GiB freeMemory: 5.47GiB\r\n2018-01-28 20:14:56.074141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2018-01-28 20:14:56.074277: E tensorflow/core/common_runtime/direct_session.cc:168] Internal: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1509, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 628, in __init__\r\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n\r\n```", "@bringtree what the command `nvidia-smi` returns?", "@bringtree Your likely problem based on the error\r\n\r\n> CUDA driver version is insufficient for CUDA runtime version\r\n\r\n- CUDA 9 needs driver 384.81+\r\n- CUDA 9.1 needs driver 390.x+  Thanks @rolla12 ", "for cuda 9.1 the driver is 390 ,, its now included with deb installation ,,it solved the problem\r\n", "@ultrasounder pip install wheel should fix the problem before build. Sorry for late reply.", "Mind that Linux 4.13.x (default on 16.04.3) has some issues with 387.22+.  No issues on Linux 4.11.0 (also available in 16.04.3)\r\n https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1742302", "@dchichkov  that issues has been solved by the driver 390.x \r\nif you reinstall cuda 9.1 you will install 390 instead of 387.x ", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi! What were a reasons why TF 1.6 hasn't been shipped with CUDA 9.1 but only 9.0?", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "And CUDA 9.2 is out. Are there any updates on what TF version is going to be shipped with 9.2 and what with 10.0.", "Hi. I am trying to run tensorflow-gpu (1.7) on Windows 10, with CUDA 9.1 and cudnn 7.0.5, python 3.6 and a GeForce 1070, and I am getting a cublas error: \"failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\". I've Googled the error and I've tried the few solutions mentioned there (calling the GPU before the CPU and not vice-versa, trying to reinstall things, etc), but nothing worked. Does anyone know why I am getting this error and if there is a fix?\r\n\r\nI followed the instructions  in this link http://www.python36.com/install-tensorflow-gpu-windows/ to install Tensorflow, but instead of building it myself, I used the prebuilt wheel from here https://drive.google.com/drive/folders/1lVK_ABvVHzVYKs7X5SUhcZFBgKpC41Qw ", "Closing this out and starting a CUDA 9.2 ticket which I hope to have as the default in TF 1.9.  \r\nhttps://github.com/tensorflow/tensorflow/issues/18906"]}, {"number": 15139, "title": "Support --config=monolithic in tf.sysconfig.get_link_flags()", "body": "Currently, `tf.sysconfig.get_link_flags()` always adds `-ltensorflow_framework`.  With this change, it would check whether TensorFlow was built with `--config=monolithic`.", "comments": ["Can one of the admins verify this patch?", "@jhseu, would be very nice if this could get in before you cut over to 1.5 branch.", "@drpngx, sounds good, updated.", "@drpngx, gentle ping.", "Sorry, forgot about this.\r\n\r\n(We should get rid of `gen_git_source.sh`, which AFAIK is only used in the Makefile version.)", "Jenkins, test this please.", "Just an FYI, this PR has mostly been reverted after pulling - it breaks forward compatibility.  I left the C objects in - after 3 weeks have passed you can resubmit the rest of the change and forward compatibility will then pass.", "@ekelsen, I just checked `master` and it seems that all the changes are still there. Can you point me to revert diff and share more context about breaking forward compatibility?", "I think it's the golden for the API compatibility in `tools/api_tests`. It's strange that it passed the tests in the first place.", "@drpngx, the golden change was part of the PR.  I'm hoping this change can be included as part of next official release (1.5.0 or 1.4.x), so there's no need to have special checks in plugin build scripts for monolithic TF builds.", "I think the push hadn't finished when you last checked - it is now.\r\n\r\nUnfortunately, given that 3 weeks need to pass, I think it is unlikely that this can make it into 1.5.0.", "Forward compatibility means that models created at HEAD need to run on binaries that are up to 3 weeks old.  This change broke this guarantee.  The solution is to add the symbols to the C code, then wait three weeks and add your python changes.", "@ekelsen, I just checked now, and the code is still in `master`.\r\n\r\nI'm not sure how would it break forward compatibility though since `tf.sysconfig.get_link_flags()` would remain internally-consistent - as long as you use Python bits and binaries from the same TF git ref.\r\n\r\nIs there a situation when folks use TF binaries from 3 weeks older than accompanying TF Python code?"]}, {"number": 15138, "title": "Document tf-coreml converter in lite/README.md", "body": "", "comments": ["Can one of the admins verify this patch?", "@sarahs1 FYI\r\n"]}, {"number": 15137, "title": "Tensorflow broken by new Bazel versions", "body": "Simplest way to reproduce the issue, run:\r\n`$ bazel build --config=opt --incompatible_load_argument_is_label --nobuild //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nSuggested fix to `tensorflow/third_party/sycl/sycl/BUILD.tpl`:\r\n```\r\n-load(\"platform\", \"sycl_library_path\")\r\n+load(\":platform.bzl\", \"sycl_library_path\")\r\n\r\n-load(\"platform\", \"readlink_command\")\r\n+load(\":platform.bzl\", \"readlink_command\")\r\n```\r\n\r\nThis should address the immediate need.\r\nThere are other issues to fix (although not as pressing). You can see them by building using `--all_incompatible_changes`.\r\n\r\nLet me know if you need any help.\r\nThanks!", "comments": ["/CC @gunan, can you resolve this?", "Thanks for the report @laurentlb Could you file a bug internally for us to quickly triage this?", "I've prepared a change that will fix this -- first internally, then externally, once the repositories are synced.", "The fix has been applied to our internal branch. The next repository sync should bring the fix over to Github.", "Thanks!"]}, {"number": 15136, "title": "Tensorflow is pulling enum34 in Python 3.5 and 3.6, which breaks code completion in Spyder", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.5, 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: `pip install tensorflow`\r\n\r\n### Describe the problem\r\nWhen you run\r\n\r\n    pip install tensorflow\r\n\r\nin a virtualenv with Python 3.5 or 3.6, one of the dependencies pulled by `pip` is `enum34`, as the following console output shows\r\n\r\n```\r\n$ pip install tensorflow\r\nCollecting tensorflow\r\n  Downloading tensorflow-1.4.0-cp35-cp35m-manylinux1_x86_64.whl (40.7MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40.7MB 39kB/s \r\nCollecting numpy>=1.12.1 (from tensorflow)\r\n  Using cached numpy-1.13.3-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting six>=1.10.0 (from tensorflow)\r\n  Using cached six-1.11.0-py2.py3-none-any.whl\r\nCollecting protobuf>=3.3.0 (from tensorflow)\r\n  Downloading protobuf-3.5.0.post1-cp35-cp35m-manylinux1_x86_64.whl (6.4MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.4MB 217kB/s \r\nRequirement already satisfied: wheel>=0.26 in ./.virtualenvs/tf/lib/python3.5/site-packages (from tensorflow)\r\nCollecting enum34>=1.1.6 (from tensorflow)\r\n  Downloading enum34-1.1.6-py3-none-any.whl\r\n```\r\n\r\nThis package is only necessary if `Python < 3.4`, as described here:\r\n\r\nhttps://pypi.python.org/pypi/enum34/1.1.6\r\n\r\nso it's an error that `tensorflow` pullis it for Python 3.5 and 3.6.\r\n\r\nBesides, this package breaks Spyder code completion machinery in its Editor, as it has been verified by several users. See for example:\r\n\r\nspyder-ide/spyder#5782.", "comments": ["@gunan @jart should we update the package?", "@av8ramit is working on 1.4.1\r\nIf we have a fix, we can cherrypick this into 1.4.1\r\nHowever, the only attempted fix ended up breaking the pip package.\r\nif we have a fix that works for all python versions, I am happy to release it with 1.4.1", "Also CC @yifeif ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I think our final decision on this was to remove the dependency on `enum34` library.\r\n@martinwicke to confirm the decision\r\n@yifeif @angersson to make sure it is removed for 1.5 release\r\n@xiejw to FYI", "Thanks for the heads up. This sounds fine to me. ", "Confirmed.", "For 1.5, enum should only be included as a dependency if the python version is < 3.4 https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/tools/pip_package/setup.py#L67", "I think the idea is to remove all use of enum, no?\n", "Just checked with tf-nightly, enum34 is only installed with python2.7. Let me know if this is not what we wanted.\r\n```\r\n~$ pip install tf-nightly\r\nCollecting tf-nightly\r\n  Using cached tf_nightly-1.5.0.dev20171211-cp34-cp34m-manylinux1_x86_64.whl\r\nCollecting protobuf>=3.4.0 (from tf-nightly)\r\n  Downloading protobuf-3.5.1-py2.py3-none-any.whl (388kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 389kB 3.7MB/s \r\nCollecting tb-nightly<1.6.0a0,>=1.5.0a0 (from tf-nightly)\r\n  Downloading tb_nightly-1.5.0a20171222-py3-none-any.whl (3.0MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.0MB 540kB/s \r\nCollecting wheel>=0.26 (from tf-nightly)\r\n  Using cached wheel-0.30.0-py2.py3-none-any.whl\r\nCollecting six>=1.10.0 (from tf-nightly)\r\n  Using cached six-1.11.0-py2.py3-none-any.whl\r\nCollecting absl-py>=0.1.6 (from tf-nightly)\r\n  Downloading absl-py-0.1.7.tar.gz (78kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 15.0MB/s \r\nCollecting numpy>=1.12.1 (from tf-nightly)\r\n  Using cached numpy-1.13.3-cp34-cp34m-manylinux1_x86_64.whl\r\nRequirement already satisfied: setuptools in ./envname/lib/python3.4/site-packages (from protobuf>=3.4.0->tf-nightly)\r\nCollecting html5lib==0.9999999 (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly)\r\n  Using cached html5lib-0.9999999.tar.gz\r\nCollecting bleach==1.5.0 (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly)\r\n  Using cached bleach-1.5.0-py2.py3-none-any.whl\r\nCollecting markdown>=2.6.8 (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly)\r\n  Using cached Markdown-2.6.10.zip\r\nCollecting werkzeug>=0.11.10 (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly)\r\n  Using cached Werkzeug-0.13-py2.py3-none-any.whl\r\nInstalling collected packages: six, protobuf, html5lib, bleach, wheel, numpy, markdown, werkzeug, tb-nightly, absl-py, tf-nightly\r\n  Running setup.py install for html5lib ... done\r\n  Running setup.py install for markdown ... done\r\n  Running setup.py install for absl-py ... done\r\nSuccessfully installed absl-py-0.1.7 bleach-1.5.0 html5lib-0.9999999 markdown-2.6.10 numpy-1.13.3 protobuf-3.5.1 six-1.11.0 tb-nightly-1.5.0a20171222 tf-nightly-1.5.0.dev20171211 werkzeug-0.13 wheel-0.30.0\r\n\r\n```", "Do we know if it is easy to remove all of our dependency on enum?", "I think there's only a two uses. One in variable_scope.py, as superclass of a private class _ReuseMode. The other in xla_client.py, as superclass of PaddingType, which is not part of the public API. \r\n\r\nSo it should be easy to get rid of entirely.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@ccordoba12 would you be willing to submit a PR?", "Sure, could you point me to the places I have to look for?", "@tensorflowbutler Waiting for the build w/o enum", "Waiting +1", "I think the enum dependency should not be fetched anymore for later python versions, @yifeif to confirm.\r\nBut we should still kill the dependency on enum34.", "We shouldn't be depending on enum34 for python 3 anymore. Let me know if that is not the case? Should we close this issue or keep it open for removing enum34 entirely at some point @gunan?", "Let's keep it open to remove enum34 entirely.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "This is causing a lot of trouble for us on Python 3.6.3 - there are workarounds but they are...unpleasant.", "@smartb-pair what kind of issue are you seeing? python3.6 shouldn't be pulling enum as a dependency anymore.", "The dep on enum is declared in the metadata for the tensorflow wheel file provided by Google (we need to install from this file rather then pypi for a variety of org-specific reasons).\n\nBlake\n\n> On 27. Mar 2018, at 15:51, Yifei Feng <notifications@github.com> wrote:\n> \n> @smartb-pair what kind of issue are you seeing? python3.6 shouldn't be pulling enum as a dependency anymore.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "@smartb-pair, are you installing old Tensorflow versions? I think this was fixed in version 1.5.", "We currently have a requirement for 1.4.1 - will see if we can rev up...\n\n> On 27. Mar 2018, at 17:40, Carlos Cordoba <notifications@github.com> wrote:\n> \n> @smartb-pair, are you installing old Tensorflow versions? I think this was fixed in version 1.5.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "Not sure whether it will help others but I managed to install Tensorflow as follows:\r\n```\r\nsudo pip install --ignore-installed tensorflow\r\n```", "@wedesoft Well **THAT** worked for me! Thanks a Lot!!", "Closing as this is resolved", "Thanks!", "@wt-huang  nope!  2019 and this is still a bug:\r\n```\r\n$ docker run -it --rm tensorflow/tensorflow:1.15.0-py3-jupyter bash\r\n\r\n...\r\n\r\nroot@2d0b0b6ff8ac:/tf# pip uninstall -y enum34\r\nUninstalling enum34-1.1.6:\r\n  Successfully uninstalled enum34-1.1.6\r\n```", "cc https://github.com/tensorflow/tensorflow/issues/18480"]}, {"number": 15135, "title": "Solved for MNIST file downloading problem", "body": "A lot of folks (#6742, #8126, #8134,#8116) were having trouble regarding this issue. Even I faced it today while writing the MNIST code as the mnist.py was unable to connect with the source url. I downloaded the files and pasted it in the folder containing the code and made some changes in the code which solves the need for connecting it to the website. Hope so this works out.", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Hello @caisq , the website is not allowing us to connect what is the solution now?", "Sorry - I'm confused what you mean by the website not allowing you to connect. I just tried\r\n\r\n```\r\nwget --spider https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz\r\nwget --spider https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\r\nwget --spider https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\r\nwget --spider https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\r\n```\r\n\r\nThe commands all work, indicating remote files exist.", "I am getting the following output\r\n\r\n`Traceback (most recent call last):\r\n  File \"mnist_softmax.py\", line 79, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/pratik/tensorflow/venv/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"mnist_softmax.py\", line 37, in main\r\n    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\r\n  File \"/home/pratik/tensorflow/venv/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py\", line 240, in read_data_sets\r\n    source_url + TRAIN_IMAGES)\r\n  File \"/home/pratik/tensorflow/venv/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 208, in maybe_download\r\n    temp_file_name, _ = urlretrieve_with_retry(source_url)\r\n  File \"/home/pratik/tensorflow/venv/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 165, in wrapped_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/home/pratik/tensorflow/venv/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py\", line 190, in urlretrieve_with_retry\r\n    return urllib.request.urlretrieve(url, filename)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 94, in urlretrieve\r\n    return _urlopener.retrieve(url, filename, reporthook, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 240, in retrieve\r\n    fp = self.open(url, data)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 208, in open\r\n    return getattr(self, name)(url)\r\n  File \"/usr/lib/python2.7/urllib.py\", line 437, in open_https\r\n    h.endheaders(data)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 1013, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 864, in _send_output\r\n    self.send(msg)\r\n  File \"/usr/lib/python2.7/httplib.py\", line 826, in send\r\n    self.connect()\r\n  File \"/usr/lib/python2.7/httplib.py\", line 1220, in connect\r\n    self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file)\r\n  File \"/usr/lib/python2.7/ssl.py\", line 487, in wrap_socket\r\n    ciphers=ciphers)\r\n  File \"/usr/lib/python2.7/ssl.py\", line 243, in __init__\r\n    self.do_handshake()\r\n  File \"/usr/lib/python2.7/ssl.py\", line 405, in do_handshake\r\n    self._sslobj.do_handshake()\r\nIOError: [Errno socket error] [Errno 1] _ssl.c:510: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol`", "This seems to be a network connectivity problem specific to you.", "Well at first I thought it was due to some proxy configuration settings but now turning off all proxies and switching my connection to another network..it shows\r\n `IOError: [Errno socket error] [Errno 111] Connection refused`"]}, {"number": 15134, "title": "contrib STFT magnitudes different to librosa's", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version**: 1.4\r\n- **Python version**: 3.5.2\r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version**: N/A\r\n- **CUDA/cuDNN version**: 6.0\r\n- **GPU model and memory**: nvidia quadro m2000m 4gb\r\n- **Exact command to reproduce**: See below code\r\n\r\nHi all!\r\n\r\nI was comparing the TensorFlow's contrib STFT against librosa's and noticed there are some discrepancies in terms of output between the two. Not sure if this normal between libraries implementations, but I wanted to raise it in case it matters!\r\n\r\nI'm also aware it could be some small bug or difference in implementation/argument that I have supplied.\r\n\r\nCode:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport librosa\r\n\r\nnp.random.seed(666)\r\nnp.set_printoptions(precision=5, suppress=True)\r\n\r\naudio_length_seconds = 2\r\nsample_rate = 44100\r\naudio_frames_length = int(sample_rate * audio_length_seconds)\r\naudio_shape = [None, audio_frames_length]\r\nfft_size = 1024\r\nhop_size = 512\r\n\r\ntf.reset_default_graph()\r\n\r\naudio = tf.placeholder(tf.float32, \r\n                       shape=audio_shape)\r\nstfts = tf.contrib.signal.stft(audio, \r\n                               frame_length=fft_size, \r\n                               frame_step=hop_size,\r\n                               fft_length=fft_size,\r\n                               pad_end=True)\r\nreal = tf.real(stfts)\r\nimag = tf.imag(stfts)\r\nmagnitudes = tf.abs(stfts)\r\nphases = tf.atan2(imag, real)\r\nfeatures = tf.concat([magnitudes, phases], axis=2)\r\n\r\nsess = tf.Session()\r\nwith sess.as_default():\r\n    \r\n    data = np.random.random((1, audio_frames_length))\r\n    tf_results = magnitudes.eval({audio: data})\r\n    \r\n    lr_results = librosa.core.stft(y=data.reshape((-1)),\r\n                                   n_fft=fft_size,\r\n                                   hop_length=hop_size,\r\n                                   win_length=fft_size)\r\n                                   \r\n    lr_results = np.abs(lr_results)\r\n    \r\n    difference = np.abs(tf_results - lr_results.T)\r\n    print(\"Differences:\\nmin:\", np.min(difference), \r\n          \"max:\", np.max(difference), \r\n          \"mean:\", np.mean(difference), \r\n          \"std:\", np.std(difference))\r\n```\r\n\r\nAnd the expected output from the print would be:\r\n\r\n```\r\nDifferences:\r\nmin: 6.97374e-05 max: 246.904 mean: 2.92715 std: 2.45132\r\n```", "comments": ["@rryan do you know anything about that?", "I was talking to a friend about this and he tested a bunch of prominent FFT libraries such as FFTW, and he noted that the output was different for those. So maybe its to be expected across implementations. Just wanted to let you know at any rate.", "The difference is probably due to the window function.  By default librosa uses the hann window function.  You can do similar in tensorflow with the following.  I have not tested your code to see if this actually does make it the same.\r\n\r\n`\r\nstfts=tf.contrib.signal.stft(audio,\r\n    \tframe_length=fft_size,\r\n    \tframe_step=hop_size,\r\n    \twindow_fn=functools.partial(tf.contrib.signal.hann_window, periodic=True),\r\n    \tpad_end=True\r\n    \t)\r\n`", "What version of librosa are you comparing to?  Given the date of the post, I'm assuming <=0.5.1.\r\n\r\nWe recently fixed a long-standing, inherited bug where the stft was incorrectly conjugated, so that might also contribute to discrepancies.  The fix was included in librosa 0.6, see [this thread](https://github.com/librosa/librosa/issues/521) for an explanation of what happened there.\r\n\r\nIt's also worth checking magnitude ratios, instead of absolute differences, just to see if it's a factor of `sqrt(2*pi*n)` issue.", "Howdy! \r\n\r\n@fedden Did you conclude that the TensorFlow's contrib STFT library is good to go? Are you using it or the librosa one?", "Hi! Thank you @fedden for the helpful repro.\r\n\r\nOne difference between librosa and `tf.contrib.signal.stft` is that librosa center-pads the signal with reflection when framing while `tf.contrib.signal.stft` (and `tf.spectral.rfft` and `np.fft.rfft`) pad from the right with zeros by default. Adding support for padding options like these to `tf.contrib.signal.stft` would be a nice addition!\r\n\r\n I think that accounts for the difference here. I put your repro in a [Colab notebook](https://colab.research.google.com/drive/1MFhk40mojsXI-_prvePwRyhSgLrYzi3p#scrollTo=nmPlOcYoPEZp) and set `center=False` and the max difference in magnitude between TF and librosa becomes `1e-5`.", "Hi @fedden !\r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. We recommend you try updating your code base to[ 2.7](https://www.tensorflow.org/api_docs/python/tf/signal/stft) and check whether issue exists or not?   Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 15133, "title": "Revert \"Speed up safe_strtod and safe_strtof functions by using doubl\u2026", "body": "\u2026e-conversion library (#12102)\"\r\n\r\nThis reverts commit 495bb7b9f6b55b0e431fc604ad9dbf5415016d90.", "comments": ["cc @AKindyakov @sb2nov @drpngx @martinwicke @petewarden ", "cc @miaout17", "@tensorflow-jenkins test this please"]}, {"number": 15132, "title": "Add decode_compressed support", "body": "This fix tries to address the issue raised in #14887 to add decode_compressed support.\r\n\r\nThe API will take a string Tensor (compressed with either ZLIB or GZIP) and output a string Tensor of the same shape with content uncompressed.\r\n\r\nThis fix fixes #14887.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["(from API review: This is good to go.)", "Jenkins, test this please.", "@martinwicke Thanks for the help. It seems python 3 build still has failures (python 2 is OK). Let me take a look and update the PR.", "@martinwicke The Python 3 build failure has been fixed and the PR has been updated and pushed. Please take a look.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Argh sorry -- I edited the docstring to make it more explicit, could you regenerate the APIDefs?", " Thanks @martinwicke. The PR has been updated with `tensorflow/core/api_def/update_api_def.sh` rerun.\r\n\r\nAll tests passed except `Ubuntu Sanity`, which I think might be unrelated as I also see several other PRs (like #15491 and #15461) having the same issue.\r\n\r\nPlease take a look.", "@martinwicke All tests passed now but `cla/google` is stuck. Not sure how to trigger to pass the test. Is there a way to manually get around it?", "Yes, that's because I added a commit. I'll merge over it.", "Thanks all for the help  \ud83d\udc4d \ud83c\udf89 \ud83c\udf08 "]}, {"number": 15131, "title": "Tensorflow Unit Test: //tensorflow/python/eager:core_test fails", "body": "Tensorflow test failing on power hardware. \r\n\r\nW tensorflow/core/common_runtime/device_mgr.cc:97] Unknown device: GPU:5 all devices: /device:GPU:1, GPU:0, /device:GPU:0,\r\n\r\nWe are using 2 GPUs.\r\n\r\nAny help appreciated", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.", "power architecture is not officially supported. IBM may have more information on this.", "System info and Steps to reproduce\r\nLinux  ppc64le GNU/Linux\r\nTF commit id 3fe5fa08dbed8134ad400f03be474aeb39bcc922\r\nPython 2.7.5\r\nBazel Build label: 0.5.4- (@non-git)\r\ngcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)\r\ncuda-9.0/\r\nNVIDIA GPU driver \r\ncommand to reproduce issue - bazel test //tensorflow/python/eager:core_test \r\n\r\n\r\ntotalMemory: 15.89GiB freeMemory: 15.60GiB\r\n2017-12-05 14:28:56.364727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix\r\n2017-12-05 14:28:56.364760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1\r\n2017-12-05 14:28:56.364766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y N\r\n2017-12-05 14:28:56.364771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   N Y\r\n2017-12-05 14:28:56.364786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name:  xyz, pci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-05 14:28:56.364793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: xyz, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\n.2017-12-05 14:28:56.552693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: xyz, pci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-05 14:28:56.552707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: xyz, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\n.2017-12-05 14:28:56.554959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: xyz, pci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-05 14:28:56.554968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: xyz, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\nF2017-12-05 14:28:56.555711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: xyz, pci bus id: 0003:01:00.0, compute capability: 6.0)\r\n2017-12-05 14:28:56.555727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: xyz, pci bus id: 0007:01:00.0, compute capability: 6.0)\r\n.2017-12-05 14:28:56.557869: W tensorflow/core/common_runtime/device_mgr.cc:97] Unknown device: GPU:5 all devices: /device:GPU:1, GPU:0, /device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1, /device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/cpu:0, /device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, CPU:0, /job:localhost/replica:0/task:0/gpu:1, XLA_CPU:0, XLA_GPU:0, /device:XLA_GPU:0, GPU:1, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/gpu:0, /job:localhost/replica:0/task:0/xla_gpu:0, /job:localhost/replica:0/task:0/xla_cpu:0\r\n\r\n======================================================================\r\nFAIL: testContextConfig \r\n\r\n- [ ] (__main_- 1. _.TFETest)\r\n\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):", "@sandipmgiri @Nayana-ibm \r\nAs we do not have power machines, it is difficult for us to help with these issues.\r\nShould we just redirect these issues to you? Is there a separate IBM support flow these users should follow?", "The Power h/w access can be obtained easily via http://osuosl.org/services/powerdev/request_hosting/ \r\nThis should make it easy for this reporter as well as any other interested developers to test and analyze ppc64le specific behaviour and issues. Those can then be reported on this forum.", "@snjagadale , I just noticed this old issue for ppc64le. I believe this test is working now in Tensorflow 1.9. Is this issue ok to close ? ", "I will close this for now. But please reopen if this is still  a problem."]}, {"number": 15130, "title": "Synchronize threads for safe output", "body": "", "comments": ["Can one of the admins verify this patch?", "@ekelsen any luck with this?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @caisq: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @caisq: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @caisq: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @ekelsen: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: It has been 16 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: It has been 151 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: It has been 166 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: It has been 181 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: It has been 196 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @ekelsen: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 211 days with no activity and the `awaiting review` label has been applied.", "Nagging Reviewer @ekelsen: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 226 days with no activity and the `awaiting review` label has been applied."]}, {"number": 15129, "title": "build error: undefined reference to `clock_gettime'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux CentOS 6.9\r\n- **TensorFlow installed from (source or binary)**:\r\nsource \r\n- **TensorFlow version (use command below)**:\r\nmaster branch: the latest version\r\n- **Python version**: \r\n2.7\r\n- **Bazel version (if compiling from source)**:\r\n0.8.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n4.8.2\r\n- **CUDA/cuDNN version**:\r\nNo\r\n- **GPU model and memory**:\r\nNo\r\n- **Exact command to reproduce**:\r\nbazel build --linkopt=-lrt -c opt --verbose_failures //tensorflow:libtensorflow_cc.so\r\n\r\n### Describe the problem\r\nI tried to build the tensor flow c++ lib from the source code, but it failed. \r\n\r\n### Source code / logs\r\nERROR: /home/baigang/Projects/xylib/thirdparty/tenserflow/package/tensorflow/tensorflow/cc/BUILD:422:1: Linking of rule '//tensorflow/cc:ops/random_ops_gen_cc' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/baigang/.cache/bazel/_bazel_baigang/d3e5550086b82aa173767408d0f485e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/baigang/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /usr/bin/gcc -o bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc '-Wl,-rpath,$ORIGIN/../../../_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow' -Lbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc-2.params)\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `clock_gettime'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 418.738s, Critical Path: 35.11s\r\nFAILED: Build did NOT complete successfully", "comments": ["/CC @gunan, do you know what could be causing this issue?", "Looks like this is an issue caused by centos 6.9\r\nA quick google search found these similar issues, and potential solution here:\r\nhttps://stackoverflow.com/questions/17150075/undefined-reference-to-clock-gettime-although-lrt-is-given\r\n\r\nClosing, as this issue is definitely caused by OS version of the user.\r\n", "It's not the same issue as the one in stackoverflow.com. \r\nActually, you will find tensorflow already defined \" -pthread -Wl,-no-as-needed\" in the build script. I think this issue is caused by tensorflow did not add -lrt in the build script. \r\n", "You did add `-lrt` in your build command, so it may be an issue when bazel needs to propagate this flag properly. \r\n@damienmg may want to take a look, but centos is not an OS we officially support, or we test/experiment on.", "I am also facing same issue here when I try to build Tensorflow for CPU from source.   \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux Server release 6.9 (Santiago)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master branch the latest version\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: 4.9.2\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\nbazel build --config=opt --verbose_failures --linkopt=-lrt //tensorflow/tools/pip_package:build_pip_package\r\n### Source code / logs\r\n```\r\nERROR: /home/user/tensorflow/tensorflow/contrib/cloud/BUILD:36:1: Linking of rule '//tensorflow/contrib/cloud:gen_gen_bigquery_reader_ops_py_wrappers_cc' failed (Exit 1): gcc failed: error executing command \r\n  (cd /root/.cache/bazel/_bazel_user/88f96db14f5044a661b2d9ab97596b51/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/jdk1.8.0_144/bin:/home/aniruddh/bazel-0.5.4-dist/output/:/usr/local/MATLAB/R2016a/bin:/usr/local/bin:/usr/local/netscape:/usr/sbin:/usr/bin:/usr/lib:/bin:/sbin:/etc:/opt/lumerical/fdtd/bin:/lib:.:/root/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /usr/bin/gcc -o bazel-out/host/bin/tensorflow/contrib/cloud/gen_gen_bigquery_reader_ops_py_wrappers_cc '-Wl,-rpath,$ORIGIN/../../../_solib_k8/_U_S_Stensorflow_Scontrib_Scloud_Cgen_Ugen_Ubigquery_Ureader_Uops_Upy_Uwrappers_Ucc___Utensorflow' -Lbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scontrib_Scloud_Cgen_Ugen_Ubigquery_Ureader_Uops_Upy_Uwrappers_Ucc___Utensorflow '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/contrib/cloud/gen_gen_bigquery_reader_ops_py_wrappers_cc-2.params).\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scontrib_Scloud_Cgen_Ugen_Ubigquery_Ureader_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `clock_gettime'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 110.105s, Critical Path: 44.90s\r\n```\r\n", "Exactly same issue on Red Hat Enterprise Linux release 6.3 (Carbon). Looks like linker option '--linkopt=-lrt' does not propagate to gcc.", "I had the same issue. To compile under one older linux Centos 6.7, i edited the tensorflow.bzl file and added manually at some linkopts field -lrt near -lm. Then compilation was successfull. Hope this help. ", "@zwergon Can you tell me how you add the \"-lrt\" field? Thanks.", "I had the same error on CentOS 6.9, but was able to get it to build successfully by adding `-lrt`  to the linking options on lines 267 and 1267 in `tensorflow.bzl`.   A small patch file with the changes is  [here](https://github.com/tensorflow/tensorflow/files/1691141/librt.txt).\r\n\r\n", "@acaprez Thanks.", "We just ran into the same issue, also using CentOS 6 and GCC 4.x on our HPC cluster. It seems, there is still a lot of demand for official support for these aging distros / compilers.\r\n\r\n**Note:** This might not be a CentOS 6 only problem, I suppose, this might as well be pinned to GCC 4.x or GCC < 6, not necessarily exclusive to CentOS 6. Not sure, though.\r\n\r\nI don't see a `.travis.yml`. If you would set up Travis CI or CI framework of your choice, I suppose, the community would even pitch in and contribute the CentOS 6 testing without too much effort on your part.", "Our build is too heavy for travis(would take hours), so we use a different CI for our official builds.\r\nSince on our side, we exclusively use debian based distros, we keep it working for these but centos issues are invisible to us.\r\nHowever, if anyone would like to maintain a centos build (non merge blocking) I am happy to help you setup webhooks from TF repo, and I am happy to expedite review of fixes on rhel/centos", "same problem. I've tried adding \"-lrt\" as much as possible, but still not work.\r\nfinally I switched to docker, as https://www.tensorflow.org/install/source#docker_linux_builds says, \"TensorFlow's Docker development images are an easy way to set up an environment to build Linux packages from source.\"\r\nuse docker image tensorflow1.12.0-devel, and some modification to .bzl files according to \r\n https://stackoverflow.com/questions/39032329/is-there-any-way-to-build-tensorflow-from-source-without-having-internet.\r\nfinally it's done", "For those arriving via Google in future, the following `-lrt` additions allowed tensorflow r1.12 to build for me on CentOS7: https://gist.github.com/joshpencheon/bd4299223c26.", "Thanks for debugging this @joshpencheon \r\nIf you like to contribute a pull request with your fix, I would be happy to review and merge your change!", "> For those arriving via Google in future, the following `-lrt` additions allowed tensorflow r1.12 to build for me on CentOS7: https://gist.github.com/joshpencheon/bd4299223c26.\r\n\r\nHello, \r\nI am facing the similar issue but the link you provided above land me to \"page not found\". Could you please help provide the command?\r\nThanks!!"]}]