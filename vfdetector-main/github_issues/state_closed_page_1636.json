[{"number": 3828, "title": "Estimator raises spurious error with dynamic_rnn model", "body": "I'm trying to train an RNN and I'm playing with the dynamic_rnn model inside an skflow Estimator and trying to traing it sequences of increasing length.\n\nSo I end up passing in data of the form [batch_size, seq_length, seq_entry_size]\n\nWhere seq_length varies, but is constant each time I call partial_fit.\n\nI am constructing my dynamic_rnn model like so:\n\n```\ndef rnn_model2(x, y):\n  cell = tf.nn.rnn_cell.GRUCell(250)\n\n  _, encoding = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n\n  target = tf.one_hot(y, 2, 1, 0)\n\n  prediction, loss = learn.models.logistic_regression(encoding, target)\n\n  # Create a training op.\n  train_op = tf.contrib.layers.optimize_loss(\n      loss, tf.contrib.framework.get_global_step(),\n      optimizer='Adam', learning_rate=0.01)\n\n  return {'class': tf.argmax(prediction, 1), 'prob': prediction}, loss, train_op\n\nclassifier = learn.Estimator(model_fn=rnn_model2)\n```\n### Environment info\n\nOperating System:\nUbuntu on Windows 10\n\nIf installed from binary pip package, provide:\n0.10.rc0\n### Steps to reproduce\n1. Create an Estimator with a model_fn that uses a dynamic_rnn\n2. Pass variable length data through partial_fit\n3. Error\n### What have you tried?\n1. I commented out the checks in estimator.py and things work\n### Logs or other output that would be helpful\n\nWARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 2, 3), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(1), Dimension(3)]), is_sparse=False).\nTraceback (most recent call last):\n  File \"mouse.py\", line 136, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"mouse.py\", line 126, in main\n    classifier.partial_fit(x_train, y_train, steps=3)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 262, in partial_fit\n    batch_size=batch_size, monitors=monitors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 219, in fit\n    max_steps=max_steps)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 478, in _train_model\n    self._check_inputs(features, targets)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 427, in _check_inputs\n    (str(features), str(self._features_info)))\nValueError: Features are incompatible with given information. Given features: Tensor(\"input:0\", shape=(?, 2, 3), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(1), Dimension(3)]), is_sparse=False).\n", "comments": ["Hmmm, I might just be doing this wrong, commenting the checks out worked with a small test batch, but then failed with a slightly larger test batch...\n\nFWIW these are the errors I'm looking at now\n\n```\nTraining on length  1  shape:  (78, 1, 3) , target:  (78,)\nWARNING:tensorflow:The current implementation of partial_fit is not optimizedfor use in a loop. Consider using fit() instead.\nWARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(1), Dimension(3)]), is_sparse=False)\nWARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\nTraceback (most recent call last):\n  File \"mouse.py\", line 136, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"mouse.py\", line 130, in main\n    y_predicted = classifier.predict(x_test)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 323, in predict\n    as_iterable=as_iterable)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 592, in _infer_model\n    predictions = self._get_predict_ops(features)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 824, in _get_predict_ops\n    predictions, _, _ = self._call_model_fn(features, targets, ModeKeys.INFER)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 733, in _call_model_fn\n    return self._model_fn(features, targets)\n  File \"mouse.py\", line 42, in rnn_model2\n    _, encoding = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 797, in dynamic_rnn\n    for input_ in flat_input)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 796, in <genexpr>\n    flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 989, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2497, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2319, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1711, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 2058, in _TransposeShape\n    input_shape.ndims))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 570, in merge_with\n    (self, other))\nValueError: Shapes (3,) and (2,) are not compatible\n```\n", "Hi,\nDo you find the solution for this problem in the end? I had the same problem as you posted\n"]}, {"number": 3827, "title": "Fix `ResourceWarning: unclosed file` warnings in reader_ops_test.py", "body": "Some file handles created in these test cases are were not being closed. This causes warnings in py3 along with leaked handles.\n\n```\n./source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:245: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/text_line.0.txt'>\n  f = open(fn, \"wb\")\n/source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:276: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/text_line.1.txt'>\n  self._testOneEpoch(self._CreateFiles(crlf=True))\n./source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:273: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/text_line.1.txt'>\n  self._testOneEpoch(self._CreateFiles(crlf=False))\n./source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:279: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/text_line.1.txt'>\n  files = self._CreateFiles()\n../source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:183: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/whole_file.0.txt'>\n  open(fn, \"wb\").write(c)\n/source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:183: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/whole_file.1.txt'>\n  open(fn, \"wb\").write(c)\n/source/tensorflow/tensorflow/python/kernel_tests/reader_ops_test.py:183: ResourceWarning: unclosed file <_io.BufferedWriter name='/var/folders/sq/vmncyd7506q_ch43llrwr8sn6zfknl/T/reader_ops_test/whole_file.2.txt'>\n  open(fn, \"wb\").write(c)\n...\n```\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n\n(Thanks!)\n"]}, {"number": 3826, "title": "GPU-enabled Mac build of TensorFlow version 0.10.0rc0-py2 was compiled against cuDNN v5", "body": "### Environment info\n\nOperating System: OS X 'El Capitan' Version 10.11.6 (15G31)\n\nInstalled version of CUDA and cuDNN: cuda_7.5.27_mac, cudnn-7.5-osx-x64-v5.0-ga (I explain why I am using cuDNN v5 rather than cuDNN v4 below.)\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n<pre>\nlrwxr-xr-x@ 1 root  wheel    50 Apr 13 02:03 libcublas.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas.7.5.dylib\nlrwxr-xr-x@ 1 root  wheel    46 Apr 13 02:03 libcublas.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas.dylib\nlrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcublas_device.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas_device.a\nlrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcublas_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcublas_static.a\n-rwxr-xr-x  2 root  wheel  8280 May 11 04:59 libcuda.1.dylib\n-rwxr-xr-x  2 root  wheel  8280 May 11 04:59 libcuda.dylib\nlrwxr-xr-x@ 1 root  wheel    45 Apr 13 02:03 libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\nlrwxr-xr-x@ 1 root  wheel    50 Apr 13 02:03 libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\nlrwxr-xr-x@ 1 root  wheel    46 Apr 13 02:03 libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\nlrwxr-xr-x@ 1 root  wheel    49 Apr 13 02:03 libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\nlrwxr-xr-x  1 root  admin    47 Aug 15 14:24 libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  admin    45 Aug 15 14:24 libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  admin    48 Aug 15 14:24 libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a\n</pre>\n\n\n`libcuda.1.dylib` is a hard link to `libcuda.dylib` per [this comment](https://github.com/tensorflow/tensorflow/issues/2940#issuecomment-238952433).\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed: `export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0rc0-py2-none-any.whl`\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: 0.10.0rc0\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### Steps to reproduce\n1. Set up TensorFlow according to the instructions at https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#prepare_environment_for_mac_os_x\n   \n   In particular, the page says to install cuDNN v4, which is labeled \"cuDNN v4 (Feb 10, 2016), for CUDA 7.0 and later.\" on the [cuDNN Download page](https://developer.nvidia.com/rdp/cudnn-download).\n2. Test the installation by running:\n   \n   `python -m tensorflow.models.image.mnist.convolutional`\n   \n   You should see:\n   \n   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR  \n   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\n3. Now run the test under `cuda-memcheck`:\n   \n   `cuda-memcheck python -m tensorflow.models.image.mnist.convolutional`\n   \n   You should see:\n   \n   > E tensorflow/stream_executor/cuda/cuda_dnn.cc:347] Loaded runtime CuDNN library: 4007 (compatibility version 4000) but source was compiled with 5005 (compatibility version 5000).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\n### What have you tried?\n\nUninstalling cuDNN v4 and installing cuDNN v5 (labeled \"cuDNN v5 (May 12, 2016), for CUDA 7.5\" on the cuDNN Download page) fixes the issue.\n\nI think that either TensorFlow should be built with cuDNN v4 or the installation instructions should be corrected to specify that cuDNN v5 should be installed.\n", "comments": ["@yifeif can you adjust the docs to maek clear that the mac builds already build against cuDNN 5?\n", "Got same issue\n", "Thanks @dtrebbien and @shkarupa-alex for the inputs. We are working on updating our docs.\n", "Installation instructions have been updated. Issue closed.\n"]}, {"number": 3825, "title": "A bug with a default initialiser and tf.nn.rnn_cell.LSTMCell/tf.contrib.rnn.LSTMFusedCell", "body": "### Environment info\n\nOperating System:\nMac OS X 10.9.5 \n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nNo CUDA\n\nIf installed from binary pip package, provide:\npip install http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=mac1-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.10.0rc0-py2-none-any.whl\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.10.0rc0\n### Steps to reproduce\n1. A minimum example to reproduce the bug:\n\n```\nimport numpy as np\nimport tensorflow as tf\n\nwith tf.variable_scope(\"rnn\", initializer=tf.contrib.layers.xavier_initializer()):\n    out_cell = tf.nn.rnn_cell.LSTMCell(num_units=100, state_is_tuple=True, use_peepholes=True)\n    #out_cell = tf.contrib.rnn.LSTMFusedCell(num_units=100)\n    input_var = tf.placeholder(dtype=tf.float32, shape=(32, 50, 100))\n\n    d, _ = tf.nn.dynamic_rnn(out_cell, input_var, dtype=tf.float32, parallel_iterations=32,\n                                 scope=\"output_rnn\")\n    init = tf.initialize_all_variables()\n    with tf.Session() as sess:\n        input = np.random.uniform(-1.0, 1.0, [32, 50, 100])\n        sess.run(init)\n        o = sess.run([d], {input_var: input})\n\n```\n1. The same bug if you comment LSTMCell and uncomment LSTMFusedCell which was renamed to LSTMBlockCell recently\n2. If I remove \", initializer=tf.contrib.layers.xavier_initializer()\" in tf.variable_scope code will work without errrors with normal distribution by default. Or if I remove use_peepholes=True in LSTMCell the bug will disappear too.\n### What have you tried?\n\n1.\n### Logs or other output that would be helpful\n\nTraceback (most recent call last):\n....\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 848, in dynamic_rnn\n    dtype=dtype)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 1015, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1992, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1877, in BuildLoop\n    pred, body, original_loop_vars, loop_vars)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1827, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 1000, in _time_step\n    (output, new_state) = call_cell()\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 986, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py\", line 443, in __call__\n    wci = vs.get_variable(\"wci\", [self._num_units])\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 830, in get_variable\n    custom_getter=custom_getter)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 673, in get_variable\n    custom_getter=custom_getter)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 217, in get_variable\n    validate_shape=validate_shape)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 202, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 536, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 281, in _init_from_args\n    self._initial_value = ops.convert_to_tensor(initial_value(),\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 526, in <lambda>\n    init_val = lambda: initializer(shape.as_list(), dtype=dtype)\n  File \"/Users/vostryakov/projects/senses/env/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py\", line 114, in _initializer\n    fan_in = float(shape[-2])\nIndexError: list index out of range\nException TypeError: TypeError(\"'NoneType' object is not callable\",) in <function _remove at 0x10248b6e0> ignored\n", "comments": ["Will take a look later this week.\n", "Thank you!\n", "``` python\ninitializer = tf.contrib.layers.xavier_initializer()\n\nb1 = tf.get_variable(\"b1\", [1024], initializer=initializer)\n```\n\nI got the same problem when using initializer on a 1d variable. It's ok if the dimension is 2.\n\n``` python\nb1 = tf.get_variable(\"b1\", [1, 1024], initializer=initializer)\n```\n\nLooks like the initializer works only on 2d shape variables.\n\n``` python\n# tensorflow/tensorflow/contrib/layers/python/layers/initializers.py\n\ndef variance_scaling_initializer(...):\n  ...\n  def _initializer(shape, dtype=dtype, partition_info=None):\n    ...\n    fan_in = float(shape[-2])\n    fan_out = float(shape[-1])\n```\n", "@ebrevdo Is there a progress on this bug?\n", "I have a pull request (#4406) for this.\n\nBTW, I found that it's not a good idea to initialize bias with xavier (in my case).\n"]}, {"number": 3824, "title": "Unclear documentation and behavior for sampler in Tensorflow", "body": "For the samplers implemented in tensorflow, e.g. tf.nn.fixed_unigram_candidate_sampler. The behavior is not well-defined in the document. For instance, I would expect the labels specified in true_classes will be excluded from the sampling pool, and the sampling will be conducted for each batch. But according to my experiments, neither of above is true.\n\nConsider the following code:\n\n`import tensorflow as tf\n\nlabels_matrix = tf.reshape(tf.constant([1, 2, 3, 4], dtype=tf.int64), [-1, 1])\n\nsampled_ids, _, _ = tf.nn.fixed_unigram_candidate_sampler(\n    true_classes = labels_matrix,\n    num_true = 1,\n    num_sampled = 1,\n    unique = True,\n    range_max = 5,\n    distortion = 0.0,\n    unigrams = range(5)\n)\n\ninit = tf.initialize_all_variables()\nwith tf.Session() as sess:\n    sess.run(init)\n    print sess.run([sampled_ids])\n`\n\nThe output can be 3, which actually belongs to the set of true classes. - Also, the output has the dimension [1], which basically means that the sampling is only conducted once, not for each batch.\n\nCan someone help to clarify this?\n", "comments": ["Is this still current?", "Yes, this is probably still a problem in the docs, and it will be useful for the TF writer to keep the issue for reference.", "any solutions for this issue? I also find this problem in version1.2"]}, {"number": 3823, "title": "R0.10", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 3822, "title": "Correct typo in word2vec.py", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "You might also want to make this change to the master branch.\n"]}, {"number": 3821, "title": "Tensorflow Checkpoint and CKPT is not working and does not give any readable error.", "body": "### Environment info\n\nOperating System:\n\nMac OSX El Capitan\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\nThe latest version of Tensorflow\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n0.10.0rc0\n### Steps to reproduce\n\nI have trained a convolutional model through the main program and stored it into a checkpoint and ckpt file. The problem lies in the evaluation program. The ckpt file seems to not output anything but a bunch of errors. The program does not complete either.\n\nThe code for main is:\n\n```\nimport Input\nimport Process\n\nimport time\nimport numpy as np\n\nimport tensorflow as tf\nfrom datetime import datetime\n\nFLAGS = tf.app.flags.FLAGS\n\ndef train():\n    with tf.Session() as sess:\n        images, labels = Process.inputs()\n\n        forward_propgation_results = Process.forward_propagation(images)\n\n        train_loss, cost = Process.error(forward_propgation_results, labels)\n\n        image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n        summary_op = tf.merge_all_summaries()\n\n        init = tf.initialize_all_variables()\n\n        saver = tf.train.Saver()\n\n        sess.run(init)\n\n        saver = tf.train.Saver(tf.all_variables())\n\n        tf.train.start_queue_runners(sess = sess)\n\n        train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n        for step in range(100):\n            start_time = time.time()\n            print(sess.run([train_loss, cost]))\n            duration = time.time() - start_time\n            if step % 1 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n\n                if step % 2 == 0:\n                    checkpoint_path = train_dir\n                    saver.save(sess, checkpoint_path, global_step = step)\n\n\ndef main(argv = None):\n    train()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nand the eval is \n\n```\nimport tensorflow as tf\n\nimport main\nimport Process\nimport Input\n\neval_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt-98\"\ncheckpoint_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"\n\n\ndef evaluate():\n  with tf.Graph().as_default() as g:\n    images, labels = Process.eval_inputs()\n    forward_propgation_results = Process.forward_propagation(images)\n    init_op = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)\n\n  with tf.Session(graph = g) as sess:\n    tf.train.start_queue_runners(sess = sess)\n    sess.run(init_op)\n    saver.restore(sess, eval_dir)\n    for i in range(100):\n        print(sess.run(top_k_op))\n\ndef main(argv = None):\n    evaluate()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n### What have you tried?\n1. I tried initializing the variables before running the queue's but that only removed the errors. The errors also do not point to any problem thats in the code.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nThe output is:\n\n[error.txt](https://github.com/tensorflow/tensorflow/files/418658/error.txt)\n", "comments": ["Hi there. I think the confusion came from how train_dir, eval_dir and checkpoint_dir are used. You need to set your checkpoint_dir to where your checkpoints reside. All the *_dir need to be directories instead of files.\n\nPlease see\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_eval.py\n\nfor examples.\n", "Hello sherrym,\n\nI managed to get it to read the checkpoint file, but now its outputting:\n\nW tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /Users/Zanhuang/Desktop/NNP/checkpoint: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\nover and over again for the number of variables in that file.\n\nWhat seems to be the problem here?\n", "Hi @StructML , I don't think your code is able to read the correct checkpoint file. Could you paste the exact commands you used for training and eval here? Also, please paste the output of the following command here:\n\n# find /Users/Zanhuang/Desktop/NNP/\n", "For Training:\n\n```\nimport Input\nimport Process\n\nimport time\nimport numpy as np\nimport os\n\nimport tensorflow as tf\nfrom datetime import datetime\n\nFLAGS = tf.app.flags.FLAGS\n\ndef train():\n    with tf.Session() as sess:\n        images, labels = Process.inputs()\n\n        forward_propgation_results = Process.forward_propagation(images)\n\n        train_loss, cost = Process.error(forward_propgation_results, labels)\n\n        image_summary_t = tf.image_summary(images.name, images, max_images = 2)\n\n        summary_op = tf.merge_all_summaries()\n\n        init = tf.initialize_all_variables()\n\n        saver = tf.train.Saver()\n\n        sess.run(init)\n\n        saver = tf.train.Saver(tf.all_variables())\n\n        tf.train.start_queue_runners(sess = sess)\n\n        train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"\n\n        summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n\n        for step in range(100):\n            start_time = time.time()\n            print(sess.run([train_loss, cost]))\n            duration = time.time() - start_time\n            if step % 1 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')\n                print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))\n\n                summary_str = sess.run(summary_op)\n                summary_writer.add_summary(summary_str, step)\n\n                if step % 2 == 0:\n                    checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step = step)\n\n\ndef main(argv = None):\n    train()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nFor Eval:\n\n```\nimport main\nimport Process\nimport Input\n\neval_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"\ncheckpoint_dir = \"/Users/Zanhuang/Desktop/NNP\"\n\n\ndef evaluate():\n  with tf.Graph().as_default() as g:\n    images, labels = Process.eval_inputs()\n    forward_propgation_results = Process.forward_propagation(images)\n    init_op = tf.initialize_all_variables()\n    saver = tf.train.Saver()\n    top_k_op = tf.nn.in_top_k(forward_propgation_results, labels, 1)\n\n  with tf.Session(graph = g) as sess:\n    tf.train.start_queue_runners(sess = sess)\n    sess.run(init_op)\n    saver.restore(sess, eval_dir)\n    for i in range(100):\n        print(sess.run(top_k_op))\n\ndef main(argv = None):\n    evaluate()\n\nif __name__ == '__main__':\n  tf.app.run()\n```\n\nThe results of find is:\n\n/Users/Zanhuang/Desktop/NNP/\n/Users/Zanhuang/Desktop/NNP//.DS_Store\n/Users/Zanhuang/Desktop/NNP//checkpoint\n/Users/Zanhuang/Desktop/NNP//DATA_PREPARE\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/.DS_Store\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/enput.py\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cacer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data1.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data2.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data3.bin\n/Users/Zanhuang/Desktop/NNP//TRAIN_MODI/TEST/Prostate_Cancer_Data4.bin\n", "In your training code, you had specified \"/Users/Zanhuang/Desktop/NNP/model.ckpt\" to be the directory for writing checkpoints. I do not see that directory under /Users/Zanhuang/Desktop/NNP at all.\n\n# Please read my previous comment on how to use train_dir, eval_dir and checkpoint_dir.\n\nHi there. I think the confusion came from how train_dir, eval_dir and checkpoint_dir are used. You need to set your checkpoint_dir to where your checkpoints reside. All the *_dir need to be directories instead of files.\n\nPlease see\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_eval.py\n\nfor examples.\n\n# \n", "Strange, there is however a model.ckpt folder. I deleted some things from the results because there was a lot of cluttering of jpeg images. I might have accidentally removed something.\n\nLet me repost:\n\n[error.txt](https://github.com/tensorflow/tensorflow/files/421129/error.txt)\n", "It still doesn't work even after moving the checkpoints out of that directory in to NNP.\n", "This looks to me like all of your paths are confused:\n\nIn your new training code, you have:\n`train_dir = \"/Users/Zanhuang/Desktop/NNP/model.ckpt\"`\nYou're writing checkpoints to here:\n `checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')`\n\nWhere `FLAGS.data_dir` is unspecified... do you provide this on the command line?  If not, what is the default value? \n\nWhen doing eval, you have:\n`eval_dir = \"/Users/Zanhuang/Desktop/NNP/checkpoint\"`\nbut strangely\n`checkpoint_dir = \"/Users/Zanhuang/Desktop/NNP\"`\n\nAnd you're actually restoring from: \n`saver.restore(sess, eval_dir)`\n\nThere does not appear to be a TensorFlow bug here, so I'm going to close this issue.  \nIf you are still having problems making your code work, StackOverflow is a more appropriate venue for general usage questions.    \n"]}, {"number": 3820, "title": "Branch 130271393", "body": "", "comments": []}, {"number": 3819, "title": "Chains of queues not working in 0.10.0 rc0", "body": "### Environment info\n\nOperating System: Ubuntu 14.04, Mac OS X\n\nInstalled version of CUDA and cuDNN: None\n\nIf installed from binary pip package, provide: \nCPU only, Python 2.7 packages for 0.9.0 and 0.10.0 rc0\n\nI am working with a scheme in which I feed several batch queues into a `batch_join` to multiplex them.\n\nThe following code works in 0.9.0 (prints several batches before encountering `OutOfRange`, but fails in 0.10.0 rc0 (first run of `sess.run(c)` produces `OutOfRange`).\n\n``` python\nimport tensorflow as tf\nimport numpy as np\nimport string\n\nsess = tf.Session()\n\na = tf.train.batch([tf.train.input_producer(list(string.ascii_lowercase), shuffle=False, num_epochs=1).dequeue()], 10)\nb = tf.train.batch([tf.train.input_producer(list(string.ascii_uppercase), shuffle=False, num_epochs=1).dequeue()], 10)\n\nc = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False), [0])\n\nsess.run(tf.initialize_all_variables())\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\nfor _ in range(20):\n    print sess.run(c)\n```\n### Steps to reproduce\n1. Run in 0.9.0\n2. Run in 0.10rc1\n### What have you tried?\n1. Noticed this behaviour in Mac OS X\n2. Double checked by creating two Docker images having TF 0.9.0 and 0.10.0 rc0 respectively installed on top of Ubuntu 14.04.\n### Logs or other output that would be helpful\n\nTensorFlow 0.9.0 output\n\n```\n['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j']\n['k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't']\n['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']\n['K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T']\nTraceback (most recent call last):\n  File \"/Untitled11.py\", line 23, in <module>\n    print sess.run(c)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 636, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 708, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 728, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: batch_join = QueueDequeueMany[_class=[\"loc:@batch_join/padding_fifo_queue\"], component_types=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_join/padding_fifo_queue, batch_join/n)]]\nCaused by op u'batch_join', defined at:\n  File \"/Untitled11.py\", line 16, in <module>\n    c = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False, dynamic_pad=True), [0])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 682, in batch_join\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 434, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 465, in _queue_dequeue_many\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n```\n\nTensorFlow 0.10.0 rc0 Output:\n\n```\nE tensorflow/core/client/tensor_c_api.cc:485] Attempting to use uninitialized value input_producer/limit_epochs/epochs\n     [[Node: input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input_producer/limit_epochs/epochs\"], limit=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer/limit_epochs/epochs)]]\nE tensorflow/core/client/tensor_c_api.cc:485] PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: batch_join = QueueDequeueMany[_class=[\"loc:@batch_join/padding_fifo_queue\"], component_types=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_join/padding_fifo_queue, batch_join/n)]]\nTraceback (most recent call last):\n  File \"/Untitled11.py\", line 23, in <module>\n    print sess.run(c)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.OutOfRangeError: PaddingFIFOQueue '_4_batch_join/padding_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: batch_join = QueueDequeueMany[_class=[\"loc:@batch_join/padding_fifo_queue\"], component_types=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch_join/padding_fifo_queue, batch_join/n)]]\nCaused by op u'batch_join', defined at:\n  File \"/Untitled11.py\", line 16, in <module>\n    c = tf.squeeze(tf.train.batch_join([(a,), (b,)], 1, enqueue_many=False, dynamic_pad=True), [0])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 708, in batch_join\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 435, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 867, in _queue_dequeue_many\n    timeout_ms=timeout_ms, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n", "comments": ["Can you try adding the following line, before starting the queue runners:\n\n``` python\nsess.run(tf.initialize_local_variables())\n```\n\n(It looks like there was a breaking change between 0.9 and 0.10, which recast how the auxiliary variables inside functions like `tf.train.input_producer()` are initialized.)\n", "Thanks - it seems this solves it.\n\n--Hannes\n\nOn Tue, Aug 16, 2016 at 1:05 PM, Derek Murray notifications@github.com\nwrote:\n\n> Can you try adding the following line, before starting the queue runners:\n> \n> sess.run(tf.initialize_local_variables())`\n> \n> (It looks like there was a breaking change between 0.9 and 0.10, which\n> recast how the auxiliary variables inside functions like\n> tf.train.input_producer() are initialized.)\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3819#issuecomment-240168039,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AATuQ2uCk7Qr84qg__hzubzaAJQhNKhsks5qge3AgaJpZM4Jkl7Q\n> .\n", "I had a similar problem and this fixes it for me too. I'm a bit puzzled though, as I had previously called `tf.initialize_all_variables().run(session=sess)` but that did not work on its own. I actually had to call `initialize_local_variables()` as well. Shouldn't the former subsume the latter?\n", "For some terrible reason, local variables are not considered part of \"all\"\n:(\n\nWe are in the process of renaming \"all\" to somethong else less confusing,\nsince models would break if we made \"all\" include local variables. It's a\nmess.\n\nOn Wed, Aug 17, 2016, 11:00 AM Mohammed AlQuraishi notifications@github.com\nwrote:\n\n> I had a similar problem and this fixes it for me too. I'm a bit puzzled\n> though, as I had previously called\n> tf.initialize_all_variables().run(session=sess) but that did not work on\n> its own. I actually had to call initialize_local_variables() as well.\n> Shouldn't the former subsume the latter?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3819#issuecomment-240494591,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAcTeReuROvOYKZGYXCM--RdmLLlyfIDks5qg0xCgaJpZM4Jkl7Q\n> .\n", "Hmmm. Why would making \"all\" include \"local\" break things though? And if that's the case then is it even a good idea to invoke initialize \"all\" followed by \"local\"? Or is your point that they need to be done as separate steps, and so long as that's the case, then it's ok?\n", "Because exactly when people call initialize_all vs. initialize_local matters (\"all\" happens once, typically, I believe \"local\" happens locally to workers whenever they restart).  I don't know the details, I actually proposed what you said and was told it would break things, and they have to be done as separate steps.  Fixing the naming will at least make it less confusing, at least, but I wish we weren't in this situation.\n", "@vrv @alquraishi If I understand the [commit](https://github.com/tensorflow/tensorflow/commit/4c85a95925a68fec324f70cd0d7f3d4548f97a38) that broke this correctly, the problem was that `all_variables()` determined not just what was initialized when you do `tf.initialize_all_variables()` but **also** what variables are saved when you construct a `tf.train.Saver()` with no arguments. This particular variable would turn up in checkpoints and cause problems (e.g. you'd restore a model and try to use it for training, but the epoch limit in the input producer would already be reached, so you'd get OutOfRange as soon as you started).\n\nAgreed that we should fix the naming, but possibly we should also separate out the notion of \"all\" (which seems useful and uncontroversial) from the notion of \"things that get saved in checkpoints by default\".\n", "@mrry if I understand you correctly, the underlying distinction seems less to be about \"global\" vs. \"local\" and more of a \"one-time initialization\" vs some notion of what's included in the checkpoint. Perhaps \"initialize\" is not even the right prefix to describe the corresponding function then.\n\nIt sure is confusing as is now.\n\nFrom a practical standpoint, is the fix to simply call both, in any given order?\n", "Yes, the problem is that 'global' vs 'local' is conflated with 'saved' vs. 'not-saved', and we're trying to clean and clear that up.\n\nToday, I think it makes sense to first call initialize_all_variables, then initialize_local_variables (I believe the Supervisor framework does this for you).  We will probably rename / deprecate _all_variables and replace it with something a bit more meaningful before 1.0.\n", "@vrv ok thanks, that is what I'm currently doing and it seems to work fine. I started writing my TF code with 0.5 and so everything is very close to the metal, without any of the fancy new stuff like the Supervisor framework. Perhaps at some point I'll refactor, but so far I've gotten away with it! ;-)\n", "Bare metal use is fine, we should have abstractions that work for everyone, with various degrees of control and ease :)\n"]}, {"number": 3818, "title": "Update to Eigen version that fixes CUDA 8 compilation error", "body": "This updates Eigen to a new version that should fix the compilation error seen in #3786.\nThe corresponding pull request in Eigen is https://bitbucket.org/eigen/eigen/pull-requests/218/fix-compilation-on-cuda-8-due-to-missing/diff.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3817, "title": "fix typo", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n"]}, {"number": 3816, "title": "Bug in tf.image.random_contrast() ?", "body": "TensorFlow v. 0.10.0rc0 CPU on Linux.\n\nIn this file for the CIFAR-10 example:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_input.py\n\nLines 178-179 are:\n\n```\ndistorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n```\n\nBut this gives the following result. Is this the intended behaviour of this function? Perhaps this should be explained better in the doc-string?\n\nThere is a similar problem with `tf.image.random_brightness()` and `adjust_brightness()` and its use in `cifar10_input.py`\n\n![random_contrast](https://cloud.githubusercontent.com/assets/13588114/17666469/889ffc9e-6300-11e6-8163-9d7e23ca0f75.png)\n", "comments": ["What do you expect the output to be?\n", "I suppose the output should be like the 3 images on the right-hand side? The other images are weirdly distorted. It seems to overflow or something when `tf.image.random_contrast()` is called with `upper > 1.0` and the cifar10 example calls it with `upper=1.8`\n\nI should mention that I call these functions in my own code where the pixels are floats between zero and one. Perhaps that is the problem. I don't know because it's not clear from the doc-strings what the functions assume of the input. Please clarify the doc-strings in `tf.image`. Perhaps an `assert upper <= 1.0` would also be a good idea in the `random_contrast()` function, and similarly for the other functions in `tf.image`.\n", "These do not necessarily look wrong to me. You are asking for contrast. The contrast formula outputs for each channel c at each pixel i,j\nmean =sum(x(i,j,c),i,j)/(N*M)\nx(i,j,c) = contrast \\* (x(i,j,c)-mean) + mean\nThis formula can produce values that are greater than 1.  This contrast formula is more general histogram equalization than what a paint program does. A paint program turns contrast into a pointwise operation typically by assuming a 0.5 mean on every channel. So the contrast behavior looks like what I would expect.  To see if you are getting a proper contrast adjustment, try doing contrast and then plotting a histogram of each channel before and after the contrast adjustment.\n\nTry doing maximum contrast on a color photo in gimp, you'll see the same extreme pixels. The standard contrast there is limited to 127 (which is because they go [0,255] by default). That is equivalent to 0.5 contrast in the [0,1] image scale. So cifar is doing way more, so the extreme pixels will be even more extreme.\n", "Thanks for the comments.\n\nI suppose there are two issues when the pixel values overflow beyond the [0, 1] range.\n\n(1) Whether the classification performance of the network is affected. I think this might be the case because this was how I initially discovered the overflow, because my neural network performed worse. Although it's been several weeks now, so I can't remember the details.\n\n(2) Plotting the images with pixels that have overflown shows weird pixels like in the images above.\n\nA simple solution is to finalize the random distortions with two lines of code that limit the pixel values to [0, 1], like so:\n\n```\nimage = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n\n# Do various other distortions ...\n\n# Limit pixel values to [0, 1]\nimage = tf.minimum(image, 1.0)\nimage = tf.maximum(image, 0.0)\n```\n\nExample with this limiting when doing various random distortions:\n\n![limited](https://cloud.githubusercontent.com/assets/13588114/18047760/c1ad0070-6dde-11e6-8367-2990eef537c6.png)\n\nWithout the limiting:\n\n![overflow](https://cloud.githubusercontent.com/assets/13588114/18047773/c98298aa-6dde-11e6-94ec-af1c5c5401a5.png)\n\nNote: To get the same random values in these two sets of images, I first set the random seed using `tf.set_random_seed(42)`, but the two right-most images in the top-row have different random crops. I don't know why.\n", "Yes. This is what I expected. I would say in general it is reasonable for float images to exceed 1. High dynamic range (HDR) images often will have this being the case. HDR images are not commonly used in ML. HDR images have to be tone-mapped (constrained) to LDR displays through some process. Contrast, brightness are simple forms of tone mapping, but there are many more complicated algorithms that can be used to preserve things like neighboring (relative contrast). \n\nThe upshot is that it does not seem appropriate to clamp the values inside of contrast functions. If a user needs or wants to do this for training performance, using tf.minimum and tf.maximum can always be added.\n", "Thanks again for the comments.\n\nI think it would be wise to add a note about this in the docs for the image functions; that their output might exceed the input range, and that an easy solution is to limit the output after a sequence of image operations. I imagine that most people don't have deep insights about these image algorithms and might be surprised about overflows if it's not in the docs.\n\nClosed.\n", "Since my un-augmented test images will only have pixel values in the range from 0-1, I decided to restrict my augmented images to the same range. Instead of the `tf.minimum(image, 1.0)` suggestion from before, I preferred to scale the pixel values, rather than just cap them at 0 or 1. I also take the min/max over all channels, to minimise colour distortion.\r\n\r\nIt's just these 4 lines of code:\r\n```\r\nimage -= tf.reduce_min(image)\r\nimage_max = tf.reduce_max(image)\r\nif image_max != 0:\r\n    image = image / image_max\r\n```\r\n\r\nThese lines can be run once after all augmentation is complete. That is more efficient than adjusting the range after each operation, so I agree that the `tf.image.X` functions should not limit the range of their outputs. i.e. they should be left as they are.\r\n\r\nEdit: added a check for a divide-by-zero problem in case every pixel in the image has the same value."]}, {"number": 3815, "title": "reduce_prod shape bug ", "body": "Installed TensorFlow using pip package for v0.10.0rc0 on Ubuntu with python 2.7\n\nPip package https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n\nThe same error appears in the GPU build.\n\nThe following minimal code example produces raise an exception at the definition of z\n\n```\nu = tf.placeholder(dtype=tf.float64, shape=(30,30))\nv = tf.reduce_prod(u, reduction_indices=[0]) \nw = tf.gradients( v, u )\n\nx = tf.placeholder(dtype=tf.float64, shape=(30,30))\ny = tf.reduce_prod(x, reduction_indices=0) \nz = tf.gradients( y, x )\n```\n\n>  z = tf.gradients( y, x )\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 478, in gradients\n>     in_grads = _AsList(grad_fn(op, *out_grads))\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 130, in _ProdGrad\n>     other, _ = array_ops.listdiff(idx, reduced)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1201, in list_diff\n>     result = _op_def_lib.apply_op(\"ListDiff\", x=x, y=y, name=name)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n>     op_def=op_def)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2312, in create_op\n>     set_shapes_for_outputs(ret)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1704, in set_shapes_for_outputs\n>     shapes = shape_func(op)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1981, in _ListDiffShape\n>     op.inputs[1].get_shape().assert_has_rank(1)\n>   File \"HOME/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 621, in assert_has_rank\n>     raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\n> ValueError: Shape () must have rank 1\n\nThe top code for u,v and w does not raise an error but the similar code for x,y, and z does. It looks like the shape code for reduce_prod cannot cope with the case where the reduction_indices is a single integer rather than a list. If you replace reduce_prod with reduce_sum in the above snippet then it does not raise an error. \n", "comments": ["This bug was introduced by me when rewriting the prod gradient to deal with zeros in the input.\nThe code doesn't handle the case where `reduction_indices` is a scalar.\n\nTo fix this we should\n- Add a line to the gradient that reshapes the `reduction_indices` to a rank 1 tensor: `tf.reshape(reduction_indices, [-1])`\n- Add a test case that computes the gradient with a scalar reduction index parameter.\n- Maybe add a bit of text to the documentation of the reduction ops that mentions that both scalars and rank tensors can be passed in? I couldn't find any mention of this being possible except for the examples.\n", "@ibab, do you plan to submit a PR? Thanks.\n", "I've just pushed #3858 with a fix.\n", "Thanks much, @ibab!\n"]}, {"number": 3814, "title": "Add a build target for a shared library that contains the c api symbols", "body": "Since r0.10, the library created by build target tensorflow:libtensorflow.so does not contain the c api symbols anymore (whereas this was the case in previous releases). I imagine that this was caused by the c api moving from tensorflow/core to tensorflow/c. This is a little inconvenient for our [ocaml tensorflow bindings](https://github.com/LaurentMazare/tensorflow-ocaml) as they rely on these symbols.\n\nWould it be possible to add back this dependency ? Something as simple as adding \"//tensorflow/c:c_api\" to the deps list worked for me.\nIf this dependency has been avoided on purpose for tensorflow:libtensorflow.so, could we add a different build target, e.g. libtensorflow_c.so, that would include it ?\nI'm happy to write a pull request for either of these if this helps.\n", "comments": ["Sorry @keveman , I probably broke this, but I don't know what the fix is.\n", "@LaurentMazare what you suggest sounds good, please send a PR.\n", "@keveman I've attached a PR with a new target that includes the C api symbols. Let me know if you think it would be better to include them directly into an existing target, e.g. libtensorflow.so.\n", "@josh11b @keveman any thoughts on this ? If it's still time I would be very happy to have this fixed in the final 0.10 release so that we can have our ocaml wrapper working on this version.\n", "@LaurentMazare I just started a jenkins test for PR #3830. I will merge that once tests are green.\n"]}, {"number": 3813, "title": "wide_n_deep model deal with large dataset got ValueError: GraphDef cannot be larger than 2GB.", "body": "wide_n_deep seems like unable to fit large dataset, when I put 1 million data, I got:\n\n```\nTraceback (most recent call last):\n  File \"search_click.py\", line 207, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"search_click.py\", line 204, in main\n    train_and_eval()\n  File \"search_click.py\", line 181, in train_and_eval\n    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 182, in fit\n    monitors=monitors)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 458, in _train_model\n    summary_writer=graph_actions.get_summary_writer(self._model_dir))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 76, in get_summary_writer\n    graph=ops.get_default_graph())\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py\", line 113, in __init__\n    self.add_graph(graph=graph, graph_def=graph_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py\", line 204, in add_graph\n    true_graph_def = graph.as_graph_def(add_shapes=True)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2117, in as_graph_def\n    raise ValueError(\"GraphDef cannot be larger than 2GB.\")\nValueError: GraphDef cannot be larger than 2GB.\n```\n\n```\ndef input_fn(df):\n  \"\"\"Input builder function.\"\"\"\n  # Creates a dictionary mapping from each continuous feature column name (k) to\n  # the values of that column stored in a constant Tensor.\n  continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n  # Creates a dictionary mapping from each categorical feature column name (k)\n  # to the values of that column stored in a tf.SparseTensor.\n  categorical_cols = {k: tf.SparseTensor(\n      indices=[[i, 0] for i in range(df[k].size)],\n      values=df[k].values,\n      shape=[df[k].size, 1])\n                      for k in CATEGORICAL_COLUMNS}\n  # Merges the two dictionaries into one.\n  feature_cols = dict(continuous_cols)\n  feature_cols.update(categorical_cols)\n  # Converts the label column into a constant Tensor.\n  label = tf.constant(df[LABEL_COLUMN].values)\n  # Returns the feature columns and the label.\n  return feature_cols, label\n```\n\nIs there a replacement of tf.constant and tf.SparseTensor, so we can load a batch once a time?\nAny help would be appreciated!\n", "comments": ["@xinyuwuhenZZ You can use `partial_fit()` found [here](https://github.com/terrytangyuan/tensorflow/blob/3ee6afa12c30816b20d638a95945c49a59bae5f0/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L236). \n", "Thanks, but seems like no difference between `fit()` and `partial_fit()`.\n", "You are right. The implementation is quite different now and many functionalities may not work anymore. Perhaps @martinwicke can advise on this better. \n", "Large datasets should not be put as constants into the graph. Use queues. You can check on the tutorials page, or on StackOverflow on how to use it. \n", "@martinwicke Can you give an example? Thank you very much. I am a freshman to tensorflow.", "Please check out this howto: https://www.tensorflow.org/how_tos/reading_data/", "@martinwicke Thank you for your time. How to edit the function `input_fn` below to fix the ValueError: GraphDef cannot be larger than 2GB? Can you give another version of function `input_fn`? Thanks a lot. I am not very clear of how to do this edition with the link https://www.tensorflow.org/how_tos/reading_data/ after trying a lot with a lot of errors.\r\n```python\r\ndef input_fn(df):\r\n  \"\"\"Input builder function.\"\"\"\r\n  # Creates a dictionary mapping from each continuous feature column name (k) to\r\n  # the values of that column stored in a constant Tensor.\r\n  continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\r\n  # Creates a dictionary mapping from each categorical feature column name (k)\r\n  # to the values of that column stored in a tf.SparseTensor.\r\n  categorical_cols = {k: tf.SparseTensor(\r\n      indices=[[i, 0] for i in range(df[k].size)],\r\n      values=df[k].values,\r\n      shape=[df[k].size, 1])\r\n                      for k in CATEGORICAL_COLUMNS}\r\n  # Merges the two dictionaries into one.\r\n  feature_cols = dict(continuous_cols)\r\n  feature_cols.update(categorical_cols)\r\n  # Converts the label column into a constant Tensor.\r\n  label = tf.constant(df[LABEL_COLUMN].values)\r\n  # Returns the feature columns and the label.\r\n  return feature_cols, label\r\n```", "Please ask this type of question on StackOverflow.\n\nAvoid calling tf.constant. Use tf.batch instead.\n\nOn Sat, Dec 31, 2016 at 20:37 zhangrong <notifications@github.com> wrote:\n\n> @martinwicke <https://github.com/martinwicke> Thank you for your time.\n> How to edit the function input_fn below to fix the ValueError: GraphDef\n> cannot be larger than 2GB? Can you give another version of function\n> input_fn? Thanks a lot. I am not very clear of how to do this edition\n> with the link https://www.tensorflow.org/how_tos/reading_data/ after\n> trying a lot with a lot of errors.\n>\n>\n> def input_fn(df):\n>\n>   \"\"\"Input builder function.\"\"\"\n>\n>   # Creates a dictionary mapping from each continuous feature column name (k) to\n>\n>   # the values of that column stored in a constant Tensor.\n>\n>   continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n>\n>   # Creates a dictionary mapping from each categorical feature column name (k)\n>\n>   # to the values of that column stored in a tf.SparseTensor.\n>\n>   categorical_cols = {k: tf.SparseTensor(\n>\n>       indices=[[i, 0] for i in range(df[k].size)],\n>\n>       values=df[k].values,\n>\n>       shape=[df[k].size, 1])\n>\n>                       for k in CATEGORICAL_COLUMNS}\n>\n>   # Merges the two dictionaries into one.\n>\n>   feature_cols = dict(continuous_cols)\n>\n>   feature_cols.update(categorical_cols)\n>\n>   # Converts the label column into a constant Tensor.\n>\n>   label = tf.constant(df[LABEL_COLUMN].values)\n>\n>   # Returns the feature columns and the label.\n>\n>   return feature_cols, label\n>\n>\n>\n>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/3813#issuecomment-269892070>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAjO_ZESr8LhQ9I2u-OpN1ugiGQ0VYIQks5rNy2YgaJpZM4JkJL4>\n> .\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n"]}, {"number": 3812, "title": "Tensorflow distributed training question: Do we have to manually copy ckpt files from worker 0  to ps servers? ", "body": "Operating System:\nLinux XNLPEXP2 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nAzure VM 8 cores, 56GB memory\nIf installed from binary pip package, provide:\npip 8.1.2 from /home/xubixiong/.local/lib/python2.7/site-packages (python 2.7)\n0.10.0rc0\n\nWhen I am trying to restore training from latest checkpoint, I found that I have to copy checkpoint files to ps servers, from worker 0. \n\nIs it the right and recommended way? Or I did something wrong? ? \n", "comments": ["In general, the `tf.train.Saver` code assumes that the worker and parameter server jobs share the same filesystem. For example, you could use a shared NFS mount, or you could use the support for Google Cloud Storage; support for more filesystems - such as HDFS,, #2218 - is in development.\n\nIn the special case that you are using the same parameter server hosts when restoring, you can try passing `sharded=True` to the saver constructor, and each parameter server will write its shard of the parameters to its local filesystem. It should then be able to restore from that path as well.\n", "Great, I did miss this point. After trying, I used rsync to work around. Now I will adjust to the recommended way.\nThank you very much.\n\nGet Outlook for iOShttps://aka.ms/o0ukef\n\nOn Mon, Aug 15, 2016 at 11:35 PM +0800, \"Derek Murray\" <notifications@github.com<mailto:notifications@github.com>> wrote:\n\nIn general, the tf.train.Saver code assumes that the worker and parameter server jobs share the same filesystem. For example, you could use a shared NFS mount, or you could use the support for Google Cloud Storage; support for more filesystems - such as HDFS,, #2218https://github.com/tensorflow/tensorflow/issues/2218 - is in development.\n\nIn the special case that you are using the same parameter server hosts when restoring, you can try passing sharded=True to the saver constructor, and each parameter server will write its shard of the parameters to its local filesystem. It should then be able to restore from that path as well.\n\n## \n\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/tensorflow/tensorflow/issues/3812#issuecomment-239834251, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AUBCfscXcI1Fn8_2EcvvxosO81o4zYiyks5qgIccgaJpZM4JkIye.\n", "@mrry \nI just find the method `_AddRestoreOps` in `Saver`.\n\nAnd I try to change this node device, from Variable's device to chief device. And it can restore the whole cluster well.\n\n```\n  new_device = '/job:worker/task:0'\n  with ops.device(graph_util.set_cpu0(new_device) if v.device else None):\n# with ops.device(graph_util.set_cpu0(v.device) if v.device else None)\n```\n\nIs this a propositional solution for this issue? Or maybe it may call other errors.\n", "@coderXiangLi I'm not sure exactly what change you're suggesting, but it doesn't look like that is a general fix. We might consider adding an API to place the save and/or restore ops on a different device, but we can't hardcode it to be on `/job:worker/task:0` as that cause far more copies than necessary (from the worker task to the PS tasks, for example).\n"]}, {"number": 3811, "title": "Allows running \"-m tensorflow.tensorboard\" (alternative solution)", "body": "Allows running `python -m tensorflow.tensorboard`. This is a more gentle alternative of #3779.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins Test this please.\n", "Very minor nit, otherwise looks good to me\n", "Year updated.\n", "Cool, thanks for the PR; we'll merge it when tests pass. \n", "Great! By the way, do you need to ask Jenkins again since I pushed the year change?\n", "@tensorflow-jenkins Test this please\n", "Style failed in BUILD file. I have updated it.\n", "@tensorflow-jenkins test this please\n", "@gustavla I feel like this should be mentioned in the documentation somewhere, maybe [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/summaries_and_tensorboard/index.md#launching-tensorboard)?\n", "Good idea, how does this look?\n", "@tensorflow-jenkins test this please\n", "@danmane is this ready to merge?\n", "@tensorflow-jenkins test this please\n", "Looks good. Yeah let's merge on tests pass @rmlarsen \n", "@rmlarsen Updated, thanks.\n\nBy the way, it would be really helpful if either non-admin contributors could ask Jenkins to test, or if `CONTRIBUTING.md` included instructions for how to run local tests to minimize CI failures (like buildifier and unit tests). That could really reduce the burden on admins to babysit minor mistakes like these.\n", "@tensorflow-jenkins test this please\n", "@gustavla agreed, but due to a (temporary) shortage of resources in our Jenkins test cluster (ironic, we are Google :-)), we prefer to not auto-trigger tests or allow contributors to do so. You can certainly run unit tests locally, which I presume you do.  @caisq or @martinwicke can the buildifier tests be run standalone?\n"]}, {"number": 3810, "title": "How can I download TF API document?", "body": "How can i download TF API document?\nSearch in webpage is not so convenient.\n", "comments": ["You can fork a local client from github and read the documents locally. Would that work?\n", "@sherrym yes, that works. However it is not so convenient, it can't support search and navigation. If there is a chm version, it will be so helpful.\n", "It's all Markdown files and GitBook toolchain has ability to to turn\nmarkdown into PDF or ePub, but it would need a bit of work to hook it up\n\nOn Wed, Aug 17, 2016 at 12:29 AM, binTang notifications@github.com wrote:\n\n> @sherrym https://github.com/sherrym yes, that works. However it is not\n> so convenient, it can't support search and navigation. If there is a chm\n> version, it will be so helpful.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3810#issuecomment-240334963,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHJtj3ghMPH8TZTx74D26NhMjM6EOks5qgrhSgaJpZM4JkFaI\n> .\n", "Marking this as contributions welcome as we'd be happy to accept contrib scripts that would streamline this, but it is not something we're likely to get to soon. Thanks!\n", "Hi, @aselle I create a pull reuqest at https://github.com/tensorflow/tensorflow/pull/4747 to fix this. May you help to review it? Thank you in advance!   \n", "The online preview address is https://haosdent.gitbooks.io/tensorflow-document/content/api_docs/\n", "@haosdent I really like your gitbook. Are you planing to update your gitbook peridcoally? It seems your gitbook is not updated to TF 1.0 documents. \r\n\r\n", "@haosdent Can you provide a PDF version?", "Closing due to lack of activity, but we're happy to accept PRs if someone wants to improve the situation.", "I've built a local version of html format, it is official version r1.10. Check it out https://github.com/danyfang/TensorFlow-Documentation-HTML", "@sherrym @rabintang \r\n`You can fork a local client from github and read the documents locally.`\r\n\r\nActually I tried this.. Forked docs from https://github.com/tensorflow/docs and tried building it by running\r\n`python setup.py build`\r\naccording to what was shown in help menu. I am getting errors.\r\n\r\nIs this the actual method to build or am I doing something wrong?\r\nCan you please share a step-by-step guide?\r\n\r\nIt's my first time building docs for offline browsing.. Thank you..", "@danyfang \r\n\r\n> I've built a local version of html format, it is official version r1.10\r\n\r\nCan you also guide me on building docs on local machine to browser offline? It would be a great help.. Please!\r\n\r\nThank you..", "@sherrym @rabintang\r\nI'm getting errors building it too.\r\n@ParikhKadam It's been more than a year now. Any luck?"]}, {"number": 3809, "title": "Fixes for Raspberry Pi docs and build files", "body": "", "comments": []}, {"number": 3808, "title": "Typo", "body": "Fix a typo in some comment.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins Test this please\n"]}, {"number": 3807, "title": "#3767 tanhgrad gradient and sigmoidgrad gradient", "body": "gradient functions for tanhgrad and sigmoidgrad\n", "comments": ["Can one of the admins verify this patch?\n", "Would be nice to have a test for this -- try looking at the tf.test.compute_gradient_error function and example uses throughout the codebase.\n", "By the way: add new commits rather than overwriting old commits, since it makes it easier to incrementally review.\n", "Looks like no more hiding shameful mistakes like math.ops..  :P\nBut I see your point.\n\nStill trying to figure out how to use and test the gradient operations.  If\nsomeone has urgent need for this, feel free to pick it up.  Otherwise I'll\nkeep trying tomorrow night.\n\nOn Mon, Aug 15, 2016 at 10:30 AM, Geoffrey Irving notifications@github.com\nwrote:\n\n> By the way: add new commits rather than overwriting old commits, since it\n> makes it easier to incrementally review.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3807#issuecomment-239868192,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADzDDKiVQvc3rc054t78MVSpfvvWxPxJks5qgKItgaJpZM4Jj8mC\n> .\n", "@girving I am having problems with my laptop after upgrading ubuntu to\n16.04.  I can't get internet and the display manager working.  Should I\nclose this pull request or leave it for someone else to take it over?  I am\nnot sure when i can get back to this.\n\nOn Wed, Aug 17, 2016, 12:03 AM Alan Wu alan.c.wu@gmail.com wrote:\n\n> Looks like no more hiding shameful mistakes like math.ops..  :P\n> But I see your point.\n> \n> Still trying to figure out how to use and test the gradient operations.\n> If someone has urgent need for this, feel free to pick it up.  Otherwise\n> I'll keep trying tomorrow night.\n> \n> On Mon, Aug 15, 2016 at 10:30 AM, Geoffrey Irving <\n> notifications@github.com> wrote:\n> \n> > By the way: add new commits rather than overwriting old commits, since it\n> > makes it easier to incrementally review.\n> > \n> > \u2014\n> > You are receiving this because you authored the thread.\n> > Reply to this email directly, view it on GitHub\n> > https://github.com/tensorflow/tensorflow/pull/3807#issuecomment-239868192,\n> > or mute the thread\n> > https://github.com/notifications/unsubscribe-auth/ADzDDKiVQvc3rc054t78MVSpfvvWxPxJks5qgKItgaJpZM4Jj8mC\n> > .\n", "@chemelnucfin Go ahead and leave it open.  It's linked from the issue, so someone else can easily take it over if they want to.  Otherwise it'll wait for you to return!\n", "Hi, I am new to contributing here and since already some of the work is done by @chemelnucfin, would it be fine for me to try to work on this ?\n", "Please feel free to ( from my point of view at least ).  I am still fixing\nmy laptop.\n\nOn Fri, Aug 26, 2016, 9:11 PM Maniteja Nandana notifications@github.com\nwrote:\n\n> Hi, I am new to contributing here and since already some of the work is\n> done by @chemelnucfin https://github.com/chemelnucfin, would it be fine\n> for me to try to work on this ?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3807#issuecomment-242894565,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADzDDMYyp-VU6BKiCNfL_GmLdRtrviFUks5qj7j9gaJpZM4Jj8mC\n> .\n", "Thank you for letting me know. Will it be okay to fork your branch and push as PRs then ?\n", "Whatever is easiest works for me!\n\nOn Fri, Aug 26, 2016, 9:30 PM Maniteja Nandana notifications@github.com\nwrote:\n\n> Thank you for letting me know. Will it be okay to fork your branch and\n> push as PRs then ?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3807#issuecomment-242895272,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADzDDNRnQr9-T71IURmPvLXvAA9GPzEzks5qj717gaJpZM4Jj8mC\n> .\n", "@maniteja123 sounds great to me, thanks.\n", "Hi, I have some questions regarding adding the tests for `sigmoid_grad` and `tanh_grad`. AFAIU, the tests in `math_ops_test.py` and `math_grad_test.py` are general test suite for `math_ops.py` and `math_grad.py` respectively. Also the `compute_gradient_error` is being done in `math_grad_test.py`. \n\nSimilar to other math ops, should I add the tests in `cwise_ops_test` in `kernel_tests` ? \nAnd regarding specific tests to check if the gradient is getting computed correctly, could you let me know the kind of tests needed ? Thanks.\n", "Hi, I added a small commit e37cf7a9f3fa7bdbd5f9830b0c6934749880ef37. But when I run the test `python/kernel_tests/cwise_test_ops.py`, it is unable to import `tanh_grad` and `sigmoid_grad`. I am unable to find out the reason. It will be really helpful if someone can tell what is it that I am missing ? Thanks.\n", "@maniteja123 are you building the python package and testing using the bazel test  library or are you manually launching python ?\n", "I have setup the environment following the instructions in the documentation. Create a build folder and run `bazel build` before running `bazel test`.\n", "See issue #3767 - another pull request has been made.\n\n@girving sorry for taking off in the middle.\n"]}, {"number": 3806, "title": "Tensorboard not showing any visuals in summaries but is loading everything correctly", "body": "Ubuntu 14.04 64bit Firefox and Chromium\nBuilt from source, master branch.\n**Edit: There appear to be no issues when building from the 0.10RC github release source.**\n\nThe GRAPHS tab displays all correctly, all the summary titles are displayed correctly, it even lets me download CSV/JSON in EVENTS but it doesn't actually display the visuals.\n\nIn HISTOGRAMS all I see are dots instead of the visuals, in EVENTS I see the \"cost_function\" and when I click on it I see it repeated but no accompanying visual.\n\nAll the visuals appear to have empty space allocated to them, nothing appears collapsed.\n\nScreenshots:\nhttp://i.imgur.com/i3B3Rdk.png\nhttp://i.imgur.com/NBhxoNR.png\nScreenshot with the option to download CSV/JSON (they do contain valid data):\nhttp://i.imgur.com/NaTMaTb.png\n\nTerminal output:\n\n```\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET / HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/webcomponentsjs/webcomponents-lite.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /lib/css/global.css HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/lodash/lodash.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/d3/d3.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/plottable/plottable.css HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/plottable/plottable.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/graphlib/dist/graphlib.core.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/dagre/dist/dagre.core.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/polymer/polymer.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-ajax/iron-ajax.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-collapse/iron-collapse.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-list/iron-list.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-button/paper-button.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-checkbox/paper-checkbox.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dialog/paper-dialog.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dropdown-menu/paper-dropdown-menu.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-header-panel/paper-header-panel.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-icon-button/paper-icon-button.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-item/paper-item.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-menu/paper-menu.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-progress/paper-progress.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-radio-button/paper-radio-button.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-radio-group/paper-radio-group.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-slider/paper-slider.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-styles/paper-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-toggle-button/paper-toggle-button.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-toolbar/paper-toolbar.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-tabs/paper-tabs.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /dist/tf-tensorboard.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/polymer/polymer-mini.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-ajax/iron-request.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-resizable-behavior/iron-resizable-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-material/paper-material.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-ripple/paper-ripple.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-behaviors/paper-button-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-flex-layout/iron-flex-layout.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-styles/default-theme.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-behaviors/paper-checked-element-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/neon-animation-runner-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dialog-behavior/paper-dialog-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dialog-behavior/paper-dialog-shared-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-a11y-keys-behavior/iron-a11y-keys-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-behaviors/iron-button-state.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-behaviors/iron-control-state.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-form-element-behavior/iron-form-element-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-icon/iron-icon.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-menu-button/paper-menu-button.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-validatable-behavior/iron-validatable-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dropdown-menu/paper-dropdown-menu-icons.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-dropdown-menu/paper-dropdown-menu-shared-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-behaviors/paper-inky-focus-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-input/iron-input.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input-char-counter.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input-container.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input-error.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-item/paper-item-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-menu-behavior/iron-menu-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-item/paper-item-shared-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-menu/paper-menu-shared-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-styles/color.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-range-behavior/iron-range-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-selector/iron-selectable.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-flex-layout/classes/iron-flex-layout.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-styles/shadow.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-styles/typography.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-menu-behavior/iron-menubar-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-tabs/paper-tabs-icons.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-tabs/paper-tab.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/polymer/polymer-micro.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/promise-polyfill/promise-polyfill-lite.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-material/paper-material-shared-styles.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-behaviors/paper-ripple-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-checked-element-behavior/iron-checked-element-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-meta/iron-meta.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/neon-animatable-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/promise-polyfill/Promise.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-overlay-behavior/iron-overlay-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-iconset-svg/iron-iconset-svg.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-dropdown/iron-dropdown.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/animations/fade-in-animation.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/animations/fade-out-animation.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-menu-button/paper-menu-button-animations.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-a11y-announcer/iron-a11y-announcer.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/paper-input/paper-input-addon-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-selector/iron-multi-selectable.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-selector/iron-selection.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-flex-layout/classes/iron-shadow-flex-layout.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/font-roboto/roboto.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-fit-behavior/iron-fit-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/animations/opaque-animation.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-overlay-behavior/iron-overlay-manager.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-dropdown/iron-dropdown-scroll-manager.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/neon-animation-behavior.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/neon-animation/web-animations.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/iron-overlay-behavior/iron-overlay-backdrop.html HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:14] \"GET /external/web-animations-js/web-animations-next-lite.min.js HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:15] \"GET /data/runs HTTP/1.1\" 200 -\n127.0.0.1 - - [14/Aug/2016 13:49:15] \"GET /data/runs HTTP/1.1\" 200 -\n```\n", "comments": ["I confirm, I see.... or don't see.. the same result.\n![image](https://cloud.githubusercontent.com/assets/6200749/17674065/3be0d95e-6324-11e6-9b50-51064651b872.png)\n", "How are you running TensorBoard? I can't reproduce it here if building from source.\n", "Closed as duplicate of #3750.\n"]}, {"number": 3805, "title": "Errors Building with Cuda 8 and CuDNN 5.1", "body": "System:\nUbuntu 16.04\nNVidia Driver Version: 367.35\nCuda 8.0\nCuDNN 5.1.5\n1.  Have to add into third_party/gpus/crosstool/CROSSTOOL an extra line to point to cuda-8.0 include\n   cxx_builtin_include_directory: \"/usr/local/cuda-8.0/include\"\n2.  When building: \n   bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\n\nExplicit Error Received:\n1 error detected in the compilation of \"/tmp/tmpxft_00005521_00000000-7_depthtospace_op_gpu.cu.cpp1.ii\".\nERROR: /home/drcrook/TensorFlow/tensorflow/tensorflow/core/kernels/BUILD:1529:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/tensorflow/core/kernels/depthtospace_op_gpu.cu.pic.o' was not created.\nERROR: /home/drcrook/TensorFlow/tensorflow/tensorflow/core/kernels/BUILD:1529:1: not all outputs were created.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n", "comments": ["Alright, so I resolved my issue by using a different branch...\ngit checkout r0.10\nThe default branch appears to just be broken every other day...\n", "The continuous builds pass (ie depthtospace_op_test in here\nhttp://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/),\nso I wonder what is it that makes a difference. CUDA 8.0 instead of\nsupported 7.5 maybe?\n\nOn Sun, Aug 14, 2016 at 8:09 AM, David Crook notifications@github.com\nwrote:\n\n> Alright, so I resolved my issue by using a different branch...\n> git checkout r0.10\n> The default branch appears to just be broken every other day...\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3805#issuecomment-239678676,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHNEwcCf3w64Coe1qmnB19q_0ZPS7ks5qfy-rgaJpZM4Jj6Fu\n> .\n", "I would suspect its CUDA 8 or CuDNN 5.1.5 I'm not really familiar enough with either right now to make an educated assessment.\n", "So not really a solution, but one thing to try is to try is CUDA 8 and\nCuDNN 5.0\nLast week I've been re-building with this configuration daily with no\nproblems\n\nOn Sun, Aug 14, 2016 at 9:20 AM, David Crook notifications@github.com\nwrote:\n\n> I would suspect its CUDA 8 or CuDNN 5.1.5 I'm not really familiar with\n> either right now to make an educated assessment.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3805#issuecomment-239682278,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHJiopAqzmje2zDrdzDsfo5DjRxZUks5qf0BdgaJpZM4Jj6Fu\n> .\n", "I was able to get a successful build against r0.10 using the latest of both, so I'm going to run with that for a while.  Not sure whats up with the default branch or why I would use that instead of the r0.10 branch.\n", "The head is under active development and could be unstable at times. Please continue to use the released branch. Thanks!\n"]}, {"number": 3804, "title": "retrain.py, changed graph_util import statement", "body": "First attempt at a Pull Request, please be gentle:\n\nI tried the TensorFlow For Poets tutorial today and followed the instructions, but retrain.py kept crashing because graph_util was being imported from the wrong location.  That's line 80.\n\nAfter the change, the tutorial went as planned!\n\nI also ran 2to3 on it...which apparently got rid of the from **future_** statements.  Hmm.\n\nThe rest is just formatting changes, PEP8 stuff.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thanks for the attempt -- unfortunately the existing code is correct: graph_util.py was moved into framework a month ago, so most likely you're using an older version of TensorFlow installed against a newer copy of the retrain.py code.  You can either upgrade your existing TF install to 0.10.0.rc0 or check out the copy of retrain.py at the version branch you have installed.\n"]}, {"number": 3803, "title": "Update Glossary section in Distributed TensorFlow document.", "body": "Let layout like [Glossary](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/resources/glossary.md).\nAnd it  more friendly for reading when using browser.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3802, "title": "seq2seq.py: Fixed the documentation to be consistent with the code", "body": "A fix for https://github.com/tensorflow/tensorflow/issues/3800\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Hi sahiliitm . I looked at your changed comments, but I don't understand them. What is `output_size`, what part of arguments is it? Are the current comments not correct? Can you explain?\n", "Hi Lukas,\n\nI have documented the bug [here](https://github.com/tensorflow/tensorflow/issues/3800). Please let me know if it is not clear. :) \nIn short, the outputs of the two functions (for which I have changed the comments) do not return tensors of size `(batch_size, num_decoder_symbols)` but rather of size `(batch_size, output_size)` where `output_size` is the same parameter as [documented for the function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L252) `embedding_rnn_decoder`\n", "Oh, I see, what is meant by output_size is cell.output_size (the comment just missed that). But I think you're not fully correct -- the functions do output num_decoder_symbol-sized tensors sometimes, it depends on the output_projection. If you're correcting it, please make it fully correct. I'll be away from github for a few weeks now, so there might be a delay in my answers, sorry.\n", "Are you sure that is the case? \nThe reason I doubt that is because of this [line of code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py#L161). We do pass the parameters `output_projection` to the function `tf.nn.seq2seq.model_with_buckets` (indirectly through the function defined at [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py#L125)) in [seq2seq_model.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py) but the output returned by it is still a `cell.output_size` sized tensor. Which is why the line of code I pointed out is needed to project it back to the size `num_decoder_symbols`.\n\nI guess what I'm asking is that if `output_projection` parameters are not `None`, is that the case when the functions under question would return `num_decoder_symbol` sized tensors? That does not seem to be the case.\n", "I think the seq2seq module behaves like you say in the end: if output_projection is not None, it returns cell.output_size - sized tensors. If it is None, it returns num_decoder_symbol - sized tensors. Is it not so?\n\nThe seq2seq_model example is a bit different. It uses sampled softmax, but that's only good for training. When decoding, it cannot sample from the softmax, so it just returns the dense logits. But that's seq2seq_model -- let's keep it separate from this issue, which is changing the seq2seq module.\n\nOr am I missing something? Let me know!\n", "Hi Lukas, \n\nSorry for the delayed reply. I was a bit busy. I agree with you. I've changed the comments accordingly.\nthanks\n", "It looks good to me now, great thanks for clarifying and making the code better! There is one small nit: it looks like the indentation of your comments is off. I'm not even sure if that's the case of if it's just the online viewer, but could you take a look and make sure they're indented ok? (I mean: the multi-line argument comments should be a few spaces to the left -- same as other comments in the file.)\n\nExcept for this, we should merge this. Some checks seem to still be running...\n", "Hi,\nSorry! Indeed, some of the comments were badly formatted. I've fixed that now.\nThanks for pointing it out.\n", "Looks good to me, thanks! Can we merge this one? Thanks! (Assigned vrv@ just for merging.)\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3801, "title": "Unclear documentation on dynamic_rnn vs rnn for efficient dynamic sequence length computation", "body": "It looks like from the latest documentation that `rnn` performs early stopping for dynamic length sequences whereas `dynamic_rnn` does not? This would seem to be the reverse of the intuition. \n\nSo it looks like in commit 855d3b56014780a90143b3e0c0865334b188c2df, the definition of `dynamic_rnn` was changed from:\n\n> The parameter `sequence_length` is required and dynamic calculation is\n> automatically performed.\n\nto:\n\n>  The parameter `sequence_length` is optional and is used to copy-through state\n>  and zero-out outputs when past a batch element's sequence length. So it's more\n>  for correctness than performance, unlike in rnn().\n\nWhereas the `rnn` documentation states:\n\n>   If the sequence_length vector is provided, dynamic calculation is performed.\n>   This method of calculation does not compute the RNN steps past the maximum\n>   sequence length of the minibatch (thus saving computational time),\n\nFor me this makes it very unclear. In this context, does `rnn` do \"more dynamic\" unrolling than `dynamic_rnn` because it actually uses sequence_length to stop early. So if I want to do efficient variable length sequences dynamically, I should use `rnn` instead of `dynamic_rnn`. \n\nIn this case, what does `dynamic_rnn` actually do (what is \"dynamic unrolling\" explicitly defined), except for accept input in a different format?\n", "comments": ["This is correct.  When running `dynamic_rnn`, it is assumed that the inputs' max_time dimension is the **maximum number of frames in your minibatch**, and can vary from step to step.  In this case, early stopping is not required: we run up to the maximum number of timesteps in your minibatch.  In contrast when feeding `rnn` you must always provide a fixed number of inputs, which is in general longer than the maximum number of frames in your minibatch.  In this case `sequence_length` is also used to perform early stopping on the calculation.\n\nThat said, if you can suggest (or even better, submit a PR) with a clarifying comment, that would be great.\n", "It would be nice if `dynamic_rnn` handled things like the fully unrolled `rnn`, by simply looking at the maximum length in `sequence_length` for each minibatch and quitting early. Requiring that the user actually vary the dimensions of the passed in tensor seems unnecessary, if the information contained in `sequence_length` is already sufficient to make the determination that past a certain time_step, all sequences in the current minibatch are padded and so it's safe to quit early.\n", "But it seems like the earlier version of dynamic _rnn was documented to stop early rather than trying the full time dimension. Was there a reason for the change?\n\nAlso @ebrevdo it seems that you can change the max time steps from step to step, but you can't actually have different max time dimension within a single batch for dynamic_rnn. But for the regular rnn function you can optimize per sample per step. Is this correct?\n", "Also, could you clarify what it means to statically unroll an rnn vs dynamically unroll? The terms are a little unclear and I wasn't able to find much supporting documentation. \n", "@alquraishi it's wasteful (in terms of both memory usage _and_ calls to `cond` within `dynamic_rnn`) to create a padded tensor past the max sequence length, and dynamic_rnn is trying to be as efficient as possible given constraints of wanting correctness.  since the user is able to change the shape from step to step, it is up to the user to do this correctly.\n\n@lingz static unroll in `rnn` means you have a fixed number of input tensors and you run through all of them.  dynamic unroll in `rnn` means you stop calculating the RNNCell past the maximum sequence_length value, and fill in the rest of the outputs with zeros.\n\nyou cannot optimize calculations per example and per step; because tensorflow relies on vectorized calculations.  the best you can do is perform calculations up to the max sequence_length, zeroing out the outputs of examples that have finished as you go along,  then past the max sequence_length you can exit the calculation early as i explained in the previous paragraph.\n\nlong story short: early stopping in `rnn` relies on `sequence_length`, but is wasteful in `dynamic_rnn`.  `dynamic_rnn` relies on the fact that your input shape can vary from step to step to perform **true** dynamic stopping.  there is no per-example per-time dynamic stopping anywhere due to vectorization of operations.\n\nif you would like to update the documentation clarifying these points, please submit a PR and I will be happy to review.  we can then reference this issue in the PR.\n"]}, {"number": 3800, "title": "Problems in Tensorflow Seq2Seq Tutorial", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \nCuda 7.5 and CuDNN v4\nOutput of ls -l /path/to/cuda/lib/cuda*:\n\n```\n-rwxrwxrwx 1 root root   322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxrwxrwx 1 root root   383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n-rwxrwxrwx 1 root root   720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\n-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so\n-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so.4\n-rwxrwxrwx 1 root root 61272736 Jul 31 21:45 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.4\n```\n\npip package installed from:\n\n```\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n```\n\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0rc0\n```\n\nThe problem:\nI'm trying out the seq2seq tutorial on natural language translation. \nThe documentation of [seq2seq.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L1086)\nmentions that the output consists of per bucket output with each bucket containing tensors of shape \n\"batch_size x num_decoder_symbols\". This seems to be incorrect because when i print the tensorflow sizes inside the function, they turn out to be (?, 1024). In other words, (batch_size, layer_size). I think either the documentation or the code is wrong, and there is certainly a mismatch. I'm wondering which is the case?\n### Steps to reproduce\n1. Install Tensorflow\n2. Clone this repo\n3. edit \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py\"\n   to include the following print statement after [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L1113)\n\n```\nprint(bucket_outputs[0].get_shape())\n```\n### What have you tried?\n1. Filed this bug.\n", "comments": ["Another thing I've noticed is that this problem only arises when the `forward_only` parameter in the [constructor](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py#L58) of Seq2Seq_model is set. \nTo verify this:\n1) add the code\n\n```\nprint(output_logits[0].shape)\n```\n\nafter [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py#L248) in translate.py\n\n2) Next run the code as `python translate.py --decode` twice. \n2.1) In the first run, set the second argument in [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py#L222) to `True` as in the original case. In this case the output of our print statement is:\n\n```\n(1, 40000)\n```\n\n2.2 In the second run, set the second argument in [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py#L222) to `False`. This mimics  training. In this case the output of our print statement is:\n\n```\n(1, 1024)\n```\n\nEDIT:\nI think I found the source of this problem. The [TF  operations](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py#L161) for converting from dense-representation to probability distribution over output tokens are only added when `forward_only` is set. This seems reasonable given that we do not wish to do extra operations during training time. However, this would be necessary to track other performance measures such as BLEU score, which give a better evaluation of the translation model.\n\nIn any case, I think the [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L1086) has to be changed to reflect that what model_with_buckets returns is a dense representation and not a probability distribution over the sparse one. I'll probably submit a PR with documentation updated. \n", "This is a documentation problem being worked on in #3802 -- please look there, closing this issue.\n"]}, {"number": 3799, "title": "distributed tensorflow on localhosts failed by \u201csocket error, connection refused\u201d", "body": "I am experimenting distributed tensorflow using a slight modification of an [official example](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html).\n\nMy experiment code is (you can skip this for now and scroll down to the problem),\n\n```\nimport tensorflow as tf\nimport numpy as np\n\n# Flags for defining the tf.train.ClusterSpec\ntf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\n\n# Flags for defining the tf.train.Server\ntf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    ps_hosts = FLAGS.ps_hosts.split(\",\")\n    worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n    # Create a cluster from the parameter server and worker hosts.\n    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster,\n                             job_name=FLAGS.job_name,\n                             task_index=FLAGS.task_index)\n\n    if FLAGS.job_name == \"ps\":\n        server.join()\n    elif FLAGS.job_name == \"worker\":\n        # Assigns ops to the local worker by default.\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster)):\n\n            # Build model...\n            x = tf.placeholder(\"float\", [10, 10], name=\"x\")\n            y = tf.placeholder(\"float\", [10, 1], name=\"y\")\n            initial_w = np.zeros((10, 1))\n            w = tf.Variable(initial_w, name=\"w\", dtype=\"float32\")\n            loss = tf.pow(tf.add(y,-tf.matmul(x,w)),2,name=\"loss\")\n            global_step = tf.Variable(0)\n\n            saver = tf.train.Saver()\n            summary_op = tf.merge_all_summaries()\n            init_op = tf.initialize_all_variables()\n\n        # Create a \"supervisor\", which oversees the training process.\n        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n                                 logdir=\"/tmp/train_logs\",\n                                 init_op=init_op,\n                                 summary_op=summary_op,\n                                 saver=saver,\n                                 global_step=global_step,\n                                 save_model_secs=600)\n\n        # The supervisor takes care of session initialization, restoring from\n        # a checkpoint, and closing when done or an error occurs.\n        with sv.managed_session(server.target) as sess:\n            # Loop until the supervisor shuts down or 1000000 steps have completed.\n            step = 0\n            while not sv.should_stop() and step < 1000000:\n                # Run a training step asynchronously.\n                # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n                # perform *synchronous* training.\n                _, step = sess.run([loss, global_step])\n                print(\"job_name: %s; task_index: %s; step: %d\" % (FLAGS.job_name,FLAGS.task_index,step))\n\n        # Ask for all the services to stop.\n        sv.stop()\n\n\nif __name__ == \"__main__\":\n    tf.app.run()\n```\n\nThen I run the following commands as instructed by the official document, changing the example host names to \"localhost\" (the script is named hello_distributed.py),\n\n```\nlocalhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=0\n\nsudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=ps --task_index=1\n\nsudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=0\n\nsudo python3 hello_distributed.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2777,localhost:2778 --job_name=worker --task_index=1\n```\n\nThe first two lines for running \"ps\" are good. The last two lines get the following \"connection refused\" error.\n\n![image](https://cloud.githubusercontent.com/assets/18235797/17646308/036f3360-6192-11e6-9e1a-4a4ef88f8264.png)\n\nAnyone can help with this? Thank you!\n", "comments": ["It looks like you didn't start the second worker. And you can start only one parameter server and two workers to simplify the situation a bit.\n", "Indeed, this is a common error when one of the workers have crashed.\n", "It might help to have a script that launches all your processes. Adapt to your needs and run the entire script with `sudo`:\n\n```\n#!/bin/bash\nCOUNT_PS_HOSTS=2\nPS_HOSTS=localhost:2222,localhost:2223\nCOUNT_WORKER_HOSTS=2\nWORKER_HOSTS=localhost:2777,localhost:2778\n\nfor INDEX in `seq 0 $(expr $COUNT_PS_HOSTS - 1)`\ndo\n    python3 hello_distributed.py \\\n            --ps_hosts=$PS_HOSTS \\\n            --worker_hosts=$WORKER_HOSTS \\\n            --job_name=ps \\\n            --task_index=$INDEX |& tee ps.${INDEX}.log &\ndone\n\nfor INDEX in `seq 0 $(expr $COUNT_WORKER_HOSTS - 1)`\ndo\n    python3 hello_distributed.py \\\n            --ps_hosts=$PS_HOSTS \\\n            --worker_hosts=$WORKER_HOSTS \\\n            --job_name=worker \\\n            --task_index=$INDEX |& tee worker.${INDEX}.log &\ndone\n```\n\nAfter executing the script you can use the files `worker.0.log` and `worker.1.log` to examine the output of the individual workers and see if they have emitted some errors.\n", "Thanks @hholst80 and @avostryakov for the responses. @tonyrivermsfly , is the problem resolved? Thanks.\n", "When I run the example code, I get this error\n\n```\nTraceback (most recent call last):\n  File \"hello_distributed.py\", line 75, in <module>\n    tf.app.run()\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"hello_distributed.py\", line 67, in main\n    _, step = sess.run([loss, global_step])\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'y' with dtype float and shape [10,1]\n     [[Node: y = Placeholder[dtype=DT_FLOAT, shape=[10,1], _device=\"/job:worker/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'y', defined at:\n  File \"hello_distributed.py\", line 75, in <module>\n    tf.app.run()\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"hello_distributed.py\", line 39, in main\n    y = tf.placeholder(\"float\", [10, 1], name=\"y\")\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1173, in placeholder\n    name=name)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1322, in _placeholder\n    name=name)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2297, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/work/.jumbo/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1231, in __init__\n    self._traceback = _extract_stack()\n```\n", "Hi guys, thank you for all your help!\n\nYes, when it says \"connection refused\", it actually means the program has crashed, and that **means there could be some error in the code**. It turns out I forgot to feed sess.run function.\n\nIn the script I use\n\n`_, step = sess.run([loss, global_step])`\n\nwhich has no feed for loss. The correct code is\n\n```\n                _, step = sess.run([loss, global_step],\n                {\n                  x: np.random.rand(10,10),\n                  y: np.random.rand(10).reshape(-1,1)\n                })\n```\n\nNow everything works! Thank you guys! Special thank you to @hholst80 for providing the script.\n\nThe whole working code is posted below,\n\n```\nimport tensorflow as tf\nimport numpy as np\n\n# Flags for defining the tf.train.ClusterSpec\ntf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\n\n# Flags for defining the tf.train.Server\ntf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    ps_hosts = FLAGS.ps_hosts.split(\",\")\n    worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n    # Create a cluster from the parameter server and worker hosts.\n    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster,\n                             job_name=FLAGS.job_name,\n                             task_index=FLAGS.task_index)\n\n    if FLAGS.job_name == \"ps\":\n        server.join()\n    elif FLAGS.job_name == \"worker\":\n        # Assigns ops to the local worker by default.\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n                cluster=cluster)):\n\n            # Build model...\n            x = tf.placeholder(\"float\", [10, 10], name=\"x\")\n            y = tf.placeholder(\"float\", [10, 1], name=\"y\")\n            initial_w = np.zeros((10, 1))\n            w = tf.Variable(initial_w, name=\"w\", dtype=\"float32\")\n            loss = tf.pow(tf.add(y,-tf.matmul(x,w)),2,name=\"loss\")\n            global_step = tf.Variable(0)\n\n            saver = tf.train.Saver()\n            summary_op = tf.merge_all_summaries()\n            init_op = tf.initialize_all_variables()\n\n        # Create a \"supervisor\", which oversees the training process.\n        sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n                                 logdir=\"/tmp/train_logs\",\n                                 init_op=init_op,\n                                 summary_op=summary_op,\n                                 saver=saver,\n                                 global_step=global_step,\n                                 save_model_secs=600)\n\n        # The supervisor takes care of session initialization, restoring from\n        # a checkpoint, and closing when done or an error occurs.\n        with sv.managed_session(server.target) as sess:\n            # Loop until the supervisor shuts down or 1000000 steps have completed.\n            step = 0\n            while not sv.should_stop() and step < 1000000:\n                # Run a training step asynchronously.\n                # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n                # perform *synchronous* training.\n                _, step = sess.run([loss, global_step],\n                {\n                  x: np.random.rand(10,10),\n                  y: np.random.rand(10).reshape(-1,1)\n                })\n                print(\"job_name: %s; task_index: %s; step: %d\" % (FLAGS.job_name,FLAGS.task_index,step))\n\n        # Ask for all the services to stop.\n        sv.stop()\n\n\nif __name__ == \"__main__\":\n    tf.app.run()\n```\n", "@sherrym  Yes the problem is now solved. Thank you!\n"]}]